{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc802916-2d8d-4787-9027-5f62c0a67d0f",
   "metadata": {},
   "source": [
    "# Sample code for Separate VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4459dd4a-c400-4707-a2f5-f0b1f3048309",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, cast, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d0ef72-173f-4faf-ae15-1db424d924d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param #0: features.0.weight\n",
      "param #1: features.0.bias\n",
      "param #2: features.2.weight\n",
      "param #3: features.2.bias\n",
      "param #4: features.5.weight\n",
      "param #5: features.5.bias\n",
      "param #6: features.7.weight\n",
      "param #7: features.7.bias\n",
      "param #8: features.10.weight\n",
      "param #9: features.10.bias\n",
      "param #10: features.12.weight\n",
      "param #11: features.12.bias\n",
      "param #12: features.14.weight\n",
      "param #13: features.14.bias\n",
      "param #14: features.17.weight\n",
      "param #15: features.17.bias\n",
      "param #16: features.19.weight\n",
      "param #17: features.19.bias\n",
      "param #18: features.21.weight\n",
      "param #19: features.21.bias\n",
      "param #20: features.24.weight\n",
      "param #21: features.24.bias\n",
      "param #22: features.26.weight\n",
      "param #23: features.26.bias\n",
      "param #24: features.28.weight\n",
      "param #25: features.28.bias\n",
      "param #26: classifier.0.weight\n",
      "param #27: classifier.0.bias\n",
      "param #28: classifier.3.weight\n",
      "param #29: classifier.3.bias\n",
      "param #30: classifier.6.weight\n",
      "param #31: classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 Model\n",
    "vgg_model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Get state_dict of top 5 layers\n",
    "top_layers_state_dict = {}\n",
    "for i, (layer_name, param) in enumerate(vgg_model.named_parameters()):\n",
    "    print(f'param #{i}: {layer_name}')\n",
    "    if 'features' in layer_name and i < 5*2:\n",
    "        top_layers_state_dict[layer_name] = param\n",
    "\n",
    "# save file path\n",
    "save_path = 'vgg_top5_layers.pth'\n",
    "\n",
    "# save state_dict\n",
    "torch.save(top_layers_state_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92378d5b-160d-4996-8d9b-ef54943bddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and modify from https://pytorch.org/vision/main/_modules/torchvision/models/vgg.html#vgg16\n",
    "\n",
    "__all__ = [\n",
    "    \"VGG\",\n",
    "    \"VGG11_Weights\",\n",
    "    \"VGG11_BN_Weights\",\n",
    "    \"VGG13_Weights\",\n",
    "    \"VGG13_BN_Weights\",\n",
    "    \"VGG16_Weights\",\n",
    "    \"VGG16_BN_Weights\",\n",
    "    \"VGG19_Weights\",\n",
    "    \"VGG19_BN_Weights\",\n",
    "    \"vgg11\",\n",
    "    \"vgg11_bn\",\n",
    "    \"vgg13\",\n",
    "    \"vgg13_bn\",\n",
    "    \"vgg16\",\n",
    "    \"vgg16_bn\",\n",
    "    \"vgg19\",\n",
    "    \"vgg19_bn\",\n",
    "]\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(\n",
    "        self, features: nn.Module, num_classes: int = 1000, init_weights: bool = True, dropout: float = 0.5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, 0, 0.01)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False, n_layers: int=100) -> nn.Sequential:\n",
    "    layers: List[nn.Module] = []\n",
    "    in_channels = 3\n",
    "    feature_count = 0\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            v = cast(int, v)\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "\n",
    "            feature_count += 1\n",
    "\n",
    "        if (feature_count >= n_layers):\n",
    "            break\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs: Dict[str, List[Union[str, int]]] = {\n",
    "    \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "    \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg_features(cfg: str, batch_norm: bool, progress: bool, n_layers: int, **kwargs: Any) -> VGG:\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm, n_layers=n_layers), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e155d0df-4e98-498d-b211-66d1bf74a2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_features = vgg_features(\"D\", False, True, 5)\n",
    "vgg_model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e04fd3e-7a89-41df-8005-b556c820bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_features.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b59ec4-46e6-4acb-a96c-0594c497398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_features.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb04b45-2c3e-4b93-b5a6-0be093434d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9733a8-bf8d-4c71-b94f-7f5c90c07955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "feature_tensor = vgg_model_features(input_tensor)\n",
    "print(feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de1ba9c-5db5-4702-b0bd-2ff59930dc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f97929d23b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tensor_hook = None\n",
    "def hook_fn(module, input, output):\n",
    "    global feature_tensor_hook\n",
    "    feature_tensor_hook = output\n",
    "\n",
    "hook_layer = vgg_model.features[11]\n",
    "hook_layer.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b80585-cb52-4596-8d77-d432d7f11255",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.eval()\n",
    "output_tensor = vgg_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0752b353-e6d7-46e0-92b7-6764f53f7f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 7.2432,  0.0000,  2.7085,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 8.9935,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 9.2600,  0.0000,  1.5271,  ...,  9.7830,  0.8683,  0.0000],\n",
       "          [16.1120,  5.3304,  0.0000,  ...,  0.0000,  2.3761,  0.0000],\n",
       "          [14.4671, 14.3048, 11.8593,  ...,  3.2519,  5.1902,  1.0948]],\n",
       "\n",
       "         [[ 5.7436,  9.6808,  3.4098,  ...,  4.9111, 12.2151, 13.2478],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.6748],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  8.2324],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.7248],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  9.6312,  8.9141,  ..., 12.8768, 16.8608, 17.6182]],\n",
       "\n",
       "         [[ 4.7295,  0.0000,  9.6665,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  4.0611, 10.8563,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 2.1227,  0.0000, 11.4712,  ...,  4.8172,  9.6870,  0.0000],\n",
       "          [11.6715,  0.0000,  9.5214,  ...,  7.1309,  7.7059,  2.7490],\n",
       "          [15.6924,  6.9858,  4.2531,  ...,  7.1511,  9.3001, 11.7540]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.7417],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.9820],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.3384],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.1502],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.9960],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.9994]],\n",
       "\n",
       "         [[ 1.4542,  0.0000,  0.0000,  ...,  7.1711,  1.8400,  5.2279],\n",
       "          [ 6.4352,  0.0000,  0.6588,  ...,  1.0760,  0.0000,  1.0821],\n",
       "          [17.5868,  0.0000,  0.0000,  ...,  5.8918,  0.4762, 16.9521],\n",
       "          ...,\n",
       "          [10.1350,  0.0000,  0.0000,  ...,  7.9151,  4.5425, 14.8016],\n",
       "          [ 9.6212,  0.0000,  0.0000,  ...,  0.1911,  0.0000,  9.4401],\n",
       "          [ 5.7806,  2.3004,  3.7223,  ...,  8.4703,  8.2508, 15.4800]],\n",
       "\n",
       "         [[20.3152, 18.4194, 22.2375,  ..., 15.8435,  7.1761,  0.0000],\n",
       "          [10.4704,  4.2538,  9.6498,  ...,  0.3593,  0.0000,  0.0000],\n",
       "          [22.1811,  2.2695,  8.8327,  ..., 15.7296, 11.0097,  0.0000],\n",
       "          ...,\n",
       "          [19.1758, 12.4513,  9.6416,  ...,  7.8907, 13.2093,  0.0000],\n",
       "          [20.0226,  8.9046,  7.6609,  ...,  6.0386, 13.6334,  0.0000],\n",
       "          [18.1327,  6.6856, 10.9849,  ..., 16.4824, 17.7856,  4.1801]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tensor_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e5a1bc-2ef0-4126-8034-1b73e392a36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 7.2432,  0.0000,  2.7085,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 8.9935,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 9.2600,  0.0000,  1.5271,  ...,  9.7830,  0.8683,  0.0000],\n",
       "          [16.1120,  5.3304,  0.0000,  ...,  0.0000,  2.3761,  0.0000],\n",
       "          [14.4671, 14.3048, 11.8593,  ...,  3.2519,  5.1902,  1.0948]],\n",
       "\n",
       "         [[ 5.7436,  9.6808,  3.4098,  ...,  4.9111, 12.2151, 13.2478],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.6748],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  8.2324],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.7248],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  9.6312,  8.9141,  ..., 12.8768, 16.8608, 17.6182]],\n",
       "\n",
       "         [[ 4.7295,  0.0000,  9.6665,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  4.0611, 10.8563,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 2.1227,  0.0000, 11.4712,  ...,  4.8172,  9.6870,  0.0000],\n",
       "          [11.6715,  0.0000,  9.5214,  ...,  7.1309,  7.7059,  2.7490],\n",
       "          [15.6924,  6.9858,  4.2531,  ...,  7.1511,  9.3001, 11.7540]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.7417],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  5.9820],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.3384],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.1502],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.9960],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  4.9994]],\n",
       "\n",
       "         [[ 1.4542,  0.0000,  0.0000,  ...,  7.1711,  1.8400,  5.2279],\n",
       "          [ 6.4352,  0.0000,  0.6588,  ...,  1.0760,  0.0000,  1.0821],\n",
       "          [17.5868,  0.0000,  0.0000,  ...,  5.8918,  0.4762, 16.9521],\n",
       "          ...,\n",
       "          [10.1350,  0.0000,  0.0000,  ...,  7.9151,  4.5425, 14.8016],\n",
       "          [ 9.6212,  0.0000,  0.0000,  ...,  0.1911,  0.0000,  9.4401],\n",
       "          [ 5.7806,  2.3004,  3.7223,  ...,  8.4703,  8.2508, 15.4800]],\n",
       "\n",
       "         [[20.3152, 18.4194, 22.2375,  ..., 15.8435,  7.1761,  0.0000],\n",
       "          [10.4704,  4.2538,  9.6498,  ...,  0.3593,  0.0000,  0.0000],\n",
       "          [22.1811,  2.2695,  8.8327,  ..., 15.7296, 11.0097,  0.0000],\n",
       "          ...,\n",
       "          [19.1758, 12.4513,  9.6416,  ...,  7.8907, 13.2093,  0.0000],\n",
       "          [20.0226,  8.9046,  7.6609,  ...,  6.0386, 13.6334,  0.0000],\n",
       "          [18.1327,  6.6856, 10.9849,  ..., 16.4824, 17.7856,  4.1801]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6730159d-401a-4e9f-83d6-daeb13ec95b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_tensor_hook == feature_tensor).all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
