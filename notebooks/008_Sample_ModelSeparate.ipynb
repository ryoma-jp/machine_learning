{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cc802916-2d8d-4787-9027-5f62c0a67d0f",
   "metadata": {},
   "source": [
    "# Sample code for Separate VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4459dd4a-c400-4707-a2f5-f0b1f3048309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-13 07:18:24.327521: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-04-13 07:18:24.327571: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-04-13 07:18:24.328304: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-04-13 07:18:24.332360: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from typing import Any, cast, Dict, List, Optional, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "\n",
    "import tensorflow as tf\n",
    "import onnx2tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd3c7ca-4fac-4cb6-8612-74b638e875fb",
   "metadata": {},
   "source": [
    "## Separate VGG16 model top 5 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63d0ef72-173f-4faf-ae15-1db424d924d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "param #0: features.0.weight\n",
      "param #1: features.0.bias\n",
      "param #2: features.2.weight\n",
      "param #3: features.2.bias\n",
      "param #4: features.5.weight\n",
      "param #5: features.5.bias\n",
      "param #6: features.7.weight\n",
      "param #7: features.7.bias\n",
      "param #8: features.10.weight\n",
      "param #9: features.10.bias\n",
      "param #10: features.12.weight\n",
      "param #11: features.12.bias\n",
      "param #12: features.14.weight\n",
      "param #13: features.14.bias\n",
      "param #14: features.17.weight\n",
      "param #15: features.17.bias\n",
      "param #16: features.19.weight\n",
      "param #17: features.19.bias\n",
      "param #18: features.21.weight\n",
      "param #19: features.21.bias\n",
      "param #20: features.24.weight\n",
      "param #21: features.24.bias\n",
      "param #22: features.26.weight\n",
      "param #23: features.26.bias\n",
      "param #24: features.28.weight\n",
      "param #25: features.28.bias\n",
      "param #26: classifier.0.weight\n",
      "param #27: classifier.0.bias\n",
      "param #28: classifier.3.weight\n",
      "param #29: classifier.3.bias\n",
      "param #30: classifier.6.weight\n",
      "param #31: classifier.6.bias\n"
     ]
    }
   ],
   "source": [
    "# Load VGG16 Model\n",
    "vgg_model = models.vgg16(pretrained=True)\n",
    "\n",
    "# Get state_dict of top 5 layers\n",
    "top_layers_state_dict = {}\n",
    "for i, (layer_name, param) in enumerate(vgg_model.named_parameters()):\n",
    "    print(f'param #{i}: {layer_name}')\n",
    "    if 'features' in layer_name and i < 5*2:\n",
    "        top_layers_state_dict[layer_name] = param\n",
    "\n",
    "# save file path\n",
    "save_path = 'vgg_top5_layers.pth'\n",
    "\n",
    "# save state_dict\n",
    "torch.save(top_layers_state_dict, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92378d5b-160d-4996-8d9b-ef54943bddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy and modify from https://pytorch.org/vision/main/_modules/torchvision/models/vgg.html#vgg16\n",
    "\n",
    "__all__ = [\n",
    "    \"VGG\",\n",
    "    \"VGG11_Weights\",\n",
    "    \"VGG11_BN_Weights\",\n",
    "    \"VGG13_Weights\",\n",
    "    \"VGG13_BN_Weights\",\n",
    "    \"VGG16_Weights\",\n",
    "    \"VGG16_BN_Weights\",\n",
    "    \"VGG19_Weights\",\n",
    "    \"VGG19_BN_Weights\",\n",
    "    \"vgg11\",\n",
    "    \"vgg11_bn\",\n",
    "    \"vgg13\",\n",
    "    \"vgg13_bn\",\n",
    "    \"vgg16\",\n",
    "    \"vgg16_bn\",\n",
    "    \"vgg19\",\n",
    "    \"vgg19_bn\",\n",
    "]\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(\n",
    "        self, features: nn.Module, num_classes: int = 1000, init_weights: bool = True, dropout: float = 0.5\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.features = features\n",
    "        if init_weights:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, nn.Conv2d):\n",
    "                    nn.init.kaiming_normal_(m.weight, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "                    if m.bias is not None:\n",
    "                        nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.BatchNorm2d):\n",
    "                    nn.init.constant_(m.weight, 1)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    nn.init.normal_(m.weight, 0, 0.01)\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def make_layers(cfg: List[Union[str, int]], batch_norm: bool = False, n_layers: int=100) -> nn.Sequential:\n",
    "    layers: List[nn.Module] = []\n",
    "    in_channels = 3\n",
    "    feature_count = 0\n",
    "    for v in cfg:\n",
    "        if v == \"M\":\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            v = cast(int, v)\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "\n",
    "            feature_count += 1\n",
    "\n",
    "        if (feature_count >= n_layers):\n",
    "            break\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs: Dict[str, List[Union[str, int]]] = {\n",
    "    \"A\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"B\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"D\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, \"M\", 512, 512, 512, \"M\", 512, 512, 512, \"M\"],\n",
    "    \"E\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, 256, 256, \"M\", 512, 512, 512, 512, \"M\", 512, 512, 512, 512, \"M\"],\n",
    "}\n",
    "\n",
    "\n",
    "def vgg_features(cfg: str, batch_norm: bool, progress: bool, n_layers: int, **kwargs: Any) -> VGG:\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm, n_layers=n_layers), **kwargs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e155d0df-4e98-498d-b211-66d1bf74a2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_features = vgg_features(\"D\", False, True, 5)\n",
    "vgg_model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e04fd3e-7a89-41df-8005-b556c820bfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_features.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6b59ec4-46e6-4acb-a96c-0594c497398e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VGG(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (6): ReLU(inplace=True)\n",
       "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (8): ReLU(inplace=True)\n",
       "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg_model_features.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb04b45-2c3e-4b93-b5a6-0be093434d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = torch.randn(1, 3, 224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9733a8-bf8d-4c71-b94f-7f5c90c07955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "feature_tensor = vgg_model_features(input_tensor)\n",
    "print(feature_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1de1ba9c-5db5-4702-b0bd-2ff59930dc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.hooks.RemovableHandle at 0x7f821365a860>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tensor_hook = None\n",
    "def hook_fn(module, input, output):\n",
    "    global feature_tensor_hook\n",
    "    feature_tensor_hook = output\n",
    "\n",
    "hook_layer = vgg_model.features[11]\n",
    "hook_layer.register_forward_hook(hook_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44b80585-cb52-4596-8d77-d432d7f11255",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_model.eval()\n",
    "output_tensor = vgg_model(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0752b353-e6d7-46e0-92b7-6764f53f7f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [15.4093,  6.7857,  4.8907,  ...,  0.9767,  0.0735,  0.0000],\n",
       "          [15.0378, 14.3292,  5.7194,  ...,  2.0751,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [11.7255,  0.0000,  2.6770,  ...,  4.2560,  0.0000,  0.0000],\n",
       "          [11.3627,  0.0000,  0.0000,  ...,  1.4773,  0.0000,  0.0000],\n",
       "          [ 9.7847,  4.7043,  5.4600,  ..., 11.3073, 11.9892,  0.3918]],\n",
       "\n",
       "         [[ 6.0661, 11.0409,  4.5133,  ..., 11.6577, 13.2693, 21.1984],\n",
       "          [ 9.4763,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 3.7147,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 2.0520,  3.4882,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.2848,  0.1977],\n",
       "          [ 4.5651,  0.0000,  8.1412,  ...,  3.0580, 10.4078,  3.7552]],\n",
       "\n",
       "         [[ 0.0000,  2.2535,  2.6899,  ...,  3.1037,  4.2589,  0.0000],\n",
       "          [ 0.0000,  5.2941,  0.0000,  ...,  0.7892,  0.0000,  1.3189],\n",
       "          [12.0700, 10.4037,  0.0000,  ...,  4.4989,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [13.5510,  0.6729,  1.8840,  ...,  3.3660,  2.2310, 11.2046],\n",
       "          [ 2.5681,  0.0000,  0.0000,  ..., 14.3422,  0.0000, 13.4856],\n",
       "          [ 5.1697,  7.7143, 13.7970,  ..., 11.3340,  0.0000,  6.3313]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.3942],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.8854],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.5873],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.8055],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.6739],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.2291,  5.4145]],\n",
       "\n",
       "         [[ 0.1460,  0.1695,  3.9356,  ...,  1.4242,  0.0000,  8.0191],\n",
       "          [ 4.0266,  0.4041,  5.7351,  ...,  1.5407,  2.3743, 19.4116],\n",
       "          [ 3.5774,  1.2199, 14.2459,  ...,  3.9296, 10.0640, 11.1178],\n",
       "          ...,\n",
       "          [13.4599,  3.9712, 12.6167,  ...,  0.4256,  4.6831,  7.8309],\n",
       "          [ 6.8124,  0.8153,  0.0000,  ...,  0.0000,  0.0000,  2.4274],\n",
       "          [15.0526,  9.3064,  4.0527,  ...,  2.2208,  3.2599,  4.4937]],\n",
       "\n",
       "         [[30.6712, 18.2090, 25.7797,  ..., 20.9253,  9.5757,  0.0000],\n",
       "          [14.6806,  9.2618,  3.4212,  ...,  7.3046,  0.0000,  0.0000],\n",
       "          [13.3564, 15.3571, 14.9300,  ..., 11.7183,  3.1550,  0.0000],\n",
       "          ...,\n",
       "          [10.2209,  0.0000,  8.3851,  ...,  1.6368, 13.1669,  0.0000],\n",
       "          [11.0278,  0.0000, 15.2493,  ...,  5.2411,  3.8819,  0.0000],\n",
       "          [12.3604,  6.9520, 19.6527,  ...,  8.0893,  8.3367,  0.0000]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tensor_hook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50e5a1bc-2ef0-4126-8034-1b73e392a36f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [15.4093,  6.7857,  4.8907,  ...,  0.9767,  0.0735,  0.0000],\n",
       "          [15.0378, 14.3292,  5.7194,  ...,  2.0751,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [11.7255,  0.0000,  2.6770,  ...,  4.2560,  0.0000,  0.0000],\n",
       "          [11.3627,  0.0000,  0.0000,  ...,  1.4773,  0.0000,  0.0000],\n",
       "          [ 9.7847,  4.7043,  5.4600,  ..., 11.3073, 11.9892,  0.3918]],\n",
       "\n",
       "         [[ 6.0661, 11.0409,  4.5133,  ..., 11.6577, 13.2693, 21.1984],\n",
       "          [ 9.4763,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 3.7147,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [ 2.0520,  3.4882,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.2848,  0.1977],\n",
       "          [ 4.5651,  0.0000,  8.1412,  ...,  3.0580, 10.4078,  3.7552]],\n",
       "\n",
       "         [[ 0.0000,  2.2535,  2.6899,  ...,  3.1037,  4.2589,  0.0000],\n",
       "          [ 0.0000,  5.2941,  0.0000,  ...,  0.7892,  0.0000,  1.3189],\n",
       "          [12.0700, 10.4037,  0.0000,  ...,  4.4989,  0.0000,  0.0000],\n",
       "          ...,\n",
       "          [13.5510,  0.6729,  1.8840,  ...,  3.3660,  2.2310, 11.2046],\n",
       "          [ 2.5681,  0.0000,  0.0000,  ..., 14.3422,  0.0000, 13.4856],\n",
       "          [ 5.1697,  7.7143, 13.7970,  ..., 11.3340,  0.0000,  6.3313]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  6.3942],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  2.8854],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000, 15.5873],\n",
       "          ...,\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.8055],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  3.6739],\n",
       "          [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.2291,  5.4145]],\n",
       "\n",
       "         [[ 0.1460,  0.1695,  3.9356,  ...,  1.4242,  0.0000,  8.0191],\n",
       "          [ 4.0266,  0.4041,  5.7351,  ...,  1.5407,  2.3743, 19.4116],\n",
       "          [ 3.5774,  1.2199, 14.2459,  ...,  3.9296, 10.0640, 11.1178],\n",
       "          ...,\n",
       "          [13.4599,  3.9712, 12.6167,  ...,  0.4256,  4.6831,  7.8309],\n",
       "          [ 6.8124,  0.8153,  0.0000,  ...,  0.0000,  0.0000,  2.4274],\n",
       "          [15.0526,  9.3064,  4.0527,  ...,  2.2208,  3.2599,  4.4937]],\n",
       "\n",
       "         [[30.6712, 18.2090, 25.7797,  ..., 20.9253,  9.5757,  0.0000],\n",
       "          [14.6806,  9.2618,  3.4212,  ...,  7.3046,  0.0000,  0.0000],\n",
       "          [13.3564, 15.3571, 14.9300,  ..., 11.7183,  3.1550,  0.0000],\n",
       "          ...,\n",
       "          [10.2209,  0.0000,  8.3851,  ...,  1.6368, 13.1669,  0.0000],\n",
       "          [11.0278,  0.0000, 15.2493,  ...,  5.2411,  3.8819,  0.0000],\n",
       "          [12.3604,  6.9520, 19.6527,  ...,  8.0893,  8.3367,  0.0000]]]],\n",
       "       grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6730159d-401a-4e9f-83d6-daeb13ec95b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(feature_tensor_hook == feature_tensor).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0241893-7dad-480c-a267-122ca63ed5b3",
   "metadata": {},
   "source": [
    "## Convert pth to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c7523f6-180e-46e1-b54a-ae678fa8fda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported graph: graph(%input.1 : Float(1, 3, 224, 224, strides=[150528, 50176, 224, 1], requires_grad=0, device=cpu),\n",
      "      %features.0.weight : Float(64, 3, 3, 3, strides=[27, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.0.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.2.weight : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.2.bias : Float(64, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.5.weight : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.5.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.7.weight : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.7.bias : Float(128, strides=[1], requires_grad=1, device=cpu),\n",
      "      %features.10.weight : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=1, device=cpu),\n",
      "      %features.10.bias : Float(256, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %/features/features.0/Conv_output_0 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.0/Conv\"](%input.1, %features.0.weight, %features.0.bias), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.1/Relu_output_0 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.1/Relu\"](%/features/features.0/Conv_output_0), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.1 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.2/Conv_output_0 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.2/Conv\"](%/features/features.1/Relu_output_0, %features.2.weight, %features.2.bias), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.3/Relu_output_0 : Float(1, 64, 224, 224, strides=[3211264, 50176, 224, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.3/Relu\"](%/features/features.2/Conv_output_0), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.3 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.4/MaxPool_output_0 : Float(1, 64, 112, 112, strides=[802816, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.4/MaxPool\"](%/features/features.3/Relu_output_0), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.4 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:791:0\n",
      "  %/features/features.5/Conv_output_0 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.5/Conv\"](%/features/features.4/MaxPool_output_0, %features.5.weight, %features.5.bias), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.5 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.6/Relu_output_0 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.6/Relu\"](%/features/features.5/Conv_output_0), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.6 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.7/Conv_output_0 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.7/Conv\"](%/features/features.6/Relu_output_0, %features.7.weight, %features.7.bias), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.7 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456:0\n",
      "  %/features/features.8/Relu_output_0 : Float(1, 128, 112, 112, strides=[1605632, 12544, 112, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.8/Relu\"](%/features/features.7/Conv_output_0), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.8 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1471:0\n",
      "  %/features/features.9/MaxPool_output_0 : Float(1, 128, 56, 56, strides=[401408, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[2, 2], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/features/features.9/MaxPool\"](%/features/features.8/Relu_output_0), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.pooling.MaxPool2d::features.9 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:791:0\n",
      "  %/features/features.10/Conv_output_0 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=0, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/features/features.10/Conv\"](%/features/features.9/MaxPool_output_0, %features.10.weight, %features.10.bias), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.conv.Conv2d::features.10 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456:0\n",
      "  %22 : Float(1, 256, 56, 56, strides=[802816, 3136, 56, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/features/features.11/Relu\"](%/features/features.10/Conv_output_0), scope: __main__.VGG::/torch.nn.modules.container.Sequential::features/torch.nn.modules.activation.ReLU::features.11 # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1471:0\n",
      "  return (%22)\n",
      "\n",
      "\n",
      "\u001b[07mModel optimizing started\u001b[0m ============================================================\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/onnx2tf/onnx2tf.py\", line 613, in convert\n",
      "    result = subprocess.check_output(\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 421, in check_output\n",
      "    return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 503, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 971, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"/usr/lib/python3.10/subprocess.py\", line 1863, in _execute_child\n",
      "    raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: 'onnxsim'\n",
      "\n",
      "\u001b[33mWARNING:\u001b[0m Failed to optimize the onnx file.\n",
      "\n",
      "\u001b[07mAutomatic generation of each OP name started\u001b[0m ========================================\n",
      "\u001b[32mAutomatic generation of each OP name complete!\u001b[0m\n",
      "\n",
      "\u001b[07mModel loaded\u001b[0m ========================================================================\n",
      "\n",
      "\u001b[07mModel conversion started\u001b[0m ============================================================\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32minput_op_name\u001b[0m: input.1 \u001b[32mshape\u001b[0m: [1, 3, 224, 224] \u001b[32mdtype\u001b[0m: float32\n",
      "\u001b[33mWARNING:\u001b[0m The optimization process for shape estimation is skipped because it contains OPs that cannot be inferred by the standard onnxruntime.\n",
      "\u001b[33mWARNING:\u001b[0m name 'ort' is not defined\n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m2 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.0/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: input.1 \u001b[36mshape\u001b[0m: [1, 3, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: features.0.weight \u001b[36mshape\u001b[0m: [64, 3, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: features.0.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: input.1 \u001b[34mshape\u001b[0m: (1, 224, 224, 3) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 3, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m3 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.1/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.0/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add/Add:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m4 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.2/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.1/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: features.2.weight \u001b[36mshape\u001b[0m: [64, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: features.2.bias \u001b[36mshape\u001b[0m: [64] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu/Relu:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (64,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m5 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.3/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.2/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_1/Add:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m6 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /features/features.4/MaxPool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.3/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 64, 224, 224] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.4/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 64, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_1/Relu:0 \u001b[34mshape\u001b[0m: (1, 224, 224, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m7 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.5/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.4/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 64, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: features.5.weight \u001b[36mshape\u001b[0m: [128, 64, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: features.5.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.5/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 64) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 64, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m8 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.6/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.5/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.6/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_2/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m9 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.7/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.6/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: features.7.weight \u001b[36mshape\u001b[0m: [128, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: features.7.bias \u001b[36mshape\u001b[0m: [128] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.7/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_2/Relu:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (128,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m10 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.8/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.7/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.8/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_3/Add:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m11 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: MaxPool\u001b[35m onnx_op_name\u001b[0m: /features/features.9/MaxPool\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.8/Relu_output_0 \u001b[36mshape\u001b[0m: [1, 128, 112, 112] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.9/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 128, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: max_pool_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_3/Relu:0 \u001b[34mshape\u001b[0m: (1, 112, 112, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.filters\u001b[0m: \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.kernel_shape\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [2, 2] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: [0, 0, 0, 0] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.ceil_mode\u001b[0m: \u001b[34mval\u001b[0m: False \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output0\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_1/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.2.output1\u001b[0m: \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m12 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Conv\u001b[35m onnx_op_name\u001b[0m: /features/features.10/Conv\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.9/MaxPool_output_0 \u001b[36mshape\u001b[0m: [1, 128, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.2\u001b[0m: features.10.weight \u001b[36mshape\u001b[0m: [256, 128, 3, 3] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.3\u001b[0m: features.10.bias \u001b[36mshape\u001b[0m: [256] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: /features/features.10/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: convolution_v2\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.input\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.max_pool2d_1/MaxPool2d:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 128) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.2.weights\u001b[0m: \u001b[34mshape\u001b[0m: (3, 3, 128, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.3.bias\u001b[0m: \u001b[34mshape\u001b[0m: (256,) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.4.strides\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.5.dilations\u001b[0m: \u001b[34mval\u001b[0m: [1, 1] \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.6.padding\u001b[0m: \u001b[34mval\u001b[0m: SAME \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.7.group\u001b[0m: \u001b[34mval\u001b[0m: 1 \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[32mINFO:\u001b[0m \u001b[32m13 / 13\u001b[0m\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35monnx_op_type\u001b[0m: Relu\u001b[35m onnx_op_name\u001b[0m: /features/features.11/Relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m input_name.1\u001b[0m: /features/features.10/Conv_output_0 \u001b[36mshape\u001b[0m: [1, 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[36m output_name.1\u001b[0m: 22 \u001b[36mshape\u001b[0m: [1, 256, 56, 56] \u001b[36mdtype\u001b[0m: float32\n",
      "\u001b[32mINFO:\u001b[0m \u001b[35mtf_op_type\u001b[0m: relu\n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m input.1.features\u001b[0m: \u001b[34mname\u001b[0m: tf.math.add_4/Add:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\u001b[32mINFO:\u001b[0m \u001b[34m output.1.output\u001b[0m: \u001b[34mname\u001b[0m: tf.nn.relu_4/Relu:0 \u001b[34mshape\u001b[0m: (1, 56, 56, 256) \u001b[34mdtype\u001b[0m: <dtype: 'float32'> \n",
      "\n",
      "\u001b[07mh5 output started\u001b[0m ===================================================================\n",
      "\u001b[32mjson output start...\u001b[0m\n",
      "\u001b[32mjson output finish\u001b[0m\n",
      "\u001b[32mweights.h5 output start...\u001b[0m\n",
      "\u001b[32mweights.h5 output finish\u001b[0m\n",
      "\u001b[32mweights.keras output start...\u001b[0m\n",
      "\u001b[32mweights.keras output finish\u001b[0m\n",
      "\u001b[32mweights.tf output start...\u001b[0m\n",
      "\u001b[32mweights.tf output finish\u001b[0m\n",
      "\u001b[32mkeras output start...\u001b[0m\n",
      "\u001b[32mkeras output finish\u001b[0m\n",
      "\u001b[32mh5 output start...\u001b[0m\n",
      "\u001b[32mh5 output complete!\u001b[0m\n",
      "\u001b[07msaved_model output started\u001b[0m ==========================================================\n",
      "\u001b[32msaved_model output complete!\u001b[0m\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 10, Total Ops 20, % non-converted = 50.00 %\n",
      " * 10 ARITH ops\n",
      "\n",
      "- arith.constant:   10 occurrences  (f32: 10)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 2)\n",
      "\u001b[32mFloat32 tflite output complete!\u001b[0m\n",
      "Summary on the non-converted ops:\n",
      "---------------------------------\n",
      " * Accepted dialects: tfl, builtin, func\n",
      " * Non-Converted Ops: 10, Total Ops 30, % non-converted = 33.33 %\n",
      " * 10 ARITH ops\n",
      "\n",
      "- arith.constant:   10 occurrences  (f16: 10)\n",
      "\n",
      "\n",
      "\n",
      "  (f32: 5)\n",
      "  (f32: 10)\n",
      "  (f32: 2)\n",
      "\u001b[32mFloat16 tflite output complete!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# --- pth to onnx ---\n",
    "torch.onnx.export(vgg_model_features, input_tensor, 'vgg_top5_layers.onnx', verbose=True)\n",
    "\n",
    "!onnx2tf -i vgg_top5_layers.onnx -oh5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430ad559-9d05-4494-a8d4-2f13d2f61045",
   "metadata": {},
   "source": [
    "## Inference dummy data using TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a2a37cbe-05ee-46e7-a758-e64f6bdb6f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [15.409332  ,  6.78569   ,  4.890681  , ...,  0.97668546,\n",
       "           0.07349937,  0.        ],\n",
       "         [15.037783  , 14.329218  ,  5.71934   , ...,  2.0750613 ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [11.7255125 ,  0.        ,  2.67697   , ...,  4.2560186 ,\n",
       "           0.        ,  0.        ],\n",
       "         [11.362651  ,  0.        ,  0.        , ...,  1.4772967 ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 9.784675  ,  4.7042713 ,  5.4599843 , ..., 11.30734   ,\n",
       "          11.989197  ,  0.3917982 ]],\n",
       "\n",
       "        [[ 6.0660524 , 11.0409    ,  4.513326  , ..., 11.6576605 ,\n",
       "          13.269262  , 21.198433  ],\n",
       "         [ 9.476288  ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 3.7147267 ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [ 2.0520318 ,  3.4882505 ,  0.        , ...,  0.        ,\n",
       "           0.        ,  0.        ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.28482747,  0.19772275],\n",
       "         [ 4.565132  ,  0.        ,  8.141177  , ...,  3.058039  ,\n",
       "          10.407765  ,  3.755242  ]],\n",
       "\n",
       "        [[ 0.        ,  2.2535205 ,  2.6899357 , ...,  3.103713  ,\n",
       "           4.2589207 ,  0.        ],\n",
       "         [ 0.        ,  5.2940907 ,  0.        , ...,  0.7891839 ,\n",
       "           0.        ,  1.3189043 ],\n",
       "         [12.0700035 , 10.403759  ,  0.        , ...,  4.4989524 ,\n",
       "           0.        ,  0.        ],\n",
       "         ...,\n",
       "         [13.550996  ,  0.67285055,  1.8840188 , ...,  3.3659685 ,\n",
       "           2.2310414 , 11.204607  ],\n",
       "         [ 2.5680742 ,  0.        ,  0.        , ..., 14.342242  ,\n",
       "           0.        , 13.485604  ],\n",
       "         [ 5.1696525 ,  7.7143364 , 13.796965  , ..., 11.334028  ,\n",
       "           0.        ,  6.33132   ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  6.394193  ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  2.8853538 ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        , 15.587317  ],\n",
       "         ...,\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  3.8055224 ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.        ,  3.6738474 ],\n",
       "         [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "           0.22909907,  5.414543  ]],\n",
       "\n",
       "        [[ 0.145962  ,  0.16947511,  3.9356272 , ...,  1.424213  ,\n",
       "           0.        ,  8.019147  ],\n",
       "         [ 4.0265646 ,  0.404058  ,  5.7351303 , ...,  1.5406873 ,\n",
       "           2.3743424 , 19.41165   ],\n",
       "         [ 3.5774343 ,  1.2199323 , 14.245898  , ...,  3.9296298 ,\n",
       "          10.064024  , 11.117808  ],\n",
       "         ...,\n",
       "         [13.459866  ,  3.9711597 , 12.616682  , ...,  0.42557427,\n",
       "           4.6830897 ,  7.830923  ],\n",
       "         [ 6.8123913 ,  0.81527615,  0.        , ...,  0.        ,\n",
       "           0.        ,  2.4273622 ],\n",
       "         [15.0526285 ,  9.30636   ,  4.052667  , ...,  2.2208254 ,\n",
       "           3.2598562 ,  4.4936967 ]],\n",
       "\n",
       "        [[30.671219  , 18.209051  , 25.779673  , ..., 20.925264  ,\n",
       "           9.57573   ,  0.        ],\n",
       "         [14.680563  ,  9.261808  ,  3.4212291 , ...,  7.304606  ,\n",
       "           0.        ,  0.        ],\n",
       "         [13.356409  , 15.357096  , 14.929991  , ..., 11.718248  ,\n",
       "           3.1549764 ,  0.        ],\n",
       "         ...,\n",
       "         [10.220931  ,  0.        ,  8.385098  , ...,  1.6367613 ,\n",
       "          13.166897  ,  0.        ],\n",
       "         [11.027764  ,  0.        , 15.249274  , ...,  5.2410626 ,\n",
       "           3.8819554 ,  0.        ],\n",
       "         [12.360447  ,  6.9520264 , 19.652704  , ...,  8.089325  ,\n",
       "           8.336705  ,  0.        ]]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load tflite ---\n",
    "interpreter = tf.lite.Interpreter(model_path='saved_model/vgg_top5_layers_float32.tflite')\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "# --- Load index ---\n",
    "input_details = interpreter.get_input_details()\n",
    "input_index = input_details[0]['index']\n",
    "\n",
    "output_details = interpreter.get_output_details()\n",
    "output_index = output_details[0]['index']\n",
    "\n",
    "# --- Set input tensor ---\n",
    "interpreter.set_tensor(input_index, input_tensor.numpy().transpose([0, 2, 3, 1]))\n",
    "\n",
    "# --- Inference ---\n",
    "interpreter.invoke()\n",
    "\n",
    "# --- Get output tensor ---\n",
    "output_tensor_tflite = interpreter.get_tensor(output_index)\n",
    "output_tensor_tflite = output_tensor_tflite.transpose([0, 3, 1, 2])\n",
    "output_tensor_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5850be44-52ef-43d8-a556-b5dfe03eb1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = feature_tensor.detach().numpy() - output_tensor_tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f43892b-5ae5-4fd5-a175-06a8d360dd13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-8.392334e-05"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db205a3c-bce2-4211-994d-5248f4378cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.583069e-05"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diff.max()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
