{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474b637f",
   "metadata": {},
   "source": [
    "# Training Image Classification Model with SGD\n",
    "\n",
    "|Item|Description|\n",
    "|---|---|\n",
    "|DeepLearning Framework|PyTorch|\n",
    "|Dataset|CIFAR-100|\n",
    "|Model Architecture|Simple CNN|\n",
    "|Optimizer|SGD|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc9d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c40f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import optuna\n",
    "\n",
    "from data_loader.data_loader import DataLoader\n",
    "from models.pytorch import simple_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080cc78",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d245650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5e7c1b3b50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b0797",
   "metadata": {},
   "source": [
    "## Device Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8918ce3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a9692",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fa0fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 256"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60045952",
   "metadata": {},
   "source": [
    "## Load Dataset and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deef041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/tmp/dataset'\n",
    "dataloader = DataLoader(dataset_name='cifar100_pytorch', dataset_dir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef213c0a",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c7f9975-c45f-4e79-86c4-6a45c2b3fc0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-05-06 11:16:42,512] A new study created in memory with name: no-name-643b35fd-d5d7-425c-b6c4-15fef46680c0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [256, 100]                --\n",
      "├─Conv2d: 1-1                            [256, 64, 32, 32]         1,792\n",
      "├─ReLU: 1-2                              [256, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-3                       [256, 64, 32, 32]         128\n",
      "├─Conv2d: 1-4                            [256, 64, 32, 32]         36,928\n",
      "├─ReLU: 1-5                              [256, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-6                       [256, 64, 32, 32]         128\n",
      "├─MaxPool2d: 1-7                         [256, 64, 16, 16]         --\n",
      "├─Dropout: 1-8                           [256, 64, 16, 16]         --\n",
      "├─Conv2d: 1-9                            [256, 128, 16, 16]        73,856\n",
      "├─ReLU: 1-10                             [256, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-11                      [256, 128, 16, 16]        256\n",
      "├─Conv2d: 1-12                           [256, 128, 16, 16]        147,584\n",
      "├─ReLU: 1-13                             [256, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-14                      [256, 128, 16, 16]        256\n",
      "├─MaxPool2d: 1-15                        [256, 128, 8, 8]          --\n",
      "├─Dropout: 1-16                          [256, 128, 8, 8]          --\n",
      "├─Conv2d: 1-17                           [256, 256, 8, 8]          295,168\n",
      "├─ReLU: 1-18                             [256, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-19                      [256, 256, 8, 8]          512\n",
      "├─Conv2d: 1-20                           [256, 256, 8, 8]          590,080\n",
      "├─ReLU: 1-21                             [256, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-22                      [256, 256, 8, 8]          512\n",
      "├─MaxPool2d: 1-23                        [256, 256, 4, 4]          --\n",
      "├─AdaptiveAvgPool2d: 1-24                [256, 256, 2, 2]          --\n",
      "├─Linear: 1-25                           [256, 512]                524,800\n",
      "├─ReLU: 1-26                             [256, 512]                --\n",
      "├─BatchNorm1d: 1-27                      [256, 512]                1,024\n",
      "├─Dropout: 1-28                          [256, 512]                --\n",
      "├─Linear: 1-29                           [256, 128]                65,664\n",
      "├─ReLU: 1-30                             [256, 128]                --\n",
      "├─BatchNorm1d: 1-31                      [256, 128]                256\n",
      "├─Dropout: 1-32                          [256, 128]                --\n",
      "├─Linear: 1-33                           [256, 100]                12,900\n",
      "├─Softmax: 1-34                          [256, 100]                --\n",
      "==========================================================================================\n",
      "Total params: 1,751,844\n",
      "Trainable params: 1,751,844\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 39.32\n",
      "==========================================================================================\n",
      "Input size (MB): 3.15\n",
      "Forward/backward pass size (MB): 942.35\n",
      "Params size (MB): 7.01\n",
      "Estimated Total Size (MB): 952.50\n",
      "==========================================================================================\n",
      "[EPOCH #0] loss: 4.605296559312446\n",
      "[EPOCH #1, elapsed time: 12.061[sec]] loss: 4.605057902772383\n",
      "[EPOCH #2, elapsed time: 24.255[sec]] loss: 4.606353387570274\n",
      "[EPOCH #3, elapsed time: 38.173[sec]] loss: 4.60783847173055\n",
      "[EPOCH #4, elapsed time: 50.525[sec]] loss: 4.61190900723292\n",
      "[EPOCH #5, elapsed time: 63.913[sec]] loss: 4.612203788696308\n",
      "[EPOCH #6, elapsed time: 74.648[sec]] loss: 4.612247236707008\n",
      "[EPOCH #7, elapsed time: 85.506[sec]] loss: 4.6122019194824455\n",
      "[EPOCH #8, elapsed time: 96.376[sec]] loss: 4.612210328046587\n",
      "[EPOCH #9, elapsed time: 109.365[sec]] loss: 4.612548639891777\n",
      "[EPOCH #10, elapsed time: 120.258[sec]] loss: 4.610818044390346\n",
      "[EPOCH #11, elapsed time: 132.296[sec]] loss: 4.611540112827957\n",
      "[EPOCH #12, elapsed time: 144.059[sec]] loss: 4.611983345017094\n",
      "[EPOCH #13, elapsed time: 155.584[sec]] loss: 4.611818129636505\n",
      "[EPOCH #14, elapsed time: 166.657[sec]] loss: 4.612090589141357\n",
      "[EPOCH #15, elapsed time: 181.680[sec]] loss: 4.611321615242302\n",
      "[EPOCH #16, elapsed time: 194.844[sec]] loss: 4.609194325699077\n",
      "[EPOCH #17, elapsed time: 205.974[sec]] loss: 4.610598457370594\n",
      "[EPOCH #18, elapsed time: 221.714[sec]] loss: 4.610795111360263\n",
      "[EPOCH #19, elapsed time: 233.318[sec]] loss: 4.611761841191288\n",
      "[EPOCH #20, elapsed time: 249.037[sec]] loss: 4.6108852723280895\n",
      "[EPOCH #21, elapsed time: 260.248[sec]] loss: 4.609031244645268\n",
      "[EPOCH #22, elapsed time: 271.474[sec]] loss: 4.605192883992454\n",
      "[EPOCH #23, elapsed time: 283.088[sec]] loss: 4.610101132993887\n",
      "[EPOCH #24, elapsed time: 297.436[sec]] loss: 4.607310295715137\n",
      "[EPOCH #25, elapsed time: 309.702[sec]] loss: 4.611815491625688\n",
      "[EPOCH #26, elapsed time: 321.556[sec]] loss: 4.612157709386512\n",
      "[EPOCH #27, elapsed time: 333.111[sec]] loss: 4.612156231282845\n",
      "[EPOCH #28, elapsed time: 347.369[sec]] loss: 4.612210301809866\n",
      "[EPOCH #29, elapsed time: 362.018[sec]] loss: 4.612538723326309\n",
      "[EPOCH #30, elapsed time: 373.099[sec]] loss: 4.6117388447049485\n",
      "[EPOCH #31, elapsed time: 384.253[sec]] loss: 4.6097460787645606\n",
      "[EPOCH #32, elapsed time: 395.502[sec]] loss: 4.607229368242788\n",
      "[EPOCH #33, elapsed time: 407.054[sec]] loss: 4.610812903213257\n",
      "[EPOCH #34, elapsed time: 418.357[sec]] loss: 4.610257750661878\n",
      "[EPOCH #35, elapsed time: 429.886[sec]] loss: 4.610928454615714\n",
      "[EPOCH #36, elapsed time: 441.306[sec]] loss: 4.610571543375651\n",
      "[EPOCH #37, elapsed time: 452.484[sec]] loss: 4.612239070985078\n",
      "[EPOCH #38, elapsed time: 463.635[sec]] loss: 4.612209760601217\n",
      "[EPOCH #39, elapsed time: 477.239[sec]] loss: 4.6122971435273525\n",
      "[EPOCH #40, elapsed time: 488.918[sec]] loss: 4.611975719283501\n",
      "[EPOCH #41, elapsed time: 504.084[sec]] loss: 4.612383331157272\n",
      "[EPOCH #42, elapsed time: 515.185[sec]] loss: 4.612210085509453\n",
      "[EPOCH #43, elapsed time: 526.818[sec]] loss: 4.611823273254219\n",
      "[EPOCH #44, elapsed time: 539.561[sec]] loss: 4.612210363740732\n",
      "[EPOCH #45, elapsed time: 552.600[sec]] loss: 4.61190998012716\n",
      "[EPOCH #46, elapsed time: 564.114[sec]] loss: 4.61221022340478\n",
      "[EPOCH #47, elapsed time: 575.659[sec]] loss: 4.61221036404581\n",
      "[EPOCH #48, elapsed time: 590.356[sec]] loss: 4.6115050392126475\n",
      "[EPOCH #49, elapsed time: 602.303[sec]] loss: 4.6122024475727335\n",
      "[EPOCH #50, elapsed time: 614.149[sec]] loss: 4.61213519980491\n",
      "[EPOCH #51, elapsed time: 625.982[sec]] loss: 4.6124771527578945\n",
      "[EPOCH #52, elapsed time: 637.628[sec]] loss: 4.612295529968984\n",
      "[EPOCH #53, elapsed time: 649.707[sec]] loss: 4.61221030943682\n",
      "[EPOCH #54, elapsed time: 661.586[sec]] loss: 4.612210363435654\n",
      "[EPOCH #55, elapsed time: 675.306[sec]] loss: 4.612311872090579\n",
      "[EPOCH #56, elapsed time: 690.086[sec]] loss: 4.6121918949193095\n",
      "[EPOCH #57, elapsed time: 705.206[sec]] loss: 4.611989061571586\n",
      "[EPOCH #58, elapsed time: 716.194[sec]] loss: 4.6118040664487365\n",
      "[EPOCH #59, elapsed time: 727.647[sec]] loss: 4.6120094084541385\n",
      "[EPOCH #60, elapsed time: 738.889[sec]] loss: 4.612208898450348\n",
      "[EPOCH #61, elapsed time: 749.899[sec]] loss: 4.611783024903223\n",
      "[EPOCH #62, elapsed time: 760.870[sec]] loss: 4.611728707873051\n",
      "[EPOCH #63, elapsed time: 772.014[sec]] loss: 4.61183652523917\n",
      "[EPOCH #64, elapsed time: 783.180[sec]] loss: 4.612009441097501\n",
      "[EPOCH #65, elapsed time: 794.319[sec]] loss: 4.611554136965721\n",
      "[EPOCH #66, elapsed time: 805.591[sec]] loss: 4.6122358057335715\n",
      "[EPOCH #67, elapsed time: 816.821[sec]] loss: 4.61220380822131\n",
      "[EPOCH #68, elapsed time: 828.193[sec]] loss: 4.612228946356306\n",
      "[EPOCH #69, elapsed time: 839.474[sec]] loss: 4.611792270296747\n",
      "[EPOCH #70, elapsed time: 850.617[sec]] loss: 4.612077594642371\n",
      "[EPOCH #71, elapsed time: 861.989[sec]] loss: 4.612010790153108\n",
      "[EPOCH #72, elapsed time: 873.437[sec]] loss: 4.611785097299138\n",
      "[EPOCH #73, elapsed time: 885.066[sec]] loss: 4.611363222716484\n",
      "[EPOCH #74, elapsed time: 896.353[sec]] loss: 4.611782527625827\n",
      "[EPOCH #75, elapsed time: 907.781[sec]] loss: 4.612042750750912\n",
      "[EPOCH #76, elapsed time: 919.263[sec]] loss: 4.612121291291767\n",
      "[EPOCH #77, elapsed time: 931.453[sec]] loss: 4.6126051434170945\n",
      "[EPOCH #78, elapsed time: 943.526[sec]] loss: 4.610927754766424\n",
      "[EPOCH #79, elapsed time: 955.079[sec]] loss: 4.610887021036081\n",
      "[EPOCH #80, elapsed time: 969.034[sec]] loss: 4.611907416555413\n",
      "[EPOCH #81, elapsed time: 980.769[sec]] loss: 4.610244477931612\n",
      "[EPOCH #82, elapsed time: 992.622[sec]] loss: 4.608402122844128\n",
      "[EPOCH #83, elapsed time: 1003.799[sec]] loss: 4.605440047941983\n",
      "[EPOCH #84, elapsed time: 1015.070[sec]] loss: 4.610633600848803\n",
      "[EPOCH #85, elapsed time: 1026.494[sec]] loss: 4.6121015823276394\n",
      "[EPOCH #86, elapsed time: 1038.184[sec]] loss: 4.612190370138684\n",
      "[EPOCH #87, elapsed time: 1050.359[sec]] loss: 4.612210358554403\n",
      "[EPOCH #88, elapsed time: 1063.721[sec]] loss: 4.6121185352157035\n",
      "[EPOCH #89, elapsed time: 1075.399[sec]] loss: 4.6122709241953705\n",
      "[EPOCH #90, elapsed time: 1087.182[sec]] loss: 4.609161025503089\n",
      "[EPOCH #91, elapsed time: 1099.054[sec]] loss: 4.610813952071958\n",
      "[EPOCH #92, elapsed time: 1113.760[sec]] loss: 4.611197665038204\n",
      "[EPOCH #93, elapsed time: 1125.720[sec]] loss: 4.6118726910342795\n",
      "[EPOCH #94, elapsed time: 1137.314[sec]] loss: 4.610369137137346\n",
      "[EPOCH #95, elapsed time: 1151.301[sec]] loss: 4.6105994934160135\n",
      "[EPOCH #96, elapsed time: 1163.197[sec]] loss: 4.611812335897239\n",
      "[EPOCH #97, elapsed time: 1174.519[sec]] loss: 4.609752540930066\n",
      "[EPOCH #98, elapsed time: 1186.096[sec]] loss: 4.610823453731134\n",
      "[EPOCH #99, elapsed time: 1199.311[sec]] loss: 4.612209615689093\n",
      "[EPOCH #100, elapsed time: 1212.084[sec]] loss: 4.612190369528528\n",
      "[EPOCH #101, elapsed time: 1223.721[sec]] loss: 4.612413600401777\n",
      "[EPOCH #102, elapsed time: 1236.756[sec]] loss: 4.612207492650204\n",
      "[EPOCH #103, elapsed time: 1248.638[sec]] loss: 4.6121914864196585\n",
      "[EPOCH #104, elapsed time: 1260.484[sec]] loss: 4.612210317063774\n",
      "[EPOCH #105, elapsed time: 1271.623[sec]] loss: 4.6123646240698095\n",
      "[EPOCH #106, elapsed time: 1282.988[sec]] loss: 4.611743222881569\n",
      "[EPOCH #107, elapsed time: 1295.232[sec]] loss: 4.612086891289025\n",
      "[EPOCH #108, elapsed time: 1305.869[sec]] loss: 4.61200937337015\n",
      "[EPOCH #109, elapsed time: 1316.799[sec]] loss: 4.612190310343366\n",
      "[EPOCH #110, elapsed time: 1328.508[sec]] loss: 4.6125900868948495\n",
      "[EPOCH #111, elapsed time: 1339.946[sec]] loss: 4.612210363740732\n",
      "[EPOCH #112, elapsed time: 1351.451[sec]] loss: 4.612210363740732\n",
      "[EPOCH #113, elapsed time: 1362.846[sec]] loss: 4.612402919615528\n",
      "[EPOCH #114, elapsed time: 1374.815[sec]] loss: 4.611963829472518\n",
      "[EPOCH #115, elapsed time: 1386.628[sec]] loss: 4.611926983048042\n",
      "[EPOCH #116, elapsed time: 1398.320[sec]] loss: 4.608389102108419\n",
      "[EPOCH #117, elapsed time: 1409.624[sec]] loss: 4.607034923324048\n",
      "[EPOCH #118, elapsed time: 1421.302[sec]] loss: 4.612315362184686\n",
      "[EPOCH #119, elapsed time: 1436.407[sec]] loss: 4.612210363740732\n",
      "[EPOCH #120, elapsed time: 1448.036[sec]] loss: 4.612210363740732\n",
      "[EPOCH #121, elapsed time: 1459.562[sec]] loss: 4.612102679693767\n",
      "[EPOCH #122, elapsed time: 1471.311[sec]] loss: 4.610831499862427\n",
      "[EPOCH #123, elapsed time: 1486.785[sec]] loss: 4.610908298712088\n",
      "[EPOCH #124, elapsed time: 1501.121[sec]] loss: 4.609462775866801\n",
      "[EPOCH #125, elapsed time: 1514.679[sec]] loss: 4.610560207891678\n",
      "[EPOCH #126, elapsed time: 1529.088[sec]] loss: 4.611169015148551\n",
      "[EPOCH #127, elapsed time: 1540.672[sec]] loss: 4.611817075896553\n",
      "[EPOCH #128, elapsed time: 1554.782[sec]] loss: 4.6115660597251455\n",
      "[EPOCH #129, elapsed time: 1568.630[sec]] loss: 4.612709647939515\n",
      "[EPOCH #130, elapsed time: 1579.768[sec]] loss: 4.6121660850022135\n",
      "[EPOCH #131, elapsed time: 1594.069[sec]] loss: 4.612135603118233\n",
      "[EPOCH #132, elapsed time: 1605.957[sec]] loss: 4.612238382423679\n",
      "[EPOCH #133, elapsed time: 1617.559[sec]] loss: 4.612210363740732\n",
      "[EPOCH #134, elapsed time: 1629.064[sec]] loss: 4.612230972380342\n",
      "[EPOCH #135, elapsed time: 1641.212[sec]] loss: 4.612331570376972\n",
      "[EPOCH #136, elapsed time: 1655.734[sec]] loss: 4.612228721818783\n",
      "[EPOCH #137, elapsed time: 1670.343[sec]] loss: 4.612210201744231\n",
      "[EPOCH #138, elapsed time: 1685.097[sec]] loss: 4.611772417640808\n",
      "[EPOCH #139, elapsed time: 1701.073[sec]] loss: 4.6116450234094035\n",
      "[EPOCH #140, elapsed time: 1715.787[sec]] loss: 4.6111439444358275\n",
      "[EPOCH #141, elapsed time: 1727.190[sec]] loss: 4.611179567496897\n",
      "[EPOCH #142, elapsed time: 1738.890[sec]] loss: 4.612344020616527\n",
      "[EPOCH #143, elapsed time: 1750.143[sec]] loss: 4.6122706499301085\n",
      "[EPOCH #144, elapsed time: 1761.362[sec]] loss: 4.612353278823335\n",
      "[EPOCH #145, elapsed time: 1775.535[sec]] loss: 4.612210313097758\n",
      "[EPOCH #146, elapsed time: 1786.766[sec]] loss: 4.61251157686181\n",
      "[EPOCH #147, elapsed time: 1798.501[sec]] loss: 4.6121359063659195\n",
      "[EPOCH #148, elapsed time: 1810.023[sec]] loss: 4.611419474857401\n",
      "[EPOCH #149, elapsed time: 1822.477[sec]] loss: 4.612307843838605\n",
      "[EPOCH #150, elapsed time: 1835.799[sec]] loss: 4.612433751729232\n",
      "[EPOCH #151, elapsed time: 1847.539[sec]] loss: 4.611865800539042\n",
      "[EPOCH #152, elapsed time: 1859.305[sec]] loss: 4.610153287019931\n",
      "[EPOCH #153, elapsed time: 1870.689[sec]] loss: 4.609224783176805\n",
      "[EPOCH #154, elapsed time: 1882.043[sec]] loss: 4.609241813859799\n",
      "[EPOCH #155, elapsed time: 1893.383[sec]] loss: 4.611998020191644\n",
      "[EPOCH #156, elapsed time: 1904.602[sec]] loss: 4.612326676923345\n",
      "[EPOCH #157, elapsed time: 1915.977[sec]] loss: 4.611925664195172\n",
      "[EPOCH #158, elapsed time: 1928.092[sec]] loss: 4.612180109750134\n",
      "[EPOCH #159, elapsed time: 1939.422[sec]] loss: 4.611439325682872\n",
      "[EPOCH #160, elapsed time: 1950.745[sec]] loss: 4.610276155416888\n",
      "[EPOCH #161, elapsed time: 1962.454[sec]] loss: 4.611569693511065\n",
      "[EPOCH #162, elapsed time: 1977.445[sec]] loss: 4.6123581042445325\n",
      "[EPOCH #163, elapsed time: 1991.566[sec]] loss: 4.612209636739485\n",
      "[EPOCH #164, elapsed time: 2002.659[sec]] loss: 4.612389548345018\n",
      "[EPOCH #165, elapsed time: 2013.879[sec]] loss: 4.6122286217531485\n",
      "[EPOCH #166, elapsed time: 2027.360[sec]] loss: 4.612028240928723\n",
      "[EPOCH #167, elapsed time: 2039.017[sec]] loss: 4.612210363740732\n",
      "[EPOCH #168, elapsed time: 2049.996[sec]] loss: 4.612210353062997\n",
      "[EPOCH #169, elapsed time: 2061.004[sec]] loss: 4.611561479586786\n",
      "[EPOCH #170, elapsed time: 2072.612[sec]] loss: 4.610237350695726\n",
      "[EPOCH #171, elapsed time: 2087.431[sec]] loss: 4.612210206015325\n",
      "[EPOCH #172, elapsed time: 2098.763[sec]] loss: 4.611824504854735\n",
      "[EPOCH #173, elapsed time: 2110.174[sec]] loss: 4.612210363740732\n",
      "[EPOCH #174, elapsed time: 2121.518[sec]] loss: 4.612351658553247\n",
      "[EPOCH #175, elapsed time: 2132.916[sec]] loss: 4.6123293606958855\n",
      "[EPOCH #176, elapsed time: 2144.957[sec]] loss: 4.612058279534143\n",
      "[EPOCH #177, elapsed time: 2160.269[sec]] loss: 4.6117601888879936\n",
      "[EPOCH #178, elapsed time: 2174.489[sec]] loss: 4.611270111337809\n",
      "[EPOCH #179, elapsed time: 2189.164[sec]] loss: 4.611303693120935\n",
      "[EPOCH #180, elapsed time: 2204.200[sec]] loss: 4.611658944430751\n",
      "[EPOCH #181, elapsed time: 2216.181[sec]] loss: 4.6122204856238\n",
      "[EPOCH #182, elapsed time: 2228.357[sec]] loss: 4.612170417112032\n",
      "[EPOCH #183, elapsed time: 2239.975[sec]] loss: 4.612414209642855\n",
      "[EPOCH #184, elapsed time: 2251.415[sec]] loss: 4.612205410186709\n",
      "[EPOCH #185, elapsed time: 2262.691[sec]] loss: 4.611505488592772\n",
      "[EPOCH #186, elapsed time: 2273.745[sec]] loss: 4.611751679953137\n",
      "[EPOCH #187, elapsed time: 2284.830[sec]] loss: 4.611317648005959\n",
      "[EPOCH #188, elapsed time: 2296.459[sec]] loss: 4.61027712129433\n",
      "[EPOCH #189, elapsed time: 2308.084[sec]] loss: 4.6105307483245985\n",
      "[EPOCH #190, elapsed time: 2319.457[sec]] loss: 4.61207450725143\n",
      "[EPOCH #191, elapsed time: 2330.695[sec]] loss: 4.610821421300457\n",
      "[EPOCH #192, elapsed time: 2342.268[sec]] loss: 4.611700655326429\n",
      "[EPOCH #193, elapsed time: 2353.738[sec]] loss: 4.612193031335441\n",
      "[EPOCH #194, elapsed time: 2365.279[sec]] loss: 4.612206093256701\n",
      "[EPOCH #195, elapsed time: 2381.061[sec]] loss: 4.611958422267277\n",
      "[EPOCH #196, elapsed time: 2392.879[sec]] loss: 4.61203801715824\n",
      "[EPOCH #197, elapsed time: 2404.443[sec]] loss: 4.610270777804228\n",
      "[EPOCH #198, elapsed time: 2415.941[sec]] loss: 4.607330862864118\n",
      "[EPOCH #199, elapsed time: 2427.416[sec]] loss: 4.609187930955844\n",
      "[EPOCH #200, elapsed time: 2438.701[sec]] loss: 4.612400957352826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2024-05-06 11:57:35,572] Trial 0 finished with value: 0.01 and parameters: {'learning_rate': 0.024242793427053037}. Best is trial 0 with value: 0.01.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [256, 100]                --\n",
      "├─Conv2d: 1-1                            [256, 64, 32, 32]         1,792\n",
      "├─ReLU: 1-2                              [256, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-3                       [256, 64, 32, 32]         128\n",
      "├─Conv2d: 1-4                            [256, 64, 32, 32]         36,928\n",
      "├─ReLU: 1-5                              [256, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-6                       [256, 64, 32, 32]         128\n",
      "├─MaxPool2d: 1-7                         [256, 64, 16, 16]         --\n",
      "├─Dropout: 1-8                           [256, 64, 16, 16]         --\n",
      "├─Conv2d: 1-9                            [256, 128, 16, 16]        73,856\n",
      "├─ReLU: 1-10                             [256, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-11                      [256, 128, 16, 16]        256\n",
      "├─Conv2d: 1-12                           [256, 128, 16, 16]        147,584\n",
      "├─ReLU: 1-13                             [256, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-14                      [256, 128, 16, 16]        256\n",
      "├─MaxPool2d: 1-15                        [256, 128, 8, 8]          --\n",
      "├─Dropout: 1-16                          [256, 128, 8, 8]          --\n",
      "├─Conv2d: 1-17                           [256, 256, 8, 8]          295,168\n",
      "├─ReLU: 1-18                             [256, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-19                      [256, 256, 8, 8]          512\n",
      "├─Conv2d: 1-20                           [256, 256, 8, 8]          590,080\n",
      "├─ReLU: 1-21                             [256, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-22                      [256, 256, 8, 8]          512\n",
      "├─MaxPool2d: 1-23                        [256, 256, 4, 4]          --\n",
      "├─AdaptiveAvgPool2d: 1-24                [256, 256, 2, 2]          --\n",
      "├─Linear: 1-25                           [256, 512]                524,800\n",
      "├─ReLU: 1-26                             [256, 512]                --\n",
      "├─BatchNorm1d: 1-27                      [256, 512]                1,024\n",
      "├─Dropout: 1-28                          [256, 512]                --\n",
      "├─Linear: 1-29                           [256, 128]                65,664\n",
      "├─ReLU: 1-30                             [256, 128]                --\n",
      "├─BatchNorm1d: 1-31                      [256, 128]                256\n",
      "├─Dropout: 1-32                          [256, 128]                --\n",
      "├─Linear: 1-33                           [256, 100]                12,900\n",
      "├─Softmax: 1-34                          [256, 100]                --\n",
      "==========================================================================================\n",
      "Total params: 1,751,844\n",
      "Trainable params: 1,751,844\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 39.32\n",
      "==========================================================================================\n",
      "Input size (MB): 3.15\n",
      "Forward/backward pass size (MB): 942.35\n",
      "Params size (MB): 7.01\n",
      "Estimated Total Size (MB): 952.50\n",
      "==========================================================================================\n",
      "[EPOCH #0] loss: 4.605268784997102\n",
      "[EPOCH #1, elapsed time: 11.814[sec]] loss: 4.595490361663369\n",
      "[EPOCH #2, elapsed time: 23.089[sec]] loss: 4.574027511452683\n",
      "[EPOCH #3, elapsed time: 34.430[sec]] loss: 4.558246424315605\n",
      "[EPOCH #4, elapsed time: 46.553[sec]] loss: 4.547070130734435\n",
      "[EPOCH #5, elapsed time: 57.948[sec]] loss: 4.538133301493913\n",
      "[EPOCH #6, elapsed time: 70.520[sec]] loss: 4.529355470446235\n",
      "[EPOCH #7, elapsed time: 81.706[sec]] loss: 4.5223612736526855\n",
      "[EPOCH #8, elapsed time: 93.482[sec]] loss: 4.515372397117102\n",
      "[EPOCH #9, elapsed time: 104.627[sec]] loss: 4.50813741586335\n",
      "[EPOCH #10, elapsed time: 116.134[sec]] loss: 4.500257904226019\n",
      "[EPOCH #11, elapsed time: 127.680[sec]] loss: 4.490565473882342\n",
      "[EPOCH #12, elapsed time: 140.539[sec]] loss: 4.483975719505598\n",
      "[EPOCH #13, elapsed time: 152.145[sec]] loss: 4.477441460065787\n",
      "[EPOCH #14, elapsed time: 164.538[sec]] loss: 4.47100139259148\n",
      "[EPOCH #15, elapsed time: 176.027[sec]] loss: 4.4652679267024205\n",
      "[EPOCH #16, elapsed time: 190.868[sec]] loss: 4.456934316297105\n",
      "[EPOCH #17, elapsed time: 201.960[sec]] loss: 4.451356692567363\n",
      "[EPOCH #18, elapsed time: 213.115[sec]] loss: 4.445173649473673\n",
      "[EPOCH #19, elapsed time: 224.804[sec]] loss: 4.438317915757192\n",
      "[EPOCH #20, elapsed time: 240.569[sec]] loss: 4.434201466907543\n",
      "[EPOCH #21, elapsed time: 252.345[sec]] loss: 4.427848331758935\n",
      "[EPOCH #22, elapsed time: 263.467[sec]] loss: 4.424064144139403\n",
      "[EPOCH #23, elapsed time: 278.312[sec]] loss: 4.41794533342104\n",
      "[EPOCH #24, elapsed time: 289.459[sec]] loss: 4.412014957886816\n",
      "[EPOCH #25, elapsed time: 300.638[sec]] loss: 4.40733398082389\n",
      "[EPOCH #26, elapsed time: 315.858[sec]] loss: 4.401925752960713\n",
      "[EPOCH #27, elapsed time: 327.433[sec]] loss: 4.395490687852934\n",
      "[EPOCH #28, elapsed time: 339.070[sec]] loss: 4.390273916973033\n",
      "[EPOCH #29, elapsed time: 353.906[sec]] loss: 4.386000790354997\n",
      "[EPOCH #30, elapsed time: 367.273[sec]] loss: 4.380706000007732\n",
      "[EPOCH #31, elapsed time: 378.462[sec]] loss: 4.37666699768867\n",
      "[EPOCH #32, elapsed time: 389.653[sec]] loss: 4.370076681968118\n",
      "[EPOCH #33, elapsed time: 403.323[sec]] loss: 4.367775843224309\n",
      "[EPOCH #34, elapsed time: 416.809[sec]] loss: 4.360634126193387\n",
      "[EPOCH #35, elapsed time: 429.635[sec]] loss: 4.358740938068276\n",
      "[EPOCH #36, elapsed time: 443.799[sec]] loss: 4.353581350122746\n",
      "[EPOCH #37, elapsed time: 456.304[sec]] loss: 4.350132227401587\n",
      "[EPOCH #38, elapsed time: 469.048[sec]] loss: 4.346282357675329\n",
      "[EPOCH #39, elapsed time: 480.159[sec]] loss: 4.341350045329245\n",
      "[EPOCH #40, elapsed time: 491.244[sec]] loss: 4.337242131346094\n",
      "[EPOCH #41, elapsed time: 504.174[sec]] loss: 4.334707427314665\n",
      "[EPOCH #42, elapsed time: 515.629[sec]] loss: 4.331167682652587\n",
      "[EPOCH #43, elapsed time: 528.055[sec]] loss: 4.328165327976396\n",
      "[EPOCH #44, elapsed time: 539.703[sec]] loss: 4.323512389426496\n",
      "[EPOCH #45, elapsed time: 555.257[sec]] loss: 4.322204719196888\n",
      "[EPOCH #46, elapsed time: 566.610[sec]] loss: 4.316659997231062\n",
      "[EPOCH #47, elapsed time: 578.174[sec]] loss: 4.3146482734289675\n",
      "[EPOCH #48, elapsed time: 589.352[sec]] loss: 4.3121420676633475\n",
      "[EPOCH #49, elapsed time: 602.454[sec]] loss: 4.308835979005273\n",
      "[EPOCH #50, elapsed time: 614.249[sec]] loss: 4.305482764924404\n",
      "[EPOCH #51, elapsed time: 625.873[sec]] loss: 4.300426240922241\n",
      "[EPOCH #52, elapsed time: 637.394[sec]] loss: 4.296819972747881\n",
      "[EPOCH #53, elapsed time: 649.209[sec]] loss: 4.2949728743052225\n",
      "[EPOCH #54, elapsed time: 661.103[sec]] loss: 4.292504289252439\n",
      "[EPOCH #55, elapsed time: 672.779[sec]] loss: 4.287798539538149\n",
      "[EPOCH #56, elapsed time: 684.573[sec]] loss: 4.284806122172741\n",
      "[EPOCH #57, elapsed time: 695.872[sec]] loss: 4.282705755166647\n",
      "[EPOCH #58, elapsed time: 707.182[sec]] loss: 4.278868490049493\n",
      "[EPOCH #59, elapsed time: 719.013[sec]] loss: 4.276994620693546\n",
      "[EPOCH #60, elapsed time: 732.906[sec]] loss: 4.272324020559027\n",
      "[EPOCH #61, elapsed time: 744.661[sec]] loss: 4.2692375872582105\n",
      "[EPOCH #62, elapsed time: 756.042[sec]] loss: 4.265685496998382\n",
      "[EPOCH #63, elapsed time: 767.708[sec]] loss: 4.262488607252857\n",
      "[EPOCH #64, elapsed time: 779.374[sec]] loss: 4.25931566049865\n",
      "[EPOCH #65, elapsed time: 792.524[sec]] loss: 4.256876275543974\n",
      "[EPOCH #66, elapsed time: 804.330[sec]] loss: 4.254794372172975\n",
      "[EPOCH #67, elapsed time: 816.152[sec]] loss: 4.252114471379413\n",
      "[EPOCH #68, elapsed time: 827.984[sec]] loss: 4.249728372443279\n",
      "[EPOCH #69, elapsed time: 840.568[sec]] loss: 4.244882814257251\n",
      "[EPOCH #70, elapsed time: 851.873[sec]] loss: 4.242800026312136\n",
      "[EPOCH #71, elapsed time: 862.979[sec]] loss: 4.238067506752332\n",
      "[EPOCH #72, elapsed time: 874.090[sec]] loss: 4.236600994682434\n",
      "[EPOCH #73, elapsed time: 885.344[sec]] loss: 4.234865512896713\n",
      "[EPOCH #74, elapsed time: 896.754[sec]] loss: 4.231660386651125\n",
      "[EPOCH #75, elapsed time: 908.250[sec]] loss: 4.228733363246125\n",
      "[EPOCH #76, elapsed time: 919.424[sec]] loss: 4.225852044514944\n",
      "[EPOCH #77, elapsed time: 931.020[sec]] loss: 4.2233172437737405\n",
      "[EPOCH #78, elapsed time: 943.756[sec]] loss: 4.220878756359\n",
      "[EPOCH #79, elapsed time: 955.972[sec]] loss: 4.217282413597375\n",
      "[EPOCH #80, elapsed time: 970.386[sec]] loss: 4.2153748172411\n",
      "[EPOCH #81, elapsed time: 983.416[sec]] loss: 4.211188741929242\n",
      "[EPOCH #82, elapsed time: 997.491[sec]] loss: 4.209593638043638\n",
      "[EPOCH #83, elapsed time: 1009.126[sec]] loss: 4.207010829135995\n",
      "[EPOCH #84, elapsed time: 1020.369[sec]] loss: 4.201624780454776\n",
      "[EPOCH #85, elapsed time: 1031.951[sec]] loss: 4.201482549509938\n",
      "[EPOCH #86, elapsed time: 1043.777[sec]] loss: 4.200341079910825\n",
      "[EPOCH #87, elapsed time: 1058.369[sec]] loss: 4.196432974730557\n",
      "[EPOCH #88, elapsed time: 1070.245[sec]] loss: 4.194011419611106\n",
      "[EPOCH #89, elapsed time: 1081.820[sec]] loss: 4.194957725069726\n",
      "[EPOCH #90, elapsed time: 1093.482[sec]] loss: 4.192534609628044\n",
      "[EPOCH #91, elapsed time: 1106.866[sec]] loss: 4.188342020287394\n",
      "[EPOCH #92, elapsed time: 1120.387[sec]] loss: 4.185923416188948\n",
      "[EPOCH #93, elapsed time: 1131.915[sec]] loss: 4.184097150313267\n",
      "[EPOCH #94, elapsed time: 1147.125[sec]] loss: 4.182009920277659\n",
      "[EPOCH #95, elapsed time: 1158.952[sec]] loss: 4.179567889075057\n",
      "[EPOCH #96, elapsed time: 1170.865[sec]] loss: 4.178821117391361\n",
      "[EPOCH #97, elapsed time: 1182.630[sec]] loss: 4.174245610118141\n",
      "[EPOCH #98, elapsed time: 1197.803[sec]] loss: 4.173770036441122\n",
      "[EPOCH #99, elapsed time: 1212.710[sec]] loss: 4.173153374184421\n",
      "[EPOCH #100, elapsed time: 1224.170[sec]] loss: 4.169408200417126\n",
      "[EPOCH #101, elapsed time: 1235.781[sec]] loss: 4.166516362286041\n",
      "[EPOCH #102, elapsed time: 1247.518[sec]] loss: 4.167676314740172\n",
      "[EPOCH #103, elapsed time: 1260.399[sec]] loss: 4.16368373357098\n",
      "[EPOCH #104, elapsed time: 1271.607[sec]] loss: 4.16217341166769\n",
      "[EPOCH #105, elapsed time: 1283.169[sec]] loss: 4.159338882925872\n",
      "[EPOCH #106, elapsed time: 1296.186[sec]] loss: 4.1573821218518665\n",
      "[EPOCH #107, elapsed time: 1307.335[sec]] loss: 4.155092998566874\n",
      "[EPOCH #108, elapsed time: 1318.595[sec]] loss: 4.152643416069749\n",
      "[EPOCH #109, elapsed time: 1329.943[sec]] loss: 4.151182531929138\n",
      "[EPOCH #110, elapsed time: 1341.349[sec]] loss: 4.149190163658128\n",
      "[EPOCH #111, elapsed time: 1352.534[sec]] loss: 4.148002255062072\n",
      "[EPOCH #112, elapsed time: 1363.982[sec]] loss: 4.146690187130841\n",
      "[EPOCH #113, elapsed time: 1375.549[sec]] loss: 4.145003248008488\n",
      "[EPOCH #114, elapsed time: 1387.280[sec]] loss: 4.141820618073603\n",
      "[EPOCH #115, elapsed time: 1399.154[sec]] loss: 4.139121585828863\n",
      "[EPOCH #116, elapsed time: 1410.811[sec]] loss: 4.138365287622121\n",
      "[EPOCH #117, elapsed time: 1423.590[sec]] loss: 4.134111520043566\n",
      "[EPOCH #118, elapsed time: 1435.475[sec]] loss: 4.134559955645736\n",
      "[EPOCH #119, elapsed time: 1450.714[sec]] loss: 4.1327872166478015\n",
      "[EPOCH #120, elapsed time: 1462.868[sec]] loss: 4.130463894711651\n",
      "[EPOCH #121, elapsed time: 1474.416[sec]] loss: 4.126604201621301\n",
      "[EPOCH #122, elapsed time: 1485.583[sec]] loss: 4.124422000298039\n",
      "[EPOCH #123, elapsed time: 1496.753[sec]] loss: 4.12300517112112\n",
      "[EPOCH #124, elapsed time: 1507.972[sec]] loss: 4.122687040195966\n",
      "[EPOCH #125, elapsed time: 1519.775[sec]] loss: 4.118219351814256\n",
      "[EPOCH #126, elapsed time: 1532.210[sec]] loss: 4.116198797830007\n",
      "[EPOCH #127, elapsed time: 1546.574[sec]] loss: 4.116539888174505\n",
      "[EPOCH #128, elapsed time: 1559.956[sec]] loss: 4.112613432543139\n",
      "[EPOCH #129, elapsed time: 1572.245[sec]] loss: 4.1106163616448885\n",
      "[EPOCH #130, elapsed time: 1584.921[sec]] loss: 4.10775579875353\n",
      "[EPOCH #131, elapsed time: 1596.155[sec]] loss: 4.105050018027434\n",
      "[EPOCH #132, elapsed time: 1609.871[sec]] loss: 4.104603881036633\n",
      "[EPOCH #133, elapsed time: 1621.666[sec]] loss: 4.102130751997252\n",
      "[EPOCH #134, elapsed time: 1636.468[sec]] loss: 4.101344858463651\n",
      "[EPOCH #135, elapsed time: 1650.688[sec]] loss: 4.098484067983987\n",
      "[EPOCH #136, elapsed time: 1662.735[sec]] loss: 4.096953749427868\n",
      "[EPOCH #137, elapsed time: 1677.305[sec]] loss: 4.094698780405163\n",
      "[EPOCH #138, elapsed time: 1691.689[sec]] loss: 4.09082223678047\n",
      "[EPOCH #139, elapsed time: 1705.854[sec]] loss: 4.090488777508433\n",
      "[EPOCH #140, elapsed time: 1720.741[sec]] loss: 4.088345081624661\n",
      "[EPOCH #141, elapsed time: 1732.023[sec]] loss: 4.084586231203622\n",
      "[EPOCH #142, elapsed time: 1746.144[sec]] loss: 4.085259535491123\n",
      "[EPOCH #143, elapsed time: 1757.717[sec]] loss: 4.080562095190574\n",
      "[EPOCH #144, elapsed time: 1768.874[sec]] loss: 4.080949569312868\n",
      "[EPOCH #145, elapsed time: 1781.356[sec]] loss: 4.080214192603386\n",
      "[EPOCH #146, elapsed time: 1792.916[sec]] loss: 4.076899870496031\n",
      "[EPOCH #147, elapsed time: 1805.122[sec]] loss: 4.075153357541797\n",
      "[EPOCH #148, elapsed time: 1816.902[sec]] loss: 4.075084750650788\n",
      "[EPOCH #149, elapsed time: 1828.714[sec]] loss: 4.073373788454101\n",
      "[EPOCH #150, elapsed time: 1840.366[sec]] loss: 4.070949529426951\n",
      "[EPOCH #151, elapsed time: 1855.417[sec]] loss: 4.070180957620905\n",
      "[EPOCH #152, elapsed time: 1870.026[sec]] loss: 4.066703302465184\n",
      "[EPOCH #153, elapsed time: 1885.144[sec]] loss: 4.066228655615603\n",
      "[EPOCH #154, elapsed time: 1898.400[sec]] loss: 4.064409262998243\n",
      "[EPOCH #155, elapsed time: 1911.584[sec]] loss: 4.062064119736811\n",
      "[EPOCH #156, elapsed time: 1922.680[sec]] loss: 4.061383872328092\n",
      "[EPOCH #157, elapsed time: 1933.791[sec]] loss: 4.058268130168805\n",
      "[EPOCH #158, elapsed time: 1945.344[sec]] loss: 4.057378980645139\n",
      "[EPOCH #159, elapsed time: 1957.319[sec]] loss: 4.053817478724191\n",
      "[EPOCH #160, elapsed time: 1968.894[sec]] loss: 4.054023269347022\n",
      "[EPOCH #161, elapsed time: 1980.495[sec]] loss: 4.051690798574583\n",
      "[EPOCH #162, elapsed time: 1994.506[sec]] loss: 4.05374089998842\n",
      "[EPOCH #163, elapsed time: 2007.849[sec]] loss: 4.04987872493473\n",
      "[EPOCH #164, elapsed time: 2019.494[sec]] loss: 4.0474079614713725\n",
      "[EPOCH #165, elapsed time: 2035.168[sec]] loss: 4.046509890699722\n",
      "[EPOCH #166, elapsed time: 2046.510[sec]] loss: 4.0454364529192945\n",
      "[EPOCH #167, elapsed time: 2058.015[sec]] loss: 4.043703100884182\n",
      "[EPOCH #168, elapsed time: 2069.313[sec]] loss: 4.041606798281825\n",
      "[EPOCH #169, elapsed time: 2080.982[sec]] loss: 4.040625138993608\n",
      "[EPOCH #170, elapsed time: 2092.567[sec]] loss: 4.038399473337965\n",
      "[EPOCH #171, elapsed time: 2104.457[sec]] loss: 4.03735127528356\n",
      "[EPOCH #172, elapsed time: 2116.632[sec]] loss: 4.034197993409687\n",
      "[EPOCH #173, elapsed time: 2131.578[sec]] loss: 4.035037890048036\n",
      "[EPOCH #174, elapsed time: 2143.635[sec]] loss: 4.032107108080151\n",
      "[EPOCH #175, elapsed time: 2156.074[sec]] loss: 4.03361834003158\n",
      "[EPOCH #176, elapsed time: 2167.150[sec]] loss: 4.029536746208742\n",
      "[EPOCH #177, elapsed time: 2177.698[sec]] loss: 4.0301077042492395\n",
      "[EPOCH #178, elapsed time: 2188.367[sec]] loss: 4.02917407829641\n",
      "[EPOCH #179, elapsed time: 2201.062[sec]] loss: 4.026789453497927\n",
      "[EPOCH #180, elapsed time: 2212.054[sec]] loss: 4.024513644586369\n",
      "[EPOCH #181, elapsed time: 2224.210[sec]] loss: 4.023346520049864\n",
      "[EPOCH #182, elapsed time: 2238.759[sec]] loss: 4.023033845447533\n",
      "[EPOCH #183, elapsed time: 2251.746[sec]] loss: 4.020910434210369\n",
      "[EPOCH #184, elapsed time: 2264.747[sec]] loss: 4.020326734275598\n",
      "[EPOCH #185, elapsed time: 2279.212[sec]] loss: 4.019784433599169\n",
      "[EPOCH #186, elapsed time: 2292.638[sec]] loss: 4.020427522793536\n",
      "[EPOCH #187, elapsed time: 2305.666[sec]] loss: 4.016976941341174\n",
      "[EPOCH #188, elapsed time: 2320.505[sec]] loss: 4.0152431718066035\n",
      "[EPOCH #189, elapsed time: 2334.618[sec]] loss: 4.013291827547802\n",
      "[EPOCH #190, elapsed time: 2349.914[sec]] loss: 4.013193204017\n",
      "[EPOCH #191, elapsed time: 2365.093[sec]] loss: 4.012468454552551\n",
      "[EPOCH #192, elapsed time: 2379.430[sec]] loss: 4.009775181268166\n",
      "[EPOCH #193, elapsed time: 2391.939[sec]] loss: 4.007619883414651\n",
      "[EPOCH #194, elapsed time: 2403.581[sec]] loss: 4.008005137635742\n",
      "[EPOCH #195, elapsed time: 2415.017[sec]] loss: 4.007503501284374\n",
      "[EPOCH #196, elapsed time: 2426.398[sec]] loss: 4.00584307680966\n",
      "[EPOCH #197, elapsed time: 2438.056[sec]] loss: 4.006014300399458\n",
      "[EPOCH #198, elapsed time: 2450.632[sec]] loss: 4.004214980857005\n",
      "[EPOCH #199, elapsed time: 2461.878[sec]] loss: 4.004773386609303\n",
      "[EPOCH #200, elapsed time: 2473.521[sec]] loss: 4.001455762488523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2024-05-06 12:39:01,460] Trial 1 finished with value: 0.63478 and parameters: {'learning_rate': 3.3109434934771945e-05}. Best is trial 1 with value: 0.63478.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [256, 100]                --\n",
      "├─Conv2d: 1-1                            [256, 64, 32, 32]         1,792\n",
      "├─ReLU: 1-2                              [256, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-3                       [256, 64, 32, 32]         128\n",
      "├─Conv2d: 1-4                            [256, 64, 32, 32]         36,928\n",
      "├─ReLU: 1-5                              [256, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-6                       [256, 64, 32, 32]         128\n",
      "├─MaxPool2d: 1-7                         [256, 64, 16, 16]         --\n",
      "├─Dropout: 1-8                           [256, 64, 16, 16]         --\n",
      "├─Conv2d: 1-9                            [256, 128, 16, 16]        73,856\n",
      "├─ReLU: 1-10                             [256, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-11                      [256, 128, 16, 16]        256\n",
      "├─Conv2d: 1-12                           [256, 128, 16, 16]        147,584\n",
      "├─ReLU: 1-13                             [256, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-14                      [256, 128, 16, 16]        256\n",
      "├─MaxPool2d: 1-15                        [256, 128, 8, 8]          --\n",
      "├─Dropout: 1-16                          [256, 128, 8, 8]          --\n",
      "├─Conv2d: 1-17                           [256, 256, 8, 8]          295,168\n",
      "├─ReLU: 1-18                             [256, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-19                      [256, 256, 8, 8]          512\n",
      "├─Conv2d: 1-20                           [256, 256, 8, 8]          590,080\n",
      "├─ReLU: 1-21                             [256, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-22                      [256, 256, 8, 8]          512\n",
      "├─MaxPool2d: 1-23                        [256, 256, 4, 4]          --\n",
      "├─AdaptiveAvgPool2d: 1-24                [256, 256, 2, 2]          --\n",
      "├─Linear: 1-25                           [256, 512]                524,800\n",
      "├─ReLU: 1-26                             [256, 512]                --\n",
      "├─BatchNorm1d: 1-27                      [256, 512]                1,024\n",
      "├─Dropout: 1-28                          [256, 512]                --\n",
      "├─Linear: 1-29                           [256, 128]                65,664\n",
      "├─ReLU: 1-30                             [256, 128]                --\n",
      "├─BatchNorm1d: 1-31                      [256, 128]                256\n",
      "├─Dropout: 1-32                          [256, 128]                --\n",
      "├─Linear: 1-33                           [256, 100]                12,900\n",
      "├─Softmax: 1-34                          [256, 100]                --\n",
      "==========================================================================================\n",
      "Total params: 1,751,844\n",
      "Trainable params: 1,751,844\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 39.32\n",
      "==========================================================================================\n",
      "Input size (MB): 3.15\n",
      "Forward/backward pass size (MB): 942.35\n",
      "Params size (MB): 7.01\n",
      "Estimated Total Size (MB): 952.50\n",
      "==========================================================================================\n",
      "[EPOCH #0] loss: 4.605237891562688\n",
      "[EPOCH #1, elapsed time: 11.472[sec]] loss: 4.577396928844586\n",
      "[EPOCH #2, elapsed time: 23.195[sec]] loss: 4.551563540560576\n",
      "[EPOCH #3, elapsed time: 34.879[sec]] loss: 4.533862507503458\n",
      "[EPOCH #4, elapsed time: 46.343[sec]] loss: 4.517447337689342\n",
      "[EPOCH #5, elapsed time: 59.705[sec]] loss: 4.499579423219823\n",
      "[EPOCH #6, elapsed time: 71.287[sec]] loss: 4.483699953868766\n",
      "[EPOCH #7, elapsed time: 85.820[sec]] loss: 4.473283483672432\n",
      "[EPOCH #8, elapsed time: 97.584[sec]] loss: 4.456593863413414\n",
      "[EPOCH #9, elapsed time: 108.897[sec]] loss: 4.451835479174984\n",
      "[EPOCH #10, elapsed time: 120.259[sec]] loss: 4.44746012605312\n",
      "[EPOCH #11, elapsed time: 135.170[sec]] loss: 4.433938676854852\n",
      "[EPOCH #12, elapsed time: 146.744[sec]] loss: 4.421682081387276\n",
      "[EPOCH #13, elapsed time: 157.892[sec]] loss: 4.416607940646982\n",
      "[EPOCH #14, elapsed time: 169.005[sec]] loss: 4.401251542743626\n",
      "[EPOCH #15, elapsed time: 180.413[sec]] loss: 4.39634479350641\n",
      "[EPOCH #16, elapsed time: 191.692[sec]] loss: 4.40005320672873\n",
      "[EPOCH #17, elapsed time: 202.942[sec]] loss: 4.383189705954251\n",
      "[EPOCH #18, elapsed time: 214.188[sec]] loss: 4.382048255422522\n",
      "[EPOCH #19, elapsed time: 225.295[sec]] loss: 4.375188928800596\n",
      "[EPOCH #20, elapsed time: 236.675[sec]] loss: 4.366743913920202\n",
      "[EPOCH #21, elapsed time: 247.912[sec]] loss: 4.361290816382117\n",
      "[EPOCH #22, elapsed time: 259.041[sec]] loss: 4.35243445699671\n",
      "[EPOCH #23, elapsed time: 274.202[sec]] loss: 4.347661906301556\n",
      "[EPOCH #24, elapsed time: 289.517[sec]] loss: 4.339688851752498\n",
      "[EPOCH #25, elapsed time: 304.288[sec]] loss: 4.3368533217441705\n",
      "[EPOCH #26, elapsed time: 315.704[sec]] loss: 4.330924519497999\n",
      "[EPOCH #27, elapsed time: 327.253[sec]] loss: 4.327528686303781\n",
      "[EPOCH #28, elapsed time: 338.680[sec]] loss: 4.324141074965874\n",
      "[EPOCH #29, elapsed time: 349.874[sec]] loss: 4.313835899721561\n",
      "[EPOCH #30, elapsed time: 361.198[sec]] loss: 4.310500416020438\n",
      "[EPOCH #31, elapsed time: 372.401[sec]] loss: 4.309429863669211\n",
      "[EPOCH #32, elapsed time: 382.858[sec]] loss: 4.299742964392507\n",
      "[EPOCH #33, elapsed time: 393.466[sec]] loss: 4.295368859955537\n",
      "[EPOCH #34, elapsed time: 404.042[sec]] loss: 4.289272367229693\n",
      "[EPOCH #35, elapsed time: 415.127[sec]] loss: 4.288994963628241\n",
      "[EPOCH #36, elapsed time: 426.312[sec]] loss: 4.28826734536135\n",
      "[EPOCH #37, elapsed time: 437.719[sec]] loss: 4.281472849220476\n",
      "[EPOCH #38, elapsed time: 449.510[sec]] loss: 4.276064720660238\n",
      "[EPOCH #39, elapsed time: 461.061[sec]] loss: 4.2702316228045305\n",
      "[EPOCH #40, elapsed time: 475.332[sec]] loss: 4.2684588301128406\n",
      "[EPOCH #41, elapsed time: 485.696[sec]] loss: 4.262344918034432\n",
      "[EPOCH #42, elapsed time: 500.911[sec]] loss: 4.258105045545582\n",
      "[EPOCH #43, elapsed time: 513.777[sec]] loss: 4.258818393934254\n",
      "[EPOCH #44, elapsed time: 524.597[sec]] loss: 4.250257521963089\n",
      "[EPOCH #45, elapsed time: 535.011[sec]] loss: 4.246982102812061\n",
      "[EPOCH #46, elapsed time: 545.575[sec]] loss: 4.241888790960428\n",
      "[EPOCH #47, elapsed time: 556.311[sec]] loss: 4.236403173921357\n",
      "[EPOCH #48, elapsed time: 569.343[sec]] loss: 4.234849552122813\n",
      "[EPOCH #49, elapsed time: 580.898[sec]] loss: 4.235972013674862\n",
      "[EPOCH #50, elapsed time: 592.444[sec]] loss: 4.227248198087598\n",
      "[EPOCH #51, elapsed time: 603.674[sec]] loss: 4.2284928140011795\n",
      "[EPOCH #52, elapsed time: 614.733[sec]] loss: 4.221900627541374\n",
      "[EPOCH #53, elapsed time: 626.110[sec]] loss: 4.214962982475491\n",
      "[EPOCH #54, elapsed time: 636.737[sec]] loss: 4.2199020074562466\n",
      "[EPOCH #55, elapsed time: 647.541[sec]] loss: 4.210482002906287\n",
      "[EPOCH #56, elapsed time: 658.432[sec]] loss: 4.2093899815950495\n",
      "[EPOCH #57, elapsed time: 669.379[sec]] loss: 4.20639268999594\n",
      "[EPOCH #58, elapsed time: 680.032[sec]] loss: 4.202021467632311\n",
      "[EPOCH #59, elapsed time: 690.498[sec]] loss: 4.198169242702686\n",
      "[EPOCH #60, elapsed time: 701.284[sec]] loss: 4.197427929629901\n",
      "[EPOCH #61, elapsed time: 712.704[sec]] loss: 4.192621545004524\n",
      "[EPOCH #62, elapsed time: 727.332[sec]] loss: 4.190554590463181\n",
      "[EPOCH #63, elapsed time: 738.079[sec]] loss: 4.185607428895459\n",
      "[EPOCH #64, elapsed time: 749.800[sec]] loss: 4.183595711500006\n",
      "[EPOCH #65, elapsed time: 765.393[sec]] loss: 4.186464365979303\n",
      "[EPOCH #66, elapsed time: 776.741[sec]] loss: 4.178057752964364\n",
      "[EPOCH #67, elapsed time: 791.605[sec]] loss: 4.173717735977563\n",
      "[EPOCH #68, elapsed time: 802.975[sec]] loss: 4.174919724845764\n",
      "[EPOCH #69, elapsed time: 814.205[sec]] loss: 4.166177809581646\n",
      "[EPOCH #70, elapsed time: 825.673[sec]] loss: 4.166877033309302\n",
      "[EPOCH #71, elapsed time: 839.880[sec]] loss: 4.1629354708177955\n",
      "[EPOCH #72, elapsed time: 851.687[sec]] loss: 4.163017633856677\n",
      "[EPOCH #73, elapsed time: 863.791[sec]] loss: 4.159591815140639\n",
      "[EPOCH #74, elapsed time: 875.810[sec]] loss: 4.155389981169161\n",
      "[EPOCH #75, elapsed time: 890.226[sec]] loss: 4.156006584393238\n",
      "[EPOCH #76, elapsed time: 903.266[sec]] loss: 4.151492136072365\n",
      "[EPOCH #77, elapsed time: 915.467[sec]] loss: 4.1461417876369895\n",
      "[EPOCH #78, elapsed time: 928.778[sec]] loss: 4.152124311248232\n",
      "[EPOCH #79, elapsed time: 941.294[sec]] loss: 4.143420824696449\n",
      "[EPOCH #80, elapsed time: 955.854[sec]] loss: 4.144780247316708\n",
      "[EPOCH #81, elapsed time: 970.583[sec]] loss: 4.14260309701994\n",
      "[EPOCH #82, elapsed time: 985.194[sec]] loss: 4.141284536873005\n",
      "[EPOCH #83, elapsed time: 998.605[sec]] loss: 4.136579946760786\n",
      "[EPOCH #84, elapsed time: 1010.402[sec]] loss: 4.1360115963758295\n",
      "[EPOCH #85, elapsed time: 1021.625[sec]] loss: 4.132655262413196\n",
      "[EPOCH #86, elapsed time: 1033.514[sec]] loss: 4.1336444133531565\n",
      "[EPOCH #87, elapsed time: 1044.906[sec]] loss: 4.131892316248352\n",
      "[EPOCH #88, elapsed time: 1056.207[sec]] loss: 4.129780192750429\n",
      "[EPOCH #89, elapsed time: 1067.494[sec]] loss: 4.126852783421561\n",
      "[EPOCH #90, elapsed time: 1082.407[sec]] loss: 4.126781099359729\n",
      "[EPOCH #91, elapsed time: 1093.729[sec]] loss: 4.121121979491953\n",
      "[EPOCH #92, elapsed time: 1107.036[sec]] loss: 4.121052947474532\n",
      "[EPOCH #93, elapsed time: 1119.215[sec]] loss: 4.121833876928914\n",
      "[EPOCH #94, elapsed time: 1130.971[sec]] loss: 4.11921980178135\n",
      "[EPOCH #95, elapsed time: 1143.766[sec]] loss: 4.117192324048346\n",
      "[EPOCH #96, elapsed time: 1159.067[sec]] loss: 4.112422371551308\n",
      "[EPOCH #97, elapsed time: 1173.576[sec]] loss: 4.1127853312708975\n",
      "[EPOCH #98, elapsed time: 1187.159[sec]] loss: 4.111495818530453\n",
      "[EPOCH #99, elapsed time: 1200.094[sec]] loss: 4.11096834739812\n",
      "[EPOCH #100, elapsed time: 1212.149[sec]] loss: 4.108756520240183\n",
      "[EPOCH #101, elapsed time: 1224.164[sec]] loss: 4.106447146782414\n",
      "[EPOCH #102, elapsed time: 1235.717[sec]] loss: 4.103409895131166\n",
      "[EPOCH #103, elapsed time: 1247.607[sec]] loss: 4.102412256764359\n",
      "[EPOCH #104, elapsed time: 1260.042[sec]] loss: 4.104139451864661\n",
      "[EPOCH #105, elapsed time: 1273.100[sec]] loss: 4.097366959028189\n",
      "[EPOCH #106, elapsed time: 1289.515[sec]] loss: 4.098969814644665\n",
      "[EPOCH #107, elapsed time: 1303.267[sec]] loss: 4.099950413481212\n",
      "[EPOCH #108, elapsed time: 1315.502[sec]] loss: 4.095813518751148\n",
      "[EPOCH #109, elapsed time: 1328.798[sec]] loss: 4.096436269605152\n",
      "[EPOCH #110, elapsed time: 1341.902[sec]] loss: 4.093904539780668\n",
      "[EPOCH #111, elapsed time: 1355.151[sec]] loss: 4.093702027527705\n",
      "[EPOCH #112, elapsed time: 1367.754[sec]] loss: 4.088395890103497\n",
      "[EPOCH #113, elapsed time: 1381.702[sec]] loss: 4.085455718745197\n",
      "[EPOCH #114, elapsed time: 1394.187[sec]] loss: 4.085380433388269\n",
      "[EPOCH #115, elapsed time: 1408.029[sec]] loss: 4.085728447786601\n",
      "[EPOCH #116, elapsed time: 1423.320[sec]] loss: 4.080575087706553\n",
      "[EPOCH #117, elapsed time: 1434.960[sec]] loss: 4.078781963843835\n",
      "[EPOCH #118, elapsed time: 1446.601[sec]] loss: 4.079339032286035\n",
      "[EPOCH #119, elapsed time: 1458.539[sec]] loss: 4.079346208944583\n",
      "[EPOCH #120, elapsed time: 1470.371[sec]] loss: 4.0765074117017415\n",
      "[EPOCH #121, elapsed time: 1482.779[sec]] loss: 4.073701624373023\n",
      "[EPOCH #122, elapsed time: 1494.954[sec]] loss: 4.072192493952472\n",
      "[EPOCH #123, elapsed time: 1507.099[sec]] loss: 4.070171735870938\n",
      "[EPOCH #124, elapsed time: 1519.512[sec]] loss: 4.070919570599469\n",
      "[EPOCH #125, elapsed time: 1532.901[sec]] loss: 4.068721208676115\n",
      "[EPOCH #126, elapsed time: 1545.674[sec]] loss: 4.06701068289373\n",
      "[EPOCH #127, elapsed time: 1559.945[sec]] loss: 4.069015458540815\n",
      "[EPOCH #128, elapsed time: 1573.364[sec]] loss: 4.064189558370862\n",
      "[EPOCH #129, elapsed time: 1588.478[sec]] loss: 4.06011313608039\n",
      "[EPOCH #130, elapsed time: 1600.298[sec]] loss: 4.061413322590287\n",
      "[EPOCH #131, elapsed time: 1612.075[sec]] loss: 4.060768547534027\n",
      "[EPOCH #132, elapsed time: 1624.852[sec]] loss: 4.0597823296154605\n",
      "[EPOCH #133, elapsed time: 1637.987[sec]] loss: 4.0589146591193845\n",
      "[EPOCH #134, elapsed time: 1649.994[sec]] loss: 4.058411004828552\n",
      "[EPOCH #135, elapsed time: 1664.780[sec]] loss: 4.053584896747836\n",
      "[EPOCH #136, elapsed time: 1679.628[sec]] loss: 4.05378079856731\n",
      "[EPOCH #137, elapsed time: 1691.457[sec]] loss: 4.054451060157819\n",
      "[EPOCH #138, elapsed time: 1703.779[sec]] loss: 4.051037478736784\n",
      "[EPOCH #139, elapsed time: 1720.208[sec]] loss: 4.049998283081153\n",
      "[EPOCH #140, elapsed time: 1735.489[sec]] loss: 4.0511370542639735\n",
      "[EPOCH #141, elapsed time: 1748.026[sec]] loss: 4.052500250395948\n",
      "[EPOCH #142, elapsed time: 1761.219[sec]] loss: 4.047743750015132\n",
      "[EPOCH #143, elapsed time: 1774.351[sec]] loss: 4.046948160792648\n",
      "[EPOCH #144, elapsed time: 1787.617[sec]] loss: 4.045756766678657\n",
      "[EPOCH #145, elapsed time: 1800.970[sec]] loss: 4.045025812839745\n",
      "[EPOCH #146, elapsed time: 1813.691[sec]] loss: 4.043682760865888\n",
      "[EPOCH #147, elapsed time: 1826.867[sec]] loss: 4.047455878266904\n",
      "[EPOCH #148, elapsed time: 1840.086[sec]] loss: 4.041692369653869\n",
      "[EPOCH #149, elapsed time: 1854.572[sec]] loss: 4.039706929402708\n",
      "[EPOCH #150, elapsed time: 1866.374[sec]] loss: 4.0410055430821705\n",
      "[EPOCH #151, elapsed time: 1877.782[sec]] loss: 4.040265171022958\n",
      "[EPOCH #152, elapsed time: 1889.240[sec]] loss: 4.0337722457073015\n",
      "[EPOCH #153, elapsed time: 1900.588[sec]] loss: 4.033560732428416\n",
      "[EPOCH #154, elapsed time: 1911.813[sec]] loss: 4.034625448634513\n",
      "[EPOCH #155, elapsed time: 1923.513[sec]] loss: 4.033325663760009\n",
      "[EPOCH #156, elapsed time: 1935.612[sec]] loss: 4.032396789094384\n",
      "[EPOCH #157, elapsed time: 1946.958[sec]] loss: 4.03304785745539\n",
      "[EPOCH #158, elapsed time: 1958.199[sec]] loss: 4.032575398016189\n",
      "[EPOCH #159, elapsed time: 1969.686[sec]] loss: 4.0278147883851485\n",
      "[EPOCH #160, elapsed time: 1981.238[sec]] loss: 4.026241509333224\n",
      "[EPOCH #161, elapsed time: 1992.682[sec]] loss: 4.023948435286109\n",
      "[EPOCH #162, elapsed time: 2004.667[sec]] loss: 4.0246346509388\n",
      "[EPOCH #163, elapsed time: 2016.555[sec]] loss: 4.026065352782178\n",
      "[EPOCH #164, elapsed time: 2030.527[sec]] loss: 4.022221048444186\n",
      "[EPOCH #165, elapsed time: 2042.538[sec]] loss: 4.019478993925313\n",
      "[EPOCH #166, elapsed time: 2055.805[sec]] loss: 4.021536852561429\n",
      "[EPOCH #167, elapsed time: 2070.458[sec]] loss: 4.021083249850526\n",
      "[EPOCH #168, elapsed time: 2082.794[sec]] loss: 4.018846776801199\n",
      "[EPOCH #169, elapsed time: 2095.019[sec]] loss: 4.0172886036941815\n",
      "[EPOCH #170, elapsed time: 2106.579[sec]] loss: 4.017423031044861\n",
      "[EPOCH #171, elapsed time: 2122.164[sec]] loss: 4.019716589403549\n",
      "[EPOCH #172, elapsed time: 2135.398[sec]] loss: 4.019413355139686\n",
      "[EPOCH #173, elapsed time: 2149.700[sec]] loss: 4.0158311481744295\n",
      "[EPOCH #174, elapsed time: 2164.005[sec]] loss: 4.014926127722381\n",
      "[EPOCH #175, elapsed time: 2178.982[sec]] loss: 4.014675005383776\n",
      "[EPOCH #176, elapsed time: 2192.808[sec]] loss: 4.014545107375943\n",
      "[EPOCH #177, elapsed time: 2206.217[sec]] loss: 4.011970221195477\n",
      "[EPOCH #178, elapsed time: 2220.354[sec]] loss: 4.013008545547895\n",
      "[EPOCH #179, elapsed time: 2231.971[sec]] loss: 4.010333006456733\n",
      "[EPOCH #180, elapsed time: 2246.838[sec]] loss: 4.012160161177622\n",
      "[EPOCH #181, elapsed time: 2259.756[sec]] loss: 4.008223961655024\n",
      "[EPOCH #182, elapsed time: 2274.772[sec]] loss: 4.009062045061352\n",
      "[EPOCH #183, elapsed time: 2287.898[sec]] loss: 4.006900203281385\n",
      "[EPOCH #184, elapsed time: 2302.129[sec]] loss: 4.007566741850615\n",
      "[EPOCH #185, elapsed time: 2314.523[sec]] loss: 4.010468957367724\n",
      "[EPOCH #186, elapsed time: 2328.203[sec]] loss: 4.008733934877167\n",
      "[EPOCH #187, elapsed time: 2339.380[sec]] loss: 4.004654453262944\n",
      "[EPOCH #188, elapsed time: 2350.540[sec]] loss: 4.0055671850230095\n",
      "[EPOCH #189, elapsed time: 2361.792[sec]] loss: 4.000387189941992\n",
      "[EPOCH #190, elapsed time: 2375.198[sec]] loss: 4.001810018785932\n",
      "[EPOCH #191, elapsed time: 2386.469[sec]] loss: 4.003704645812168\n",
      "[EPOCH #192, elapsed time: 2399.905[sec]] loss: 4.001096407419889\n",
      "[EPOCH #193, elapsed time: 2411.331[sec]] loss: 4.000436234306389\n",
      "[EPOCH #194, elapsed time: 2422.665[sec]] loss: 4.001655043353656\n",
      "[EPOCH #195, elapsed time: 2433.940[sec]] loss: 3.9997715172062906\n",
      "[EPOCH #196, elapsed time: 2445.323[sec]] loss: 3.996312552206194\n",
      "[EPOCH #197, elapsed time: 2456.891[sec]] loss: 3.9954756261138527\n",
      "[EPOCH #198, elapsed time: 2470.726[sec]] loss: 3.9967479133789006\n",
      "[EPOCH #199, elapsed time: 2482.119[sec]] loss: 3.9970839113588146\n",
      "[EPOCH #200, elapsed time: 2493.436[sec]] loss: 3.9942720671609204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "[I 2024-05-06 13:20:47,567] Trial 2 finished with value: 0.64086 and parameters: {'learning_rate': 0.0005303739462539983}. Best is trial 2 with value: 0.64086.\n"
     ]
    }
   ],
   "source": [
    "def objective_lr(dataloader):\n",
    "    def objective(trial):\n",
    "        learning_rate = trial.suggest_float('learning_rate', 0.00001, 0.1, log=True)\n",
    "        \n",
    "        input_size = (batch_size, 3, 32, 32)\n",
    "        num_classes = 100\n",
    "        model = simple_cnn.SimpleCNN(device, input_size=input_size, num_classes=num_classes)\n",
    "        model_dir = f'cifar-100_model-{trial}'\n",
    "        train_result = model.train(dataloader.dataset.trainloader, epochs=epochs, lr=learning_rate, output_dir=model_dir)\n",
    "    \n",
    "        train_result = model.predict(dataloader.dataset.trainloader)\n",
    "        train_predictions, train_labels = train_result\n",
    "\n",
    "        train_eval_result = model.evaluate(train_labels, train_predictions)\n",
    "\n",
    "        return train_eval_result['accuracy']\n",
    "\n",
    "    return objective\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "#study.optimize(objective_lr(dataloader), n_trials=100)\n",
    "study.optimize(objective_lr(dataloader), n_trials=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05cf4ce-0d96-4bfa-b38c-701484c0591f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.0005303739462539983}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3710cb38-e83c-4d08-8665-0b87409eeead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x = [epoch for epoch in range(epochs)]\n",
    "#plt.plot(x, train_result['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e916e0b",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce133ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = model.predict(dataloader.dataset.trainloader)\n",
    "train_predictions, train_labels = train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1510ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.56602,\n",
      " 'classification_report': {'0': {'f1-score': 0.7144060657118786,\n",
      "                                 'precision': 0.6171761280931587,\n",
      "                                 'recall': 0.848,\n",
      "                                 'support': 500},\n",
      "                           '1': {'f1-score': 0.6572379367720466,\n",
      "                                 'precision': 0.5626780626780626,\n",
      "                                 'recall': 0.79,\n",
      "                                 'support': 500},\n",
      "                           '10': {'f1-score': 0.4807511737089202,\n",
      "                                  'precision': 0.45309734513274336,\n",
      "                                  'recall': 0.512,\n",
      "                                  'support': 500},\n",
      "                           '11': {'f1-score': 0.4094754653130288,\n",
      "                                  'precision': 0.3548387096774194,\n",
      "                                  'recall': 0.484,\n",
      "                                  'support': 500},\n",
      "                           '12': {'f1-score': 0.6098294884653962,\n",
      "                                  'precision': 0.6116700201207244,\n",
      "                                  'recall': 0.608,\n",
      "                                  'support': 500},\n",
      "                           '13': {'f1-score': 0.6517273576097105,\n",
      "                                  'precision': 0.6112084063047285,\n",
      "                                  'recall': 0.698,\n",
      "                                  'support': 500},\n",
      "                           '14': {'f1-score': 0.5232903865213082,\n",
      "                                  'precision': 0.518664047151277,\n",
      "                                  'recall': 0.528,\n",
      "                                  'support': 500},\n",
      "                           '15': {'f1-score': 0.5661914460285132,\n",
      "                                  'precision': 0.5767634854771784,\n",
      "                                  'recall': 0.556,\n",
      "                                  'support': 500},\n",
      "                           '16': {'f1-score': 0.6038781163434903,\n",
      "                                  'precision': 0.5608919382504288,\n",
      "                                  'recall': 0.654,\n",
      "                                  'support': 500},\n",
      "                           '17': {'f1-score': 0.76657060518732,\n",
      "                                  'precision': 0.7375231053604436,\n",
      "                                  'recall': 0.798,\n",
      "                                  'support': 500},\n",
      "                           '18': {'f1-score': 0.4873803307223673,\n",
      "                                  'precision': 0.43143297380585516,\n",
      "                                  'recall': 0.56,\n",
      "                                  'support': 500},\n",
      "                           '19': {'f1-score': 0.5330490405117272,\n",
      "                                  'precision': 0.5707762557077626,\n",
      "                                  'recall': 0.5,\n",
      "                                  'support': 500},\n",
      "                           '2': {'f1-score': 0.0,\n",
      "                                 'precision': 0.0,\n",
      "                                 'recall': 0.0,\n",
      "                                 'support': 500},\n",
      "                           '20': {'f1-score': 0.7532679738562092,\n",
      "                                  'precision': 0.6367403314917127,\n",
      "                                  'recall': 0.922,\n",
      "                                  'support': 500},\n",
      "                           '21': {'f1-score': 0.6328699918233852,\n",
      "                                  'precision': 0.5352697095435685,\n",
      "                                  'recall': 0.774,\n",
      "                                  'support': 500},\n",
      "                           '22': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 500},\n",
      "                           '23': {'f1-score': 0.6822107081174438,\n",
      "                                  'precision': 0.6003039513677811,\n",
      "                                  'recall': 0.79,\n",
      "                                  'support': 500},\n",
      "                           '24': {'f1-score': 0.6872791519434629,\n",
      "                                  'precision': 0.615506329113924,\n",
      "                                  'recall': 0.778,\n",
      "                                  'support': 500},\n",
      "                           '25': {'f1-score': 0.5166666666666666,\n",
      "                                  'precision': 0.5391304347826087,\n",
      "                                  'recall': 0.496,\n",
      "                                  'support': 500},\n",
      "                           '26': {'f1-score': 0.5274043433298863,\n",
      "                                  'precision': 0.5460385438972163,\n",
      "                                  'recall': 0.51,\n",
      "                                  'support': 500},\n",
      "                           '27': {'f1-score': 0.4645161290322581,\n",
      "                                  'precision': 0.3891891891891892,\n",
      "                                  'recall': 0.576,\n",
      "                                  'support': 500},\n",
      "                           '28': {'f1-score': 0.7109375,\n",
      "                                  'precision': 0.6946564885496184,\n",
      "                                  'recall': 0.728,\n",
      "                                  'support': 500},\n",
      "                           '29': {'f1-score': 0.591728525980912,\n",
      "                                  'precision': 0.6297968397291196,\n",
      "                                  'recall': 0.558,\n",
      "                                  'support': 500},\n",
      "                           '3': {'f1-score': 0.37045454545454554,\n",
      "                                 'precision': 0.42894736842105263,\n",
      "                                 'recall': 0.326,\n",
      "                                 'support': 500},\n",
      "                           '30': {'f1-score': 0.6006066734074823,\n",
      "                                  'precision': 0.6073619631901841,\n",
      "                                  'recall': 0.594,\n",
      "                                  'support': 500},\n",
      "                           '31': {'f1-score': 0.6245353159851302,\n",
      "                                  'precision': 0.5833333333333334,\n",
      "                                  'recall': 0.672,\n",
      "                                  'support': 500},\n",
      "                           '32': {'f1-score': 0.4562569213732004,\n",
      "                                  'precision': 0.511166253101737,\n",
      "                                  'recall': 0.412,\n",
      "                                  'support': 500},\n",
      "                           '33': {'f1-score': 0.5728643216080402,\n",
      "                                  'precision': 0.5757575757575758,\n",
      "                                  'recall': 0.57,\n",
      "                                  'support': 500},\n",
      "                           '34': {'f1-score': 0.5524542829643888,\n",
      "                                  'precision': 0.5324675324675324,\n",
      "                                  'recall': 0.574,\n",
      "                                  'support': 500},\n",
      "                           '35': {'f1-score': 0.4283246977547496,\n",
      "                                  'precision': 0.3768996960486322,\n",
      "                                  'recall': 0.496,\n",
      "                                  'support': 500},\n",
      "                           '36': {'f1-score': 0.5887924230465668,\n",
      "                                  'precision': 0.4863102998696219,\n",
      "                                  'recall': 0.746,\n",
      "                                  'support': 500},\n",
      "                           '37': {'f1-score': 0.6076642335766423,\n",
      "                                  'precision': 0.5587248322147651,\n",
      "                                  'recall': 0.666,\n",
      "                                  'support': 500},\n",
      "                           '38': {'f1-score': 0.42791411042944794,\n",
      "                                  'precision': 0.34701492537313433,\n",
      "                                  'recall': 0.558,\n",
      "                                  'support': 500},\n",
      "                           '39': {'f1-score': 0.7116104868913857,\n",
      "                                  'precision': 0.6690140845070423,\n",
      "                                  'recall': 0.76,\n",
      "                                  'support': 500},\n",
      "                           '4': {'f1-score': 0.20987654320987656,\n",
      "                                 'precision': 0.27419354838709675,\n",
      "                                 'recall': 0.17,\n",
      "                                 'support': 500},\n",
      "                           '40': {'f1-score': 0.5422396856581533,\n",
      "                                  'precision': 0.5328185328185329,\n",
      "                                  'recall': 0.552,\n",
      "                                  'support': 500},\n",
      "                           '41': {'f1-score': 0.7497446373850868,\n",
      "                                  'precision': 0.7661795407098121,\n",
      "                                  'recall': 0.734,\n",
      "                                  'support': 500},\n",
      "                           '42': {'f1-score': 0.5563451776649747,\n",
      "                                  'precision': 0.5649484536082474,\n",
      "                                  'recall': 0.548,\n",
      "                                  'support': 500},\n",
      "                           '43': {'f1-score': 0.6180327868852459,\n",
      "                                  'precision': 0.5236111111111111,\n",
      "                                  'recall': 0.754,\n",
      "                                  'support': 500},\n",
      "                           '44': {'f1-score': 0.34079844206426485,\n",
      "                                  'precision': 0.33206831119544594,\n",
      "                                  'recall': 0.35,\n",
      "                                  'support': 500},\n",
      "                           '45': {'f1-score': 0.36972704714640203,\n",
      "                                  'precision': 0.4869281045751634,\n",
      "                                  'recall': 0.298,\n",
      "                                  'support': 500},\n",
      "                           '46': {'f1-score': 0.46511627906976744,\n",
      "                                  'precision': 0.42071197411003236,\n",
      "                                  'recall': 0.52,\n",
      "                                  'support': 500},\n",
      "                           '47': {'f1-score': 0.6152219873150107,\n",
      "                                  'precision': 0.6524663677130045,\n",
      "                                  'recall': 0.582,\n",
      "                                  'support': 500},\n",
      "                           '48': {'f1-score': 0.7857829010566761,\n",
      "                                  'precision': 0.756007393715342,\n",
      "                                  'recall': 0.818,\n",
      "                                  'support': 500},\n",
      "                           '49': {'f1-score': 0.707803992740472,\n",
      "                                  'precision': 0.6478405315614618,\n",
      "                                  'recall': 0.78,\n",
      "                                  'support': 500},\n",
      "                           '5': {'f1-score': 0.6451612903225806,\n",
      "                                 'precision': 0.5982905982905983,\n",
      "                                 'recall': 0.7,\n",
      "                                 'support': 500},\n",
      "                           '50': {'f1-score': 0.23157894736842102,\n",
      "                                  'precision': 0.3384615384615385,\n",
      "                                  'recall': 0.176,\n",
      "                                  'support': 500},\n",
      "                           '51': {'f1-score': 0.5878787878787878,\n",
      "                                  'precision': 0.5938775510204082,\n",
      "                                  'recall': 0.582,\n",
      "                                  'support': 500},\n",
      "                           '52': {'f1-score': 0.7165775401069518,\n",
      "                                  'precision': 0.6463022508038585,\n",
      "                                  'recall': 0.804,\n",
      "                                  'support': 500},\n",
      "                           '53': {'f1-score': 0.7475113122171946,\n",
      "                                  'precision': 0.6826446280991736,\n",
      "                                  'recall': 0.826,\n",
      "                                  'support': 500},\n",
      "                           '54': {'f1-score': 0.6373239436619718,\n",
      "                                  'precision': 0.5691823899371069,\n",
      "                                  'recall': 0.724,\n",
      "                                  'support': 500},\n",
      "                           '55': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 500},\n",
      "                           '56': {'f1-score': 0.7543378995433789,\n",
      "                                  'precision': 0.6941176470588235,\n",
      "                                  'recall': 0.826,\n",
      "                                  'support': 500},\n",
      "                           '57': {'f1-score': 0.615097856477167,\n",
      "                                  'precision': 0.5759162303664922,\n",
      "                                  'recall': 0.66,\n",
      "                                  'support': 500},\n",
      "                           '58': {'f1-score': 0.781954887218045,\n",
      "                                  'precision': 0.7375886524822695,\n",
      "                                  'recall': 0.832,\n",
      "                                  'support': 500},\n",
      "                           '59': {'f1-score': 0.561023622047244,\n",
      "                                  'precision': 0.5523255813953488,\n",
      "                                  'recall': 0.57,\n",
      "                                  'support': 500},\n",
      "                           '6': {'f1-score': 0.5801801801801802,\n",
      "                                 'precision': 0.5278688524590164,\n",
      "                                 'recall': 0.644,\n",
      "                                 'support': 500},\n",
      "                           '60': {'f1-score': 0.7690763052208835,\n",
      "                                  'precision': 0.7721774193548387,\n",
      "                                  'recall': 0.766,\n",
      "                                  'support': 500},\n",
      "                           '61': {'f1-score': 0.6458333333333334,\n",
      "                                  'precision': 0.5705521472392638,\n",
      "                                  'recall': 0.744,\n",
      "                                  'support': 500},\n",
      "                           '62': {'f1-score': 0.5958965209634255,\n",
      "                                  'precision': 0.537842190016103,\n",
      "                                  'recall': 0.668,\n",
      "                                  'support': 500},\n",
      "                           '63': {'f1-score': 0.5866935483870968,\n",
      "                                  'precision': 0.5914634146341463,\n",
      "                                  'recall': 0.582,\n",
      "                                  'support': 500},\n",
      "                           '64': {'f1-score': 0.45436507936507936,\n",
      "                                  'precision': 0.4507874015748031,\n",
      "                                  'recall': 0.458,\n",
      "                                  'support': 500},\n",
      "                           '65': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 500},\n",
      "                           '66': {'f1-score': 0.09294320137693632,\n",
      "                                  'precision': 0.3333333333333333,\n",
      "                                  'recall': 0.054,\n",
      "                                  'support': 500},\n",
      "                           '67': {'f1-score': 0.4784889821615949,\n",
      "                                  'precision': 0.5033112582781457,\n",
      "                                  'recall': 0.456,\n",
      "                                  'support': 500},\n",
      "                           '68': {'f1-score': 0.8368663594470046,\n",
      "                                  'precision': 0.7760683760683761,\n",
      "                                  'recall': 0.908,\n",
      "                                  'support': 500},\n",
      "                           '69': {'f1-score': 0.7287449392712552,\n",
      "                                  'precision': 0.7377049180327869,\n",
      "                                  'recall': 0.72,\n",
      "                                  'support': 500},\n",
      "                           '7': {'f1-score': 0.45340501792114696,\n",
      "                                 'precision': 0.4107142857142857,\n",
      "                                 'recall': 0.506,\n",
      "                                 'support': 500},\n",
      "                           '70': {'f1-score': 0.5699481865284974,\n",
      "                                  'precision': 0.5015197568389058,\n",
      "                                  'recall': 0.66,\n",
      "                                  'support': 500},\n",
      "                           '71': {'f1-score': 0.7046070460704608,\n",
      "                                  'precision': 0.642504118616145,\n",
      "                                  'recall': 0.78,\n",
      "                                  'support': 500},\n",
      "                           '72': {'f1-score': 0.28502994011976046,\n",
      "                                  'precision': 0.35522388059701493,\n",
      "                                  'recall': 0.238,\n",
      "                                  'support': 500},\n",
      "                           '73': {'f1-score': 0.5223048327137547,\n",
      "                                  'precision': 0.4878472222222222,\n",
      "                                  'recall': 0.562,\n",
      "                                  'support': 500},\n",
      "                           '74': {'f1-score': 0.44666001994017945,\n",
      "                                  'precision': 0.44532803180914515,\n",
      "                                  'recall': 0.448,\n",
      "                                  'support': 500},\n",
      "                           '75': {'f1-score': 0.7289546716003701,\n",
      "                                  'precision': 0.6781411359724613,\n",
      "                                  'recall': 0.788,\n",
      "                                  'support': 500},\n",
      "                           '76': {'f1-score': 0.7797563261480788,\n",
      "                                  'precision': 0.7336860670194003,\n",
      "                                  'recall': 0.832,\n",
      "                                  'support': 500},\n",
      "                           '77': {'f1-score': 0.33264462809917356,\n",
      "                                  'precision': 0.344017094017094,\n",
      "                                  'recall': 0.322,\n",
      "                                  'support': 500},\n",
      "                           '78': {'f1-score': 0.4319526627218935,\n",
      "                                  'precision': 0.4260700389105058,\n",
      "                                  'recall': 0.438,\n",
      "                                  'support': 500},\n",
      "                           '79': {'f1-score': 0.5438596491228069,\n",
      "                                  'precision': 0.6019417475728155,\n",
      "                                  'recall': 0.496,\n",
      "                                  'support': 500},\n",
      "                           '8': {'f1-score': 0.7209533267130089,\n",
      "                                 'precision': 0.7159763313609467,\n",
      "                                 'recall': 0.726,\n",
      "                                 'support': 500},\n",
      "                           '80': {'f1-score': 0.30472516875602695,\n",
      "                                  'precision': 0.2942271880819367,\n",
      "                                  'recall': 0.316,\n",
      "                                  'support': 500},\n",
      "                           '81': {'f1-score': 0.6584673604541154,\n",
      "                                  'precision': 0.6247755834829444,\n",
      "                                  'recall': 0.696,\n",
      "                                  'support': 500},\n",
      "                           '82': {'f1-score': 0.7649484536082474,\n",
      "                                  'precision': 0.7893617021276595,\n",
      "                                  'recall': 0.742,\n",
      "                                  'support': 500},\n",
      "                           '83': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 500},\n",
      "                           '84': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 500},\n",
      "                           '85': {'f1-score': 0.7371483996120272,\n",
      "                                  'precision': 0.7156308851224106,\n",
      "                                  'recall': 0.76,\n",
      "                                  'support': 500},\n",
      "                           '86': {'f1-score': 0.6568712186689715,\n",
      "                                  'precision': 0.578386605783866,\n",
      "                                  'recall': 0.76,\n",
      "                                  'support': 500},\n",
      "                           '87': {'f1-score': 0.6463104325699746,\n",
      "                                  'precision': 0.561119293078056,\n",
      "                                  'recall': 0.762,\n",
      "                                  'support': 500},\n",
      "                           '88': {'f1-score': 0.6191335740072204,\n",
      "                                  'precision': 0.5641447368421053,\n",
      "                                  'recall': 0.686,\n",
      "                                  'support': 500},\n",
      "                           '89': {'f1-score': 0.6777668952007835,\n",
      "                                  'precision': 0.6641074856046065,\n",
      "                                  'recall': 0.692,\n",
      "                                  'support': 500},\n",
      "                           '9': {'f1-score': 0.7223340040241449,\n",
      "                                 'precision': 0.7267206477732794,\n",
      "                                 'recall': 0.718,\n",
      "                                 'support': 500},\n",
      "                           '90': {'f1-score': 0.593453009503696,\n",
      "                                  'precision': 0.6286353467561522,\n",
      "                                  'recall': 0.562,\n",
      "                                  'support': 500},\n",
      "                           '91': {'f1-score': 0.670899470899471,\n",
      "                                  'precision': 0.7123595505617978,\n",
      "                                  'recall': 0.634,\n",
      "                                  'support': 500},\n",
      "                           '92': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 500},\n",
      "                           '93': {'f1-score': 0.28191489361702127,\n",
      "                                  'precision': 0.42063492063492064,\n",
      "                                  'recall': 0.212,\n",
      "                                  'support': 500},\n",
      "                           '94': {'f1-score': 0.7850098619329388,\n",
      "                                  'precision': 0.77431906614786,\n",
      "                                  'recall': 0.796,\n",
      "                                  'support': 500},\n",
      "                           '95': {'f1-score': 0.6443298969072164,\n",
      "                                  'precision': 0.5647590361445783,\n",
      "                                  'recall': 0.75,\n",
      "                                  'support': 500},\n",
      "                           '96': {'f1-score': 0.5827814569536424,\n",
      "                                  'precision': 0.5529622980251346,\n",
      "                                  'recall': 0.616,\n",
      "                                  'support': 500},\n",
      "                           '97': {'f1-score': 0.5829823083403538,\n",
      "                                  'precision': 0.5036390101892285,\n",
      "                                  'recall': 0.692,\n",
      "                                  'support': 500},\n",
      "                           '98': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 500},\n",
      "                           '99': {'f1-score': 0.564,\n",
      "                                  'precision': 0.564,\n",
      "                                  'recall': 0.564,\n",
      "                                  'support': 500},\n",
      "                           'accuracy': 0.56602,\n",
      "                           'macro avg': {'f1-score': 0.5353352314563695,\n",
      "                                         'precision': 0.5180069347512829,\n",
      "                                         'recall': 0.5660200000000001,\n",
      "                                         'support': 50000},\n",
      "                           'weighted avg': {'f1-score': 0.5353352314563696,\n",
      "                                            'precision': 0.518006934751283,\n",
      "                                            'recall': 0.56602,\n",
      "                                            'support': 50000}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = model.evaluate(train_labels, train_predictions)\n",
    "pprint.pprint(train_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5715967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict(dataloader.dataset.testloader)\n",
    "test_predictions, test_labels = test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5c25f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.444,\n",
      " 'classification_report': {'0': {'f1-score': 0.5793650793650794,\n",
      "                                 'precision': 0.48026315789473684,\n",
      "                                 'recall': 0.73,\n",
      "                                 'support': 100},\n",
      "                           '1': {'f1-score': 0.49586776859504134,\n",
      "                                 'precision': 0.4225352112676056,\n",
      "                                 'recall': 0.6,\n",
      "                                 'support': 100},\n",
      "                           '10': {'f1-score': 0.3069767441860466,\n",
      "                                  'precision': 0.28695652173913044,\n",
      "                                  'recall': 0.33,\n",
      "                                  'support': 100},\n",
      "                           '11': {'f1-score': 0.29184549356223183,\n",
      "                                  'precision': 0.2556390977443609,\n",
      "                                  'recall': 0.34,\n",
      "                                  'support': 100},\n",
      "                           '12': {'f1-score': 0.5888324873096447,\n",
      "                                  'precision': 0.5979381443298969,\n",
      "                                  'recall': 0.58,\n",
      "                                  'support': 100},\n",
      "                           '13': {'f1-score': 0.47169811320754723,\n",
      "                                  'precision': 0.44642857142857145,\n",
      "                                  'recall': 0.5,\n",
      "                                  'support': 100},\n",
      "                           '14': {'f1-score': 0.27692307692307694,\n",
      "                                  'precision': 0.28421052631578947,\n",
      "                                  'recall': 0.27,\n",
      "                                  'support': 100},\n",
      "                           '15': {'f1-score': 0.36548223350253806,\n",
      "                                  'precision': 0.3711340206185567,\n",
      "                                  'recall': 0.36,\n",
      "                                  'support': 100},\n",
      "                           '16': {'f1-score': 0.46728971962616817,\n",
      "                                  'precision': 0.43859649122807015,\n",
      "                                  'recall': 0.5,\n",
      "                                  'support': 100},\n",
      "                           '17': {'f1-score': 0.6470588235294118,\n",
      "                                  'precision': 0.6346153846153846,\n",
      "                                  'recall': 0.66,\n",
      "                                  'support': 100},\n",
      "                           '18': {'f1-score': 0.4104803493449781,\n",
      "                                  'precision': 0.3643410852713178,\n",
      "                                  'recall': 0.47,\n",
      "                                  'support': 100},\n",
      "                           '19': {'f1-score': 0.41711229946524064,\n",
      "                                  'precision': 0.4482758620689655,\n",
      "                                  'recall': 0.39,\n",
      "                                  'support': 100},\n",
      "                           '2': {'f1-score': 0.0,\n",
      "                                 'precision': 0.0,\n",
      "                                 'recall': 0.0,\n",
      "                                 'support': 100},\n",
      "                           '20': {'f1-score': 0.611111111111111,\n",
      "                                  'precision': 0.506578947368421,\n",
      "                                  'recall': 0.77,\n",
      "                                  'support': 100},\n",
      "                           '21': {'f1-score': 0.5152838427947598,\n",
      "                                  'precision': 0.4573643410852713,\n",
      "                                  'recall': 0.59,\n",
      "                                  'support': 100},\n",
      "                           '22': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 100},\n",
      "                           '23': {'f1-score': 0.5739130434782608,\n",
      "                                  'precision': 0.5076923076923077,\n",
      "                                  'recall': 0.66,\n",
      "                                  'support': 100},\n",
      "                           '24': {'f1-score': 0.6098654708520179,\n",
      "                                  'precision': 0.5528455284552846,\n",
      "                                  'recall': 0.68,\n",
      "                                  'support': 100},\n",
      "                           '25': {'f1-score': 0.2983425414364641,\n",
      "                                  'precision': 0.3333333333333333,\n",
      "                                  'recall': 0.27,\n",
      "                                  'support': 100},\n",
      "                           '26': {'f1-score': 0.3957219251336898,\n",
      "                                  'precision': 0.42528735632183906,\n",
      "                                  'recall': 0.37,\n",
      "                                  'support': 100},\n",
      "                           '27': {'f1-score': 0.23107569721115537,\n",
      "                                  'precision': 0.19205298013245034,\n",
      "                                  'recall': 0.29,\n",
      "                                  'support': 100},\n",
      "                           '28': {'f1-score': 0.6634615384615383,\n",
      "                                  'precision': 0.6388888888888888,\n",
      "                                  'recall': 0.69,\n",
      "                                  'support': 100},\n",
      "                           '29': {'f1-score': 0.39378238341968913,\n",
      "                                  'precision': 0.40860215053763443,\n",
      "                                  'recall': 0.38,\n",
      "                                  'support': 100},\n",
      "                           '3': {'f1-score': 0.1564245810055866,\n",
      "                                 'precision': 0.17721518987341772,\n",
      "                                 'recall': 0.14,\n",
      "                                 'support': 100},\n",
      "                           '30': {'f1-score': 0.4117647058823529,\n",
      "                                  'precision': 0.40384615384615385,\n",
      "                                  'recall': 0.42,\n",
      "                                  'support': 100},\n",
      "                           '31': {'f1-score': 0.38862559241706157,\n",
      "                                  'precision': 0.36936936936936937,\n",
      "                                  'recall': 0.41,\n",
      "                                  'support': 100},\n",
      "                           '32': {'f1-score': 0.42391304347826086,\n",
      "                                  'precision': 0.4642857142857143,\n",
      "                                  'recall': 0.39,\n",
      "                                  'support': 100},\n",
      "                           '33': {'f1-score': 0.4183673469387755,\n",
      "                                  'precision': 0.4270833333333333,\n",
      "                                  'recall': 0.41,\n",
      "                                  'support': 100},\n",
      "                           '34': {'f1-score': 0.35978835978835977,\n",
      "                                  'precision': 0.38202247191011235,\n",
      "                                  'recall': 0.34,\n",
      "                                  'support': 100},\n",
      "                           '35': {'f1-score': 0.29184549356223183,\n",
      "                                  'precision': 0.2556390977443609,\n",
      "                                  'recall': 0.34,\n",
      "                                  'support': 100},\n",
      "                           '36': {'f1-score': 0.46511627906976744,\n",
      "                                  'precision': 0.379746835443038,\n",
      "                                  'recall': 0.6,\n",
      "                                  'support': 100},\n",
      "                           '37': {'f1-score': 0.4752475247524752,\n",
      "                                  'precision': 0.47058823529411764,\n",
      "                                  'recall': 0.48,\n",
      "                                  'support': 100},\n",
      "                           '38': {'f1-score': 0.2867383512544803,\n",
      "                                  'precision': 0.22346368715083798,\n",
      "                                  'recall': 0.4,\n",
      "                                  'support': 100},\n",
      "                           '39': {'f1-score': 0.6339285714285714,\n",
      "                                  'precision': 0.5725806451612904,\n",
      "                                  'recall': 0.71,\n",
      "                                  'support': 100},\n",
      "                           '4': {'f1-score': 0.18292682926829268,\n",
      "                                 'precision': 0.234375,\n",
      "                                 'recall': 0.15,\n",
      "                                 'support': 100},\n",
      "                           '40': {'f1-score': 0.4423076923076923,\n",
      "                                  'precision': 0.42592592592592593,\n",
      "                                  'recall': 0.46,\n",
      "                                  'support': 100},\n",
      "                           '41': {'f1-score': 0.6666666666666667,\n",
      "                                  'precision': 0.6842105263157895,\n",
      "                                  'recall': 0.65,\n",
      "                                  'support': 100},\n",
      "                           '42': {'f1-score': 0.5,\n",
      "                                  'precision': 0.49038461538461536,\n",
      "                                  'recall': 0.51,\n",
      "                                  'support': 100},\n",
      "                           '43': {'f1-score': 0.43018867924528303,\n",
      "                                  'precision': 0.34545454545454546,\n",
      "                                  'recall': 0.57,\n",
      "                                  'support': 100},\n",
      "                           '44': {'f1-score': 0.205607476635514,\n",
      "                                  'precision': 0.19298245614035087,\n",
      "                                  'recall': 0.22,\n",
      "                                  'support': 100},\n",
      "                           '45': {'f1-score': 0.26582278481012656,\n",
      "                                  'precision': 0.3620689655172414,\n",
      "                                  'recall': 0.21,\n",
      "                                  'support': 100},\n",
      "                           '46': {'f1-score': 0.31674208144796373,\n",
      "                                  'precision': 0.2892561983471074,\n",
      "                                  'recall': 0.35,\n",
      "                                  'support': 100},\n",
      "                           '47': {'f1-score': 0.45555555555555555,\n",
      "                                  'precision': 0.5125,\n",
      "                                  'recall': 0.41,\n",
      "                                  'support': 100},\n",
      "                           '48': {'f1-score': 0.7238095238095238,\n",
      "                                  'precision': 0.6909090909090909,\n",
      "                                  'recall': 0.76,\n",
      "                                  'support': 100},\n",
      "                           '49': {'f1-score': 0.5991189427312776,\n",
      "                                  'precision': 0.5354330708661418,\n",
      "                                  'recall': 0.68,\n",
      "                                  'support': 100},\n",
      "                           '5': {'f1-score': 0.3864734299516908,\n",
      "                                 'precision': 0.37383177570093457,\n",
      "                                 'recall': 0.4,\n",
      "                                 'support': 100},\n",
      "                           '50': {'f1-score': 0.21118012422360247,\n",
      "                                  'precision': 0.2786885245901639,\n",
      "                                  'recall': 0.17,\n",
      "                                  'support': 100},\n",
      "                           '51': {'f1-score': 0.39593908629441626,\n",
      "                                  'precision': 0.4020618556701031,\n",
      "                                  'recall': 0.39,\n",
      "                                  'support': 100},\n",
      "                           '52': {'f1-score': 0.5967741935483871,\n",
      "                                  'precision': 0.5,\n",
      "                                  'recall': 0.74,\n",
      "                                  'support': 100},\n",
      "                           '53': {'f1-score': 0.6553191489361703,\n",
      "                                  'precision': 0.5703703703703704,\n",
      "                                  'recall': 0.77,\n",
      "                                  'support': 100},\n",
      "                           '54': {'f1-score': 0.5019607843137255,\n",
      "                                  'precision': 0.4129032258064516,\n",
      "                                  'recall': 0.64,\n",
      "                                  'support': 100},\n",
      "                           '55': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 100},\n",
      "                           '56': {'f1-score': 0.6513761467889908,\n",
      "                                  'precision': 0.6016949152542372,\n",
      "                                  'recall': 0.71,\n",
      "                                  'support': 100},\n",
      "                           '57': {'f1-score': 0.5436893203883495,\n",
      "                                  'precision': 0.5283018867924528,\n",
      "                                  'recall': 0.56,\n",
      "                                  'support': 100},\n",
      "                           '58': {'f1-score': 0.5882352941176471,\n",
      "                                  'precision': 0.5769230769230769,\n",
      "                                  'recall': 0.6,\n",
      "                                  'support': 100},\n",
      "                           '59': {'f1-score': 0.47959183673469385,\n",
      "                                  'precision': 0.4895833333333333,\n",
      "                                  'recall': 0.47,\n",
      "                                  'support': 100},\n",
      "                           '6': {'f1-score': 0.4954128440366973,\n",
      "                                 'precision': 0.4576271186440678,\n",
      "                                 'recall': 0.54,\n",
      "                                 'support': 100},\n",
      "                           '60': {'f1-score': 0.6570048309178744,\n",
      "                                  'precision': 0.6355140186915887,\n",
      "                                  'recall': 0.68,\n",
      "                                  'support': 100},\n",
      "                           '61': {'f1-score': 0.5414847161572052,\n",
      "                                  'precision': 0.4806201550387597,\n",
      "                                  'recall': 0.62,\n",
      "                                  'support': 100},\n",
      "                           '62': {'f1-score': 0.52,\n",
      "                                  'precision': 0.52,\n",
      "                                  'recall': 0.52,\n",
      "                                  'support': 100},\n",
      "                           '63': {'f1-score': 0.4065934065934066,\n",
      "                                  'precision': 0.45121951219512196,\n",
      "                                  'recall': 0.37,\n",
      "                                  'support': 100},\n",
      "                           '64': {'f1-score': 0.27659574468085113,\n",
      "                                  'precision': 0.29545454545454547,\n",
      "                                  'recall': 0.26,\n",
      "                                  'support': 100},\n",
      "                           '65': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 100},\n",
      "                           '66': {'f1-score': 0.13445378151260506,\n",
      "                                  'precision': 0.42105263157894735,\n",
      "                                  'recall': 0.08,\n",
      "                                  'support': 100},\n",
      "                           '67': {'f1-score': 0.27932960893854747,\n",
      "                                  'precision': 0.31645569620253167,\n",
      "                                  'recall': 0.25,\n",
      "                                  'support': 100},\n",
      "                           '68': {'f1-score': 0.7757009345794393,\n",
      "                                  'precision': 0.7280701754385965,\n",
      "                                  'recall': 0.83,\n",
      "                                  'support': 100},\n",
      "                           '69': {'f1-score': 0.5685279187817258,\n",
      "                                  'precision': 0.5773195876288659,\n",
      "                                  'recall': 0.56,\n",
      "                                  'support': 100},\n",
      "                           '7': {'f1-score': 0.3791469194312796,\n",
      "                                 'precision': 0.36036036036036034,\n",
      "                                 'recall': 0.4,\n",
      "                                 'support': 100},\n",
      "                           '70': {'f1-score': 0.5126050420168067,\n",
      "                                  'precision': 0.4420289855072464,\n",
      "                                  'recall': 0.61,\n",
      "                                  'support': 100},\n",
      "                           '71': {'f1-score': 0.6261682242990654,\n",
      "                                  'precision': 0.5877192982456141,\n",
      "                                  'recall': 0.67,\n",
      "                                  'support': 100},\n",
      "                           '72': {'f1-score': 0.14634146341463414,\n",
      "                                  'precision': 0.1875,\n",
      "                                  'recall': 0.12,\n",
      "                                  'support': 100},\n",
      "                           '73': {'f1-score': 0.36936936936936937,\n",
      "                                  'precision': 0.3360655737704918,\n",
      "                                  'recall': 0.41,\n",
      "                                  'support': 100},\n",
      "                           '74': {'f1-score': 0.2535211267605634,\n",
      "                                  'precision': 0.23893805309734514,\n",
      "                                  'recall': 0.27,\n",
      "                                  'support': 100},\n",
      "                           '75': {'f1-score': 0.5765765765765766,\n",
      "                                  'precision': 0.5245901639344263,\n",
      "                                  'recall': 0.64,\n",
      "                                  'support': 100},\n",
      "                           '76': {'f1-score': 0.6820276497695852,\n",
      "                                  'precision': 0.6324786324786325,\n",
      "                                  'recall': 0.74,\n",
      "                                  'support': 100},\n",
      "                           '77': {'f1-score': 0.2631578947368421,\n",
      "                                  'precision': 0.2777777777777778,\n",
      "                                  'recall': 0.25,\n",
      "                                  'support': 100},\n",
      "                           '78': {'f1-score': 0.27619047619047615,\n",
      "                                  'precision': 0.2636363636363636,\n",
      "                                  'recall': 0.29,\n",
      "                                  'support': 100},\n",
      "                           '79': {'f1-score': 0.5425531914893618,\n",
      "                                  'precision': 0.5795454545454546,\n",
      "                                  'recall': 0.51,\n",
      "                                  'support': 100},\n",
      "                           '8': {'f1-score': 0.5784313725490196,\n",
      "                                 'precision': 0.5673076923076923,\n",
      "                                 'recall': 0.59,\n",
      "                                 'support': 100},\n",
      "                           '80': {'f1-score': 0.19909502262443438,\n",
      "                                  'precision': 0.18181818181818182,\n",
      "                                  'recall': 0.22,\n",
      "                                  'support': 100},\n",
      "                           '81': {'f1-score': 0.5438596491228069,\n",
      "                                  'precision': 0.484375,\n",
      "                                  'recall': 0.62,\n",
      "                                  'support': 100},\n",
      "                           '82': {'f1-score': 0.6914893617021277,\n",
      "                                  'precision': 0.7386363636363636,\n",
      "                                  'recall': 0.65,\n",
      "                                  'support': 100},\n",
      "                           '83': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 100},\n",
      "                           '84': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 100},\n",
      "                           '85': {'f1-score': 0.5071770334928231,\n",
      "                                  'precision': 0.48623853211009177,\n",
      "                                  'recall': 0.53,\n",
      "                                  'support': 100},\n",
      "                           '86': {'f1-score': 0.4845814977973568,\n",
      "                                  'precision': 0.4330708661417323,\n",
      "                                  'recall': 0.55,\n",
      "                                  'support': 100},\n",
      "                           '87': {'f1-score': 0.5857740585774058,\n",
      "                                  'precision': 0.5035971223021583,\n",
      "                                  'recall': 0.7,\n",
      "                                  'support': 100},\n",
      "                           '88': {'f1-score': 0.4571428571428572,\n",
      "                                  'precision': 0.43636363636363634,\n",
      "                                  'recall': 0.48,\n",
      "                                  'support': 100},\n",
      "                           '89': {'f1-score': 0.43269230769230765,\n",
      "                                  'precision': 0.4166666666666667,\n",
      "                                  'recall': 0.45,\n",
      "                                  'support': 100},\n",
      "                           '9': {'f1-score': 0.6296296296296295,\n",
      "                                 'precision': 0.5862068965517241,\n",
      "                                 'recall': 0.68,\n",
      "                                 'support': 100},\n",
      "                           '90': {'f1-score': 0.4974619289340101,\n",
      "                                  'precision': 0.5051546391752577,\n",
      "                                  'recall': 0.49,\n",
      "                                  'support': 100},\n",
      "                           '91': {'f1-score': 0.5494505494505494,\n",
      "                                  'precision': 0.6097560975609756,\n",
      "                                  'recall': 0.5,\n",
      "                                  'support': 100},\n",
      "                           '92': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 100},\n",
      "                           '93': {'f1-score': 0.19161676646706588,\n",
      "                                  'precision': 0.23880597014925373,\n",
      "                                  'recall': 0.16,\n",
      "                                  'support': 100},\n",
      "                           '94': {'f1-score': 0.8186528497409327,\n",
      "                                  'precision': 0.8494623655913979,\n",
      "                                  'recall': 0.79,\n",
      "                                  'support': 100},\n",
      "                           '95': {'f1-score': 0.47111111111111115,\n",
      "                                  'precision': 0.424,\n",
      "                                  'recall': 0.53,\n",
      "                                  'support': 100},\n",
      "                           '96': {'f1-score': 0.3663366336633664,\n",
      "                                  'precision': 0.3627450980392157,\n",
      "                                  'recall': 0.37,\n",
      "                                  'support': 100},\n",
      "                           '97': {'f1-score': 0.4884792626728111,\n",
      "                                  'precision': 0.452991452991453,\n",
      "                                  'recall': 0.53,\n",
      "                                  'support': 100},\n",
      "                           '98': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 100},\n",
      "                           '99': {'f1-score': 0.4945054945054946,\n",
      "                                  'precision': 0.5487804878048781,\n",
      "                                  'recall': 0.45,\n",
      "                                  'support': 100},\n",
      "                           'accuracy': 0.444,\n",
      "                           'macro avg': {'f1-score': 0.41992784296998203,\n",
      "                                         'precision': 0.4081723117448891,\n",
      "                                         'recall': 0.444,\n",
      "                                         'support': 10000},\n",
      "                           'weighted avg': {'f1-score': 0.419927842969982,\n",
      "                                            'precision': 0.40817231174488916,\n",
      "                                            'recall': 0.444,\n",
      "                                            'support': 10000}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_eval_result = model.evaluate(test_labels, test_predictions)\n",
    "pprint.pprint(test_eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
