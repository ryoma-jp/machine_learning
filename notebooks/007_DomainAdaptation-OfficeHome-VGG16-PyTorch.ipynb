{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474b637f",
   "metadata": {},
   "source": [
    "# Domain Adaptation Sample\n",
    "\n",
    "|Item|Description|\n",
    "|---|---|\n",
    "|DeepLearning Framework|PyTorch|\n",
    "|Dataset|[Office-Home](https://www.hemanthdv.org/officeHomeDataset.html)|\n",
    "|Model Architecture|VGG16|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc9d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c40f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "from data_loader.data_loader import DataLoader\n",
    "from models.pytorch import vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080cc78",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d245650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbcd59236f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b0797",
   "metadata": {},
   "source": [
    "## Device Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8918ce3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b33722-c3bb-4202-9172-75aa4070bdd0",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "\n",
    "### Download Dataset\n",
    "\n",
    "Download `OfficeHomeDataset_10072016.zip` from [Dataset Download](https://drive.google.com/file/d/0B81rNlvomiwed0V1YUxQdC1uOTg/view?usp=sharing&resourcekey=0-2SNWq0CDAuWOBRRBL7ZZsw) and save to `/workspace/dataset_tmp/OfficeHomeDataset_10072016.zip`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273fec8f-6424-4c3f-8a18-39d3280f8d02",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3263dcf8-cbe2-4ee9-ab84-e94d7bfcee66",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 400\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 0.004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60045952",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deef041c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset_name = 'officehome_pytorch'\n",
    "dataset_dir = '/workspace/dataset_tmp'\n",
    "\n",
    "dataloader = DataLoader(dataset_name, dataset_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d4b5bda",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Alarm_Clock',\n",
       " 'Backpack',\n",
       " 'Batteries',\n",
       " 'Bed',\n",
       " 'Bike',\n",
       " 'Bottle',\n",
       " 'Bucket',\n",
       " 'Calculator',\n",
       " 'Calendar',\n",
       " 'Candles',\n",
       " 'Chair',\n",
       " 'Clipboards',\n",
       " 'Computer',\n",
       " 'Couch',\n",
       " 'Curtains',\n",
       " 'Desk_Lamp',\n",
       " 'Drill',\n",
       " 'Eraser',\n",
       " 'Exit_Sign',\n",
       " 'Fan',\n",
       " 'File_Cabinet',\n",
       " 'Flipflops',\n",
       " 'Flowers',\n",
       " 'Folder',\n",
       " 'Fork',\n",
       " 'Glasses',\n",
       " 'Hammer',\n",
       " 'Helmet',\n",
       " 'Kettle',\n",
       " 'Keyboard',\n",
       " 'Knives',\n",
       " 'Lamp_Shade',\n",
       " 'Laptop',\n",
       " 'Marker',\n",
       " 'Monitor',\n",
       " 'Mop',\n",
       " 'Mouse',\n",
       " 'Mug',\n",
       " 'Notebook',\n",
       " 'Oven',\n",
       " 'Pan',\n",
       " 'Paper_Clip',\n",
       " 'Pen',\n",
       " 'Pencil',\n",
       " 'Postit_Notes',\n",
       " 'Printer',\n",
       " 'Push_Pin',\n",
       " 'Radio',\n",
       " 'Refrigerator',\n",
       " 'Ruler',\n",
       " 'Scissors',\n",
       " 'Screwdriver',\n",
       " 'Shelf',\n",
       " 'Sink',\n",
       " 'Sneakers',\n",
       " 'Soda',\n",
       " 'Speaker',\n",
       " 'Spoon',\n",
       " 'TV',\n",
       " 'Table',\n",
       " 'Telephone',\n",
       " 'ToothBrush',\n",
       " 'Toys',\n",
       " 'Trash_Can',\n",
       " 'Webcam']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset.class_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef213c0a",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9458841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [32, 65]                  --\n",
      "├─Sequential: 1-1                        [32, 64, 227, 227]        --\n",
      "│    └─Conv2d: 2-1                       [32, 64, 227, 227]        1,792\n",
      "│    └─BatchNorm2d: 2-2                  [32, 64, 227, 227]        128\n",
      "│    └─ReLU: 2-3                         [32, 64, 227, 227]        --\n",
      "├─Sequential: 1-2                        [32, 64, 113, 113]        --\n",
      "│    └─Conv2d: 2-4                       [32, 64, 227, 227]        36,928\n",
      "│    └─BatchNorm2d: 2-5                  [32, 64, 227, 227]        128\n",
      "│    └─ReLU: 2-6                         [32, 64, 227, 227]        --\n",
      "│    └─MaxPool2d: 2-7                    [32, 64, 113, 113]        --\n",
      "├─Sequential: 1-3                        [32, 128, 113, 113]       --\n",
      "│    └─Conv2d: 2-8                       [32, 128, 113, 113]       73,856\n",
      "│    └─BatchNorm2d: 2-9                  [32, 128, 113, 113]       256\n",
      "│    └─ReLU: 2-10                        [32, 128, 113, 113]       --\n",
      "├─Sequential: 1-4                        [32, 128, 56, 56]         --\n",
      "│    └─Conv2d: 2-11                      [32, 128, 113, 113]       147,584\n",
      "│    └─BatchNorm2d: 2-12                 [32, 128, 113, 113]       256\n",
      "│    └─ReLU: 2-13                        [32, 128, 113, 113]       --\n",
      "│    └─MaxPool2d: 2-14                   [32, 128, 56, 56]         --\n",
      "├─Sequential: 1-5                        [32, 256, 56, 56]         --\n",
      "│    └─Conv2d: 2-15                      [32, 256, 56, 56]         295,168\n",
      "│    └─BatchNorm2d: 2-16                 [32, 256, 56, 56]         512\n",
      "│    └─ReLU: 2-17                        [32, 256, 56, 56]         --\n",
      "├─Sequential: 1-6                        [32, 256, 56, 56]         --\n",
      "│    └─Conv2d: 2-18                      [32, 256, 56, 56]         590,080\n",
      "│    └─BatchNorm2d: 2-19                 [32, 256, 56, 56]         512\n",
      "│    └─ReLU: 2-20                        [32, 256, 56, 56]         --\n",
      "├─Sequential: 1-7                        [32, 256, 28, 28]         --\n",
      "│    └─Conv2d: 2-21                      [32, 256, 56, 56]         590,080\n",
      "│    └─BatchNorm2d: 2-22                 [32, 256, 56, 56]         512\n",
      "│    └─ReLU: 2-23                        [32, 256, 56, 56]         --\n",
      "│    └─MaxPool2d: 2-24                   [32, 256, 28, 28]         --\n",
      "├─Sequential: 1-8                        [32, 512, 28, 28]         --\n",
      "│    └─Conv2d: 2-25                      [32, 512, 28, 28]         1,180,160\n",
      "│    └─BatchNorm2d: 2-26                 [32, 512, 28, 28]         1,024\n",
      "│    └─ReLU: 2-27                        [32, 512, 28, 28]         --\n",
      "├─Sequential: 1-9                        [32, 512, 28, 28]         --\n",
      "│    └─Conv2d: 2-28                      [32, 512, 28, 28]         2,359,808\n",
      "│    └─BatchNorm2d: 2-29                 [32, 512, 28, 28]         1,024\n",
      "│    └─ReLU: 2-30                        [32, 512, 28, 28]         --\n",
      "├─Sequential: 1-10                       [32, 512, 14, 14]         --\n",
      "│    └─Conv2d: 2-31                      [32, 512, 28, 28]         2,359,808\n",
      "│    └─BatchNorm2d: 2-32                 [32, 512, 28, 28]         1,024\n",
      "│    └─ReLU: 2-33                        [32, 512, 28, 28]         --\n",
      "│    └─MaxPool2d: 2-34                   [32, 512, 14, 14]         --\n",
      "├─Sequential: 1-11                       [32, 512, 14, 14]         --\n",
      "│    └─Conv2d: 2-35                      [32, 512, 14, 14]         2,359,808\n",
      "│    └─BatchNorm2d: 2-36                 [32, 512, 14, 14]         1,024\n",
      "│    └─ReLU: 2-37                        [32, 512, 14, 14]         --\n",
      "├─Sequential: 1-12                       [32, 512, 14, 14]         --\n",
      "│    └─Conv2d: 2-38                      [32, 512, 14, 14]         2,359,808\n",
      "│    └─BatchNorm2d: 2-39                 [32, 512, 14, 14]         1,024\n",
      "│    └─ReLU: 2-40                        [32, 512, 14, 14]         --\n",
      "├─Sequential: 1-13                       [32, 512, 7, 7]           --\n",
      "│    └─Conv2d: 2-41                      [32, 512, 14, 14]         2,359,808\n",
      "│    └─BatchNorm2d: 2-42                 [32, 512, 14, 14]         1,024\n",
      "│    └─ReLU: 2-43                        [32, 512, 14, 14]         --\n",
      "│    └─MaxPool2d: 2-44                   [32, 512, 7, 7]           --\n",
      "├─Sequential: 1-14                       [32, 4096]                --\n",
      "│    └─Dropout: 2-45                     [32, 25088]               --\n",
      "│    └─Linear: 2-46                      [32, 4096]                102,764,544\n",
      "│    └─ReLU: 2-47                        [32, 4096]                --\n",
      "├─Sequential: 1-15                       [32, 4096]                --\n",
      "│    └─Dropout: 2-48                     [32, 4096]                --\n",
      "│    └─Linear: 2-49                      [32, 4096]                16,781,312\n",
      "│    └─ReLU: 2-50                        [32, 4096]                --\n",
      "├─Sequential: 1-16                       [32, 65]                  --\n",
      "│    └─Linear: 2-51                      [32, 65]                  266,305\n",
      "==========================================================================================\n",
      "Total params: 134,535,297\n",
      "Trainable params: 134,535,297\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 498.63\n",
      "==========================================================================================\n",
      "Input size (MB): 19.79\n",
      "Forward/backward pass size (MB): 7056.61\n",
      "Params size (MB): 538.14\n",
      "Estimated Total Size (MB): 7614.53\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "input_size = (batch_size, 3, 227, 227)\n",
    "num_classes = len(dataloader.dataset.class_name)\n",
    "model = vgg16.VGG16(device, input_size=input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f21dcead",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH #0] loss: 4.232601755543759\n",
      "[EPOCH #1, elapsed time: 17.355[sec]] loss: 4.134408266920793\n",
      "[EPOCH #2, elapsed time: 34.821[sec]] loss: 4.174676804166091\n",
      "[EPOCH #3, elapsed time: 52.343[sec]] loss: 4.143182644718571\n",
      "[EPOCH #4, elapsed time: 69.901[sec]] loss: 4.070711405653703\n",
      "[EPOCH #5, elapsed time: 87.119[sec]] loss: 4.140988519317226\n",
      "[EPOCH #6, elapsed time: 104.287[sec]] loss: 4.07164278155879\n",
      "[EPOCH #7, elapsed time: 121.450[sec]] loss: 4.084255096159484\n",
      "[EPOCH #8, elapsed time: 138.823[sec]] loss: 4.093585428438689\n",
      "[EPOCH #9, elapsed time: 156.109[sec]] loss: 4.099932243949489\n",
      "[EPOCH #10, elapsed time: 173.446[sec]] loss: 4.108473934625325\n",
      "[EPOCH #11, elapsed time: 190.769[sec]] loss: 4.092969759514458\n",
      "[EPOCH #12, elapsed time: 207.906[sec]] loss: 4.154813615899337\n",
      "[EPOCH #13, elapsed time: 225.185[sec]] loss: 4.107218855305722\n",
      "[EPOCH #14, elapsed time: 242.311[sec]] loss: 4.11021490787205\n",
      "[EPOCH #15, elapsed time: 259.448[sec]] loss: 4.10850473454124\n",
      "[EPOCH #16, elapsed time: 276.680[sec]] loss: 4.094188338831851\n",
      "[EPOCH #17, elapsed time: 294.191[sec]] loss: 4.068141629821376\n",
      "[EPOCH #18, elapsed time: 311.425[sec]] loss: 4.0687083476468136\n",
      "[EPOCH #19, elapsed time: 328.796[sec]] loss: 4.056519687175751\n",
      "[EPOCH #20, elapsed time: 346.307[sec]] loss: 4.059752285480499\n",
      "[EPOCH #21, elapsed time: 363.769[sec]] loss: 4.05246397068626\n",
      "[EPOCH #22, elapsed time: 381.010[sec]] loss: 4.048349308340173\n",
      "[EPOCH #23, elapsed time: 398.279[sec]] loss: 4.074715705294358\n",
      "[EPOCH #24, elapsed time: 415.586[sec]] loss: 4.083512943041952\n",
      "[EPOCH #25, elapsed time: 432.950[sec]] loss: 4.054059725058706\n",
      "[EPOCH #26, elapsed time: 450.235[sec]] loss: 4.067104571744015\n",
      "[EPOCH #27, elapsed time: 467.484[sec]] loss: 4.069365231614364\n",
      "[EPOCH #28, elapsed time: 485.108[sec]] loss: 4.050920505272715\n",
      "[EPOCH #29, elapsed time: 502.276[sec]] loss: 4.05207338772322\n",
      "[EPOCH #30, elapsed time: 519.439[sec]] loss: 4.044120776025872\n",
      "[EPOCH #31, elapsed time: 536.728[sec]] loss: 4.051670300333123\n",
      "[EPOCH #32, elapsed time: 554.052[sec]] loss: 4.046863254747893\n",
      "[EPOCH #33, elapsed time: 571.462[sec]] loss: 4.053476371263203\n",
      "[EPOCH #34, elapsed time: 588.663[sec]] loss: 4.04692531573145\n",
      "[EPOCH #35, elapsed time: 605.859[sec]] loss: 4.059791950803054\n",
      "[EPOCH #36, elapsed time: 623.115[sec]] loss: 4.047356705916555\n",
      "[EPOCH #37, elapsed time: 640.615[sec]] loss: 4.050254479834908\n",
      "[EPOCH #38, elapsed time: 657.858[sec]] loss: 4.043013055073588\n",
      "[EPOCH #39, elapsed time: 675.178[sec]] loss: 4.041802196126235\n",
      "[EPOCH #40, elapsed time: 692.508[sec]] loss: 4.044777440397363\n",
      "[EPOCH #41, elapsed time: 709.957[sec]] loss: 4.05482048109958\n",
      "[EPOCH #42, elapsed time: 727.363[sec]] loss: 4.041789823456814\n",
      "[EPOCH #43, elapsed time: 744.865[sec]] loss: 4.045945550266065\n",
      "[EPOCH #44, elapsed time: 762.394[sec]] loss: 4.046971220719187\n",
      "[EPOCH #45, elapsed time: 779.989[sec]] loss: 4.073826733388398\n",
      "[EPOCH #46, elapsed time: 797.225[sec]] loss: 4.094975063675328\n",
      "[EPOCH #47, elapsed time: 814.499[sec]] loss: 4.06401621040545\n",
      "[EPOCH #48, elapsed time: 831.803[sec]] loss: 4.0538014644070675\n",
      "[EPOCH #49, elapsed time: 848.990[sec]] loss: 4.0467867694403\n",
      "[EPOCH #50, elapsed time: 866.318[sec]] loss: 4.0625454061909725\n",
      "[EPOCH #51, elapsed time: 883.581[sec]] loss: 4.0474175497105245\n",
      "[EPOCH #52, elapsed time: 900.831[sec]] loss: 4.0499625990265296\n",
      "[EPOCH #53, elapsed time: 918.122[sec]] loss: 4.039382140887411\n",
      "[EPOCH #54, elapsed time: 935.340[sec]] loss: 4.041744806264576\n",
      "[EPOCH #55, elapsed time: 952.931[sec]] loss: 4.051814289469468\n",
      "[EPOCH #56, elapsed time: 970.479[sec]] loss: 4.034676937680495\n",
      "[EPOCH #57, elapsed time: 987.996[sec]] loss: 4.0662463589718465\n",
      "[EPOCH #58, elapsed time: 1005.504[sec]] loss: 4.061519011070854\n",
      "[EPOCH #59, elapsed time: 1022.837[sec]] loss: 4.048208396685751\n",
      "[EPOCH #60, elapsed time: 1040.172[sec]] loss: 4.054855735678422\n",
      "[EPOCH #61, elapsed time: 1057.656[sec]] loss: 4.035853928641269\n",
      "[EPOCH #62, elapsed time: 1075.179[sec]] loss: 4.0460785031318665\n",
      "[EPOCH #63, elapsed time: 1092.607[sec]] loss: 4.057184674237904\n",
      "[EPOCH #64, elapsed time: 1109.855[sec]] loss: 4.037791819948899\n",
      "[EPOCH #65, elapsed time: 1127.197[sec]] loss: 4.033921100591359\n",
      "[EPOCH #66, elapsed time: 1144.639[sec]] loss: 4.02621832333113\n",
      "[EPOCH #67, elapsed time: 1162.176[sec]] loss: 4.027426133030339\n",
      "[EPOCH #68, elapsed time: 1179.708[sec]] loss: 4.025700663265429\n",
      "[EPOCH #69, elapsed time: 1197.209[sec]] loss: 4.092922951045789\n",
      "[EPOCH #70, elapsed time: 1214.727[sec]] loss: 4.071562851730146\n",
      "[EPOCH #71, elapsed time: 1232.315[sec]] loss: 4.0847082859591435\n",
      "[EPOCH #72, elapsed time: 1249.842[sec]] loss: 4.107720152327889\n",
      "[EPOCH #73, elapsed time: 1267.386[sec]] loss: 4.069721272117214\n",
      "[EPOCH #74, elapsed time: 1284.751[sec]] loss: 4.058442385573136\n",
      "[EPOCH #75, elapsed time: 1302.025[sec]] loss: 4.046915364892859\n",
      "[EPOCH #76, elapsed time: 1319.335[sec]] loss: 4.068739950656891\n",
      "[EPOCH #77, elapsed time: 1336.919[sec]] loss: 4.05477237701416\n",
      "[EPOCH #78, elapsed time: 1354.469[sec]] loss: 4.053703182622006\n",
      "[EPOCH #79, elapsed time: 1371.996[sec]] loss: 4.045548338639109\n",
      "[EPOCH #80, elapsed time: 1389.553[sec]] loss: 4.039782116287633\n",
      "[EPOCH #81, elapsed time: 1407.164[sec]] loss: 4.032322450688011\n",
      "[EPOCH #82, elapsed time: 1424.780[sec]] loss: 4.032581796771602\n",
      "[EPOCH #83, elapsed time: 1442.152[sec]] loss: 4.023766959968366\n",
      "[EPOCH #84, elapsed time: 1459.530[sec]] loss: 4.02605748803992\n",
      "[EPOCH #85, elapsed time: 1476.898[sec]] loss: 4.0223844427811475\n",
      "[EPOCH #86, elapsed time: 1494.339[sec]] loss: 4.026066268745222\n",
      "[EPOCH #87, elapsed time: 1511.726[sec]] loss: 4.0190279107344775\n",
      "[EPOCH #88, elapsed time: 1529.304[sec]] loss: 4.021443222698412\n",
      "[EPOCH #89, elapsed time: 1547.210[sec]] loss: 4.007893377228787\n",
      "[EPOCH #90, elapsed time: 1565.044[sec]] loss: 4.028774725763421\n",
      "[EPOCH #91, elapsed time: 1582.414[sec]] loss: 4.009603983477542\n",
      "[EPOCH #92, elapsed time: 1600.006[sec]] loss: 4.01188590024647\n",
      "[EPOCH #93, elapsed time: 1617.553[sec]] loss: 4.007213890552521\n",
      "[EPOCH #94, elapsed time: 1635.434[sec]] loss: 4.009804211164775\n",
      "[EPOCH #95, elapsed time: 1652.873[sec]] loss: 4.01147000413192\n",
      "[EPOCH #96, elapsed time: 1670.178[sec]] loss: 4.008287624308937\n",
      "[EPOCH #97, elapsed time: 1687.512[sec]] loss: 4.008687392661446\n",
      "[EPOCH #98, elapsed time: 1705.055[sec]] loss: 4.006581789568851\n",
      "[EPOCH #99, elapsed time: 1722.730[sec]] loss: 4.005146839116749\n",
      "[EPOCH #100, elapsed time: 1740.443[sec]] loss: 4.004322281009273\n",
      "[EPOCH #101, elapsed time: 1758.255[sec]] loss: 3.9989026471188196\n",
      "[EPOCH #102, elapsed time: 1776.006[sec]] loss: 3.9991344401710913\n",
      "[EPOCH #103, elapsed time: 1793.890[sec]] loss: 4.009674348329243\n",
      "[EPOCH #104, elapsed time: 1811.747[sec]] loss: 3.9958955018143905\n",
      "[EPOCH #105, elapsed time: 1829.593[sec]] loss: 3.9978710632575187\n",
      "[EPOCH #106, elapsed time: 1847.355[sec]] loss: 3.9970884040782324\n",
      "[EPOCH #107, elapsed time: 1865.156[sec]] loss: 3.991422126167699\n",
      "[EPOCH #108, elapsed time: 1883.025[sec]] loss: 3.998921695508455\n",
      "[EPOCH #109, elapsed time: 1900.806[sec]] loss: 3.9920983063547233\n",
      "[EPOCH #110, elapsed time: 1918.521[sec]] loss: 3.9827597831424915\n",
      "[EPOCH #111, elapsed time: 1936.334[sec]] loss: 3.981802159234097\n",
      "[EPOCH #112, elapsed time: 1954.132[sec]] loss: 3.984138187609221\n",
      "[EPOCH #113, elapsed time: 1971.821[sec]] loss: 3.9935869856884607\n",
      "[EPOCH #114, elapsed time: 1989.555[sec]] loss: 3.987551061730636\n",
      "[EPOCH #115, elapsed time: 2007.312[sec]] loss: 3.9823972614187944\n",
      "[EPOCH #116, elapsed time: 2025.051[sec]] loss: 3.979583602202566\n",
      "[EPOCH #117, elapsed time: 2042.797[sec]] loss: 3.983734883760151\n",
      "[EPOCH #118, elapsed time: 2060.540[sec]] loss: 3.9868785331123755\n",
      "[EPOCH #119, elapsed time: 2078.303[sec]] loss: 3.9897567002396834\n",
      "[EPOCH #120, elapsed time: 2095.986[sec]] loss: 3.977805589374743\n",
      "[EPOCH #121, elapsed time: 2113.820[sec]] loss: 3.9758551465837577\n",
      "[EPOCH #122, elapsed time: 2131.557[sec]] loss: 3.978460126801541\n",
      "[EPOCH #123, elapsed time: 2149.300[sec]] loss: 3.9752901698413647\n",
      "[EPOCH #124, elapsed time: 2167.021[sec]] loss: 3.9750845338168896\n",
      "[EPOCH #125, elapsed time: 2184.711[sec]] loss: 3.972906784007424\n",
      "[EPOCH #126, elapsed time: 2202.437[sec]] loss: 3.972000950261166\n",
      "[EPOCH #127, elapsed time: 2220.203[sec]] loss: 3.962239500723387\n",
      "[EPOCH #128, elapsed time: 2237.971[sec]] loss: 3.975520149657601\n",
      "[EPOCH #129, elapsed time: 2255.789[sec]] loss: 3.9730749349845085\n",
      "[EPOCH #130, elapsed time: 2273.569[sec]] loss: 3.9662849620768896\n",
      "[EPOCH #131, elapsed time: 2291.285[sec]] loss: 3.9719211835610237\n",
      "[EPOCH #132, elapsed time: 2308.968[sec]] loss: 3.9641419304044625\n",
      "[EPOCH #133, elapsed time: 2326.624[sec]] loss: 3.9608926898554753\n",
      "[EPOCH #134, elapsed time: 2344.323[sec]] loss: 3.9606919696456506\n",
      "[EPOCH #135, elapsed time: 2362.014[sec]] loss: 3.9544717136182284\n",
      "[EPOCH #136, elapsed time: 2379.713[sec]] loss: 3.957672329325425\n",
      "[EPOCH #137, elapsed time: 2397.489[sec]] loss: 3.970535607714402\n",
      "[EPOCH #138, elapsed time: 2415.212[sec]] loss: 3.9674603374380815\n",
      "[EPOCH #139, elapsed time: 2432.959[sec]] loss: 3.9692416975372717\n",
      "[EPOCH #140, elapsed time: 2450.686[sec]] loss: 3.984900803942429\n",
      "[EPOCH #141, elapsed time: 2468.408[sec]] loss: 3.960483952572471\n",
      "[EPOCH #142, elapsed time: 2486.173[sec]] loss: 3.972144876655779\n",
      "[EPOCH #143, elapsed time: 2503.970[sec]] loss: 3.9757037696085478\n",
      "[EPOCH #144, elapsed time: 2521.749[sec]] loss: 3.9739183375709937\n",
      "[EPOCH #145, elapsed time: 2539.534[sec]] loss: 4.034986743801518\n",
      "[EPOCH #146, elapsed time: 2557.341[sec]] loss: 4.06885207954206\n",
      "[EPOCH #147, elapsed time: 2575.069[sec]] loss: 4.063225661453448\n",
      "[EPOCH #148, elapsed time: 2592.799[sec]] loss: 4.022427941623487\n",
      "[EPOCH #149, elapsed time: 2610.510[sec]] loss: 3.997945873360885\n",
      "[EPOCH #150, elapsed time: 2628.275[sec]] loss: 3.9970712661743164\n",
      "[EPOCH #151, elapsed time: 2645.972[sec]] loss: 3.9792503714561462\n",
      "[EPOCH #152, elapsed time: 2663.889[sec]] loss: 3.96555631411703\n",
      "[EPOCH #153, elapsed time: 2681.854[sec]] loss: 3.94539811736659\n",
      "[EPOCH #154, elapsed time: 2699.871[sec]] loss: 3.9517558969949422\n",
      "[EPOCH #155, elapsed time: 2717.870[sec]] loss: 3.9620448476389836\n",
      "[EPOCH #156, elapsed time: 2735.883[sec]] loss: 3.9246222282710828\n",
      "[EPOCH #157, elapsed time: 2753.871[sec]] loss: 3.9265702617795846\n",
      "[EPOCH #158, elapsed time: 2771.912[sec]] loss: 3.9143281045712923\n",
      "[EPOCH #159, elapsed time: 2789.904[sec]] loss: 3.8950355868590507\n",
      "[EPOCH #160, elapsed time: 2807.866[sec]] loss: 3.895387690318258\n",
      "[EPOCH #161, elapsed time: 2825.888[sec]] loss: 3.8772710248043665\n",
      "[EPOCH #162, elapsed time: 2843.854[sec]] loss: 3.8774755252035042\n",
      "[EPOCH #163, elapsed time: 2861.858[sec]] loss: 3.835427519522215\n",
      "[EPOCH #164, elapsed time: 2879.858[sec]] loss: 3.8290588636147347\n",
      "[EPOCH #165, elapsed time: 2897.903[sec]] loss: 3.8010195179989466\n",
      "[EPOCH #166, elapsed time: 2915.845[sec]] loss: 3.789261585787723\n",
      "[EPOCH #167, elapsed time: 2933.830[sec]] loss: 3.7778372231282686\n",
      "[EPOCH #168, elapsed time: 2951.798[sec]] loss: 3.7513170618759957\n",
      "[EPOCH #169, elapsed time: 2969.203[sec]] loss: 3.7237273768374792\n",
      "[EPOCH #170, elapsed time: 2986.937[sec]] loss: 3.689744974437513\n",
      "[EPOCH #171, elapsed time: 3004.617[sec]] loss: 3.6752635836601257\n",
      "[EPOCH #172, elapsed time: 3022.286[sec]] loss: 3.6171181421530876\n",
      "[EPOCH #173, elapsed time: 3040.028[sec]] loss: 3.6222337107909355\n",
      "[EPOCH #174, elapsed time: 3057.485[sec]] loss: 3.564095286946548\n",
      "[EPOCH #175, elapsed time: 3074.710[sec]] loss: 3.5296869811258818\n",
      "[EPOCH #176, elapsed time: 3091.928[sec]] loss: 3.480631062858983\n",
      "[EPOCH #177, elapsed time: 3109.165[sec]] loss: 3.4689279104533948\n",
      "[EPOCH #178, elapsed time: 3126.350[sec]] loss: 3.448130761322222\n",
      "[EPOCH #179, elapsed time: 3143.625[sec]] loss: 3.3734637687080786\n",
      "[EPOCH #180, elapsed time: 3160.877[sec]] loss: 3.3339416572922156\n",
      "[EPOCH #181, elapsed time: 3178.154[sec]] loss: 3.3403564283722327\n",
      "[EPOCH #182, elapsed time: 3195.340[sec]] loss: 3.2603509582971273\n",
      "[EPOCH #183, elapsed time: 3212.586[sec]] loss: 3.2146073360192147\n",
      "[EPOCH #184, elapsed time: 3229.777[sec]] loss: 3.1380975716992427\n",
      "[EPOCH #185, elapsed time: 3247.006[sec]] loss: 3.131546858109926\n",
      "[EPOCH #186, elapsed time: 3264.333[sec]] loss: 3.068994851488816\n",
      "[EPOCH #187, elapsed time: 3281.602[sec]] loss: 3.06711041613629\n",
      "[EPOCH #188, elapsed time: 3298.886[sec]] loss: 3.029649367457942\n",
      "[EPOCH #189, elapsed time: 3316.131[sec]] loss: 2.948768320836519\n",
      "[EPOCH #190, elapsed time: 3333.369[sec]] loss: 2.882453463579479\n",
      "[EPOCH #191, elapsed time: 3350.675[sec]] loss: 2.885441243648529\n",
      "[EPOCH #192, elapsed time: 3368.017[sec]] loss: 2.80172462212412\n",
      "[EPOCH #193, elapsed time: 3385.205[sec]] loss: 2.762686723156979\n",
      "[EPOCH #194, elapsed time: 3402.470[sec]] loss: 2.767967795070849\n",
      "[EPOCH #195, elapsed time: 3419.690[sec]] loss: 2.6623673250800683\n",
      "[EPOCH #196, elapsed time: 3436.883[sec]] loss: 2.645844534823769\n",
      "[EPOCH #197, elapsed time: 3454.045[sec]] loss: 2.617368985163538\n",
      "[EPOCH #198, elapsed time: 3471.185[sec]] loss: 2.6180521343883716\n",
      "[EPOCH #199, elapsed time: 3488.356[sec]] loss: 2.515616431048042\n",
      "[EPOCH #200, elapsed time: 3505.502[sec]] loss: 2.5116666696573557\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'office-home'\n",
    "model.train(dataloader.dataset.trainloader, epochs=epochs, lr=learning_rate, wd=weight_decay, output_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e916e0b",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce133ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = model.predict(dataloader.dataset.trainloader)\n",
    "train_predictions, train_labels = train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1510ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_eval_result = model.evaluate(train_labels, train_predictions)\n",
    "pprint.pprint(train_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5715967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict(dataloader.dataset.testloader)\n",
    "test_predictions, test_labels = test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c25f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eval_result = model.evaluate(test_labels, test_predictions)\n",
    "pprint.pprint(test_eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
