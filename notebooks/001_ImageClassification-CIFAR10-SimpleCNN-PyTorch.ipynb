{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474b637f",
   "metadata": {},
   "source": [
    "# Image Classification Sample\n",
    "\n",
    "|Item|Description|\n",
    "|---|---|\n",
    "|DeepLearning Framework|PyTorch|\n",
    "|Dataset|CIFAR-10|\n",
    "|Model Architecture|Simple CNN|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6dc9d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19c40f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "from data_loader.data_loader import DataLoader\n",
    "from models.pytorch import simple_cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f080cc78",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d245650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fdca85abb50>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120b0797",
   "metadata": {},
   "source": [
    "## Device Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8918ce3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2a9692",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fa0fb52",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 512\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60045952",
   "metadata": {},
   "source": [
    "## Load Dataset and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deef041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resize=(32, 32)\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/tmp/dataset'\n",
    "dataloader = DataLoader(dataset_name='cifar10_pytorch', dataset_dir=dataset_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef213c0a",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9458841",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [512, 10]                 --\n",
      "├─Conv2d: 1-1                            [512, 64, 32, 32]         1,792\n",
      "├─ReLU: 1-2                              [512, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-3                       [512, 64, 32, 32]         128\n",
      "├─Conv2d: 1-4                            [512, 64, 32, 32]         36,928\n",
      "├─ReLU: 1-5                              [512, 64, 32, 32]         --\n",
      "├─BatchNorm2d: 1-6                       [512, 64, 32, 32]         128\n",
      "├─MaxPool2d: 1-7                         [512, 64, 16, 16]         --\n",
      "├─Dropout: 1-8                           [512, 64, 16, 16]         --\n",
      "├─Conv2d: 1-9                            [512, 128, 16, 16]        73,856\n",
      "├─ReLU: 1-10                             [512, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-11                      [512, 128, 16, 16]        256\n",
      "├─Conv2d: 1-12                           [512, 128, 16, 16]        147,584\n",
      "├─ReLU: 1-13                             [512, 128, 16, 16]        --\n",
      "├─BatchNorm2d: 1-14                      [512, 128, 16, 16]        256\n",
      "├─MaxPool2d: 1-15                        [512, 128, 8, 8]          --\n",
      "├─Dropout: 1-16                          [512, 128, 8, 8]          --\n",
      "├─Conv2d: 1-17                           [512, 256, 8, 8]          295,168\n",
      "├─ReLU: 1-18                             [512, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-19                      [512, 256, 8, 8]          512\n",
      "├─Conv2d: 1-20                           [512, 256, 8, 8]          590,080\n",
      "├─ReLU: 1-21                             [512, 256, 8, 8]          --\n",
      "├─BatchNorm2d: 1-22                      [512, 256, 8, 8]          512\n",
      "├─MaxPool2d: 1-23                        [512, 256, 4, 4]          --\n",
      "├─AdaptiveAvgPool2d: 1-24                [512, 256, 2, 2]          --\n",
      "├─Linear: 1-25                           [512, 512]                524,800\n",
      "├─ReLU: 1-26                             [512, 512]                --\n",
      "├─BatchNorm1d: 1-27                      [512, 512]                1,024\n",
      "├─Dropout: 1-28                          [512, 512]                --\n",
      "├─Linear: 1-29                           [512, 128]                65,664\n",
      "├─ReLU: 1-30                             [512, 128]                --\n",
      "├─BatchNorm1d: 1-31                      [512, 128]                256\n",
      "├─Dropout: 1-32                          [512, 128]                --\n",
      "├─Linear: 1-33                           [512, 10]                 1,290\n",
      "├─Softmax: 1-34                          [512, 10]                 --\n",
      "==========================================================================================\n",
      "Total params: 1,740,234\n",
      "Trainable params: 1,740,234\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 78.64\n",
      "==========================================================================================\n",
      "Input size (MB): 6.29\n",
      "Forward/backward pass size (MB): 1884.33\n",
      "Params size (MB): 6.96\n",
      "Estimated Total Size (MB): 1897.58\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "input_size = (batch_size, 3, 32, 32)\n",
    "num_classes = 10\n",
    "model = simple_cnn.SimpleCNN(device, input_size=input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c7f9975-c45f-4e79-86c4-6a45c2b3fc0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH #0] loss: 2.306330711354984\n",
      "[EPOCH #1, elapsed time: 16.581[sec]] loss: 2.034145789274556\n",
      "[EPOCH #2, elapsed time: 26.779[sec]] loss: 1.90959046318679\n",
      "[EPOCH #3, elapsed time: 37.864[sec]] loss: 1.8554306744156324\n",
      "[EPOCH #4, elapsed time: 49.056[sec]] loss: 1.8251735715628128\n",
      "[EPOCH #5, elapsed time: 60.500[sec]] loss: 1.7918429652315946\n",
      "[EPOCH #6, elapsed time: 73.052[sec]] loss: 1.7702950983572219\n",
      "[EPOCH #7, elapsed time: 85.173[sec]] loss: 1.7556345911263962\n",
      "[EPOCH #8, elapsed time: 97.936[sec]] loss: 1.7474098273446297\n",
      "[EPOCH #9, elapsed time: 107.971[sec]] loss: 1.7343185873117037\n",
      "[EPOCH #10, elapsed time: 117.910[sec]] loss: 1.7346616394612855\n",
      "[EPOCH #11, elapsed time: 127.938[sec]] loss: 1.7199460070482524\n",
      "[EPOCH #12, elapsed time: 138.577[sec]] loss: 1.709724036303378\n",
      "[EPOCH #13, elapsed time: 148.482[sec]] loss: 1.7047728338229373\n",
      "[EPOCH #14, elapsed time: 162.373[sec]] loss: 1.6992923675709173\n",
      "[EPOCH #15, elapsed time: 173.988[sec]] loss: 1.6951553701820545\n",
      "[EPOCH #16, elapsed time: 187.749[sec]] loss: 1.6941723751853996\n",
      "[EPOCH #17, elapsed time: 198.441[sec]] loss: 1.6970388772620348\n",
      "[EPOCH #18, elapsed time: 208.562[sec]] loss: 1.686994088893507\n",
      "[EPOCH #19, elapsed time: 219.109[sec]] loss: 1.6780409048706464\n",
      "[EPOCH #20, elapsed time: 233.339[sec]] loss: 1.6735665315401074\n",
      "[EPOCH #21, elapsed time: 243.678[sec]] loss: 1.6725596011790875\n",
      "[EPOCH #22, elapsed time: 254.017[sec]] loss: 1.667962030119722\n",
      "[EPOCH #23, elapsed time: 264.215[sec]] loss: 1.67372236790294\n",
      "[EPOCH #24, elapsed time: 274.548[sec]] loss: 1.66358117491331\n",
      "[EPOCH #25, elapsed time: 284.452[sec]] loss: 1.6527403128581861\n",
      "[EPOCH #26, elapsed time: 294.403[sec]] loss: 1.6546656942794664\n",
      "[EPOCH #27, elapsed time: 305.616[sec]] loss: 1.6518827151275948\n",
      "[EPOCH #28, elapsed time: 315.352[sec]] loss: 1.6503551364783973\n",
      "[EPOCH #29, elapsed time: 325.281[sec]] loss: 1.6454868022249969\n",
      "[EPOCH #30, elapsed time: 336.042[sec]] loss: 1.644526614337416\n",
      "[EPOCH #31, elapsed time: 346.115[sec]] loss: 1.642700177465428\n",
      "[EPOCH #32, elapsed time: 355.991[sec]] loss: 1.641898353818282\n",
      "[EPOCH #33, elapsed time: 367.396[sec]] loss: 1.6409216059070326\n",
      "[EPOCH #34, elapsed time: 377.448[sec]] loss: 1.6365623667845723\n",
      "[EPOCH #35, elapsed time: 388.081[sec]] loss: 1.635595085448511\n",
      "[EPOCH #36, elapsed time: 398.016[sec]] loss: 1.6317082240805745\n",
      "[EPOCH #37, elapsed time: 408.710[sec]] loss: 1.6289410170880327\n",
      "[EPOCH #38, elapsed time: 420.815[sec]] loss: 1.6280263230652665\n",
      "[EPOCH #39, elapsed time: 430.753[sec]] loss: 1.6275554729133406\n",
      "[EPOCH #40, elapsed time: 441.885[sec]] loss: 1.6241436106839855\n",
      "[EPOCH #41, elapsed time: 452.688[sec]] loss: 1.6249266172629935\n",
      "[EPOCH #42, elapsed time: 462.522[sec]] loss: 1.620220670620753\n",
      "[EPOCH #43, elapsed time: 473.281[sec]] loss: 1.6231195796245348\n",
      "[EPOCH #44, elapsed time: 483.657[sec]] loss: 1.6194712214186187\n",
      "[EPOCH #45, elapsed time: 493.628[sec]] loss: 1.6166719652793382\n",
      "[EPOCH #46, elapsed time: 504.312[sec]] loss: 1.616565561874204\n",
      "[EPOCH #47, elapsed time: 514.989[sec]] loss: 1.6162139344352677\n",
      "[EPOCH #48, elapsed time: 528.363[sec]] loss: 1.6115934288204288\n",
      "[EPOCH #49, elapsed time: 538.970[sec]] loss: 1.6088163476682822\n",
      "[EPOCH #50, elapsed time: 549.028[sec]] loss: 1.6089563573390646\n",
      "[EPOCH #51, elapsed time: 560.574[sec]] loss: 1.610499402688088\n",
      "[EPOCH #52, elapsed time: 574.423[sec]] loss: 1.6065291708581966\n",
      "[EPOCH #53, elapsed time: 589.107[sec]] loss: 1.6035942752927217\n",
      "[EPOCH #54, elapsed time: 603.362[sec]] loss: 1.6042282161084185\n",
      "[EPOCH #55, elapsed time: 613.958[sec]] loss: 1.603522303847266\n",
      "[EPOCH #56, elapsed time: 627.976[sec]] loss: 1.6011611828800965\n",
      "[EPOCH #57, elapsed time: 638.327[sec]] loss: 1.6016578855075214\n",
      "[EPOCH #58, elapsed time: 650.271[sec]] loss: 1.5991673760893097\n",
      "[EPOCH #59, elapsed time: 661.084[sec]] loss: 1.5948180132620013\n",
      "[EPOCH #60, elapsed time: 670.894[sec]] loss: 1.5967354629562973\n",
      "[EPOCH #61, elapsed time: 684.601[sec]] loss: 1.5947831483964194\n",
      "[EPOCH #62, elapsed time: 695.755[sec]] loss: 1.5973117086876683\n",
      "[EPOCH #63, elapsed time: 706.346[sec]] loss: 1.593140199942537\n",
      "[EPOCH #64, elapsed time: 716.519[sec]] loss: 1.5933373662346995\n",
      "[EPOCH #65, elapsed time: 729.849[sec]] loss: 1.5901953368635415\n",
      "[EPOCH #66, elapsed time: 739.937[sec]] loss: 1.58939397914701\n",
      "[EPOCH #67, elapsed time: 750.125[sec]] loss: 1.5894348767805924\n",
      "[EPOCH #68, elapsed time: 760.358[sec]] loss: 1.5887209273879526\n",
      "[EPOCH #69, elapsed time: 770.526[sec]] loss: 1.5872531996578723\n",
      "[EPOCH #70, elapsed time: 785.091[sec]] loss: 1.587138140956637\n",
      "[EPOCH #71, elapsed time: 795.144[sec]] loss: 1.5866233413217927\n",
      "[EPOCH #72, elapsed time: 806.712[sec]] loss: 1.583815313727903\n",
      "[EPOCH #73, elapsed time: 818.693[sec]] loss: 1.584328374722335\n",
      "[EPOCH #74, elapsed time: 830.426[sec]] loss: 1.5844087250630823\n",
      "[EPOCH #75, elapsed time: 841.670[sec]] loss: 1.5830582415378789\n",
      "[EPOCH #76, elapsed time: 853.217[sec]] loss: 1.5796171265081649\n",
      "[EPOCH #77, elapsed time: 864.657[sec]] loss: 1.5822051883277721\n",
      "[EPOCH #78, elapsed time: 876.194[sec]] loss: 1.582950726504213\n",
      "[EPOCH #79, elapsed time: 888.913[sec]] loss: 1.5776517225699935\n",
      "[EPOCH #80, elapsed time: 900.126[sec]] loss: 1.5780517378451346\n",
      "[EPOCH #81, elapsed time: 913.323[sec]] loss: 1.5789979383568693\n",
      "[EPOCH #82, elapsed time: 926.778[sec]] loss: 1.5766205101995536\n",
      "[EPOCH #83, elapsed time: 937.404[sec]] loss: 1.5762715424319833\n",
      "[EPOCH #84, elapsed time: 947.974[sec]] loss: 1.5782218366880412\n",
      "[EPOCH #85, elapsed time: 958.569[sec]] loss: 1.5752700183609702\n",
      "[EPOCH #86, elapsed time: 969.336[sec]] loss: 1.5741778413836038\n",
      "[EPOCH #87, elapsed time: 979.919[sec]] loss: 1.5740781934003532\n",
      "[EPOCH #88, elapsed time: 991.568[sec]] loss: 1.5727111293349751\n",
      "[EPOCH #89, elapsed time: 1002.197[sec]] loss: 1.5732153271225424\n",
      "[EPOCH #90, elapsed time: 1015.219[sec]] loss: 1.572111067906146\n",
      "[EPOCH #91, elapsed time: 1026.058[sec]] loss: 1.5718433307060735\n",
      "[EPOCH #92, elapsed time: 1040.464[sec]] loss: 1.5714804516033873\n",
      "[EPOCH #93, elapsed time: 1053.353[sec]] loss: 1.570705070224086\n",
      "[EPOCH #94, elapsed time: 1066.151[sec]] loss: 1.5686954204958368\n",
      "[EPOCH #95, elapsed time: 1078.250[sec]] loss: 1.569040149736313\n",
      "[EPOCH #96, elapsed time: 1090.481[sec]] loss: 1.5689239404328115\n",
      "[EPOCH #97, elapsed time: 1103.456[sec]] loss: 1.5690519226260926\n",
      "[EPOCH #98, elapsed time: 1113.974[sec]] loss: 1.5668956561494316\n",
      "[EPOCH #99, elapsed time: 1125.243[sec]] loss: 1.5674709408846104\n",
      "[EPOCH #100, elapsed time: 1137.014[sec]] loss: 1.568982485083533\n",
      "[EPOCH #101, elapsed time: 1147.324[sec]] loss: 1.5645733746823332\n",
      "[EPOCH #102, elapsed time: 1159.968[sec]] loss: 1.5642488984366067\n",
      "[EPOCH #103, elapsed time: 1172.761[sec]] loss: 1.5630040093255364\n",
      "[EPOCH #104, elapsed time: 1185.277[sec]] loss: 1.5638478602344077\n",
      "[EPOCH #105, elapsed time: 1197.574[sec]] loss: 1.5651553814333368\n",
      "[EPOCH #106, elapsed time: 1210.929[sec]] loss: 1.5660589371288882\n",
      "[EPOCH #107, elapsed time: 1220.951[sec]] loss: 1.5640362854272376\n",
      "[EPOCH #108, elapsed time: 1230.880[sec]] loss: 1.5614147039079087\n",
      "[EPOCH #109, elapsed time: 1240.851[sec]] loss: 1.5634611099100388\n",
      "[EPOCH #110, elapsed time: 1252.402[sec]] loss: 1.564370834514718\n",
      "[EPOCH #111, elapsed time: 1262.586[sec]] loss: 1.563075397690366\n",
      "[EPOCH #112, elapsed time: 1272.504[sec]] loss: 1.5596867959924943\n",
      "[EPOCH #113, elapsed time: 1282.576[sec]] loss: 1.5605189010872722\n",
      "[EPOCH #114, elapsed time: 1292.452[sec]] loss: 1.5628096507439153\n",
      "[EPOCH #115, elapsed time: 1302.277[sec]] loss: 1.5590256563151257\n",
      "[EPOCH #116, elapsed time: 1312.805[sec]] loss: 1.5551082705810753\n",
      "[EPOCH #117, elapsed time: 1322.616[sec]] loss: 1.5594695510577485\n",
      "[EPOCH #118, elapsed time: 1332.407[sec]] loss: 1.5568796852347337\n",
      "[EPOCH #119, elapsed time: 1342.481[sec]] loss: 1.5549650382171893\n",
      "[EPOCH #120, elapsed time: 1352.403[sec]] loss: 1.557055802888315\n",
      "[EPOCH #121, elapsed time: 1362.302[sec]] loss: 1.5551494798519943\n",
      "[EPOCH #122, elapsed time: 1372.139[sec]] loss: 1.5571032011272505\n",
      "[EPOCH #123, elapsed time: 1382.031[sec]] loss: 1.5563938972359654\n",
      "[EPOCH #124, elapsed time: 1392.052[sec]] loss: 1.5541668780248132\n",
      "[EPOCH #125, elapsed time: 1402.841[sec]] loss: 1.5552330500638722\n",
      "[EPOCH #126, elapsed time: 1413.388[sec]] loss: 1.5539239743391977\n",
      "[EPOCH #127, elapsed time: 1423.877[sec]] loss: 1.5538914210508057\n",
      "[EPOCH #128, elapsed time: 1434.432[sec]] loss: 1.5558661368132705\n",
      "[EPOCH #129, elapsed time: 1445.207[sec]] loss: 1.5623950108609288\n",
      "[EPOCH #130, elapsed time: 1458.847[sec]] loss: 1.5549080354314695\n",
      "[EPOCH #131, elapsed time: 1469.551[sec]] loss: 1.554450957727829\n",
      "[EPOCH #132, elapsed time: 1480.035[sec]] loss: 1.5537140528055924\n",
      "[EPOCH #133, elapsed time: 1490.446[sec]] loss: 1.5512577759784838\n",
      "[EPOCH #134, elapsed time: 1501.778[sec]] loss: 1.553041379495988\n",
      "[EPOCH #135, elapsed time: 1511.704[sec]] loss: 1.554969055943968\n",
      "[EPOCH #136, elapsed time: 1521.993[sec]] loss: 1.5531557596271341\n",
      "[EPOCH #137, elapsed time: 1532.612[sec]] loss: 1.5534599215574014\n",
      "[EPOCH #138, elapsed time: 1542.615[sec]] loss: 1.554114561925999\n",
      "[EPOCH #139, elapsed time: 1552.764[sec]] loss: 1.556037891772948\n",
      "[EPOCH #140, elapsed time: 1563.367[sec]] loss: 1.5519721917593547\n",
      "[EPOCH #141, elapsed time: 1573.273[sec]] loss: 1.551255138577823\n",
      "[EPOCH #142, elapsed time: 1583.437[sec]] loss: 1.549234479799228\n",
      "[EPOCH #143, elapsed time: 1593.521[sec]] loss: 1.5537124086631389\n",
      "[EPOCH #144, elapsed time: 1604.241[sec]] loss: 1.550879716873169\n",
      "[EPOCH #145, elapsed time: 1616.365[sec]] loss: 1.5531266743909526\n",
      "[EPOCH #146, elapsed time: 1626.318[sec]] loss: 1.5504287944264086\n",
      "[EPOCH #147, elapsed time: 1636.869[sec]] loss: 1.5493724147860086\n",
      "[EPOCH #148, elapsed time: 1646.923[sec]] loss: 1.5600100194347721\n",
      "[EPOCH #149, elapsed time: 1659.265[sec]] loss: 1.5540466423760755\n",
      "[EPOCH #150, elapsed time: 1669.936[sec]] loss: 1.5461375843006606\n",
      "[EPOCH #151, elapsed time: 1680.678[sec]] loss: 1.5497754593347024\n",
      "[EPOCH #152, elapsed time: 1691.400[sec]] loss: 1.5478870926647712\n",
      "[EPOCH #153, elapsed time: 1701.919[sec]] loss: 1.5472836428853998\n",
      "[EPOCH #154, elapsed time: 1712.600[sec]] loss: 1.5501632977203155\n",
      "[EPOCH #155, elapsed time: 1723.079[sec]] loss: 1.5472271356991447\n",
      "[EPOCH #156, elapsed time: 1735.149[sec]] loss: 1.5476335702000408\n",
      "[EPOCH #157, elapsed time: 1748.791[sec]] loss: 1.5465162776634622\n",
      "[EPOCH #158, elapsed time: 1762.758[sec]] loss: 1.5442540740173594\n",
      "[EPOCH #159, elapsed time: 1775.322[sec]] loss: 1.5470299327976034\n",
      "[EPOCH #160, elapsed time: 1786.034[sec]] loss: 1.5465916904667898\n",
      "[EPOCH #161, elapsed time: 1799.286[sec]] loss: 1.546967431512004\n",
      "[EPOCH #162, elapsed time: 1812.887[sec]] loss: 1.5447516114148891\n",
      "[EPOCH #163, elapsed time: 1826.953[sec]] loss: 1.5460580633148808\n",
      "[EPOCH #164, elapsed time: 1839.398[sec]] loss: 1.5462920792348402\n",
      "[EPOCH #165, elapsed time: 1853.718[sec]] loss: 1.5444156355531415\n",
      "[EPOCH #166, elapsed time: 1868.039[sec]] loss: 1.5455358099342535\n",
      "[EPOCH #167, elapsed time: 1878.821[sec]] loss: 1.544728742146141\n",
      "[EPOCH #168, elapsed time: 1889.551[sec]] loss: 1.542442164890902\n",
      "[EPOCH #169, elapsed time: 1899.416[sec]] loss: 1.5428023582380397\n",
      "[EPOCH #170, elapsed time: 1909.338[sec]] loss: 1.5443399543573058\n",
      "[EPOCH #171, elapsed time: 1919.271[sec]] loss: 1.5431868241371745\n",
      "[EPOCH #172, elapsed time: 1929.262[sec]] loss: 1.5416988218280647\n",
      "[EPOCH #173, elapsed time: 1939.222[sec]] loss: 1.542137349635763\n",
      "[EPOCH #174, elapsed time: 1949.929[sec]] loss: 1.5402755034099538\n",
      "[EPOCH #175, elapsed time: 1960.589[sec]] loss: 1.5419036014218859\n",
      "[EPOCH #176, elapsed time: 1970.558[sec]] loss: 1.542312045167519\n",
      "[EPOCH #177, elapsed time: 1980.536[sec]] loss: 1.5398444417799733\n",
      "[EPOCH #178, elapsed time: 1994.278[sec]] loss: 1.5411184282540817\n",
      "[EPOCH #179, elapsed time: 2006.916[sec]] loss: 1.5404436068129097\n",
      "[EPOCH #180, elapsed time: 2019.954[sec]] loss: 1.5414471085530705\n",
      "[EPOCH #181, elapsed time: 2029.810[sec]] loss: 1.540822681142059\n",
      "[EPOCH #182, elapsed time: 2041.335[sec]] loss: 1.5396214700706174\n",
      "[EPOCH #183, elapsed time: 2052.614[sec]] loss: 1.5433015228461853\n",
      "[EPOCH #184, elapsed time: 2065.359[sec]] loss: 1.5400040885689772\n",
      "[EPOCH #185, elapsed time: 2075.203[sec]] loss: 1.539319495627\n",
      "[EPOCH #186, elapsed time: 2085.140[sec]] loss: 1.5417843516332097\n",
      "[EPOCH #187, elapsed time: 2095.056[sec]] loss: 1.5385211562774765\n",
      "[EPOCH #188, elapsed time: 2105.715[sec]] loss: 1.5369194162555482\n",
      "[EPOCH #189, elapsed time: 2115.778[sec]] loss: 1.539331274084456\n",
      "[EPOCH #190, elapsed time: 2129.082[sec]] loss: 1.5392300202460603\n",
      "[EPOCH #191, elapsed time: 2139.015[sec]] loss: 1.5383334543486855\n",
      "[EPOCH #192, elapsed time: 2149.143[sec]] loss: 1.540159827611878\n",
      "[EPOCH #193, elapsed time: 2159.130[sec]] loss: 1.5395382718252815\n",
      "[EPOCH #194, elapsed time: 2168.984[sec]] loss: 1.5378544068992406\n",
      "[EPOCH #195, elapsed time: 2179.009[sec]] loss: 1.539320598637074\n",
      "[EPOCH #196, elapsed time: 2189.123[sec]] loss: 1.5382539689045112\n",
      "[EPOCH #197, elapsed time: 2199.131[sec]] loss: 1.5383172752150953\n",
      "[EPOCH #198, elapsed time: 2213.199[sec]] loss: 1.536143098133768\n",
      "[EPOCH #199, elapsed time: 2223.910[sec]] loss: 1.537517951454631\n",
      "[EPOCH #200, elapsed time: 2234.622[sec]] loss: 1.5365084109211762\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'cifar-10_model'\n",
    "model.train(dataloader.dataset.trainloader, epochs=epochs, lr=learning_rate, wd=weight_decay, output_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e916e0b",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ce133ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = model.predict(dataloader.dataset.trainloader)\n",
    "train_predictions, train_labels = train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1510ab2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.92924,\n",
      " 'classification_report': {'0': {'f1-score': 0.9296950864245483,\n",
      "                                 'precision': 0.9035485088712721,\n",
      "                                 'recall': 0.9574,\n",
      "                                 'support': 5000},\n",
      "                           '1': {'f1-score': 0.9646894068220466,\n",
      "                                 'precision': 0.9649789873924355,\n",
      "                                 'recall': 0.9644,\n",
      "                                 'support': 5000},\n",
      "                           '2': {'f1-score': 0.9082596769277661,\n",
      "                                 'precision': 0.9229816229609746,\n",
      "                                 'recall': 0.894,\n",
      "                                 'support': 5000},\n",
      "                           '3': {'f1-score': 0.8807447329740324,\n",
      "                                 'precision': 0.8634005763688761,\n",
      "                                 'recall': 0.8988,\n",
      "                                 'support': 5000},\n",
      "                           '4': {'f1-score': 0.9144028703229113,\n",
      "                                 'precision': 0.9379600420609885,\n",
      "                                 'recall': 0.892,\n",
      "                                 'support': 5000},\n",
      "                           '5': {'f1-score': 0.8975649023948481,\n",
      "                                 'precision': 0.903199675982179,\n",
      "                                 'recall': 0.892,\n",
      "                                 'support': 5000},\n",
      "                           '6': {'f1-score': 0.9395088840087843,\n",
      "                                 'precision': 0.9378238341968912,\n",
      "                                 'recall': 0.9412,\n",
      "                                 'support': 5000},\n",
      "                           '7': {'f1-score': 0.9423019431988042,\n",
      "                                 'precision': 0.9390268123138034,\n",
      "                                 'recall': 0.9456,\n",
      "                                 'support': 5000},\n",
      "                           '8': {'f1-score': 0.9614494212380473,\n",
      "                                 'precision': 0.9677811550151976,\n",
      "                                 'recall': 0.9552,\n",
      "                                 'support': 5000},\n",
      "                           '9': {'f1-score': 0.9540898155573376,\n",
      "                                 'precision': 0.9563906752411575,\n",
      "                                 'recall': 0.9518,\n",
      "                                 'support': 5000},\n",
      "                           'accuracy': 0.92924,\n",
      "                           'macro avg': {'f1-score': 0.9292706739869125,\n",
      "                                         'precision': 0.9297091890403776,\n",
      "                                         'recall': 0.9292400000000001,\n",
      "                                         'support': 50000},\n",
      "                           'weighted avg': {'f1-score': 0.9292706739869128,\n",
      "                                            'precision': 0.9297091890403777,\n",
      "                                            'recall': 0.92924,\n",
      "                                            'support': 50000}}}\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = model.evaluate(train_labels, train_predictions)\n",
    "pprint.pprint(train_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5715967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict(dataloader.dataset.testloader)\n",
    "test_predictions, test_labels = test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5c25f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.8117,\n",
      " 'classification_report': {'0': {'f1-score': 0.8277511961722489,\n",
      "                                 'precision': 0.7935779816513762,\n",
      "                                 'recall': 0.865,\n",
      "                                 'support': 1000},\n",
      "                           '1': {'f1-score': 0.8970661362506216,\n",
      "                                 'precision': 0.8921859545004945,\n",
      "                                 'recall': 0.902,\n",
      "                                 'support': 1000},\n",
      "                           '2': {'f1-score': 0.7265264238070804,\n",
      "                                 'precision': 0.7460484720758693,\n",
      "                                 'recall': 0.708,\n",
      "                                 'support': 1000},\n",
      "                           '3': {'f1-score': 0.6750250752256771,\n",
      "                                 'precision': 0.6770623742454729,\n",
      "                                 'recall': 0.673,\n",
      "                                 'support': 1000},\n",
      "                           '4': {'f1-score': 0.7886597938144329,\n",
      "                                 'precision': 0.8138297872340425,\n",
      "                                 'recall': 0.765,\n",
      "                                 'support': 1000},\n",
      "                           '5': {'f1-score': 0.7290836653386455,\n",
      "                                 'precision': 0.7261904761904762,\n",
      "                                 'recall': 0.732,\n",
      "                                 'support': 1000},\n",
      "                           '6': {'f1-score': 0.85546875,\n",
      "                                 'precision': 0.8358778625954199,\n",
      "                                 'recall': 0.876,\n",
      "                                 'support': 1000},\n",
      "                           '7': {'f1-score': 0.8551587301587302,\n",
      "                                 'precision': 0.8484251968503937,\n",
      "                                 'recall': 0.862,\n",
      "                                 'support': 1000},\n",
      "                           '8': {'f1-score': 0.8778004073319756,\n",
      "                                 'precision': 0.8941908713692946,\n",
      "                                 'recall': 0.862,\n",
      "                                 'support': 1000},\n",
      "                           '9': {'f1-score': 0.8808080808080808,\n",
      "                                 'precision': 0.889795918367347,\n",
      "                                 'recall': 0.872,\n",
      "                                 'support': 1000},\n",
      "                           'accuracy': 0.8117,\n",
      "                           'macro avg': {'f1-score': 0.8113348258907493,\n",
      "                                         'precision': 0.8117184895080186,\n",
      "                                         'recall': 0.8116999999999999,\n",
      "                                         'support': 10000},\n",
      "                           'weighted avg': {'f1-score': 0.8113348258907493,\n",
      "                                            'precision': 0.8117184895080187,\n",
      "                                            'recall': 0.8117,\n",
      "                                            'support': 10000}}}\n"
     ]
    }
   ],
   "source": [
    "test_eval_result = model.evaluate(test_labels, test_predictions)\n",
    "pprint.pprint(test_eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
