{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7bfcf5ad-531c-4505-9fb2-48db18b4568e",
   "metadata": {},
   "source": [
    "# Sample code of Image Classification VGG16 Model with PyTorch\n",
    "\n",
    "This notebook is the sample code of training the image classification model using COCO2014 dataset.  \n",
    "COCO2014 dataset has not classification labels, therefore it makes classification dataset cropping bounding boxes.\n",
    "\n",
    "|Item|Description|\n",
    "|---|---|\n",
    "|DeepLearning Framework|PyTorch|\n",
    "|Dataset|COCO2014 Classification|\n",
    "|Model Architecture|VGG16|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea2f3e25-58a2-4dae-9166-a85f649bde47",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d563f93f-798e-4334-8094-334e84c69097",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#import cv2\n",
    "#import json\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "#from PIL import Image\n",
    "#from data_loader.data_loader import DataLoader\n",
    "#from models.pytorch import vgg16\n",
    "import itertools\n",
    "#\n",
    "#import torch\n",
    "#from torch.utils.data import Dataset\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import pprint\n",
    "\n",
    "from data_loader.data_loader import DataLoader\n",
    "from models.pytorch import vgg16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da0d189-4ff4-4619-b8e4-91151436612c",
   "metadata": {},
   "source": [
    "## Set Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6f272e2-e60d-4bf3-aff9-a255ce7e68f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f31bb339b90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed=42\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53721ad-cdf2-4570-a63d-34eca78d01bf",
   "metadata": {},
   "source": [
    "## Device Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d22f5cd-18ef-4a30-9d92-ce0c0afffd66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ca638a-c879-4044-bd94-4181db50a2d2",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfee9194-b6b7-438e-a967-eb25c0f544fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "batch_size = 32\n",
    "learning_rate = 0.0005\n",
    "weight_decay = 0.001\n",
    "input_tensor_shape = (3, 224, 224)   # CHW"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06247d29-f8d4-4ab5-83bf-830195df2ef8",
   "metadata": {},
   "source": [
    "## Preparing Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ac110b-b5d8-4dbd-b982-49b82ee743c6",
   "metadata": {},
   "source": [
    "### Download and Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f86cf2bd-366a-4e94-8835-4a01ed16deee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dir = '/tmp/dataset'\n",
    "os.makedirs(dataset_dir, exist_ok=True)\n",
    "dataloader = DataLoader(dataset_name='coco2014_classification_pytorch', resize=input_tensor_shape[1:], dataset_dir=dataset_dir, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52d834f0-a039-4ae1-b7db-de5b04812f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotations\t\t      train2014.zip\t val2014      val2014_clf.csv\n",
      "annotations_trainval2014.zip  train2014_clf\t val2014.zip\n",
      "train2014\t\t      train2014_clf.csv  val2014_clf\n"
     ]
    }
   ],
   "source": [
    "!ls {dataset_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2b3fa3a-64fa-4d11-81a0-7a5822b2d430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['person',\n",
       " 'bicycle',\n",
       " 'car',\n",
       " 'motorcycle',\n",
       " 'airplane',\n",
       " 'bus',\n",
       " 'train',\n",
       " 'truck',\n",
       " 'boat',\n",
       " 'traffic light',\n",
       " 'fire hydrant',\n",
       " 'stop sign',\n",
       " 'parking meter',\n",
       " 'bench',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'dog',\n",
       " 'horse',\n",
       " 'sheep',\n",
       " 'cow',\n",
       " 'elephant',\n",
       " 'bear',\n",
       " 'zebra',\n",
       " 'giraffe',\n",
       " 'backpack',\n",
       " 'umbrella',\n",
       " 'handbag',\n",
       " 'tie',\n",
       " 'suitcase',\n",
       " 'frisbee',\n",
       " 'skis',\n",
       " 'snowboard',\n",
       " 'sports ball',\n",
       " 'kite',\n",
       " 'baseball bat',\n",
       " 'baseball glove',\n",
       " 'skateboard',\n",
       " 'surfboard',\n",
       " 'tennis racket',\n",
       " 'bottle',\n",
       " 'wine glass',\n",
       " 'cup',\n",
       " 'fork',\n",
       " 'knife',\n",
       " 'spoon',\n",
       " 'bowl',\n",
       " 'banana',\n",
       " 'apple',\n",
       " 'sandwich',\n",
       " 'orange',\n",
       " 'broccoli',\n",
       " 'carrot',\n",
       " 'hot dog',\n",
       " 'pizza',\n",
       " 'donut',\n",
       " 'cake',\n",
       " 'chair',\n",
       " 'couch',\n",
       " 'potted plant',\n",
       " 'bed',\n",
       " 'dining table',\n",
       " 'toilet',\n",
       " 'tv',\n",
       " 'laptop',\n",
       " 'mouse',\n",
       " 'remote',\n",
       " 'keyboard',\n",
       " 'cell phone',\n",
       " 'microwave',\n",
       " 'oven',\n",
       " 'toaster',\n",
       " 'sink',\n",
       " 'refrigerator',\n",
       " 'book',\n",
       " 'clock',\n",
       " 'vase',\n",
       " 'scissors',\n",
       " 'teddy bear',\n",
       " 'hair drier',\n",
       " 'toothbrush']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.dataset.class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aa766c6-60fb-437b-9647-119d398e2491",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = dataloader.dataset.trainloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "17e44063-dcd7-473c-a029-2e514d149c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 2500/2500 [09:19<00:00,  4.47it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[70,\n",
       " 73,\n",
       " 70,\n",
       " 33,\n",
       " 79,\n",
       " 4,\n",
       " 10,\n",
       " 73,\n",
       " 72,\n",
       " 62,\n",
       " 2,\n",
       " 63,\n",
       " 74,\n",
       " 31,\n",
       " 64,\n",
       " 73,\n",
       " 88,\n",
       " 27,\n",
       " 37,\n",
       " 7,\n",
       " 51,\n",
       " 11,\n",
       " 75,\n",
       " 28,\n",
       " 42,\n",
       " 36,\n",
       " 18,\n",
       " 23,\n",
       " 63,\n",
       " 89,\n",
       " 78,\n",
       " 85,\n",
       " 32,\n",
       " 72,\n",
       " 28,\n",
       " 23,\n",
       " 56,\n",
       " 18,\n",
       " 61,\n",
       " 70,\n",
       " 88,\n",
       " 62,\n",
       " 9,\n",
       " 85,\n",
       " 87,\n",
       " 33,\n",
       " 2,\n",
       " 78,\n",
       " 24,\n",
       " 40,\n",
       " 17,\n",
       " 49,\n",
       " 15,\n",
       " 1,\n",
       " 81,\n",
       " 1,\n",
       " 13,\n",
       " 73,\n",
       " 61,\n",
       " 62,\n",
       " 74,\n",
       " 28,\n",
       " 39,\n",
       " 51,\n",
       " 25,\n",
       " 31,\n",
       " 27,\n",
       " 81,\n",
       " 58,\n",
       " 36,\n",
       " 86,\n",
       " 86,\n",
       " 76,\n",
       " 60,\n",
       " 42,\n",
       " 62,\n",
       " 46,\n",
       " 79,\n",
       " 49,\n",
       " 53,\n",
       " 4,\n",
       " 7,\n",
       " 81,\n",
       " 61,\n",
       " 1,\n",
       " 70,\n",
       " 47,\n",
       " 21,\n",
       " 73,\n",
       " 41,\n",
       " 28,\n",
       " 79,\n",
       " 46,\n",
       " 24,\n",
       " 89,\n",
       " 77,\n",
       " 90,\n",
       " 60,\n",
       " 89,\n",
       " 46,\n",
       " 74,\n",
       " 11,\n",
       " 76,\n",
       " 55,\n",
       " 34,\n",
       " 56,\n",
       " 89,\n",
       " 88,\n",
       " 42,\n",
       " 65,\n",
       " 48,\n",
       " 2,\n",
       " 36,\n",
       " 52,\n",
       " 58,\n",
       " 90,\n",
       " 42,\n",
       " 19,\n",
       " 76,\n",
       " 76,\n",
       " 75,\n",
       " 53,\n",
       " 33,\n",
       " 19,\n",
       " 31,\n",
       " 7,\n",
       " 88,\n",
       " 50,\n",
       " 63,\n",
       " 50,\n",
       " 56,\n",
       " 23,\n",
       " 87,\n",
       " 62,\n",
       " 46,\n",
       " 44,\n",
       " 10,\n",
       " 22,\n",
       " 15,\n",
       " 63,\n",
       " 39,\n",
       " 23,\n",
       " 73,\n",
       " 90,\n",
       " 11,\n",
       " 31,\n",
       " 88,\n",
       " 76,\n",
       " 80,\n",
       " 38,\n",
       " 51,\n",
       " 47,\n",
       " 8,\n",
       " 17,\n",
       " 43,\n",
       " 74,\n",
       " 82,\n",
       " 82,\n",
       " 77,\n",
       " 46,\n",
       " 19,\n",
       " 14,\n",
       " 4,\n",
       " 42,\n",
       " 85,\n",
       " 74,\n",
       " 61,\n",
       " 88,\n",
       " 1,\n",
       " 42,\n",
       " 70,\n",
       " 74,\n",
       " 40,\n",
       " 81,\n",
       " 61,\n",
       " 73,\n",
       " 48,\n",
       " 85,\n",
       " 37,\n",
       " 19,\n",
       " 64,\n",
       " 5,\n",
       " 77,\n",
       " 31,\n",
       " 60,\n",
       " 52,\n",
       " 42,\n",
       " 24,\n",
       " 1,\n",
       " 17,\n",
       " 1,\n",
       " 37,\n",
       " 57,\n",
       " 57,\n",
       " 11,\n",
       " 5,\n",
       " 47,\n",
       " 21,\n",
       " 24,\n",
       " 61,\n",
       " 80,\n",
       " 2,\n",
       " 41,\n",
       " 56,\n",
       " 80,\n",
       " 28,\n",
       " 28,\n",
       " 86,\n",
       " 44,\n",
       " 49,\n",
       " 51,\n",
       " 17,\n",
       " 17,\n",
       " 86,\n",
       " 86,\n",
       " 15,\n",
       " 87,\n",
       " 17,\n",
       " 27,\n",
       " 56,\n",
       " 33,\n",
       " 17,\n",
       " 8,\n",
       " 50,\n",
       " 25,\n",
       " 11,\n",
       " 88,\n",
       " 36,\n",
       " 64,\n",
       " 25,\n",
       " 4,\n",
       " 27,\n",
       " 36,\n",
       " 49,\n",
       " 33,\n",
       " 17,\n",
       " 6,\n",
       " 40,\n",
       " 51,\n",
       " 56,\n",
       " 35,\n",
       " 75,\n",
       " 11,\n",
       " 35,\n",
       " 42,\n",
       " 1,\n",
       " 21,\n",
       " 79,\n",
       " 14,\n",
       " 75,\n",
       " 63,\n",
       " 85,\n",
       " 34,\n",
       " 39,\n",
       " 49,\n",
       " 61,\n",
       " 23,\n",
       " 86,\n",
       " 88,\n",
       " 64,\n",
       " 54,\n",
       " 72,\n",
       " 76,\n",
       " 82,\n",
       " 38,\n",
       " 73,\n",
       " 64,\n",
       " 74,\n",
       " 59,\n",
       " 41,\n",
       " 82,\n",
       " 33,\n",
       " 74,\n",
       " 63,\n",
       " 67,\n",
       " 41,\n",
       " 14,\n",
       " 9,\n",
       " 82,\n",
       " 81,\n",
       " 51,\n",
       " 70,\n",
       " 48,\n",
       " 22,\n",
       " 41,\n",
       " 6,\n",
       " 60,\n",
       " 58,\n",
       " 3,\n",
       " 38,\n",
       " 44,\n",
       " 52,\n",
       " 35,\n",
       " 43,\n",
       " 16,\n",
       " 57,\n",
       " 41,\n",
       " 51,\n",
       " 72,\n",
       " 90,\n",
       " 51,\n",
       " 7,\n",
       " 6,\n",
       " 6,\n",
       " 9,\n",
       " 64,\n",
       " 52,\n",
       " 51,\n",
       " 35,\n",
       " 14,\n",
       " 52,\n",
       " 31,\n",
       " 43,\n",
       " 13,\n",
       " 37,\n",
       " 43,\n",
       " 20,\n",
       " 27,\n",
       " 89,\n",
       " 32,\n",
       " 81,\n",
       " 22,\n",
       " 70,\n",
       " 80,\n",
       " 31,\n",
       " 76,\n",
       " 28,\n",
       " 40,\n",
       " 74,\n",
       " 7,\n",
       " 88,\n",
       " 79,\n",
       " 9,\n",
       " 65,\n",
       " 11,\n",
       " 47,\n",
       " 58,\n",
       " 47,\n",
       " 54,\n",
       " 16,\n",
       " 22,\n",
       " 34,\n",
       " 87,\n",
       " 24,\n",
       " 90,\n",
       " 49,\n",
       " 20,\n",
       " 54,\n",
       " 74,\n",
       " 58,\n",
       " 9,\n",
       " 19,\n",
       " 41,\n",
       " 54,\n",
       " 46,\n",
       " 33,\n",
       " 72,\n",
       " 64,\n",
       " 7,\n",
       " 75,\n",
       " 43,\n",
       " 10,\n",
       " 84,\n",
       " 25,\n",
       " 23,\n",
       " 18,\n",
       " 2,\n",
       " 32,\n",
       " 11,\n",
       " 8,\n",
       " 6,\n",
       " 33,\n",
       " 3,\n",
       " 58,\n",
       " 22,\n",
       " 72,\n",
       " 90,\n",
       " 8,\n",
       " 52,\n",
       " 7,\n",
       " 63,\n",
       " 65,\n",
       " 38,\n",
       " 80,\n",
       " 15,\n",
       " 24,\n",
       " 62,\n",
       " 18,\n",
       " 8,\n",
       " 87,\n",
       " 80,\n",
       " 61,\n",
       " 62,\n",
       " 86,\n",
       " 65,\n",
       " 75,\n",
       " 50,\n",
       " 49,\n",
       " 11,\n",
       " 67,\n",
       " 81,\n",
       " 34,\n",
       " 16,\n",
       " 84,\n",
       " 15,\n",
       " 34,\n",
       " 4,\n",
       " 77,\n",
       " 17,\n",
       " 76,\n",
       " 65,\n",
       " 15,\n",
       " 48,\n",
       " 34,\n",
       " 9,\n",
       " 58,\n",
       " 44,\n",
       " 76,\n",
       " 82,\n",
       " 8,\n",
       " 25,\n",
       " 63,\n",
       " 80,\n",
       " 59,\n",
       " 28,\n",
       " 17,\n",
       " 51,\n",
       " 49,\n",
       " 39,\n",
       " 33,\n",
       " 41,\n",
       " 6,\n",
       " 33,\n",
       " 27,\n",
       " 42,\n",
       " 28,\n",
       " 64,\n",
       " 77,\n",
       " 27,\n",
       " 67,\n",
       " 75,\n",
       " 64,\n",
       " 4,\n",
       " 7,\n",
       " 62,\n",
       " 62,\n",
       " 46,\n",
       " 37,\n",
       " 41,\n",
       " 63,\n",
       " 7,\n",
       " 36,\n",
       " 28,\n",
       " 2,\n",
       " 31,\n",
       " 36,\n",
       " 84,\n",
       " 65,\n",
       " 6,\n",
       " 21,\n",
       " 50,\n",
       " 53,\n",
       " 61,\n",
       " 21,\n",
       " 33,\n",
       " 48,\n",
       " 56,\n",
       " 1,\n",
       " 33,\n",
       " 41,\n",
       " 28,\n",
       " 82,\n",
       " 75,\n",
       " 7,\n",
       " 9,\n",
       " 86,\n",
       " 15,\n",
       " 13,\n",
       " 61,\n",
       " 28,\n",
       " 22,\n",
       " 87,\n",
       " 24,\n",
       " 14,\n",
       " 54,\n",
       " 3,\n",
       " 27,\n",
       " 20,\n",
       " 15,\n",
       " 56,\n",
       " 46,\n",
       " 38,\n",
       " 22,\n",
       " 49,\n",
       " 60,\n",
       " 20,\n",
       " 11,\n",
       " 64,\n",
       " 78,\n",
       " 20,\n",
       " 75,\n",
       " 52,\n",
       " 57,\n",
       " 41,\n",
       " 33,\n",
       " 89,\n",
       " 36,\n",
       " 22,\n",
       " 87,\n",
       " 35,\n",
       " 31,\n",
       " 3,\n",
       " 8,\n",
       " 17,\n",
       " 7,\n",
       " 28,\n",
       " 2,\n",
       " 27,\n",
       " 32,\n",
       " 78,\n",
       " 56,\n",
       " 35,\n",
       " 55,\n",
       " 15,\n",
       " 33,\n",
       " 78,\n",
       " 52,\n",
       " 2,\n",
       " 80,\n",
       " 38,\n",
       " 75,\n",
       " 79,\n",
       " 9,\n",
       " 33,\n",
       " 67,\n",
       " 52,\n",
       " 50,\n",
       " 14,\n",
       " 28,\n",
       " 28,\n",
       " 48,\n",
       " 85,\n",
       " 37,\n",
       " 50,\n",
       " 6,\n",
       " 58,\n",
       " 3,\n",
       " 44,\n",
       " 16,\n",
       " 34,\n",
       " 67,\n",
       " 3,\n",
       " 65,\n",
       " 86,\n",
       " 52,\n",
       " 86,\n",
       " 74,\n",
       " 75,\n",
       " 7,\n",
       " 27,\n",
       " 64,\n",
       " 87,\n",
       " 14,\n",
       " 87,\n",
       " 86,\n",
       " 22,\n",
       " 62,\n",
       " 25,\n",
       " 54,\n",
       " 40,\n",
       " 14,\n",
       " 38,\n",
       " 34,\n",
       " 80,\n",
       " 88,\n",
       " 5,\n",
       " 78,\n",
       " 42,\n",
       " 47,\n",
       " 17,\n",
       " 62,\n",
       " 21,\n",
       " 42,\n",
       " 89,\n",
       " 25,\n",
       " 52,\n",
       " 2,\n",
       " 14,\n",
       " 47,\n",
       " 53,\n",
       " 6,\n",
       " 6,\n",
       " 18,\n",
       " 39,\n",
       " 60,\n",
       " 50,\n",
       " 42,\n",
       " 87,\n",
       " 52,\n",
       " 53,\n",
       " 34,\n",
       " 52,\n",
       " 52,\n",
       " 47,\n",
       " 2,\n",
       " 25,\n",
       " 48,\n",
       " 36,\n",
       " 84,\n",
       " 67,\n",
       " 8,\n",
       " 43,\n",
       " 63,\n",
       " 20,\n",
       " 65,\n",
       " 80,\n",
       " 53,\n",
       " 57,\n",
       " 46,\n",
       " 21,\n",
       " 8,\n",
       " 64,\n",
       " 78,\n",
       " 8,\n",
       " 34,\n",
       " 18,\n",
       " 33,\n",
       " 80,\n",
       " 6,\n",
       " 27,\n",
       " 49,\n",
       " 11,\n",
       " 51,\n",
       " 37,\n",
       " 57,\n",
       " 82,\n",
       " 5,\n",
       " 20,\n",
       " 46,\n",
       " 84,\n",
       " 10,\n",
       " 72,\n",
       " 62,\n",
       " 72,\n",
       " 78,\n",
       " 46,\n",
       " 24,\n",
       " 11,\n",
       " 57,\n",
       " 37,\n",
       " 14,\n",
       " 90,\n",
       " 58,\n",
       " 5,\n",
       " 48,\n",
       " 51,\n",
       " 53,\n",
       " 54,\n",
       " 86,\n",
       " 64,\n",
       " 15,\n",
       " 73,\n",
       " 73,\n",
       " 76,\n",
       " 28,\n",
       " 10,\n",
       " 77,\n",
       " 89,\n",
       " 11,\n",
       " 2,\n",
       " 22,\n",
       " 59,\n",
       " 53,\n",
       " 77,\n",
       " 75,\n",
       " 9,\n",
       " 9,\n",
       " 82,\n",
       " 60,\n",
       " 3,\n",
       " 27,\n",
       " 82,\n",
       " 61,\n",
       " 10,\n",
       " 63,\n",
       " 56,\n",
       " 6,\n",
       " 53,\n",
       " 51,\n",
       " 57,\n",
       " 76,\n",
       " 25,\n",
       " 44,\n",
       " 24,\n",
       " 74,\n",
       " 34,\n",
       " 81,\n",
       " 74,\n",
       " 87,\n",
       " 89,\n",
       " 72,\n",
       " 75,\n",
       " 51,\n",
       " 27,\n",
       " 43,\n",
       " 22,\n",
       " 22,\n",
       " 14,\n",
       " 20,\n",
       " 31,\n",
       " 21,\n",
       " 21,\n",
       " 51,\n",
       " 2,\n",
       " 56,\n",
       " 81,\n",
       " 86,\n",
       " 8,\n",
       " 48,\n",
       " 82,\n",
       " 57,\n",
       " 77,\n",
       " 65,\n",
       " 80,\n",
       " 49,\n",
       " 44,\n",
       " 4,\n",
       " 78,\n",
       " 72,\n",
       " 17,\n",
       " 43,\n",
       " 47,\n",
       " 72,\n",
       " 6,\n",
       " 14,\n",
       " 17,\n",
       " 46,\n",
       " 77,\n",
       " 14,\n",
       " 59,\n",
       " 78,\n",
       " 7,\n",
       " 24,\n",
       " 70,\n",
       " 74,\n",
       " 34,\n",
       " 81,\n",
       " 36,\n",
       " 8,\n",
       " 4,\n",
       " 13,\n",
       " 13,\n",
       " 53,\n",
       " 80,\n",
       " 63,\n",
       " 11,\n",
       " 56,\n",
       " 57,\n",
       " 81,\n",
       " 50,\n",
       " 87,\n",
       " 85,\n",
       " 80,\n",
       " 34,\n",
       " 51,\n",
       " 8,\n",
       " 40,\n",
       " 59,\n",
       " 8,\n",
       " 87,\n",
       " 54,\n",
       " 1,\n",
       " 67,\n",
       " 3,\n",
       " 77,\n",
       " 4,\n",
       " 90,\n",
       " 75,\n",
       " 82,\n",
       " 42,\n",
       " 14,\n",
       " 72,\n",
       " 1,\n",
       " 11,\n",
       " 63,\n",
       " 56,\n",
       " 63,\n",
       " 90,\n",
       " 31,\n",
       " 21,\n",
       " 81,\n",
       " 56,\n",
       " 88,\n",
       " 48,\n",
       " 9,\n",
       " 72,\n",
       " 2,\n",
       " 39,\n",
       " 89,\n",
       " 86,\n",
       " 65,\n",
       " 51,\n",
       " 21,\n",
       " 47,\n",
       " 13,\n",
       " 17,\n",
       " 44,\n",
       " 33,\n",
       " 87,\n",
       " 53,\n",
       " 10,\n",
       " 60,\n",
       " 31,\n",
       " 79,\n",
       " 76,\n",
       " 77,\n",
       " 16,\n",
       " 18,\n",
       " 77,\n",
       " 6,\n",
       " 2,\n",
       " 27,\n",
       " 14,\n",
       " 3,\n",
       " 3,\n",
       " 55,\n",
       " 70,\n",
       " 70,\n",
       " 53,\n",
       " 57,\n",
       " 72,\n",
       " 85,\n",
       " 77,\n",
       " 9,\n",
       " 13,\n",
       " 82,\n",
       " 3,\n",
       " 48,\n",
       " 9,\n",
       " 88,\n",
       " 24,\n",
       " 28,\n",
       " 28,\n",
       " 67,\n",
       " 86,\n",
       " 6,\n",
       " 70,\n",
       " 19,\n",
       " 55,\n",
       " 21,\n",
       " 41,\n",
       " 4,\n",
       " 21,\n",
       " 51,\n",
       " 39,\n",
       " 37,\n",
       " 19,\n",
       " 70,\n",
       " 5,\n",
       " 23,\n",
       " 10,\n",
       " 17,\n",
       " 49,\n",
       " 39,\n",
       " 14,\n",
       " 39,\n",
       " 48,\n",
       " 58,\n",
       " 77,\n",
       " 47,\n",
       " 18,\n",
       " 62,\n",
       " 44,\n",
       " 13,\n",
       " 65,\n",
       " 4,\n",
       " 74,\n",
       " 7,\n",
       " 18,\n",
       " 77,\n",
       " 9,\n",
       " 6,\n",
       " 70,\n",
       " 9,\n",
       " 89,\n",
       " 8,\n",
       " 59,\n",
       " 80,\n",
       " 86,\n",
       " 22,\n",
       " 51,\n",
       " 34,\n",
       " 28,\n",
       " 73,\n",
       " 36,\n",
       " 42,\n",
       " 87,\n",
       " 73,\n",
       " 13,\n",
       " 43,\n",
       " 64,\n",
       " 82,\n",
       " 49,\n",
       " 14,\n",
       " 39,\n",
       " 78,\n",
       " 35,\n",
       " 13,\n",
       " 84,\n",
       " 32,\n",
       " 40,\n",
       " 33,\n",
       " 79,\n",
       " 60,\n",
       " 79,\n",
       " 76,\n",
       " 10,\n",
       " 77,\n",
       " 35,\n",
       " 90,\n",
       " 79,\n",
       " 14,\n",
       " 84,\n",
       " 46,\n",
       " 17,\n",
       " 63,\n",
       " 19,\n",
       " 21,\n",
       " 79,\n",
       " 9,\n",
       " 16,\n",
       " 9,\n",
       " 39,\n",
       " 54,\n",
       " 4,\n",
       " 73,\n",
       " 47,\n",
       " 75,\n",
       " 60,\n",
       " 60,\n",
       " 57,\n",
       " 63,\n",
       " 60,\n",
       " 2,\n",
       " 81,\n",
       " 31,\n",
       " 47,\n",
       " 42,\n",
       " 36,\n",
       " 51,\n",
       " 85,\n",
       " 82,\n",
       " 1,\n",
       " 89,\n",
       " 53,\n",
       " 48,\n",
       " 2,\n",
       " 10,\n",
       " 42,\n",
       " 2,\n",
       " 85,\n",
       " 63,\n",
       " 48,\n",
       " 38,\n",
       " 34,\n",
       " 5,\n",
       " 81,\n",
       " 72,\n",
       " 81,\n",
       " 18,\n",
       " 49,\n",
       " 37,\n",
       " 37,\n",
       " 46,\n",
       " 62,\n",
       " 27,\n",
       " 17,\n",
       " 8,\n",
       " 33,\n",
       " 34,\n",
       " 20,\n",
       " 17,\n",
       " 73,\n",
       " 39,\n",
       " 53,\n",
       " 34,\n",
       " 10,\n",
       " 78,\n",
       " 64,\n",
       " 31,\n",
       " 44,\n",
       " 86,\n",
       " 86,\n",
       " 63,\n",
       " 21,\n",
       " 75,\n",
       " 4,\n",
       " 25,\n",
       " 19,\n",
       " 40,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = []\n",
    "i = 0\n",
    "for inputs, labels in tqdm(trainloader):\n",
    "    train_labels += labels.tolist()\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7897b529-e6f2-48fe-9540-9ff7c7bb9424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1f58e3e-864f-4cd1-ae3e-df466a4cbde2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1     1000\n",
       "2     1000\n",
       "64    1000\n",
       "63    1000\n",
       "62    1000\n",
       "      ... \n",
       "28    1000\n",
       "27    1000\n",
       "25    1000\n",
       "24    1000\n",
       "90    1000\n",
       "Length: 80, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(train_labels).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bccf373-81f5-410f-a26f-30ec64268064",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.Series(np.array(train_labels, dtype=int)).plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e7b42b8-bf32-4027-ae82-19319487d35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([70, 73, 33, 79,  4, 10, 72, 62,  2, 63, 74, 31, 64, 88, 27, 37,  7,\n",
       "       51, 11, 75, 28, 42, 36, 18, 23, 89, 78, 85, 32, 56, 61,  9, 87, 24,\n",
       "       40, 17, 49, 15,  1, 81, 13, 39, 25, 58, 86, 76, 60, 46, 53, 47, 21,\n",
       "       41, 77, 90, 55, 34, 65, 48, 52, 19, 50, 44, 22, 80, 38,  8, 43, 82,\n",
       "       14,  5, 57,  6, 35, 54, 59, 67,  3, 16, 20, 84])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(np.array(train_labels, dtype=int)).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8d051482-6e8a-4047-bacc-2c9fe9565b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d567088-238b-45ef-93a2-d490ceafcef1",
   "metadata": {},
   "source": [
    "## Training VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "803a91f2-3e38-4378-be27-0267d8892b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "Net                                      [32, 91]                  --\n",
      "├─Sequential: 1-1                        [32, 64, 224, 224]        --\n",
      "│    └─Conv2d: 2-1                       [32, 64, 224, 224]        1,792\n",
      "│    └─BatchNorm2d: 2-2                  [32, 64, 224, 224]        128\n",
      "│    └─ReLU: 2-3                         [32, 64, 224, 224]        --\n",
      "├─Sequential: 1-2                        [32, 64, 112, 112]        --\n",
      "│    └─Conv2d: 2-4                       [32, 64, 224, 224]        36,928\n",
      "│    └─BatchNorm2d: 2-5                  [32, 64, 224, 224]        128\n",
      "│    └─ReLU: 2-6                         [32, 64, 224, 224]        --\n",
      "│    └─MaxPool2d: 2-7                    [32, 64, 112, 112]        --\n",
      "├─Sequential: 1-3                        [32, 128, 112, 112]       --\n",
      "│    └─Conv2d: 2-8                       [32, 128, 112, 112]       73,856\n",
      "│    └─BatchNorm2d: 2-9                  [32, 128, 112, 112]       256\n",
      "│    └─ReLU: 2-10                        [32, 128, 112, 112]       --\n",
      "├─Sequential: 1-4                        [32, 128, 56, 56]         --\n",
      "│    └─Conv2d: 2-11                      [32, 128, 112, 112]       147,584\n",
      "│    └─BatchNorm2d: 2-12                 [32, 128, 112, 112]       256\n",
      "│    └─ReLU: 2-13                        [32, 128, 112, 112]       --\n",
      "│    └─MaxPool2d: 2-14                   [32, 128, 56, 56]         --\n",
      "├─Sequential: 1-5                        [32, 256, 56, 56]         --\n",
      "│    └─Conv2d: 2-15                      [32, 256, 56, 56]         295,168\n",
      "│    └─BatchNorm2d: 2-16                 [32, 256, 56, 56]         512\n",
      "│    └─ReLU: 2-17                        [32, 256, 56, 56]         --\n",
      "├─Sequential: 1-6                        [32, 256, 56, 56]         --\n",
      "│    └─Conv2d: 2-18                      [32, 256, 56, 56]         590,080\n",
      "│    └─BatchNorm2d: 2-19                 [32, 256, 56, 56]         512\n",
      "│    └─ReLU: 2-20                        [32, 256, 56, 56]         --\n",
      "├─Sequential: 1-7                        [32, 256, 28, 28]         --\n",
      "│    └─Conv2d: 2-21                      [32, 256, 56, 56]         590,080\n",
      "│    └─BatchNorm2d: 2-22                 [32, 256, 56, 56]         512\n",
      "│    └─ReLU: 2-23                        [32, 256, 56, 56]         --\n",
      "│    └─MaxPool2d: 2-24                   [32, 256, 28, 28]         --\n",
      "├─Sequential: 1-8                        [32, 512, 28, 28]         --\n",
      "│    └─Conv2d: 2-25                      [32, 512, 28, 28]         1,180,160\n",
      "│    └─BatchNorm2d: 2-26                 [32, 512, 28, 28]         1,024\n",
      "│    └─ReLU: 2-27                        [32, 512, 28, 28]         --\n",
      "├─Sequential: 1-9                        [32, 512, 28, 28]         --\n",
      "│    └─Conv2d: 2-28                      [32, 512, 28, 28]         2,359,808\n",
      "│    └─BatchNorm2d: 2-29                 [32, 512, 28, 28]         1,024\n",
      "│    └─ReLU: 2-30                        [32, 512, 28, 28]         --\n",
      "├─Sequential: 1-10                       [32, 512, 14, 14]         --\n",
      "│    └─Conv2d: 2-31                      [32, 512, 28, 28]         2,359,808\n",
      "│    └─BatchNorm2d: 2-32                 [32, 512, 28, 28]         1,024\n",
      "│    └─ReLU: 2-33                        [32, 512, 28, 28]         --\n",
      "│    └─MaxPool2d: 2-34                   [32, 512, 14, 14]         --\n",
      "├─Sequential: 1-11                       [32, 512, 14, 14]         --\n",
      "│    └─Conv2d: 2-35                      [32, 512, 14, 14]         2,359,808\n",
      "│    └─BatchNorm2d: 2-36                 [32, 512, 14, 14]         1,024\n",
      "│    └─ReLU: 2-37                        [32, 512, 14, 14]         --\n",
      "├─Sequential: 1-12                       [32, 512, 14, 14]         --\n",
      "│    └─Conv2d: 2-38                      [32, 512, 14, 14]         2,359,808\n",
      "│    └─BatchNorm2d: 2-39                 [32, 512, 14, 14]         1,024\n",
      "│    └─ReLU: 2-40                        [32, 512, 14, 14]         --\n",
      "├─Sequential: 1-13                       [32, 512, 7, 7]           --\n",
      "│    └─Conv2d: 2-41                      [32, 512, 14, 14]         2,359,808\n",
      "│    └─BatchNorm2d: 2-42                 [32, 512, 14, 14]         1,024\n",
      "│    └─ReLU: 2-43                        [32, 512, 14, 14]         --\n",
      "│    └─MaxPool2d: 2-44                   [32, 512, 7, 7]           --\n",
      "├─AdaptiveAvgPool2d: 1-14                [32, 512, 7, 7]           --\n",
      "├─Sequential: 1-15                       [32, 4096]                --\n",
      "│    └─Linear: 2-45                      [32, 4096]                102,764,544\n",
      "│    └─ReLU: 2-46                        [32, 4096]                --\n",
      "│    └─Dropout: 2-47                     [32, 4096]                --\n",
      "├─Sequential: 1-16                       [32, 4096]                --\n",
      "│    └─Linear: 2-48                      [32, 4096]                16,781,312\n",
      "│    └─ReLU: 2-49                        [32, 4096]                --\n",
      "│    └─Dropout: 2-50                     [32, 4096]                --\n",
      "├─Sequential: 1-17                       [32, 91]                  --\n",
      "│    └─Linear: 2-51                      [32, 91]                  372,827\n",
      "==========================================================================================\n",
      "Total params: 134,641,819\n",
      "Trainable params: 134,641,819\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 495.36\n",
      "==========================================================================================\n",
      "Input size (MB): 19.27\n",
      "Forward/backward pass size (MB): 6938.45\n",
      "Params size (MB): 538.57\n",
      "Estimated Total Size (MB): 7496.29\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "input_size = (batch_size, 3, 224, 224)\n",
    "#num_classes = len(dataloader.dataset.class_name)\n",
    "num_classes = max(train_labels)+1\n",
    "model = vgg16.VGG16(device, input_size=input_size, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "528c4a81-3ed8-4c1a-8f9c-acd8e1b23dad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EPOCH #0, step #0] loss: 4.803815841674805\n",
      "[EPOCH #0, step #2] loss: 4.846447467803955\n",
      "[EPOCH #0, step #4] loss: 4.825207996368408\n",
      "[EPOCH #0, step #6] loss: 4.854938915797642\n",
      "[EPOCH #0, step #8] loss: 4.821528010898167\n",
      "[EPOCH #0, step #10] loss: 4.798192457719282\n",
      "[EPOCH #0, step #12] loss: 4.810479677640474\n",
      "[EPOCH #0, step #14] loss: 4.815703741709391\n",
      "[EPOCH #0, step #16] loss: 4.810518517213709\n",
      "[EPOCH #0, step #18] loss: 4.793528481533653\n",
      "[EPOCH #0, step #20] loss: 4.7988656134832475\n",
      "[EPOCH #0, step #22] loss: 4.8056332961372705\n",
      "[EPOCH #0, step #24] loss: 4.789730243682861\n",
      "[EPOCH #0, step #26] loss: 4.791834089491102\n",
      "[EPOCH #0, step #28] loss: 4.79501433208071\n",
      "[EPOCH #0, step #30] loss: 4.7947879145222325\n",
      "[EPOCH #0, step #32] loss: 4.80763121807214\n",
      "[EPOCH #0, step #34] loss: 4.798536246163504\n",
      "[EPOCH #0, step #36] loss: 4.790479711584143\n",
      "[EPOCH #0, step #38] loss: 4.791704275669196\n",
      "[EPOCH #0, step #40] loss: 4.791296144811119\n",
      "[EPOCH #0, step #42] loss: 4.794527064922244\n",
      "[EPOCH #0, step #44] loss: 4.791841231452095\n",
      "[EPOCH #0, step #46] loss: 4.795890473304911\n",
      "[EPOCH #0, step #48] loss: 4.788495384916967\n",
      "[EPOCH #0, step #50] loss: 4.793064341825597\n",
      "[EPOCH #0, step #52] loss: 4.791313990107122\n",
      "[EPOCH #0, step #54] loss: 4.79085954319347\n",
      "[EPOCH #0, step #56] loss: 4.786420688294528\n",
      "[EPOCH #0, step #58] loss: 4.786622079752259\n",
      "[EPOCH #0, step #60] loss: 4.788025707495017\n",
      "[EPOCH #0, step #62] loss: 4.787069116319929\n",
      "[EPOCH #0, step #64] loss: 4.786976718902588\n",
      "[EPOCH #0, step #66] loss: 4.784549542327426\n",
      "[EPOCH #0, step #68] loss: 4.785405787868776\n",
      "[EPOCH #0, step #70] loss: 4.788357553347735\n",
      "[EPOCH #0, step #72] loss: 4.783992466861254\n",
      "[EPOCH #0, step #74] loss: 4.783399314880371\n",
      "[EPOCH #0, step #76] loss: 4.786586396105878\n",
      "[EPOCH #0, step #78] loss: 4.785538057737712\n",
      "[EPOCH #0, step #80] loss: 4.78658726774616\n",
      "[EPOCH #0, step #82] loss: 4.784642696380615\n",
      "[EPOCH #0, step #84] loss: 4.788633408265955\n",
      "[EPOCH #0, step #86] loss: 4.79272776636584\n",
      "[EPOCH #0, step #88] loss: 4.791478917839822\n",
      "[EPOCH #0, step #90] loss: 4.789493031554169\n",
      "[EPOCH #0, step #92] loss: 4.792623155860491\n",
      "[EPOCH #0, step #94] loss: 4.795946924309981\n",
      "[EPOCH #0, step #96] loss: 4.79631811810523\n",
      "[EPOCH #0, step #98] loss: 4.7953954802619085\n",
      "[EPOCH #0, step #100] loss: 4.794697379121686\n",
      "[EPOCH #0, step #102] loss: 4.794316851977006\n",
      "[EPOCH #0, step #104] loss: 4.796288562956311\n",
      "[EPOCH #0, step #106] loss: 4.798191217618568\n",
      "[EPOCH #0, step #108] loss: 4.796341926679698\n",
      "[EPOCH #0, step #110] loss: 4.796299212687725\n",
      "[EPOCH #0, step #112] loss: 4.7936173498103045\n",
      "[EPOCH #0, step #114] loss: 4.792207589356796\n",
      "[EPOCH #0, step #116] loss: 4.791065395387829\n",
      "[EPOCH #0, step #118] loss: 4.791810528570864\n",
      "[EPOCH #0, step #120] loss: 4.792346847944023\n",
      "[EPOCH #0, step #122] loss: 4.791291682700801\n",
      "[EPOCH #0, step #124] loss: 4.792785285949707\n",
      "[EPOCH #0, step #126] loss: 4.793367036684292\n",
      "[EPOCH #0, step #128] loss: 4.794944948004198\n",
      "[EPOCH #0, step #130] loss: 4.7939300027512415\n",
      "[EPOCH #0, step #132] loss: 4.794912356183045\n",
      "[EPOCH #0, step #134] loss: 4.79660005569458\n",
      "[EPOCH #0, step #136] loss: 4.7962818667836435\n",
      "[EPOCH #0, step #138] loss: 4.8007351443064294\n",
      "[EPOCH #0, step #140] loss: 4.798890404667414\n",
      "[EPOCH #0, step #142] loss: 4.796990858091341\n",
      "[EPOCH #0, step #144] loss: 4.795486058859989\n",
      "[EPOCH #0, step #146] loss: 4.794041743894824\n",
      "[EPOCH #0, step #148] loss: 4.795129366369055\n",
      "[EPOCH #0, step #150] loss: 4.794872268146237\n",
      "[EPOCH #0, step #152] loss: 4.793661734637092\n",
      "[EPOCH #0, step #154] loss: 4.793146114964639\n",
      "[EPOCH #0, step #156] loss: 4.791897442690127\n",
      "[EPOCH #0, step #158] loss: 4.792618382651851\n",
      "[EPOCH #0, step #160] loss: 4.792485121614444\n",
      "[EPOCH #0, step #162] loss: 4.791897247174035\n",
      "[EPOCH #0, step #164] loss: 4.791138007424094\n",
      "[EPOCH #0, step #166] loss: 4.790238900098972\n",
      "[EPOCH #0, step #168] loss: 4.78904436608038\n",
      "[EPOCH #0, step #170] loss: 4.787357628694054\n",
      "[EPOCH #0, step #172] loss: 4.788550382404658\n",
      "[EPOCH #0, step #174] loss: 4.789824226924352\n",
      "[EPOCH #0, step #176] loss: 4.788755438422079\n",
      "[EPOCH #0, step #178] loss: 4.7877388160321965\n",
      "[EPOCH #0, step #180] loss: 4.7884208378870845\n",
      "[EPOCH #0, step #182] loss: 4.789511479966627\n",
      "[EPOCH #0, step #184] loss: 4.7909951931721455\n",
      "[EPOCH #0, step #186] loss: 4.790109193261294\n",
      "[EPOCH #0, step #188] loss: 4.789986317750638\n",
      "[EPOCH #0, step #190] loss: 4.79119494323331\n",
      "[EPOCH #0, step #192] loss: 4.793317557616555\n",
      "[EPOCH #0, step #194] loss: 4.79456497339102\n",
      "[EPOCH #0, step #196] loss: 4.793913446707169\n",
      "[EPOCH #0, step #198] loss: 4.795424674623575\n",
      "[EPOCH #0, step #200] loss: 4.797583971450578\n",
      "[EPOCH #0, step #202] loss: 4.799766531131538\n",
      "[EPOCH #0, step #204] loss: 4.798746897534627\n",
      "[EPOCH #0, step #206] loss: 4.796801735237601\n",
      "[EPOCH #0, step #208] loss: 4.796521417261881\n",
      "[EPOCH #0, step #210] loss: 4.797965187597049\n",
      "[EPOCH #0, step #212] loss: 4.798073479827021\n",
      "[EPOCH #0, step #214] loss: 4.79820492988409\n",
      "[EPOCH #0, step #216] loss: 4.798928904643256\n",
      "[EPOCH #0, step #218] loss: 4.797600389071251\n",
      "[EPOCH #0, step #220] loss: 4.797801552854512\n",
      "[EPOCH #0, step #222] loss: 4.797710371658941\n",
      "[EPOCH #0, step #224] loss: 4.797630498674181\n",
      "[EPOCH #0, step #226] loss: 4.79766640684153\n",
      "[EPOCH #0, step #228] loss: 4.798122680863959\n",
      "[EPOCH #0, step #230] loss: 4.800094389812255\n",
      "[EPOCH #0, step #232] loss: 4.7996343154252346\n",
      "[EPOCH #0, step #234] loss: 4.8004002550815015\n",
      "[EPOCH #0, step #236] loss: 4.8004237911369225\n",
      "[EPOCH #0, step #238] loss: 4.801685159675247\n",
      "[EPOCH #0, step #240] loss: 4.802256910632755\n",
      "[EPOCH #0, step #242] loss: 4.801722650174741\n",
      "[EPOCH #0, step #244] loss: 4.802292119240274\n",
      "[EPOCH #0, step #246] loss: 4.802070777908511\n",
      "[EPOCH #0, step #248] loss: 4.800892151981952\n",
      "[EPOCH #0, step #250] loss: 4.8001548151570965\n",
      "[EPOCH #0, step #252] loss: 4.80011503687018\n",
      "[EPOCH #0, step #254] loss: 4.799550875495462\n",
      "[EPOCH #0, step #256] loss: 4.79821146508599\n",
      "[EPOCH #0, step #258] loss: 4.797043746962971\n",
      "[EPOCH #0, step #260] loss: 4.795982594691017\n",
      "[EPOCH #0, step #262] loss: 4.79565380553329\n",
      "[EPOCH #0, step #264] loss: 4.794962550109288\n",
      "[EPOCH #0, step #266] loss: 4.794554458575302\n",
      "[EPOCH #0, step #268] loss: 4.794937693939776\n",
      "[EPOCH #0, step #270] loss: 4.794987089079685\n",
      "[EPOCH #0, step #272] loss: 4.794615584852058\n",
      "[EPOCH #0, step #274] loss: 4.794678493846546\n",
      "[EPOCH #0, step #276] loss: 4.79367109326249\n",
      "[EPOCH #0, step #278] loss: 4.7944026044619985\n",
      "[EPOCH #0, step #280] loss: 4.794289405659849\n",
      "[EPOCH #0, step #282] loss: 4.794389578141931\n",
      "[EPOCH #0, step #284] loss: 4.794152365232769\n",
      "[EPOCH #0, step #286] loss: 4.793419327885432\n",
      "[EPOCH #0, step #288] loss: 4.794214659496162\n",
      "[EPOCH #0, step #290] loss: 4.795106717401354\n",
      "[EPOCH #0, step #292] loss: 4.79430523016347\n",
      "[EPOCH #0, step #294] loss: 4.794220835475598\n",
      "[EPOCH #0, step #296] loss: 4.793459131260111\n",
      "[EPOCH #0, step #298] loss: 4.79393994449373\n",
      "[EPOCH #0, step #300] loss: 4.793598336634842\n",
      "[EPOCH #0, step #302] loss: 4.793180566416321\n",
      "[EPOCH #0, step #304] loss: 4.794358342592833\n",
      "[EPOCH #0, step #306] loss: 4.795614531451794\n",
      "[EPOCH #0, step #308] loss: 4.795414981718588\n",
      "[EPOCH #0, step #310] loss: 4.795425231050449\n",
      "[EPOCH #0, step #312] loss: 4.795581611962364\n",
      "[EPOCH #0, step #314] loss: 4.795000624278235\n",
      "[EPOCH #0, step #316] loss: 4.79444060942352\n",
      "[EPOCH #0, step #318] loss: 4.794372225256176\n",
      "[EPOCH #0, step #320] loss: 4.794100213273663\n",
      "[EPOCH #0, step #322] loss: 4.7945840705659\n",
      "[EPOCH #0, step #324] loss: 4.793808872516339\n",
      "[EPOCH #0, step #326] loss: 4.794181001295737\n",
      "[EPOCH #0, step #328] loss: 4.793519869401462\n",
      "[EPOCH #0, step #330] loss: 4.7929952079796\n",
      "[EPOCH #0, step #332] loss: 4.79233229410899\n",
      "[EPOCH #0, step #334] loss: 4.793326349400762\n",
      "[EPOCH #0, step #336] loss: 4.7934955602583615\n",
      "[EPOCH #0, step #338] loss: 4.794229324588382\n",
      "[EPOCH #0, step #340] loss: 4.794584717568764\n",
      "[EPOCH #0, step #342] loss: 4.7943652739677765\n",
      "[EPOCH #0, step #344] loss: 4.795149359495744\n",
      "[EPOCH #0, step #346] loss: 4.794364691467725\n",
      "[EPOCH #0, step #348] loss: 4.7943786358765\n",
      "[EPOCH #0, step #350] loss: 4.793742446138649\n",
      "[EPOCH #0, step #352] loss: 4.792966513052878\n",
      "[EPOCH #0, step #354] loss: 4.792241295290665\n",
      "[EPOCH #0, step #356] loss: 4.792852330942448\n",
      "[EPOCH #0, step #358] loss: 4.793073773716154\n",
      "[EPOCH #0, step #360] loss: 4.792923656527025\n",
      "[EPOCH #0, step #362] loss: 4.792464370569907\n",
      "[EPOCH #0, step #364] loss: 4.793123697254756\n",
      "[EPOCH #0, step #366] loss: 4.793355614352941\n",
      "[EPOCH #0, step #368] loss: 4.793721532433983\n",
      "[EPOCH #0, step #370] loss: 4.793460453938281\n",
      "[EPOCH #0, step #372] loss: 4.794080137247694\n",
      "[EPOCH #0, step #374] loss: 4.7938411305745445\n",
      "[EPOCH #0, step #376] loss: 4.794027887541672\n",
      "[EPOCH #0, step #378] loss: 4.7941324201297\n",
      "[EPOCH #0, step #380] loss: 4.794335823359452\n",
      "[EPOCH #0, step #382] loss: 4.794002860395467\n",
      "[EPOCH #0, step #384] loss: 4.794623449251249\n",
      "[EPOCH #0, step #386] loss: 4.795245430574244\n",
      "[EPOCH #0, step #388] loss: 4.79467406677403\n",
      "[EPOCH #0, step #390] loss: 4.794755468588046\n",
      "[EPOCH #0, step #392] loss: 4.795134767624561\n",
      "[EPOCH #0, step #394] loss: 4.7953036103067515\n",
      "[EPOCH #0, step #396] loss: 4.795518591662198\n",
      "[EPOCH #0, step #398] loss: 4.795213105385764\n",
      "[EPOCH #0, step #400] loss: 4.79477571430349\n",
      "[EPOCH #0, step #402] loss: 4.794645120133241\n",
      "[EPOCH #0, step #404] loss: 4.795056367803503\n",
      "[EPOCH #0, step #406] loss: 4.7952277982557145\n",
      "[EPOCH #0, step #408] loss: 4.79536963325258\n",
      "[EPOCH #0, step #410] loss: 4.796378589314556\n",
      "[EPOCH #0, step #412] loss: 4.796473638197412\n",
      "[EPOCH #0, step #414] loss: 4.7965021144912905\n",
      "[EPOCH #0, step #416] loss: 4.796597798665364\n",
      "[EPOCH #0, step #418] loss: 4.796324932489873\n",
      "[EPOCH #0, step #420] loss: 4.796470908257854\n",
      "[EPOCH #0, step #422] loss: 4.79610504213518\n",
      "[EPOCH #0, step #424] loss: 4.7961005379171935\n",
      "[EPOCH #0, step #426] loss: 4.7960763524790275\n",
      "[EPOCH #0, step #428] loss: 4.795767717428141\n",
      "[EPOCH #0, step #430] loss: 4.795725657602474\n",
      "[EPOCH #0, step #432] loss: 4.796351256601805\n",
      "[EPOCH #0, step #434] loss: 4.796599290562773\n",
      "[EPOCH #0, step #436] loss: 4.796931535210162\n",
      "[EPOCH #0, step #438] loss: 4.797292782125277\n",
      "[EPOCH #0, step #440] loss: 4.797630030011374\n",
      "[EPOCH #0, step #442] loss: 4.7968759332230615\n",
      "[EPOCH #0, step #444] loss: 4.796830800945839\n",
      "[EPOCH #0, step #446] loss: 4.796860123107364\n",
      "[EPOCH #0, step #448] loss: 4.7972529003508635\n",
      "[EPOCH #0, step #450] loss: 4.79764718861379\n",
      "[EPOCH #0, step #452] loss: 4.7972457751006745\n",
      "[EPOCH #0, step #454] loss: 4.7975472471216225\n",
      "[EPOCH #0, step #456] loss: 4.797815194536873\n",
      "[EPOCH #0, step #458] loss: 4.798085777847855\n",
      "[EPOCH #0, step #460] loss: 4.797692740558285\n",
      "[EPOCH #0, step #462] loss: 4.797024985369029\n",
      "[EPOCH #0, step #464] loss: 4.797377894001622\n",
      "[EPOCH #0, step #466] loss: 4.797509307779643\n",
      "[EPOCH #0, step #468] loss: 4.79735508859793\n",
      "[EPOCH #0, step #470] loss: 4.7975300669417\n",
      "[EPOCH #0, step #472] loss: 4.7978065956470575\n",
      "[EPOCH #0, step #474] loss: 4.797633088764392\n",
      "[EPOCH #0, step #476] loss: 4.797650685100435\n",
      "[EPOCH #0, step #478] loss: 4.798277208849881\n",
      "[EPOCH #0, step #480] loss: 4.798034253586355\n",
      "[EPOCH #0, step #482] loss: 4.797608741815539\n",
      "[EPOCH #0, step #484] loss: 4.797434308356846\n",
      "[EPOCH #0, step #486] loss: 4.79825174539241\n",
      "[EPOCH #0, step #488] loss: 4.798486889018116\n",
      "[EPOCH #0, step #490] loss: 4.7985180099238685\n",
      "[EPOCH #0, step #492] loss: 4.79901504226437\n",
      "[EPOCH #0, step #494] loss: 4.798987271087338\n",
      "[EPOCH #0, step #496] loss: 4.799070528095637\n",
      "[EPOCH #0, step #498] loss: 4.798682605575225\n",
      "[EPOCH #0, step #500] loss: 4.798111517748195\n",
      "[EPOCH #0, step #502] loss: 4.798869609832764\n",
      "[EPOCH #0, step #504] loss: 4.799132351828094\n",
      "[EPOCH #0, step #506] loss: 4.798677021229761\n",
      "[EPOCH #0, step #508] loss: 4.798524074329609\n",
      "[EPOCH #0, step #510] loss: 4.798434463732397\n",
      "[EPOCH #0, step #512] loss: 4.798429953889308\n",
      "[EPOCH #0, step #514] loss: 4.798443906284073\n",
      "[EPOCH #0, step #516] loss: 4.798573413716063\n",
      "[EPOCH #0, step #518] loss: 4.79875814662044\n",
      "[EPOCH #0, step #520] loss: 4.79845858993091\n",
      "[EPOCH #0, step #522] loss: 4.798239073379546\n",
      "[EPOCH #0, step #524] loss: 4.798064135596865\n",
      "[EPOCH #0, step #526] loss: 4.798310068119635\n",
      "[EPOCH #0, step #528] loss: 4.798314159443788\n",
      "[EPOCH #0, step #530] loss: 4.7986432235344205\n",
      "[EPOCH #0, step #532] loss: 4.799270080580721\n",
      "[EPOCH #0, step #534] loss: 4.799827779787723\n",
      "[EPOCH #0, step #536] loss: 4.79964216150607\n",
      "[EPOCH #0, step #538] loss: 4.799110455946489\n",
      "[EPOCH #0, step #540] loss: 4.798657800706168\n",
      "[EPOCH #0, step #542] loss: 4.798365498994157\n",
      "[EPOCH #0, step #544] loss: 4.79808655835073\n",
      "[EPOCH #0, step #546] loss: 4.798244174699243\n",
      "[EPOCH #0, step #548] loss: 4.798315591065176\n",
      "[EPOCH #0, step #550] loss: 4.798774022588712\n",
      "[EPOCH #0, step #552] loss: 4.798342958281312\n",
      "[EPOCH #0, step #554] loss: 4.7984217282888055\n",
      "[EPOCH #0, step #556] loss: 4.798516841080287\n",
      "[EPOCH #0, step #558] loss: 4.798561188317369\n",
      "[EPOCH #0, step #560] loss: 4.797999461916891\n",
      "[EPOCH #0, step #562] loss: 4.797668750078597\n",
      "[EPOCH #0, step #564] loss: 4.798088481362942\n",
      "[EPOCH #0, step #566] loss: 4.797515436875547\n",
      "[EPOCH #0, step #568] loss: 4.798447018976999\n",
      "[EPOCH #0, step #570] loss: 4.798803145747677\n",
      "[EPOCH #0, step #572] loss: 4.798782377758991\n",
      "[EPOCH #0, step #574] loss: 4.798882112917693\n",
      "[EPOCH #0, step #576] loss: 4.798864499328455\n",
      "[EPOCH #0, step #578] loss: 4.798605320984835\n",
      "[EPOCH #0, step #580] loss: 4.798752070704343\n",
      "[EPOCH #0, step #582] loss: 4.798849944185025\n",
      "[EPOCH #0, step #584] loss: 4.798786521161723\n",
      "[EPOCH #0, step #586] loss: 4.798936499444549\n",
      "[EPOCH #0, step #588] loss: 4.799498701338452\n",
      "[EPOCH #0, step #590] loss: 4.799547118785619\n",
      "[EPOCH #0, step #592] loss: 4.799730431973231\n",
      "[EPOCH #0, step #594] loss: 4.799609302873371\n",
      "[EPOCH #0, step #596] loss: 4.799554703423326\n",
      "[EPOCH #0, step #598] loss: 4.800037181039087\n",
      "[EPOCH #0, step #600] loss: 4.799560653191438\n",
      "[EPOCH #0, step #602] loss: 4.79945504408373\n",
      "[EPOCH #0, step #604] loss: 4.799128060301474\n",
      "[EPOCH #0, step #606] loss: 4.799047674339332\n",
      "[EPOCH #0, step #608] loss: 4.799262331820082\n",
      "[EPOCH #0, step #610] loss: 4.7992458671282625\n",
      "[EPOCH #0, step #612] loss: 4.799847931107339\n",
      "[EPOCH #0, step #614] loss: 4.800149918377884\n",
      "[EPOCH #0, step #616] loss: 4.7998772185277705\n",
      "[EPOCH #0, step #618] loss: 4.800200612556568\n",
      "[EPOCH #0, step #620] loss: 4.7997771914262515\n",
      "[EPOCH #0, step #622] loss: 4.79948406387868\n",
      "[EPOCH #0, step #624] loss: 4.799670973205567\n",
      "[EPOCH #0, step #626] loss: 4.7995636269236295\n",
      "[EPOCH #0, step #628] loss: 4.799391770779803\n",
      "[EPOCH #0, step #630] loss: 4.799107362653487\n",
      "[EPOCH #0, step #632] loss: 4.798460015000137\n",
      "[EPOCH #0, step #634] loss: 4.79892916792021\n",
      "[EPOCH #0, step #636] loss: 4.799342939954725\n",
      "[EPOCH #0, step #638] loss: 4.798676744499863\n",
      "[EPOCH #0, step #640] loss: 4.798369556432953\n",
      "[EPOCH #0, step #642] loss: 4.798270798767707\n",
      "[EPOCH #0, step #644] loss: 4.797987597857335\n",
      "[EPOCH #0, step #646] loss: 4.798255198152946\n",
      "[EPOCH #0, step #648] loss: 4.798285099317553\n",
      "[EPOCH #0, step #650] loss: 4.798226392397317\n",
      "[EPOCH #0, step #652] loss: 4.798140955920607\n",
      "[EPOCH #0, step #654] loss: 4.798405840196683\n",
      "[EPOCH #0, step #656] loss: 4.798650246595502\n",
      "[EPOCH #0, step #658] loss: 4.798653999120223\n",
      "[EPOCH #0, step #660] loss: 4.79828467058883\n",
      "[EPOCH #0, step #662] loss: 4.798183481437948\n",
      "[EPOCH #0, step #664] loss: 4.798176888774212\n",
      "[EPOCH #0, step #666] loss: 4.798175058264782\n",
      "[EPOCH #0, step #668] loss: 4.798053307383585\n",
      "[EPOCH #0, step #670] loss: 4.798360876461433\n",
      "[EPOCH #0, step #672] loss: 4.798250156561298\n",
      "[EPOCH #0, step #674] loss: 4.797921541708487\n",
      "[EPOCH #0, step #676] loss: 4.798116347286163\n",
      "[EPOCH #0, step #678] loss: 4.7979269385864525\n",
      "[EPOCH #0, step #680] loss: 4.798208776549621\n",
      "[EPOCH #0, step #682] loss: 4.798100412153744\n",
      "[EPOCH #0, step #684] loss: 4.798468027323702\n",
      "[EPOCH #0, step #686] loss: 4.798486776226993\n",
      "[EPOCH #0, step #688] loss: 4.7985234710405456\n",
      "[EPOCH #0, step #690] loss: 4.798448190675286\n",
      "[EPOCH #0, step #692] loss: 4.797935718409771\n",
      "[EPOCH #0, step #694] loss: 4.79836035049219\n",
      "[EPOCH #0, step #696] loss: 4.798274031328505\n",
      "[EPOCH #0, step #698] loss: 4.798539557341001\n",
      "[EPOCH #0, step #700] loss: 4.798230072571106\n",
      "[EPOCH #0, step #702] loss: 4.798699239239753\n",
      "[EPOCH #0, step #704] loss: 4.798780034788957\n",
      "[EPOCH #0, step #706] loss: 4.798522885820316\n",
      "[EPOCH #0, step #708] loss: 4.798222742901198\n",
      "[EPOCH #0, step #710] loss: 4.797999373971159\n",
      "[EPOCH #0, step #712] loss: 4.797805582824964\n",
      "[EPOCH #0, step #714] loss: 4.797864617834558\n",
      "[EPOCH #0, step #716] loss: 4.797573920905673\n",
      "[EPOCH #0, step #718] loss: 4.797687596837072\n",
      "[EPOCH #0, step #720] loss: 4.797765028790859\n",
      "[EPOCH #0, step #722] loss: 4.79736852184206\n",
      "[EPOCH #0, step #724] loss: 4.797260598149793\n",
      "[EPOCH #0, step #726] loss: 4.797213562253089\n",
      "[EPOCH #0, step #728] loss: 4.797383600792276\n",
      "[EPOCH #0, step #730] loss: 4.797313441656193\n",
      "[EPOCH #0, step #732] loss: 4.797526101298417\n",
      "[EPOCH #0, step #734] loss: 4.797534096646471\n",
      "[EPOCH #0, step #736] loss: 4.79772658458073\n",
      "[EPOCH #0, step #738] loss: 4.797904957292529\n",
      "[EPOCH #0, step #740] loss: 4.798537151372706\n",
      "[EPOCH #0, step #742] loss: 4.7985284492112745\n",
      "[EPOCH #0, step #744] loss: 4.798897243346144\n",
      "[EPOCH #0, step #746] loss: 4.7993469461698925\n",
      "[EPOCH #0, step #748] loss: 4.7995731935641155\n",
      "[EPOCH #0, step #750] loss: 4.799669020026724\n",
      "[EPOCH #0, step #752] loss: 4.7996639109861015\n",
      "[EPOCH #0, step #754] loss: 4.799919652623057\n",
      "[EPOCH #0, step #756] loss: 4.800063397169428\n",
      "[EPOCH #0, step #758] loss: 4.800350818709423\n",
      "[EPOCH #0, step #760] loss: 4.800116837886254\n",
      "[EPOCH #0, step #762] loss: 4.800023781362711\n",
      "[EPOCH #0, step #764] loss: 4.800545363332711\n",
      "[EPOCH #0, step #766] loss: 4.8003479486338625\n",
      "[EPOCH #0, step #768] loss: 4.800274467592277\n",
      "[EPOCH #0, step #770] loss: 4.8003279572176405\n",
      "[EPOCH #0, step #772] loss: 4.799852365664029\n",
      "[EPOCH #0, step #774] loss: 4.800222177197856\n",
      "[EPOCH #0, step #776] loss: 4.800453875822757\n",
      "[EPOCH #0, step #778] loss: 4.799949317290633\n",
      "[EPOCH #0, step #780] loss: 4.800220519418753\n",
      "[EPOCH #0, step #782] loss: 4.8003445853066475\n",
      "[EPOCH #0, step #784] loss: 4.800233559092139\n",
      "[EPOCH #0, step #786] loss: 4.800296488983658\n",
      "[EPOCH #0, step #788] loss: 4.799980853144811\n",
      "[EPOCH #0, step #790] loss: 4.799700321048008\n",
      "[EPOCH #0, step #792] loss: 4.799472035555942\n",
      "[EPOCH #0, step #794] loss: 4.799355223193858\n",
      "[EPOCH #0, step #796] loss: 4.799181449966718\n",
      "[EPOCH #0, step #798] loss: 4.7990359782575815\n",
      "[EPOCH #0, step #800] loss: 4.799323661199372\n",
      "[EPOCH #0, step #802] loss: 4.799415276623604\n",
      "[EPOCH #0, step #804] loss: 4.799286834053372\n",
      "[EPOCH #0, step #806] loss: 4.799239158039494\n",
      "[EPOCH #0, step #808] loss: 4.7992982286752675\n",
      "[EPOCH #0, step #810] loss: 4.799255255853204\n",
      "[EPOCH #0, step #812] loss: 4.799535543129746\n",
      "[EPOCH #0, step #814] loss: 4.79926658115504\n",
      "[EPOCH #0, step #816] loss: 4.799240669684719\n",
      "[EPOCH #0, step #818] loss: 4.799325555235475\n",
      "[EPOCH #0, step #820] loss: 4.799152571158926\n",
      "[EPOCH #0, step #822] loss: 4.799421050279138\n",
      "[EPOCH #0, step #824] loss: 4.7995328689344\n",
      "[EPOCH #0, step #826] loss: 4.799404204252121\n",
      "[EPOCH #0, step #828] loss: 4.799286512183913\n",
      "[EPOCH #0, step #830] loss: 4.799151887101817\n",
      "[EPOCH #0, step #832] loss: 4.799426944888368\n",
      "[EPOCH #0, step #834] loss: 4.799682309955894\n",
      "[EPOCH #0, step #836] loss: 4.799797145269251\n",
      "[EPOCH #0, step #838] loss: 4.7998245401803015\n",
      "[EPOCH #0, step #840] loss: 4.799464408339275\n",
      "[EPOCH #0, step #842] loss: 4.7996730974136295\n",
      "[EPOCH #0, step #844] loss: 4.799563846362413\n",
      "[EPOCH #0, step #846] loss: 4.799341460749278\n",
      "[EPOCH #0, step #848] loss: 4.799097830611769\n",
      "[EPOCH #0, step #850] loss: 4.79865118031216\n",
      "[EPOCH #0, step #852] loss: 4.798476366197378\n",
      "[EPOCH #0, step #854] loss: 4.797882595954583\n",
      "[EPOCH #0, step #856] loss: 4.7976641827453115\n",
      "[EPOCH #0, step #858] loss: 4.797817873038846\n",
      "[EPOCH #0, step #860] loss: 4.798262418908663\n",
      "[EPOCH #0, step #862] loss: 4.798323987671288\n",
      "[EPOCH #0, step #864] loss: 4.798250164186334\n",
      "[EPOCH #0, step #866] loss: 4.79884774462162\n",
      "[EPOCH #0, step #868] loss: 4.798958204969575\n",
      "[EPOCH #0, step #870] loss: 4.7988279826605496\n",
      "[EPOCH #0, step #872] loss: 4.798668390560259\n",
      "[EPOCH #0, step #874] loss: 4.798447611127581\n",
      "[EPOCH #0, step #876] loss: 4.7986366006640235\n",
      "[EPOCH #0, step #878] loss: 4.798955202373899\n",
      "[EPOCH #0, step #880] loss: 4.799095729152406\n",
      "[EPOCH #0, step #882] loss: 4.7990703782570865\n",
      "[EPOCH #0, step #884] loss: 4.798923348033496\n",
      "[EPOCH #0, step #886] loss: 4.799123251182788\n",
      "[EPOCH #0, step #888] loss: 4.7988739850416495\n",
      "[EPOCH #0, step #890] loss: 4.799091353025768\n",
      "[EPOCH #0, step #892] loss: 4.799002740311062\n",
      "[EPOCH #0, step #894] loss: 4.798982179631068\n",
      "[EPOCH #0, step #896] loss: 4.7988612654482905\n",
      "[EPOCH #0, step #898] loss: 4.798959514057809\n",
      "[EPOCH #0, step #900] loss: 4.7991236502534145\n",
      "[EPOCH #0, step #902] loss: 4.799198986023896\n",
      "[EPOCH #0, step #904] loss: 4.799365124254596\n",
      "[EPOCH #0, step #906] loss: 4.799280335911054\n",
      "[EPOCH #0, step #908] loss: 4.799410797450671\n",
      "[EPOCH #0, step #910] loss: 4.799504987756455\n",
      "[EPOCH #0, step #912] loss: 4.799496075670925\n",
      "[EPOCH #0, step #914] loss: 4.799685176995283\n",
      "[EPOCH #0, step #916] loss: 4.799302272214234\n",
      "[EPOCH #0, step #918] loss: 4.799361596818328\n",
      "[EPOCH #0, step #920] loss: 4.7989797819968025\n",
      "[EPOCH #0, step #922] loss: 4.7987637075546115\n",
      "[EPOCH #0, step #924] loss: 4.798749994845004\n",
      "[EPOCH #0, step #926] loss: 4.798573272256532\n",
      "[EPOCH #0, step #928] loss: 4.79863216648574\n",
      "[EPOCH #0, step #930] loss: 4.79839769111412\n",
      "[EPOCH #0, step #932] loss: 4.798077262355073\n",
      "[EPOCH #0, step #934] loss: 4.797865787036916\n",
      "[EPOCH #0, step #936] loss: 4.798036828239547\n",
      "[EPOCH #0, step #938] loss: 4.798121874324811\n",
      "[EPOCH #0, step #940] loss: 4.798193938167138\n",
      "[EPOCH #0, step #942] loss: 4.798169523382743\n",
      "[EPOCH #0, step #944] loss: 4.797872134112807\n",
      "[EPOCH #0, step #946] loss: 4.797824457807048\n",
      "[EPOCH #0, step #948] loss: 4.797947504246574\n",
      "[EPOCH #0, step #950] loss: 4.797852575340231\n",
      "[EPOCH #0, step #952] loss: 4.797883865340434\n",
      "[EPOCH #0, step #954] loss: 4.797828869045717\n",
      "[EPOCH #0, step #956] loss: 4.797565107933531\n",
      "[EPOCH #0, step #958] loss: 4.797105182572127\n",
      "[EPOCH #0, step #960] loss: 4.797134596400901\n",
      "[EPOCH #0, step #962] loss: 4.797123809964981\n",
      "[EPOCH #0, step #964] loss: 4.797389090740619\n",
      "[EPOCH #0, step #966] loss: 4.797465030508426\n",
      "[EPOCH #0, step #968] loss: 4.797460759756365\n",
      "[EPOCH #0, step #970] loss: 4.797291454154112\n",
      "[EPOCH #0, step #972] loss: 4.797221427341159\n",
      "[EPOCH #0, step #974] loss: 4.796919976747953\n",
      "[EPOCH #0, step #976] loss: 4.7970101923635085\n",
      "[EPOCH #0, step #978] loss: 4.797085049447049\n",
      "[EPOCH #0, step #980] loss: 4.797303115191445\n",
      "[EPOCH #0, step #982] loss: 4.79740973430878\n",
      "[EPOCH #0, step #984] loss: 4.79735494410326\n",
      "[EPOCH #0, step #986] loss: 4.797373547500873\n",
      "[EPOCH #0, step #988] loss: 4.797706120898919\n",
      "[EPOCH #0, step #990] loss: 4.798013691464298\n",
      "[EPOCH #0, step #992] loss: 4.798257426312803\n",
      "[EPOCH #0, step #994] loss: 4.79858454364029\n",
      "[EPOCH #0, step #996] loss: 4.798467997682011\n",
      "[EPOCH #0, step #998] loss: 4.798274471714452\n",
      "[EPOCH #0, step #1000] loss: 4.798494306596724\n",
      "[EPOCH #0, step #1002] loss: 4.798527061047844\n",
      "[EPOCH #0, step #1004] loss: 4.798371428874002\n",
      "[EPOCH #0, step #1006] loss: 4.798314036300189\n",
      "[EPOCH #0, step #1008] loss: 4.798187172684608\n",
      "[EPOCH #0, step #1010] loss: 4.798239529191799\n",
      "[EPOCH #0, step #1012] loss: 4.79803361120723\n",
      "[EPOCH #0, step #1014] loss: 4.797895107833035\n",
      "[EPOCH #0, step #1016] loss: 4.797940584293392\n",
      "[EPOCH #0, step #1018] loss: 4.797965420357028\n",
      "[EPOCH #0, step #1020] loss: 4.797693827476838\n",
      "[EPOCH #0, step #1022] loss: 4.7977593418207105\n",
      "[EPOCH #0, step #1024] loss: 4.79800833074058\n",
      "[EPOCH #0, step #1026] loss: 4.798080326867777\n",
      "[EPOCH #0, step #1028] loss: 4.798244915620231\n",
      "[EPOCH #0, step #1030] loss: 4.798795397598459\n",
      "[EPOCH #0, step #1032] loss: 4.798709260528801\n",
      "[EPOCH #0, step #1034] loss: 4.7986193449600885\n",
      "[EPOCH #0, step #1036] loss: 4.798862857781818\n",
      "[EPOCH #0, step #1038] loss: 4.798912365007446\n",
      "[EPOCH #0, step #1040] loss: 4.7990573577074676\n",
      "[EPOCH #0, step #1042] loss: 4.79895739998822\n",
      "[EPOCH #0, step #1044] loss: 4.7993433587288745\n",
      "[EPOCH #0, step #1046] loss: 4.799307014334167\n",
      "[EPOCH #0, step #1048] loss: 4.799173473289061\n",
      "[EPOCH #0, step #1050] loss: 4.799224121246192\n",
      "[EPOCH #0, step #1052] loss: 4.799391304099435\n",
      "[EPOCH #0, step #1054] loss: 4.799624573223964\n",
      "[EPOCH #0, step #1056] loss: 4.7994051620209115\n",
      "[EPOCH #0, step #1058] loss: 4.799345501421532\n",
      "[EPOCH #0, step #1060] loss: 4.799670342563123\n",
      "[EPOCH #0, step #1062] loss: 4.799694756573365\n",
      "[EPOCH #0, step #1064] loss: 4.799825476256895\n",
      "[EPOCH #0, step #1066] loss: 4.799763031953277\n",
      "[EPOCH #0, step #1068] loss: 4.799657931385807\n",
      "[EPOCH #0, step #1070] loss: 4.799605135824166\n",
      "[EPOCH #0, step #1072] loss: 4.799720413975924\n",
      "[EPOCH #0, step #1074] loss: 4.799412098374478\n",
      "[EPOCH #0, step #1076] loss: 4.799469778243324\n",
      "[EPOCH #0, step #1078] loss: 4.799423900547682\n",
      "[EPOCH #0, step #1080] loss: 4.799501064416989\n",
      "[EPOCH #0, step #1082] loss: 4.799515414656255\n",
      "[EPOCH #0, step #1084] loss: 4.7995476133812405\n",
      "[EPOCH #0, step #1086] loss: 4.7993406587055\n",
      "[EPOCH #0, step #1088] loss: 4.799357158969147\n",
      "[EPOCH #0, step #1090] loss: 4.7994427414360015\n",
      "[EPOCH #0, step #1092] loss: 4.799709114587754\n",
      "[EPOCH #0, step #1094] loss: 4.7996511119685765\n",
      "[EPOCH #0, step #1096] loss: 4.799657233976296\n",
      "[EPOCH #0, step #1098] loss: 4.799822692766962\n",
      "[EPOCH #0, step #1100] loss: 4.7997876824734975\n",
      "[EPOCH #0, step #1102] loss: 4.799982895768997\n",
      "[EPOCH #0, step #1104] loss: 4.799848701080046\n",
      "[EPOCH #0, step #1106] loss: 4.799651058062628\n",
      "[EPOCH #0, step #1108] loss: 4.799369725587671\n",
      "[EPOCH #0, step #1110] loss: 4.799247047259505\n",
      "[EPOCH #0, step #1112] loss: 4.799358259528367\n",
      "[EPOCH #0, step #1114] loss: 4.799404476148665\n",
      "[EPOCH #0, step #1116] loss: 4.799586331086599\n",
      "[EPOCH #0, step #1118] loss: 4.799795087263774\n",
      "[EPOCH #0, step #1120] loss: 4.799767493350925\n",
      "[EPOCH #0, step #1122] loss: 4.799724736387774\n",
      "[EPOCH #0, step #1124] loss: 4.799879878573948\n",
      "[EPOCH #0, step #1126] loss: 4.799627754258814\n",
      "[EPOCH #0, step #1128] loss: 4.799665534253454\n",
      "[EPOCH #0, step #1130] loss: 4.799655157101038\n",
      "[EPOCH #0, step #1132] loss: 4.79947979767977\n",
      "[EPOCH #0, step #1134] loss: 4.799248492455168\n",
      "[EPOCH #0, step #1136] loss: 4.799265749536278\n",
      "[EPOCH #0, step #1138] loss: 4.799325507601905\n",
      "[EPOCH #0, step #1140] loss: 4.7994400922088225\n",
      "[EPOCH #0, step #1142] loss: 4.7994587194053935\n",
      "[EPOCH #0, step #1144] loss: 4.799340147743059\n",
      "[EPOCH #0, step #1146] loss: 4.799596144203113\n",
      "[EPOCH #0, step #1148] loss: 4.799818487972462\n",
      "[EPOCH #0, step #1150] loss: 4.800063632033785\n",
      "[EPOCH #0, step #1152] loss: 4.80001187924189\n",
      "[EPOCH #0, step #1154] loss: 4.800046827473166\n",
      "[EPOCH #0, step #1156] loss: 4.800169906847005\n",
      "[EPOCH #0, step #1158] loss: 4.800343921207168\n",
      "[EPOCH #0, step #1160] loss: 4.800269399605159\n",
      "[EPOCH #0, step #1162] loss: 4.800365271695401\n",
      "[EPOCH #0, step #1164] loss: 4.8004391752087505\n",
      "[EPOCH #0, step #1166] loss: 4.800340882508083\n",
      "[EPOCH #0, step #1168] loss: 4.800222371560677\n",
      "[EPOCH #0, step #1170] loss: 4.800363135480351\n",
      "[EPOCH #0, step #1172] loss: 4.800126634696967\n",
      "[EPOCH #0, step #1174] loss: 4.800057480994691\n",
      "[EPOCH #0, step #1176] loss: 4.80027057077283\n",
      "[EPOCH #0, step #1178] loss: 4.800202836416049\n",
      "[EPOCH #0, step #1180] loss: 4.80007124027895\n",
      "[EPOCH #0, step #1182] loss: 4.8001123877369745\n",
      "[EPOCH #0, step #1184] loss: 4.799910893420127\n",
      "[EPOCH #0, step #1186] loss: 4.800015516208819\n",
      "[EPOCH #0, step #1188] loss: 4.8001291938345405\n",
      "[EPOCH #0, step #1190] loss: 4.800111840694117\n",
      "[EPOCH #0, step #1192] loss: 4.800192402074643\n",
      "[EPOCH #0, step #1194] loss: 4.800288101020717\n",
      "[EPOCH #0, step #1196] loss: 4.8001951470211734\n",
      "[EPOCH #0, step #1198] loss: 4.800366425931801\n",
      "[EPOCH #0, step #1200] loss: 4.8004852234572795\n",
      "[EPOCH #0, step #1202] loss: 4.800326863032822\n",
      "[EPOCH #0, step #1204] loss: 4.800193536924623\n",
      "[EPOCH #0, step #1206] loss: 4.799741040998584\n",
      "[EPOCH #0, step #1208] loss: 4.7997243863871715\n",
      "[EPOCH #0, step #1210] loss: 4.799994671078973\n",
      "[EPOCH #0, step #1212] loss: 4.799952503481092\n",
      "[EPOCH #0, step #1214] loss: 4.799934834609797\n",
      "[EPOCH #0, step #1216] loss: 4.799785378141881\n",
      "[EPOCH #0, step #1218] loss: 4.799648890053278\n",
      "[EPOCH #0, step #1220] loss: 4.799456195690708\n",
      "[EPOCH #0, step #1222] loss: 4.799416236378381\n",
      "[EPOCH #0, step #1224] loss: 4.799694785682522\n",
      "[EPOCH #0, step #1226] loss: 4.79957248451463\n",
      "[EPOCH #0, step #1228] loss: 4.799675237657191\n",
      "[EPOCH #0, step #1230] loss: 4.799575503912522\n",
      "[EPOCH #0, step #1232] loss: 4.799535667035798\n",
      "[EPOCH #0, step #1234] loss: 4.799590494565153\n",
      "[EPOCH #0, step #1236] loss: 4.7997005380925\n",
      "[EPOCH #0, step #1238] loss: 4.799849820002324\n",
      "[EPOCH #0, step #1240] loss: 4.799651377245268\n",
      "[EPOCH #0, step #1242] loss: 4.799855153597082\n",
      "[EPOCH #0, step #1244] loss: 4.799811800225193\n",
      "[EPOCH #0, step #1246] loss: 4.7999754009384485\n",
      "[EPOCH #0, step #1248] loss: 4.799916296409931\n",
      "[EPOCH #0, step #1250] loss: 4.799873853663651\n",
      "[EPOCH #0, step #1252] loss: 4.799638016739562\n",
      "[EPOCH #0, step #1254] loss: 4.799704444930848\n",
      "[EPOCH #0, step #1256] loss: 4.799538132493801\n",
      "[EPOCH #0, step #1258] loss: 4.799530860258531\n",
      "[EPOCH #0, step #1260] loss: 4.799354520324296\n",
      "[EPOCH #0, step #1262] loss: 4.799173982957008\n",
      "[EPOCH #0, step #1264] loss: 4.7991188181247635\n",
      "[EPOCH #0, step #1266] loss: 4.799222884821722\n",
      "[EPOCH #0, step #1268] loss: 4.799248942622432\n",
      "[EPOCH #0, step #1270] loss: 4.799436065739857\n",
      "[EPOCH #0, step #1272] loss: 4.7993505602265\n",
      "[EPOCH #0, step #1274] loss: 4.799271745494767\n",
      "[EPOCH #0, step #1276] loss: 4.799290456152\n",
      "[EPOCH #0, step #1278] loss: 4.799447795951432\n",
      "[EPOCH #0, step #1280] loss: 4.7995911984588835\n",
      "[EPOCH #0, step #1282] loss: 4.7999046608886955\n",
      "[EPOCH #0, step #1284] loss: 4.799930032960172\n",
      "[EPOCH #0, step #1286] loss: 4.799937533146666\n",
      "[EPOCH #0, step #1288] loss: 4.799873454890758\n",
      "[EPOCH #0, step #1290] loss: 4.7998363870137615\n",
      "[EPOCH #0, step #1292] loss: 4.799976527736986\n",
      "[EPOCH #0, step #1294] loss: 4.800110427753346\n",
      "[EPOCH #0, step #1296] loss: 4.800089087592885\n",
      "[EPOCH #0, step #1298] loss: 4.79998647331549\n",
      "[EPOCH #0, step #1300] loss: 4.800256954533242\n",
      "[EPOCH #0, step #1302] loss: 4.800255595768586\n",
      "[EPOCH #0, step #1304] loss: 4.800066594602504\n",
      "[EPOCH #0, step #1306] loss: 4.800048452711507\n",
      "[EPOCH #0, step #1308] loss: 4.800224685960366\n",
      "[EPOCH #0, step #1310] loss: 4.800220578249678\n",
      "[EPOCH #0, step #1312] loss: 4.8001701423255705\n",
      "[EPOCH #0, step #1314] loss: 4.800438572336059\n",
      "[EPOCH #0, step #1316] loss: 4.800586283342714\n",
      "[EPOCH #0, step #1318] loss: 4.800510517117469\n",
      "[EPOCH #0, step #1320] loss: 4.800590545818897\n",
      "[EPOCH #0, step #1322] loss: 4.800688703944984\n",
      "[EPOCH #0, step #1324] loss: 4.800942362299505\n",
      "[EPOCH #0, step #1326] loss: 4.801239920632679\n",
      "[EPOCH #0, step #1328] loss: 4.801065384668906\n",
      "[EPOCH #0, step #1330] loss: 4.801106590153489\n",
      "[EPOCH #0, step #1332] loss: 4.800940155535825\n",
      "[EPOCH #0, step #1334] loss: 4.8008265145262525\n",
      "[EPOCH #0, step #1336] loss: 4.800979322163847\n",
      "[EPOCH #0, step #1338] loss: 4.80083150058829\n",
      "[EPOCH #0, step #1340] loss: 4.800794675757332\n",
      "[EPOCH #0, step #1342] loss: 4.800833662321384\n",
      "[EPOCH #0, step #1344] loss: 4.801080726070475\n",
      "[EPOCH #0, step #1346] loss: 4.801112651824951\n",
      "[EPOCH #0, step #1348] loss: 4.801169043739607\n",
      "[EPOCH #0, step #1350] loss: 4.801420238616288\n",
      "[EPOCH #0, step #1352] loss: 4.801362623396575\n",
      "[EPOCH #0, step #1354] loss: 4.801331522543932\n",
      "[EPOCH #0, step #1356] loss: 4.801633140490876\n",
      "[EPOCH #0, step #1358] loss: 4.8018554493817796\n",
      "[EPOCH #0, step #1360] loss: 4.801833711942271\n",
      "[EPOCH #0, step #1362] loss: 4.801742046087521\n",
      "[EPOCH #0, step #1364] loss: 4.801752809028486\n",
      "[EPOCH #0, step #1366] loss: 4.801724017058835\n",
      "[EPOCH #0, step #1368] loss: 4.801366275901599\n",
      "[EPOCH #0, step #1370] loss: 4.801230118276428\n",
      "[EPOCH #0, step #1372] loss: 4.80116493894684\n",
      "[EPOCH #0, step #1374] loss: 4.801208632035689\n",
      "[EPOCH #0, step #1376] loss: 4.8008356572236375\n",
      "[EPOCH #0, step #1378] loss: 4.800831747712045\n",
      "[EPOCH #0, step #1380] loss: 4.801030150019199\n",
      "[EPOCH #0, step #1382] loss: 4.801147650569052\n",
      "[EPOCH #0, step #1384] loss: 4.80125494313154\n",
      "[EPOCH #0, step #1386] loss: 4.801297934861517\n",
      "[EPOCH #0, step #1388] loss: 4.80115845359599\n",
      "[EPOCH #0, step #1390] loss: 4.801062550328774\n",
      "[EPOCH #0, step #1392] loss: 4.801052777440276\n",
      "[EPOCH #0, step #1394] loss: 4.801018306773196\n",
      "[EPOCH #0, step #1396] loss: 4.80114004896979\n",
      "[EPOCH #0, step #1398] loss: 4.80129760635845\n",
      "[EPOCH #0, step #1400] loss: 4.801273898343203\n",
      "[EPOCH #0, step #1402] loss: 4.8013132391703275\n",
      "[EPOCH #0, step #1404] loss: 4.801389120651733\n",
      "[EPOCH #0, step #1406] loss: 4.801302572303235\n",
      "[EPOCH #0, step #1408] loss: 4.801190019584531\n",
      "[EPOCH #0, step #1410] loss: 4.801208618091067\n",
      "[EPOCH #0, step #1412] loss: 4.801074777860972\n",
      "[EPOCH #0, step #1414] loss: 4.800989639632694\n",
      "[EPOCH #0, step #1416] loss: 4.800975318012224\n",
      "[EPOCH #0, step #1418] loss: 4.801109896653802\n",
      "[EPOCH #0, step #1420] loss: 4.800865012268883\n",
      "[EPOCH #0, step #1422] loss: 4.800831223070328\n",
      "[EPOCH #0, step #1424] loss: 4.800946389583119\n",
      "[EPOCH #0, step #1426] loss: 4.800920221466407\n",
      "[EPOCH #0, step #1428] loss: 4.801031038592628\n",
      "[EPOCH #0, step #1430] loss: 4.801234331937373\n",
      "[EPOCH #0, step #1432] loss: 4.801326609622825\n",
      "[EPOCH #0, step #1434] loss: 4.801543329817077\n",
      "[EPOCH #0, step #1436] loss: 4.801693714901068\n",
      "[EPOCH #0, step #1438] loss: 4.801530286286588\n",
      "[EPOCH #0, step #1440] loss: 4.801737987523605\n",
      "[EPOCH #0, step #1442] loss: 4.801620615908279\n",
      "[EPOCH #0, step #1444] loss: 4.801569947569428\n",
      "[EPOCH #0, step #1446] loss: 4.801565815517634\n",
      "[EPOCH #0, step #1448] loss: 4.801629386333205\n",
      "[EPOCH #0, step #1450] loss: 4.801490078130153\n",
      "[EPOCH #0, step #1452] loss: 4.801475072678253\n",
      "[EPOCH #0, step #1454] loss: 4.801458903112772\n",
      "[EPOCH #0, step #1456] loss: 4.801397901572998\n",
      "[EPOCH #0, step #1458] loss: 4.801440400404012\n",
      "[EPOCH #0, step #1460] loss: 4.801282155521923\n",
      "[EPOCH #0, step #1462] loss: 4.801285149541035\n",
      "[EPOCH #0, step #1464] loss: 4.801353971461794\n",
      "[EPOCH #0, step #1466] loss: 4.801495307631125\n",
      "[EPOCH #0, step #1468] loss: 4.801560245134783\n",
      "[EPOCH #0, step #1470] loss: 4.801581696212738\n",
      "[EPOCH #0, step #1472] loss: 4.8017700111793165\n",
      "[EPOCH #0, step #1474] loss: 4.80187055911048\n",
      "[EPOCH #0, step #1476] loss: 4.801653939481515\n",
      "[EPOCH #0, step #1478] loss: 4.801811881449031\n",
      "[EPOCH #0, step #1480] loss: 4.801726941077151\n",
      "[EPOCH #0, step #1482] loss: 4.801693547519573\n",
      "[EPOCH #0, step #1484] loss: 4.801713503892173\n",
      "[EPOCH #0, step #1486] loss: 4.801790276548569\n",
      "[EPOCH #0, step #1488] loss: 4.801770526342859\n",
      "[EPOCH #0, step #1490] loss: 4.80204171034252\n",
      "[EPOCH #0, step #1492] loss: 4.802155442630694\n",
      "[EPOCH #0, step #1494] loss: 4.802268494251979\n",
      "[EPOCH #0, step #1496] loss: 4.802239196015424\n",
      "[EPOCH #0, step #1498] loss: 4.802307364620949\n",
      "[EPOCH #0, step #1500] loss: 4.802060680338576\n",
      "[EPOCH #0, step #1502] loss: 4.801905743693481\n",
      "[EPOCH #0, step #1504] loss: 4.802018397511834\n",
      "[EPOCH #0, step #1506] loss: 4.801673425612421\n",
      "[EPOCH #0, step #1508] loss: 4.8015758326071\n",
      "[EPOCH #0, step #1510] loss: 4.80128974302331\n",
      "[EPOCH #0, step #1512] loss: 4.801413240766809\n",
      "[EPOCH #0, step #1514] loss: 4.801359785980124\n",
      "[EPOCH #0, step #1516] loss: 4.801368731295661\n",
      "[EPOCH #0, step #1518] loss: 4.801288836405731\n",
      "[EPOCH #0, step #1520] loss: 4.801523441236949\n",
      "[EPOCH #0, step #1522] loss: 4.801611064064291\n",
      "[EPOCH #0, step #1524] loss: 4.801905641712126\n",
      "[EPOCH #0, step #1526] loss: 4.80184975807075\n",
      "[EPOCH #0, step #1528] loss: 4.80166329270956\n",
      "[EPOCH #0, step #1530] loss: 4.801616366590105\n",
      "[EPOCH #0, step #1532] loss: 4.801657329877839\n",
      "[EPOCH #0, step #1534] loss: 4.801816349153798\n",
      "[EPOCH #0, step #1536] loss: 4.80199842198607\n",
      "[EPOCH #0, step #1538] loss: 4.802164380778113\n",
      "[EPOCH #0, step #1540] loss: 4.802040060799591\n",
      "[EPOCH #0, step #1542] loss: 4.801978900536112\n",
      "[EPOCH #0, step #1544] loss: 4.80190555023144\n",
      "[EPOCH #0, step #1546] loss: 4.8017390198143515\n",
      "[EPOCH #0, step #1548] loss: 4.801612034853695\n",
      "[EPOCH #0, step #1550] loss: 4.801564326369324\n",
      "[EPOCH #0, step #1552] loss: 4.801634444318429\n",
      "[EPOCH #0, step #1554] loss: 4.80148906401116\n",
      "[EPOCH #0, step #1556] loss: 4.801242027209214\n",
      "[EPOCH #0, step #1558] loss: 4.801376611013455\n",
      "[EPOCH #0, step #1560] loss: 4.801297416296011\n",
      "[EPOCH #0, step #1562] loss: 4.801100351683848\n",
      "[EPOCH #0, step #1564] loss: 4.801246296635832\n",
      "[EPOCH #0, step #1566] loss: 4.801145492424688\n",
      "[EPOCH #0, step #1568] loss: 4.801009501827378\n",
      "[EPOCH #0, step #1570] loss: 4.801025104401295\n",
      "[EPOCH #0, step #1572] loss: 4.800917024909503\n",
      "[EPOCH #0, step #1574] loss: 4.800916012658013\n",
      "[EPOCH #0, step #1576] loss: 4.800912572223322\n",
      "[EPOCH #0, step #1578] loss: 4.801125317755344\n",
      "[EPOCH #0, step #1580] loss: 4.801273527513343\n",
      "[EPOCH #0, step #1582] loss: 4.801219003982206\n",
      "[EPOCH #0, step #1584] loss: 4.801201255690036\n",
      "[EPOCH #0, step #1586] loss: 4.80115047700013\n",
      "[EPOCH #0, step #1588] loss: 4.8010218264998095\n",
      "[EPOCH #0, step #1590] loss: 4.800846184970896\n",
      "[EPOCH #0, step #1592] loss: 4.800788278334259\n",
      "[EPOCH #0, step #1594] loss: 4.800921184814836\n",
      "[EPOCH #0, step #1596] loss: 4.801085340730384\n",
      "[EPOCH #0, step #1598] loss: 4.800982064347926\n",
      "[EPOCH #0, step #1600] loss: 4.800910804064701\n",
      "[EPOCH #0, step #1602] loss: 4.800946934403141\n",
      "[EPOCH #0, step #1604] loss: 4.800725977591636\n",
      "[EPOCH #0, step #1606] loss: 4.800826645075496\n",
      "[EPOCH #0, step #1608] loss: 4.800766314535574\n",
      "[EPOCH #0, step #1610] loss: 4.8005510637436055\n",
      "[EPOCH #0, step #1612] loss: 4.800607878158201\n",
      "[EPOCH #0, step #1614] loss: 4.800816616849634\n",
      "[EPOCH #0, step #1616] loss: 4.800778225018201\n",
      "[EPOCH #0, step #1618] loss: 4.800661820405202\n",
      "[EPOCH #0, step #1620] loss: 4.800710695162002\n",
      "[EPOCH #0, step #1622] loss: 4.800732901708916\n",
      "[EPOCH #0, step #1624] loss: 4.800674602215107\n",
      "[EPOCH #0, step #1626] loss: 4.800821104149329\n",
      "[EPOCH #0, step #1628] loss: 4.800658449942236\n",
      "[EPOCH #0, step #1630] loss: 4.800724510471197\n",
      "[EPOCH #0, step #1632] loss: 4.800749883283813\n",
      "[EPOCH #0, step #1634] loss: 4.80073901680996\n",
      "[EPOCH #0, step #1636] loss: 4.800995842159414\n",
      "[EPOCH #0, step #1638] loss: 4.800907284548692\n",
      "[EPOCH #0, step #1640] loss: 4.801033628488153\n",
      "[EPOCH #0, step #1642] loss: 4.800918401775023\n",
      "[EPOCH #0, step #1644] loss: 4.800923150940869\n",
      "[EPOCH #0, step #1646] loss: 4.800841681509938\n",
      "[EPOCH #0, step #1648] loss: 4.800701360546364\n",
      "[EPOCH #0, step #1650] loss: 4.800463525401254\n",
      "[EPOCH #0, step #1652] loss: 4.800533864689969\n",
      "[EPOCH #0, step #1654] loss: 4.800385628149948\n",
      "[EPOCH #0, step #1656] loss: 4.800447307153862\n",
      "[EPOCH #0, step #1658] loss: 4.8006990175781805\n",
      "[EPOCH #0, step #1660] loss: 4.800823733865461\n",
      "[EPOCH #0, step #1662] loss: 4.800618594049762\n",
      "[EPOCH #0, step #1664] loss: 4.800631083812084\n",
      "[EPOCH #0, step #1666] loss: 4.800781528893959\n",
      "[EPOCH #0, step #1668] loss: 4.8008323361446505\n",
      "[EPOCH #0, step #1670] loss: 4.800917467622968\n",
      "[EPOCH #0, step #1672] loss: 4.801106279365189\n",
      "[EPOCH #0, step #1674] loss: 4.8011128493921085\n",
      "[EPOCH #0, step #1676] loss: 4.801188865017877\n",
      "[EPOCH #0, step #1678] loss: 4.801398733955824\n",
      "[EPOCH #0, step #1680] loss: 4.801383178763132\n",
      "[EPOCH #0, step #1682] loss: 4.8015017523626735\n",
      "[EPOCH #0, step #1684] loss: 4.8015318126282285\n",
      "[EPOCH #0, step #1686] loss: 4.801540163048076\n",
      "[EPOCH #0, step #1688] loss: 4.8014359217271645\n",
      "[EPOCH #0, step #1690] loss: 4.801408246027373\n",
      "[EPOCH #0, step #1692] loss: 4.801285078169253\n",
      "[EPOCH #0, step #1694] loss: 4.801323121557545\n",
      "[EPOCH #0, step #1696] loss: 4.801323490558685\n",
      "[EPOCH #0, step #1698] loss: 4.801485691721682\n",
      "[EPOCH #0, step #1700] loss: 4.801397450596777\n",
      "[EPOCH #0, step #1702] loss: 4.8015078277498295\n",
      "[EPOCH #0, step #1704] loss: 4.801562851265379\n",
      "[EPOCH #0, step #1706] loss: 4.801361802173205\n",
      "[EPOCH #0, step #1708] loss: 4.801514020923148\n",
      "[EPOCH #0, step #1710] loss: 4.801461205017072\n",
      "[EPOCH #0, step #1712] loss: 4.801296280895975\n",
      "[EPOCH #0, step #1714] loss: 4.801176035021902\n",
      "[EPOCH #0, step #1716] loss: 4.801221074374804\n",
      "[EPOCH #0, step #1718] loss: 4.801282475201317\n",
      "[EPOCH #0, step #1720] loss: 4.80137279156957\n",
      "[EPOCH #0, step #1722] loss: 4.801546827970517\n",
      "[EPOCH #0, step #1724] loss: 4.801410143479057\n",
      "[EPOCH #0, step #1726] loss: 4.801229330591887\n",
      "[EPOCH #0, step #1728] loss: 4.801437420952589\n",
      "[EPOCH #0, step #1730] loss: 4.801300081333489\n",
      "[EPOCH #0, step #1732] loss: 4.801247880971989\n",
      "[EPOCH #0, step #1734] loss: 4.801186008068601\n",
      "[EPOCH #0, step #1736] loss: 4.80118681194457\n",
      "[EPOCH #0, step #1738] loss: 4.801029550816699\n",
      "[EPOCH #0, step #1740] loss: 4.801087022033113\n",
      "[EPOCH #0, step #1742] loss: 4.8011705950629215\n",
      "[EPOCH #0, step #1744] loss: 4.801103480429226\n",
      "[EPOCH #0, step #1746] loss: 4.801160859324691\n",
      "[EPOCH #0, step #1748] loss: 4.801325205600623\n",
      "[EPOCH #0, step #1750] loss: 4.8013768555572005\n",
      "[EPOCH #0, step #1752] loss: 4.80143556333717\n",
      "[EPOCH #0, step #1754] loss: 4.8012514448573445\n",
      "[EPOCH #0, step #1756] loss: 4.801351086144836\n",
      "[EPOCH #0, step #1758] loss: 4.801308510451238\n",
      "[EPOCH #0, step #1760] loss: 4.801475833045834\n",
      "[EPOCH #0, step #1762] loss: 4.80156802968822\n",
      "[EPOCH #0, step #1764] loss: 4.801563681421469\n",
      "[EPOCH #0, step #1766] loss: 4.8014324824555015\n",
      "[EPOCH #0, step #1768] loss: 4.801418938968329\n",
      "[EPOCH #0, step #1770] loss: 4.80150315857149\n",
      "[EPOCH #0, step #1772] loss: 4.801517916344278\n",
      "[EPOCH #0, step #1774] loss: 4.801579024623817\n",
      "[EPOCH #0, step #1776] loss: 4.801577926554168\n",
      "[EPOCH #0, step #1778] loss: 4.801723451276653\n",
      "[EPOCH #0, step #1780] loss: 4.801669247427528\n",
      "[EPOCH #0, step #1782] loss: 4.8014970039692875\n",
      "[EPOCH #0, step #1784] loss: 4.8015621439081615\n",
      "[EPOCH #0, step #1786] loss: 4.801479489028154\n",
      "[EPOCH #0, step #1788] loss: 4.801414632610665\n",
      "[EPOCH #0, step #1790] loss: 4.801452450882716\n",
      "[EPOCH #0, step #1792] loss: 4.801457907989978\n",
      "[EPOCH #0, step #1794] loss: 4.801264237959073\n",
      "[EPOCH #0, step #1796] loss: 4.8013343301559726\n",
      "[EPOCH #0, step #1798] loss: 4.801415736573215\n",
      "[EPOCH #0, step #1800] loss: 4.801607005401561\n",
      "[EPOCH #0, step #1802] loss: 4.801548278140017\n",
      "[EPOCH #0, step #1804] loss: 4.801672052346438\n",
      "[EPOCH #0, step #1806] loss: 4.801743163017522\n",
      "[EPOCH #0, step #1808] loss: 4.801640816325309\n",
      "[EPOCH #0, step #1810] loss: 4.801614563613883\n",
      "[EPOCH #0, step #1812] loss: 4.801486995558152\n",
      "[EPOCH #0, step #1814] loss: 4.801419515846189\n",
      "[EPOCH #0, step #1816] loss: 4.801489129588705\n",
      "[EPOCH #0, step #1818] loss: 4.801615623014848\n",
      "[EPOCH #0, step #1820] loss: 4.80158635275106\n",
      "[EPOCH #0, step #1822] loss: 4.801603604723187\n",
      "[EPOCH #0, step #1824] loss: 4.8015915128629505\n",
      "[EPOCH #0, step #1826] loss: 4.801561840518811\n",
      "[EPOCH #0, step #1828] loss: 4.801548729704142\n",
      "[EPOCH #0, step #1830] loss: 4.801583971370445\n",
      "[EPOCH #0, step #1832] loss: 4.80159761862747\n",
      "[EPOCH #0, step #1834] loss: 4.801543142230375\n",
      "[EPOCH #0, step #1836] loss: 4.801618008102226\n",
      "[EPOCH #0, step #1838] loss: 4.801658983526183\n",
      "[EPOCH #0, step #1840] loss: 4.801699176552113\n",
      "[EPOCH #0, step #1842] loss: 4.801631354664695\n",
      "[EPOCH #0, step #1844] loss: 4.801845435786054\n",
      "[EPOCH #0, step #1846] loss: 4.801902034441458\n",
      "[EPOCH #0, step #1848] loss: 4.80182512416396\n",
      "[EPOCH #0, step #1850] loss: 4.801926595594096\n",
      "[EPOCH #0, step #1852] loss: 4.801884512224522\n",
      "[EPOCH #0, step #1854] loss: 4.801857889437612\n",
      "[EPOCH #0, step #1856] loss: 4.801798326967863\n",
      "[EPOCH #0, step #1858] loss: 4.801736504881532\n",
      "[EPOCH #0, step #1860] loss: 4.801688244495258\n",
      "[EPOCH #0, step #1862] loss: 4.801641547673502\n",
      "[EPOCH #0, step #1864] loss: 4.801646934182011\n",
      "[EPOCH #0, step #1866] loss: 4.801780125516331\n",
      "[EPOCH #0, step #1868] loss: 4.801848084228826\n",
      "[EPOCH #0, step #1870] loss: 4.801888765592998\n",
      "[EPOCH #0, step #1872] loss: 4.801824191898442\n",
      "[EPOCH #0, step #1874] loss: 4.801975166575114\n",
      "[EPOCH #0, step #1876] loss: 4.801891629214483\n",
      "[EPOCH #0, step #1878] loss: 4.801941315121572\n",
      "[EPOCH #0, step #1880] loss: 4.801944609971074\n",
      "[EPOCH #0, step #1882] loss: 4.801930400455372\n",
      "[EPOCH #0, step #1884] loss: 4.801933950581032\n",
      "[EPOCH #0, step #1886] loss: 4.801997250201655\n",
      "[EPOCH #0, step #1888] loss: 4.802043580579783\n",
      "[EPOCH #0, step #1890] loss: 4.8018472223670186\n",
      "[EPOCH #0, step #1892] loss: 4.801840552941115\n",
      "[EPOCH #0, step #1894] loss: 4.80189358376576\n",
      "[EPOCH #0, step #1896] loss: 4.8017707557255935\n",
      "[EPOCH #0, step #1898] loss: 4.801876337544551\n",
      "[EPOCH #0, step #1900] loss: 4.8017888470488685\n",
      "[EPOCH #0, step #1902] loss: 4.8019180285323\n",
      "[EPOCH #0, step #1904] loss: 4.801846945755125\n",
      "[EPOCH #0, step #1906] loss: 4.801635465386905\n",
      "[EPOCH #0, step #1908] loss: 4.801683304508423\n",
      "[EPOCH #0, step #1910] loss: 4.801725141045187\n",
      "[EPOCH #0, step #1912] loss: 4.801660429290995\n",
      "[EPOCH #0, step #1914] loss: 4.801649790084082\n",
      "[EPOCH #0, step #1916] loss: 4.8016559529192575\n",
      "[EPOCH #0, step #1918] loss: 4.801761349394273\n",
      "[EPOCH #0, step #1920] loss: 4.801647378900658\n",
      "[EPOCH #0, step #1922] loss: 4.8017190803293754\n",
      "[EPOCH #0, step #1924] loss: 4.8017859468831645\n",
      "[EPOCH #0, step #1926] loss: 4.8018196993809505\n",
      "[EPOCH #0, step #1928] loss: 4.801658585381793\n",
      "[EPOCH #0, step #1930] loss: 4.801741060971103\n",
      "[EPOCH #0, step #1932] loss: 4.8018775240350005\n",
      "[EPOCH #0, step #1934] loss: 4.801982207630956\n",
      "[EPOCH #0, step #1936] loss: 4.802108346154287\n",
      "[EPOCH #0, step #1938] loss: 4.802116563481237\n",
      "[EPOCH #0, step #1940] loss: 4.802131160763598\n",
      "[EPOCH #0, step #1942] loss: 4.802186190437792\n",
      "[EPOCH #0, step #1944] loss: 4.802003293662573\n",
      "[EPOCH #0, step #1946] loss: 4.802035387320339\n",
      "[EPOCH #0, step #1948] loss: 4.8021709122616185\n",
      "[EPOCH #0, step #1950] loss: 4.802210906540535\n",
      "[EPOCH #0, step #1952] loss: 4.8020747256047045\n",
      "[EPOCH #0, step #1954] loss: 4.8021209843628245\n",
      "[EPOCH #0, step #1956] loss: 4.802343851702519\n",
      "[EPOCH #0, step #1958] loss: 4.802348863962902\n",
      "[EPOCH #0, step #1960] loss: 4.802347750520293\n",
      "[EPOCH #0, step #1962] loss: 4.802303308379085\n",
      "[EPOCH #0, step #1964] loss: 4.802379279342923\n",
      "[EPOCH #0, step #1966] loss: 4.802279068239462\n",
      "[EPOCH #0, step #1968] loss: 4.802223391312522\n",
      "[EPOCH #0, step #1970] loss: 4.802285408260011\n",
      "[EPOCH #0, step #1972] loss: 4.802432597499177\n",
      "[EPOCH #0, step #1974] loss: 4.802637306647965\n",
      "[EPOCH #0, step #1976] loss: 4.802570781505162\n",
      "[EPOCH #0, step #1978] loss: 4.8025970018048545\n",
      "[EPOCH #0, step #1980] loss: 4.802596932285546\n",
      "[EPOCH #0, step #1982] loss: 4.802616163389405\n",
      "[EPOCH #0, step #1984] loss: 4.802749421434378\n",
      "[EPOCH #0, step #1986] loss: 4.802712876771524\n",
      "[EPOCH #0, step #1988] loss: 4.802790346907994\n",
      "[EPOCH #0, step #1990] loss: 4.80283355952387\n",
      "[EPOCH #0, step #1992] loss: 4.80287262619409\n",
      "[EPOCH #0, step #1994] loss: 4.802812710621004\n",
      "[EPOCH #0, step #1996] loss: 4.802666780646586\n",
      "[EPOCH #0, step #1998] loss: 4.802589574415961\n",
      "[EPOCH #0, step #2000] loss: 4.80242534043609\n",
      "[EPOCH #0, step #2002] loss: 4.802397022352062\n",
      "[EPOCH #0, step #2004] loss: 4.802450903038729\n",
      "[EPOCH #0, step #2006] loss: 4.802496274312337\n",
      "[EPOCH #0, step #2008] loss: 4.802516231375467\n",
      "[EPOCH #0, step #2010] loss: 4.802509697203255\n",
      "[EPOCH #0, step #2012] loss: 4.802597851760341\n",
      "[EPOCH #0, step #2014] loss: 4.80274196771475\n",
      "[EPOCH #0, step #2016] loss: 4.802671369137478\n",
      "[EPOCH #0, step #2018] loss: 4.802617114862042\n",
      "[EPOCH #0, step #2020] loss: 4.802744292788196\n",
      "[EPOCH #0, step #2022] loss: 4.8028182813688725\n",
      "[EPOCH #0, step #2024] loss: 4.802880027912281\n",
      "[EPOCH #0, step #2026] loss: 4.802734329362896\n",
      "[EPOCH #0, step #2028] loss: 4.802844417923597\n",
      "[EPOCH #0, step #2030] loss: 4.802929407971531\n",
      "[EPOCH #0, step #2032] loss: 4.8029244571147265\n",
      "[EPOCH #0, step #2034] loss: 4.802988746418121\n",
      "[EPOCH #0, step #2036] loss: 4.802834025070722\n",
      "[EPOCH #0, step #2038] loss: 4.802833931769969\n",
      "[EPOCH #0, step #2040] loss: 4.8028609679061836\n",
      "[EPOCH #0, step #2042] loss: 4.802778882835638\n",
      "[EPOCH #0, step #2044] loss: 4.802823462171484\n",
      "[EPOCH #0, step #2046] loss: 4.802686259871177\n",
      "[EPOCH #0, step #2048] loss: 4.802667665737556\n",
      "[EPOCH #0, step #2050] loss: 4.802654938486249\n",
      "[EPOCH #0, step #2052] loss: 4.802593607932721\n",
      "[EPOCH #0, step #2054] loss: 4.802626385886014\n",
      "[EPOCH #0, step #2056] loss: 4.80242529666476\n",
      "[EPOCH #0, step #2058] loss: 4.802525906843025\n",
      "[EPOCH #0, step #2060] loss: 4.802452300255418\n",
      "[EPOCH #0, step #2062] loss: 4.802516988799575\n",
      "[EPOCH #0, step #2064] loss: 4.802500465476196\n",
      "[EPOCH #0, step #2066] loss: 4.802401831718707\n",
      "[EPOCH #0, step #2068] loss: 4.802424101970114\n",
      "[EPOCH #0, step #2070] loss: 4.802240763350652\n",
      "[EPOCH #0, step #2072] loss: 4.802444000262542\n",
      "[EPOCH #0, step #2074] loss: 4.802380281701145\n",
      "[EPOCH #0, step #2076] loss: 4.802231233052239\n",
      "[EPOCH #0, step #2078] loss: 4.802231097347522\n",
      "[EPOCH #0, step #2080] loss: 4.802079432632762\n",
      "[EPOCH #0, step #2082] loss: 4.802101707321145\n",
      "[EPOCH #0, step #2084] loss: 4.801949253128015\n",
      "[EPOCH #0, step #2086] loss: 4.801990046133307\n",
      "[EPOCH #0, step #2088] loss: 4.801940320381541\n",
      "[EPOCH #0, step #2090] loss: 4.801990722709156\n",
      "[EPOCH #0, step #2092] loss: 4.801992404762775\n",
      "[EPOCH #0, step #2094] loss: 4.8019960979288685\n",
      "[EPOCH #0, step #2096] loss: 4.802069429562214\n",
      "[EPOCH #0, step #2098] loss: 4.80217775133123\n",
      "[EPOCH #0, step #2100] loss: 4.802057509987426\n",
      "[EPOCH #0, step #2102] loss: 4.802028079175745\n",
      "[EPOCH #0, step #2104] loss: 4.802028001345818\n",
      "[EPOCH #0, step #2106] loss: 4.801960173182766\n",
      "[EPOCH #0, step #2108] loss: 4.802148605082599\n",
      "[EPOCH #0, step #2110] loss: 4.802162215812463\n",
      "[EPOCH #0, step #2112] loss: 4.802108216048754\n",
      "[EPOCH #0, step #2114] loss: 4.80221145868865\n",
      "[EPOCH #0, step #2116] loss: 4.802247305326322\n",
      "[EPOCH #0, step #2118] loss: 4.802376245765992\n",
      "[EPOCH #0, step #2120] loss: 4.802322427937581\n",
      "[EPOCH #0, step #2122] loss: 4.8024768279062595\n",
      "[EPOCH #0, step #2124] loss: 4.802449185090906\n",
      "[EPOCH #0, step #2126] loss: 4.802378434332312\n",
      "[EPOCH #0, step #2128] loss: 4.802370570645527\n",
      "[EPOCH #0, step #2130] loss: 4.802336682069475\n",
      "[EPOCH #0, step #2132] loss: 4.802383447665873\n",
      "[EPOCH #0, step #2134] loss: 4.802487022926992\n",
      "[EPOCH #0, step #2136] loss: 4.802414823147422\n",
      "[EPOCH #0, step #2138] loss: 4.8023845660123605\n",
      "[EPOCH #0, step #2140] loss: 4.802376903255984\n",
      "[EPOCH #0, step #2142] loss: 4.802336729301563\n",
      "[EPOCH #0, step #2144] loss: 4.80239570524309\n",
      "[EPOCH #0, step #2146] loss: 4.802396597726766\n",
      "[EPOCH #0, step #2148] loss: 4.802348438669438\n",
      "[EPOCH #0, step #2150] loss: 4.802336956832865\n",
      "[EPOCH #0, step #2152] loss: 4.802519560413919\n",
      "[EPOCH #0, step #2154] loss: 4.802303128342064\n",
      "[EPOCH #0, step #2156] loss: 4.8022080358665304\n",
      "[EPOCH #0, step #2158] loss: 4.802174575685516\n",
      "[EPOCH #0, step #2160] loss: 4.802119840024412\n",
      "[EPOCH #0, step #2162] loss: 4.802029965709769\n",
      "[EPOCH #0, step #2164] loss: 4.8020408291189005\n",
      "[EPOCH #0, step #2166] loss: 4.802075600591078\n",
      "[EPOCH #0, step #2168] loss: 4.801970533755255\n",
      "[EPOCH #0, step #2170] loss: 4.8019244801553365\n",
      "[EPOCH #0, step #2172] loss: 4.802001891682568\n",
      "[EPOCH #0, step #2174] loss: 4.80208502056955\n",
      "[EPOCH #0, step #2176] loss: 4.802095408389258\n",
      "[EPOCH #0, step #2178] loss: 4.802100502826469\n",
      "[EPOCH #0, step #2180] loss: 4.8020589153791775\n",
      "[EPOCH #0, step #2182] loss: 4.802059960157785\n",
      "[EPOCH #0, step #2184] loss: 4.802144872460267\n",
      "[EPOCH #0, step #2186] loss: 4.802134526282835\n",
      "[EPOCH #0, step #2188] loss: 4.802170093226183\n",
      "[EPOCH #0, step #2190] loss: 4.802158146130881\n",
      "[EPOCH #0, step #2192] loss: 4.802298525180982\n",
      "[EPOCH #0, step #2194] loss: 4.802339405894008\n",
      "[EPOCH #0, step #2196] loss: 4.802400396908745\n",
      "[EPOCH #0, step #2198] loss: 4.802196522418235\n",
      "[EPOCH #0, step #2200] loss: 4.802118972993233\n",
      "[EPOCH #0, step #2202] loss: 4.802126255026742\n",
      "[EPOCH #0, step #2204] loss: 4.8019769493414435\n",
      "[EPOCH #0, step #2206] loss: 4.801932005197363\n",
      "[EPOCH #0, step #2208] loss: 4.801786154845874\n",
      "[EPOCH #0, step #2210] loss: 4.801738505447574\n",
      "[EPOCH #0, step #2212] loss: 4.801723140857901\n",
      "[EPOCH #0, step #2214] loss: 4.80175570515962\n",
      "[EPOCH #0, step #2216] loss: 4.802016684317514\n",
      "[EPOCH #0, step #2218] loss: 4.802068587840812\n",
      "[EPOCH #0, step #2220] loss: 4.802074133088491\n",
      "[EPOCH #0, step #2222] loss: 4.8020240257733375\n",
      "[EPOCH #0, step #2224] loss: 4.802131978152843\n",
      "[EPOCH #0, step #2226] loss: 4.8021446385617\n",
      "[EPOCH #0, step #2228] loss: 4.802178563853452\n",
      "[EPOCH #0, step #2230] loss: 4.802192872653142\n",
      "[EPOCH #0, step #2232] loss: 4.802082482443441\n",
      "[EPOCH #0, step #2234] loss: 4.801979923034941\n",
      "[EPOCH #0, step #2236] loss: 4.801873281058532\n",
      "[EPOCH #0, step #2238] loss: 4.801949576428555\n",
      "[EPOCH #0, step #2240] loss: 4.801965135806695\n",
      "[EPOCH #0, step #2242] loss: 4.802002916365822\n",
      "[EPOCH #0, step #2244] loss: 4.801986292051048\n",
      "[EPOCH #0, step #2246] loss: 4.8019512496527215\n",
      "[EPOCH #0, step #2248] loss: 4.801897550593911\n",
      "[EPOCH #0, step #2250] loss: 4.801892391155689\n",
      "[EPOCH #0, step #2252] loss: 4.80200905531076\n",
      "[EPOCH #0, step #2254] loss: 4.802049422845608\n",
      "[EPOCH #0, step #2256] loss: 4.801991945882788\n",
      "[EPOCH #0, step #2258] loss: 4.802106221516927\n",
      "[EPOCH #0, step #2260] loss: 4.802030654672709\n",
      "[EPOCH #0, step #2262] loss: 4.802087571839026\n",
      "[EPOCH #0, step #2264] loss: 4.802128170131321\n",
      "[EPOCH #0, step #2266] loss: 4.802340307896181\n",
      "[EPOCH #0, step #2268] loss: 4.80227697867557\n",
      "[EPOCH #0, step #2270] loss: 4.802306244941285\n",
      "[EPOCH #0, step #2272] loss: 4.802426948245276\n",
      "[EPOCH #0, step #2274] loss: 4.802387602041056\n",
      "[EPOCH #0, step #2276] loss: 4.8024035025752845\n",
      "[EPOCH #0, step #2278] loss: 4.802386632662376\n",
      "[EPOCH #0, step #2280] loss: 4.80241790104205\n",
      "[EPOCH #0, step #2282] loss: 4.8025436670802115\n",
      "[EPOCH #0, step #2284] loss: 4.802653615479918\n",
      "[EPOCH #0, step #2286] loss: 4.802796826281296\n",
      "[EPOCH #0, step #2288] loss: 4.802826739961583\n",
      "[EPOCH #0, step #2290] loss: 4.802846391978403\n",
      "[EPOCH #0, step #2292] loss: 4.802829994887075\n",
      "[EPOCH #0, step #2294] loss: 4.802908943940871\n",
      "[EPOCH #0, step #2296] loss: 4.802806591229902\n",
      "[EPOCH #0, step #2298] loss: 4.802944656453375\n",
      "[EPOCH #0, step #2300] loss: 4.802884749462686\n",
      "[EPOCH #0, step #2302] loss: 4.802962958890357\n",
      "[EPOCH #0, step #2304] loss: 4.802962198278133\n",
      "[EPOCH #0, step #2306] loss: 4.802965944444766\n",
      "[EPOCH #0, step #2308] loss: 4.802969431763555\n",
      "[EPOCH #0, step #2310] loss: 4.803015777838793\n",
      "[EPOCH #0, step #2312] loss: 4.803061490444409\n",
      "[EPOCH #0, step #2314] loss: 4.803020498304593\n",
      "[EPOCH #0, step #2316] loss: 4.803158695449796\n",
      "[EPOCH #0, step #2318] loss: 4.80322592687175\n",
      "[EPOCH #0, step #2320] loss: 4.803252411628272\n",
      "[EPOCH #0, step #2322] loss: 4.803336677395266\n",
      "[EPOCH #0, step #2324] loss: 4.803280872427007\n",
      "[EPOCH #0, step #2326] loss: 4.803340879898498\n",
      "[EPOCH #0, step #2328] loss: 4.803393983697625\n",
      "[EPOCH #0, step #2330] loss: 4.803308719936127\n",
      "[EPOCH #0, step #2332] loss: 4.803293953931132\n",
      "[EPOCH #0, step #2334] loss: 4.803355222902155\n",
      "[EPOCH #0, step #2336] loss: 4.8032135583928985\n",
      "[EPOCH #0, step #2338] loss: 4.80324666629545\n",
      "[EPOCH #0, step #2340] loss: 4.803305124431938\n",
      "[EPOCH #0, step #2342] loss: 4.80318442298671\n",
      "[EPOCH #0, step #2344] loss: 4.8030775495175355\n",
      "[EPOCH #0, step #2346] loss: 4.803074400527557\n",
      "[EPOCH #0, step #2348] loss: 4.802905223175737\n",
      "[EPOCH #0, step #2350] loss: 4.802984220633756\n",
      "[EPOCH #0, step #2352] loss: 4.802899538786726\n",
      "[EPOCH #0, step #2354] loss: 4.80290313323845\n",
      "[EPOCH #0, step #2356] loss: 4.802807104096961\n",
      "[EPOCH #0, step #2358] loss: 4.802805198557855\n",
      "[EPOCH #0, step #2360] loss: 4.802805906632653\n",
      "[EPOCH #0, step #2362] loss: 4.802839951549503\n",
      "[EPOCH #0, step #2364] loss: 4.802809748337082\n",
      "[EPOCH #0, step #2366] loss: 4.802632673510933\n",
      "[EPOCH #0, step #2368] loss: 4.8025682221086985\n",
      "[EPOCH #0, step #2370] loss: 4.8025965101353885\n",
      "[EPOCH #0, step #2372] loss: 4.802504639559238\n",
      "[EPOCH #0, step #2374] loss: 4.802572518398887\n",
      "[EPOCH #0, step #2376] loss: 4.802731066227561\n",
      "[EPOCH #0, step #2378] loss: 4.802680403808427\n",
      "[EPOCH #0, step #2380] loss: 4.802580591712064\n",
      "[EPOCH #0, step #2382] loss: 4.80265721562426\n",
      "[EPOCH #0, step #2384] loss: 4.802857366198014\n",
      "[EPOCH #0, step #2386] loss: 4.802896888175169\n",
      "[EPOCH #0, step #2388] loss: 4.80285137654748\n",
      "[EPOCH #0, step #2390] loss: 4.8028799549200105\n",
      "[EPOCH #0, step #2392] loss: 4.802858187073302\n",
      "[EPOCH #0, step #2394] loss: 4.803014478703381\n",
      "[EPOCH #0, step #2396] loss: 4.803074585083479\n",
      "[EPOCH #0, step #2398] loss: 4.803087047856765\n",
      "[EPOCH #0, step #2400] loss: 4.803094990995217\n",
      "[EPOCH #0, step #2402] loss: 4.8030967726292735\n",
      "[EPOCH #0, step #2404] loss: 4.8030068692942915\n",
      "[EPOCH #0, step #2406] loss: 4.803236986523998\n",
      "[EPOCH #0, step #2408] loss: 4.80319750284248\n",
      "[EPOCH #0, step #2410] loss: 4.803204545535669\n",
      "[EPOCH #0, step #2412] loss: 4.803279394536309\n",
      "[EPOCH #0, step #2414] loss: 4.803248900458926\n",
      "[EPOCH #0, step #2416] loss: 4.803174533378402\n",
      "[EPOCH #0, step #2418] loss: 4.803144071357415\n",
      "[EPOCH #0, step #2420] loss: 4.803240324041657\n",
      "[EPOCH #0, step #2422] loss: 4.803252716670586\n",
      "[EPOCH #0, step #2424] loss: 4.8032939810605395\n",
      "[EPOCH #0, step #2426] loss: 4.8030678474416835\n",
      "[EPOCH #0, step #2428] loss: 4.8029333093422535\n",
      "[EPOCH #0, step #2430] loss: 4.80284559162788\n",
      "[EPOCH #0, step #2432] loss: 4.802755398560198\n",
      "[EPOCH #0, step #2434] loss: 4.802813904192414\n",
      "[EPOCH #0, step #2436] loss: 4.802785485016796\n",
      "[EPOCH #0, step #2438] loss: 4.802854469341545\n",
      "[EPOCH #0, step #2440] loss: 4.8028652542001735\n",
      "[EPOCH #0, step #2442] loss: 4.802791595458984\n",
      "[EPOCH #0, step #2444] loss: 4.802815280906506\n",
      "[EPOCH #0, step #2446] loss: 4.802818121011763\n",
      "[EPOCH #0, step #2448] loss: 4.802807436811043\n",
      "[EPOCH #0, step #2450] loss: 4.802734328503027\n",
      "[EPOCH #0, step #2452] loss: 4.802600777008268\n",
      "[EPOCH #0, step #2454] loss: 4.802636553653632\n",
      "[EPOCH #0, step #2456] loss: 4.802665291251717\n",
      "[EPOCH #0, step #2458] loss: 4.802689167579629\n",
      "[EPOCH #0, step #2460] loss: 4.8026669098080195\n",
      "[EPOCH #0, step #2462] loss: 4.802628378533175\n",
      "[EPOCH #0, step #2464] loss: 4.802677326511901\n",
      "[EPOCH #0, step #2466] loss: 4.802566983895984\n",
      "[EPOCH #0, step #2468] loss: 4.802585951950735\n",
      "[EPOCH #0, step #2470] loss: 4.802520741725537\n",
      "[EPOCH #0, step #2472] loss: 4.802349390214241\n",
      "[EPOCH #0, step #2474] loss: 4.8023569263111465\n",
      "[EPOCH #0, step #2476] loss: 4.802460288924462\n",
      "[EPOCH #0, step #2478] loss: 4.8025156346575395\n",
      "[EPOCH #0, step #2480] loss: 4.802606668168621\n",
      "[EPOCH #0, step #2482] loss: 4.802644432143151\n",
      "[EPOCH #0, step #2484] loss: 4.802646509550467\n",
      "[EPOCH #0, step #2486] loss: 4.80260410508239\n",
      "[EPOCH #0, step #2488] loss: 4.802614986585201\n",
      "[EPOCH #0, step #2490] loss: 4.802496332951886\n",
      "[EPOCH #0, step #2492] loss: 4.802442332993441\n",
      "[EPOCH #0, step #2494] loss: 4.802382582318568\n",
      "[EPOCH #0, step #2496] loss: 4.80229624281132\n",
      "[EPOCH #0, step #2498] loss: 4.802299752908976\n",
      "[EPOCH #0] loss: 4.802287447357178\n",
      "[EPOCH #1, step #0] loss: 4.728654861450195\n",
      "[EPOCH #1, step #2] loss: 4.770167350769043\n",
      "[EPOCH #1, step #4] loss: 4.764125919342041\n",
      "[EPOCH #1, step #6] loss: 4.725754261016846\n",
      "[EPOCH #1, step #8] loss: 4.7301375601026745\n",
      "[EPOCH #1, step #10] loss: 4.691607648676092\n",
      "[EPOCH #1, step #12] loss: 4.704535924471342\n",
      "[EPOCH #1, step #14] loss: 4.71158135732015\n",
      "[EPOCH #1, step #16] loss: 4.715088788200827\n",
      "[EPOCH #1, step #18] loss: 4.706333913301167\n",
      "[EPOCH #1, step #20] loss: 4.7251346451895575\n",
      "[EPOCH #1, step #22] loss: 4.7117640039195186\n",
      "[EPOCH #1, step #24] loss: 4.718460311889649\n",
      "[EPOCH #1, step #26] loss: 4.713012077190258\n",
      "[EPOCH #1, step #28] loss: 4.717062654166386\n",
      "[EPOCH #1, step #30] loss: 4.712766878066525\n",
      "[EPOCH #1, step #32] loss: 4.713117238247033\n",
      "[EPOCH #1, step #34] loss: 4.7227767535618375\n",
      "[EPOCH #1, step #36] loss: 4.7243892308827995\n",
      "[EPOCH #1, step #38] loss: 4.7265849724794045\n",
      "[EPOCH #1, step #40] loss: 4.717606102547994\n",
      "[EPOCH #1, step #42] loss: 4.722874053688937\n",
      "[EPOCH #1, step #44] loss: 4.713625600602891\n",
      "[EPOCH #1, step #46] loss: 4.714822160436752\n",
      "[EPOCH #1, step #48] loss: 4.715653974182752\n",
      "[EPOCH #1, step #50] loss: 4.712974211748908\n",
      "[EPOCH #1, step #52] loss: 4.714077859554651\n",
      "[EPOCH #1, step #54] loss: 4.718550994179465\n",
      "[EPOCH #1, step #56] loss: 4.7192275900589795\n",
      "[EPOCH #1, step #58] loss: 4.722339403831352\n",
      "[EPOCH #1, step #60] loss: 4.718936412060847\n",
      "[EPOCH #1, step #62] loss: 4.717816231742738\n",
      "[EPOCH #1, step #64] loss: 4.717476294590877\n",
      "[EPOCH #1, step #66] loss: 4.714156898099985\n",
      "[EPOCH #1, step #68] loss: 4.711658021678096\n",
      "[EPOCH #1, step #70] loss: 4.710767651947451\n",
      "[EPOCH #1, step #72] loss: 4.70778713487599\n",
      "[EPOCH #1, step #74] loss: 4.706591777801513\n",
      "[EPOCH #1, step #76] loss: 4.703707335831283\n",
      "[EPOCH #1, step #78] loss: 4.70030756841732\n",
      "[EPOCH #1, step #80] loss: 4.699690830560378\n",
      "[EPOCH #1, step #82] loss: 4.696604338036963\n",
      "[EPOCH #1, step #84] loss: 4.694462697646197\n",
      "[EPOCH #1, step #86] loss: 4.69055053009384\n",
      "[EPOCH #1, step #88] loss: 4.690371663382884\n",
      "[EPOCH #1, step #90] loss: 4.693145841032594\n",
      "[EPOCH #1, step #92] loss: 4.692864571848223\n",
      "[EPOCH #1, step #94] loss: 4.693750858306885\n",
      "[EPOCH #1, step #96] loss: 4.693959727729719\n",
      "[EPOCH #1, step #98] loss: 4.6957573457197705\n",
      "[EPOCH #1, step #100] loss: 4.696118756095962\n",
      "[EPOCH #1, step #102] loss: 4.693204620509472\n",
      "[EPOCH #1, step #104] loss: 4.690228830065046\n",
      "[EPOCH #1, step #106] loss: 4.688750409634314\n",
      "[EPOCH #1, step #108] loss: 4.690240754993684\n",
      "[EPOCH #1, step #110] loss: 4.690289836746079\n",
      "[EPOCH #1, step #112] loss: 4.6888984114722865\n",
      "[EPOCH #1, step #114] loss: 4.687616215581479\n",
      "[EPOCH #1, step #116] loss: 4.686006819081102\n",
      "[EPOCH #1, step #118] loss: 4.685949794384611\n",
      "[EPOCH #1, step #120] loss: 4.684558210294108\n",
      "[EPOCH #1, step #122] loss: 4.682125580020067\n",
      "[EPOCH #1, step #124] loss: 4.680542980194092\n",
      "[EPOCH #1, step #126] loss: 4.678510042626088\n",
      "[EPOCH #1, step #128] loss: 4.678220253582149\n",
      "[EPOCH #1, step #130] loss: 4.6768370038680445\n",
      "[EPOCH #1, step #132] loss: 4.676444491049401\n",
      "[EPOCH #1, step #134] loss: 4.67429385361848\n",
      "[EPOCH #1, step #136] loss: 4.673663682311121\n",
      "[EPOCH #1, step #138] loss: 4.673142364556841\n",
      "[EPOCH #1, step #140] loss: 4.67247297408733\n",
      "[EPOCH #1, step #142] loss: 4.6710237656439935\n",
      "[EPOCH #1, step #144] loss: 4.670794296264648\n",
      "[EPOCH #1, step #146] loss: 4.669575590665649\n",
      "[EPOCH #1, step #148] loss: 4.66977274337871\n",
      "[EPOCH #1, step #150] loss: 4.669957678839071\n",
      "[EPOCH #1, step #152] loss: 4.667767851960425\n",
      "[EPOCH #1, step #154] loss: 4.665854844739361\n",
      "[EPOCH #1, step #156] loss: 4.664541496592722\n",
      "[EPOCH #1, step #158] loss: 4.663997146318543\n",
      "[EPOCH #1, step #160] loss: 4.66362514555084\n",
      "[EPOCH #1, step #162] loss: 4.661738846199644\n",
      "[EPOCH #1, step #164] loss: 4.661783255952777\n",
      "[EPOCH #1, step #166] loss: 4.659531750364931\n",
      "[EPOCH #1, step #168] loss: 4.659225940704346\n",
      "[EPOCH #1, step #170] loss: 4.6576009800559595\n",
      "[EPOCH #1, step #172] loss: 4.656099493103909\n",
      "[EPOCH #1, step #174] loss: 4.655403314317976\n",
      "[EPOCH #1, step #176] loss: 4.653984754099011\n",
      "[EPOCH #1, step #178] loss: 4.65407041464438\n",
      "[EPOCH #1, step #180] loss: 4.651379933014759\n",
      "[EPOCH #1, step #182] loss: 4.648974754771248\n",
      "[EPOCH #1, step #184] loss: 4.648392509769749\n",
      "[EPOCH #1, step #186] loss: 4.6467478874532935\n",
      "[EPOCH #1, step #188] loss: 4.646468278592225\n",
      "[EPOCH #1, step #190] loss: 4.647030206250895\n",
      "[EPOCH #1, step #192] loss: 4.645279400089244\n",
      "[EPOCH #1, step #194] loss: 4.644809040656456\n",
      "[EPOCH #1, step #196] loss: 4.64404482042729\n",
      "[EPOCH #1, step #198] loss: 4.644030532645221\n",
      "[EPOCH #1, step #200] loss: 4.643490119953061\n",
      "[EPOCH #1, step #202] loss: 4.6420503437812695\n",
      "[EPOCH #1, step #204] loss: 4.639962170763714\n",
      "[EPOCH #1, step #206] loss: 4.63894782319737\n",
      "[EPOCH #1, step #208] loss: 4.639560441651413\n",
      "[EPOCH #1, step #210] loss: 4.638019925610149\n",
      "[EPOCH #1, step #212] loss: 4.636962857044918\n",
      "[EPOCH #1, step #214] loss: 4.6361298228419106\n",
      "[EPOCH #1, step #216] loss: 4.635164005965132\n",
      "[EPOCH #1, step #218] loss: 4.634582310506742\n",
      "[EPOCH #1, step #220] loss: 4.633202065170081\n",
      "[EPOCH #1, step #222] loss: 4.632857063960602\n",
      "[EPOCH #1, step #224] loss: 4.631672412024604\n",
      "[EPOCH #1, step #226] loss: 4.63175617125591\n",
      "[EPOCH #1, step #228] loss: 4.631096350574077\n",
      "[EPOCH #1, step #230] loss: 4.63056738139231\n",
      "[EPOCH #1, step #232] loss: 4.629538855327557\n",
      "[EPOCH #1, step #234] loss: 4.627988667183734\n",
      "[EPOCH #1, step #236] loss: 4.626861493798751\n",
      "[EPOCH #1, step #238] loss: 4.6265694506497566\n",
      "[EPOCH #1, step #240] loss: 4.625870948015901\n",
      "[EPOCH #1, step #242] loss: 4.62610522219183\n",
      "[EPOCH #1, step #244] loss: 4.625234092011744\n",
      "[EPOCH #1, step #246] loss: 4.624626186695176\n",
      "[EPOCH #1, step #248] loss: 4.6255549963219575\n",
      "[EPOCH #1, step #250] loss: 4.623461383272452\n",
      "[EPOCH #1, step #252] loss: 4.622589701249194\n",
      "[EPOCH #1, step #254] loss: 4.621524764042275\n",
      "[EPOCH #1, step #256] loss: 4.621137374106084\n",
      "[EPOCH #1, step #258] loss: 4.62044163744422\n",
      "[EPOCH #1, step #260] loss: 4.619064696447146\n",
      "[EPOCH #1, step #262] loss: 4.618512255157355\n",
      "[EPOCH #1, step #264] loss: 4.61867049235218\n",
      "[EPOCH #1, step #266] loss: 4.617021403509133\n",
      "[EPOCH #1, step #268] loss: 4.6153880176047855\n",
      "[EPOCH #1, step #270] loss: 4.61378977483489\n",
      "[EPOCH #1, step #272] loss: 4.613089091611869\n",
      "[EPOCH #1, step #274] loss: 4.611967145746404\n",
      "[EPOCH #1, step #276] loss: 4.610973645633739\n",
      "[EPOCH #1, step #278] loss: 4.610504469991158\n",
      "[EPOCH #1, step #280] loss: 4.6098338446158955\n",
      "[EPOCH #1, step #282] loss: 4.609118037004774\n",
      "[EPOCH #1, step #284] loss: 4.608430649941428\n",
      "[EPOCH #1, step #286] loss: 4.608145665624001\n",
      "[EPOCH #1, step #288] loss: 4.6078118139484765\n",
      "[EPOCH #1, step #290] loss: 4.606423124005294\n",
      "[EPOCH #1, step #292] loss: 4.6060542327958975\n",
      "[EPOCH #1, step #294] loss: 4.605344009399414\n",
      "[EPOCH #1, step #296] loss: 4.604805931900486\n",
      "[EPOCH #1, step #298] loss: 4.604406723609338\n",
      "[EPOCH #1, step #300] loss: 4.605313796933704\n",
      "[EPOCH #1, step #302] loss: 4.604095896478533\n",
      "[EPOCH #1, step #304] loss: 4.603637624959477\n",
      "[EPOCH #1, step #306] loss: 4.603646135485522\n",
      "[EPOCH #1, step #308] loss: 4.602381462418146\n",
      "[EPOCH #1, step #310] loss: 4.60193162102408\n",
      "[EPOCH #1, step #312] loss: 4.601218761346591\n",
      "[EPOCH #1, step #314] loss: 4.600717679281083\n",
      "[EPOCH #1, step #316] loss: 4.6006181503319965\n",
      "[EPOCH #1, step #318] loss: 4.60000204217845\n",
      "[EPOCH #1, step #320] loss: 4.599416991260564\n",
      "[EPOCH #1, step #322] loss: 4.598476030509169\n",
      "[EPOCH #1, step #324] loss: 4.597883205413819\n",
      "[EPOCH #1, step #326] loss: 4.59754205989546\n",
      "[EPOCH #1, step #328] loss: 4.597369049095455\n",
      "[EPOCH #1, step #330] loss: 4.596288902882002\n",
      "[EPOCH #1, step #332] loss: 4.595565274671033\n",
      "[EPOCH #1, step #334] loss: 4.594461015445083\n",
      "[EPOCH #1, step #336] loss: 4.594139307118311\n",
      "[EPOCH #1, step #338] loss: 4.593055021798013\n",
      "[EPOCH #1, step #340] loss: 4.592701168004369\n",
      "[EPOCH #1, step #342] loss: 4.59223701933035\n",
      "[EPOCH #1, step #344] loss: 4.5919088474218395\n",
      "[EPOCH #1, step #346] loss: 4.591372591617815\n",
      "[EPOCH #1, step #348] loss: 4.5904284630259\n",
      "[EPOCH #1, step #350] loss: 4.590412095061734\n",
      "[EPOCH #1, step #352] loss: 4.589724267846126\n",
      "[EPOCH #1, step #354] loss: 4.5887089836765345\n",
      "[EPOCH #1, step #356] loss: 4.588827329523423\n",
      "[EPOCH #1, step #358] loss: 4.588005570648108\n",
      "[EPOCH #1, step #360] loss: 4.587664126028975\n",
      "[EPOCH #1, step #362] loss: 4.587519160972154\n",
      "[EPOCH #1, step #364] loss: 4.587277234743719\n",
      "[EPOCH #1, step #366] loss: 4.5863823799736165\n",
      "[EPOCH #1, step #368] loss: 4.585794243386121\n",
      "[EPOCH #1, step #370] loss: 4.585083339413543\n",
      "[EPOCH #1, step #372] loss: 4.584378110819144\n",
      "[EPOCH #1, step #374] loss: 4.583743364969889\n",
      "[EPOCH #1, step #376] loss: 4.5829606663327\n",
      "[EPOCH #1, step #378] loss: 4.582840693028432\n",
      "[EPOCH #1, step #380] loss: 4.583237193700835\n",
      "[EPOCH #1, step #382] loss: 4.582617882960148\n",
      "[EPOCH #1, step #384] loss: 4.5822311054576526\n",
      "[EPOCH #1, step #386] loss: 4.582292712012003\n",
      "[EPOCH #1, step #388] loss: 4.581668935888531\n",
      "[EPOCH #1, step #390] loss: 4.581942552190912\n",
      "[EPOCH #1, step #392] loss: 4.581538615335945\n",
      "[EPOCH #1, step #394] loss: 4.580651131159143\n",
      "[EPOCH #1, step #396] loss: 4.579956729706349\n",
      "[EPOCH #1, step #398] loss: 4.579826046649675\n",
      "[EPOCH #1, step #400] loss: 4.579086792439297\n",
      "[EPOCH #1, step #402] loss: 4.578933550169687\n",
      "[EPOCH #1, step #404] loss: 4.578431346092695\n",
      "[EPOCH #1, step #406] loss: 4.57802117954601\n",
      "[EPOCH #1, step #408] loss: 4.576957884511038\n",
      "[EPOCH #1, step #410] loss: 4.576932408223767\n",
      "[EPOCH #1, step #412] loss: 4.576465670190769\n",
      "[EPOCH #1, step #414] loss: 4.575914454172893\n",
      "[EPOCH #1, step #416] loss: 4.575772408958819\n",
      "[EPOCH #1, step #418] loss: 4.575098116244223\n",
      "[EPOCH #1, step #420] loss: 4.575063592181353\n",
      "[EPOCH #1, step #422] loss: 4.5741910607538605\n",
      "[EPOCH #1, step #424] loss: 4.5739202981836655\n",
      "[EPOCH #1, step #426] loss: 4.573824323033281\n",
      "[EPOCH #1, step #428] loss: 4.573490031671413\n",
      "[EPOCH #1, step #430] loss: 4.5728750793120705\n",
      "[EPOCH #1, step #432] loss: 4.57206394160317\n",
      "[EPOCH #1, step #434] loss: 4.571431733273911\n",
      "[EPOCH #1, step #436] loss: 4.570900200160745\n",
      "[EPOCH #1, step #438] loss: 4.57001035468725\n",
      "[EPOCH #1, step #440] loss: 4.56981239189096\n",
      "[EPOCH #1, step #442] loss: 4.5689504700912575\n",
      "[EPOCH #1, step #444] loss: 4.568448397818576\n",
      "[EPOCH #1, step #446] loss: 4.56772180424974\n",
      "[EPOCH #1, step #448] loss: 4.5674316856537205\n",
      "[EPOCH #1, step #450] loss: 4.566579064878815\n",
      "[EPOCH #1, step #452] loss: 4.566423043509983\n",
      "[EPOCH #1, step #454] loss: 4.5661864406459935\n",
      "[EPOCH #1, step #456] loss: 4.565972417919067\n",
      "[EPOCH #1, step #458] loss: 4.56494271729247\n",
      "[EPOCH #1, step #460] loss: 4.56470024559865\n",
      "[EPOCH #1, step #462] loss: 4.564289234111943\n",
      "[EPOCH #1, step #464] loss: 4.563849719878166\n",
      "[EPOCH #1, step #466] loss: 4.562321730293094\n",
      "[EPOCH #1, step #468] loss: 4.561970212566319\n",
      "[EPOCH #1, step #470] loss: 4.561398594242752\n",
      "[EPOCH #1, step #472] loss: 4.560342515497832\n",
      "[EPOCH #1, step #474] loss: 4.559818131296258\n",
      "[EPOCH #1, step #476] loss: 4.559362898332767\n",
      "[EPOCH #1, step #478] loss: 4.559351711034277\n",
      "[EPOCH #1, step #480] loss: 4.5588709500128415\n",
      "[EPOCH #1, step #482] loss: 4.558062880182365\n",
      "[EPOCH #1, step #484] loss: 4.558042077919872\n",
      "[EPOCH #1, step #486] loss: 4.55806000570497\n",
      "[EPOCH #1, step #488] loss: 4.557523033126488\n",
      "[EPOCH #1, step #490] loss: 4.556707759981486\n",
      "[EPOCH #1, step #492] loss: 4.556621608579376\n",
      "[EPOCH #1, step #494] loss: 4.556137155282377\n",
      "[EPOCH #1, step #496] loss: 4.555970966216305\n",
      "[EPOCH #1, step #498] loss: 4.55519045617633\n",
      "[EPOCH #1, step #500] loss: 4.554563780268747\n",
      "[EPOCH #1, step #502] loss: 4.554055663273775\n",
      "[EPOCH #1, step #504] loss: 4.553980527065768\n",
      "[EPOCH #1, step #506] loss: 4.553472821764222\n",
      "[EPOCH #1, step #508] loss: 4.552747658989987\n",
      "[EPOCH #1, step #510] loss: 4.552686024085416\n",
      "[EPOCH #1, step #512] loss: 4.552338920838651\n",
      "[EPOCH #1, step #514] loss: 4.551569586818658\n",
      "[EPOCH #1, step #516] loss: 4.5510717517402695\n",
      "[EPOCH #1, step #518] loss: 4.550910181622514\n",
      "[EPOCH #1, step #520] loss: 4.550291934535051\n",
      "[EPOCH #1, step #522] loss: 4.549773331126109\n",
      "[EPOCH #1, step #524] loss: 4.5496102060590475\n",
      "[EPOCH #1, step #526] loss: 4.548961939802658\n",
      "[EPOCH #1, step #528] loss: 4.548594915573899\n",
      "[EPOCH #1, step #530] loss: 4.548677219060406\n",
      "[EPOCH #1, step #532] loss: 4.548388853305724\n",
      "[EPOCH #1, step #534] loss: 4.5477505193692505\n",
      "[EPOCH #1, step #536] loss: 4.547450639238127\n",
      "[EPOCH #1, step #538] loss: 4.546885998218091\n",
      "[EPOCH #1, step #540] loss: 4.546425273810649\n",
      "[EPOCH #1, step #542] loss: 4.546099270246305\n",
      "[EPOCH #1, step #544] loss: 4.546049349898592\n",
      "[EPOCH #1, step #546] loss: 4.545340028061945\n",
      "[EPOCH #1, step #548] loss: 4.5446222110741346\n",
      "[EPOCH #1, step #550] loss: 4.544183056930016\n",
      "[EPOCH #1, step #552] loss: 4.543764699863482\n",
      "[EPOCH #1, step #554] loss: 4.542941529042012\n",
      "[EPOCH #1, step #556] loss: 4.542550704209552\n",
      "[EPOCH #1, step #558] loss: 4.541887018036544\n",
      "[EPOCH #1, step #560] loss: 4.541351749297769\n",
      "[EPOCH #1, step #562] loss: 4.540916082914092\n",
      "[EPOCH #1, step #564] loss: 4.540921790198942\n",
      "[EPOCH #1, step #566] loss: 4.540545879007437\n",
      "[EPOCH #1, step #568] loss: 4.540047100851532\n",
      "[EPOCH #1, step #570] loss: 4.539300007494444\n",
      "[EPOCH #1, step #572] loss: 4.538989876785411\n",
      "[EPOCH #1, step #574] loss: 4.538494392892589\n",
      "[EPOCH #1, step #576] loss: 4.538124600977377\n",
      "[EPOCH #1, step #578] loss: 4.537950885522345\n",
      "[EPOCH #1, step #580] loss: 4.537147361932647\n",
      "[EPOCH #1, step #582] loss: 4.53706893135712\n",
      "[EPOCH #1, step #584] loss: 4.537026963682256\n",
      "[EPOCH #1, step #586] loss: 4.5366362461239556\n",
      "[EPOCH #1, step #588] loss: 4.536166739990027\n",
      "[EPOCH #1, step #590] loss: 4.535865487584406\n",
      "[EPOCH #1, step #592] loss: 4.535665302212283\n",
      "[EPOCH #1, step #594] loss: 4.5351611225544906\n",
      "[EPOCH #1, step #596] loss: 4.534929757142187\n",
      "[EPOCH #1, step #598] loss: 4.53460637476289\n",
      "[EPOCH #1, step #600] loss: 4.534392644085623\n",
      "[EPOCH #1, step #602] loss: 4.534240710794629\n",
      "[EPOCH #1, step #604] loss: 4.533584821716813\n",
      "[EPOCH #1, step #606] loss: 4.533254148147055\n",
      "[EPOCH #1, step #608] loss: 4.533270192263749\n",
      "[EPOCH #1, step #610] loss: 4.5330126578210805\n",
      "[EPOCH #1, step #612] loss: 4.53289754239031\n",
      "[EPOCH #1, step #614] loss: 4.532522739627497\n",
      "[EPOCH #1, step #616] loss: 4.532151991196544\n",
      "[EPOCH #1, step #618] loss: 4.531746459122814\n",
      "[EPOCH #1, step #620] loss: 4.531643511976405\n",
      "[EPOCH #1, step #622] loss: 4.531495825245522\n",
      "[EPOCH #1, step #624] loss: 4.530945072174072\n",
      "[EPOCH #1, step #626] loss: 4.531066415412575\n",
      "[EPOCH #1, step #628] loss: 4.530654576700329\n",
      "[EPOCH #1, step #630] loss: 4.530631505932936\n",
      "[EPOCH #1, step #632] loss: 4.5302620303197685\n",
      "[EPOCH #1, step #634] loss: 4.530111845271794\n",
      "[EPOCH #1, step #636] loss: 4.529821228195023\n",
      "[EPOCH #1, step #638] loss: 4.529436719622784\n",
      "[EPOCH #1, step #640] loss: 4.5290184370627085\n",
      "[EPOCH #1, step #642] loss: 4.529068716947991\n",
      "[EPOCH #1, step #644] loss: 4.528456460228262\n",
      "[EPOCH #1, step #646] loss: 4.5281169130776355\n",
      "[EPOCH #1, step #648] loss: 4.527960162317073\n",
      "[EPOCH #1, step #650] loss: 4.5275017698788975\n",
      "[EPOCH #1, step #652] loss: 4.526788327449314\n",
      "[EPOCH #1, step #654] loss: 4.526309583387302\n",
      "[EPOCH #1, step #656] loss: 4.525982813203716\n",
      "[EPOCH #1, step #658] loss: 4.525747330308142\n",
      "[EPOCH #1, step #660] loss: 4.525388152083543\n",
      "[EPOCH #1, step #662] loss: 4.524955945856431\n",
      "[EPOCH #1, step #664] loss: 4.524551682723196\n",
      "[EPOCH #1, step #666] loss: 4.5242381610613\n",
      "[EPOCH #1, step #668] loss: 4.524002021738232\n",
      "[EPOCH #1, step #670] loss: 4.52376151262559\n",
      "[EPOCH #1, step #672] loss: 4.52343008103732\n",
      "[EPOCH #1, step #674] loss: 4.523395268475568\n",
      "[EPOCH #1, step #676] loss: 4.52297048906808\n",
      "[EPOCH #1, step #678] loss: 4.522875287220299\n",
      "[EPOCH #1, step #680] loss: 4.522275639000443\n",
      "[EPOCH #1, step #682] loss: 4.521805408583902\n",
      "[EPOCH #1, step #684] loss: 4.521340223994568\n",
      "[EPOCH #1, step #686] loss: 4.521400450966071\n",
      "[EPOCH #1, step #688] loss: 4.521016910564052\n",
      "[EPOCH #1, step #690] loss: 4.520843477566577\n",
      "[EPOCH #1, step #692] loss: 4.520686510149362\n",
      "[EPOCH #1, step #694] loss: 4.52034394518077\n",
      "[EPOCH #1, step #696] loss: 4.520011115108364\n",
      "[EPOCH #1, step #698] loss: 4.519896942487943\n",
      "[EPOCH #1, step #700] loss: 4.519706775730585\n",
      "[EPOCH #1, step #702] loss: 4.519124950826762\n",
      "[EPOCH #1, step #704] loss: 4.518881792379609\n",
      "[EPOCH #1, step #706] loss: 4.518532912161259\n",
      "[EPOCH #1, step #708] loss: 4.518355169148304\n",
      "[EPOCH #1, step #710] loss: 4.517806419340367\n",
      "[EPOCH #1, step #712] loss: 4.517191357900184\n",
      "[EPOCH #1, step #714] loss: 4.517195630240273\n",
      "[EPOCH #1, step #716] loss: 4.516863362725974\n",
      "[EPOCH #1, step #718] loss: 4.516530452749493\n",
      "[EPOCH #1, step #720] loss: 4.516459308947009\n",
      "[EPOCH #1, step #722] loss: 4.516400557500858\n",
      "[EPOCH #1, step #724] loss: 4.516018244644691\n",
      "[EPOCH #1, step #726] loss: 4.515652598180338\n",
      "[EPOCH #1, step #728] loss: 4.5152050869945635\n",
      "[EPOCH #1, step #730] loss: 4.514950769218309\n",
      "[EPOCH #1, step #732] loss: 4.5146672221518145\n",
      "[EPOCH #1, step #734] loss: 4.514349250404202\n",
      "[EPOCH #1, step #736] loss: 4.513870690215071\n",
      "[EPOCH #1, step #738] loss: 4.513560343498467\n",
      "[EPOCH #1, step #740] loss: 4.51324340238584\n",
      "[EPOCH #1, step #742] loss: 4.513077997102391\n",
      "[EPOCH #1, step #744] loss: 4.512954160191069\n",
      "[EPOCH #1, step #746] loss: 4.512696811951787\n",
      "[EPOCH #1, step #748] loss: 4.512443329208843\n",
      "[EPOCH #1, step #750] loss: 4.5121121724023325\n",
      "[EPOCH #1, step #752] loss: 4.511476452132145\n",
      "[EPOCH #1, step #754] loss: 4.511246743739046\n",
      "[EPOCH #1, step #756] loss: 4.51119314695129\n",
      "[EPOCH #1, step #758] loss: 4.511009032233116\n",
      "[EPOCH #1, step #760] loss: 4.510784883536741\n",
      "[EPOCH #1, step #762] loss: 4.510510805862447\n",
      "[EPOCH #1, step #764] loss: 4.510244548398685\n",
      "[EPOCH #1, step #766] loss: 4.510027857460908\n",
      "[EPOCH #1, step #768] loss: 4.509695852376395\n",
      "[EPOCH #1, step #770] loss: 4.509437535678057\n",
      "[EPOCH #1, step #772] loss: 4.509045427551862\n",
      "[EPOCH #1, step #774] loss: 4.508518524169922\n",
      "[EPOCH #1, step #776] loss: 4.508132822878726\n",
      "[EPOCH #1, step #778] loss: 4.507893463766468\n",
      "[EPOCH #1, step #780] loss: 4.50753048836956\n",
      "[EPOCH #1, step #782] loss: 4.5072372169786945\n",
      "[EPOCH #1, step #784] loss: 4.507036324519261\n",
      "[EPOCH #1, step #786] loss: 4.506841073648145\n",
      "[EPOCH #1, step #788] loss: 4.506646004617592\n",
      "[EPOCH #1, step #790] loss: 4.506255931709569\n",
      "[EPOCH #1, step #792] loss: 4.505951721460792\n",
      "[EPOCH #1, step #794] loss: 4.505677343764395\n",
      "[EPOCH #1, step #796] loss: 4.505333446349523\n",
      "[EPOCH #1, step #798] loss: 4.50515207748986\n",
      "[EPOCH #1, step #800] loss: 4.504932146393851\n",
      "[EPOCH #1, step #802] loss: 4.50465753693064\n",
      "[EPOCH #1, step #804] loss: 4.5042412609787466\n",
      "[EPOCH #1, step #806] loss: 4.50378562674351\n",
      "[EPOCH #1, step #808] loss: 4.5038417508487205\n",
      "[EPOCH #1, step #810] loss: 4.503669665862247\n",
      "[EPOCH #1, step #812] loss: 4.503286752900221\n",
      "[EPOCH #1, step #814] loss: 4.5030042250463564\n",
      "[EPOCH #1, step #816] loss: 4.502436426599285\n",
      "[EPOCH #1, step #818] loss: 4.501887559599638\n",
      "[EPOCH #1, step #820] loss: 4.501629236409493\n",
      "[EPOCH #1, step #822] loss: 4.501580821787022\n",
      "[EPOCH #1, step #824] loss: 4.501119629831025\n",
      "[EPOCH #1, step #826] loss: 4.500783450369967\n",
      "[EPOCH #1, step #828] loss: 4.50052938415288\n",
      "[EPOCH #1, step #830] loss: 4.500104399220895\n",
      "[EPOCH #1, step #832] loss: 4.499629391627867\n",
      "[EPOCH #1, step #834] loss: 4.499581232470667\n",
      "[EPOCH #1, step #836] loss: 4.499435748962804\n",
      "[EPOCH #1, step #838] loss: 4.499417551083844\n",
      "[EPOCH #1, step #840] loss: 4.498953149094735\n",
      "[EPOCH #1, step #842] loss: 4.498417737786597\n",
      "[EPOCH #1, step #844] loss: 4.4979921487661505\n",
      "[EPOCH #1, step #846] loss: 4.497750949972214\n",
      "[EPOCH #1, step #848] loss: 4.4976321502344065\n",
      "[EPOCH #1, step #850] loss: 4.497407335512226\n",
      "[EPOCH #1, step #852] loss: 4.497282513979591\n",
      "[EPOCH #1, step #854] loss: 4.497092430493985\n",
      "[EPOCH #1, step #856] loss: 4.496874914981659\n",
      "[EPOCH #1, step #858] loss: 4.496625223037666\n",
      "[EPOCH #1, step #860] loss: 4.496656626082187\n",
      "[EPOCH #1, step #862] loss: 4.49646332200405\n",
      "[EPOCH #1, step #864] loss: 4.495900966666337\n",
      "[EPOCH #1, step #866] loss: 4.495473447005504\n",
      "[EPOCH #1, step #868] loss: 4.495273297620451\n",
      "[EPOCH #1, step #870] loss: 4.494639732260107\n",
      "[EPOCH #1, step #872] loss: 4.494067277285652\n",
      "[EPOCH #1, step #874] loss: 4.493927552359445\n",
      "[EPOCH #1, step #876] loss: 4.493779439610793\n",
      "[EPOCH #1, step #878] loss: 4.4932439112961635\n",
      "[EPOCH #1, step #880] loss: 4.493059863567893\n",
      "[EPOCH #1, step #882] loss: 4.4928670269716635\n",
      "[EPOCH #1, step #884] loss: 4.492752425414694\n",
      "[EPOCH #1, step #886] loss: 4.492418813329135\n",
      "[EPOCH #1, step #888] loss: 4.4919280067203555\n",
      "[EPOCH #1, step #890] loss: 4.491364927538049\n",
      "[EPOCH #1, step #892] loss: 4.491077682072211\n",
      "[EPOCH #1, step #894] loss: 4.4906815891159315\n",
      "[EPOCH #1, step #896] loss: 4.490494330458285\n",
      "[EPOCH #1, step #898] loss: 4.490325892197012\n",
      "[EPOCH #1, step #900] loss: 4.490191779840535\n",
      "[EPOCH #1, step #902] loss: 4.489891554430078\n",
      "[EPOCH #1, step #904] loss: 4.4895723606341456\n",
      "[EPOCH #1, step #906] loss: 4.489196438247865\n",
      "[EPOCH #1, step #908] loss: 4.489052339748974\n",
      "[EPOCH #1, step #910] loss: 4.4886146293120905\n",
      "[EPOCH #1, step #912] loss: 4.4883452245204625\n",
      "[EPOCH #1, step #914] loss: 4.488162869833857\n",
      "[EPOCH #1, step #916] loss: 4.487817607243162\n",
      "[EPOCH #1, step #918] loss: 4.4876609896679565\n",
      "[EPOCH #1, step #920] loss: 4.487316228926635\n",
      "[EPOCH #1, step #922] loss: 4.486967577061183\n",
      "[EPOCH #1, step #924] loss: 4.486798194163555\n",
      "[EPOCH #1, step #926] loss: 4.486495480439681\n",
      "[EPOCH #1, step #928] loss: 4.486220929543092\n",
      "[EPOCH #1, step #930] loss: 4.4855862514032845\n",
      "[EPOCH #1, step #932] loss: 4.485241654857051\n",
      "[EPOCH #1, step #934] loss: 4.484593411307921\n",
      "[EPOCH #1, step #936] loss: 4.48421197156387\n",
      "[EPOCH #1, step #938] loss: 4.4842077804703555\n",
      "[EPOCH #1, step #940] loss: 4.484208779938036\n",
      "[EPOCH #1, step #942] loss: 4.483882018136827\n",
      "[EPOCH #1, step #944] loss: 4.483663038223509\n",
      "[EPOCH #1, step #946] loss: 4.483614171319174\n",
      "[EPOCH #1, step #948] loss: 4.483423782224022\n",
      "[EPOCH #1, step #950] loss: 4.48321969777377\n",
      "[EPOCH #1, step #952] loss: 4.483003060940305\n",
      "[EPOCH #1, step #954] loss: 4.483002279191741\n",
      "[EPOCH #1, step #956] loss: 4.483015717632967\n",
      "[EPOCH #1, step #958] loss: 4.4826866896731765\n",
      "[EPOCH #1, step #960] loss: 4.482344982651345\n",
      "[EPOCH #1, step #962] loss: 4.481812077519307\n",
      "[EPOCH #1, step #964] loss: 4.481408417163117\n",
      "[EPOCH #1, step #966] loss: 4.481417678134765\n",
      "[EPOCH #1, step #968] loss: 4.481111537315282\n",
      "[EPOCH #1, step #970] loss: 4.4807625946374925\n",
      "[EPOCH #1, step #972] loss: 4.480560333608723\n",
      "[EPOCH #1, step #974] loss: 4.4804198935093025\n",
      "[EPOCH #1, step #976] loss: 4.480101527796797\n",
      "[EPOCH #1, step #978] loss: 4.480018354168465\n",
      "[EPOCH #1, step #980] loss: 4.479585295180419\n",
      "[EPOCH #1, step #982] loss: 4.479381076195718\n",
      "[EPOCH #1, step #984] loss: 4.479003322911142\n",
      "[EPOCH #1, step #986] loss: 4.478630058671204\n",
      "[EPOCH #1, step #988] loss: 4.478359334268753\n",
      "[EPOCH #1, step #990] loss: 4.478264265897656\n",
      "[EPOCH #1, step #992] loss: 4.4779848399359174\n",
      "[EPOCH #1, step #994] loss: 4.47785007294698\n",
      "[EPOCH #1, step #996] loss: 4.47758353844569\n",
      "[EPOCH #1, step #998] loss: 4.477152140410216\n",
      "[EPOCH #1, step #1000] loss: 4.476638207545171\n",
      "[EPOCH #1, step #1002] loss: 4.476433016129529\n",
      "[EPOCH #1, step #1004] loss: 4.47590070458787\n",
      "[EPOCH #1, step #1006] loss: 4.475784718457613\n",
      "[EPOCH #1, step #1008] loss: 4.4756571615652\n",
      "[EPOCH #1, step #1010] loss: 4.475574183063149\n",
      "[EPOCH #1, step #1012] loss: 4.475398353151132\n",
      "[EPOCH #1, step #1014] loss: 4.475162167854497\n",
      "[EPOCH #1, step #1016] loss: 4.474945416258265\n",
      "[EPOCH #1, step #1018] loss: 4.474835147333566\n",
      "[EPOCH #1, step #1020] loss: 4.474300270566277\n",
      "[EPOCH #1, step #1022] loss: 4.47405377674196\n",
      "[EPOCH #1, step #1024] loss: 4.473833910314048\n",
      "[EPOCH #1, step #1026] loss: 4.473496641829509\n",
      "[EPOCH #1, step #1028] loss: 4.473169431973709\n",
      "[EPOCH #1, step #1030] loss: 4.4729227839339485\n",
      "[EPOCH #1, step #1032] loss: 4.4728242060798875\n",
      "[EPOCH #1, step #1034] loss: 4.472448758572196\n",
      "[EPOCH #1, step #1036] loss: 4.472175646426018\n",
      "[EPOCH #1, step #1038] loss: 4.47198281228485\n",
      "[EPOCH #1, step #1040] loss: 4.47191363223806\n",
      "[EPOCH #1, step #1042] loss: 4.47161450436337\n",
      "[EPOCH #1, step #1044] loss: 4.471627099890458\n",
      "[EPOCH #1, step #1046] loss: 4.471456877026198\n",
      "[EPOCH #1, step #1048] loss: 4.471255366522659\n",
      "[EPOCH #1, step #1050] loss: 4.471055271736675\n",
      "[EPOCH #1, step #1052] loss: 4.470721839839577\n",
      "[EPOCH #1, step #1054] loss: 4.470316591308015\n",
      "[EPOCH #1, step #1056] loss: 4.470003061736656\n",
      "[EPOCH #1, step #1058] loss: 4.469881516115298\n",
      "[EPOCH #1, step #1060] loss: 4.469513010461863\n",
      "[EPOCH #1, step #1062] loss: 4.469221852124018\n",
      "[EPOCH #1, step #1064] loss: 4.46882323099414\n",
      "[EPOCH #1, step #1066] loss: 4.4684474729664885\n",
      "[EPOCH #1, step #1068] loss: 4.468183635215652\n",
      "[EPOCH #1, step #1070] loss: 4.467862038830527\n",
      "[EPOCH #1, step #1072] loss: 4.467473441156848\n",
      "[EPOCH #1, step #1074] loss: 4.4669757412755215\n",
      "[EPOCH #1, step #1076] loss: 4.4666677769844245\n",
      "[EPOCH #1, step #1078] loss: 4.466367328244298\n",
      "[EPOCH #1, step #1080] loss: 4.466144549857677\n",
      "[EPOCH #1, step #1082] loss: 4.466011467402661\n",
      "[EPOCH #1, step #1084] loss: 4.46572598444152\n",
      "[EPOCH #1, step #1086] loss: 4.46544355631094\n",
      "[EPOCH #1, step #1088] loss: 4.465235729848057\n",
      "[EPOCH #1, step #1090] loss: 4.465169187645427\n",
      "[EPOCH #1, step #1092] loss: 4.464967697995143\n",
      "[EPOCH #1, step #1094] loss: 4.464627240673048\n",
      "[EPOCH #1, step #1096] loss: 4.464285772283619\n",
      "[EPOCH #1, step #1098] loss: 4.464005239450248\n",
      "[EPOCH #1, step #1100] loss: 4.4637623318317905\n",
      "[EPOCH #1, step #1102] loss: 4.4635956449500025\n",
      "[EPOCH #1, step #1104] loss: 4.4634365146516135\n",
      "[EPOCH #1, step #1106] loss: 4.463360384981591\n",
      "[EPOCH #1, step #1108] loss: 4.4628038935235645\n",
      "[EPOCH #1, step #1110] loss: 4.462693257765337\n",
      "[EPOCH #1, step #1112] loss: 4.462293582035418\n",
      "[EPOCH #1, step #1114] loss: 4.462072274503152\n",
      "[EPOCH #1, step #1116] loss: 4.461859426865539\n",
      "[EPOCH #1, step #1118] loss: 4.461817699633506\n",
      "[EPOCH #1, step #1120] loss: 4.461531201395789\n",
      "[EPOCH #1, step #1122] loss: 4.4612655597187425\n",
      "[EPOCH #1, step #1124] loss: 4.461129184299045\n",
      "[EPOCH #1, step #1126] loss: 4.460934110098215\n",
      "[EPOCH #1, step #1128] loss: 4.460677377094306\n",
      "[EPOCH #1, step #1130] loss: 4.460439549200731\n",
      "[EPOCH #1, step #1132] loss: 4.460390683937578\n",
      "[EPOCH #1, step #1134] loss: 4.459991622706342\n",
      "[EPOCH #1, step #1136] loss: 4.4595704456117975\n",
      "[EPOCH #1, step #1138] loss: 4.459521457330505\n",
      "[EPOCH #1, step #1140] loss: 4.459285246709477\n",
      "[EPOCH #1, step #1142] loss: 4.459086937124231\n",
      "[EPOCH #1, step #1144] loss: 4.458912335941364\n",
      "[EPOCH #1, step #1146] loss: 4.458787854069092\n",
      "[EPOCH #1, step #1148] loss: 4.458550800542607\n",
      "[EPOCH #1, step #1150] loss: 4.457910903943921\n",
      "[EPOCH #1, step #1152] loss: 4.457515019286951\n",
      "[EPOCH #1, step #1154] loss: 4.457272588639032\n",
      "[EPOCH #1, step #1156] loss: 4.4567623966813805\n",
      "[EPOCH #1, step #1158] loss: 4.456633420932694\n",
      "[EPOCH #1, step #1160] loss: 4.456291307979981\n",
      "[EPOCH #1, step #1162] loss: 4.455915469090075\n",
      "[EPOCH #1, step #1164] loss: 4.455837686481394\n",
      "[EPOCH #1, step #1166] loss: 4.455681578563438\n",
      "[EPOCH #1, step #1168] loss: 4.455340107248011\n",
      "[EPOCH #1, step #1170] loss: 4.45507939262944\n",
      "[EPOCH #1, step #1172] loss: 4.4549340384695535\n",
      "[EPOCH #1, step #1174] loss: 4.454607247697546\n",
      "[EPOCH #1, step #1176] loss: 4.454415569289215\n",
      "[EPOCH #1, step #1178] loss: 4.454151504215696\n",
      "[EPOCH #1, step #1180] loss: 4.453831541043636\n",
      "[EPOCH #1, step #1182] loss: 4.453667719688641\n",
      "[EPOCH #1, step #1184] loss: 4.453477138004223\n",
      "[EPOCH #1, step #1186] loss: 4.453221620384544\n",
      "[EPOCH #1, step #1188] loss: 4.453056149767466\n",
      "[EPOCH #1, step #1190] loss: 4.452832987486666\n",
      "[EPOCH #1, step #1192] loss: 4.452605091616174\n",
      "[EPOCH #1, step #1194] loss: 4.452170989303908\n",
      "[EPOCH #1, step #1196] loss: 4.451746637859042\n",
      "[EPOCH #1, step #1198] loss: 4.451609578104791\n",
      "[EPOCH #1, step #1200] loss: 4.451349960377969\n",
      "[EPOCH #1, step #1202] loss: 4.451135233849758\n",
      "[EPOCH #1, step #1204] loss: 4.450985198199007\n",
      "[EPOCH #1, step #1206] loss: 4.45064470722543\n",
      "[EPOCH #1, step #1208] loss: 4.450480711568575\n",
      "[EPOCH #1, step #1210] loss: 4.450308127997829\n",
      "[EPOCH #1, step #1212] loss: 4.449909020335047\n",
      "[EPOCH #1, step #1214] loss: 4.449728937109802\n",
      "[EPOCH #1, step #1216] loss: 4.449436219481043\n",
      "[EPOCH #1, step #1218] loss: 4.449367436744621\n",
      "[EPOCH #1, step #1220] loss: 4.449064018880608\n",
      "[EPOCH #1, step #1222] loss: 4.4488715552347955\n",
      "[EPOCH #1, step #1224] loss: 4.4488080160958425\n",
      "[EPOCH #1, step #1226] loss: 4.448614251837074\n",
      "[EPOCH #1, step #1228] loss: 4.448429545316394\n",
      "[EPOCH #1, step #1230] loss: 4.448157577375199\n",
      "[EPOCH #1, step #1232] loss: 4.448116444419867\n",
      "[EPOCH #1, step #1234] loss: 4.44791916719815\n",
      "[EPOCH #1, step #1236] loss: 4.447451731034991\n",
      "[EPOCH #1, step #1238] loss: 4.447265541101291\n",
      "[EPOCH #1, step #1240] loss: 4.447045441888014\n",
      "[EPOCH #1, step #1242] loss: 4.446904926269359\n",
      "[EPOCH #1, step #1244] loss: 4.446704646573966\n",
      "[EPOCH #1, step #1246] loss: 4.446376452946912\n",
      "[EPOCH #1, step #1248] loss: 4.446158625203386\n",
      "[EPOCH #1, step #1250] loss: 4.44586549235953\n",
      "[EPOCH #1, step #1252] loss: 4.44557936364712\n",
      "[EPOCH #1, step #1254] loss: 4.4452744791707195\n",
      "[EPOCH #1, step #1256] loss: 4.4449269769679205\n",
      "[EPOCH #1, step #1258] loss: 4.444579243375916\n",
      "[EPOCH #1, step #1260] loss: 4.444256803707694\n",
      "[EPOCH #1, step #1262] loss: 4.444011136264152\n",
      "[EPOCH #1, step #1264] loss: 4.443891467972707\n",
      "[EPOCH #1, step #1266] loss: 4.443624041827532\n",
      "[EPOCH #1, step #1268] loss: 4.443487630292503\n",
      "[EPOCH #1, step #1270] loss: 4.443174758358887\n",
      "[EPOCH #1, step #1272] loss: 4.442841054507343\n",
      "[EPOCH #1, step #1274] loss: 4.442753376680262\n",
      "[EPOCH #1, step #1276] loss: 4.442416852773309\n",
      "[EPOCH #1, step #1278] loss: 4.442253829353577\n",
      "[EPOCH #1, step #1280] loss: 4.442034968168451\n",
      "[EPOCH #1, step #1282] loss: 4.441837661636127\n",
      "[EPOCH #1, step #1284] loss: 4.441778262765491\n",
      "[EPOCH #1, step #1286] loss: 4.441715433510496\n",
      "[EPOCH #1, step #1288] loss: 4.441683867996844\n",
      "[EPOCH #1, step #1290] loss: 4.441193936316197\n",
      "[EPOCH #1, step #1292] loss: 4.440934147654074\n",
      "[EPOCH #1, step #1294] loss: 4.440674139265848\n",
      "[EPOCH #1, step #1296] loss: 4.4403490604762395\n",
      "[EPOCH #1, step #1298] loss: 4.440035396763872\n",
      "[EPOCH #1, step #1300] loss: 4.439695715995865\n",
      "[EPOCH #1, step #1302] loss: 4.439219543591702\n",
      "[EPOCH #1, step #1304] loss: 4.438942487577826\n",
      "[EPOCH #1, step #1306] loss: 4.438757192295019\n",
      "[EPOCH #1, step #1308] loss: 4.438490708790452\n",
      "[EPOCH #1, step #1310] loss: 4.4382366155686945\n",
      "[EPOCH #1, step #1312] loss: 4.4379355211977005\n",
      "[EPOCH #1, step #1314] loss: 4.437739288489628\n",
      "[EPOCH #1, step #1316] loss: 4.437469300304114\n",
      "[EPOCH #1, step #1318] loss: 4.437372619767728\n",
      "[EPOCH #1, step #1320] loss: 4.437229562581804\n",
      "[EPOCH #1, step #1322] loss: 4.436949715142167\n",
      "[EPOCH #1, step #1324] loss: 4.436744984320875\n",
      "[EPOCH #1, step #1326] loss: 4.436410818049668\n",
      "[EPOCH #1, step #1328] loss: 4.436102408587798\n",
      "[EPOCH #1, step #1330] loss: 4.4359193571880295\n",
      "[EPOCH #1, step #1332] loss: 4.435620833766792\n",
      "[EPOCH #1, step #1334] loss: 4.435384337821703\n",
      "[EPOCH #1, step #1336] loss: 4.435178833392992\n",
      "[EPOCH #1, step #1338] loss: 4.435001422078686\n",
      "[EPOCH #1, step #1340] loss: 4.434874668661824\n",
      "[EPOCH #1, step #1342] loss: 4.434701596101717\n",
      "[EPOCH #1, step #1344] loss: 4.434419951385725\n",
      "[EPOCH #1, step #1346] loss: 4.434073486059085\n",
      "[EPOCH #1, step #1348] loss: 4.433792002559857\n",
      "[EPOCH #1, step #1350] loss: 4.43343090746334\n",
      "[EPOCH #1, step #1352] loss: 4.433079670908182\n",
      "[EPOCH #1, step #1354] loss: 4.432897479771688\n",
      "[EPOCH #1, step #1356] loss: 4.432589478587612\n",
      "[EPOCH #1, step #1358] loss: 4.432400532554755\n",
      "[EPOCH #1, step #1360] loss: 4.432143500410048\n",
      "[EPOCH #1, step #1362] loss: 4.431769758659693\n",
      "[EPOCH #1, step #1364] loss: 4.431497726859627\n",
      "[EPOCH #1, step #1366] loss: 4.431149267156192\n",
      "[EPOCH #1, step #1368] loss: 4.4310132065683145\n",
      "[EPOCH #1, step #1370] loss: 4.431029026217916\n",
      "[EPOCH #1, step #1372] loss: 4.430939633396535\n",
      "[EPOCH #1, step #1374] loss: 4.430716869701039\n",
      "[EPOCH #1, step #1376] loss: 4.4305612402024614\n",
      "[EPOCH #1, step #1378] loss: 4.430319747343886\n",
      "[EPOCH #1, step #1380] loss: 4.430144257169112\n",
      "[EPOCH #1, step #1382] loss: 4.429946405337672\n",
      "[EPOCH #1, step #1384] loss: 4.429771850943996\n",
      "[EPOCH #1, step #1386] loss: 4.4295539051487705\n",
      "[EPOCH #1, step #1388] loss: 4.4292976016874706\n",
      "[EPOCH #1, step #1390] loss: 4.42882188252628\n",
      "[EPOCH #1, step #1392] loss: 4.42849736066491\n",
      "[EPOCH #1, step #1394] loss: 4.428309258765217\n",
      "[EPOCH #1, step #1396] loss: 4.4281736263310645\n",
      "[EPOCH #1, step #1398] loss: 4.4278995672066435\n",
      "[EPOCH #1, step #1400] loss: 4.427704881890002\n",
      "[EPOCH #1, step #1402] loss: 4.427558698062802\n",
      "[EPOCH #1, step #1404] loss: 4.427386760372284\n",
      "[EPOCH #1, step #1406] loss: 4.426943536336827\n",
      "[EPOCH #1, step #1408] loss: 4.426898395532915\n",
      "[EPOCH #1, step #1410] loss: 4.426566400061593\n",
      "[EPOCH #1, step #1412] loss: 4.426339597627784\n",
      "[EPOCH #1, step #1414] loss: 4.4262460526644976\n",
      "[EPOCH #1, step #1416] loss: 4.425948770599796\n",
      "[EPOCH #1, step #1418] loss: 4.425675313182075\n",
      "[EPOCH #1, step #1420] loss: 4.425480898965168\n",
      "[EPOCH #1, step #1422] loss: 4.425183018076528\n",
      "[EPOCH #1, step #1424] loss: 4.424834367517839\n",
      "[EPOCH #1, step #1426] loss: 4.424672048912235\n",
      "[EPOCH #1, step #1428] loss: 4.424476828751988\n",
      "[EPOCH #1, step #1430] loss: 4.424141257397367\n",
      "[EPOCH #1, step #1432] loss: 4.423848232021718\n",
      "[EPOCH #1, step #1434] loss: 4.423698041497207\n",
      "[EPOCH #1, step #1436] loss: 4.423627529529208\n",
      "[EPOCH #1, step #1438] loss: 4.423243997824366\n",
      "[EPOCH #1, step #1440] loss: 4.423194658251623\n",
      "[EPOCH #1, step #1442] loss: 4.42289979244716\n",
      "[EPOCH #1, step #1444] loss: 4.422523360598871\n",
      "[EPOCH #1, step #1446] loss: 4.422419863070137\n",
      "[EPOCH #1, step #1448] loss: 4.422250208976435\n",
      "[EPOCH #1, step #1450] loss: 4.4219697170796515\n",
      "[EPOCH #1, step #1452] loss: 4.421668544606512\n",
      "[EPOCH #1, step #1454] loss: 4.421521809174842\n",
      "[EPOCH #1, step #1456] loss: 4.42124096759804\n",
      "[EPOCH #1, step #1458] loss: 4.42096085708545\n",
      "[EPOCH #1, step #1460] loss: 4.4207483920881305\n",
      "[EPOCH #1, step #1462] loss: 4.420683417512551\n",
      "[EPOCH #1, step #1464] loss: 4.4205424087446294\n",
      "[EPOCH #1, step #1466] loss: 4.42025139027903\n",
      "[EPOCH #1, step #1468] loss: 4.420004028621541\n",
      "[EPOCH #1, step #1470] loss: 4.41986355564369\n",
      "[EPOCH #1, step #1472] loss: 4.419595606700952\n",
      "[EPOCH #1, step #1474] loss: 4.419455549595719\n",
      "[EPOCH #1, step #1476] loss: 4.419138376988829\n",
      "[EPOCH #1, step #1478] loss: 4.418804939894196\n",
      "[EPOCH #1, step #1480] loss: 4.4185186221259904\n",
      "[EPOCH #1, step #1482] loss: 4.418470884928893\n",
      "[EPOCH #1, step #1484] loss: 4.418258788368918\n",
      "[EPOCH #1, step #1486] loss: 4.418003605609783\n",
      "[EPOCH #1, step #1488] loss: 4.417732929206679\n",
      "[EPOCH #1, step #1490] loss: 4.4174261656005775\n",
      "[EPOCH #1, step #1492] loss: 4.417148983566376\n",
      "[EPOCH #1, step #1494] loss: 4.416974387918428\n",
      "[EPOCH #1, step #1496] loss: 4.416725750517352\n",
      "[EPOCH #1, step #1498] loss: 4.4165907039731405\n",
      "[EPOCH #1, step #1500] loss: 4.416297863674989\n",
      "[EPOCH #1, step #1502] loss: 4.416195357393124\n",
      "[EPOCH #1, step #1504] loss: 4.4159801571868185\n",
      "[EPOCH #1, step #1506] loss: 4.415722333127169\n",
      "[EPOCH #1, step #1508] loss: 4.415340149141922\n",
      "[EPOCH #1, step #1510] loss: 4.415196806133228\n",
      "[EPOCH #1, step #1512] loss: 4.4148753764057345\n",
      "[EPOCH #1, step #1514] loss: 4.414708787615937\n",
      "[EPOCH #1, step #1516] loss: 4.414539706651993\n",
      "[EPOCH #1, step #1518] loss: 4.414364365388721\n",
      "[EPOCH #1, step #1520] loss: 4.414246301600841\n",
      "[EPOCH #1, step #1522] loss: 4.414067343669899\n",
      "[EPOCH #1, step #1524] loss: 4.413857779112019\n",
      "[EPOCH #1, step #1526] loss: 4.413725222960436\n",
      "[EPOCH #1, step #1528] loss: 4.413499781475728\n",
      "[EPOCH #1, step #1530] loss: 4.413010432002281\n",
      "[EPOCH #1, step #1532] loss: 4.4128245929449275\n",
      "[EPOCH #1, step #1534] loss: 4.412685666565786\n",
      "[EPOCH #1, step #1536] loss: 4.412509223432919\n",
      "[EPOCH #1, step #1538] loss: 4.412136764941547\n",
      "[EPOCH #1, step #1540] loss: 4.411898933394554\n",
      "[EPOCH #1, step #1542] loss: 4.41162728135337\n",
      "[EPOCH #1, step #1544] loss: 4.411358729458164\n",
      "[EPOCH #1, step #1546] loss: 4.411047914680082\n",
      "[EPOCH #1, step #1548] loss: 4.410795973530887\n",
      "[EPOCH #1, step #1550] loss: 4.410506286135341\n",
      "[EPOCH #1, step #1552] loss: 4.410232456898735\n",
      "[EPOCH #1, step #1554] loss: 4.410032483159154\n",
      "[EPOCH #1, step #1556] loss: 4.409959877769994\n",
      "[EPOCH #1, step #1558] loss: 4.409628207596393\n",
      "[EPOCH #1, step #1560] loss: 4.409422915230799\n",
      "[EPOCH #1, step #1562] loss: 4.409388063355126\n",
      "[EPOCH #1, step #1564] loss: 4.409117022413796\n",
      "[EPOCH #1, step #1566] loss: 4.408887674341402\n",
      "[EPOCH #1, step #1568] loss: 4.408543611499745\n",
      "[EPOCH #1, step #1570] loss: 4.408252954179508\n",
      "[EPOCH #1, step #1572] loss: 4.408080667730963\n",
      "[EPOCH #1, step #1574] loss: 4.407937628276764\n",
      "[EPOCH #1, step #1576] loss: 4.407728288471509\n",
      "[EPOCH #1, step #1578] loss: 4.407426368593792\n",
      "[EPOCH #1, step #1580] loss: 4.407177763902108\n",
      "[EPOCH #1, step #1582] loss: 4.40677493370114\n",
      "[EPOCH #1, step #1584] loss: 4.406394571310338\n",
      "[EPOCH #1, step #1586] loss: 4.406051853879413\n",
      "[EPOCH #1, step #1588] loss: 4.405786387945887\n",
      "[EPOCH #1, step #1590] loss: 4.405594632731977\n",
      "[EPOCH #1, step #1592] loss: 4.405343800165784\n",
      "[EPOCH #1, step #1594] loss: 4.405101759680386\n",
      "[EPOCH #1, step #1596] loss: 4.404865809508093\n",
      "[EPOCH #1, step #1598] loss: 4.404369481136234\n",
      "[EPOCH #1, step #1600] loss: 4.404232280541777\n",
      "[EPOCH #1, step #1602] loss: 4.404112103278385\n",
      "[EPOCH #1, step #1604] loss: 4.403794054673097\n",
      "[EPOCH #1, step #1606] loss: 4.403676860141101\n",
      "[EPOCH #1, step #1608] loss: 4.4034502826320825\n",
      "[EPOCH #1, step #1610] loss: 4.40314661102366\n",
      "[EPOCH #1, step #1612] loss: 4.402872795801464\n",
      "[EPOCH #1, step #1614] loss: 4.4027300561544696\n",
      "[EPOCH #1, step #1616] loss: 4.402446065777677\n",
      "[EPOCH #1, step #1618] loss: 4.402165868534138\n",
      "[EPOCH #1, step #1620] loss: 4.401873427066885\n",
      "[EPOCH #1, step #1622] loss: 4.401781880995115\n",
      "[EPOCH #1, step #1624] loss: 4.401606865222638\n",
      "[EPOCH #1, step #1626] loss: 4.401405440273648\n",
      "[EPOCH #1, step #1628] loss: 4.401217813942607\n",
      "[EPOCH #1, step #1630] loss: 4.401149815244224\n",
      "[EPOCH #1, step #1632] loss: 4.400920987056211\n",
      "[EPOCH #1, step #1634] loss: 4.400709217258185\n",
      "[EPOCH #1, step #1636] loss: 4.40052659116872\n",
      "[EPOCH #1, step #1638] loss: 4.400367728379385\n",
      "[EPOCH #1, step #1640] loss: 4.400208131777376\n",
      "[EPOCH #1, step #1642] loss: 4.40000121824203\n",
      "[EPOCH #1, step #1644] loss: 4.399743376676797\n",
      "[EPOCH #1, step #1646] loss: 4.399396589762092\n",
      "[EPOCH #1, step #1648] loss: 4.399145428811948\n",
      "[EPOCH #1, step #1650] loss: 4.398811312605583\n",
      "[EPOCH #1, step #1652] loss: 4.398604116653286\n",
      "[EPOCH #1, step #1654] loss: 4.398341007751281\n",
      "[EPOCH #1, step #1656] loss: 4.398025695717903\n",
      "[EPOCH #1, step #1658] loss: 4.39762989335063\n",
      "[EPOCH #1, step #1660] loss: 4.397365833319217\n",
      "[EPOCH #1, step #1662] loss: 4.397049678497406\n",
      "[EPOCH #1, step #1664] loss: 4.396876709167664\n",
      "[EPOCH #1, step #1666] loss: 4.396683981837666\n",
      "[EPOCH #1, step #1668] loss: 4.396513235219015\n",
      "[EPOCH #1, step #1670] loss: 4.396215505046377\n",
      "[EPOCH #1, step #1672] loss: 4.396100209276618\n",
      "[EPOCH #1, step #1674] loss: 4.395941595675341\n",
      "[EPOCH #1, step #1676] loss: 4.3957182208057235\n",
      "[EPOCH #1, step #1678] loss: 4.395395776783873\n",
      "[EPOCH #1, step #1680] loss: 4.395222119814154\n",
      "[EPOCH #1, step #1682] loss: 4.3951121226564025\n",
      "[EPOCH #1, step #1684] loss: 4.3947539473853405\n",
      "[EPOCH #1, step #1686] loss: 4.394527930795051\n",
      "[EPOCH #1, step #1688] loss: 4.394221114999377\n",
      "[EPOCH #1, step #1690] loss: 4.393986306621929\n",
      "[EPOCH #1, step #1692] loss: 4.3937508875423825\n",
      "[EPOCH #1, step #1694] loss: 4.3934601178914745\n",
      "[EPOCH #1, step #1696] loss: 4.393283431784293\n",
      "[EPOCH #1, step #1698] loss: 4.393022234963277\n",
      "[EPOCH #1, step #1700] loss: 4.3928792164088835\n",
      "[EPOCH #1, step #1702] loss: 4.392592228795946\n",
      "[EPOCH #1, step #1704] loss: 4.3923230562741455\n",
      "[EPOCH #1, step #1706] loss: 4.392100391153292\n",
      "[EPOCH #1, step #1708] loss: 4.391758991864217\n",
      "[EPOCH #1, step #1710] loss: 4.391619452393452\n",
      "[EPOCH #1, step #1712] loss: 4.39126575835184\n",
      "[EPOCH #1, step #1714] loss: 4.3910162147210565\n",
      "[EPOCH #1, step #1716] loss: 4.390798972523622\n",
      "[EPOCH #1, step #1718] loss: 4.390689793542903\n",
      "[EPOCH #1, step #1720] loss: 4.390422784194636\n",
      "[EPOCH #1, step #1722] loss: 4.3899620269801956\n",
      "[EPOCH #1, step #1724] loss: 4.389820092519124\n",
      "[EPOCH #1, step #1726] loss: 4.389602414845178\n",
      "[EPOCH #1, step #1728] loss: 4.389339682820079\n",
      "[EPOCH #1, step #1730] loss: 4.389095776622383\n",
      "[EPOCH #1, step #1732] loss: 4.3889035369644125\n",
      "[EPOCH #1, step #1734] loss: 4.388734257942661\n",
      "[EPOCH #1, step #1736] loss: 4.3884816164248415\n",
      "[EPOCH #1, step #1738] loss: 4.388108611312524\n",
      "[EPOCH #1, step #1740] loss: 4.387866245337699\n",
      "[EPOCH #1, step #1742] loss: 4.38776152611326\n",
      "[EPOCH #1, step #1744] loss: 4.387412172060642\n",
      "[EPOCH #1, step #1746] loss: 4.3870022874186905\n",
      "[EPOCH #1, step #1748] loss: 4.386863856263813\n",
      "[EPOCH #1, step #1750] loss: 4.38662670000426\n",
      "[EPOCH #1, step #1752] loss: 4.3863919680280405\n",
      "[EPOCH #1, step #1754] loss: 4.386021228121896\n",
      "[EPOCH #1, step #1756] loss: 4.385562240365017\n",
      "[EPOCH #1, step #1758] loss: 4.385200551316574\n",
      "[EPOCH #1, step #1760] loss: 4.385021533294539\n",
      "[EPOCH #1, step #1762] loss: 4.384690655542245\n",
      "[EPOCH #1, step #1764] loss: 4.3843866960185105\n",
      "[EPOCH #1, step #1766] loss: 4.384262079428871\n",
      "[EPOCH #1, step #1768] loss: 4.383907189134692\n",
      "[EPOCH #1, step #1770] loss: 4.383633119652057\n",
      "[EPOCH #1, step #1772] loss: 4.383484530166522\n",
      "[EPOCH #1, step #1774] loss: 4.383160460566131\n",
      "[EPOCH #1, step #1776] loss: 4.382796499792216\n",
      "[EPOCH #1, step #1778] loss: 4.382518782248451\n",
      "[EPOCH #1, step #1780] loss: 4.382426300991257\n",
      "[EPOCH #1, step #1782] loss: 4.382266130463433\n",
      "[EPOCH #1, step #1784] loss: 4.381923388366272\n",
      "[EPOCH #1, step #1786] loss: 4.381829133698176\n",
      "[EPOCH #1, step #1788] loss: 4.3816799083323765\n",
      "[EPOCH #1, step #1790] loss: 4.381308139468757\n",
      "[EPOCH #1, step #1792] loss: 4.381159641459476\n",
      "[EPOCH #1, step #1794] loss: 4.38095333024984\n",
      "[EPOCH #1, step #1796] loss: 4.380641285817227\n",
      "[EPOCH #1, step #1798] loss: 4.380290511981059\n",
      "[EPOCH #1, step #1800] loss: 4.380104077650003\n",
      "[EPOCH #1, step #1802] loss: 4.37987609763841\n",
      "[EPOCH #1, step #1804] loss: 4.379649567538021\n",
      "[EPOCH #1, step #1806] loss: 4.379441098739379\n",
      "[EPOCH #1, step #1808] loss: 4.379133643334317\n",
      "[EPOCH #1, step #1810] loss: 4.379090221727309\n",
      "[EPOCH #1, step #1812] loss: 4.378769425614657\n",
      "[EPOCH #1, step #1814] loss: 4.378456002227531\n",
      "[EPOCH #1, step #1816] loss: 4.378250401821777\n",
      "[EPOCH #1, step #1818] loss: 4.3780205513239565\n",
      "[EPOCH #1, step #1820] loss: 4.377842806774728\n",
      "[EPOCH #1, step #1822] loss: 4.377507608144805\n",
      "[EPOCH #1, step #1824] loss: 4.377138380024531\n",
      "[EPOCH #1, step #1826] loss: 4.376900283508635\n",
      "[EPOCH #1, step #1828] loss: 4.376821442338663\n",
      "[EPOCH #1, step #1830] loss: 4.376531717361876\n",
      "[EPOCH #1, step #1832] loss: 4.376342646749177\n",
      "[EPOCH #1, step #1834] loss: 4.376159601705275\n",
      "[EPOCH #1, step #1836] loss: 4.3758920719912995\n",
      "[EPOCH #1, step #1838] loss: 4.375528182200338\n",
      "[EPOCH #1, step #1840] loss: 4.375386239004679\n",
      "[EPOCH #1, step #1842] loss: 4.375186913309703\n",
      "[EPOCH #1, step #1844] loss: 4.374870763303141\n",
      "[EPOCH #1, step #1846] loss: 4.374722922371088\n",
      "[EPOCH #1, step #1848] loss: 4.374543629574608\n",
      "[EPOCH #1, step #1850] loss: 4.374435913620737\n",
      "[EPOCH #1, step #1852] loss: 4.3742707707209005\n",
      "[EPOCH #1, step #1854] loss: 4.374134650448904\n",
      "[EPOCH #1, step #1856] loss: 4.3737179416446965\n",
      "[EPOCH #1, step #1858] loss: 4.37346690633465\n",
      "[EPOCH #1, step #1860] loss: 4.3733036851191125\n",
      "[EPOCH #1, step #1862] loss: 4.37294219273492\n",
      "[EPOCH #1, step #1864] loss: 4.372756712813799\n",
      "[EPOCH #1, step #1866] loss: 4.372411497787287\n",
      "[EPOCH #1, step #1868] loss: 4.372263961963439\n",
      "[EPOCH #1, step #1870] loss: 4.372185063069036\n",
      "[EPOCH #1, step #1872] loss: 4.371999379344885\n",
      "[EPOCH #1, step #1874] loss: 4.371772173817953\n",
      "[EPOCH #1, step #1876] loss: 4.3716561102016085\n",
      "[EPOCH #1, step #1878] loss: 4.371472490157391\n",
      "[EPOCH #1, step #1880] loss: 4.371253397666286\n",
      "[EPOCH #1, step #1882] loss: 4.371164890153574\n",
      "[EPOCH #1, step #1884] loss: 4.370979719389655\n",
      "[EPOCH #1, step #1886] loss: 4.370707016617897\n",
      "[EPOCH #1, step #1888] loss: 4.370548396466458\n",
      "[EPOCH #1, step #1890] loss: 4.370280209323957\n",
      "[EPOCH #1, step #1892] loss: 4.370089171238822\n",
      "[EPOCH #1, step #1894] loss: 4.369918344140367\n",
      "[EPOCH #1, step #1896] loss: 4.36966694614167\n",
      "[EPOCH #1, step #1898] loss: 4.369532542708298\n",
      "[EPOCH #1, step #1900] loss: 4.36929042159978\n",
      "[EPOCH #1, step #1902] loss: 4.369006104551988\n",
      "[EPOCH #1, step #1904] loss: 4.368933582556217\n",
      "[EPOCH #1, step #1906] loss: 4.368705624738912\n",
      "[EPOCH #1, step #1908] loss: 4.368435514728832\n",
      "[EPOCH #1, step #1910] loss: 4.368308612029007\n",
      "[EPOCH #1, step #1912] loss: 4.368238741480363\n",
      "[EPOCH #1, step #1914] loss: 4.368096998777464\n",
      "[EPOCH #1, step #1916] loss: 4.367967284714485\n",
      "[EPOCH #1, step #1918] loss: 4.367949798120813\n",
      "[EPOCH #1, step #1920] loss: 4.3676935600030555\n",
      "[EPOCH #1, step #1922] loss: 4.367381022240554\n",
      "[EPOCH #1, step #1924] loss: 4.367141323585015\n",
      "[EPOCH #1, step #1926] loss: 4.366922613370585\n",
      "[EPOCH #1, step #1928] loss: 4.366635642934179\n",
      "[EPOCH #1, step #1930] loss: 4.3665741340660915\n",
      "[EPOCH #1, step #1932] loss: 4.366521902918137\n",
      "[EPOCH #1, step #1934] loss: 4.366375078896219\n",
      "[EPOCH #1, step #1936] loss: 4.366261940120604\n",
      "[EPOCH #1, step #1938] loss: 4.365997739155431\n",
      "[EPOCH #1, step #1940] loss: 4.365730311439432\n",
      "[EPOCH #1, step #1942] loss: 4.365467615122655\n",
      "[EPOCH #1, step #1944] loss: 4.365364563557054\n",
      "[EPOCH #1, step #1946] loss: 4.3652721690592795\n",
      "[EPOCH #1, step #1948] loss: 4.365122330745347\n",
      "[EPOCH #1, step #1950] loss: 4.365031998320031\n",
      "[EPOCH #1, step #1952] loss: 4.364720908056085\n",
      "[EPOCH #1, step #1954] loss: 4.364306150494939\n",
      "[EPOCH #1, step #1956] loss: 4.364063085678834\n",
      "[EPOCH #1, step #1958] loss: 4.36383804573947\n",
      "[EPOCH #1, step #1960] loss: 4.363556887044522\n",
      "[EPOCH #1, step #1962] loss: 4.363291275118664\n",
      "[EPOCH #1, step #1964] loss: 4.3631390526701175\n",
      "[EPOCH #1, step #1966] loss: 4.362962735747709\n",
      "[EPOCH #1, step #1968] loss: 4.362917906260842\n",
      "[EPOCH #1, step #1970] loss: 4.362701684675018\n",
      "[EPOCH #1, step #1972] loss: 4.36252702376109\n",
      "[EPOCH #1, step #1974] loss: 4.36234662007682\n",
      "[EPOCH #1, step #1976] loss: 4.361979362876595\n",
      "[EPOCH #1, step #1978] loss: 4.361717976964803\n",
      "[EPOCH #1, step #1980] loss: 4.361406925890796\n",
      "[EPOCH #1, step #1982] loss: 4.361276257236498\n",
      "[EPOCH #1, step #1984] loss: 4.361024838550866\n",
      "[EPOCH #1, step #1986] loss: 4.360890461442215\n",
      "[EPOCH #1, step #1988] loss: 4.36075261419535\n",
      "[EPOCH #1, step #1990] loss: 4.360482818933063\n",
      "[EPOCH #1, step #1992] loss: 4.360280759000802\n",
      "[EPOCH #1, step #1994] loss: 4.359986248470488\n",
      "[EPOCH #1, step #1996] loss: 4.359722960156444\n",
      "[EPOCH #1, step #1998] loss: 4.35954976654339\n",
      "[EPOCH #1, step #2000] loss: 4.359422783444131\n",
      "[EPOCH #1, step #2002] loss: 4.359371532991536\n",
      "[EPOCH #1, step #2004] loss: 4.359122865277335\n",
      "[EPOCH #1, step #2006] loss: 4.358805475154206\n",
      "[EPOCH #1, step #2008] loss: 4.358581418597087\n",
      "[EPOCH #1, step #2010] loss: 4.358540396498306\n",
      "[EPOCH #1, step #2012] loss: 4.358334861817907\n",
      "[EPOCH #1, step #2014] loss: 4.358064427624269\n",
      "[EPOCH #1, step #2016] loss: 4.357856906754697\n",
      "[EPOCH #1, step #2018] loss: 4.35771848920432\n",
      "[EPOCH #1, step #2020] loss: 4.357647230694755\n",
      "[EPOCH #1, step #2022] loss: 4.357511722387445\n",
      "[EPOCH #1, step #2024] loss: 4.357215249567856\n",
      "[EPOCH #1, step #2026] loss: 4.357222818893109\n",
      "[EPOCH #1, step #2028] loss: 4.356933755907535\n",
      "[EPOCH #1, step #2030] loss: 4.356682365366768\n",
      "[EPOCH #1, step #2032] loss: 4.356359972956142\n",
      "[EPOCH #1, step #2034] loss: 4.356214543701097\n",
      "[EPOCH #1, step #2036] loss: 4.355902421690988\n",
      "[EPOCH #1, step #2038] loss: 4.355646953213268\n",
      "[EPOCH #1, step #2040] loss: 4.355488700413459\n",
      "[EPOCH #1, step #2042] loss: 4.355265547933966\n",
      "[EPOCH #1, step #2044] loss: 4.354995854967672\n",
      "[EPOCH #1, step #2046] loss: 4.354810477933711\n",
      "[EPOCH #1, step #2048] loss: 4.3545631818971495\n",
      "[EPOCH #1, step #2050] loss: 4.3543645512586915\n",
      "[EPOCH #1, step #2052] loss: 4.35416727244883\n",
      "[EPOCH #1, step #2054] loss: 4.354093790286359\n",
      "[EPOCH #1, step #2056] loss: 4.353768824603758\n",
      "[EPOCH #1, step #2058] loss: 4.353489135757935\n",
      "[EPOCH #1, step #2060] loss: 4.353354170043627\n",
      "[EPOCH #1, step #2062] loss: 4.353072370190789\n",
      "[EPOCH #1, step #2064] loss: 4.352888969185854\n",
      "[EPOCH #1, step #2066] loss: 4.352593488490229\n",
      "[EPOCH #1, step #2068] loss: 4.352375007586066\n",
      "[EPOCH #1, step #2070] loss: 4.352251993291681\n",
      "[EPOCH #1, step #2072] loss: 4.351921222431902\n",
      "[EPOCH #1, step #2074] loss: 4.3516863720675545\n",
      "[EPOCH #1, step #2076] loss: 4.351409768966396\n",
      "[EPOCH #1, step #2078] loss: 4.351112651389169\n",
      "[EPOCH #1, step #2080] loss: 4.350887837861376\n",
      "[EPOCH #1, step #2082] loss: 4.350571395798022\n",
      "[EPOCH #1, step #2084] loss: 4.350442895386145\n",
      "[EPOCH #1, step #2086] loss: 4.3502987064010625\n",
      "[EPOCH #1, step #2088] loss: 4.350132497204954\n",
      "[EPOCH #1, step #2090] loss: 4.350099272274162\n",
      "[EPOCH #1, step #2092] loss: 4.349732609041217\n",
      "[EPOCH #1, step #2094] loss: 4.349557446181632\n",
      "[EPOCH #1, step #2096] loss: 4.349272682943058\n",
      "[EPOCH #1, step #2098] loss: 4.3491413867036295\n",
      "[EPOCH #1, step #2100] loss: 4.349077674560692\n",
      "[EPOCH #1, step #2102] loss: 4.348723189013377\n",
      "[EPOCH #1, step #2104] loss: 4.348460415026921\n",
      "[EPOCH #1, step #2106] loss: 4.348266302718899\n",
      "[EPOCH #1, step #2108] loss: 4.348166906986264\n",
      "[EPOCH #1, step #2110] loss: 4.34811023952045\n",
      "[EPOCH #1, step #2112] loss: 4.347878858143833\n",
      "[EPOCH #1, step #2114] loss: 4.347616274813388\n",
      "[EPOCH #1, step #2116] loss: 4.347251310627811\n",
      "[EPOCH #1, step #2118] loss: 4.346982751493467\n",
      "[EPOCH #1, step #2120] loss: 4.346856699862158\n",
      "[EPOCH #1, step #2122] loss: 4.34664469656942\n",
      "[EPOCH #1, step #2124] loss: 4.346224965600406\n",
      "[EPOCH #1, step #2126] loss: 4.345941330156923\n",
      "[EPOCH #1, step #2128] loss: 4.345693599903399\n",
      "[EPOCH #1, step #2130] loss: 4.34547692674362\n",
      "[EPOCH #1, step #2132] loss: 4.345315651328028\n",
      "[EPOCH #1, step #2134] loss: 4.345085494914714\n",
      "[EPOCH #1, step #2136] loss: 4.344823478704086\n",
      "[EPOCH #1, step #2138] loss: 4.344748672451467\n",
      "[EPOCH #1, step #2140] loss: 4.344675570100003\n",
      "[EPOCH #1, step #2142] loss: 4.344524253377055\n",
      "[EPOCH #1, step #2144] loss: 4.344221204255288\n",
      "[EPOCH #1, step #2146] loss: 4.344011185054841\n",
      "[EPOCH #1, step #2148] loss: 4.343572512844542\n",
      "[EPOCH #1, step #2150] loss: 4.343392855508114\n",
      "[EPOCH #1, step #2152] loss: 4.343092828255391\n",
      "[EPOCH #1, step #2154] loss: 4.342897520485721\n",
      "[EPOCH #1, step #2156] loss: 4.34266099876754\n",
      "[EPOCH #1, step #2158] loss: 4.342432781853793\n",
      "[EPOCH #1, step #2160] loss: 4.342033926175183\n",
      "[EPOCH #1, step #2162] loss: 4.341811251761568\n",
      "[EPOCH #1, step #2164] loss: 4.341722629141863\n",
      "[EPOCH #1, step #2166] loss: 4.3415022241832695\n",
      "[EPOCH #1, step #2168] loss: 4.341258497708621\n",
      "[EPOCH #1, step #2170] loss: 4.340958402981576\n",
      "[EPOCH #1, step #2172] loss: 4.340739723618986\n",
      "[EPOCH #1, step #2174] loss: 4.340497331619263\n",
      "[EPOCH #1, step #2176] loss: 4.340264927535961\n",
      "[EPOCH #1, step #2178] loss: 4.339989758894607\n",
      "[EPOCH #1, step #2180] loss: 4.339794370134398\n",
      "[EPOCH #1, step #2182] loss: 4.339418215321337\n",
      "[EPOCH #1, step #2184] loss: 4.339354939537135\n",
      "[EPOCH #1, step #2186] loss: 4.339071868596472\n",
      "[EPOCH #1, step #2188] loss: 4.338799311288038\n",
      "[EPOCH #1, step #2190] loss: 4.33858989309035\n",
      "[EPOCH #1, step #2192] loss: 4.338457215174768\n",
      "[EPOCH #1, step #2194] loss: 4.338251822738822\n",
      "[EPOCH #1, step #2196] loss: 4.338025009518165\n",
      "[EPOCH #1, step #2198] loss: 4.337773707738081\n",
      "[EPOCH #1, step #2200] loss: 4.337635395365485\n",
      "[EPOCH #1, step #2202] loss: 4.337372515237282\n",
      "[EPOCH #1, step #2204] loss: 4.337063912091072\n",
      "[EPOCH #1, step #2206] loss: 4.336834565405939\n",
      "[EPOCH #1, step #2208] loss: 4.336733798302909\n",
      "[EPOCH #1, step #2210] loss: 4.336475323466142\n",
      "[EPOCH #1, step #2212] loss: 4.336248247320707\n",
      "[EPOCH #1, step #2214] loss: 4.33604340833143\n",
      "[EPOCH #1, step #2216] loss: 4.335735225333359\n",
      "[EPOCH #1, step #2218] loss: 4.335478528870715\n",
      "[EPOCH #1, step #2220] loss: 4.335350937909878\n",
      "[EPOCH #1, step #2222] loss: 4.335121281877381\n",
      "[EPOCH #1, step #2224] loss: 4.334845833831959\n",
      "[EPOCH #1, step #2226] loss: 4.3345241383902415\n",
      "[EPOCH #1, step #2228] loss: 4.334345921853991\n",
      "[EPOCH #1, step #2230] loss: 4.334151041983276\n",
      "[EPOCH #1, step #2232] loss: 4.333981199964941\n",
      "[EPOCH #1, step #2234] loss: 4.333743454999305\n",
      "[EPOCH #1, step #2236] loss: 4.333506000857295\n",
      "[EPOCH #1, step #2238] loss: 4.333303121223467\n",
      "[EPOCH #1, step #2240] loss: 4.333190366871811\n",
      "[EPOCH #1, step #2242] loss: 4.332860228742174\n",
      "[EPOCH #1, step #2244] loss: 4.332641856017251\n",
      "[EPOCH #1, step #2246] loss: 4.332413926780303\n",
      "[EPOCH #1, step #2248] loss: 4.332084586642593\n",
      "[EPOCH #1, step #2250] loss: 4.331827710120745\n",
      "[EPOCH #1, step #2252] loss: 4.331480637794593\n",
      "[EPOCH #1, step #2254] loss: 4.331280612945557\n",
      "[EPOCH #1, step #2256] loss: 4.331011763704948\n",
      "[EPOCH #1, step #2258] loss: 4.330801219315379\n",
      "[EPOCH #1, step #2260] loss: 4.3306121585749775\n",
      "[EPOCH #1, step #2262] loss: 4.330395926325078\n",
      "[EPOCH #1, step #2264] loss: 4.330239132382222\n",
      "[EPOCH #1, step #2266] loss: 4.330052872402425\n",
      "[EPOCH #1, step #2268] loss: 4.329604243958979\n",
      "[EPOCH #1, step #2270] loss: 4.329422157380823\n",
      "[EPOCH #1, step #2272] loss: 4.32926864567382\n",
      "[EPOCH #1, step #2274] loss: 4.3291823954110615\n",
      "[EPOCH #1, step #2276] loss: 4.329057598511901\n",
      "[EPOCH #1, step #2278] loss: 4.328851817103006\n",
      "[EPOCH #1, step #2280] loss: 4.328762826350947\n",
      "[EPOCH #1, step #2282] loss: 4.328627800346204\n",
      "[EPOCH #1, step #2284] loss: 4.328371950729671\n",
      "[EPOCH #1, step #2286] loss: 4.32813147503995\n",
      "[EPOCH #1, step #2288] loss: 4.327970583400335\n",
      "[EPOCH #1, step #2290] loss: 4.3277370411462\n",
      "[EPOCH #1, step #2292] loss: 4.327651893837817\n",
      "[EPOCH #1, step #2294] loss: 4.327528278188768\n",
      "[EPOCH #1, step #2296] loss: 4.32726486122603\n",
      "[EPOCH #1, step #2298] loss: 4.327099430815144\n",
      "[EPOCH #1, step #2300] loss: 4.326845380856855\n",
      "[EPOCH #1, step #2302] loss: 4.326610295398827\n",
      "[EPOCH #1, step #2304] loss: 4.3263172019329605\n",
      "[EPOCH #1, step #2306] loss: 4.326148677192625\n",
      "[EPOCH #1, step #2308] loss: 4.325963261118179\n",
      "[EPOCH #1, step #2310] loss: 4.325551268756261\n",
      "[EPOCH #1, step #2312] loss: 4.325283103622094\n",
      "[EPOCH #1, step #2314] loss: 4.325118410613058\n",
      "[EPOCH #1, step #2316] loss: 4.324867128862818\n",
      "[EPOCH #1, step #2318] loss: 4.32460889316623\n",
      "[EPOCH #1, step #2320] loss: 4.324559089799525\n",
      "[EPOCH #1, step #2322] loss: 4.32432486566551\n",
      "[EPOCH #1, step #2324] loss: 4.324061532174388\n",
      "[EPOCH #1, step #2326] loss: 4.323984066201322\n",
      "[EPOCH #1, step #2328] loss: 4.323780737705321\n",
      "[EPOCH #1, step #2330] loss: 4.323623377179342\n",
      "[EPOCH #1, step #2332] loss: 4.323416237150504\n",
      "[EPOCH #1, step #2334] loss: 4.3232385357646415\n",
      "[EPOCH #1, step #2336] loss: 4.323092927471613\n",
      "[EPOCH #1, step #2338] loss: 4.322915507157983\n",
      "[EPOCH #1, step #2340] loss: 4.322747322597446\n",
      "[EPOCH #1, step #2342] loss: 4.322591786093555\n",
      "[EPOCH #1, step #2344] loss: 4.3223549188073\n",
      "[EPOCH #1, step #2346] loss: 4.3219950356583015\n",
      "[EPOCH #1, step #2348] loss: 4.321771100207865\n",
      "[EPOCH #1, step #2350] loss: 4.32157676385241\n",
      "[EPOCH #1, step #2352] loss: 4.321348623270893\n",
      "[EPOCH #1, step #2354] loss: 4.321227798846624\n",
      "[EPOCH #1, step #2356] loss: 4.320854892759036\n",
      "[EPOCH #1, step #2358] loss: 4.3206009478728715\n",
      "[EPOCH #1, step #2360] loss: 4.320437286729178\n",
      "[EPOCH #1, step #2362] loss: 4.320181072540219\n",
      "[EPOCH #1, step #2364] loss: 4.31989690093107\n",
      "[EPOCH #1, step #2366] loss: 4.319883637555199\n",
      "[EPOCH #1, step #2368] loss: 4.319556907643342\n",
      "[EPOCH #1, step #2370] loss: 4.31926139976746\n",
      "[EPOCH #1, step #2372] loss: 4.31904608671845\n",
      "[EPOCH #1, step #2374] loss: 4.319022980238262\n",
      "[EPOCH #1, step #2376] loss: 4.318976428862825\n",
      "[EPOCH #1, step #2378] loss: 4.318871704055863\n",
      "[EPOCH #1, step #2380] loss: 4.318574213070411\n",
      "[EPOCH #1, step #2382] loss: 4.318360863340236\n",
      "[EPOCH #1, step #2384] loss: 4.318126774434024\n",
      "[EPOCH #1, step #2386] loss: 4.3178306514866245\n",
      "[EPOCH #1, step #2388] loss: 4.317691694198167\n",
      "[EPOCH #1, step #2390] loss: 4.317561488827618\n",
      "[EPOCH #1, step #2392] loss: 4.317367051368072\n",
      "[EPOCH #1, step #2394] loss: 4.317159061392065\n",
      "[EPOCH #1, step #2396] loss: 4.317027966280903\n",
      "[EPOCH #1, step #2398] loss: 4.31663736843874\n",
      "[EPOCH #1, step #2400] loss: 4.316449369405121\n",
      "[EPOCH #1, step #2402] loss: 4.316260774781493\n",
      "[EPOCH #1, step #2404] loss: 4.316005932516466\n",
      "[EPOCH #1, step #2406] loss: 4.3158692264636125\n",
      "[EPOCH #1, step #2408] loss: 4.315762198876919\n",
      "[EPOCH #1, step #2410] loss: 4.315518453080641\n",
      "[EPOCH #1, step #2412] loss: 4.315224559881161\n",
      "[EPOCH #1, step #2414] loss: 4.315002402607699\n",
      "[EPOCH #1, step #2416] loss: 4.3148227401839145\n",
      "[EPOCH #1, step #2418] loss: 4.314617654418788\n",
      "[EPOCH #1, step #2420] loss: 4.314524215787268\n",
      "[EPOCH #1, step #2422] loss: 4.314392293232608\n",
      "[EPOCH #1, step #2424] loss: 4.314238858862022\n",
      "[EPOCH #1, step #2426] loss: 4.313963171578161\n",
      "[EPOCH #1, step #2428] loss: 4.3138367223759255\n",
      "[EPOCH #1, step #2430] loss: 4.313678702519589\n",
      "[EPOCH #1, step #2432] loss: 4.313408174781313\n",
      "[EPOCH #1, step #2434] loss: 4.31318175836755\n",
      "[EPOCH #1, step #2436] loss: 4.312810964451298\n",
      "[EPOCH #1, step #2438] loss: 4.312574002135723\n",
      "[EPOCH #1, step #2440] loss: 4.312262466724463\n",
      "[EPOCH #1, step #2442] loss: 4.3121600461406295\n",
      "[EPOCH #1, step #2444] loss: 4.312059793491793\n",
      "[EPOCH #1, step #2446] loss: 4.311781960016959\n",
      "[EPOCH #1, step #2448] loss: 4.31170887477839\n",
      "[EPOCH #1, step #2450] loss: 4.31146944449513\n",
      "[EPOCH #1, step #2452] loss: 4.311139319412474\n",
      "[EPOCH #1, step #2454] loss: 4.310915594431145\n",
      "[EPOCH #1, step #2456] loss: 4.31067623905792\n",
      "[EPOCH #1, step #2458] loss: 4.310356977365036\n",
      "[EPOCH #1, step #2460] loss: 4.310235630443841\n",
      "[EPOCH #1, step #2462] loss: 4.309936214645268\n",
      "[EPOCH #1, step #2464] loss: 4.309744079117842\n",
      "[EPOCH #1, step #2466] loss: 4.309560236294935\n",
      "[EPOCH #1, step #2468] loss: 4.309441178662905\n",
      "[EPOCH #1, step #2470] loss: 4.309206403252182\n",
      "[EPOCH #1, step #2472] loss: 4.309112077100625\n",
      "[EPOCH #1, step #2474] loss: 4.3089369571570195\n",
      "[EPOCH #1, step #2476] loss: 4.308862582396537\n",
      "[EPOCH #1, step #2478] loss: 4.308653888417713\n",
      "[EPOCH #1, step #2480] loss: 4.3084457159907235\n",
      "[EPOCH #1, step #2482] loss: 4.3083424320443715\n",
      "[EPOCH #1, step #2484] loss: 4.308022796508053\n",
      "[EPOCH #1, step #2486] loss: 4.307756804825553\n",
      "[EPOCH #1, step #2488] loss: 4.307580910997249\n",
      "[EPOCH #1, step #2490] loss: 4.3072252131905815\n",
      "[EPOCH #1, step #2492] loss: 4.30699956871351\n",
      "[EPOCH #1, step #2494] loss: 4.306657505035401\n",
      "[EPOCH #1, step #2496] loss: 4.306412544926501\n",
      "[EPOCH #1, step #2498] loss: 4.306242052008028\n",
      "[EPOCH #1, elapsed time: 513.828[sec]] loss: 4.306214892864228\n",
      "[EPOCH #2, step #0] loss: 4.108457565307617\n",
      "[EPOCH #2, step #2] loss: 3.98269255956014\n",
      "[EPOCH #2, step #4] loss: 3.9961852073669433\n",
      "[EPOCH #2, step #6] loss: 4.009358610425677\n",
      "[EPOCH #2, step #8] loss: 4.0509221818712025\n",
      "[EPOCH #2, step #10] loss: 4.053405675021085\n",
      "[EPOCH #2, step #12] loss: 4.0445239177116985\n",
      "[EPOCH #2, step #14] loss: 4.046017980575561\n",
      "[EPOCH #2, step #16] loss: 4.048238824395573\n",
      "[EPOCH #2, step #18] loss: 4.014770934456273\n",
      "[EPOCH #2, step #20] loss: 3.9968087559654597\n",
      "[EPOCH #2, step #22] loss: 3.992701012155284\n",
      "[EPOCH #2, step #24] loss: 3.9836044788360594\n",
      "[EPOCH #2, step #26] loss: 3.981152622788041\n",
      "[EPOCH #2, step #28] loss: 3.975485061777049\n",
      "[EPOCH #2, step #30] loss: 3.9851343708653606\n",
      "[EPOCH #2, step #32] loss: 3.979181976029367\n",
      "[EPOCH #2, step #34] loss: 3.9832697459629602\n",
      "[EPOCH #2, step #36] loss: 3.9904101345990157\n",
      "[EPOCH #2, step #38] loss: 3.998161193652031\n",
      "[EPOCH #2, step #40] loss: 4.002428229262189\n",
      "[EPOCH #2, step #42] loss: 3.9990241749342097\n",
      "[EPOCH #2, step #44] loss: 4.001757955551147\n",
      "[EPOCH #2, step #46] loss: 4.009940152472638\n",
      "[EPOCH #2, step #48] loss: 4.012003377992279\n",
      "[EPOCH #2, step #50] loss: 4.018888478185616\n",
      "[EPOCH #2, step #52] loss: 4.019217684583844\n",
      "[EPOCH #2, step #54] loss: 4.023523430390791\n",
      "[EPOCH #2, step #56] loss: 4.0266110478786\n",
      "[EPOCH #2, step #58] loss: 4.03064442893206\n",
      "[EPOCH #2, step #60] loss: 4.030733049892988\n",
      "[EPOCH #2, step #62] loss: 4.033829295446003\n",
      "[EPOCH #2, step #64] loss: 4.033484231508695\n",
      "[EPOCH #2, step #66] loss: 4.03714486734191\n",
      "[EPOCH #2, step #68] loss: 4.0320828513822695\n",
      "[EPOCH #2, step #70] loss: 4.031223710154144\n",
      "[EPOCH #2, step #72] loss: 4.033355778210784\n",
      "[EPOCH #2, step #74] loss: 4.031998214721679\n",
      "[EPOCH #2, step #76] loss: 4.0349582634963\n",
      "[EPOCH #2, step #78] loss: 4.032069719290432\n",
      "[EPOCH #2, step #80] loss: 4.032869338989258\n",
      "[EPOCH #2, step #82] loss: 4.030892340533705\n",
      "[EPOCH #2, step #84] loss: 4.029433020423441\n",
      "[EPOCH #2, step #86] loss: 4.029935403801929\n",
      "[EPOCH #2, step #88] loss: 4.029043444086996\n",
      "[EPOCH #2, step #90] loss: 4.028835013672546\n",
      "[EPOCH #2, step #92] loss: 4.027876448887651\n",
      "[EPOCH #2, step #94] loss: 4.0271146071584605\n",
      "[EPOCH #2, step #96] loss: 4.028374588366637\n",
      "[EPOCH #2, step #98] loss: 4.02603289334461\n",
      "[EPOCH #2, step #100] loss: 4.03034488989575\n",
      "[EPOCH #2, step #102] loss: 4.0296140735589185\n",
      "[EPOCH #2, step #104] loss: 4.028636248906453\n",
      "[EPOCH #2, step #106] loss: 4.028262617432069\n",
      "[EPOCH #2, step #108] loss: 4.03053311907917\n",
      "[EPOCH #2, step #110] loss: 4.031907577772398\n",
      "[EPOCH #2, step #112] loss: 4.033400704375411\n",
      "[EPOCH #2, step #114] loss: 4.0358173080112625\n",
      "[EPOCH #2, step #116] loss: 4.034721621081361\n",
      "[EPOCH #2, step #118] loss: 4.033822963217728\n",
      "[EPOCH #2, step #120] loss: 4.03216769675578\n",
      "[EPOCH #2, step #122] loss: 4.033075268675641\n",
      "[EPOCH #2, step #124] loss: 4.033564371109009\n",
      "[EPOCH #2, step #126] loss: 4.033945117409774\n",
      "[EPOCH #2, step #128] loss: 4.035230026688686\n",
      "[EPOCH #2, step #130] loss: 4.034912850110586\n",
      "[EPOCH #2, step #132] loss: 4.034125822827332\n",
      "[EPOCH #2, step #134] loss: 4.035012803254304\n",
      "[EPOCH #2, step #136] loss: 4.033671488727096\n",
      "[EPOCH #2, step #138] loss: 4.030829227227959\n",
      "[EPOCH #2, step #140] loss: 4.030363449813627\n",
      "[EPOCH #2, step #142] loss: 4.0300408309989875\n",
      "[EPOCH #2, step #144] loss: 4.03246593804195\n",
      "[EPOCH #2, step #146] loss: 4.032165078078808\n",
      "[EPOCH #2, step #148] loss: 4.031479693099156\n",
      "[EPOCH #2, step #150] loss: 4.03017711165725\n",
      "[EPOCH #2, step #152] loss: 4.030646152745664\n",
      "[EPOCH #2, step #154] loss: 4.0330986576695596\n",
      "[EPOCH #2, step #156] loss: 4.031122467320436\n",
      "[EPOCH #2, step #158] loss: 4.030810581063324\n",
      "[EPOCH #2, step #160] loss: 4.030598806298298\n",
      "[EPOCH #2, step #162] loss: 4.030425001507156\n",
      "[EPOCH #2, step #164] loss: 4.029517891912749\n",
      "[EPOCH #2, step #166] loss: 4.027446441307753\n",
      "[EPOCH #2, step #168] loss: 4.0265727043151855\n",
      "[EPOCH #2, step #170] loss: 4.025608047407273\n",
      "[EPOCH #2, step #172] loss: 4.025930946272922\n",
      "[EPOCH #2, step #174] loss: 4.024958366666521\n",
      "[EPOCH #2, step #176] loss: 4.0258392573749955\n",
      "[EPOCH #2, step #178] loss: 4.025826984277651\n",
      "[EPOCH #2, step #180] loss: 4.027767518607292\n",
      "[EPOCH #2, step #182] loss: 4.02817897067044\n",
      "[EPOCH #2, step #184] loss: 4.026708233034289\n",
      "[EPOCH #2, step #186] loss: 4.026721833223965\n",
      "[EPOCH #2, step #188] loss: 4.0256938618957685\n",
      "[EPOCH #2, step #190] loss: 4.027722359951878\n",
      "[EPOCH #2, step #192] loss: 4.0279613986534155\n",
      "[EPOCH #2, step #194] loss: 4.0286264505141824\n",
      "[EPOCH #2, step #196] loss: 4.027170673844778\n",
      "[EPOCH #2, step #198] loss: 4.027790679404484\n",
      "[EPOCH #2, step #200] loss: 4.0289833000050255\n",
      "[EPOCH #2, step #202] loss: 4.028942853946404\n",
      "[EPOCH #2, step #204] loss: 4.028323553829658\n",
      "[EPOCH #2, step #206] loss: 4.029123305122633\n",
      "[EPOCH #2, step #208] loss: 4.029992038553411\n",
      "[EPOCH #2, step #210] loss: 4.031001700044243\n",
      "[EPOCH #2, step #212] loss: 4.030520788380797\n",
      "[EPOCH #2, step #214] loss: 4.030548790998237\n",
      "[EPOCH #2, step #216] loss: 4.031195072534447\n",
      "[EPOCH #2, step #218] loss: 4.030435719990839\n",
      "[EPOCH #2, step #220] loss: 4.029201878681442\n",
      "[EPOCH #2, step #222] loss: 4.028633474769079\n",
      "[EPOCH #2, step #224] loss: 4.028597340053982\n",
      "[EPOCH #2, step #226] loss: 4.029111576500443\n",
      "[EPOCH #2, step #228] loss: 4.0280332908880245\n",
      "[EPOCH #2, step #230] loss: 4.027834044906484\n",
      "[EPOCH #2, step #232] loss: 4.028100070011974\n",
      "[EPOCH #2, step #234] loss: 4.028731030606209\n",
      "[EPOCH #2, step #236] loss: 4.027501809446117\n",
      "[EPOCH #2, step #238] loss: 4.0297647170940705\n",
      "[EPOCH #2, step #240] loss: 4.02895156080792\n",
      "[EPOCH #2, step #242] loss: 4.029074218538073\n",
      "[EPOCH #2, step #244] loss: 4.0293705765081915\n",
      "[EPOCH #2, step #246] loss: 4.029134288973172\n",
      "[EPOCH #2, step #248] loss: 4.029793913584636\n",
      "[EPOCH #2, step #250] loss: 4.029627761042925\n",
      "[EPOCH #2, step #252] loss: 4.029424926509028\n",
      "[EPOCH #2, step #254] loss: 4.028640036489449\n",
      "[EPOCH #2, step #256] loss: 4.028068883873609\n",
      "[EPOCH #2, step #258] loss: 4.026709639427745\n",
      "[EPOCH #2, step #260] loss: 4.026145017010042\n",
      "[EPOCH #2, step #262] loss: 4.026589089926658\n",
      "[EPOCH #2, step #264] loss: 4.0262103836491425\n",
      "[EPOCH #2, step #266] loss: 4.026428486077527\n",
      "[EPOCH #2, step #268] loss: 4.025642798292592\n",
      "[EPOCH #2, step #270] loss: 4.024989204653075\n",
      "[EPOCH #2, step #272] loss: 4.024298792793637\n",
      "[EPOCH #2, step #274] loss: 4.023683182109486\n",
      "[EPOCH #2, step #276] loss: 4.02314385868582\n",
      "[EPOCH #2, step #278] loss: 4.022591745554332\n",
      "[EPOCH #2, step #280] loss: 4.021490010502499\n",
      "[EPOCH #2, step #282] loss: 4.021310533314628\n",
      "[EPOCH #2, step #284] loss: 4.020391712690655\n",
      "[EPOCH #2, step #286] loss: 4.019851926311799\n",
      "[EPOCH #2, step #288] loss: 4.018833213198969\n",
      "[EPOCH #2, step #290] loss: 4.018413972199168\n",
      "[EPOCH #2, step #292] loss: 4.018190974668431\n",
      "[EPOCH #2, step #294] loss: 4.018172082254442\n",
      "[EPOCH #2, step #296] loss: 4.017362164327191\n",
      "[EPOCH #2, step #298] loss: 4.016611765060935\n",
      "[EPOCH #2, step #300] loss: 4.015297827134496\n",
      "[EPOCH #2, step #302] loss: 4.016069894576623\n",
      "[EPOCH #2, step #304] loss: 4.016905027139383\n",
      "[EPOCH #2, step #306] loss: 4.017364211501826\n",
      "[EPOCH #2, step #308] loss: 4.016680666543905\n",
      "[EPOCH #2, step #310] loss: 4.016016389779339\n",
      "[EPOCH #2, step #312] loss: 4.016186353116751\n",
      "[EPOCH #2, step #314] loss: 4.016683599683973\n",
      "[EPOCH #2, step #316] loss: 4.016427471058602\n",
      "[EPOCH #2, step #318] loss: 4.015896885372628\n",
      "[EPOCH #2, step #320] loss: 4.016745677246854\n",
      "[EPOCH #2, step #322] loss: 4.01730956972199\n",
      "[EPOCH #2, step #324] loss: 4.0160329569303075\n",
      "[EPOCH #2, step #326] loss: 4.015452968235774\n",
      "[EPOCH #2, step #328] loss: 4.0152323390937505\n",
      "[EPOCH #2, step #330] loss: 4.0142173630233255\n",
      "[EPOCH #2, step #332] loss: 4.015603482902229\n",
      "[EPOCH #2, step #334] loss: 4.0169169589654725\n",
      "[EPOCH #2, step #336] loss: 4.017892910394187\n",
      "[EPOCH #2, step #338] loss: 4.018294054498363\n",
      "[EPOCH #2, step #340] loss: 4.019113979731137\n",
      "[EPOCH #2, step #342] loss: 4.01954071862357\n",
      "[EPOCH #2, step #344] loss: 4.019352208704189\n",
      "[EPOCH #2, step #346] loss: 4.0199279682093465\n",
      "[EPOCH #2, step #348] loss: 4.019694623427951\n",
      "[EPOCH #2, step #350] loss: 4.018408104225442\n",
      "[EPOCH #2, step #352] loss: 4.018002249363799\n",
      "[EPOCH #2, step #354] loss: 4.017761714021924\n",
      "[EPOCH #2, step #356] loss: 4.01786577401041\n",
      "[EPOCH #2, step #358] loss: 4.017251395249433\n",
      "[EPOCH #2, step #360] loss: 4.01704601633912\n",
      "[EPOCH #2, step #362] loss: 4.017295516226903\n",
      "[EPOCH #2, step #364] loss: 4.016993775433057\n",
      "[EPOCH #2, step #366] loss: 4.0170673654904485\n",
      "[EPOCH #2, step #368] loss: 4.016674704021877\n",
      "[EPOCH #2, step #370] loss: 4.017660669882021\n",
      "[EPOCH #2, step #372] loss: 4.016044395538821\n",
      "[EPOCH #2, step #374] loss: 4.016269877115885\n",
      "[EPOCH #2, step #376] loss: 4.015497618075707\n",
      "[EPOCH #2, step #378] loss: 4.015658812032211\n",
      "[EPOCH #2, step #380] loss: 4.015972492263073\n",
      "[EPOCH #2, step #382] loss: 4.015873493787203\n",
      "[EPOCH #2, step #384] loss: 4.015889748660001\n",
      "[EPOCH #2, step #386] loss: 4.015290670616682\n",
      "[EPOCH #2, step #388] loss: 4.015464072975218\n",
      "[EPOCH #2, step #390] loss: 4.014372745743188\n",
      "[EPOCH #2, step #392] loss: 4.013750229173034\n",
      "[EPOCH #2, step #394] loss: 4.012769869309437\n",
      "[EPOCH #2, step #396] loss: 4.012105336417479\n",
      "[EPOCH #2, step #398] loss: 4.011103001453524\n",
      "[EPOCH #2, step #400] loss: 4.0105779985537255\n",
      "[EPOCH #2, step #402] loss: 4.010486222378374\n",
      "[EPOCH #2, step #404] loss: 4.010524579625071\n",
      "[EPOCH #2, step #406] loss: 4.0097292336550625\n",
      "[EPOCH #2, step #408] loss: 4.009752778960324\n",
      "[EPOCH #2, step #410] loss: 4.009107743446554\n",
      "[EPOCH #2, step #412] loss: 4.009193288789246\n",
      "[EPOCH #2, step #414] loss: 4.009301077601421\n",
      "[EPOCH #2, step #416] loss: 4.008801609492131\n",
      "[EPOCH #2, step #418] loss: 4.008484282755339\n",
      "[EPOCH #2, step #420] loss: 4.0071234618116724\n",
      "[EPOCH #2, step #422] loss: 4.006412781722156\n",
      "[EPOCH #2, step #424] loss: 4.006240694382612\n",
      "[EPOCH #2, step #426] loss: 4.005329724497203\n",
      "[EPOCH #2, step #428] loss: 4.005495426538107\n",
      "[EPOCH #2, step #430] loss: 4.005174913428499\n",
      "[EPOCH #2, step #432] loss: 4.005971531945068\n",
      "[EPOCH #2, step #434] loss: 4.006184999970184\n",
      "[EPOCH #2, step #436] loss: 4.006994859577589\n",
      "[EPOCH #2, step #438] loss: 4.006585253126801\n",
      "[EPOCH #2, step #440] loss: 4.005902939642908\n",
      "[EPOCH #2, step #442] loss: 4.005538806958339\n",
      "[EPOCH #2, step #444] loss: 4.0053385322013595\n",
      "[EPOCH #2, step #446] loss: 4.005084114586747\n",
      "[EPOCH #2, step #448] loss: 4.005120114919072\n",
      "[EPOCH #2, step #450] loss: 4.00519716184578\n",
      "[EPOCH #2, step #452] loss: 4.005349896601494\n",
      "[EPOCH #2, step #454] loss: 4.005477485551939\n",
      "[EPOCH #2, step #456] loss: 4.0058020747203535\n",
      "[EPOCH #2, step #458] loss: 4.005164891806044\n",
      "[EPOCH #2, step #460] loss: 4.00473440184769\n",
      "[EPOCH #2, step #462] loss: 4.004553346860486\n",
      "[EPOCH #2, step #464] loss: 4.004555406365343\n",
      "[EPOCH #2, step #466] loss: 4.004365824529905\n",
      "[EPOCH #2, step #468] loss: 4.004461993540782\n",
      "[EPOCH #2, step #470] loss: 4.005428805725843\n",
      "[EPOCH #2, step #472] loss: 4.005714144817619\n",
      "[EPOCH #2, step #474] loss: 4.004399007998015\n",
      "[EPOCH #2, step #476] loss: 4.004439979729162\n",
      "[EPOCH #2, step #478] loss: 4.004269786567927\n",
      "[EPOCH #2, step #480] loss: 4.004569475467388\n",
      "[EPOCH #2, step #482] loss: 4.003820563942256\n",
      "[EPOCH #2, step #484] loss: 4.00390925751519\n",
      "[EPOCH #2, step #486] loss: 4.003791942243948\n",
      "[EPOCH #2, step #488] loss: 4.003706566882768\n",
      "[EPOCH #2, step #490] loss: 4.003233831428948\n",
      "[EPOCH #2, step #492] loss: 4.0026557682493875\n",
      "[EPOCH #2, step #494] loss: 4.001707312555024\n",
      "[EPOCH #2, step #496] loss: 4.001415959786121\n",
      "[EPOCH #2, step #498] loss: 4.000501181176287\n",
      "[EPOCH #2, step #500] loss: 3.999949022205528\n",
      "[EPOCH #2, step #502] loss: 3.999303826280901\n",
      "[EPOCH #2, step #504] loss: 3.9991843648476175\n",
      "[EPOCH #2, step #506] loss: 3.9989625659920054\n",
      "[EPOCH #2, step #508] loss: 3.999335832352254\n",
      "[EPOCH #2, step #510] loss: 3.9985643814221286\n",
      "[EPOCH #2, step #512] loss: 3.998783221254107\n",
      "[EPOCH #2, step #514] loss: 3.9984893650684543\n",
      "[EPOCH #2, step #516] loss: 3.9983040262698206\n",
      "[EPOCH #2, step #518] loss: 3.998228721765654\n",
      "[EPOCH #2, step #520] loss: 3.998054373058385\n",
      "[EPOCH #2, step #522] loss: 3.9982604474456087\n",
      "[EPOCH #2, step #524] loss: 3.9973026198432557\n",
      "[EPOCH #2, step #526] loss: 3.9976867991561456\n",
      "[EPOCH #2, step #528] loss: 3.998009434719843\n",
      "[EPOCH #2, step #530] loss: 3.998018994843219\n",
      "[EPOCH #2, step #532] loss: 3.9976923886204303\n",
      "[EPOCH #2, step #534] loss: 3.9979938279802556\n",
      "[EPOCH #2, step #536] loss: 3.9977054063168316\n",
      "[EPOCH #2, step #538] loss: 3.997298459175124\n",
      "[EPOCH #2, step #540] loss: 3.997161512233854\n",
      "[EPOCH #2, step #542] loss: 3.9976722298406107\n",
      "[EPOCH #2, step #544] loss: 3.997343850792001\n",
      "[EPOCH #2, step #546] loss: 3.9972577448083015\n",
      "[EPOCH #2, step #548] loss: 3.997156030276217\n",
      "[EPOCH #2, step #550] loss: 3.9968138065615064\n",
      "[EPOCH #2, step #552] loss: 3.9969554331160366\n",
      "[EPOCH #2, step #554] loss: 3.9971612633885565\n",
      "[EPOCH #2, step #556] loss: 3.9968107470062093\n",
      "[EPOCH #2, step #558] loss: 3.997120437553829\n",
      "[EPOCH #2, step #560] loss: 3.9967484605928583\n",
      "[EPOCH #2, step #562] loss: 3.9965912546188327\n",
      "[EPOCH #2, step #564] loss: 3.996541422025292\n",
      "[EPOCH #2, step #566] loss: 3.9964132927082203\n",
      "[EPOCH #2, step #568] loss: 3.9966016678902303\n",
      "[EPOCH #2, step #570] loss: 3.997067178402181\n",
      "[EPOCH #2, step #572] loss: 3.9963455462330923\n",
      "[EPOCH #2, step #574] loss: 3.99600064319113\n",
      "[EPOCH #2, step #576] loss: 3.9957062801413974\n",
      "[EPOCH #2, step #578] loss: 3.995511462651386\n",
      "[EPOCH #2, step #580] loss: 3.995133084397308\n",
      "[EPOCH #2, step #582] loss: 3.9954974823096197\n",
      "[EPOCH #2, step #584] loss: 3.9949819658556556\n",
      "[EPOCH #2, step #586] loss: 3.9944391124699345\n",
      "[EPOCH #2, step #588] loss: 3.995018237313107\n",
      "[EPOCH #2, step #590] loss: 3.9946275358474397\n",
      "[EPOCH #2, step #592] loss: 3.9941425616986432\n",
      "[EPOCH #2, step #594] loss: 3.9937712585224823\n",
      "[EPOCH #2, step #596] loss: 3.993765903677373\n",
      "[EPOCH #2, step #598] loss: 3.9937300280059915\n",
      "[EPOCH #2, step #600] loss: 3.9931708564377466\n",
      "[EPOCH #2, step #602] loss: 3.9926974413604484\n",
      "[EPOCH #2, step #604] loss: 3.9925593372218864\n",
      "[EPOCH #2, step #606] loss: 3.992072783349177\n",
      "[EPOCH #2, step #608] loss: 3.991772078528193\n",
      "[EPOCH #2, step #610] loss: 3.9917278012745507\n",
      "[EPOCH #2, step #612] loss: 3.99194483850364\n",
      "[EPOCH #2, step #614] loss: 3.991683621522857\n",
      "[EPOCH #2, step #616] loss: 3.9916619628522927\n",
      "[EPOCH #2, step #618] loss: 3.9915726801112705\n",
      "[EPOCH #2, step #620] loss: 3.991493473114407\n",
      "[EPOCH #2, step #622] loss: 3.991256961470431\n",
      "[EPOCH #2, step #624] loss: 3.991328995895386\n",
      "[EPOCH #2, step #626] loss: 3.9914650879027933\n",
      "[EPOCH #2, step #628] loss: 3.9913420707508567\n",
      "[EPOCH #2, step #630] loss: 3.990757874188068\n",
      "[EPOCH #2, step #632] loss: 3.9898361120178802\n",
      "[EPOCH #2, step #634] loss: 3.988980925177026\n",
      "[EPOCH #2, step #636] loss: 3.989263198813614\n",
      "[EPOCH #2, step #638] loss: 3.989218045848076\n",
      "[EPOCH #2, step #640] loss: 3.989502261469777\n",
      "[EPOCH #2, step #642] loss: 3.9892265529691895\n",
      "[EPOCH #2, step #644] loss: 3.988410577478335\n",
      "[EPOCH #2, step #646] loss: 3.9882875509571623\n",
      "[EPOCH #2, step #648] loss: 3.9884360314150253\n",
      "[EPOCH #2, step #650] loss: 3.9882792152018043\n",
      "[EPOCH #2, step #652] loss: 3.9880704500043556\n",
      "[EPOCH #2, step #654] loss: 3.988047816007192\n",
      "[EPOCH #2, step #656] loss: 3.98824367711896\n",
      "[EPOCH #2, step #658] loss: 3.988546772683336\n",
      "[EPOCH #2, step #660] loss: 3.988538116983134\n",
      "[EPOCH #2, step #662] loss: 3.9882175433330045\n",
      "[EPOCH #2, step #664] loss: 3.9880752412896405\n",
      "[EPOCH #2, step #666] loss: 3.988293567340056\n",
      "[EPOCH #2, step #668] loss: 3.9882452997569726\n",
      "[EPOCH #2, step #670] loss: 3.9882845999409295\n",
      "[EPOCH #2, step #672] loss: 3.988484628133221\n",
      "[EPOCH #2, step #674] loss: 3.9879689862993026\n",
      "[EPOCH #2, step #676] loss: 3.987981905084945\n",
      "[EPOCH #2, step #678] loss: 3.9885021102270426\n",
      "[EPOCH #2, step #680] loss: 3.988105442380415\n",
      "[EPOCH #2, step #682] loss: 3.987705523936326\n",
      "[EPOCH #2, step #684] loss: 3.98813323348108\n",
      "[EPOCH #2, step #686] loss: 3.9876134572591324\n",
      "[EPOCH #2, step #688] loss: 3.9875583465282736\n",
      "[EPOCH #2, step #690] loss: 3.9877588555712777\n",
      "[EPOCH #2, step #692] loss: 3.987212780750159\n",
      "[EPOCH #2, step #694] loss: 3.9864840733919213\n",
      "[EPOCH #2, step #696] loss: 3.9867291464183046\n",
      "[EPOCH #2, step #698] loss: 3.986136620989514\n",
      "[EPOCH #2, step #700] loss: 3.985639896950606\n",
      "[EPOCH #2, step #702] loss: 3.9849089365426034\n",
      "[EPOCH #2, step #704] loss: 3.985235850016276\n",
      "[EPOCH #2, step #706] loss: 3.9849297366351353\n",
      "[EPOCH #2, step #708] loss: 3.985251404502664\n",
      "[EPOCH #2, step #710] loss: 3.985156546832808\n",
      "[EPOCH #2, step #712] loss: 3.985105852926931\n",
      "[EPOCH #2, step #714] loss: 3.9856242299913527\n",
      "[EPOCH #2, step #716] loss: 3.9859709307405904\n",
      "[EPOCH #2, step #718] loss: 3.9859571397221636\n",
      "[EPOCH #2, step #720] loss: 3.9861348511937917\n",
      "[EPOCH #2, step #722] loss: 3.9866447105777048\n",
      "[EPOCH #2, step #724] loss: 3.986755293484392\n",
      "[EPOCH #2, step #726] loss: 3.986812951640217\n",
      "[EPOCH #2, step #728] loss: 3.986483379319535\n",
      "[EPOCH #2, step #730] loss: 3.986580958607748\n",
      "[EPOCH #2, step #732] loss: 3.9864442989250484\n",
      "[EPOCH #2, step #734] loss: 3.986195499718595\n",
      "[EPOCH #2, step #736] loss: 3.9856978391209967\n",
      "[EPOCH #2, step #738] loss: 3.9861593185161546\n",
      "[EPOCH #2, step #740] loss: 3.985448457934113\n",
      "[EPOCH #2, step #742] loss: 3.985190141249152\n",
      "[EPOCH #2, step #744] loss: 3.9847592421026037\n",
      "[EPOCH #2, step #746] loss: 3.984855488441396\n",
      "[EPOCH #2, step #748] loss: 3.984136312443997\n",
      "[EPOCH #2, step #750] loss: 3.9841134138653347\n",
      "[EPOCH #2, step #752] loss: 3.9839164286179054\n",
      "[EPOCH #2, step #754] loss: 3.9838240939260317\n",
      "[EPOCH #2, step #756] loss: 3.983681408543253\n",
      "[EPOCH #2, step #758] loss: 3.9837715126309\n",
      "[EPOCH #2, step #760] loss: 3.983688436575851\n",
      "[EPOCH #2, step #762] loss: 3.9834109002609552\n",
      "[EPOCH #2, step #764] loss: 3.9834672379337883\n",
      "[EPOCH #2, step #766] loss: 3.982989760390161\n",
      "[EPOCH #2, step #768] loss: 3.982579692597507\n",
      "[EPOCH #2, step #770] loss: 3.9824705355826056\n",
      "[EPOCH #2, step #772] loss: 3.981638885253768\n",
      "[EPOCH #2, step #774] loss: 3.9818092927625104\n",
      "[EPOCH #2, step #776] loss: 3.981643602808163\n",
      "[EPOCH #2, step #778] loss: 3.9816919058676095\n",
      "[EPOCH #2, step #780] loss: 3.981671026513152\n",
      "[EPOCH #2, step #782] loss: 3.981689609025782\n",
      "[EPOCH #2, step #784] loss: 3.981730926112764\n",
      "[EPOCH #2, step #786] loss: 3.9820629574898088\n",
      "[EPOCH #2, step #788] loss: 3.981780861418208\n",
      "[EPOCH #2, step #790] loss: 3.9812595952777885\n",
      "[EPOCH #2, step #792] loss: 3.9816463700158597\n",
      "[EPOCH #2, step #794] loss: 3.9817813399452833\n",
      "[EPOCH #2, step #796] loss: 3.9816673253680412\n",
      "[EPOCH #2, step #798] loss: 3.98155432260678\n",
      "[EPOCH #2, step #800] loss: 3.9812618992599504\n",
      "[EPOCH #2, step #802] loss: 3.981478643595504\n",
      "[EPOCH #2, step #804] loss: 3.9813679016895174\n",
      "[EPOCH #2, step #806] loss: 3.98092651130837\n",
      "[EPOCH #2, step #808] loss: 3.9806598476485355\n",
      "[EPOCH #2, step #810] loss: 3.9801381736736556\n",
      "[EPOCH #2, step #812] loss: 3.980002117039679\n",
      "[EPOCH #2, step #814] loss: 3.980293090504371\n",
      "[EPOCH #2, step #816] loss: 3.98042865190541\n",
      "[EPOCH #2, step #818] loss: 3.980358297280485\n",
      "[EPOCH #2, step #820] loss: 3.979932571009219\n",
      "[EPOCH #2, step #822] loss: 3.979940145302514\n",
      "[EPOCH #2, step #824] loss: 3.979644389297023\n",
      "[EPOCH #2, step #826] loss: 3.9795080491104033\n",
      "[EPOCH #2, step #828] loss: 3.9793920936860565\n",
      "[EPOCH #2, step #830] loss: 3.979684970869484\n",
      "[EPOCH #2, step #832] loss: 3.9789613681394798\n",
      "[EPOCH #2, step #834] loss: 3.9787708128283836\n",
      "[EPOCH #2, step #836] loss: 3.9784982218679703\n",
      "[EPOCH #2, step #838] loss: 3.978054131881841\n",
      "[EPOCH #2, step #840] loss: 3.9780652350109342\n",
      "[EPOCH #2, step #842] loss: 3.9776554121807095\n",
      "[EPOCH #2, step #844] loss: 3.9773836813029453\n",
      "[EPOCH #2, step #846] loss: 3.9772367167782474\n",
      "[EPOCH #2, step #848] loss: 3.976813211036655\n",
      "[EPOCH #2, step #850] loss: 3.9764263551467733\n",
      "[EPOCH #2, step #852] loss: 3.9766982496134142\n",
      "[EPOCH #2, step #854] loss: 3.976627114223458\n",
      "[EPOCH #2, step #856] loss: 3.9766887180168125\n",
      "[EPOCH #2, step #858] loss: 3.9764242433141637\n",
      "[EPOCH #2, step #860] loss: 3.9767597909588432\n",
      "[EPOCH #2, step #862] loss: 3.9767994145805563\n",
      "[EPOCH #2, step #864] loss: 3.976679726969989\n",
      "[EPOCH #2, step #866] loss: 3.9764529649499103\n",
      "[EPOCH #2, step #868] loss: 3.9766328713424737\n",
      "[EPOCH #2, step #870] loss: 3.976362765998709\n",
      "[EPOCH #2, step #872] loss: 3.9759656653781117\n",
      "[EPOCH #2, step #874] loss: 3.9757814311981203\n",
      "[EPOCH #2, step #876] loss: 3.9756924271447627\n",
      "[EPOCH #2, step #878] loss: 3.975692318839289\n",
      "[EPOCH #2, step #880] loss: 3.9765505027554497\n",
      "[EPOCH #2, step #882] loss: 3.9760756014697547\n",
      "[EPOCH #2, step #884] loss: 3.9761201691492802\n",
      "[EPOCH #2, step #886] loss: 3.9756761801417544\n",
      "[EPOCH #2, step #888] loss: 3.9757634705714087\n",
      "[EPOCH #2, step #890] loss: 3.975403307262896\n",
      "[EPOCH #2, step #892] loss: 3.975094360573695\n",
      "[EPOCH #2, step #894] loss: 3.974586152764006\n",
      "[EPOCH #2, step #896] loss: 3.974784609200298\n",
      "[EPOCH #2, step #898] loss: 3.9746407147111564\n",
      "[EPOCH #2, step #900] loss: 3.9745599657264057\n",
      "[EPOCH #2, step #902] loss: 3.974530784790698\n",
      "[EPOCH #2, step #904] loss: 3.9740831775559906\n",
      "[EPOCH #2, step #906] loss: 3.97382111244454\n",
      "[EPOCH #2, step #908] loss: 3.9736957169733165\n",
      "[EPOCH #2, step #910] loss: 3.973812799684041\n",
      "[EPOCH #2, step #912] loss: 3.973878017782773\n",
      "[EPOCH #2, step #914] loss: 3.97399944477394\n",
      "[EPOCH #2, step #916] loss: 3.974064960344537\n",
      "[EPOCH #2, step #918] loss: 3.9740239108088744\n",
      "[EPOCH #2, step #920] loss: 3.9740250594711717\n",
      "[EPOCH #2, step #922] loss: 3.9739638811072187\n",
      "[EPOCH #2, step #924] loss: 3.9740223358772897\n",
      "[EPOCH #2, step #926] loss: 3.973678958711758\n",
      "[EPOCH #2, step #928] loss: 3.973936889861962\n",
      "[EPOCH #2, step #930] loss: 3.9736858863707645\n",
      "[EPOCH #2, step #932] loss: 3.97332342082409\n",
      "[EPOCH #2, step #934] loss: 3.973023896293844\n",
      "[EPOCH #2, step #936] loss: 3.972817179487507\n",
      "[EPOCH #2, step #938] loss: 3.9729855367804743\n",
      "[EPOCH #2, step #940] loss: 3.9726888667257634\n",
      "[EPOCH #2, step #942] loss: 3.9726172105378588\n",
      "[EPOCH #2, step #944] loss: 3.972215892902758\n",
      "[EPOCH #2, step #946] loss: 3.9721345178932426\n",
      "[EPOCH #2, step #948] loss: 3.972204021206646\n",
      "[EPOCH #2, step #950] loss: 3.9719881136460007\n",
      "[EPOCH #2, step #952] loss: 3.9717063481009642\n",
      "[EPOCH #2, step #954] loss: 3.971273686873351\n",
      "[EPOCH #2, step #956] loss: 3.971059134013974\n",
      "[EPOCH #2, step #958] loss: 3.970687363518167\n",
      "[EPOCH #2, step #960] loss: 3.97063691112427\n",
      "[EPOCH #2, step #962] loss: 3.970477011840044\n",
      "[EPOCH #2, step #964] loss: 3.96991981076453\n",
      "[EPOCH #2, step #966] loss: 3.9699215669543197\n",
      "[EPOCH #2, step #968] loss: 3.9697108030073167\n",
      "[EPOCH #2, step #970] loss: 3.9693431805140205\n",
      "[EPOCH #2, step #972] loss: 3.968880882243581\n",
      "[EPOCH #2, step #974] loss: 3.9686642035459863\n",
      "[EPOCH #2, step #976] loss: 3.968647336764614\n",
      "[EPOCH #2, step #978] loss: 3.9690393344618085\n",
      "[EPOCH #2, step #980] loss: 3.969161967132677\n",
      "[EPOCH #2, step #982] loss: 3.969151274476386\n",
      "[EPOCH #2, step #984] loss: 3.968992703820243\n",
      "[EPOCH #2, step #986] loss: 3.9687874428286256\n",
      "[EPOCH #2, step #988] loss: 3.9689477386802463\n",
      "[EPOCH #2, step #990] loss: 3.968861556558388\n",
      "[EPOCH #2, step #992] loss: 3.9687226582149724\n",
      "[EPOCH #2, step #994] loss: 3.9689330021939684\n",
      "[EPOCH #2, step #996] loss: 3.96878331092559\n",
      "[EPOCH #2, step #998] loss: 3.968219453985388\n",
      "[EPOCH #2, step #1000] loss: 3.967836303548975\n",
      "[EPOCH #2, step #1002] loss: 3.9677634098950554\n",
      "[EPOCH #2, step #1004] loss: 3.967224518695281\n",
      "[EPOCH #2, step #1006] loss: 3.9671606132030015\n",
      "[EPOCH #2, step #1008] loss: 3.967041489626655\n",
      "[EPOCH #2, step #1010] loss: 3.9668597382678477\n",
      "[EPOCH #2, step #1012] loss: 3.9669625519058664\n",
      "[EPOCH #2, step #1014] loss: 3.9671422716432017\n",
      "[EPOCH #2, step #1016] loss: 3.967147419000211\n",
      "[EPOCH #2, step #1018] loss: 3.9669379088314756\n",
      "[EPOCH #2, step #1020] loss: 3.9665707481713066\n",
      "[EPOCH #2, step #1022] loss: 3.966283841333548\n",
      "[EPOCH #2, step #1024] loss: 3.9659037717958774\n",
      "[EPOCH #2, step #1026] loss: 3.965976620602631\n",
      "[EPOCH #2, step #1028] loss: 3.9656426473308004\n",
      "[EPOCH #2, step #1030] loss: 3.965586253674023\n",
      "[EPOCH #2, step #1032] loss: 3.9655252158468715\n",
      "[EPOCH #2, step #1034] loss: 3.964988038620511\n",
      "[EPOCH #2, step #1036] loss: 3.964791732216065\n",
      "[EPOCH #2, step #1038] loss: 3.964387839292539\n",
      "[EPOCH #2, step #1040] loss: 3.9637705040710918\n",
      "[EPOCH #2, step #1042] loss: 3.963398278731056\n",
      "[EPOCH #2, step #1044] loss: 3.963521435386256\n",
      "[EPOCH #2, step #1046] loss: 3.963266790539396\n",
      "[EPOCH #2, step #1048] loss: 3.9631293747286436\n",
      "[EPOCH #2, step #1050] loss: 3.9632086109593296\n",
      "[EPOCH #2, step #1052] loss: 3.963091781449567\n",
      "[EPOCH #2, step #1054] loss: 3.963477190749905\n",
      "[EPOCH #2, step #1056] loss: 3.963280393813394\n",
      "[EPOCH #2, step #1058] loss: 3.9630281017905027\n",
      "[EPOCH #2, step #1060] loss: 3.9630749090789736\n",
      "[EPOCH #2, step #1062] loss: 3.962864827571449\n",
      "[EPOCH #2, step #1064] loss: 3.9625500435000856\n",
      "[EPOCH #2, step #1066] loss: 3.962186410255039\n",
      "[EPOCH #2, step #1068] loss: 3.9617460253530847\n",
      "[EPOCH #2, step #1070] loss: 3.961722469908628\n",
      "[EPOCH #2, step #1072] loss: 3.9614410218188167\n",
      "[EPOCH #2, step #1074] loss: 3.961369948941608\n",
      "[EPOCH #2, step #1076] loss: 3.9613688753618614\n",
      "[EPOCH #2, step #1078] loss: 3.9610931351849943\n",
      "[EPOCH #2, step #1080] loss: 3.960945628507616\n",
      "[EPOCH #2, step #1082] loss: 3.9608899428683744\n",
      "[EPOCH #2, step #1084] loss: 3.9605913748938915\n",
      "[EPOCH #2, step #1086] loss: 3.960493948663608\n",
      "[EPOCH #2, step #1088] loss: 3.96003009268075\n",
      "[EPOCH #2, step #1090] loss: 3.9598757630635792\n",
      "[EPOCH #2, step #1092] loss: 3.959773364245946\n",
      "[EPOCH #2, step #1094] loss: 3.959739986184525\n",
      "[EPOCH #2, step #1096] loss: 3.959397997764859\n",
      "[EPOCH #2, step #1098] loss: 3.959211352741425\n",
      "[EPOCH #2, step #1100] loss: 3.9590114254392783\n",
      "[EPOCH #2, step #1102] loss: 3.959155115341989\n",
      "[EPOCH #2, step #1104] loss: 3.9587306404545295\n",
      "[EPOCH #2, step #1106] loss: 3.9586244394031858\n",
      "[EPOCH #2, step #1108] loss: 3.9587996044709297\n",
      "[EPOCH #2, step #1110] loss: 3.958884166662592\n",
      "[EPOCH #2, step #1112] loss: 3.9588805622381877\n",
      "[EPOCH #2, step #1114] loss: 3.959074463651854\n",
      "[EPOCH #2, step #1116] loss: 3.958965014429528\n",
      "[EPOCH #2, step #1118] loss: 3.958781860469174\n",
      "[EPOCH #2, step #1120] loss: 3.9585521997456885\n",
      "[EPOCH #2, step #1122] loss: 3.9582468119457377\n",
      "[EPOCH #2, step #1124] loss: 3.957950582080417\n",
      "[EPOCH #2, step #1126] loss: 3.9580044919871185\n",
      "[EPOCH #2, step #1128] loss: 3.957621223003702\n",
      "[EPOCH #2, step #1130] loss: 3.9575290589286203\n",
      "[EPOCH #2, step #1132] loss: 3.9575280135222903\n",
      "[EPOCH #2, step #1134] loss: 3.9573223338778325\n",
      "[EPOCH #2, step #1136] loss: 3.9571526235095638\n",
      "[EPOCH #2, step #1138] loss: 3.956785629672686\n",
      "[EPOCH #2, step #1140] loss: 3.9567497988524507\n",
      "[EPOCH #2, step #1142] loss: 3.9565497913177037\n",
      "[EPOCH #2, step #1144] loss: 3.9561222978033874\n",
      "[EPOCH #2, step #1146] loss: 3.9560445421346917\n",
      "[EPOCH #2, step #1148] loss: 3.9560959100515767\n",
      "[EPOCH #2, step #1150] loss: 3.9559793420504943\n",
      "[EPOCH #2, step #1152] loss: 3.955858625335892\n",
      "[EPOCH #2, step #1154] loss: 3.9556239732932217\n",
      "[EPOCH #2, step #1156] loss: 3.9554082630210226\n",
      "[EPOCH #2, step #1158] loss: 3.955455276655472\n",
      "[EPOCH #2, step #1160] loss: 3.955330194634266\n",
      "[EPOCH #2, step #1162] loss: 3.9549096936515356\n",
      "[EPOCH #2, step #1164] loss: 3.954765246149808\n",
      "[EPOCH #2, step #1166] loss: 3.9546602830584474\n",
      "[EPOCH #2, step #1168] loss: 3.954801213547549\n",
      "[EPOCH #2, step #1170] loss: 3.955014285829513\n",
      "[EPOCH #2, step #1172] loss: 3.954850046226131\n",
      "[EPOCH #2, step #1174] loss: 3.954481811320528\n",
      "[EPOCH #2, step #1176] loss: 3.9542338226240576\n",
      "[EPOCH #2, step #1178] loss: 3.953803145349582\n",
      "[EPOCH #2, step #1180] loss: 3.953747283594776\n",
      "[EPOCH #2, step #1182] loss: 3.9534920686800805\n",
      "[EPOCH #2, step #1184] loss: 3.9534375975403604\n",
      "[EPOCH #2, step #1186] loss: 3.953230452919167\n",
      "[EPOCH #2, step #1188] loss: 3.953368728555883\n",
      "[EPOCH #2, step #1190] loss: 3.953249306362482\n",
      "[EPOCH #2, step #1192] loss: 3.95339627957404\n",
      "[EPOCH #2, step #1194] loss: 3.9532062161417687\n",
      "[EPOCH #2, step #1196] loss: 3.952949469947974\n",
      "[EPOCH #2, step #1198] loss: 3.9528345395566227\n",
      "[EPOCH #2, step #1200] loss: 3.952822457344506\n",
      "[EPOCH #2, step #1202] loss: 3.952716739397691\n",
      "[EPOCH #2, step #1204] loss: 3.952418865504601\n",
      "[EPOCH #2, step #1206] loss: 3.9520887575963357\n",
      "[EPOCH #2, step #1208] loss: 3.9517750201686734\n",
      "[EPOCH #2, step #1210] loss: 3.9517153671809604\n",
      "[EPOCH #2, step #1212] loss: 3.951641566087073\n",
      "[EPOCH #2, step #1214] loss: 3.9515439410268525\n",
      "[EPOCH #2, step #1216] loss: 3.9516173613884455\n",
      "[EPOCH #2, step #1218] loss: 3.9516927394053307\n",
      "[EPOCH #2, step #1220] loss: 3.951890893689342\n",
      "[EPOCH #2, step #1222] loss: 3.9520120591485686\n",
      "[EPOCH #2, step #1224] loss: 3.952106878319565\n",
      "[EPOCH #2, step #1226] loss: 3.952099742594053\n",
      "[EPOCH #2, step #1228] loss: 3.951802819603531\n",
      "[EPOCH #2, step #1230] loss: 3.95146439832754\n",
      "[EPOCH #2, step #1232] loss: 3.9510513040367803\n",
      "[EPOCH #2, step #1234] loss: 3.950590216293026\n",
      "[EPOCH #2, step #1236] loss: 3.9504661847240228\n",
      "[EPOCH #2, step #1238] loss: 3.9502459986735197\n",
      "[EPOCH #2, step #1240] loss: 3.9501942504710676\n",
      "[EPOCH #2, step #1242] loss: 3.950198053834137\n",
      "[EPOCH #2, step #1244] loss: 3.9500364339974032\n",
      "[EPOCH #2, step #1246] loss: 3.9496744979163982\n",
      "[EPOCH #2, step #1248] loss: 3.9497618612239034\n",
      "[EPOCH #2, step #1250] loss: 3.9495110138238285\n",
      "[EPOCH #2, step #1252] loss: 3.9492592665070263\n",
      "[EPOCH #2, step #1254] loss: 3.949305253769772\n",
      "[EPOCH #2, step #1256] loss: 3.9489585850669355\n",
      "[EPOCH #2, step #1258] loss: 3.9488745932544953\n",
      "[EPOCH #2, step #1260] loss: 3.948560913057199\n",
      "[EPOCH #2, step #1262] loss: 3.948632766213194\n",
      "[EPOCH #2, step #1264] loss: 3.948439807854151\n",
      "[EPOCH #2, step #1266] loss: 3.9482975241323106\n",
      "[EPOCH #2, step #1268] loss: 3.948131252406055\n",
      "[EPOCH #2, step #1270] loss: 3.948105208054009\n",
      "[EPOCH #2, step #1272] loss: 3.9480129569324096\n",
      "[EPOCH #2, step #1274] loss: 3.9476797988368015\n",
      "[EPOCH #2, step #1276] loss: 3.947463281283457\n",
      "[EPOCH #2, step #1278] loss: 3.947457263579678\n",
      "[EPOCH #2, step #1280] loss: 3.9470763934207653\n",
      "[EPOCH #2, step #1282] loss: 3.9467275025597424\n",
      "[EPOCH #2, step #1284] loss: 3.9466731973195355\n",
      "[EPOCH #2, step #1286] loss: 3.946348603603538\n",
      "[EPOCH #2, step #1288] loss: 3.9460035076984794\n",
      "[EPOCH #2, step #1290] loss: 3.9459009120669317\n",
      "[EPOCH #2, step #1292] loss: 3.945615185570182\n",
      "[EPOCH #2, step #1294] loss: 3.945462653259513\n",
      "[EPOCH #2, step #1296] loss: 3.9453973987052877\n",
      "[EPOCH #2, step #1298] loss: 3.9451489967965823\n",
      "[EPOCH #2, step #1300] loss: 3.944911861859497\n",
      "[EPOCH #2, step #1302] loss: 3.9447122416126663\n",
      "[EPOCH #2, step #1304] loss: 3.9447902379821542\n",
      "[EPOCH #2, step #1306] loss: 3.9446009994921285\n",
      "[EPOCH #2, step #1308] loss: 3.94445854493732\n",
      "[EPOCH #2, step #1310] loss: 3.944389978680876\n",
      "[EPOCH #2, step #1312] loss: 3.944325366459634\n",
      "[EPOCH #2, step #1314] loss: 3.9443283675741334\n",
      "[EPOCH #2, step #1316] loss: 3.944260491325535\n",
      "[EPOCH #2, step #1318] loss: 3.9440731411182672\n",
      "[EPOCH #2, step #1320] loss: 3.9436978813737382\n",
      "[EPOCH #2, step #1322] loss: 3.9437795447654467\n",
      "[EPOCH #2, step #1324] loss: 3.943360063085016\n",
      "[EPOCH #2, step #1326] loss: 3.9431602187684898\n",
      "[EPOCH #2, step #1328] loss: 3.94321233801056\n",
      "[EPOCH #2, step #1330] loss: 3.943257480165638\n",
      "[EPOCH #2, step #1332] loss: 3.9431743192565416\n",
      "[EPOCH #2, step #1334] loss: 3.9432201433717533\n",
      "[EPOCH #2, step #1336] loss: 3.9432304996827154\n",
      "[EPOCH #2, step #1338] loss: 3.9431719849410567\n",
      "[EPOCH #2, step #1340] loss: 3.9430275621207946\n",
      "[EPOCH #2, step #1342] loss: 3.9432348881918196\n",
      "[EPOCH #2, step #1344] loss: 3.94317947479872\n",
      "[EPOCH #2, step #1346] loss: 3.9432409153041257\n",
      "[EPOCH #2, step #1348] loss: 3.9430245149568597\n",
      "[EPOCH #2, step #1350] loss: 3.9429082000458533\n",
      "[EPOCH #2, step #1352] loss: 3.9426272826466136\n",
      "[EPOCH #2, step #1354] loss: 3.9426713661953974\n",
      "[EPOCH #2, step #1356] loss: 3.942517997415609\n",
      "[EPOCH #2, step #1358] loss: 3.942690366853064\n",
      "[EPOCH #2, step #1360] loss: 3.9424287819144133\n",
      "[EPOCH #2, step #1362] loss: 3.942291962426984\n",
      "[EPOCH #2, step #1364] loss: 3.9420294345953524\n",
      "[EPOCH #2, step #1366] loss: 3.9417053468923284\n",
      "[EPOCH #2, step #1368] loss: 3.9417115893130585\n",
      "[EPOCH #2, step #1370] loss: 3.9416426261092172\n",
      "[EPOCH #2, step #1372] loss: 3.9414423159761145\n",
      "[EPOCH #2, step #1374] loss: 3.9411784947135233\n",
      "[EPOCH #2, step #1376] loss: 3.940871267796602\n",
      "[EPOCH #2, step #1378] loss: 3.9410418067140975\n",
      "[EPOCH #2, step #1380] loss: 3.9407787751150165\n",
      "[EPOCH #2, step #1382] loss: 3.9406625129826587\n",
      "[EPOCH #2, step #1384] loss: 3.9404089270085634\n",
      "[EPOCH #2, step #1386] loss: 3.9406333856644524\n",
      "[EPOCH #2, step #1388] loss: 3.9403682161870837\n",
      "[EPOCH #2, step #1390] loss: 3.9400072003507853\n",
      "[EPOCH #2, step #1392] loss: 3.939996123741791\n",
      "[EPOCH #2, step #1394] loss: 3.9396171298078313\n",
      "[EPOCH #2, step #1396] loss: 3.939451751149204\n",
      "[EPOCH #2, step #1398] loss: 3.9395794428783795\n",
      "[EPOCH #2, step #1400] loss: 3.9394458485534583\n",
      "[EPOCH #2, step #1402] loss: 3.939169446485687\n",
      "[EPOCH #2, step #1404] loss: 3.9390213034755392\n",
      "[EPOCH #2, step #1406] loss: 3.9388786095969626\n",
      "[EPOCH #2, step #1408] loss: 3.9387745919846915\n",
      "[EPOCH #2, step #1410] loss: 3.9383726833054227\n",
      "[EPOCH #2, step #1412] loss: 3.9381898635680677\n",
      "[EPOCH #2, step #1414] loss: 3.937788970057619\n",
      "[EPOCH #2, step #1416] loss: 3.9374204307857665\n",
      "[EPOCH #2, step #1418] loss: 3.937300203550526\n",
      "[EPOCH #2, step #1420] loss: 3.9374763368301875\n",
      "[EPOCH #2, step #1422] loss: 3.9373360531311676\n",
      "[EPOCH #2, step #1424] loss: 3.9367847432588277\n",
      "[EPOCH #2, step #1426] loss: 3.9369841223424684\n",
      "[EPOCH #2, step #1428] loss: 3.936592369666877\n",
      "[EPOCH #2, step #1430] loss: 3.936493023719761\n",
      "[EPOCH #2, step #1432] loss: 3.9360894085390954\n",
      "[EPOCH #2, step #1434] loss: 3.9360092010232215\n",
      "[EPOCH #2, step #1436] loss: 3.9359985542695557\n",
      "[EPOCH #2, step #1438] loss: 3.935707305188474\n",
      "[EPOCH #2, step #1440] loss: 3.9355537952605757\n",
      "[EPOCH #2, step #1442] loss: 3.9355897581255115\n",
      "[EPOCH #2, step #1444] loss: 3.9358179379499494\n",
      "[EPOCH #2, step #1446] loss: 3.9358780512582374\n",
      "[EPOCH #2, step #1448] loss: 3.9356842180874696\n",
      "[EPOCH #2, step #1450] loss: 3.935432341080711\n",
      "[EPOCH #2, step #1452] loss: 3.9353371677280538\n",
      "[EPOCH #2, step #1454] loss: 3.9351864665644274\n",
      "[EPOCH #2, step #1456] loss: 3.934976169158108\n",
      "[EPOCH #2, step #1458] loss: 3.9348478095019983\n",
      "[EPOCH #2, step #1460] loss: 3.935104144427321\n",
      "[EPOCH #2, step #1462] loss: 3.934848562300572\n",
      "[EPOCH #2, step #1464] loss: 3.9345552045737517\n",
      "[EPOCH #2, step #1466] loss: 3.934289004905092\n",
      "[EPOCH #2, step #1468] loss: 3.9343282890774263\n",
      "[EPOCH #2, step #1470] loss: 3.9340547447217555\n",
      "[EPOCH #2, step #1472] loss: 3.933867937678475\n",
      "[EPOCH #2, step #1474] loss: 3.9339973606497556\n",
      "[EPOCH #2, step #1476] loss: 3.9337638497917573\n",
      "[EPOCH #2, step #1478] loss: 3.9339133988690587\n",
      "[EPOCH #2, step #1480] loss: 3.933608300616659\n",
      "[EPOCH #2, step #1482] loss: 3.933175439538782\n",
      "[EPOCH #2, step #1484] loss: 3.932661770810985\n",
      "[EPOCH #2, step #1486] loss: 3.932413935260478\n",
      "[EPOCH #2, step #1488] loss: 3.9324633572388206\n",
      "[EPOCH #2, step #1490] loss: 3.9326510267878123\n",
      "[EPOCH #2, step #1492] loss: 3.9327184856936026\n",
      "[EPOCH #2, step #1494] loss: 3.9325200375904608\n",
      "[EPOCH #2, step #1496] loss: 3.932354117841345\n",
      "[EPOCH #2, step #1498] loss: 3.9318390466754956\n",
      "[EPOCH #2, step #1500] loss: 3.9314325229078033\n",
      "[EPOCH #2, step #1502] loss: 3.9313404550571405\n",
      "[EPOCH #2, step #1504] loss: 3.931577207083718\n",
      "[EPOCH #2, step #1506] loss: 3.931307323420372\n",
      "[EPOCH #2, step #1508] loss: 3.93129679444138\n",
      "[EPOCH #2, step #1510] loss: 3.9311818628418456\n",
      "[EPOCH #2, step #1512] loss: 3.93105874799059\n",
      "[EPOCH #2, step #1514] loss: 3.930794542300032\n",
      "[EPOCH #2, step #1516] loss: 3.9305177556894764\n",
      "[EPOCH #2, step #1518] loss: 3.9304968034695293\n",
      "[EPOCH #2, step #1520] loss: 3.930192225078154\n",
      "[EPOCH #2, step #1522] loss: 3.9301409035705848\n",
      "[EPOCH #2, step #1524] loss: 3.930057319109557\n",
      "[EPOCH #2, step #1526] loss: 3.930107785270506\n",
      "[EPOCH #2, step #1528] loss: 3.9298806385404537\n",
      "[EPOCH #2, step #1530] loss: 3.9298526986917586\n",
      "[EPOCH #2, step #1532] loss: 3.9296466761450324\n",
      "[EPOCH #2, step #1534] loss: 3.929560136018436\n",
      "[EPOCH #2, step #1536] loss: 3.92935680133147\n",
      "[EPOCH #2, step #1538] loss: 3.929206680368494\n",
      "[EPOCH #2, step #1540] loss: 3.929188644630734\n",
      "[EPOCH #2, step #1542] loss: 3.929125222615893\n",
      "[EPOCH #2, step #1544] loss: 3.928823631249585\n",
      "[EPOCH #2, step #1546] loss: 3.9287393751187563\n",
      "[EPOCH #2, step #1548] loss: 3.928682384681825\n",
      "[EPOCH #2, step #1550] loss: 3.9287734263793337\n",
      "[EPOCH #2, step #1552] loss: 3.928578270072716\n",
      "[EPOCH #2, step #1554] loss: 3.9284540012335087\n",
      "[EPOCH #2, step #1556] loss: 3.9286225258576692\n",
      "[EPOCH #2, step #1558] loss: 3.928458792036202\n",
      "[EPOCH #2, step #1560] loss: 3.928396738469028\n",
      "[EPOCH #2, step #1562] loss: 3.928722890157083\n",
      "[EPOCH #2, step #1564] loss: 3.9288037616985676\n",
      "[EPOCH #2, step #1566] loss: 3.9286562138175842\n",
      "[EPOCH #2, step #1568] loss: 3.9286179349557697\n",
      "[EPOCH #2, step #1570] loss: 3.928347535530979\n",
      "[EPOCH #2, step #1572] loss: 3.928214844517547\n",
      "[EPOCH #2, step #1574] loss: 3.928099460147676\n",
      "[EPOCH #2, step #1576] loss: 3.927962106470073\n",
      "[EPOCH #2, step #1578] loss: 3.927705492831394\n",
      "[EPOCH #2, step #1580] loss: 3.9273599551343827\n",
      "[EPOCH #2, step #1582] loss: 3.9272942059565703\n",
      "[EPOCH #2, step #1584] loss: 3.9270235539986884\n",
      "[EPOCH #2, step #1586] loss: 3.9269162238432913\n",
      "[EPOCH #2, step #1588] loss: 3.9269210423516956\n",
      "[EPOCH #2, step #1590] loss: 3.9269090509504587\n",
      "[EPOCH #2, step #1592] loss: 3.926726108965302\n",
      "[EPOCH #2, step #1594] loss: 3.926461988257764\n",
      "[EPOCH #2, step #1596] loss: 3.926232445292273\n",
      "[EPOCH #2, step #1598] loss: 3.9259360079619197\n",
      "[EPOCH #2, step #1600] loss: 3.9260419916168443\n",
      "[EPOCH #2, step #1602] loss: 3.9258625849440034\n",
      "[EPOCH #2, step #1604] loss: 3.9255186245820233\n",
      "[EPOCH #2, step #1606] loss: 3.9256282898677974\n",
      "[EPOCH #2, step #1608] loss: 3.9253409864592803\n",
      "[EPOCH #2, step #1610] loss: 3.9251825744361333\n",
      "[EPOCH #2, step #1612] loss: 3.9251493439494047\n",
      "[EPOCH #2, step #1614] loss: 3.925022598242981\n",
      "[EPOCH #2, step #1616] loss: 3.925333509934708\n",
      "[EPOCH #2, step #1618] loss: 3.9251246705623672\n",
      "[EPOCH #2, step #1620] loss: 3.9252092180834515\n",
      "[EPOCH #2, step #1622] loss: 3.92508203764426\n",
      "[EPOCH #2, step #1624] loss: 3.9249768936450664\n",
      "[EPOCH #2, step #1626] loss: 3.9248107250438706\n",
      "[EPOCH #2, step #1628] loss: 3.9247965351652705\n",
      "[EPOCH #2, step #1630] loss: 3.9248613131550614\n",
      "[EPOCH #2, step #1632] loss: 3.9245754796452705\n",
      "[EPOCH #2, step #1634] loss: 3.9243582579703142\n",
      "[EPOCH #2, step #1636] loss: 3.924211264093547\n",
      "[EPOCH #2, step #1638] loss: 3.9239741691079644\n",
      "[EPOCH #2, step #1640] loss: 3.9237282457764304\n",
      "[EPOCH #2, step #1642] loss: 3.9235222071173417\n",
      "[EPOCH #2, step #1644] loss: 3.923288897685367\n",
      "[EPOCH #2, step #1646] loss: 3.9233866804791133\n",
      "[EPOCH #2, step #1648] loss: 3.9232136655244196\n",
      "[EPOCH #2, step #1650] loss: 3.92326209705429\n",
      "[EPOCH #2, step #1652] loss: 3.9230850524636955\n",
      "[EPOCH #2, step #1654] loss: 3.9228629868556366\n",
      "[EPOCH #2, step #1656] loss: 3.922525879555462\n",
      "[EPOCH #2, step #1658] loss: 3.92247548614948\n",
      "[EPOCH #2, step #1660] loss: 3.9225580100909836\n",
      "[EPOCH #2, step #1662] loss: 3.922413525635839\n",
      "[EPOCH #2, step #1664] loss: 3.922359256629829\n",
      "[EPOCH #2, step #1666] loss: 3.922291317741243\n",
      "[EPOCH #2, step #1668] loss: 3.9221468254647047\n",
      "[EPOCH #2, step #1670] loss: 3.9219635854146926\n",
      "[EPOCH #2, step #1672] loss: 3.9216153603147337\n",
      "[EPOCH #2, step #1674] loss: 3.92153969878581\n",
      "[EPOCH #2, step #1676] loss: 3.921455134077305\n",
      "[EPOCH #2, step #1678] loss: 3.921452148390924\n",
      "[EPOCH #2, step #1680] loss: 3.9212726958091597\n",
      "[EPOCH #2, step #1682] loss: 3.921459464182545\n",
      "[EPOCH #2, step #1684] loss: 3.9214663915888845\n",
      "[EPOCH #2, step #1686] loss: 3.9213780862167167\n",
      "[EPOCH #2, step #1688] loss: 3.921041179790237\n",
      "[EPOCH #2, step #1690] loss: 3.921093763225111\n",
      "[EPOCH #2, step #1692] loss: 3.920623782395049\n",
      "[EPOCH #2, step #1694] loss: 3.920294032054665\n",
      "[EPOCH #2, step #1696] loss: 3.92010807794336\n",
      "[EPOCH #2, step #1698] loss: 3.919915051092605\n",
      "[EPOCH #2, step #1700] loss: 3.919689843824231\n",
      "[EPOCH #2, step #1702] loss: 3.919502420279816\n",
      "[EPOCH #2, step #1704] loss: 3.9195157357324955\n",
      "[EPOCH #2, step #1706] loss: 3.9193277522423986\n",
      "[EPOCH #2, step #1708] loss: 3.919353886889463\n",
      "[EPOCH #2, step #1710] loss: 3.919115799898853\n",
      "[EPOCH #2, step #1712] loss: 3.9188855354088616\n",
      "[EPOCH #2, step #1714] loss: 3.918642770583706\n",
      "[EPOCH #2, step #1716] loss: 3.918652370771698\n",
      "[EPOCH #2, step #1718] loss: 3.9184768567465293\n",
      "[EPOCH #2, step #1720] loss: 3.9182710517360193\n",
      "[EPOCH #2, step #1722] loss: 3.918221153772922\n",
      "[EPOCH #2, step #1724] loss: 3.9181440123958864\n",
      "[EPOCH #2, step #1726] loss: 3.918260702316514\n",
      "[EPOCH #2, step #1728] loss: 3.918179060697142\n",
      "[EPOCH #2, step #1730] loss: 3.918038382274026\n",
      "[EPOCH #2, step #1732] loss: 3.9178578267534965\n",
      "[EPOCH #2, step #1734] loss: 3.9177004283718144\n",
      "[EPOCH #2, step #1736] loss: 3.9177848872743124\n",
      "[EPOCH #2, step #1738] loss: 3.9175391681171\n",
      "[EPOCH #2, step #1740] loss: 3.9173672189663225\n",
      "[EPOCH #2, step #1742] loss: 3.9170600659397232\n",
      "[EPOCH #2, step #1744] loss: 3.917090973539817\n",
      "[EPOCH #2, step #1746] loss: 3.9171380861595693\n",
      "[EPOCH #2, step #1748] loss: 3.91672130337165\n",
      "[EPOCH #2, step #1750] loss: 3.916778573712099\n",
      "[EPOCH #2, step #1752] loss: 3.9163862515094277\n",
      "[EPOCH #2, step #1754] loss: 3.916552856097534\n",
      "[EPOCH #2, step #1756] loss: 3.9162043818168226\n",
      "[EPOCH #2, step #1758] loss: 3.916140703940812\n",
      "[EPOCH #2, step #1760] loss: 3.915835389625207\n",
      "[EPOCH #2, step #1762] loss: 3.9156910168198245\n",
      "[EPOCH #2, step #1764] loss: 3.91556707347081\n",
      "[EPOCH #2, step #1766] loss: 3.915462726243283\n",
      "[EPOCH #2, step #1768] loss: 3.9155085310550515\n",
      "[EPOCH #2, step #1770] loss: 3.915103553446722\n",
      "[EPOCH #2, step #1772] loss: 3.914951714162294\n",
      "[EPOCH #2, step #1774] loss: 3.9151593914837903\n",
      "[EPOCH #2, step #1776] loss: 3.9149833462113532\n",
      "[EPOCH #2, step #1778] loss: 3.9151155798538406\n",
      "[EPOCH #2, step #1780] loss: 3.9151586865120427\n",
      "[EPOCH #2, step #1782] loss: 3.9149363816486473\n",
      "[EPOCH #2, step #1784] loss: 3.914891568886466\n",
      "[EPOCH #2, step #1786] loss: 3.915075492912254\n",
      "[EPOCH #2, step #1788] loss: 3.9149762972431383\n",
      "[EPOCH #2, step #1790] loss: 3.914722435039092\n",
      "[EPOCH #2, step #1792] loss: 3.914883297645241\n",
      "[EPOCH #2, step #1794] loss: 3.9147630165546383\n",
      "[EPOCH #2, step #1796] loss: 3.914699543696612\n",
      "[EPOCH #2, step #1798] loss: 3.9146084866303745\n",
      "[EPOCH #2, step #1800] loss: 3.9145048905054374\n",
      "[EPOCH #2, step #1802] loss: 3.9144089264269346\n",
      "[EPOCH #2, step #1804] loss: 3.9144543802308904\n",
      "[EPOCH #2, step #1806] loss: 3.914219407264739\n",
      "[EPOCH #2, step #1808] loss: 3.914053095316215\n",
      "[EPOCH #2, step #1810] loss: 3.913728812595285\n",
      "[EPOCH #2, step #1812] loss: 3.913621844603617\n",
      "[EPOCH #2, step #1814] loss: 3.9135607488227615\n",
      "[EPOCH #2, step #1816] loss: 3.9132232790670356\n",
      "[EPOCH #2, step #1818] loss: 3.9130145920181483\n",
      "[EPOCH #2, step #1820] loss: 3.912783462093925\n",
      "[EPOCH #2, step #1822] loss: 3.9129164122122693\n",
      "[EPOCH #2, step #1824] loss: 3.9127758211632298\n",
      "[EPOCH #2, step #1826] loss: 3.9127178916398724\n",
      "[EPOCH #2, step #1828] loss: 3.912671706401435\n",
      "[EPOCH #2, step #1830] loss: 3.9125619230213093\n",
      "[EPOCH #2, step #1832] loss: 3.9124303454593172\n",
      "[EPOCH #2, step #1834] loss: 3.9123157798756694\n",
      "[EPOCH #2, step #1836] loss: 3.912325903846313\n",
      "[EPOCH #2, step #1838] loss: 3.91226932002903\n",
      "[EPOCH #2, step #1840] loss: 3.9121926231011304\n",
      "[EPOCH #2, step #1842] loss: 3.912018758217019\n",
      "[EPOCH #2, step #1844] loss: 3.9116350635280455\n",
      "[EPOCH #2, step #1846] loss: 3.911635493483489\n",
      "[EPOCH #2, step #1848] loss: 3.91131501793539\n",
      "[EPOCH #2, step #1850] loss: 3.9110464641430904\n",
      "[EPOCH #2, step #1852] loss: 3.9110351416849793\n",
      "[EPOCH #2, step #1854] loss: 3.9109336994407635\n",
      "[EPOCH #2, step #1856] loss: 3.910634246126708\n",
      "[EPOCH #2, step #1858] loss: 3.9102961157777734\n",
      "[EPOCH #2, step #1860] loss: 3.9103076241466064\n",
      "[EPOCH #2, step #1862] loss: 3.9101351913558626\n",
      "[EPOCH #2, step #1864] loss: 3.9098908021686545\n",
      "[EPOCH #2, step #1866] loss: 3.9095940022910414\n",
      "[EPOCH #2, step #1868] loss: 3.909411658699848\n",
      "[EPOCH #2, step #1870] loss: 3.9094160235163873\n",
      "[EPOCH #2, step #1872] loss: 3.9092572089254825\n",
      "[EPOCH #2, step #1874] loss: 3.909077139409383\n",
      "[EPOCH #2, step #1876] loss: 3.908889621131015\n",
      "[EPOCH #2, step #1878] loss: 3.9085738231299594\n",
      "[EPOCH #2, step #1880] loss: 3.9081741844574736\n",
      "[EPOCH #2, step #1882] loss: 3.908088882869694\n",
      "[EPOCH #2, step #1884] loss: 3.9081665920642075\n",
      "[EPOCH #2, step #1886] loss: 3.9079400594738596\n",
      "[EPOCH #2, step #1888] loss: 3.907769299613666\n",
      "[EPOCH #2, step #1890] loss: 3.9075245081842547\n",
      "[EPOCH #2, step #1892] loss: 3.9073227852409755\n",
      "[EPOCH #2, step #1894] loss: 3.9073231865674023\n",
      "[EPOCH #2, step #1896] loss: 3.9072071540713877\n",
      "[EPOCH #2, step #1898] loss: 3.906875375322821\n",
      "[EPOCH #2, step #1900] loss: 3.90669514880815\n",
      "[EPOCH #2, step #1902] loss: 3.9064522444794694\n",
      "[EPOCH #2, step #1904] loss: 3.9064361514694736\n",
      "[EPOCH #2, step #1906] loss: 3.906415635275478\n",
      "[EPOCH #2, step #1908] loss: 3.9063757445064122\n",
      "[EPOCH #2, step #1910] loss: 3.906117653235411\n",
      "[EPOCH #2, step #1912] loss: 3.9060714288463285\n",
      "[EPOCH #2, step #1914] loss: 3.905800393107043\n",
      "[EPOCH #2, step #1916] loss: 3.905697665615012\n",
      "[EPOCH #2, step #1918] loss: 3.905581318133197\n",
      "[EPOCH #2, step #1920] loss: 3.905318896141231\n",
      "[EPOCH #2, step #1922] loss: 3.9053144033415146\n",
      "[EPOCH #2, step #1924] loss: 3.905217561597948\n",
      "[EPOCH #2, step #1926] loss: 3.9049322725146562\n",
      "[EPOCH #2, step #1928] loss: 3.9048180056087953\n",
      "[EPOCH #2, step #1930] loss: 3.9046234190618354\n",
      "[EPOCH #2, step #1932] loss: 3.9044956746523205\n",
      "[EPOCH #2, step #1934] loss: 3.9042258927988454\n",
      "[EPOCH #2, step #1936] loss: 3.904147075634367\n",
      "[EPOCH #2, step #1938] loss: 3.903927988462561\n",
      "[EPOCH #2, step #1940] loss: 3.9035853037571306\n",
      "[EPOCH #2, step #1942] loss: 3.9033645241148864\n",
      "[EPOCH #2, step #1944] loss: 3.9032375920401132\n",
      "[EPOCH #2, step #1946] loss: 3.9030177168314677\n",
      "[EPOCH #2, step #1948] loss: 3.9029544449390787\n",
      "[EPOCH #2, step #1950] loss: 3.9027982975262243\n",
      "[EPOCH #2, step #1952] loss: 3.9025945938127933\n",
      "[EPOCH #2, step #1954] loss: 3.902729784558191\n",
      "[EPOCH #2, step #1956] loss: 3.9025108961652113\n",
      "[EPOCH #2, step #1958] loss: 3.902403696146834\n",
      "[EPOCH #2, step #1960] loss: 3.902187178172608\n",
      "[EPOCH #2, step #1962] loss: 3.9022364660118285\n",
      "[EPOCH #2, step #1964] loss: 3.9022545395916657\n",
      "[EPOCH #2, step #1966] loss: 3.902266477290058\n",
      "[EPOCH #2, step #1968] loss: 3.902116934740949\n",
      "[EPOCH #2, step #1970] loss: 3.901905960990716\n",
      "[EPOCH #2, step #1972] loss: 3.901558789999063\n",
      "[EPOCH #2, step #1974] loss: 3.9015324719344515\n",
      "[EPOCH #2, step #1976] loss: 3.9014754985159072\n",
      "[EPOCH #2, step #1978] loss: 3.9014447331729714\n",
      "[EPOCH #2, step #1980] loss: 3.9011949616691672\n",
      "[EPOCH #2, step #1982] loss: 3.901206412942976\n",
      "[EPOCH #2, step #1984] loss: 3.9010060751167894\n",
      "[EPOCH #2, step #1986] loss: 3.900809700547839\n",
      "[EPOCH #2, step #1988] loss: 3.900631378139306\n",
      "[EPOCH #2, step #1990] loss: 3.9004365996701345\n",
      "[EPOCH #2, step #1992] loss: 3.900431312153343\n",
      "[EPOCH #2, step #1994] loss: 3.900182702846097\n",
      "[EPOCH #2, step #1996] loss: 3.9001469904623094\n",
      "[EPOCH #2, step #1998] loss: 3.8997177350157317\n",
      "[EPOCH #2, step #2000] loss: 3.899703509565713\n",
      "[EPOCH #2, step #2002] loss: 3.89948413744606\n",
      "[EPOCH #2, step #2004] loss: 3.899392323838802\n",
      "[EPOCH #2, step #2006] loss: 3.8992415986728717\n",
      "[EPOCH #2, step #2008] loss: 3.899025865666839\n",
      "[EPOCH #2, step #2010] loss: 3.899012985779598\n",
      "[EPOCH #2, step #2012] loss: 3.898674684084889\n",
      "[EPOCH #2, step #2014] loss: 3.898601332373418\n",
      "[EPOCH #2, step #2016] loss: 3.8986101843191365\n",
      "[EPOCH #2, step #2018] loss: 3.898425250079385\n",
      "[EPOCH #2, step #2020] loss: 3.8982966284773126\n",
      "[EPOCH #2, step #2022] loss: 3.898117154762996\n",
      "[EPOCH #2, step #2024] loss: 3.897954926902865\n",
      "[EPOCH #2, step #2026] loss: 3.8976882236840162\n",
      "[EPOCH #2, step #2028] loss: 3.8973234632791938\n",
      "[EPOCH #2, step #2030] loss: 3.897144125107766\n",
      "[EPOCH #2, step #2032] loss: 3.896981191588222\n",
      "[EPOCH #2, step #2034] loss: 3.8969925294637093\n",
      "[EPOCH #2, step #2036] loss: 3.896860470418317\n",
      "[EPOCH #2, step #2038] loss: 3.8964937694403634\n",
      "[EPOCH #2, step #2040] loss: 3.896428231221096\n",
      "[EPOCH #2, step #2042] loss: 3.8963066393758408\n",
      "[EPOCH #2, step #2044] loss: 3.8962971367870973\n",
      "[EPOCH #2, step #2046] loss: 3.8960082827979434\n",
      "[EPOCH #2, step #2048] loss: 3.895811827023359\n",
      "[EPOCH #2, step #2050] loss: 3.895557824836482\n",
      "[EPOCH #2, step #2052] loss: 3.8953145312148076\n",
      "[EPOCH #2, step #2054] loss: 3.8954971711420954\n",
      "[EPOCH #2, step #2056] loss: 3.8953530456930556\n",
      "[EPOCH #2, step #2058] loss: 3.8951044053693256\n",
      "[EPOCH #2, step #2060] loss: 3.8951291453774726\n",
      "[EPOCH #2, step #2062] loss: 3.8951627109100446\n",
      "[EPOCH #2, step #2064] loss: 3.8949832842367327\n",
      "[EPOCH #2, step #2066] loss: 3.89461166511484\n",
      "[EPOCH #2, step #2068] loss: 3.8946330737468413\n",
      "[EPOCH #2, step #2070] loss: 3.8946867868671204\n",
      "[EPOCH #2, step #2072] loss: 3.894485049815898\n",
      "[EPOCH #2, step #2074] loss: 3.894345787461982\n",
      "[EPOCH #2, step #2076] loss: 3.8941770680087315\n",
      "[EPOCH #2, step #2078] loss: 3.8940239007682855\n",
      "[EPOCH #2, step #2080] loss: 3.893669901416601\n",
      "[EPOCH #2, step #2082] loss: 3.893397549740466\n",
      "[EPOCH #2, step #2084] loss: 3.893196078970564\n",
      "[EPOCH #2, step #2086] loss: 3.8929547971095775\n",
      "[EPOCH #2, step #2088] loss: 3.8928181361558623\n",
      "[EPOCH #2, step #2090] loss: 3.8927427171691646\n",
      "[EPOCH #2, step #2092] loss: 3.892651203882734\n",
      "[EPOCH #2, step #2094] loss: 3.8925790825436395\n",
      "[EPOCH #2, step #2096] loss: 3.8923696034512862\n",
      "[EPOCH #2, step #2098] loss: 3.892414051104069\n",
      "[EPOCH #2, step #2100] loss: 3.8923560226037353\n",
      "[EPOCH #2, step #2102] loss: 3.892206096785215\n",
      "[EPOCH #2, step #2104] loss: 3.8919497517112314\n",
      "[EPOCH #2, step #2106] loss: 3.892024652619581\n",
      "[EPOCH #2, step #2108] loss: 3.8920246784921053\n",
      "[EPOCH #2, step #2110] loss: 3.891827919312644\n",
      "[EPOCH #2, step #2112] loss: 3.891742851967728\n",
      "[EPOCH #2, step #2114] loss: 3.891581586855805\n",
      "[EPOCH #2, step #2116] loss: 3.891264739664985\n",
      "[EPOCH #2, step #2118] loss: 3.891036367798932\n",
      "[EPOCH #2, step #2120] loss: 3.8906460746961176\n",
      "[EPOCH #2, step #2122] loss: 3.890591872283102\n",
      "[EPOCH #2, step #2124] loss: 3.8907963223176845\n",
      "[EPOCH #2, step #2126] loss: 3.8905267088862727\n",
      "[EPOCH #2, step #2128] loss: 3.8902267634784633\n",
      "[EPOCH #2, step #2130] loss: 3.890170793363266\n",
      "[EPOCH #2, step #2132] loss: 3.890131433860718\n",
      "[EPOCH #2, step #2134] loss: 3.889823011715462\n",
      "[EPOCH #2, step #2136] loss: 3.8898567411461107\n",
      "[EPOCH #2, step #2138] loss: 3.889575631777891\n",
      "[EPOCH #2, step #2140] loss: 3.889580365153798\n",
      "[EPOCH #2, step #2142] loss: 3.8894920438124765\n",
      "[EPOCH #2, step #2144] loss: 3.8894258257948158\n",
      "[EPOCH #2, step #2146] loss: 3.889459864616838\n",
      "[EPOCH #2, step #2148] loss: 3.889432060380157\n",
      "[EPOCH #2, step #2150] loss: 3.88909503572323\n",
      "[EPOCH #2, step #2152] loss: 3.8889017556912946\n",
      "[EPOCH #2, step #2154] loss: 3.8885389018224727\n",
      "[EPOCH #2, step #2156] loss: 3.888430460658845\n",
      "[EPOCH #2, step #2158] loss: 3.8881933714516355\n",
      "[EPOCH #2, step #2160] loss: 3.8880027623598026\n",
      "[EPOCH #2, step #2162] loss: 3.8876519813837414\n",
      "[EPOCH #2, step #2164] loss: 3.8875800634917157\n",
      "[EPOCH #2, step #2166] loss: 3.887273378728665\n",
      "[EPOCH #2, step #2168] loss: 3.887066210069212\n",
      "[EPOCH #2, step #2170] loss: 3.8870117574285\n",
      "[EPOCH #2, step #2172] loss: 3.8870966669276625\n",
      "[EPOCH #2, step #2174] loss: 3.887077978397238\n",
      "[EPOCH #2, step #2176] loss: 3.886784653078814\n",
      "[EPOCH #2, step #2178] loss: 3.8867506856161174\n",
      "[EPOCH #2, step #2180] loss: 3.8866265970105043\n",
      "[EPOCH #2, step #2182] loss: 3.8863496158956337\n",
      "[EPOCH #2, step #2184] loss: 3.886227031812515\n",
      "[EPOCH #2, step #2186] loss: 3.8863110388584423\n",
      "[EPOCH #2, step #2188] loss: 3.885963945205814\n",
      "[EPOCH #2, step #2190] loss: 3.8857747152590525\n",
      "[EPOCH #2, step #2192] loss: 3.885552014382637\n",
      "[EPOCH #2, step #2194] loss: 3.8852400075873375\n",
      "[EPOCH #2, step #2196] loss: 3.88514176009729\n",
      "[EPOCH #2, step #2198] loss: 3.8848223568038973\n",
      "[EPOCH #2, step #2200] loss: 3.8846852450086984\n",
      "[EPOCH #2, step #2202] loss: 3.8844489610795807\n",
      "[EPOCH #2, step #2204] loss: 3.8843073535668338\n",
      "[EPOCH #2, step #2206] loss: 3.8843251653100013\n",
      "[EPOCH #2, step #2208] loss: 3.8842574377953603\n",
      "[EPOCH #2, step #2210] loss: 3.8839702378673717\n",
      "[EPOCH #2, step #2212] loss: 3.8837566046061904\n",
      "[EPOCH #2, step #2214] loss: 3.883448200247358\n",
      "[EPOCH #2, step #2216] loss: 3.883390264248708\n",
      "[EPOCH #2, step #2218] loss: 3.883059842675696\n",
      "[EPOCH #2, step #2220] loss: 3.883083365834119\n",
      "[EPOCH #2, step #2222] loss: 3.8827677237467353\n",
      "[EPOCH #2, step #2224] loss: 3.8828895622424864\n",
      "[EPOCH #2, step #2226] loss: 3.8826911029764286\n",
      "[EPOCH #2, step #2228] loss: 3.8824721973217247\n",
      "[EPOCH #2, step #2230] loss: 3.882479787140029\n",
      "[EPOCH #2, step #2232] loss: 3.882473209221375\n",
      "[EPOCH #2, step #2234] loss: 3.8821542334503243\n",
      "[EPOCH #2, step #2236] loss: 3.8818654968208857\n",
      "[EPOCH #2, step #2238] loss: 3.881745637980568\n",
      "[EPOCH #2, step #2240] loss: 3.8815221529036745\n",
      "[EPOCH #2, step #2242] loss: 3.8811509914287647\n",
      "[EPOCH #2, step #2244] loss: 3.880818424989492\n",
      "[EPOCH #2, step #2246] loss: 3.880834971951229\n",
      "[EPOCH #2, step #2248] loss: 3.8807910599672515\n",
      "[EPOCH #2, step #2250] loss: 3.8806007981353314\n",
      "[EPOCH #2, step #2252] loss: 3.880534324548639\n",
      "[EPOCH #2, step #2254] loss: 3.8803731831637296\n",
      "[EPOCH #2, step #2256] loss: 3.88020143595532\n",
      "[EPOCH #2, step #2258] loss: 3.8801926630373917\n",
      "[EPOCH #2, step #2260] loss: 3.880046074499023\n",
      "[EPOCH #2, step #2262] loss: 3.880040431623168\n",
      "[EPOCH #2, step #2264] loss: 3.879973300508579\n",
      "[EPOCH #2, step #2266] loss: 3.879986325496611\n",
      "[EPOCH #2, step #2268] loss: 3.879718685948728\n",
      "[EPOCH #2, step #2270] loss: 3.8795396442824868\n",
      "[EPOCH #2, step #2272] loss: 3.8794717911419445\n",
      "[EPOCH #2, step #2274] loss: 3.879120526366181\n",
      "[EPOCH #2, step #2276] loss: 3.8789424477410934\n",
      "[EPOCH #2, step #2278] loss: 3.8787031324352284\n",
      "[EPOCH #2, step #2280] loss: 3.8785019168619628\n",
      "[EPOCH #2, step #2282] loss: 3.8782905430528505\n",
      "[EPOCH #2, step #2284] loss: 3.8781580275988423\n",
      "[EPOCH #2, step #2286] loss: 3.8779627392789293\n",
      "[EPOCH #2, step #2288] loss: 3.877697617792052\n",
      "[EPOCH #2, step #2290] loss: 3.8775345066758233\n",
      "[EPOCH #2, step #2292] loss: 3.877199564861825\n",
      "[EPOCH #2, step #2294] loss: 3.8769982494819657\n",
      "[EPOCH #2, step #2296] loss: 3.876856866897995\n",
      "[EPOCH #2, step #2298] loss: 3.8766358375756726\n",
      "[EPOCH #2, step #2300] loss: 3.8765145609141536\n",
      "[EPOCH #2, step #2302] loss: 3.8763874024346867\n",
      "[EPOCH #2, step #2304] loss: 3.8761318287466717\n",
      "[EPOCH #2, step #2306] loss: 3.8759443075769537\n",
      "[EPOCH #2, step #2308] loss: 3.8758015267102426\n",
      "[EPOCH #2, step #2310] loss: 3.8755148377371063\n",
      "[EPOCH #2, step #2312] loss: 3.875359606031623\n",
      "[EPOCH #2, step #2314] loss: 3.8753131493636395\n",
      "[EPOCH #2, step #2316] loss: 3.875352564174963\n",
      "[EPOCH #2, step #2318] loss: 3.8753234576233093\n",
      "[EPOCH #2, step #2320] loss: 3.8752256493689634\n",
      "[EPOCH #2, step #2322] loss: 3.875079890237612\n",
      "[EPOCH #2, step #2324] loss: 3.874964432870188\n",
      "[EPOCH #2, step #2326] loss: 3.8745972081525775\n",
      "[EPOCH #2, step #2328] loss: 3.874504692926075\n",
      "[EPOCH #2, step #2330] loss: 3.8744264256539953\n",
      "[EPOCH #2, step #2332] loss: 3.8743402061674965\n",
      "[EPOCH #2, step #2334] loss: 3.8741761492457583\n",
      "[EPOCH #2, step #2336] loss: 3.873795665019488\n",
      "[EPOCH #2, step #2338] loss: 3.8736813558682055\n",
      "[EPOCH #2, step #2340] loss: 3.873580334992146\n",
      "[EPOCH #2, step #2342] loss: 3.8732830559245754\n",
      "[EPOCH #2, step #2344] loss: 3.8731722648718208\n",
      "[EPOCH #2, step #2346] loss: 3.872994606272434\n",
      "[EPOCH #2, step #2348] loss: 3.872689653325964\n",
      "[EPOCH #2, step #2350] loss: 3.8724794847211754\n",
      "[EPOCH #2, step #2352] loss: 3.8723394680266376\n",
      "[EPOCH #2, step #2354] loss: 3.8720332749077215\n",
      "[EPOCH #2, step #2356] loss: 3.87178615315971\n",
      "[EPOCH #2, step #2358] loss: 3.871740315010003\n",
      "[EPOCH #2, step #2360] loss: 3.8714755359013067\n",
      "[EPOCH #2, step #2362] loss: 3.8713286162129004\n",
      "[EPOCH #2, step #2364] loss: 3.871203800890965\n",
      "[EPOCH #2, step #2366] loss: 3.871169067909811\n",
      "[EPOCH #2, step #2368] loss: 3.8710817113210503\n",
      "[EPOCH #2, step #2370] loss: 3.8709307951748193\n",
      "[EPOCH #2, step #2372] loss: 3.8707758300273265\n",
      "[EPOCH #2, step #2374] loss: 3.870613791014019\n",
      "[EPOCH #2, step #2376] loss: 3.870532340044528\n",
      "[EPOCH #2, step #2378] loss: 3.870381608937357\n",
      "[EPOCH #2, step #2380] loss: 3.8700826432413535\n",
      "[EPOCH #2, step #2382] loss: 3.869836564130059\n",
      "[EPOCH #2, step #2384] loss: 3.869935111779587\n",
      "[EPOCH #2, step #2386] loss: 3.869921342069053\n",
      "[EPOCH #2, step #2388] loss: 3.870143702460313\n",
      "[EPOCH #2, step #2390] loss: 3.8701640966296544\n",
      "[EPOCH #2, step #2392] loss: 3.869981126510295\n",
      "[EPOCH #2, step #2394] loss: 3.869801930644567\n",
      "[EPOCH #2, step #2396] loss: 3.8697330310138804\n",
      "[EPOCH #2, step #2398] loss: 3.8695264310824866\n",
      "[EPOCH #2, step #2400] loss: 3.8693977848086343\n",
      "[EPOCH #2, step #2402] loss: 3.869091852773888\n",
      "[EPOCH #2, step #2404] loss: 3.868995040370124\n",
      "[EPOCH #2, step #2406] loss: 3.86877021890584\n",
      "[EPOCH #2, step #2408] loss: 3.8688374443537175\n",
      "[EPOCH #2, step #2410] loss: 3.8688025734623355\n",
      "[EPOCH #2, step #2412] loss: 3.8687810398857474\n",
      "[EPOCH #2, step #2414] loss: 3.8686750907582033\n",
      "[EPOCH #2, step #2416] loss: 3.8686326912330307\n",
      "[EPOCH #2, step #2418] loss: 3.8686708685483455\n",
      "[EPOCH #2, step #2420] loss: 3.8685122361512088\n",
      "[EPOCH #2, step #2422] loss: 3.868242999418088\n",
      "[EPOCH #2, step #2424] loss: 3.868247268519451\n",
      "[EPOCH #2, step #2426] loss: 3.868099880650744\n",
      "[EPOCH #2, step #2428] loss: 3.8681204480956053\n",
      "[EPOCH #2, step #2430] loss: 3.86805275583993\n",
      "[EPOCH #2, step #2432] loss: 3.8680574094323137\n",
      "[EPOCH #2, step #2434] loss: 3.8678678124837074\n",
      "[EPOCH #2, step #2436] loss: 3.867755743730347\n",
      "[EPOCH #2, step #2438] loss: 3.867622195525754\n",
      "[EPOCH #2, step #2440] loss: 3.867579461316113\n",
      "[EPOCH #2, step #2442] loss: 3.8673878696869495\n",
      "[EPOCH #2, step #2444] loss: 3.867178853937941\n",
      "[EPOCH #2, step #2446] loss: 3.8671409083133725\n",
      "[EPOCH #2, step #2448] loss: 3.8671531759022986\n",
      "[EPOCH #2, step #2450] loss: 3.8671005102917886\n",
      "[EPOCH #2, step #2452] loss: 3.866913463842903\n",
      "[EPOCH #2, step #2454] loss: 3.8668240354891465\n",
      "[EPOCH #2, step #2456] loss: 3.866851047427372\n",
      "[EPOCH #2, step #2458] loss: 3.8666444951414625\n",
      "[EPOCH #2, step #2460] loss: 3.866739364331062\n",
      "[EPOCH #2, step #2462] loss: 3.866789309609677\n",
      "[EPOCH #2, step #2464] loss: 3.8668604669899778\n",
      "[EPOCH #2, step #2466] loss: 3.8666914418780665\n",
      "[EPOCH #2, step #2468] loss: 3.8664930633515566\n",
      "[EPOCH #2, step #2470] loss: 3.8662734675243384\n",
      "[EPOCH #2, step #2472] loss: 3.8660656856323996\n",
      "[EPOCH #2, step #2474] loss: 3.86594561152988\n",
      "[EPOCH #2, step #2476] loss: 3.8658417114385637\n",
      "[EPOCH #2, step #2478] loss: 3.865755599753998\n",
      "[EPOCH #2, step #2480] loss: 3.865695216107013\n",
      "[EPOCH #2, step #2482] loss: 3.865501260930283\n",
      "[EPOCH #2, step #2484] loss: 3.8654373138243523\n",
      "[EPOCH #2, step #2486] loss: 3.8651555592054145\n",
      "[EPOCH #2, step #2488] loss: 3.864880626007178\n",
      "[EPOCH #2, step #2490] loss: 3.8648345355574074\n",
      "[EPOCH #2, step #2492] loss: 3.8647295543098372\n",
      "[EPOCH #2, step #2494] loss: 3.8646033980803405\n",
      "[EPOCH #2, step #2496] loss: 3.864310768445969\n",
      "[EPOCH #2, step #2498] loss: 3.8641706953624957\n",
      "[EPOCH #2, elapsed time: 1026.383[sec]] loss: 3.86411679019928\n",
      "[EPOCH #3, step #0] loss: 3.727590560913086\n",
      "[EPOCH #3, step #2] loss: 3.7602471510569253\n",
      "[EPOCH #3, step #4] loss: 3.6842320442199705\n",
      "[EPOCH #3, step #6] loss: 3.6602546146937778\n",
      "[EPOCH #3, step #8] loss: 3.61452497376336\n",
      "[EPOCH #3, step #10] loss: 3.639052087610418\n",
      "[EPOCH #3, step #12] loss: 3.6706247879908633\n",
      "[EPOCH #3, step #14] loss: 3.6715225060780843\n",
      "[EPOCH #3, step #16] loss: 3.6832180584178253\n",
      "[EPOCH #3, step #18] loss: 3.691108465194702\n",
      "[EPOCH #3, step #20] loss: 3.6932688440595354\n",
      "[EPOCH #3, step #22] loss: 3.680607629858929\n",
      "[EPOCH #3, step #24] loss: 3.6683381462097167\n",
      "[EPOCH #3, step #26] loss: 3.6880605309097856\n",
      "[EPOCH #3, step #28] loss: 3.676871793023471\n",
      "[EPOCH #3, step #30] loss: 3.6736833280132664\n",
      "[EPOCH #3, step #32] loss: 3.677241491548943\n",
      "[EPOCH #3, step #34] loss: 3.6778138773781914\n",
      "[EPOCH #3, step #36] loss: 3.6782691994228878\n",
      "[EPOCH #3, step #38] loss: 3.6769867493556094\n",
      "[EPOCH #3, step #40] loss: 3.6816445327386624\n",
      "[EPOCH #3, step #42] loss: 3.6897940025773157\n",
      "[EPOCH #3, step #44] loss: 3.7020350615183513\n",
      "[EPOCH #3, step #46] loss: 3.69884932294805\n",
      "[EPOCH #3, step #48] loss: 3.6863332865189533\n",
      "[EPOCH #3, step #50] loss: 3.68605497304131\n",
      "[EPOCH #3, step #52] loss: 3.690355606798856\n",
      "[EPOCH #3, step #54] loss: 3.6863870837471704\n",
      "[EPOCH #3, step #56] loss: 3.6860503313834205\n",
      "[EPOCH #3, step #58] loss: 3.6814408746816345\n",
      "[EPOCH #3, step #60] loss: 3.6805299969970204\n",
      "[EPOCH #3, step #62] loss: 3.6744584431723943\n",
      "[EPOCH #3, step #64] loss: 3.673998209146353\n",
      "[EPOCH #3, step #66] loss: 3.6716580924703113\n",
      "[EPOCH #3, step #68] loss: 3.669395363849142\n",
      "[EPOCH #3, step #70] loss: 3.663197184952212\n",
      "[EPOCH #3, step #72] loss: 3.6624072675835597\n",
      "[EPOCH #3, step #74] loss: 3.657874879837036\n",
      "[EPOCH #3, step #76] loss: 3.6559215830518053\n",
      "[EPOCH #3, step #78] loss: 3.658102524431446\n",
      "[EPOCH #3, step #80] loss: 3.65771214167277\n",
      "[EPOCH #3, step #82] loss: 3.650461013058582\n",
      "[EPOCH #3, step #84] loss: 3.649069267160752\n",
      "[EPOCH #3, step #86] loss: 3.649774285568588\n",
      "[EPOCH #3, step #88] loss: 3.656168128667253\n",
      "[EPOCH #3, step #90] loss: 3.657556664812696\n",
      "[EPOCH #3, step #92] loss: 3.6578193838878343\n",
      "[EPOCH #3, step #94] loss: 3.6574622681266384\n",
      "[EPOCH #3, step #96] loss: 3.6585280551123867\n",
      "[EPOCH #3, step #98] loss: 3.6577209896511502\n",
      "[EPOCH #3, step #100] loss: 3.653487774405149\n",
      "[EPOCH #3, step #102] loss: 3.6507329500994636\n",
      "[EPOCH #3, step #104] loss: 3.6505279268537247\n",
      "[EPOCH #3, step #106] loss: 3.6477955033845992\n",
      "[EPOCH #3, step #108] loss: 3.652924552969976\n",
      "[EPOCH #3, step #110] loss: 3.6521589240512333\n",
      "[EPOCH #3, step #112] loss: 3.651688328886454\n",
      "[EPOCH #3, step #114] loss: 3.649419158437978\n",
      "[EPOCH #3, step #116] loss: 3.648447654186151\n",
      "[EPOCH #3, step #118] loss: 3.650316504871144\n",
      "[EPOCH #3, step #120] loss: 3.647831010424401\n",
      "[EPOCH #3, step #122] loss: 3.648674524896513\n",
      "[EPOCH #3, step #124] loss: 3.649318098068237\n",
      "[EPOCH #3, step #126] loss: 3.6490037835489106\n",
      "[EPOCH #3, step #128] loss: 3.6557241114535075\n",
      "[EPOCH #3, step #130] loss: 3.6536768228953123\n",
      "[EPOCH #3, step #132] loss: 3.652023464217222\n",
      "[EPOCH #3, step #134] loss: 3.6533144209120008\n",
      "[EPOCH #3, step #136] loss: 3.654090030349954\n",
      "[EPOCH #3, step #138] loss: 3.653199087801597\n",
      "[EPOCH #3, step #140] loss: 3.6529625831766332\n",
      "[EPOCH #3, step #142] loss: 3.653569474920526\n",
      "[EPOCH #3, step #144] loss: 3.6554020470586317\n",
      "[EPOCH #3, step #146] loss: 3.6540913111498567\n",
      "[EPOCH #3, step #148] loss: 3.652175821713953\n",
      "[EPOCH #3, step #150] loss: 3.6494810423314177\n",
      "[EPOCH #3, step #152] loss: 3.648351952920552\n",
      "[EPOCH #3, step #154] loss: 3.6453190403599893\n",
      "[EPOCH #3, step #156] loss: 3.642273104114897\n",
      "[EPOCH #3, step #158] loss: 3.6417497658879503\n",
      "[EPOCH #3, step #160] loss: 3.642842768141942\n",
      "[EPOCH #3, step #162] loss: 3.6419557808367022\n",
      "[EPOCH #3, step #164] loss: 3.6444209055467085\n",
      "[EPOCH #3, step #166] loss: 3.6454745880857913\n",
      "[EPOCH #3, step #168] loss: 3.645967067346065\n",
      "[EPOCH #3, step #170] loss: 3.6469624335305735\n",
      "[EPOCH #3, step #172] loss: 3.6439876418582275\n",
      "[EPOCH #3, step #174] loss: 3.6473716912950787\n",
      "[EPOCH #3, step #176] loss: 3.6497880227148194\n",
      "[EPOCH #3, step #178] loss: 3.647730085436858\n",
      "[EPOCH #3, step #180] loss: 3.648121570355326\n",
      "[EPOCH #3, step #182] loss: 3.649730864769774\n",
      "[EPOCH #3, step #184] loss: 3.650233357661479\n",
      "[EPOCH #3, step #186] loss: 3.6513317817035205\n",
      "[EPOCH #3, step #188] loss: 3.6494911196370605\n",
      "[EPOCH #3, step #190] loss: 3.6497868255794983\n",
      "[EPOCH #3, step #192] loss: 3.6510920364004344\n",
      "[EPOCH #3, step #194] loss: 3.6505406330793333\n",
      "[EPOCH #3, step #196] loss: 3.6496342777600748\n",
      "[EPOCH #3, step #198] loss: 3.649341901942114\n",
      "[EPOCH #3, step #200] loss: 3.6526660800573243\n",
      "[EPOCH #3, step #202] loss: 3.652321324559855\n",
      "[EPOCH #3, step #204] loss: 3.6555201763060037\n",
      "[EPOCH #3, step #206] loss: 3.6578118328886906\n",
      "[EPOCH #3, step #208] loss: 3.657824441006309\n",
      "[EPOCH #3, step #210] loss: 3.659550099576254\n",
      "[EPOCH #3, step #212] loss: 3.6599458886983807\n",
      "[EPOCH #3, step #214] loss: 3.6581429226453914\n",
      "[EPOCH #3, step #216] loss: 3.6590229553011704\n",
      "[EPOCH #3, step #218] loss: 3.659554423806874\n",
      "[EPOCH #3, step #220] loss: 3.6589408827043766\n",
      "[EPOCH #3, step #222] loss: 3.6605950759665316\n",
      "[EPOCH #3, step #224] loss: 3.6586412620544433\n",
      "[EPOCH #3, step #226] loss: 3.6592589159894096\n",
      "[EPOCH #3, step #228] loss: 3.6606881982894963\n",
      "[EPOCH #3, step #230] loss: 3.661049202923135\n",
      "[EPOCH #3, step #232] loss: 3.66187183028127\n",
      "[EPOCH #3, step #234] loss: 3.6632169368419243\n",
      "[EPOCH #3, step #236] loss: 3.6646531302214673\n",
      "[EPOCH #3, step #238] loss: 3.6639868335245045\n",
      "[EPOCH #3, step #240] loss: 3.661930191071696\n",
      "[EPOCH #3, step #242] loss: 3.6623125782719366\n",
      "[EPOCH #3, step #244] loss: 3.663223615957766\n",
      "[EPOCH #3, step #246] loss: 3.6646244043280722\n",
      "[EPOCH #3, step #248] loss: 3.6652555743374498\n",
      "[EPOCH #3, step #250] loss: 3.662835455510721\n",
      "[EPOCH #3, step #252] loss: 3.662189987808348\n",
      "[EPOCH #3, step #254] loss: 3.6603488753823674\n",
      "[EPOCH #3, step #256] loss: 3.6596698324967916\n",
      "[EPOCH #3, step #258] loss: 3.657499887768366\n",
      "[EPOCH #3, step #260] loss: 3.6573005352897208\n",
      "[EPOCH #3, step #262] loss: 3.6587377129398826\n",
      "[EPOCH #3, step #264] loss: 3.658659846827669\n",
      "[EPOCH #3, step #266] loss: 3.658454209231259\n",
      "[EPOCH #3, step #268] loss: 3.659084281070525\n",
      "[EPOCH #3, step #270] loss: 3.6584195501250094\n",
      "[EPOCH #3, step #272] loss: 3.658922094128507\n",
      "[EPOCH #3, step #274] loss: 3.658972863284024\n",
      "[EPOCH #3, step #276] loss: 3.6590882354695013\n",
      "[EPOCH #3, step #278] loss: 3.6589904113482405\n",
      "[EPOCH #3, step #280] loss: 3.659003948401726\n",
      "[EPOCH #3, step #282] loss: 3.6582801333585815\n",
      "[EPOCH #3, step #284] loss: 3.659254130982516\n",
      "[EPOCH #3, step #286] loss: 3.658506465705845\n",
      "[EPOCH #3, step #288] loss: 3.6583850185763875\n",
      "[EPOCH #3, step #290] loss: 3.6568838493111206\n",
      "[EPOCH #3, step #292] loss: 3.656918466294585\n",
      "[EPOCH #3, step #294] loss: 3.6564412270562126\n",
      "[EPOCH #3, step #296] loss: 3.654708425605337\n",
      "[EPOCH #3, step #298] loss: 3.6534746602227455\n",
      "[EPOCH #3, step #300] loss: 3.653399331229074\n",
      "[EPOCH #3, step #302] loss: 3.652488647121014\n",
      "[EPOCH #3, step #304] loss: 3.651056320940862\n",
      "[EPOCH #3, step #306] loss: 3.6536939563502706\n",
      "[EPOCH #3, step #308] loss: 3.654648109547143\n",
      "[EPOCH #3, step #310] loss: 3.6549960930631094\n",
      "[EPOCH #3, step #312] loss: 3.6548409751428963\n",
      "[EPOCH #3, step #314] loss: 3.656499143630739\n",
      "[EPOCH #3, step #316] loss: 3.657010649280969\n",
      "[EPOCH #3, step #318] loss: 3.656941502071847\n",
      "[EPOCH #3, step #320] loss: 3.657911472231428\n",
      "[EPOCH #3, step #322] loss: 3.65800291465901\n",
      "[EPOCH #3, step #324] loss: 3.657459982358492\n",
      "[EPOCH #3, step #326] loss: 3.6569601825982425\n",
      "[EPOCH #3, step #328] loss: 3.6577911347966063\n",
      "[EPOCH #3, step #330] loss: 3.6589088202243123\n",
      "[EPOCH #3, step #332] loss: 3.658149884627746\n",
      "[EPOCH #3, step #334] loss: 3.6589626846028795\n",
      "[EPOCH #3, step #336] loss: 3.659228079396822\n",
      "[EPOCH #3, step #338] loss: 3.6593499654865544\n",
      "[EPOCH #3, step #340] loss: 3.659233967929292\n",
      "[EPOCH #3, step #342] loss: 3.659644003859762\n",
      "[EPOCH #3, step #344] loss: 3.660817095162212\n",
      "[EPOCH #3, step #346] loss: 3.661874696912958\n",
      "[EPOCH #3, step #348] loss: 3.6600408697538183\n",
      "[EPOCH #3, step #350] loss: 3.6592277088056604\n",
      "[EPOCH #3, step #352] loss: 3.6594944148833624\n",
      "[EPOCH #3, step #354] loss: 3.6596755833692955\n",
      "[EPOCH #3, step #356] loss: 3.660056427413342\n",
      "[EPOCH #3, step #358] loss: 3.657996471877882\n",
      "[EPOCH #3, step #360] loss: 3.657581200560044\n",
      "[EPOCH #3, step #362] loss: 3.657230248464369\n",
      "[EPOCH #3, step #364] loss: 3.6583353676208077\n",
      "[EPOCH #3, step #366] loss: 3.6584673811369437\n",
      "[EPOCH #3, step #368] loss: 3.6582586112707287\n",
      "[EPOCH #3, step #370] loss: 3.6583903581305655\n",
      "[EPOCH #3, step #372] loss: 3.658447246449243\n",
      "[EPOCH #3, step #374] loss: 3.658485921859741\n",
      "[EPOCH #3, step #376] loss: 3.6595967751915324\n",
      "[EPOCH #3, step #378] loss: 3.6597656562020093\n",
      "[EPOCH #3, step #380] loss: 3.6598619069327207\n",
      "[EPOCH #3, step #382] loss: 3.6600940594785207\n",
      "[EPOCH #3, step #384] loss: 3.6597273969031\n",
      "[EPOCH #3, step #386] loss: 3.6600954581908787\n",
      "[EPOCH #3, step #388] loss: 3.659925395847899\n",
      "[EPOCH #3, step #390] loss: 3.6587227957937722\n",
      "[EPOCH #3, step #392] loss: 3.657469956929447\n",
      "[EPOCH #3, step #394] loss: 3.657139648365069\n",
      "[EPOCH #3, step #396] loss: 3.657947270635994\n",
      "[EPOCH #3, step #398] loss: 3.657082093389411\n",
      "[EPOCH #3, step #400] loss: 3.65648565268576\n",
      "[EPOCH #3, step #402] loss: 3.6566120797292174\n",
      "[EPOCH #3, step #404] loss: 3.657432495517495\n",
      "[EPOCH #3, step #406] loss: 3.656538898294622\n",
      "[EPOCH #3, step #408] loss: 3.656089339104725\n",
      "[EPOCH #3, step #410] loss: 3.6538687918308006\n",
      "[EPOCH #3, step #412] loss: 3.653031798309622\n",
      "[EPOCH #3, step #414] loss: 3.6521139196602697\n",
      "[EPOCH #3, step #416] loss: 3.652688581022999\n",
      "[EPOCH #3, step #418] loss: 3.651728747283644\n",
      "[EPOCH #3, step #420] loss: 3.6520530237437994\n",
      "[EPOCH #3, step #422] loss: 3.6517422807977553\n",
      "[EPOCH #3, step #424] loss: 3.6514837545507093\n",
      "[EPOCH #3, step #426] loss: 3.6514379006638182\n",
      "[EPOCH #3, step #428] loss: 3.6515241841891983\n",
      "[EPOCH #3, step #430] loss: 3.6515075015357916\n",
      "[EPOCH #3, step #432] loss: 3.6514379185286736\n",
      "[EPOCH #3, step #434] loss: 3.6518404259078805\n",
      "[EPOCH #3, step #436] loss: 3.6515633312461033\n",
      "[EPOCH #3, step #438] loss: 3.6506895823467835\n",
      "[EPOCH #3, step #440] loss: 3.6511758806483816\n",
      "[EPOCH #3, step #442] loss: 3.650555253297965\n",
      "[EPOCH #3, step #444] loss: 3.6519464032033855\n",
      "[EPOCH #3, step #446] loss: 3.651429832915065\n",
      "[EPOCH #3, step #448] loss: 3.6508452706453793\n",
      "[EPOCH #3, step #450] loss: 3.6502153365945076\n",
      "[EPOCH #3, step #452] loss: 3.6501518532666677\n",
      "[EPOCH #3, step #454] loss: 3.649352997475928\n",
      "[EPOCH #3, step #456] loss: 3.6497097140589743\n",
      "[EPOCH #3, step #458] loss: 3.6498274579806527\n",
      "[EPOCH #3, step #460] loss: 3.6493343732879375\n",
      "[EPOCH #3, step #462] loss: 3.6496853622453003\n",
      "[EPOCH #3, step #464] loss: 3.6493987708963376\n",
      "[EPOCH #3, step #466] loss: 3.648491694023573\n",
      "[EPOCH #3, step #468] loss: 3.647921575920414\n",
      "[EPOCH #3, step #470] loss: 3.6478228219755136\n",
      "[EPOCH #3, step #472] loss: 3.647384870379974\n",
      "[EPOCH #3, step #474] loss: 3.647117395902935\n",
      "[EPOCH #3, step #476] loss: 3.6473333865591564\n",
      "[EPOCH #3, step #478] loss: 3.6469828520040175\n",
      "[EPOCH #3, step #480] loss: 3.6458678116669527\n",
      "[EPOCH #3, step #482] loss: 3.646317441517769\n",
      "[EPOCH #3, step #484] loss: 3.6465596621798486\n",
      "[EPOCH #3, step #486] loss: 3.647008747045999\n",
      "[EPOCH #3, step #488] loss: 3.647303796740885\n",
      "[EPOCH #3, step #490] loss: 3.6478989794395122\n",
      "[EPOCH #3, step #492] loss: 3.6477105627195345\n",
      "[EPOCH #3, step #494] loss: 3.647858681823268\n",
      "[EPOCH #3, step #496] loss: 3.6474525813365606\n",
      "[EPOCH #3, step #498] loss: 3.647249381862327\n",
      "[EPOCH #3, step #500] loss: 3.6484265922310346\n",
      "[EPOCH #3, step #502] loss: 3.6491854413603217\n",
      "[EPOCH #3, step #504] loss: 3.6488439432465203\n",
      "[EPOCH #3, step #506] loss: 3.64814608760134\n",
      "[EPOCH #3, step #508] loss: 3.647717893709134\n",
      "[EPOCH #3, step #510] loss: 3.6469973929940838\n",
      "[EPOCH #3, step #512] loss: 3.647845619603207\n",
      "[EPOCH #3, step #514] loss: 3.647616406783317\n",
      "[EPOCH #3, step #516] loss: 3.647260213036602\n",
      "[EPOCH #3, step #518] loss: 3.6473832998661635\n",
      "[EPOCH #3, step #520] loss: 3.646897823476517\n",
      "[EPOCH #3, step #522] loss: 3.646776140078076\n",
      "[EPOCH #3, step #524] loss: 3.6458895864940826\n",
      "[EPOCH #3, step #526] loss: 3.6467032192780353\n",
      "[EPOCH #3, step #528] loss: 3.6465492167409743\n",
      "[EPOCH #3, step #530] loss: 3.6453758754299184\n",
      "[EPOCH #3, step #532] loss: 3.6448667550400096\n",
      "[EPOCH #3, step #534] loss: 3.644444413497069\n",
      "[EPOCH #3, step #536] loss: 3.6441495858091217\n",
      "[EPOCH #3, step #538] loss: 3.6438912022755185\n",
      "[EPOCH #3, step #540] loss: 3.643865738249971\n",
      "[EPOCH #3, step #542] loss: 3.6437649726867676\n",
      "[EPOCH #3, step #544] loss: 3.643362046600482\n",
      "[EPOCH #3, step #546] loss: 3.642697785410628\n",
      "[EPOCH #3, step #548] loss: 3.6418440281150555\n",
      "[EPOCH #3, step #550] loss: 3.641997952210276\n",
      "[EPOCH #3, step #552] loss: 3.6418814943668854\n",
      "[EPOCH #3, step #554] loss: 3.6414413778631536\n",
      "[EPOCH #3, step #556] loss: 3.640706105548989\n",
      "[EPOCH #3, step #558] loss: 3.640366936412395\n",
      "[EPOCH #3, step #560] loss: 3.640242386204249\n",
      "[EPOCH #3, step #562] loss: 3.6408839035203573\n",
      "[EPOCH #3, step #564] loss: 3.64122351967128\n",
      "[EPOCH #3, step #566] loss: 3.641340544614842\n",
      "[EPOCH #3, step #568] loss: 3.641311250378252\n",
      "[EPOCH #3, step #570] loss: 3.6413754819779807\n",
      "[EPOCH #3, step #572] loss: 3.6415091738442893\n",
      "[EPOCH #3, step #574] loss: 3.641185420907062\n",
      "[EPOCH #3, step #576] loss: 3.64201654140003\n",
      "[EPOCH #3, step #578] loss: 3.6415933879134155\n",
      "[EPOCH #3, step #580] loss: 3.641500549759594\n",
      "[EPOCH #3, step #582] loss: 3.641055273150907\n",
      "[EPOCH #3, step #584] loss: 3.6407801448789416\n",
      "[EPOCH #3, step #586] loss: 3.640594726932922\n",
      "[EPOCH #3, step #588] loss: 3.640244249172243\n",
      "[EPOCH #3, step #590] loss: 3.640916844511597\n",
      "[EPOCH #3, step #592] loss: 3.6408362629843802\n",
      "[EPOCH #3, step #594] loss: 3.640810729675934\n",
      "[EPOCH #3, step #596] loss: 3.6405694652442357\n",
      "[EPOCH #3, step #598] loss: 3.6408088684878086\n",
      "[EPOCH #3, step #600] loss: 3.640283579040883\n",
      "[EPOCH #3, step #602] loss: 3.640447314501204\n",
      "[EPOCH #3, step #604] loss: 3.639732231975587\n",
      "[EPOCH #3, step #606] loss: 3.6394744716719702\n",
      "[EPOCH #3, step #608] loss: 3.6396443017793603\n",
      "[EPOCH #3, step #610] loss: 3.6387868446531155\n",
      "[EPOCH #3, step #612] loss: 3.6386240878268516\n",
      "[EPOCH #3, step #614] loss: 3.639266747575465\n",
      "[EPOCH #3, step #616] loss: 3.638601757139209\n",
      "[EPOCH #3, step #618] loss: 3.639188087429484\n",
      "[EPOCH #3, step #620] loss: 3.6391115403597674\n",
      "[EPOCH #3, step #622] loss: 3.6379913124188565\n",
      "[EPOCH #3, step #624] loss: 3.637473886871338\n",
      "[EPOCH #3, step #626] loss: 3.6376457050846716\n",
      "[EPOCH #3, step #628] loss: 3.6372740014747897\n",
      "[EPOCH #3, step #630] loss: 3.637584112336632\n",
      "[EPOCH #3, step #632] loss: 3.6371740906912757\n",
      "[EPOCH #3, step #634] loss: 3.6370472468729096\n",
      "[EPOCH #3, step #636] loss: 3.636911000337107\n",
      "[EPOCH #3, step #638] loss: 3.636912144778853\n",
      "[EPOCH #3, step #640] loss: 3.635655732311064\n",
      "[EPOCH #3, step #642] loss: 3.6354937445876385\n",
      "[EPOCH #3, step #644] loss: 3.6347426906112554\n",
      "[EPOCH #3, step #646] loss: 3.6350310607892466\n",
      "[EPOCH #3, step #648] loss: 3.6348427319196044\n",
      "[EPOCH #3, step #650] loss: 3.6346242134838427\n",
      "[EPOCH #3, step #652] loss: 3.633755374648487\n",
      "[EPOCH #3, step #654] loss: 3.6339495396796075\n",
      "[EPOCH #3, step #656] loss: 3.63346832382806\n",
      "[EPOCH #3, step #658] loss: 3.6338384064629516\n",
      "[EPOCH #3, step #660] loss: 3.633341144685846\n",
      "[EPOCH #3, step #662] loss: 3.6332275450319544\n",
      "[EPOCH #3, step #664] loss: 3.6327932053042535\n",
      "[EPOCH #3, step #666] loss: 3.632654989677212\n",
      "[EPOCH #3, step #668] loss: 3.632624053099765\n",
      "[EPOCH #3, step #670] loss: 3.6314552615545193\n",
      "[EPOCH #3, step #672] loss: 3.6314035046508018\n",
      "[EPOCH #3, step #674] loss: 3.631333072803639\n",
      "[EPOCH #3, step #676] loss: 3.6306877963828197\n",
      "[EPOCH #3, step #678] loss: 3.6300473111367544\n",
      "[EPOCH #3, step #680] loss: 3.6302854391621775\n",
      "[EPOCH #3, step #682] loss: 3.6302483458819186\n",
      "[EPOCH #3, step #684] loss: 3.6301339929121252\n",
      "[EPOCH #3, step #686] loss: 3.6295834632246082\n",
      "[EPOCH #3, step #688] loss: 3.629284652120316\n",
      "[EPOCH #3, step #690] loss: 3.629267981014445\n",
      "[EPOCH #3, step #692] loss: 3.629501106763127\n",
      "[EPOCH #3, step #694] loss: 3.62939956273964\n",
      "[EPOCH #3, step #696] loss: 3.629289398918535\n",
      "[EPOCH #3, step #698] loss: 3.6297441541892774\n",
      "[EPOCH #3, step #700] loss: 3.6292650015990167\n",
      "[EPOCH #3, step #702] loss: 3.6298572420226054\n",
      "[EPOCH #3, step #704] loss: 3.6298585688814202\n",
      "[EPOCH #3, step #706] loss: 3.6294125185323063\n",
      "[EPOCH #3, step #708] loss: 3.6293470308037503\n",
      "[EPOCH #3, step #710] loss: 3.629861841054238\n",
      "[EPOCH #3, step #712] loss: 3.629637113627344\n",
      "[EPOCH #3, step #714] loss: 3.62940599268133\n",
      "[EPOCH #3, step #716] loss: 3.6289829915204974\n",
      "[EPOCH #3, step #718] loss: 3.6289606286686884\n",
      "[EPOCH #3, step #720] loss: 3.6289539304090437\n",
      "[EPOCH #3, step #722] loss: 3.6293842287973743\n",
      "[EPOCH #3, step #724] loss: 3.6293374716002367\n",
      "[EPOCH #3, step #726] loss: 3.6287433855143343\n",
      "[EPOCH #3, step #728] loss: 3.629377211726415\n",
      "[EPOCH #3, step #730] loss: 3.62926153673519\n",
      "[EPOCH #3, step #732] loss: 3.629402924039354\n",
      "[EPOCH #3, step #734] loss: 3.629540913769988\n",
      "[EPOCH #3, step #736] loss: 3.629165039618918\n",
      "[EPOCH #3, step #738] loss: 3.6290675335549856\n",
      "[EPOCH #3, step #740] loss: 3.628335578560668\n",
      "[EPOCH #3, step #742] loss: 3.628272456404017\n",
      "[EPOCH #3, step #744] loss: 3.627935137524701\n",
      "[EPOCH #3, step #746] loss: 3.628890003066465\n",
      "[EPOCH #3, step #748] loss: 3.628467677909637\n",
      "[EPOCH #3, step #750] loss: 3.6278313466616856\n",
      "[EPOCH #3, step #752] loss: 3.6278599014636845\n",
      "[EPOCH #3, step #754] loss: 3.6280772509164367\n",
      "[EPOCH #3, step #756] loss: 3.627275113857879\n",
      "[EPOCH #3, step #758] loss: 3.627181996469912\n",
      "[EPOCH #3, step #760] loss: 3.6274633868138517\n",
      "[EPOCH #3, step #762] loss: 3.6269286681908923\n",
      "[EPOCH #3, step #764] loss: 3.627196528864842\n",
      "[EPOCH #3, step #766] loss: 3.6269496864259163\n",
      "[EPOCH #3, step #768] loss: 3.6267295348783772\n",
      "[EPOCH #3, step #770] loss: 3.62656418637079\n",
      "[EPOCH #3, step #772] loss: 3.6262144709311976\n",
      "[EPOCH #3, step #774] loss: 3.625929271636471\n",
      "[EPOCH #3, step #776] loss: 3.625950996173088\n",
      "[EPOCH #3, step #778] loss: 3.625747200766332\n",
      "[EPOCH #3, step #780] loss: 3.625506023438731\n",
      "[EPOCH #3, step #782] loss: 3.625101392144292\n",
      "[EPOCH #3, step #784] loss: 3.624888254882424\n",
      "[EPOCH #3, step #786] loss: 3.62479425294578\n",
      "[EPOCH #3, step #788] loss: 3.6244727888336956\n",
      "[EPOCH #3, step #790] loss: 3.624262851047154\n",
      "[EPOCH #3, step #792] loss: 3.6236412891974816\n",
      "[EPOCH #3, step #794] loss: 3.623099795227531\n",
      "[EPOCH #3, step #796] loss: 3.622948421289212\n",
      "[EPOCH #3, step #798] loss: 3.622686396552266\n",
      "[EPOCH #3, step #800] loss: 3.622487497091591\n",
      "[EPOCH #3, step #802] loss: 3.622814845623145\n",
      "[EPOCH #3, step #804] loss: 3.6227574668315627\n",
      "[EPOCH #3, step #806] loss: 3.6228223106970425\n",
      "[EPOCH #3, step #808] loss: 3.6237869716545266\n",
      "[EPOCH #3, step #810] loss: 3.62322648973853\n",
      "[EPOCH #3, step #812] loss: 3.6224625705939526\n",
      "[EPOCH #3, step #814] loss: 3.6226139940367155\n",
      "[EPOCH #3, step #816] loss: 3.622657716639039\n",
      "[EPOCH #3, step #818] loss: 3.6228945272746103\n",
      "[EPOCH #3, step #820] loss: 3.622912742914439\n",
      "[EPOCH #3, step #822] loss: 3.6227221972742463\n",
      "[EPOCH #3, step #824] loss: 3.6230600839672666\n",
      "[EPOCH #3, step #826] loss: 3.622931382964571\n",
      "[EPOCH #3, step #828] loss: 3.622195680121317\n",
      "[EPOCH #3, step #830] loss: 3.6224990760376308\n",
      "[EPOCH #3, step #832] loss: 3.622733217184426\n",
      "[EPOCH #3, step #834] loss: 3.6226477617275217\n",
      "[EPOCH #3, step #836] loss: 3.623068044404972\n",
      "[EPOCH #3, step #838] loss: 3.623223464167871\n",
      "[EPOCH #3, step #840] loss: 3.623633875432961\n",
      "[EPOCH #3, step #842] loss: 3.6235498912535244\n",
      "[EPOCH #3, step #844] loss: 3.623142620233389\n",
      "[EPOCH #3, step #846] loss: 3.623216679132815\n",
      "[EPOCH #3, step #848] loss: 3.623220947802558\n",
      "[EPOCH #3, step #850] loss: 3.6233269330617546\n",
      "[EPOCH #3, step #852] loss: 3.622874532467036\n",
      "[EPOCH #3, step #854] loss: 3.6224427423979106\n",
      "[EPOCH #3, step #856] loss: 3.622295672306519\n",
      "[EPOCH #3, step #858] loss: 3.622174741502968\n",
      "[EPOCH #3, step #860] loss: 3.622327416892943\n",
      "[EPOCH #3, step #862] loss: 3.622405140038023\n",
      "[EPOCH #3, step #864] loss: 3.6218707845390186\n",
      "[EPOCH #3, step #866] loss: 3.621946868599492\n",
      "[EPOCH #3, step #868] loss: 3.6220901369088265\n",
      "[EPOCH #3, step #870] loss: 3.621823819715585\n",
      "[EPOCH #3, step #872] loss: 3.621833063346277\n",
      "[EPOCH #3, step #874] loss: 3.6214381553104946\n",
      "[EPOCH #3, step #876] loss: 3.621489899732096\n",
      "[EPOCH #3, step #878] loss: 3.6211175915866716\n",
      "[EPOCH #3, step #880] loss: 3.6207509506303523\n",
      "[EPOCH #3, step #882] loss: 3.620607906127705\n",
      "[EPOCH #3, step #884] loss: 3.6211327288783877\n",
      "[EPOCH #3, step #886] loss: 3.6211015869020207\n",
      "[EPOCH #3, step #888] loss: 3.620633634861194\n",
      "[EPOCH #3, step #890] loss: 3.621034078994049\n",
      "[EPOCH #3, step #892] loss: 3.6213949789258693\n",
      "[EPOCH #3, step #894] loss: 3.621393918991089\n",
      "[EPOCH #3, step #896] loss: 3.6208807271194035\n",
      "[EPOCH #3, step #898] loss: 3.620390219470948\n",
      "[EPOCH #3, step #900] loss: 3.620766696337193\n",
      "[EPOCH #3, step #902] loss: 3.6207645723590027\n",
      "[EPOCH #3, step #904] loss: 3.620866234658173\n",
      "[EPOCH #3, step #906] loss: 3.6205018791631933\n",
      "[EPOCH #3, step #908] loss: 3.6199784045434495\n",
      "[EPOCH #3, step #910] loss: 3.6197769045175496\n",
      "[EPOCH #3, step #912] loss: 3.619390370159003\n",
      "[EPOCH #3, step #914] loss: 3.61880674492466\n",
      "[EPOCH #3, step #916] loss: 3.6183188455575426\n",
      "[EPOCH #3, step #918] loss: 3.61733666415832\n",
      "[EPOCH #3, step #920] loss: 3.6175434371935817\n",
      "[EPOCH #3, step #922] loss: 3.617837451002838\n",
      "[EPOCH #3, step #924] loss: 3.617730164656768\n",
      "[EPOCH #3, step #926] loss: 3.6176198254125405\n",
      "[EPOCH #3, step #928] loss: 3.617792846825459\n",
      "[EPOCH #3, step #930] loss: 3.6176461100450266\n",
      "[EPOCH #3, step #932] loss: 3.618184870845635\n",
      "[EPOCH #3, step #934] loss: 3.6179229659830185\n",
      "[EPOCH #3, step #936] loss: 3.6179224996963715\n",
      "[EPOCH #3, step #938] loss: 3.6179488352693308\n",
      "[EPOCH #3, step #940] loss: 3.6179295825147477\n",
      "[EPOCH #3, step #942] loss: 3.618389378676106\n",
      "[EPOCH #3, step #944] loss: 3.6183495688059972\n",
      "[EPOCH #3, step #946] loss: 3.6188788411483843\n",
      "[EPOCH #3, step #948] loss: 3.6190660323935893\n",
      "[EPOCH #3, step #950] loss: 3.6190116092108275\n",
      "[EPOCH #3, step #952] loss: 3.6190334242013167\n",
      "[EPOCH #3, step #954] loss: 3.618927147500802\n",
      "[EPOCH #3, step #956] loss: 3.6186784260449865\n",
      "[EPOCH #3, step #958] loss: 3.618333359580095\n",
      "[EPOCH #3, step #960] loss: 3.618335413759134\n",
      "[EPOCH #3, step #962] loss: 3.6181789429883473\n",
      "[EPOCH #3, step #964] loss: 3.6181510999412736\n",
      "[EPOCH #3, step #966] loss: 3.6178249321654516\n",
      "[EPOCH #3, step #968] loss: 3.6179597215386736\n",
      "[EPOCH #3, step #970] loss: 3.617739240123855\n",
      "[EPOCH #3, step #972] loss: 3.6174165425785767\n",
      "[EPOCH #3, step #974] loss: 3.6175289046458707\n",
      "[EPOCH #3, step #976] loss: 3.617032301218507\n",
      "[EPOCH #3, step #978] loss: 3.6167368187480613\n",
      "[EPOCH #3, step #980] loss: 3.6163969776316884\n",
      "[EPOCH #3, step #982] loss: 3.6163703005529735\n",
      "[EPOCH #3, step #984] loss: 3.6162296551738295\n",
      "[EPOCH #3, step #986] loss: 3.616234971397191\n",
      "[EPOCH #3, step #988] loss: 3.616119871727738\n",
      "[EPOCH #3, step #990] loss: 3.615985317018511\n",
      "[EPOCH #3, step #992] loss: 3.6154046478828517\n",
      "[EPOCH #3, step #994] loss: 3.6159047390348347\n",
      "[EPOCH #3, step #996] loss: 3.615897021776695\n",
      "[EPOCH #3, step #998] loss: 3.616175913357281\n",
      "[EPOCH #3, step #1000] loss: 3.6162316887290564\n",
      "[EPOCH #3, step #1002] loss: 3.6160663212997726\n",
      "[EPOCH #3, step #1004] loss: 3.6162055409369778\n",
      "[EPOCH #3, step #1006] loss: 3.616084379614761\n",
      "[EPOCH #3, step #1008] loss: 3.615569298520197\n",
      "[EPOCH #3, step #1010] loss: 3.614876620965235\n",
      "[EPOCH #3, step #1012] loss: 3.6148022150828596\n",
      "[EPOCH #3, step #1014] loss: 3.6151962782949063\n",
      "[EPOCH #3, step #1016] loss: 3.614814935063425\n",
      "[EPOCH #3, step #1018] loss: 3.6148149578798274\n",
      "[EPOCH #3, step #1020] loss: 3.614292732532064\n",
      "[EPOCH #3, step #1022] loss: 3.6137447455062195\n",
      "[EPOCH #3, step #1024] loss: 3.6136127892936147\n",
      "[EPOCH #3, step #1026] loss: 3.613511388234526\n",
      "[EPOCH #3, step #1028] loss: 3.613091585355783\n",
      "[EPOCH #3, step #1030] loss: 3.613225326852586\n",
      "[EPOCH #3, step #1032] loss: 3.613435233550981\n",
      "[EPOCH #3, step #1034] loss: 3.6135207957115725\n",
      "[EPOCH #3, step #1036] loss: 3.6141864034915727\n",
      "[EPOCH #3, step #1038] loss: 3.6143437264858242\n",
      "[EPOCH #3, step #1040] loss: 3.614752753667254\n",
      "[EPOCH #3, step #1042] loss: 3.6145909518317776\n",
      "[EPOCH #3, step #1044] loss: 3.6147125143753853\n",
      "[EPOCH #3, step #1046] loss: 3.6147138468970996\n",
      "[EPOCH #3, step #1048] loss: 3.614382365865862\n",
      "[EPOCH #3, step #1050] loss: 3.613909151302305\n",
      "[EPOCH #3, step #1052] loss: 3.613782547591192\n",
      "[EPOCH #3, step #1054] loss: 3.614214510714273\n",
      "[EPOCH #3, step #1056] loss: 3.614207897980256\n",
      "[EPOCH #3, step #1058] loss: 3.614261616165622\n",
      "[EPOCH #3, step #1060] loss: 3.614096224251836\n",
      "[EPOCH #3, step #1062] loss: 3.6138165389605548\n",
      "[EPOCH #3, step #1064] loss: 3.6137329788834838\n",
      "[EPOCH #3, step #1066] loss: 3.6138203722802746\n",
      "[EPOCH #3, step #1068] loss: 3.613887983800319\n",
      "[EPOCH #3, step #1070] loss: 3.613914944767173\n",
      "[EPOCH #3, step #1072] loss: 3.614123922580886\n",
      "[EPOCH #3, step #1074] loss: 3.614141922218855\n",
      "[EPOCH #3, step #1076] loss: 3.614396651364524\n",
      "[EPOCH #3, step #1078] loss: 3.6144745153227373\n",
      "[EPOCH #3, step #1080] loss: 3.614308259754022\n",
      "[EPOCH #3, step #1082] loss: 3.614533809193394\n",
      "[EPOCH #3, step #1084] loss: 3.6145643166133334\n",
      "[EPOCH #3, step #1086] loss: 3.6146847001982043\n",
      "[EPOCH #3, step #1088] loss: 3.614470279578007\n",
      "[EPOCH #3, step #1090] loss: 3.6150217615716724\n",
      "[EPOCH #3, step #1092] loss: 3.6147164644065084\n",
      "[EPOCH #3, step #1094] loss: 3.6142048957685358\n",
      "[EPOCH #3, step #1096] loss: 3.613802462137061\n",
      "[EPOCH #3, step #1098] loss: 3.613730314105505\n",
      "[EPOCH #3, step #1100] loss: 3.6136938947422954\n",
      "[EPOCH #3, step #1102] loss: 3.6135698808720194\n",
      "[EPOCH #3, step #1104] loss: 3.6133316488826974\n",
      "[EPOCH #3, step #1106] loss: 3.6134144475897263\n",
      "[EPOCH #3, step #1108] loss: 3.6132121989058414\n",
      "[EPOCH #3, step #1110] loss: 3.613044174376315\n",
      "[EPOCH #3, step #1112] loss: 3.613245897858612\n",
      "[EPOCH #3, step #1114] loss: 3.6129066777336223\n",
      "[EPOCH #3, step #1116] loss: 3.6128635372342868\n",
      "[EPOCH #3, step #1118] loss: 3.613181509856564\n",
      "[EPOCH #3, step #1120] loss: 3.6127180168396866\n",
      "[EPOCH #3, step #1122] loss: 3.6128350722397\n",
      "[EPOCH #3, step #1124] loss: 3.612879517449273\n",
      "[EPOCH #3, step #1126] loss: 3.612626868216676\n",
      "[EPOCH #3, step #1128] loss: 3.61249973586009\n",
      "[EPOCH #3, step #1130] loss: 3.61205583289068\n",
      "[EPOCH #3, step #1132] loss: 3.6119869742263027\n",
      "[EPOCH #3, step #1134] loss: 3.6119545615192026\n",
      "[EPOCH #3, step #1136] loss: 3.6115093281526995\n",
      "[EPOCH #3, step #1138] loss: 3.61130894287518\n",
      "[EPOCH #3, step #1140] loss: 3.6113925876583997\n",
      "[EPOCH #3, step #1142] loss: 3.611284947666492\n",
      "[EPOCH #3, step #1144] loss: 3.6113348785966766\n",
      "[EPOCH #3, step #1146] loss: 3.611212770733089\n",
      "[EPOCH #3, step #1148] loss: 3.610722779605158\n",
      "[EPOCH #3, step #1150] loss: 3.610182622533379\n",
      "[EPOCH #3, step #1152] loss: 3.609956296340135\n",
      "[EPOCH #3, step #1154] loss: 3.610225740655676\n",
      "[EPOCH #3, step #1156] loss: 3.6100592670918745\n",
      "[EPOCH #3, step #1158] loss: 3.6104813356457135\n",
      "[EPOCH #3, step #1160] loss: 3.6100867022531595\n",
      "[EPOCH #3, step #1162] loss: 3.609825174457947\n",
      "[EPOCH #3, step #1164] loss: 3.609737606416956\n",
      "[EPOCH #3, step #1166] loss: 3.6101222910631794\n",
      "[EPOCH #3, step #1168] loss: 3.6104048458911904\n",
      "[EPOCH #3, step #1170] loss: 3.610369979164521\n",
      "[EPOCH #3, step #1172] loss: 3.610677776840743\n",
      "[EPOCH #3, step #1174] loss: 3.609976513233591\n",
      "[EPOCH #3, step #1176] loss: 3.6101431279437666\n",
      "[EPOCH #3, step #1178] loss: 3.6100036230402743\n",
      "[EPOCH #3, step #1180] loss: 3.61001009339503\n",
      "[EPOCH #3, step #1182] loss: 3.60940955154793\n",
      "[EPOCH #3, step #1184] loss: 3.6092507438820625\n",
      "[EPOCH #3, step #1186] loss: 3.6086740875404826\n",
      "[EPOCH #3, step #1188] loss: 3.609146944307499\n",
      "[EPOCH #3, step #1190] loss: 3.6092916848177072\n",
      "[EPOCH #3, step #1192] loss: 3.6094858914189047\n",
      "[EPOCH #3, step #1194] loss: 3.6090366577004787\n",
      "[EPOCH #3, step #1196] loss: 3.6090504710835623\n",
      "[EPOCH #3, step #1198] loss: 3.608918929318769\n",
      "[EPOCH #3, step #1200] loss: 3.6093505320203594\n",
      "[EPOCH #3, step #1202] loss: 3.609390765354223\n",
      "[EPOCH #3, step #1204] loss: 3.609012786976035\n",
      "[EPOCH #3, step #1206] loss: 3.6085147259150445\n",
      "[EPOCH #3, step #1208] loss: 3.608524520501704\n",
      "[EPOCH #3, step #1210] loss: 3.6083659718196124\n",
      "[EPOCH #3, step #1212] loss: 3.6084241249889555\n",
      "[EPOCH #3, step #1214] loss: 3.6082043355384483\n",
      "[EPOCH #3, step #1216] loss: 3.60809018382697\n",
      "[EPOCH #3, step #1218] loss: 3.6077918677764216\n",
      "[EPOCH #3, step #1220] loss: 3.6074468605250827\n",
      "[EPOCH #3, step #1222] loss: 3.6070513388024716\n",
      "[EPOCH #3, step #1224] loss: 3.6070964953364157\n",
      "[EPOCH #3, step #1226] loss: 3.606856057191148\n",
      "[EPOCH #3, step #1228] loss: 3.606843254447856\n",
      "[EPOCH #3, step #1230] loss: 3.606580576792081\n",
      "[EPOCH #3, step #1232] loss: 3.606396899992919\n",
      "[EPOCH #3, step #1234] loss: 3.606227025908497\n",
      "[EPOCH #3, step #1236] loss: 3.606265855779933\n",
      "[EPOCH #3, step #1238] loss: 3.6060860959438665\n",
      "[EPOCH #3, step #1240] loss: 3.606145674139141\n",
      "[EPOCH #3, step #1242] loss: 3.605727742778996\n",
      "[EPOCH #3, step #1244] loss: 3.6056367493058783\n",
      "[EPOCH #3, step #1246] loss: 3.605459543257211\n",
      "[EPOCH #3, step #1248] loss: 3.6057296715515723\n",
      "[EPOCH #3, step #1250] loss: 3.605499510380099\n",
      "[EPOCH #3, step #1252] loss: 3.6051708552139052\n",
      "[EPOCH #3, step #1254] loss: 3.60467111028998\n",
      "[EPOCH #3, step #1256] loss: 3.604848399651648\n",
      "[EPOCH #3, step #1258] loss: 3.6045843121359704\n",
      "[EPOCH #3, step #1260] loss: 3.6042823141099536\n",
      "[EPOCH #3, step #1262] loss: 3.6041802200927493\n",
      "[EPOCH #3, step #1264] loss: 3.603466511338125\n",
      "[EPOCH #3, step #1266] loss: 3.603067672431422\n",
      "[EPOCH #3, step #1268] loss: 3.6033513555383947\n",
      "[EPOCH #3, step #1270] loss: 3.6031256054068623\n",
      "[EPOCH #3, step #1272] loss: 3.602587036887961\n",
      "[EPOCH #3, step #1274] loss: 3.6022854900360106\n",
      "[EPOCH #3, step #1276] loss: 3.6024327668344593\n",
      "[EPOCH #3, step #1278] loss: 3.6024260377399244\n",
      "[EPOCH #3, step #1280] loss: 3.602140604937849\n",
      "[EPOCH #3, step #1282] loss: 3.601997267335816\n",
      "[EPOCH #3, step #1284] loss: 3.6020584818917953\n",
      "[EPOCH #3, step #1286] loss: 3.602130267633054\n",
      "[EPOCH #3, step #1288] loss: 3.602222356248771\n",
      "[EPOCH #3, step #1290] loss: 3.6020903302938048\n",
      "[EPOCH #3, step #1292] loss: 3.6020420163708513\n",
      "[EPOCH #3, step #1294] loss: 3.602142319992242\n",
      "[EPOCH #3, step #1296] loss: 3.6019563463530178\n",
      "[EPOCH #3, step #1298] loss: 3.6015185494896444\n",
      "[EPOCH #3, step #1300] loss: 3.6017913444513177\n",
      "[EPOCH #3, step #1302] loss: 3.6017145356670857\n",
      "[EPOCH #3, step #1304] loss: 3.601716218414891\n",
      "[EPOCH #3, step #1306] loss: 3.6017514245603133\n",
      "[EPOCH #3, step #1308] loss: 3.6020843694918567\n",
      "[EPOCH #3, step #1310] loss: 3.602079573521443\n",
      "[EPOCH #3, step #1312] loss: 3.6018214167662457\n",
      "[EPOCH #3, step #1314] loss: 3.601702484885096\n",
      "[EPOCH #3, step #1316] loss: 3.6017228206541834\n",
      "[EPOCH #3, step #1318] loss: 3.6016348425956997\n",
      "[EPOCH #3, step #1320] loss: 3.601574908234151\n",
      "[EPOCH #3, step #1322] loss: 3.6015826331244574\n",
      "[EPOCH #3, step #1324] loss: 3.601281066930519\n",
      "[EPOCH #3, step #1326] loss: 3.6009144714746424\n",
      "[EPOCH #3, step #1328] loss: 3.600667896981164\n",
      "[EPOCH #3, step #1330] loss: 3.6001942005487066\n",
      "[EPOCH #3, step #1332] loss: 3.5998382344786064\n",
      "[EPOCH #3, step #1334] loss: 3.5994842891835988\n",
      "[EPOCH #3, step #1336] loss: 3.5992187159045383\n",
      "[EPOCH #3, step #1338] loss: 3.599227102235505\n",
      "[EPOCH #3, step #1340] loss: 3.5987998335153466\n",
      "[EPOCH #3, step #1342] loss: 3.598674034770531\n",
      "[EPOCH #3, step #1344] loss: 3.598291933314951\n",
      "[EPOCH #3, step #1346] loss: 3.5980875435456046\n",
      "[EPOCH #3, step #1348] loss: 3.5980975838216525\n",
      "[EPOCH #3, step #1350] loss: 3.597832248265614\n",
      "[EPOCH #3, step #1352] loss: 3.5980964951046466\n",
      "[EPOCH #3, step #1354] loss: 3.597954072635552\n",
      "[EPOCH #3, step #1356] loss: 3.597671501936944\n",
      "[EPOCH #3, step #1358] loss: 3.5973880710279005\n",
      "[EPOCH #3, step #1360] loss: 3.597547409378545\n",
      "[EPOCH #3, step #1362] loss: 3.597404661724345\n",
      "[EPOCH #3, step #1364] loss: 3.5973366646539597\n",
      "[EPOCH #3, step #1366] loss: 3.5972625246515393\n",
      "[EPOCH #3, step #1368] loss: 3.5976986327773903\n",
      "[EPOCH #3, step #1370] loss: 3.597319555491274\n",
      "[EPOCH #3, step #1372] loss: 3.5972865506496556\n",
      "[EPOCH #3, step #1374] loss: 3.597172880346125\n",
      "[EPOCH #3, step #1376] loss: 3.5968825927919985\n",
      "[EPOCH #3, step #1378] loss: 3.5967448667134816\n",
      "[EPOCH #3, step #1380] loss: 3.5962281953934565\n",
      "[EPOCH #3, step #1382] loss: 3.5964330876985495\n",
      "[EPOCH #3, step #1384] loss: 3.5962424863546762\n",
      "[EPOCH #3, step #1386] loss: 3.596144075091141\n",
      "[EPOCH #3, step #1388] loss: 3.5959499234171375\n",
      "[EPOCH #3, step #1390] loss: 3.5961241651832587\n",
      "[EPOCH #3, step #1392] loss: 3.5962177414904373\n",
      "[EPOCH #3, step #1394] loss: 3.5956778681833685\n",
      "[EPOCH #3, step #1396] loss: 3.5960273877500892\n",
      "[EPOCH #3, step #1398] loss: 3.596402412998071\n",
      "[EPOCH #3, step #1400] loss: 3.5964674859451957\n",
      "[EPOCH #3, step #1402] loss: 3.5964451867686114\n",
      "[EPOCH #3, step #1404] loss: 3.596319094586627\n",
      "[EPOCH #3, step #1406] loss: 3.5964171332336945\n",
      "[EPOCH #3, step #1408] loss: 3.5963908343386195\n",
      "[EPOCH #3, step #1410] loss: 3.596701288797769\n",
      "[EPOCH #3, step #1412] loss: 3.596795518433719\n",
      "[EPOCH #3, step #1414] loss: 3.5967560919771766\n",
      "[EPOCH #3, step #1416] loss: 3.5969379203960603\n",
      "[EPOCH #3, step #1418] loss: 3.5959907747474333\n",
      "[EPOCH #3, step #1420] loss: 3.595879421193863\n",
      "[EPOCH #3, step #1422] loss: 3.5958034442665707\n",
      "[EPOCH #3, step #1424] loss: 3.595725849887781\n",
      "[EPOCH #3, step #1426] loss: 3.595787152261607\n",
      "[EPOCH #3, step #1428] loss: 3.5952559963984454\n",
      "[EPOCH #3, step #1430] loss: 3.594794797864017\n",
      "[EPOCH #3, step #1432] loss: 3.5946404464745636\n",
      "[EPOCH #3, step #1434] loss: 3.5945455094247745\n",
      "[EPOCH #3, step #1436] loss: 3.5941705746873023\n",
      "[EPOCH #3, step #1438] loss: 3.5939270903287124\n",
      "[EPOCH #3, step #1440] loss: 3.5935226348768414\n",
      "[EPOCH #3, step #1442] loss: 3.5935132505161764\n",
      "[EPOCH #3, step #1444] loss: 3.5935173462006462\n",
      "[EPOCH #3, step #1446] loss: 3.5932452696804846\n",
      "[EPOCH #3, step #1448] loss: 3.5932795644382347\n",
      "[EPOCH #3, step #1450] loss: 3.593291486402284\n",
      "[EPOCH #3, step #1452] loss: 3.593100675286216\n",
      "[EPOCH #3, step #1454] loss: 3.5931025506704533\n",
      "[EPOCH #3, step #1456] loss: 3.592989855951533\n",
      "[EPOCH #3, step #1458] loss: 3.593108833448947\n",
      "[EPOCH #3, step #1460] loss: 3.5928335395437\n",
      "[EPOCH #3, step #1462] loss: 3.592625075142757\n",
      "[EPOCH #3, step #1464] loss: 3.592656336872244\n",
      "[EPOCH #3, step #1466] loss: 3.5925347718886966\n",
      "[EPOCH #3, step #1468] loss: 3.592629672395201\n",
      "[EPOCH #3, step #1470] loss: 3.592405408681614\n",
      "[EPOCH #3, step #1472] loss: 3.5923907505923682\n",
      "[EPOCH #3, step #1474] loss: 3.592310530452405\n",
      "[EPOCH #3, step #1476] loss: 3.5922491351897925\n",
      "[EPOCH #3, step #1478] loss: 3.592252847389082\n",
      "[EPOCH #3, step #1480] loss: 3.59208637777814\n",
      "[EPOCH #3, step #1482] loss: 3.591646515189677\n",
      "[EPOCH #3, step #1484] loss: 3.591795991004918\n",
      "[EPOCH #3, step #1486] loss: 3.5915088550949865\n",
      "[EPOCH #3, step #1488] loss: 3.5913617734223746\n",
      "[EPOCH #3, step #1490] loss: 3.5915735242832114\n",
      "[EPOCH #3, step #1492] loss: 3.591692332844565\n",
      "[EPOCH #3, step #1494] loss: 3.591734202490204\n",
      "[EPOCH #3, step #1496] loss: 3.591504047931475\n",
      "[EPOCH #3, step #1498] loss: 3.5911731545013774\n",
      "[EPOCH #3, step #1500] loss: 3.5911377197420653\n",
      "[EPOCH #3, step #1502] loss: 3.591197623464162\n",
      "[EPOCH #3, step #1504] loss: 3.5910805141410953\n",
      "[EPOCH #3, step #1506] loss: 3.5907002556933105\n",
      "[EPOCH #3, step #1508] loss: 3.5905578134864116\n",
      "[EPOCH #3, step #1510] loss: 3.5904830534043177\n",
      "[EPOCH #3, step #1512] loss: 3.5905570928733708\n",
      "[EPOCH #3, step #1514] loss: 3.5909765635386552\n",
      "[EPOCH #3, step #1516] loss: 3.5906580168712114\n",
      "[EPOCH #3, step #1518] loss: 3.5904825589152995\n",
      "[EPOCH #3, step #1520] loss: 3.59070123237344\n",
      "[EPOCH #3, step #1522] loss: 3.5905739304585746\n",
      "[EPOCH #3, step #1524] loss: 3.590523023918027\n",
      "[EPOCH #3, step #1526] loss: 3.5903804121098646\n",
      "[EPOCH #3, step #1528] loss: 3.5901870777436997\n",
      "[EPOCH #3, step #1530] loss: 3.5902879582286116\n",
      "[EPOCH #3, step #1532] loss: 3.590616833984813\n",
      "[EPOCH #3, step #1534] loss: 3.590583932050276\n",
      "[EPOCH #3, step #1536] loss: 3.5907652381184665\n",
      "[EPOCH #3, step #1538] loss: 3.590763888628627\n",
      "[EPOCH #3, step #1540] loss: 3.590328754348309\n",
      "[EPOCH #3, step #1542] loss: 3.5903236892265076\n",
      "[EPOCH #3, step #1544] loss: 3.5901939950714605\n",
      "[EPOCH #3, step #1546] loss: 3.5900854464878016\n",
      "[EPOCH #3, step #1548] loss: 3.589886243609631\n",
      "[EPOCH #3, step #1550] loss: 3.5897053547016196\n",
      "[EPOCH #3, step #1552] loss: 3.5897053262915675\n",
      "[EPOCH #3, step #1554] loss: 3.5896217821495324\n",
      "[EPOCH #3, step #1556] loss: 3.589617687536496\n",
      "[EPOCH #3, step #1558] loss: 3.5897674734887595\n",
      "[EPOCH #3, step #1560] loss: 3.5896778045595648\n",
      "[EPOCH #3, step #1562] loss: 3.5894602220636562\n",
      "[EPOCH #3, step #1564] loss: 3.589146041717773\n",
      "[EPOCH #3, step #1566] loss: 3.5885154421951793\n",
      "[EPOCH #3, step #1568] loss: 3.5885518287077613\n",
      "[EPOCH #3, step #1570] loss: 3.5885515618218045\n",
      "[EPOCH #3, step #1572] loss: 3.5888182863792037\n",
      "[EPOCH #3, step #1574] loss: 3.588741119172838\n",
      "[EPOCH #3, step #1576] loss: 3.588647999337147\n",
      "[EPOCH #3, step #1578] loss: 3.5884849268700068\n",
      "[EPOCH #3, step #1580] loss: 3.5886088664738307\n",
      "[EPOCH #3, step #1582] loss: 3.5881911286506485\n",
      "[EPOCH #3, step #1584] loss: 3.5881974099938425\n",
      "[EPOCH #3, step #1586] loss: 3.5878908829487717\n",
      "[EPOCH #3, step #1588] loss: 3.5880992089974346\n",
      "[EPOCH #3, step #1590] loss: 3.588216030395383\n",
      "[EPOCH #3, step #1592] loss: 3.5879162110701643\n",
      "[EPOCH #3, step #1594] loss: 3.587689973717573\n",
      "[EPOCH #3, step #1596] loss: 3.5876234186837728\n",
      "[EPOCH #3, step #1598] loss: 3.5876917324638726\n",
      "[EPOCH #3, step #1600] loss: 3.5874910062733925\n",
      "[EPOCH #3, step #1602] loss: 3.5870946704486126\n",
      "[EPOCH #3, step #1604] loss: 3.586841929218851\n",
      "[EPOCH #3, step #1606] loss: 3.5866745254158157\n",
      "[EPOCH #3, step #1608] loss: 3.5864159721554696\n",
      "[EPOCH #3, step #1610] loss: 3.586165317314001\n",
      "[EPOCH #3, step #1612] loss: 3.5857370796960404\n",
      "[EPOCH #3, step #1614] loss: 3.58543780625051\n",
      "[EPOCH #3, step #1616] loss: 3.5852962177184606\n",
      "[EPOCH #3, step #1618] loss: 3.585092127507229\n",
      "[EPOCH #3, step #1620] loss: 3.584952370610081\n",
      "[EPOCH #3, step #1622] loss: 3.585235207299722\n",
      "[EPOCH #3, step #1624] loss: 3.585193651639498\n",
      "[EPOCH #3, step #1626] loss: 3.585022270423031\n",
      "[EPOCH #3, step #1628] loss: 3.5850229588222327\n",
      "[EPOCH #3, step #1630] loss: 3.5845523332248503\n",
      "[EPOCH #3, step #1632] loss: 3.5841145573842037\n",
      "[EPOCH #3, step #1634] loss: 3.583997854909401\n",
      "[EPOCH #3, step #1636] loss: 3.583912216459168\n",
      "[EPOCH #3, step #1638] loss: 3.5837606877506762\n",
      "[EPOCH #3, step #1640] loss: 3.5839878189207792\n",
      "[EPOCH #3, step #1642] loss: 3.583973740921903\n",
      "[EPOCH #3, step #1644] loss: 3.583854107436438\n",
      "[EPOCH #3, step #1646] loss: 3.5838556913585466\n",
      "[EPOCH #3, step #1648] loss: 3.583740113792165\n",
      "[EPOCH #3, step #1650] loss: 3.5837303397873543\n",
      "[EPOCH #3, step #1652] loss: 3.5831201604403513\n",
      "[EPOCH #3, step #1654] loss: 3.582800164899797\n",
      "[EPOCH #3, step #1656] loss: 3.58226405099421\n",
      "[EPOCH #3, step #1658] loss: 3.582135815588806\n",
      "[EPOCH #3, step #1660] loss: 3.5820037748783484\n",
      "[EPOCH #3, step #1662] loss: 3.581846099407359\n",
      "[EPOCH #3, step #1664] loss: 3.581578923560478\n",
      "[EPOCH #3, step #1666] loss: 3.581641537026152\n",
      "[EPOCH #3, step #1668] loss: 3.5814331314962304\n",
      "[EPOCH #3, step #1670] loss: 3.5813317457264158\n",
      "[EPOCH #3, step #1672] loss: 3.5812431970757066\n",
      "[EPOCH #3, step #1674] loss: 3.581023124011595\n",
      "[EPOCH #3, step #1676] loss: 3.58097030040261\n",
      "[EPOCH #3, step #1678] loss: 3.5812178502983105\n",
      "[EPOCH #3, step #1680] loss: 3.5813063013631625\n",
      "[EPOCH #3, step #1682] loss: 3.5814328458574085\n",
      "[EPOCH #3, step #1684] loss: 3.580989370572461\n",
      "[EPOCH #3, step #1686] loss: 3.5807812237923287\n",
      "[EPOCH #3, step #1688] loss: 3.5807152323782128\n",
      "[EPOCH #3, step #1690] loss: 3.580943555397652\n",
      "[EPOCH #3, step #1692] loss: 3.5812142682512063\n",
      "[EPOCH #3, step #1694] loss: 3.5812739178142716\n",
      "[EPOCH #3, step #1696] loss: 3.581137985781353\n",
      "[EPOCH #3, step #1698] loss: 3.581321842604486\n",
      "[EPOCH #3, step #1700] loss: 3.581012536749147\n",
      "[EPOCH #3, step #1702] loss: 3.5805962691920263\n",
      "[EPOCH #3, step #1704] loss: 3.580460011155025\n",
      "[EPOCH #3, step #1706] loss: 3.580231660838426\n",
      "[EPOCH #3, step #1708] loss: 3.580188351810292\n",
      "[EPOCH #3, step #1710] loss: 3.580443049787012\n",
      "[EPOCH #3, step #1712] loss: 3.580171269557661\n",
      "[EPOCH #3, step #1714] loss: 3.580218959897322\n",
      "[EPOCH #3, step #1716] loss: 3.5801790550689607\n",
      "[EPOCH #3, step #1718] loss: 3.5802000036345034\n",
      "[EPOCH #3, step #1720] loss: 3.579664756363731\n",
      "[EPOCH #3, step #1722] loss: 3.5793938032084958\n",
      "[EPOCH #3, step #1724] loss: 3.5793330632085385\n",
      "[EPOCH #3, step #1726] loss: 3.5791184160843295\n",
      "[EPOCH #3, step #1728] loss: 3.5789693640173343\n",
      "[EPOCH #3, step #1730] loss: 3.5790321813161357\n",
      "[EPOCH #3, step #1732] loss: 3.579090452029123\n",
      "[EPOCH #3, step #1734] loss: 3.5789796757766767\n",
      "[EPOCH #3, step #1736] loss: 3.5787491062693575\n",
      "[EPOCH #3, step #1738] loss: 3.578687299730587\n",
      "[EPOCH #3, step #1740] loss: 3.578578993755124\n",
      "[EPOCH #3, step #1742] loss: 3.5785496498891423\n",
      "[EPOCH #3, step #1744] loss: 3.578529166902034\n",
      "[EPOCH #3, step #1746] loss: 3.5782111898857862\n",
      "[EPOCH #3, step #1748] loss: 3.5781331599406205\n",
      "[EPOCH #3, step #1750] loss: 3.5781942549465318\n",
      "[EPOCH #3, step #1752] loss: 3.578070784730362\n",
      "[EPOCH #3, step #1754] loss: 3.5776617521574017\n",
      "[EPOCH #3, step #1756] loss: 3.57776864279246\n",
      "[EPOCH #3, step #1758] loss: 3.577479783346058\n",
      "[EPOCH #3, step #1760] loss: 3.5773577247405175\n",
      "[EPOCH #3, step #1762] loss: 3.5773868199714665\n",
      "[EPOCH #3, step #1764] loss: 3.5773295895573773\n",
      "[EPOCH #3, step #1766] loss: 3.576777542251345\n",
      "[EPOCH #3, step #1768] loss: 3.5765078842741005\n",
      "[EPOCH #3, step #1770] loss: 3.576510020799384\n",
      "[EPOCH #3, step #1772] loss: 3.576472386490875\n",
      "[EPOCH #3, step #1774] loss: 3.576361445440373\n",
      "[EPOCH #3, step #1776] loss: 3.575766437430696\n",
      "[EPOCH #3, step #1778] loss: 3.575551841284466\n",
      "[EPOCH #3, step #1780] loss: 3.57545498473667\n",
      "[EPOCH #3, step #1782] loss: 3.575746185246038\n",
      "[EPOCH #3, step #1784] loss: 3.5755410299915558\n",
      "[EPOCH #3, step #1786] loss: 3.5752969319151977\n",
      "[EPOCH #3, step #1788] loss: 3.575272155514371\n",
      "[EPOCH #3, step #1790] loss: 3.575209459201508\n",
      "[EPOCH #3, step #1792] loss: 3.5750158346370817\n",
      "[EPOCH #3, step #1794] loss: 3.5750268999912613\n",
      "[EPOCH #3, step #1796] loss: 3.574683438822768\n",
      "[EPOCH #3, step #1798] loss: 3.57426104007528\n",
      "[EPOCH #3, step #1800] loss: 3.574326102697869\n",
      "[EPOCH #3, step #1802] loss: 3.574180992589814\n",
      "[EPOCH #3, step #1804] loss: 3.5743201617719063\n",
      "[EPOCH #3, step #1806] loss: 3.5743888874507834\n",
      "[EPOCH #3, step #1808] loss: 3.574192743791672\n",
      "[EPOCH #3, step #1810] loss: 3.5742688317248863\n",
      "[EPOCH #3, step #1812] loss: 3.5741730140048498\n",
      "[EPOCH #3, step #1814] loss: 3.5741455432797267\n",
      "[EPOCH #3, step #1816] loss: 3.574016476832187\n",
      "[EPOCH #3, step #1818] loss: 3.574031505825888\n",
      "[EPOCH #3, step #1820] loss: 3.573703305136038\n",
      "[EPOCH #3, step #1822] loss: 3.5735715863734763\n",
      "[EPOCH #3, step #1824] loss: 3.573531884101972\n",
      "[EPOCH #3, step #1826] loss: 3.5734037683515125\n",
      "[EPOCH #3, step #1828] loss: 3.5730699834568114\n",
      "[EPOCH #3, step #1830] loss: 3.5731135926436752\n",
      "[EPOCH #3, step #1832] loss: 3.5729287637106006\n",
      "[EPOCH #3, step #1834] loss: 3.5728994772284817\n",
      "[EPOCH #3, step #1836] loss: 3.5725839810327273\n",
      "[EPOCH #3, step #1838] loss: 3.572469866489703\n",
      "[EPOCH #3, step #1840] loss: 3.5724946735087846\n",
      "[EPOCH #3, step #1842] loss: 3.5722637494750082\n",
      "[EPOCH #3, step #1844] loss: 3.5723665331760395\n",
      "[EPOCH #3, step #1846] loss: 3.572235891737677\n",
      "[EPOCH #3, step #1848] loss: 3.572065601611924\n",
      "[EPOCH #3, step #1850] loss: 3.571944474143508\n",
      "[EPOCH #3, step #1852] loss: 3.5718527501554536\n",
      "[EPOCH #3, step #1854] loss: 3.571593908479593\n",
      "[EPOCH #3, step #1856] loss: 3.5713990182727655\n",
      "[EPOCH #3, step #1858] loss: 3.571245173987296\n",
      "[EPOCH #3, step #1860] loss: 3.571122921518841\n",
      "[EPOCH #3, step #1862] loss: 3.5708763137403765\n",
      "[EPOCH #3, step #1864] loss: 3.5708495097889017\n",
      "[EPOCH #3, step #1866] loss: 3.5706165506039063\n",
      "[EPOCH #3, step #1868] loss: 3.5704089734183078\n",
      "[EPOCH #3, step #1870] loss: 3.570291260357912\n",
      "[EPOCH #3, step #1872] loss: 3.5703043425967844\n",
      "[EPOCH #3, step #1874] loss: 3.5701687250773113\n",
      "[EPOCH #3, step #1876] loss: 3.570133994980956\n",
      "[EPOCH #3, step #1878] loss: 3.5698554555173247\n",
      "[EPOCH #3, step #1880] loss: 3.569679182048556\n",
      "[EPOCH #3, step #1882] loss: 3.5696953706645105\n",
      "[EPOCH #3, step #1884] loss: 3.5694173127333744\n",
      "[EPOCH #3, step #1886] loss: 3.569364193955236\n",
      "[EPOCH #3, step #1888] loss: 3.5693725960288747\n",
      "[EPOCH #3, step #1890] loss: 3.5692227271295365\n",
      "[EPOCH #3, step #1892] loss: 3.569023067587214\n",
      "[EPOCH #3, step #1894] loss: 3.568595170219844\n",
      "[EPOCH #3, step #1896] loss: 3.5685806312118635\n",
      "[EPOCH #3, step #1898] loss: 3.568497192991477\n",
      "[EPOCH #3, step #1900] loss: 3.568313324470259\n",
      "[EPOCH #3, step #1902] loss: 3.5682439894282814\n",
      "[EPOCH #3, step #1904] loss: 3.5683258863884633\n",
      "[EPOCH #3, step #1906] loss: 3.5684593551497716\n",
      "[EPOCH #3, step #1908] loss: 3.5682509779742775\n",
      "[EPOCH #3, step #1910] loss: 3.5681078987930035\n",
      "[EPOCH #3, step #1912] loss: 3.5680726167735664\n",
      "[EPOCH #3, step #1914] loss: 3.5679431474551206\n",
      "[EPOCH #3, step #1916] loss: 3.5680462934725847\n",
      "[EPOCH #3, step #1918] loss: 3.5678940267846135\n",
      "[EPOCH #3, step #1920] loss: 3.567948096745465\n",
      "[EPOCH #3, step #1922] loss: 3.567941943246501\n",
      "[EPOCH #3, step #1924] loss: 3.5675252313737746\n",
      "[EPOCH #3, step #1926] loss: 3.5671339061016485\n",
      "[EPOCH #3, step #1928] loss: 3.5669229573199885\n",
      "[EPOCH #3, step #1930] loss: 3.566418550225628\n",
      "[EPOCH #3, step #1932] loss: 3.5660979456686936\n",
      "[EPOCH #3, step #1934] loss: 3.5660414275580905\n",
      "[EPOCH #3, step #1936] loss: 3.5660484270392216\n",
      "[EPOCH #3, step #1938] loss: 3.5659499917219692\n",
      "[EPOCH #3, step #1940] loss: 3.56591467891754\n",
      "[EPOCH #3, step #1942] loss: 3.5656982702627293\n",
      "[EPOCH #3, step #1944] loss: 3.565835645204951\n",
      "[EPOCH #3, step #1946] loss: 3.565904144513405\n",
      "[EPOCH #3, step #1948] loss: 3.565785061340567\n",
      "[EPOCH #3, step #1950] loss: 3.5656467533795912\n",
      "[EPOCH #3, step #1952] loss: 3.5654781223625265\n",
      "[EPOCH #3, step #1954] loss: 3.565417390467261\n",
      "[EPOCH #3, step #1956] loss: 3.565289857257186\n",
      "[EPOCH #3, step #1958] loss: 3.56504914771543\n",
      "[EPOCH #3, step #1960] loss: 3.564549854615098\n",
      "[EPOCH #3, step #1962] loss: 3.5645079871433705\n",
      "[EPOCH #3, step #1964] loss: 3.5644524780545224\n",
      "[EPOCH #3, step #1966] loss: 3.5644026198966525\n",
      "[EPOCH #3, step #1968] loss: 3.5641328773866636\n",
      "[EPOCH #3, step #1970] loss: 3.5642121894174514\n",
      "[EPOCH #3, step #1972] loss: 3.5640596798453545\n",
      "[EPOCH #3, step #1974] loss: 3.564097608856008\n",
      "[EPOCH #3, step #1976] loss: 3.563711840634884\n",
      "[EPOCH #3, step #1978] loss: 3.563407836266393\n",
      "[EPOCH #3, step #1980] loss: 3.5633064144371374\n",
      "[EPOCH #3, step #1982] loss: 3.5633381515576033\n",
      "[EPOCH #3, step #1984] loss: 3.5628584137491375\n",
      "[EPOCH #3, step #1986] loss: 3.5628146455704295\n",
      "[EPOCH #3, step #1988] loss: 3.5626455967962114\n",
      "[EPOCH #3, step #1990] loss: 3.562049372958993\n",
      "[EPOCH #3, step #1992] loss: 3.561723600843117\n",
      "[EPOCH #3, step #1994] loss: 3.5611314178409432\n",
      "[EPOCH #3, step #1996] loss: 3.560941219329834\n",
      "[EPOCH #3, step #1998] loss: 3.560635627657846\n",
      "[EPOCH #3, step #2000] loss: 3.560477660692435\n",
      "[EPOCH #3, step #2002] loss: 3.5603831890399493\n",
      "[EPOCH #3, step #2004] loss: 3.5602829928410022\n",
      "[EPOCH #3, step #2006] loss: 3.560364472432462\n",
      "[EPOCH #3, step #2008] loss: 3.560408038960101\n",
      "[EPOCH #3, step #2010] loss: 3.560447409400769\n",
      "[EPOCH #3, step #2012] loss: 3.5603182318195206\n",
      "[EPOCH #3, step #2014] loss: 3.560127527364726\n",
      "[EPOCH #3, step #2016] loss: 3.5598337396159287\n",
      "[EPOCH #3, step #2018] loss: 3.559787964690966\n",
      "[EPOCH #3, step #2020] loss: 3.5594682353726124\n",
      "[EPOCH #3, step #2022] loss: 3.5592579100312305\n",
      "[EPOCH #3, step #2024] loss: 3.5592445455951456\n",
      "[EPOCH #3, step #2026] loss: 3.5593534071103186\n",
      "[EPOCH #3, step #2028] loss: 3.5590777856602114\n",
      "[EPOCH #3, step #2030] loss: 3.5585675255997553\n",
      "[EPOCH #3, step #2032] loss: 3.558346118941075\n",
      "[EPOCH #3, step #2034] loss: 3.5580974572999473\n",
      "[EPOCH #3, step #2036] loss: 3.5580945442164125\n",
      "[EPOCH #3, step #2038] loss: 3.5578422503122926\n",
      "[EPOCH #3, step #2040] loss: 3.557861566076321\n",
      "[EPOCH #3, step #2042] loss: 3.558009008770764\n",
      "[EPOCH #3, step #2044] loss: 3.557891796853548\n",
      "[EPOCH #3, step #2046] loss: 3.558162452537488\n",
      "[EPOCH #3, step #2048] loss: 3.558424983389963\n",
      "[EPOCH #3, step #2050] loss: 3.5583548579548463\n",
      "[EPOCH #3, step #2052] loss: 3.5579898950824838\n",
      "[EPOCH #3, step #2054] loss: 3.5581740424580817\n",
      "[EPOCH #3, step #2056] loss: 3.558148923636526\n",
      "[EPOCH #3, step #2058] loss: 3.55814315914934\n",
      "[EPOCH #3, step #2060] loss: 3.5579331496107756\n",
      "[EPOCH #3, step #2062] loss: 3.557935618337242\n",
      "[EPOCH #3, step #2064] loss: 3.5578392779278696\n",
      "[EPOCH #3, step #2066] loss: 3.5577939256816657\n",
      "[EPOCH #3, step #2068] loss: 3.557635504361683\n",
      "[EPOCH #3, step #2070] loss: 3.5575566123730313\n",
      "[EPOCH #3, step #2072] loss: 3.557566965138113\n",
      "[EPOCH #3, step #2074] loss: 3.5577753289923613\n",
      "[EPOCH #3, step #2076] loss: 3.5576784731277664\n",
      "[EPOCH #3, step #2078] loss: 3.55746205326684\n",
      "[EPOCH #3, step #2080] loss: 3.557295567252669\n",
      "[EPOCH #3, step #2082] loss: 3.5571299727811185\n",
      "[EPOCH #3, step #2084] loss: 3.5572731024927373\n",
      "[EPOCH #3, step #2086] loss: 3.5572425865590085\n",
      "[EPOCH #3, step #2088] loss: 3.557149968688256\n",
      "[EPOCH #3, step #2090] loss: 3.5571416808565743\n",
      "[EPOCH #3, step #2092] loss: 3.5571586291754698\n",
      "[EPOCH #3, step #2094] loss: 3.556718019312492\n",
      "[EPOCH #3, step #2096] loss: 3.556607866264492\n",
      "[EPOCH #3, step #2098] loss: 3.556736049792947\n",
      "[EPOCH #3, step #2100] loss: 3.556456397341184\n",
      "[EPOCH #3, step #2102] loss: 3.556331901282738\n",
      "[EPOCH #3, step #2104] loss: 3.556221184198194\n",
      "[EPOCH #3, step #2106] loss: 3.556131870643641\n",
      "[EPOCH #3, step #2108] loss: 3.5559303334336985\n",
      "[EPOCH #3, step #2110] loss: 3.5557412315126506\n",
      "[EPOCH #3, step #2112] loss: 3.5558560836727\n",
      "[EPOCH #3, step #2114] loss: 3.555761941724917\n",
      "[EPOCH #3, step #2116] loss: 3.5554446585064627\n",
      "[EPOCH #3, step #2118] loss: 3.555179594034516\n",
      "[EPOCH #3, step #2120] loss: 3.555176353859261\n",
      "[EPOCH #3, step #2122] loss: 3.555400589081795\n",
      "[EPOCH #3, step #2124] loss: 3.555304100373212\n",
      "[EPOCH #3, step #2126] loss: 3.555388122306612\n",
      "[EPOCH #3, step #2128] loss: 3.55543472096079\n",
      "[EPOCH #3, step #2130] loss: 3.555407504305936\n",
      "[EPOCH #3, step #2132] loss: 3.555421844089864\n",
      "[EPOCH #3, step #2134] loss: 3.555538618480852\n",
      "[EPOCH #3, step #2136] loss: 3.555417881538559\n",
      "[EPOCH #3, step #2138] loss: 3.5551958954629637\n",
      "[EPOCH #3, step #2140] loss: 3.5549836696614063\n",
      "[EPOCH #3, step #2142] loss: 3.554916742300798\n",
      "[EPOCH #3, step #2144] loss: 3.5546945041709845\n",
      "[EPOCH #3, step #2146] loss: 3.55472302958751\n",
      "[EPOCH #3, step #2148] loss: 3.554716873523966\n",
      "[EPOCH #3, step #2150] loss: 3.5548334311241883\n",
      "[EPOCH #3, step #2152] loss: 3.554713837113759\n",
      "[EPOCH #3, step #2154] loss: 3.554770505953831\n",
      "[EPOCH #3, step #2156] loss: 3.5545854767439926\n",
      "[EPOCH #3, step #2158] loss: 3.5543219030538387\n",
      "[EPOCH #3, step #2160] loss: 3.553913352998083\n",
      "[EPOCH #3, step #2162] loss: 3.5536429370601477\n",
      "[EPOCH #3, step #2164] loss: 3.553370896332809\n",
      "[EPOCH #3, step #2166] loss: 3.5531003200133164\n",
      "[EPOCH #3, step #2168] loss: 3.5529967717390116\n",
      "[EPOCH #3, step #2170] loss: 3.5529964018505\n",
      "[EPOCH #3, step #2172] loss: 3.5527148704291815\n",
      "[EPOCH #3, step #2174] loss: 3.5526205518875997\n",
      "[EPOCH #3, step #2176] loss: 3.5524298878618485\n",
      "[EPOCH #3, step #2178] loss: 3.552326168801709\n",
      "[EPOCH #3, step #2180] loss: 3.5521869988465515\n",
      "[EPOCH #3, step #2182] loss: 3.552046028780271\n",
      "[EPOCH #3, step #2184] loss: 3.552061292945111\n",
      "[EPOCH #3, step #2186] loss: 3.552035318971171\n",
      "[EPOCH #3, step #2188] loss: 3.552028110224452\n",
      "[EPOCH #3, step #2190] loss: 3.5520152298079837\n",
      "[EPOCH #3, step #2192] loss: 3.552039483122993\n",
      "[EPOCH #3, step #2194] loss: 3.552004963933471\n",
      "[EPOCH #3, step #2196] loss: 3.551829426734622\n",
      "[EPOCH #3, step #2198] loss: 3.551642796081432\n",
      "[EPOCH #3, step #2200] loss: 3.55143920717755\n",
      "[EPOCH #3, step #2202] loss: 3.5511052827103486\n",
      "[EPOCH #3, step #2204] loss: 3.5511376551760025\n",
      "[EPOCH #3, step #2206] loss: 3.551007911313104\n",
      "[EPOCH #3, step #2208] loss: 3.5510818373298902\n",
      "[EPOCH #3, step #2210] loss: 3.551053962250308\n",
      "[EPOCH #3, step #2212] loss: 3.551102992371095\n",
      "[EPOCH #3, step #2214] loss: 3.5508697892957564\n",
      "[EPOCH #3, step #2216] loss: 3.5506567938885927\n",
      "[EPOCH #3, step #2218] loss: 3.5505245787004673\n",
      "[EPOCH #3, step #2220] loss: 3.5504153224596404\n",
      "[EPOCH #3, step #2222] loss: 3.5503819299827435\n",
      "[EPOCH #3, step #2224] loss: 3.5502945349189674\n",
      "[EPOCH #3, step #2226] loss: 3.5502871648045895\n",
      "[EPOCH #3, step #2228] loss: 3.5503263287396645\n",
      "[EPOCH #3, step #2230] loss: 3.5503533932725606\n",
      "[EPOCH #3, step #2232] loss: 3.5501254810328127\n",
      "[EPOCH #3, step #2234] loss: 3.549988641248187\n",
      "[EPOCH #3, step #2236] loss: 3.5498782610008637\n",
      "[EPOCH #3, step #2238] loss: 3.5497953084602374\n",
      "[EPOCH #3, step #2240] loss: 3.5496297639057817\n",
      "[EPOCH #3, step #2242] loss: 3.5495018668861404\n",
      "[EPOCH #3, step #2244] loss: 3.5493948233419643\n",
      "[EPOCH #3, step #2246] loss: 3.549580890759925\n",
      "[EPOCH #3, step #2248] loss: 3.54947512549472\n",
      "[EPOCH #3, step #2250] loss: 3.549249466341477\n",
      "[EPOCH #3, step #2252] loss: 3.5491619339742715\n",
      "[EPOCH #3, step #2254] loss: 3.5492047002204505\n",
      "[EPOCH #3, step #2256] loss: 3.5488221317886195\n",
      "[EPOCH #3, step #2258] loss: 3.548810397908454\n",
      "[EPOCH #3, step #2260] loss: 3.5486174696897415\n",
      "[EPOCH #3, step #2262] loss: 3.548472416279751\n",
      "[EPOCH #3, step #2264] loss: 3.5483357810553073\n",
      "[EPOCH #3, step #2266] loss: 3.5482696296362084\n",
      "[EPOCH #3, step #2268] loss: 3.5482820572439087\n",
      "[EPOCH #3, step #2270] loss: 3.5482182834495903\n",
      "[EPOCH #3, step #2272] loss: 3.5480944457895367\n",
      "[EPOCH #3, step #2274] loss: 3.5478286090263955\n",
      "[EPOCH #3, step #2276] loss: 3.547806404220152\n",
      "[EPOCH #3, step #2278] loss: 3.5476994769726997\n",
      "[EPOCH #3, step #2280] loss: 3.547549120536346\n",
      "[EPOCH #3, step #2282] loss: 3.547476121118807\n",
      "[EPOCH #3, step #2284] loss: 3.547320276798774\n",
      "[EPOCH #3, step #2286] loss: 3.5474711463187636\n",
      "[EPOCH #3, step #2288] loss: 3.547477980168327\n",
      "[EPOCH #3, step #2290] loss: 3.547287308665042\n",
      "[EPOCH #3, step #2292] loss: 3.5468359034081187\n",
      "[EPOCH #3, step #2294] loss: 3.546890041563246\n",
      "[EPOCH #3, step #2296] loss: 3.5466753889489913\n",
      "[EPOCH #3, step #2298] loss: 3.546769926681784\n",
      "[EPOCH #3, step #2300] loss: 3.5466540811995433\n",
      "[EPOCH #3, step #2302] loss: 3.5467886079977866\n",
      "[EPOCH #3, step #2304] loss: 3.54678573101565\n",
      "[EPOCH #3, step #2306] loss: 3.546866308314799\n",
      "[EPOCH #3, step #2308] loss: 3.546558504963706\n",
      "[EPOCH #3, step #2310] loss: 3.5465953792652902\n",
      "[EPOCH #3, step #2312] loss: 3.546461537963531\n",
      "[EPOCH #3, step #2314] loss: 3.546538776970322\n",
      "[EPOCH #3, step #2316] loss: 3.5465901752047153\n",
      "[EPOCH #3, step #2318] loss: 3.546434144410351\n",
      "[EPOCH #3, step #2320] loss: 3.546246126159313\n",
      "[EPOCH #3, step #2322] loss: 3.5461095174837873\n",
      "[EPOCH #3, step #2324] loss: 3.545882938959265\n",
      "[EPOCH #3, step #2326] loss: 3.545797326916218\n",
      "[EPOCH #3, step #2328] loss: 3.5457579640166963\n",
      "[EPOCH #3, step #2330] loss: 3.545488831312653\n",
      "[EPOCH #3, step #2332] loss: 3.545438987116317\n",
      "[EPOCH #3, step #2334] loss: 3.545248935768895\n",
      "[EPOCH #3, step #2336] loss: 3.544917305565615\n",
      "[EPOCH #3, step #2338] loss: 3.5447560730730685\n",
      "[EPOCH #3, step #2340] loss: 3.5446985940146987\n",
      "[EPOCH #3, step #2342] loss: 3.5445669574509613\n",
      "[EPOCH #3, step #2344] loss: 3.5444232696663343\n",
      "[EPOCH #3, step #2346] loss: 3.5442528141575975\n",
      "[EPOCH #3, step #2348] loss: 3.5441613587078615\n",
      "[EPOCH #3, step #2350] loss: 3.544003808817829\n",
      "[EPOCH #3, step #2352] loss: 3.5439832720207347\n",
      "[EPOCH #3, step #2354] loss: 3.5438012742692497\n",
      "[EPOCH #3, step #2356] loss: 3.5437114513876278\n",
      "[EPOCH #3, step #2358] loss: 3.543472333296015\n",
      "[EPOCH #3, step #2360] loss: 3.54366676063166\n",
      "[EPOCH #3, step #2362] loss: 3.543515386694425\n",
      "[EPOCH #3, step #2364] loss: 3.5435087695938337\n",
      "[EPOCH #3, step #2366] loss: 3.5433079270708143\n",
      "[EPOCH #3, step #2368] loss: 3.5432402913507\n",
      "[EPOCH #3, step #2370] loss: 3.543253425504024\n",
      "[EPOCH #3, step #2372] loss: 3.543279008829187\n",
      "[EPOCH #3, step #2374] loss: 3.5431009181173225\n",
      "[EPOCH #3, step #2376] loss: 3.5431145692904757\n",
      "[EPOCH #3, step #2378] loss: 3.542889252386458\n",
      "[EPOCH #3, step #2380] loss: 3.542618229728644\n",
      "[EPOCH #3, step #2382] loss: 3.54235204647831\n",
      "[EPOCH #3, step #2384] loss: 3.542308531167372\n",
      "[EPOCH #3, step #2386] loss: 3.542072582804213\n",
      "[EPOCH #3, step #2388] loss: 3.541991192908305\n",
      "[EPOCH #3, step #2390] loss: 3.5420724351452963\n",
      "[EPOCH #3, step #2392] loss: 3.541978879598609\n",
      "[EPOCH #3, step #2394] loss: 3.5418574313281224\n",
      "[EPOCH #3, step #2396] loss: 3.5414792331596887\n",
      "[EPOCH #3, step #2398] loss: 3.541205375877307\n",
      "[EPOCH #3, step #2400] loss: 3.5413348783010843\n",
      "[EPOCH #3, step #2402] loss: 3.541165644954851\n",
      "[EPOCH #3, step #2404] loss: 3.5412353637560487\n",
      "[EPOCH #3, step #2406] loss: 3.540845090440561\n",
      "[EPOCH #3, step #2408] loss: 3.540580619564191\n",
      "[EPOCH #3, step #2410] loss: 3.540303879682081\n",
      "[EPOCH #3, step #2412] loss: 3.5402201956058508\n",
      "[EPOCH #3, step #2414] loss: 3.5399271499049343\n",
      "[EPOCH #3, step #2416] loss: 3.539668026076993\n",
      "[EPOCH #3, step #2418] loss: 3.53950714522918\n",
      "[EPOCH #3, step #2420] loss: 3.5395133553433644\n",
      "[EPOCH #3, step #2422] loss: 3.539684920875779\n",
      "[EPOCH #3, step #2424] loss: 3.5395632913923754\n",
      "[EPOCH #3, step #2426] loss: 3.539454383323553\n",
      "[EPOCH #3, step #2428] loss: 3.539236170119737\n",
      "[EPOCH #3, step #2430] loss: 3.5389482365964815\n",
      "[EPOCH #3, step #2432] loss: 3.5388588295813896\n",
      "[EPOCH #3, step #2434] loss: 3.5386099452110775\n",
      "[EPOCH #3, step #2436] loss: 3.538576931458396\n",
      "[EPOCH #3, step #2438] loss: 3.5385379075710772\n",
      "[EPOCH #3, step #2440] loss: 3.5385189738150555\n",
      "[EPOCH #3, step #2442] loss: 3.538498245591372\n",
      "[EPOCH #3, step #2444] loss: 3.5386203149588806\n",
      "[EPOCH #3, step #2446] loss: 3.5385573561161356\n",
      "[EPOCH #3, step #2448] loss: 3.538365430664461\n",
      "[EPOCH #3, step #2450] loss: 3.538030007477927\n",
      "[EPOCH #3, step #2452] loss: 3.5378751565231092\n",
      "[EPOCH #3, step #2454] loss: 3.5378226482212667\n",
      "[EPOCH #3, step #2456] loss: 3.537792703801653\n",
      "[EPOCH #3, step #2458] loss: 3.537805448658537\n",
      "[EPOCH #3, step #2460] loss: 3.5376084380787303\n",
      "[EPOCH #3, step #2462] loss: 3.5373074940632283\n",
      "[EPOCH #3, step #2464] loss: 3.5371515200539485\n",
      "[EPOCH #3, step #2466] loss: 3.5370359569606773\n",
      "[EPOCH #3, step #2468] loss: 3.5366327307783383\n",
      "[EPOCH #3, step #2470] loss: 3.536482201371295\n",
      "[EPOCH #3, step #2472] loss: 3.536355830569331\n",
      "[EPOCH #3, step #2474] loss: 3.5364583660857845\n",
      "[EPOCH #3, step #2476] loss: 3.536267405129942\n",
      "[EPOCH #3, step #2478] loss: 3.5363038794173978\n",
      "[EPOCH #3, step #2480] loss: 3.535935511852358\n",
      "[EPOCH #3, step #2482] loss: 3.5357234611465143\n",
      "[EPOCH #3, step #2484] loss: 3.5355720205326198\n",
      "[EPOCH #3, step #2486] loss: 3.535446908227593\n",
      "[EPOCH #3, step #2488] loss: 3.5353139834789062\n",
      "[EPOCH #3, step #2490] loss: 3.53511258896361\n",
      "[EPOCH #3, step #2492] loss: 3.534975496774881\n",
      "[EPOCH #3, step #2494] loss: 3.53508229141006\n",
      "[EPOCH #3, step #2496] loss: 3.5351435738083454\n",
      "[EPOCH #3, step #2498] loss: 3.5349475976799716\n",
      "[EPOCH #3, elapsed time: 1520.946[sec]] loss: 3.5348021188735963\n",
      "[EPOCH #4, step #0] loss: 3.256406307220459\n",
      "[EPOCH #4, step #2] loss: 3.3035637537638345\n",
      "[EPOCH #4, step #4] loss: 3.3504104614257812\n",
      "[EPOCH #4, step #6] loss: 3.410922186715262\n",
      "[EPOCH #4, step #8] loss: 3.3848201168908014\n",
      "[EPOCH #4, step #10] loss: 3.3827612183310767\n",
      "[EPOCH #4, step #12] loss: 3.3627049922943115\n",
      "[EPOCH #4, step #14] loss: 3.3737220605214437\n",
      "[EPOCH #4, step #16] loss: 3.3580794194165398\n",
      "[EPOCH #4, step #18] loss: 3.364368300688894\n",
      "[EPOCH #4, step #20] loss: 3.3630961577097573\n",
      "[EPOCH #4, step #22] loss: 3.356481997863106\n",
      "[EPOCH #4, step #24] loss: 3.3490304279327394\n",
      "[EPOCH #4, step #26] loss: 3.367350763744778\n",
      "[EPOCH #4, step #28] loss: 3.3856263900625296\n",
      "[EPOCH #4, step #30] loss: 3.379828845300982\n",
      "[EPOCH #4, step #32] loss: 3.3979073871265757\n",
      "[EPOCH #4, step #34] loss: 3.394430759974888\n",
      "[EPOCH #4, step #36] loss: 3.400979203146857\n",
      "[EPOCH #4, step #38] loss: 3.4021750474587464\n",
      "[EPOCH #4, step #40] loss: 3.3881996085004107\n",
      "[EPOCH #4, step #42] loss: 3.389703817145769\n",
      "[EPOCH #4, step #44] loss: 3.3896410624186197\n",
      "[EPOCH #4, step #46] loss: 3.3924060831678675\n",
      "[EPOCH #4, step #48] loss: 3.3858727387019565\n",
      "[EPOCH #4, step #50] loss: 3.3914921330470666\n",
      "[EPOCH #4, step #52] loss: 3.3928838585907557\n",
      "[EPOCH #4, step #54] loss: 3.3917438116940586\n",
      "[EPOCH #4, step #56] loss: 3.3918123077927973\n",
      "[EPOCH #4, step #58] loss: 3.3908464908599854\n",
      "[EPOCH #4, step #60] loss: 3.3922693338550505\n",
      "[EPOCH #4, step #62] loss: 3.395004461682032\n",
      "[EPOCH #4, step #64] loss: 3.3961411219376783\n",
      "[EPOCH #4, step #66] loss: 3.3941808031566105\n",
      "[EPOCH #4, step #68] loss: 3.400439044703608\n",
      "[EPOCH #4, step #70] loss: 3.3980827029322236\n",
      "[EPOCH #4, step #72] loss: 3.398282096810537\n",
      "[EPOCH #4, step #74] loss: 3.3991828060150144\n",
      "[EPOCH #4, step #76] loss: 3.405815976006644\n",
      "[EPOCH #4, step #78] loss: 3.4008998810490474\n",
      "[EPOCH #4, step #80] loss: 3.411023928795332\n",
      "[EPOCH #4, step #82] loss: 3.413347011589142\n",
      "[EPOCH #4, step #84] loss: 3.4138711845173555\n",
      "[EPOCH #4, step #86] loss: 3.4131739331387925\n",
      "[EPOCH #4, step #88] loss: 3.4127447712287475\n",
      "[EPOCH #4, step #90] loss: 3.4059783259590906\n",
      "[EPOCH #4, step #92] loss: 3.4069256526167675\n",
      "[EPOCH #4, step #94] loss: 3.405472511994211\n",
      "[EPOCH #4, step #96] loss: 3.4035624007588807\n",
      "[EPOCH #4, step #98] loss: 3.3998674503480544\n",
      "[EPOCH #4, step #100] loss: 3.4033209404142775\n",
      "[EPOCH #4, step #102] loss: 3.3972671471753166\n",
      "[EPOCH #4, step #104] loss: 3.3976035049983433\n",
      "[EPOCH #4, step #106] loss: 3.3972522432559003\n",
      "[EPOCH #4, step #108] loss: 3.399346856895937\n",
      "[EPOCH #4, step #110] loss: 3.4034017700332777\n",
      "[EPOCH #4, step #112] loss: 3.4057594421690545\n",
      "[EPOCH #4, step #114] loss: 3.4044707609259564\n",
      "[EPOCH #4, step #116] loss: 3.401696940772554\n",
      "[EPOCH #4, step #118] loss: 3.4030179997452166\n",
      "[EPOCH #4, step #120] loss: 3.4014948281374844\n",
      "[EPOCH #4, step #122] loss: 3.402418886742941\n",
      "[EPOCH #4, step #124] loss: 3.4051091918945313\n",
      "[EPOCH #4, step #126] loss: 3.4041976928710938\n",
      "[EPOCH #4, step #128] loss: 3.408170308253562\n",
      "[EPOCH #4, step #130] loss: 3.400670730430661\n",
      "[EPOCH #4, step #132] loss: 3.401020089486488\n",
      "[EPOCH #4, step #134] loss: 3.40126062852365\n",
      "[EPOCH #4, step #136] loss: 3.398686734429241\n",
      "[EPOCH #4, step #138] loss: 3.401653682585243\n",
      "[EPOCH #4, step #140] loss: 3.399522624117263\n",
      "[EPOCH #4, step #142] loss: 3.4013035664191613\n",
      "[EPOCH #4, step #144] loss: 3.4016989625733474\n",
      "[EPOCH #4, step #146] loss: 3.398568378824766\n",
      "[EPOCH #4, step #148] loss: 3.394332583318621\n",
      "[EPOCH #4, step #150] loss: 3.3911282874101043\n",
      "[EPOCH #4, step #152] loss: 3.3856132279813678\n",
      "[EPOCH #4, step #154] loss: 3.383902871224188\n",
      "[EPOCH #4, step #156] loss: 3.387812014597996\n",
      "[EPOCH #4, step #158] loss: 3.3853670771017015\n",
      "[EPOCH #4, step #160] loss: 3.3823179739602605\n",
      "[EPOCH #4, step #162] loss: 3.383208516185269\n",
      "[EPOCH #4, step #164] loss: 3.3831192334493\n",
      "[EPOCH #4, step #166] loss: 3.381574333784823\n",
      "[EPOCH #4, step #168] loss: 3.38114528543145\n",
      "[EPOCH #4, step #170] loss: 3.380340984690259\n",
      "[EPOCH #4, step #172] loss: 3.3797026052640353\n",
      "[EPOCH #4, step #174] loss: 3.379542655944824\n",
      "[EPOCH #4, step #176] loss: 3.3805325004340565\n",
      "[EPOCH #4, step #178] loss: 3.380639870073542\n",
      "[EPOCH #4, step #180] loss: 3.378923360814047\n",
      "[EPOCH #4, step #182] loss: 3.3813949986233736\n",
      "[EPOCH #4, step #184] loss: 3.3786228605218835\n",
      "[EPOCH #4, step #186] loss: 3.381341030253446\n",
      "[EPOCH #4, step #188] loss: 3.383709085050714\n",
      "[EPOCH #4, step #190] loss: 3.381769727037839\n",
      "[EPOCH #4, step #192] loss: 3.3835449898181182\n",
      "[EPOCH #4, step #194] loss: 3.3824577038104717\n",
      "[EPOCH #4, step #196] loss: 3.3833719473804917\n",
      "[EPOCH #4, step #198] loss: 3.384837666947638\n",
      "[EPOCH #4, step #200] loss: 3.3857978588313014\n",
      "[EPOCH #4, step #202] loss: 3.387293289447653\n",
      "[EPOCH #4, step #204] loss: 3.38885724602676\n",
      "[EPOCH #4, step #206] loss: 3.3867118969055765\n",
      "[EPOCH #4, step #208] loss: 3.3851078138397073\n",
      "[EPOCH #4, step #210] loss: 3.388127847870379\n",
      "[EPOCH #4, step #212] loss: 3.386050286987018\n",
      "[EPOCH #4, step #214] loss: 3.384107824813488\n",
      "[EPOCH #4, step #216] loss: 3.3854444927883587\n",
      "[EPOCH #4, step #218] loss: 3.3862005826000754\n",
      "[EPOCH #4, step #220] loss: 3.3872644696300385\n",
      "[EPOCH #4, step #222] loss: 3.387905328263082\n",
      "[EPOCH #4, step #224] loss: 3.3872073141733807\n",
      "[EPOCH #4, step #226] loss: 3.388731759025137\n",
      "[EPOCH #4, step #228] loss: 3.3887345093306496\n",
      "[EPOCH #4, step #230] loss: 3.3895385007321575\n",
      "[EPOCH #4, step #232] loss: 3.38758746544179\n",
      "[EPOCH #4, step #234] loss: 3.388135843074068\n",
      "[EPOCH #4, step #236] loss: 3.387102691433098\n",
      "[EPOCH #4, step #238] loss: 3.3847189069293036\n",
      "[EPOCH #4, step #240] loss: 3.3867017243413016\n",
      "[EPOCH #4, step #242] loss: 3.3892445103131204\n",
      "[EPOCH #4, step #244] loss: 3.3915523237111618\n",
      "[EPOCH #4, step #246] loss: 3.3917140159529713\n",
      "[EPOCH #4, step #248] loss: 3.3894318490622033\n",
      "[EPOCH #4, step #250] loss: 3.3885024809742355\n",
      "[EPOCH #4, step #252] loss: 3.38631486704227\n",
      "[EPOCH #4, step #254] loss: 3.3866562422584083\n",
      "[EPOCH #4, step #256] loss: 3.386741353380077\n",
      "[EPOCH #4, step #258] loss: 3.386968458021009\n",
      "[EPOCH #4, step #260] loss: 3.3862266695819137\n",
      "[EPOCH #4, step #262] loss: 3.387870104140655\n",
      "[EPOCH #4, step #264] loss: 3.386610858845261\n",
      "[EPOCH #4, step #266] loss: 3.3847779093610213\n",
      "[EPOCH #4, step #268] loss: 3.3870093583174357\n",
      "[EPOCH #4, step #270] loss: 3.3872053456042526\n",
      "[EPOCH #4, step #272] loss: 3.384263405433068\n",
      "[EPOCH #4, step #274] loss: 3.384820748242465\n",
      "[EPOCH #4, step #276] loss: 3.3845435944705233\n",
      "[EPOCH #4, step #278] loss: 3.385744725504229\n",
      "[EPOCH #4, step #280] loss: 3.3848126613372584\n",
      "[EPOCH #4, step #282] loss: 3.384522224062323\n",
      "[EPOCH #4, step #284] loss: 3.383657485560367\n",
      "[EPOCH #4, step #286] loss: 3.3848816584211607\n",
      "[EPOCH #4, step #288] loss: 3.3850456381339105\n",
      "[EPOCH #4, step #290] loss: 3.383519658518001\n",
      "[EPOCH #4, step #292] loss: 3.3855390914877934\n",
      "[EPOCH #4, step #294] loss: 3.385910804392928\n",
      "[EPOCH #4, step #296] loss: 3.3866562586440785\n",
      "[EPOCH #4, step #298] loss: 3.3871715826334365\n",
      "[EPOCH #4, step #300] loss: 3.3863969276909813\n",
      "[EPOCH #4, step #302] loss: 3.3872230517195394\n",
      "[EPOCH #4, step #304] loss: 3.3871843314561687\n",
      "[EPOCH #4, step #306] loss: 3.386327844489281\n",
      "[EPOCH #4, step #308] loss: 3.384888660560534\n",
      "[EPOCH #4, step #310] loss: 3.383701981455567\n",
      "[EPOCH #4, step #312] loss: 3.383978088823751\n",
      "[EPOCH #4, step #314] loss: 3.3868295654417975\n",
      "[EPOCH #4, step #316] loss: 3.387423239295791\n",
      "[EPOCH #4, step #318] loss: 3.3872352610561167\n",
      "[EPOCH #4, step #320] loss: 3.386908749553645\n",
      "[EPOCH #4, step #322] loss: 3.3858155178211793\n",
      "[EPOCH #4, step #324] loss: 3.386903203817514\n",
      "[EPOCH #4, step #326] loss: 3.386286161726039\n",
      "[EPOCH #4, step #328] loss: 3.3868658803516607\n",
      "[EPOCH #4, step #330] loss: 3.3854572456048695\n",
      "[EPOCH #4, step #332] loss: 3.3864612844255237\n",
      "[EPOCH #4, step #334] loss: 3.38601726133432\n",
      "[EPOCH #4, step #336] loss: 3.3853109795544905\n",
      "[EPOCH #4, step #338] loss: 3.386074635131521\n",
      "[EPOCH #4, step #340] loss: 3.3826859941230842\n",
      "[EPOCH #4, step #342] loss: 3.383349436712682\n",
      "[EPOCH #4, step #344] loss: 3.3823215090710184\n",
      "[EPOCH #4, step #346] loss: 3.382310798601046\n",
      "[EPOCH #4, step #348] loss: 3.3826259617135994\n",
      "[EPOCH #4, step #350] loss: 3.3827838082598825\n",
      "[EPOCH #4, step #352] loss: 3.381187645639306\n",
      "[EPOCH #4, step #354] loss: 3.380051468459653\n",
      "[EPOCH #4, step #356] loss: 3.3814811138879683\n",
      "[EPOCH #4, step #358] loss: 3.381524384187789\n",
      "[EPOCH #4, step #360] loss: 3.382391736778196\n",
      "[EPOCH #4, step #362] loss: 3.381893242686248\n",
      "[EPOCH #4, step #364] loss: 3.3810625618451264\n",
      "[EPOCH #4, step #366] loss: 3.3806741205158284\n",
      "[EPOCH #4, step #368] loss: 3.3803895017318935\n",
      "[EPOCH #4, step #370] loss: 3.380757216816\n",
      "[EPOCH #4, step #372] loss: 3.379877055298547\n",
      "[EPOCH #4, step #374] loss: 3.378459306716919\n",
      "[EPOCH #4, step #376] loss: 3.3793716310506157\n",
      "[EPOCH #4, step #378] loss: 3.3804299126828883\n",
      "[EPOCH #4, step #380] loss: 3.380835746529847\n",
      "[EPOCH #4, step #382] loss: 3.380559595695675\n",
      "[EPOCH #4, step #384] loss: 3.3808944212925898\n",
      "[EPOCH #4, step #386] loss: 3.3802810473035474\n",
      "[EPOCH #4, step #388] loss: 3.3804740446085795\n",
      "[EPOCH #4, step #390] loss: 3.3795933064902224\n",
      "[EPOCH #4, step #392] loss: 3.379234661582772\n",
      "[EPOCH #4, step #394] loss: 3.380388716806339\n",
      "[EPOCH #4, step #396] loss: 3.379979762382411\n",
      "[EPOCH #4, step #398] loss: 3.3793481489769497\n",
      "[EPOCH #4, step #400] loss: 3.377977877780981\n",
      "[EPOCH #4, step #402] loss: 3.379162016932485\n",
      "[EPOCH #4, step #404] loss: 3.378929699791802\n",
      "[EPOCH #4, step #406] loss: 3.3776494255815734\n",
      "[EPOCH #4, step #408] loss: 3.3779007735637117\n",
      "[EPOCH #4, step #410] loss: 3.3776330646227164\n",
      "[EPOCH #4, step #412] loss: 3.3789476707541626\n",
      "[EPOCH #4, step #414] loss: 3.377815964135779\n",
      "[EPOCH #4, step #416] loss: 3.378226522633212\n",
      "[EPOCH #4, step #418] loss: 3.3785310150046337\n",
      "[EPOCH #4, step #420] loss: 3.3775315114834528\n",
      "[EPOCH #4, step #422] loss: 3.377210799683916\n",
      "[EPOCH #4, step #424] loss: 3.3778081024394315\n",
      "[EPOCH #4, step #426] loss: 3.3779196018915822\n",
      "[EPOCH #4, step #428] loss: 3.377168693742552\n",
      "[EPOCH #4, step #430] loss: 3.378287836459839\n",
      "[EPOCH #4, step #432] loss: 3.3787159870182943\n",
      "[EPOCH #4, step #434] loss: 3.3782842170233014\n",
      "[EPOCH #4, step #436] loss: 3.3792781949861643\n",
      "[EPOCH #4, step #438] loss: 3.3790920399859172\n",
      "[EPOCH #4, step #440] loss: 3.378684642363568\n",
      "[EPOCH #4, step #442] loss: 3.3797233987338924\n",
      "[EPOCH #4, step #444] loss: 3.3786417789673537\n",
      "[EPOCH #4, step #446] loss: 3.378536589193664\n",
      "[EPOCH #4, step #448] loss: 3.378292479334536\n",
      "[EPOCH #4, step #450] loss: 3.3782936971626367\n",
      "[EPOCH #4, step #452] loss: 3.3794359155574907\n",
      "[EPOCH #4, step #454] loss: 3.3794256053128087\n",
      "[EPOCH #4, step #456] loss: 3.378749265190809\n",
      "[EPOCH #4, step #458] loss: 3.3800425176267272\n",
      "[EPOCH #4, step #460] loss: 3.3803430058692387\n",
      "[EPOCH #4, step #462] loss: 3.380061173799486\n",
      "[EPOCH #4, step #464] loss: 3.3804032028362316\n",
      "[EPOCH #4, step #466] loss: 3.379561104662158\n",
      "[EPOCH #4, step #468] loss: 3.37970923157389\n",
      "[EPOCH #4, step #470] loss: 3.378856628057557\n",
      "[EPOCH #4, step #472] loss: 3.3799213128160472\n",
      "[EPOCH #4, step #474] loss: 3.3796503127248663\n",
      "[EPOCH #4, step #476] loss: 3.3798824836123162\n",
      "[EPOCH #4, step #478] loss: 3.3802283108856583\n",
      "[EPOCH #4, step #480] loss: 3.3815100396249496\n",
      "[EPOCH #4, step #482] loss: 3.382599669213621\n",
      "[EPOCH #4, step #484] loss: 3.383143105949323\n",
      "[EPOCH #4, step #486] loss: 3.3831607766709535\n",
      "[EPOCH #4, step #488] loss: 3.3817682968326874\n",
      "[EPOCH #4, step #490] loss: 3.3826526944846096\n",
      "[EPOCH #4, step #492] loss: 3.3829149682429933\n",
      "[EPOCH #4, step #494] loss: 3.383082548777262\n",
      "[EPOCH #4, step #496] loss: 3.382281299088323\n",
      "[EPOCH #4, step #498] loss: 3.3829853964711956\n",
      "[EPOCH #4, step #500] loss: 3.3822604044230875\n",
      "[EPOCH #4, step #502] loss: 3.3811059201924984\n",
      "[EPOCH #4, step #504] loss: 3.381458401443935\n",
      "[EPOCH #4, step #506] loss: 3.3808214086047292\n",
      "[EPOCH #4, step #508] loss: 3.379895707713129\n",
      "[EPOCH #4, step #510] loss: 3.378204465145701\n",
      "[EPOCH #4, step #512] loss: 3.3790721251950626\n",
      "[EPOCH #4, step #514] loss: 3.378528217204566\n",
      "[EPOCH #4, step #516] loss: 3.3785140970919993\n",
      "[EPOCH #4, step #518] loss: 3.3786501861491414\n",
      "[EPOCH #4, step #520] loss: 3.378859206033073\n",
      "[EPOCH #4, step #522] loss: 3.377614350437434\n",
      "[EPOCH #4, step #524] loss: 3.3760739862351192\n",
      "[EPOCH #4, step #526] loss: 3.376186149622503\n",
      "[EPOCH #4, step #528] loss: 3.3764056947596357\n",
      "[EPOCH #4, step #530] loss: 3.3759825157804904\n",
      "[EPOCH #4, step #532] loss: 3.375064513025767\n",
      "[EPOCH #4, step #534] loss: 3.37469208842126\n",
      "[EPOCH #4, step #536] loss: 3.374493148295795\n",
      "[EPOCH #4, step #538] loss: 3.375324935771539\n",
      "[EPOCH #4, step #540] loss: 3.3743812760231453\n",
      "[EPOCH #4, step #542] loss: 3.373577606173071\n",
      "[EPOCH #4, step #544] loss: 3.3738468410771922\n",
      "[EPOCH #4, step #546] loss: 3.374454363608491\n",
      "[EPOCH #4, step #548] loss: 3.3733677256085617\n",
      "[EPOCH #4, step #550] loss: 3.373603930274285\n",
      "[EPOCH #4, step #552] loss: 3.372567194926588\n",
      "[EPOCH #4, step #554] loss: 3.3717091672055357\n",
      "[EPOCH #4, step #556] loss: 3.3717595460812966\n",
      "[EPOCH #4, step #558] loss: 3.370228943116763\n",
      "[EPOCH #4, step #560] loss: 3.3690422452494846\n",
      "[EPOCH #4, step #562] loss: 3.3695350074429284\n",
      "[EPOCH #4, step #564] loss: 3.3699408645123508\n",
      "[EPOCH #4, step #566] loss: 3.37011333958392\n",
      "[EPOCH #4, step #568] loss: 3.370185317808798\n",
      "[EPOCH #4, step #570] loss: 3.370619229385189\n",
      "[EPOCH #4, step #572] loss: 3.3704374855933596\n",
      "[EPOCH #4, step #574] loss: 3.370184608542401\n",
      "[EPOCH #4, step #576] loss: 3.3703020941240123\n",
      "[EPOCH #4, step #578] loss: 3.370116832136902\n",
      "[EPOCH #4, step #580] loss: 3.3708322257470344\n",
      "[EPOCH #4, step #582] loss: 3.370126288710082\n",
      "[EPOCH #4, step #584] loss: 3.3694352296682504\n",
      "[EPOCH #4, step #586] loss: 3.3684584107472095\n",
      "[EPOCH #4, step #588] loss: 3.3686369157606557\n",
      "[EPOCH #4, step #590] loss: 3.368691168460749\n",
      "[EPOCH #4, step #592] loss: 3.3677153619505704\n",
      "[EPOCH #4, step #594] loss: 3.367039997437421\n",
      "[EPOCH #4, step #596] loss: 3.366663090947086\n",
      "[EPOCH #4, step #598] loss: 3.3665315141661933\n",
      "[EPOCH #4, step #600] loss: 3.3663545023780097\n",
      "[EPOCH #4, step #602] loss: 3.366264470971837\n",
      "[EPOCH #4, step #604] loss: 3.3667511435579662\n",
      "[EPOCH #4, step #606] loss: 3.3666685436663557\n",
      "[EPOCH #4, step #608] loss: 3.3670326187497093\n",
      "[EPOCH #4, step #610] loss: 3.3664176795759686\n",
      "[EPOCH #4, step #612] loss: 3.365858018495519\n",
      "[EPOCH #4, step #614] loss: 3.366157186322096\n",
      "[EPOCH #4, step #616] loss: 3.3658614077483042\n",
      "[EPOCH #4, step #618] loss: 3.365063902249436\n",
      "[EPOCH #4, step #620] loss: 3.364699583698586\n",
      "[EPOCH #4, step #622] loss: 3.3648387555325967\n",
      "[EPOCH #4, step #624] loss: 3.3647156078338623\n",
      "[EPOCH #4, step #626] loss: 3.3650543077520587\n",
      "[EPOCH #4, step #628] loss: 3.3647066557540044\n",
      "[EPOCH #4, step #630] loss: 3.364807535842557\n",
      "[EPOCH #4, step #632] loss: 3.3640816456522047\n",
      "[EPOCH #4, step #634] loss: 3.364808275568204\n",
      "[EPOCH #4, step #636] loss: 3.36461966677775\n",
      "[EPOCH #4, step #638] loss: 3.364120751665978\n",
      "[EPOCH #4, step #640] loss: 3.36456815872847\n",
      "[EPOCH #4, step #642] loss: 3.3643743216898727\n",
      "[EPOCH #4, step #644] loss: 3.3645334428595017\n",
      "[EPOCH #4, step #646] loss: 3.3637912052307835\n",
      "[EPOCH #4, step #648] loss: 3.363274698815838\n",
      "[EPOCH #4, step #650] loss: 3.363027867084275\n",
      "[EPOCH #4, step #652] loss: 3.363111800840766\n",
      "[EPOCH #4, step #654] loss: 3.363168091082391\n",
      "[EPOCH #4, step #656] loss: 3.363370394597859\n",
      "[EPOCH #4, step #658] loss: 3.363534266380692\n",
      "[EPOCH #4, step #660] loss: 3.362539143858086\n",
      "[EPOCH #4, step #662] loss: 3.362315099883044\n",
      "[EPOCH #4, step #664] loss: 3.362181333670939\n",
      "[EPOCH #4, step #666] loss: 3.361410937030455\n",
      "[EPOCH #4, step #668] loss: 3.361121576819541\n",
      "[EPOCH #4, step #670] loss: 3.3603154628713865\n",
      "[EPOCH #4, step #672] loss: 3.3607219470025527\n",
      "[EPOCH #4, step #674] loss: 3.360720704043353\n",
      "[EPOCH #4, step #676] loss: 3.3599661153739806\n",
      "[EPOCH #4, step #678] loss: 3.3604762571725297\n",
      "[EPOCH #4, step #680] loss: 3.360316836361318\n",
      "[EPOCH #4, step #682] loss: 3.359633990995706\n",
      "[EPOCH #4, step #684] loss: 3.359204491385578\n",
      "[EPOCH #4, step #686] loss: 3.358638375086555\n",
      "[EPOCH #4, step #688] loss: 3.3586672739989525\n",
      "[EPOCH #4, step #690] loss: 3.3593609964450777\n",
      "[EPOCH #4, step #692] loss: 3.358374322475637\n",
      "[EPOCH #4, step #694] loss: 3.35730008976065\n",
      "[EPOCH #4, step #696] loss: 3.357591837003207\n",
      "[EPOCH #4, step #698] loss: 3.3582658041188647\n",
      "[EPOCH #4, step #700] loss: 3.3586165214571224\n",
      "[EPOCH #4, step #702] loss: 3.3586773767240694\n",
      "[EPOCH #4, step #704] loss: 3.3591967457575156\n",
      "[EPOCH #4, step #706] loss: 3.3594323991886124\n",
      "[EPOCH #4, step #708] loss: 3.357983797662517\n",
      "[EPOCH #4, step #710] loss: 3.3583259978207187\n",
      "[EPOCH #4, step #712] loss: 3.3584980857656515\n",
      "[EPOCH #4, step #714] loss: 3.358477486430348\n",
      "[EPOCH #4, step #716] loss: 3.358116117315146\n",
      "[EPOCH #4, step #718] loss: 3.358198634440776\n",
      "[EPOCH #4, step #720] loss: 3.357632268318356\n",
      "[EPOCH #4, step #722] loss: 3.358102245779288\n",
      "[EPOCH #4, step #724] loss: 3.3586633070584\n",
      "[EPOCH #4, step #726] loss: 3.358285289027176\n",
      "[EPOCH #4, step #728] loss: 3.3587985647068104\n",
      "[EPOCH #4, step #730] loss: 3.3580635269102417\n",
      "[EPOCH #4, step #732] loss: 3.358141252809137\n",
      "[EPOCH #4, step #734] loss: 3.3574875883504647\n",
      "[EPOCH #4, step #736] loss: 3.3574706903144493\n",
      "[EPOCH #4, step #738] loss: 3.35725637734017\n",
      "[EPOCH #4, step #740] loss: 3.3561261681570858\n",
      "[EPOCH #4, step #742] loss: 3.3557929418289163\n",
      "[EPOCH #4, step #744] loss: 3.355238743596429\n",
      "[EPOCH #4, step #746] loss: 3.355135428698028\n",
      "[EPOCH #4, step #748] loss: 3.3547813198435925\n",
      "[EPOCH #4, step #750] loss: 3.3546460182784243\n",
      "[EPOCH #4, step #752] loss: 3.354308444665248\n",
      "[EPOCH #4, step #754] loss: 3.354168689803572\n",
      "[EPOCH #4, step #756] loss: 3.353467255004016\n",
      "[EPOCH #4, step #758] loss: 3.353588028544651\n",
      "[EPOCH #4, step #760] loss: 3.353901915731944\n",
      "[EPOCH #4, step #762] loss: 3.3536481466705803\n",
      "[EPOCH #4, step #764] loss: 3.353240701264026\n",
      "[EPOCH #4, step #766] loss: 3.3538194837284214\n",
      "[EPOCH #4, step #768] loss: 3.353406794824588\n",
      "[EPOCH #4, step #770] loss: 3.353056496374029\n",
      "[EPOCH #4, step #772] loss: 3.353986899572079\n",
      "[EPOCH #4, step #774] loss: 3.353792785829113\n",
      "[EPOCH #4, step #776] loss: 3.3538515352988028\n",
      "[EPOCH #4, step #778] loss: 3.354271295287949\n",
      "[EPOCH #4, step #780] loss: 3.3547388905904967\n",
      "[EPOCH #4, step #782] loss: 3.3547910304209587\n",
      "[EPOCH #4, step #784] loss: 3.3545967645705885\n",
      "[EPOCH #4, step #786] loss: 3.354684121726883\n",
      "[EPOCH #4, step #788] loss: 3.3548539579292367\n",
      "[EPOCH #4, step #790] loss: 3.3546437731886334\n",
      "[EPOCH #4, step #792] loss: 3.355207780571032\n",
      "[EPOCH #4, step #794] loss: 3.355504888858435\n",
      "[EPOCH #4, step #796] loss: 3.3558100894224387\n",
      "[EPOCH #4, step #798] loss: 3.3562447639818633\n",
      "[EPOCH #4, step #800] loss: 3.3561202283209184\n",
      "[EPOCH #4, step #802] loss: 3.3560552882079318\n",
      "[EPOCH #4, step #804] loss: 3.3560415647044683\n",
      "[EPOCH #4, step #806] loss: 3.3565583149296643\n",
      "[EPOCH #4, step #808] loss: 3.3566205802158313\n",
      "[EPOCH #4, step #810] loss: 3.35623271133103\n",
      "[EPOCH #4, step #812] loss: 3.3557825865634108\n",
      "[EPOCH #4, step #814] loss: 3.356072864649486\n",
      "[EPOCH #4, step #816] loss: 3.355062340872962\n",
      "[EPOCH #4, step #818] loss: 3.354765958110637\n",
      "[EPOCH #4, step #820] loss: 3.354060517739727\n",
      "[EPOCH #4, step #822] loss: 3.3536427759747602\n",
      "[EPOCH #4, step #824] loss: 3.3532220941601376\n",
      "[EPOCH #4, step #826] loss: 3.3530240814227437\n",
      "[EPOCH #4, step #828] loss: 3.3528933910466505\n",
      "[EPOCH #4, step #830] loss: 3.3525087334188743\n",
      "[EPOCH #4, step #832] loss: 3.3528017622797717\n",
      "[EPOCH #4, step #834] loss: 3.3520115189923496\n",
      "[EPOCH #4, step #836] loss: 3.3516974602976153\n",
      "[EPOCH #4, step #838] loss: 3.351875420264607\n",
      "[EPOCH #4, step #840] loss: 3.351530795431874\n",
      "[EPOCH #4, step #842] loss: 3.3512885443256417\n",
      "[EPOCH #4, step #844] loss: 3.351113739803698\n",
      "[EPOCH #4, step #846] loss: 3.3510459927487966\n",
      "[EPOCH #4, step #848] loss: 3.350898209393235\n",
      "[EPOCH #4, step #850] loss: 3.3513845817462817\n",
      "[EPOCH #4, step #852] loss: 3.3510575157536713\n",
      "[EPOCH #4, step #854] loss: 3.3508821813683762\n",
      "[EPOCH #4, step #856] loss: 3.350274152488664\n",
      "[EPOCH #4, step #858] loss: 3.350946629005761\n",
      "[EPOCH #4, step #860] loss: 3.3512495314479565\n",
      "[EPOCH #4, step #862] loss: 3.350934283620098\n",
      "[EPOCH #4, step #864] loss: 3.351135461730075\n",
      "[EPOCH #4, step #866] loss: 3.3506636050333203\n",
      "[EPOCH #4, step #868] loss: 3.350400263475741\n",
      "[EPOCH #4, step #870] loss: 3.3505921558178664\n",
      "[EPOCH #4, step #872] loss: 3.3500124785498655\n",
      "[EPOCH #4, step #874] loss: 3.3498753119877405\n",
      "[EPOCH #4, step #876] loss: 3.349551766057379\n",
      "[EPOCH #4, step #878] loss: 3.349489148837579\n",
      "[EPOCH #4, step #880] loss: 3.348982023191506\n",
      "[EPOCH #4, step #882] loss: 3.348979193383948\n",
      "[EPOCH #4, step #884] loss: 3.34886288831463\n",
      "[EPOCH #4, step #886] loss: 3.349676568451702\n",
      "[EPOCH #4, step #888] loss: 3.3498123330394116\n",
      "[EPOCH #4, step #890] loss: 3.349985237207209\n",
      "[EPOCH #4, step #892] loss: 3.3492713906329796\n",
      "[EPOCH #4, step #894] loss: 3.3491472124387434\n",
      "[EPOCH #4, step #896] loss: 3.349263600814037\n",
      "[EPOCH #4, step #898] loss: 3.3489418748488546\n",
      "[EPOCH #4, step #900] loss: 3.348775640576582\n",
      "[EPOCH #4, step #902] loss: 3.349684102458679\n",
      "[EPOCH #4, step #904] loss: 3.3497231093559474\n",
      "[EPOCH #4, step #906] loss: 3.3498837690237733\n",
      "[EPOCH #4, step #908] loss: 3.3500129607382125\n",
      "[EPOCH #4, step #910] loss: 3.349637529852623\n",
      "[EPOCH #4, step #912] loss: 3.3496250683219384\n",
      "[EPOCH #4, step #914] loss: 3.349577692167355\n",
      "[EPOCH #4, step #916] loss: 3.350291789033031\n",
      "[EPOCH #4, step #918] loss: 3.3499752240289933\n",
      "[EPOCH #4, step #920] loss: 3.3497907165336818\n",
      "[EPOCH #4, step #922] loss: 3.3505830800933674\n",
      "[EPOCH #4, step #924] loss: 3.350520447653693\n",
      "[EPOCH #4, step #926] loss: 3.351480831991893\n",
      "[EPOCH #4, step #928] loss: 3.3507452693770854\n",
      "[EPOCH #4, step #930] loss: 3.3506004899964297\n",
      "[EPOCH #4, step #932] loss: 3.3509878596053375\n",
      "[EPOCH #4, step #934] loss: 3.3506708981519076\n",
      "[EPOCH #4, step #936] loss: 3.3505668059993323\n",
      "[EPOCH #4, step #938] loss: 3.3507846541805897\n",
      "[EPOCH #4, step #940] loss: 3.351190797580796\n",
      "[EPOCH #4, step #942] loss: 3.3513125753857804\n",
      "[EPOCH #4, step #944] loss: 3.351689288729713\n",
      "[EPOCH #4, step #946] loss: 3.351856964065004\n",
      "[EPOCH #4, step #948] loss: 3.3520487480344463\n",
      "[EPOCH #4, step #950] loss: 3.3519820334658137\n",
      "[EPOCH #4, step #952] loss: 3.3515637951657755\n",
      "[EPOCH #4, step #954] loss: 3.3515570702977207\n",
      "[EPOCH #4, step #956] loss: 3.351729733567751\n",
      "[EPOCH #4, step #958] loss: 3.3523222246557878\n",
      "[EPOCH #4, step #960] loss: 3.3523048190991167\n",
      "[EPOCH #4, step #962] loss: 3.3523064365268125\n",
      "[EPOCH #4, step #964] loss: 3.3526928162945366\n",
      "[EPOCH #4, step #966] loss: 3.3528863967019746\n",
      "[EPOCH #4, step #968] loss: 3.352815308930089\n",
      "[EPOCH #4, step #970] loss: 3.352490298411628\n",
      "[EPOCH #4, step #972] loss: 3.3526618213594754\n",
      "[EPOCH #4, step #974] loss: 3.3529917252369414\n",
      "[EPOCH #4, step #976] loss: 3.3521600862852505\n",
      "[EPOCH #4, step #978] loss: 3.352428773085114\n",
      "[EPOCH #4, step #980] loss: 3.3519167817453117\n",
      "[EPOCH #4, step #982] loss: 3.351546555060215\n",
      "[EPOCH #4, step #984] loss: 3.3510627439179395\n",
      "[EPOCH #4, step #986] loss: 3.3512194207374084\n",
      "[EPOCH #4, step #988] loss: 3.350930163785589\n",
      "[EPOCH #4, step #990] loss: 3.3513529928613504\n",
      "[EPOCH #4, step #992] loss: 3.3512582351553957\n",
      "[EPOCH #4, step #994] loss: 3.351301433812434\n",
      "[EPOCH #4, step #996] loss: 3.3517996102661165\n",
      "[EPOCH #4, step #998] loss: 3.351907116992099\n",
      "[EPOCH #4, step #1000] loss: 3.3516236811608344\n",
      "[EPOCH #4, step #1002] loss: 3.351847813350491\n",
      "[EPOCH #4, step #1004] loss: 3.351217798451286\n",
      "[EPOCH #4, step #1006] loss: 3.351010552465975\n",
      "[EPOCH #4, step #1008] loss: 3.351095268109627\n",
      "[EPOCH #4, step #1010] loss: 3.3511903283621978\n",
      "[EPOCH #4, step #1012] loss: 3.3507372975231746\n",
      "[EPOCH #4, step #1014] loss: 3.3509273900187075\n",
      "[EPOCH #4, step #1016] loss: 3.3511698262412524\n",
      "[EPOCH #4, step #1018] loss: 3.3510251882850715\n",
      "[EPOCH #4, step #1020] loss: 3.3510346996445612\n",
      "[EPOCH #4, step #1022] loss: 3.3507691478449577\n",
      "[EPOCH #4, step #1024] loss: 3.3504870344952837\n",
      "[EPOCH #4, step #1026] loss: 3.350448340961044\n",
      "[EPOCH #4, step #1028] loss: 3.350535670105292\n",
      "[EPOCH #4, step #1030] loss: 3.3508464906194857\n",
      "[EPOCH #4, step #1032] loss: 3.3508874873801098\n",
      "[EPOCH #4, step #1034] loss: 3.3505982539504044\n",
      "[EPOCH #4, step #1036] loss: 3.349765578484236\n",
      "[EPOCH #4, step #1038] loss: 3.3502223778505296\n",
      "[EPOCH #4, step #1040] loss: 3.3500104502458967\n",
      "[EPOCH #4, step #1042] loss: 3.349912890080409\n",
      "[EPOCH #4, step #1044] loss: 3.350439353422685\n",
      "[EPOCH #4, step #1046] loss: 3.350925473337984\n",
      "[EPOCH #4, step #1048] loss: 3.3507297186765133\n",
      "[EPOCH #4, step #1050] loss: 3.3506185427719246\n",
      "[EPOCH #4, step #1052] loss: 3.3508958762187904\n",
      "[EPOCH #4, step #1054] loss: 3.3506585507596274\n",
      "[EPOCH #4, step #1056] loss: 3.3508006707609206\n",
      "[EPOCH #4, step #1058] loss: 3.3502849762568054\n",
      "[EPOCH #4, step #1060] loss: 3.3505558183348256\n",
      "[EPOCH #4, step #1062] loss: 3.3503173371025223\n",
      "[EPOCH #4, step #1064] loss: 3.3500963864751823\n",
      "[EPOCH #4, step #1066] loss: 3.349751510459235\n",
      "[EPOCH #4, step #1068] loss: 3.349705426017183\n",
      "[EPOCH #4, step #1070] loss: 3.3492101449815053\n",
      "[EPOCH #4, step #1072] loss: 3.3493123363359776\n",
      "[EPOCH #4, step #1074] loss: 3.349043316064879\n",
      "[EPOCH #4, step #1076] loss: 3.3493646922328457\n",
      "[EPOCH #4, step #1078] loss: 3.3490634634055065\n",
      "[EPOCH #4, step #1080] loss: 3.3489696516359877\n",
      "[EPOCH #4, step #1082] loss: 3.3494591270457343\n",
      "[EPOCH #4, step #1084] loss: 3.349649589292465\n",
      "[EPOCH #4, step #1086] loss: 3.349209076127769\n",
      "[EPOCH #4, step #1088] loss: 3.349302798044364\n",
      "[EPOCH #4, step #1090] loss: 3.348708188173205\n",
      "[EPOCH #4, step #1092] loss: 3.3484783528163033\n",
      "[EPOCH #4, step #1094] loss: 3.3485147450068227\n",
      "[EPOCH #4, step #1096] loss: 3.3481459506772926\n",
      "[EPOCH #4, step #1098] loss: 3.348493393385161\n",
      "[EPOCH #4, step #1100] loss: 3.3483571330598005\n",
      "[EPOCH #4, step #1102] loss: 3.348285191943185\n",
      "[EPOCH #4, step #1104] loss: 3.3484982009387125\n",
      "[EPOCH #4, step #1106] loss: 3.348302642181314\n",
      "[EPOCH #4, step #1108] loss: 3.348184197738001\n",
      "[EPOCH #4, step #1110] loss: 3.3486408603609843\n",
      "[EPOCH #4, step #1112] loss: 3.3481180785694105\n",
      "[EPOCH #4, step #1114] loss: 3.3482002978902226\n",
      "[EPOCH #4, step #1116] loss: 3.3484002576945824\n",
      "[EPOCH #4, step #1118] loss: 3.3484965041879033\n",
      "[EPOCH #4, step #1120] loss: 3.3485737363745547\n",
      "[EPOCH #4, step #1122] loss: 3.3488019056226777\n",
      "[EPOCH #4, step #1124] loss: 3.3490214400821263\n",
      "[EPOCH #4, step #1126] loss: 3.3489659171032504\n",
      "[EPOCH #4, step #1128] loss: 3.349302119127515\n",
      "[EPOCH #4, step #1130] loss: 3.349312658546036\n",
      "[EPOCH #4, step #1132] loss: 3.3490950425746475\n",
      "[EPOCH #4, step #1134] loss: 3.348966859195726\n",
      "[EPOCH #4, step #1136] loss: 3.3489579204519067\n",
      "[EPOCH #4, step #1138] loss: 3.348786414349885\n",
      "[EPOCH #4, step #1140] loss: 3.3486482292596547\n",
      "[EPOCH #4, step #1142] loss: 3.348505188056699\n",
      "[EPOCH #4, step #1144] loss: 3.3487159395842574\n",
      "[EPOCH #4, step #1146] loss: 3.3484942370533632\n",
      "[EPOCH #4, step #1148] loss: 3.348621887783054\n",
      "[EPOCH #4, step #1150] loss: 3.34858742576387\n",
      "[EPOCH #4, step #1152] loss: 3.348651331399486\n",
      "[EPOCH #4, step #1154] loss: 3.3484354830407477\n",
      "[EPOCH #4, step #1156] loss: 3.348600052715687\n",
      "[EPOCH #4, step #1158] loss: 3.3483969348581626\n",
      "[EPOCH #4, step #1160] loss: 3.348317125354934\n",
      "[EPOCH #4, step #1162] loss: 3.348233605087162\n",
      "[EPOCH #4, step #1164] loss: 3.3486211469756686\n",
      "[EPOCH #4, step #1166] loss: 3.3484551763575405\n",
      "[EPOCH #4, step #1168] loss: 3.348127166464147\n",
      "[EPOCH #4, step #1170] loss: 3.347798713754121\n",
      "[EPOCH #4, step #1172] loss: 3.3473511986110522\n",
      "[EPOCH #4, step #1174] loss: 3.347934228207203\n",
      "[EPOCH #4, step #1176] loss: 3.3474093156035107\n",
      "[EPOCH #4, step #1178] loss: 3.3473866541978157\n",
      "[EPOCH #4, step #1180] loss: 3.3472552035038596\n",
      "[EPOCH #4, step #1182] loss: 3.347606878812698\n",
      "[EPOCH #4, step #1184] loss: 3.347549055598456\n",
      "[EPOCH #4, step #1186] loss: 3.3472036931729656\n",
      "[EPOCH #4, step #1188] loss: 3.3468034730627316\n",
      "[EPOCH #4, step #1190] loss: 3.3469707529450745\n",
      "[EPOCH #4, step #1192] loss: 3.3470658328687057\n",
      "[EPOCH #4, step #1194] loss: 3.347145902561842\n",
      "[EPOCH #4, step #1196] loss: 3.3474269676128823\n",
      "[EPOCH #4, step #1198] loss: 3.347409458136539\n",
      "[EPOCH #4, step #1200] loss: 3.3476874212936796\n",
      "[EPOCH #4, step #1202] loss: 3.3476827697563647\n",
      "[EPOCH #4, step #1204] loss: 3.347857048897328\n",
      "[EPOCH #4, step #1206] loss: 3.347990926870553\n",
      "[EPOCH #4, step #1208] loss: 3.3481052913776206\n",
      "[EPOCH #4, step #1210] loss: 3.348041975823047\n",
      "[EPOCH #4, step #1212] loss: 3.3480285147645703\n",
      "[EPOCH #4, step #1214] loss: 3.3478765575974077\n",
      "[EPOCH #4, step #1216] loss: 3.3480791526440234\n",
      "[EPOCH #4, step #1218] loss: 3.3476263891975835\n",
      "[EPOCH #4, step #1220] loss: 3.3476727735205425\n",
      "[EPOCH #4, step #1222] loss: 3.3473452876458283\n",
      "[EPOCH #4, step #1224] loss: 3.3478498231148235\n",
      "[EPOCH #4, step #1226] loss: 3.347837523318153\n",
      "[EPOCH #4, step #1228] loss: 3.347946063981394\n",
      "[EPOCH #4, step #1230] loss: 3.3476868227765775\n",
      "[EPOCH #4, step #1232] loss: 3.3477477803040787\n",
      "[EPOCH #4, step #1234] loss: 3.347833832265877\n",
      "[EPOCH #4, step #1236] loss: 3.347744602875644\n",
      "[EPOCH #4, step #1238] loss: 3.3474029567185863\n",
      "[EPOCH #4, step #1240] loss: 3.3473234557029605\n",
      "[EPOCH #4, step #1242] loss: 3.347507763944704\n",
      "[EPOCH #4, step #1244] loss: 3.347633955660594\n",
      "[EPOCH #4, step #1246] loss: 3.347081481884648\n",
      "[EPOCH #4, step #1248] loss: 3.3470682748515097\n",
      "[EPOCH #4, step #1250] loss: 3.347420222467656\n",
      "[EPOCH #4, step #1252] loss: 3.3470703332022675\n",
      "[EPOCH #4, step #1254] loss: 3.3467171325151663\n",
      "[EPOCH #4, step #1256] loss: 3.3462846330355913\n",
      "[EPOCH #4, step #1258] loss: 3.3467220138992175\n",
      "[EPOCH #4, step #1260] loss: 3.346597395465073\n",
      "[EPOCH #4, step #1262] loss: 3.346433272365531\n",
      "[EPOCH #4, step #1264] loss: 3.346147535912133\n",
      "[EPOCH #4, step #1266] loss: 3.3466548532035847\n",
      "[EPOCH #4, step #1268] loss: 3.3463762287458536\n",
      "[EPOCH #4, step #1270] loss: 3.3462419663706133\n",
      "[EPOCH #4, step #1272] loss: 3.346647907221121\n",
      "[EPOCH #4, step #1274] loss: 3.346190024918201\n",
      "[EPOCH #4, step #1276] loss: 3.346172367676964\n",
      "[EPOCH #4, step #1278] loss: 3.3460377420271814\n",
      "[EPOCH #4, step #1280] loss: 3.34613226857807\n",
      "[EPOCH #4, step #1282] loss: 3.3461776827799556\n",
      "[EPOCH #4, step #1284] loss: 3.3461602776894774\n",
      "[EPOCH #4, step #1286] loss: 3.3462386892669964\n",
      "[EPOCH #4, step #1288] loss: 3.3457749000901487\n",
      "[EPOCH #4, step #1290] loss: 3.3454307974262076\n",
      "[EPOCH #4, step #1292] loss: 3.3452908931918044\n",
      "[EPOCH #4, step #1294] loss: 3.345156212663098\n",
      "[EPOCH #4, step #1296] loss: 3.3447596646311104\n",
      "[EPOCH #4, step #1298] loss: 3.3441934378170983\n",
      "[EPOCH #4, step #1300] loss: 3.3438864069476115\n",
      "[EPOCH #4, step #1302] loss: 3.3438973263969625\n",
      "[EPOCH #4, step #1304] loss: 3.343987314728485\n",
      "[EPOCH #4, step #1306] loss: 3.3437916847614266\n",
      "[EPOCH #4, step #1308] loss: 3.343627453396756\n",
      "[EPOCH #4, step #1310] loss: 3.343793469835655\n",
      "[EPOCH #4, step #1312] loss: 3.343730480908803\n",
      "[EPOCH #4, step #1314] loss: 3.344606049251194\n",
      "[EPOCH #4, step #1316] loss: 3.344247400534361\n",
      "[EPOCH #4, step #1318] loss: 3.34444663342063\n",
      "[EPOCH #4, step #1320] loss: 3.3446739142271356\n",
      "[EPOCH #4, step #1322] loss: 3.344610197113395\n",
      "[EPOCH #4, step #1324] loss: 3.344880056921041\n",
      "[EPOCH #4, step #1326] loss: 3.344621153639597\n",
      "[EPOCH #4, step #1328] loss: 3.3444161793627716\n",
      "[EPOCH #4, step #1330] loss: 3.34463711039273\n",
      "[EPOCH #4, step #1332] loss: 3.3443502167160135\n",
      "[EPOCH #4, step #1334] loss: 3.3445989228366466\n",
      "[EPOCH #4, step #1336] loss: 3.3446043436439874\n",
      "[EPOCH #4, step #1338] loss: 3.3443892399173247\n",
      "[EPOCH #4, step #1340] loss: 3.3440783612324534\n",
      "[EPOCH #4, step #1342] loss: 3.3439120555758386\n",
      "[EPOCH #4, step #1344] loss: 3.3438679723491456\n",
      "[EPOCH #4, step #1346] loss: 3.343484189126256\n",
      "[EPOCH #4, step #1348] loss: 3.3435414731723454\n",
      "[EPOCH #4, step #1350] loss: 3.343842145339548\n",
      "[EPOCH #4, step #1352] loss: 3.3443241595164634\n",
      "[EPOCH #4, step #1354] loss: 3.344283526410036\n",
      "[EPOCH #4, step #1356] loss: 3.3440937718312003\n",
      "[EPOCH #4, step #1358] loss: 3.3437419120137353\n",
      "[EPOCH #4, step #1360] loss: 3.3438048791920414\n",
      "[EPOCH #4, step #1362] loss: 3.3438857145722265\n",
      "[EPOCH #4, step #1364] loss: 3.344055268528697\n",
      "[EPOCH #4, step #1366] loss: 3.3439552386311084\n",
      "[EPOCH #4, step #1368] loss: 3.3440381733495186\n",
      "[EPOCH #4, step #1370] loss: 3.3439889802800575\n",
      "[EPOCH #4, step #1372] loss: 3.3435516701244734\n",
      "[EPOCH #4, step #1374] loss: 3.343630309018222\n",
      "[EPOCH #4, step #1376] loss: 3.3436265407304617\n",
      "[EPOCH #4, step #1378] loss: 3.3436210390620684\n",
      "[EPOCH #4, step #1380] loss: 3.3438357383250152\n",
      "[EPOCH #4, step #1382] loss: 3.3435982899310703\n",
      "[EPOCH #4, step #1384] loss: 3.343978558206386\n",
      "[EPOCH #4, step #1386] loss: 3.3438222147014045\n",
      "[EPOCH #4, step #1388] loss: 3.34349022210288\n",
      "[EPOCH #4, step #1390] loss: 3.34328246082358\n",
      "[EPOCH #4, step #1392] loss: 3.3429181618563835\n",
      "[EPOCH #4, step #1394] loss: 3.343058843339216\n",
      "[EPOCH #4, step #1396] loss: 3.343016239089802\n",
      "[EPOCH #4, step #1398] loss: 3.343135113031034\n",
      "[EPOCH #4, step #1400] loss: 3.343108735196851\n",
      "[EPOCH #4, step #1402] loss: 3.3430430975796406\n",
      "[EPOCH #4, step #1404] loss: 3.3427551483344353\n",
      "[EPOCH #4, step #1406] loss: 3.342353242800942\n",
      "[EPOCH #4, step #1408] loss: 3.342222796677697\n",
      "[EPOCH #4, step #1410] loss: 3.3422803794298503\n",
      "[EPOCH #4, step #1412] loss: 3.342158865776791\n",
      "[EPOCH #4, step #1414] loss: 3.342566771557811\n",
      "[EPOCH #4, step #1416] loss: 3.3422177620310975\n",
      "[EPOCH #4, step #1418] loss: 3.342069102812183\n",
      "[EPOCH #4, step #1420] loss: 3.342398539636439\n",
      "[EPOCH #4, step #1422] loss: 3.3422823098035908\n",
      "[EPOCH #4, step #1424] loss: 3.341662814157051\n",
      "[EPOCH #4, step #1426] loss: 3.3416037699853782\n",
      "[EPOCH #4, step #1428] loss: 3.341400223565819\n",
      "[EPOCH #4, step #1430] loss: 3.34128366359708\n",
      "[EPOCH #4, step #1432] loss: 3.3412760709934273\n",
      "[EPOCH #4, step #1434] loss: 3.341374306396325\n",
      "[EPOCH #4, step #1436] loss: 3.3412200297924404\n",
      "[EPOCH #4, step #1438] loss: 3.3410858597665962\n",
      "[EPOCH #4, step #1440] loss: 3.3412612250577567\n",
      "[EPOCH #4, step #1442] loss: 3.340805076181434\n",
      "[EPOCH #4, step #1444] loss: 3.340760158585017\n",
      "[EPOCH #4, step #1446] loss: 3.340848873628776\n",
      "[EPOCH #4, step #1448] loss: 3.340693919884081\n",
      "[EPOCH #4, step #1450] loss: 3.3405888667195356\n",
      "[EPOCH #4, step #1452] loss: 3.340498306959642\n",
      "[EPOCH #4, step #1454] loss: 3.3403220320894955\n",
      "[EPOCH #4, step #1456] loss: 3.339711972434961\n",
      "[EPOCH #4, step #1458] loss: 3.339441422651368\n",
      "[EPOCH #4, step #1460] loss: 3.339302705951458\n",
      "[EPOCH #4, step #1462] loss: 3.3393937128501157\n",
      "[EPOCH #4, step #1464] loss: 3.3395729969792805\n",
      "[EPOCH #4, step #1466] loss: 3.339466853457076\n",
      "[EPOCH #4, step #1468] loss: 3.3396817227461617\n",
      "[EPOCH #4, step #1470] loss: 3.339722883125943\n",
      "[EPOCH #4, step #1472] loss: 3.339609088981872\n",
      "[EPOCH #4, step #1474] loss: 3.339340136253228\n",
      "[EPOCH #4, step #1476] loss: 3.339303586478159\n",
      "[EPOCH #4, step #1478] loss: 3.339274858122665\n",
      "[EPOCH #4, step #1480] loss: 3.3391964152244036\n",
      "[EPOCH #4, step #1482] loss: 3.339233945851702\n",
      "[EPOCH #4, step #1484] loss: 3.339044446977301\n",
      "[EPOCH #4, step #1486] loss: 3.3388671902257\n",
      "[EPOCH #4, step #1488] loss: 3.3385569046935113\n",
      "[EPOCH #4, step #1490] loss: 3.338884734371858\n",
      "[EPOCH #4, step #1492] loss: 3.338913153899411\n",
      "[EPOCH #4, step #1494] loss: 3.3388812776393317\n",
      "[EPOCH #4, step #1496] loss: 3.3386487011600514\n",
      "[EPOCH #4, step #1498] loss: 3.338824481945025\n",
      "[EPOCH #4, step #1500] loss: 3.338765424223918\n",
      "[EPOCH #4, step #1502] loss: 3.3384533943688957\n",
      "[EPOCH #4, step #1504] loss: 3.3384248627380675\n",
      "[EPOCH #4, step #1506] loss: 3.3384657502569897\n",
      "[EPOCH #4, step #1508] loss: 3.338542195327081\n",
      "[EPOCH #4, step #1510] loss: 3.338541381805642\n",
      "[EPOCH #4, step #1512] loss: 3.338403523874377\n",
      "[EPOCH #4, step #1514] loss: 3.3383510761135087\n",
      "[EPOCH #4, step #1516] loss: 3.338172531788021\n",
      "[EPOCH #4, step #1518] loss: 3.338025238264384\n",
      "[EPOCH #4, step #1520] loss: 3.3380419171851847\n",
      "[EPOCH #4, step #1522] loss: 3.337940980162342\n",
      "[EPOCH #4, step #1524] loss: 3.337885185304235\n",
      "[EPOCH #4, step #1526] loss: 3.3375875358106892\n",
      "[EPOCH #4, step #1528] loss: 3.33698645037245\n",
      "[EPOCH #4, step #1530] loss: 3.3370093072184854\n",
      "[EPOCH #4, step #1532] loss: 3.3372033093384643\n",
      "[EPOCH #4, step #1534] loss: 3.3375106631350437\n",
      "[EPOCH #4, step #1536] loss: 3.3377655673973265\n",
      "[EPOCH #4, step #1538] loss: 3.3378260072134314\n",
      "[EPOCH #4, step #1540] loss: 3.3378940436222737\n",
      "[EPOCH #4, step #1542] loss: 3.3377192485510183\n",
      "[EPOCH #4, step #1544] loss: 3.3375775369625647\n",
      "[EPOCH #4, step #1546] loss: 3.3373439262663847\n",
      "[EPOCH #4, step #1548] loss: 3.336995293818573\n",
      "[EPOCH #4, step #1550] loss: 3.336895818175384\n",
      "[EPOCH #4, step #1552] loss: 3.336806183850005\n",
      "[EPOCH #4, step #1554] loss: 3.3366091335701404\n",
      "[EPOCH #4, step #1556] loss: 3.3363721249726774\n",
      "[EPOCH #4, step #1558] loss: 3.336360801864389\n",
      "[EPOCH #4, step #1560] loss: 3.33618920739838\n",
      "[EPOCH #4, step #1562] loss: 3.335968396332656\n",
      "[EPOCH #4, step #1564] loss: 3.3358178478460343\n",
      "[EPOCH #4, step #1566] loss: 3.3359743401588875\n",
      "[EPOCH #4, step #1568] loss: 3.335541190274435\n",
      "[EPOCH #4, step #1570] loss: 3.3354666923581227\n",
      "[EPOCH #4, step #1572] loss: 3.3357347332590033\n",
      "[EPOCH #4, step #1574] loss: 3.3358187428731765\n",
      "[EPOCH #4, step #1576] loss: 3.3355920579362386\n",
      "[EPOCH #4, step #1578] loss: 3.335366667940165\n",
      "[EPOCH #4, step #1580] loss: 3.334991713553422\n",
      "[EPOCH #4, step #1582] loss: 3.3349775948708222\n",
      "[EPOCH #4, step #1584] loss: 3.335135683125878\n",
      "[EPOCH #4, step #1586] loss: 3.334922809757072\n",
      "[EPOCH #4, step #1588] loss: 3.3347376618766424\n",
      "[EPOCH #4, step #1590] loss: 3.3341529265954613\n",
      "[EPOCH #4, step #1592] loss: 3.334381957512117\n",
      "[EPOCH #4, step #1594] loss: 3.334468399544121\n",
      "[EPOCH #4, step #1596] loss: 3.334016806346294\n",
      "[EPOCH #4, step #1598] loss: 3.3340781638590973\n",
      "[EPOCH #4, step #1600] loss: 3.334072362177823\n",
      "[EPOCH #4, step #1602] loss: 3.3344646428275393\n",
      "[EPOCH #4, step #1604] loss: 3.334332682559052\n",
      "[EPOCH #4, step #1606] loss: 3.33437538517879\n",
      "[EPOCH #4, step #1608] loss: 3.33479306903813\n",
      "[EPOCH #4, step #1610] loss: 3.3346836922111014\n",
      "[EPOCH #4, step #1612] loss: 3.334316641960688\n",
      "[EPOCH #4, step #1614] loss: 3.333914718539353\n",
      "[EPOCH #4, step #1616] loss: 3.3338023408666833\n",
      "[EPOCH #4, step #1618] loss: 3.3336966053949157\n",
      "[EPOCH #4, step #1620] loss: 3.33380102596483\n",
      "[EPOCH #4, step #1622] loss: 3.3334573236278597\n",
      "[EPOCH #4, step #1624] loss: 3.3331960575397197\n",
      "[EPOCH #4, step #1626] loss: 3.3330408990493052\n",
      "[EPOCH #4, step #1628] loss: 3.3330399685655365\n",
      "[EPOCH #4, step #1630] loss: 3.333160142384008\n",
      "[EPOCH #4, step #1632] loss: 3.333082163034592\n",
      "[EPOCH #4, step #1634] loss: 3.3331633372408898\n",
      "[EPOCH #4, step #1636] loss: 3.3330381384111427\n",
      "[EPOCH #4, step #1638] loss: 3.33304898138087\n",
      "[EPOCH #4, step #1640] loss: 3.333173588962543\n",
      "[EPOCH #4, step #1642] loss: 3.3332176900679067\n",
      "[EPOCH #4, step #1644] loss: 3.3331092566342337\n",
      "[EPOCH #4, step #1646] loss: 3.333026531760303\n",
      "[EPOCH #4, step #1648] loss: 3.3332771455395793\n",
      "[EPOCH #4, step #1650] loss: 3.333196762906357\n",
      "[EPOCH #4, step #1652] loss: 3.3331346966177495\n",
      "[EPOCH #4, step #1654] loss: 3.333213878902424\n",
      "[EPOCH #4, step #1656] loss: 3.3329710161822637\n",
      "[EPOCH #4, step #1658] loss: 3.332585076958103\n",
      "[EPOCH #4, step #1660] loss: 3.3324971580849865\n",
      "[EPOCH #4, step #1662] loss: 3.3329656286119196\n",
      "[EPOCH #4, step #1664] loss: 3.3328634681644385\n",
      "[EPOCH #4, step #1666] loss: 3.3326314685583545\n",
      "[EPOCH #4, step #1668] loss: 3.3330809981470124\n",
      "[EPOCH #4, step #1670] loss: 3.332963353926946\n",
      "[EPOCH #4, step #1672] loss: 3.3332596003332324\n",
      "[EPOCH #4, step #1674] loss: 3.3329674038958195\n",
      "[EPOCH #4, step #1676] loss: 3.332753436083444\n",
      "[EPOCH #4, step #1678] loss: 3.332949130999467\n",
      "[EPOCH #4, step #1680] loss: 3.33257607432223\n",
      "[EPOCH #4, step #1682] loss: 3.332472895697618\n",
      "[EPOCH #4, step #1684] loss: 3.332483039482411\n",
      "[EPOCH #4, step #1686] loss: 3.3324343012010975\n",
      "[EPOCH #4, step #1688] loss: 3.332015308139591\n",
      "[EPOCH #4, step #1690] loss: 3.331823338847552\n",
      "[EPOCH #4, step #1692] loss: 3.3317994608093278\n",
      "[EPOCH #4, step #1694] loss: 3.3319772506533822\n",
      "[EPOCH #4, step #1696] loss: 3.3319438842723983\n",
      "[EPOCH #4, step #1698] loss: 3.3322353194642584\n",
      "[EPOCH #4, step #1700] loss: 3.3323441555330433\n",
      "[EPOCH #4, step #1702] loss: 3.3324750586950422\n",
      "[EPOCH #4, step #1704] loss: 3.3328554641466335\n",
      "[EPOCH #4, step #1706] loss: 3.3326242727079656\n",
      "[EPOCH #4, step #1708] loss: 3.3323657939558213\n",
      "[EPOCH #4, step #1710] loss: 3.3321844638264855\n",
      "[EPOCH #4, step #1712] loss: 3.3321753167577186\n",
      "[EPOCH #4, step #1714] loss: 3.3320419424129297\n",
      "[EPOCH #4, step #1716] loss: 3.332125822888187\n",
      "[EPOCH #4, step #1718] loss: 3.3316521383843636\n",
      "[EPOCH #4, step #1720] loss: 3.331750286380473\n",
      "[EPOCH #4, step #1722] loss: 3.331510239400216\n",
      "[EPOCH #4, step #1724] loss: 3.331009104355522\n",
      "[EPOCH #4, step #1726] loss: 3.330720758879882\n",
      "[EPOCH #4, step #1728] loss: 3.330420102185083\n",
      "[EPOCH #4, step #1730] loss: 3.33043466435217\n",
      "[EPOCH #4, step #1732] loss: 3.330438511672903\n",
      "[EPOCH #4, step #1734] loss: 3.3306768108170037\n",
      "[EPOCH #4, step #1736] loss: 3.330640813710021\n",
      "[EPOCH #4, step #1738] loss: 3.3303156358336086\n",
      "[EPOCH #4, step #1740] loss: 3.3300862946365153\n",
      "[EPOCH #4, step #1742] loss: 3.329896478904641\n",
      "[EPOCH #4, step #1744] loss: 3.3294769262516053\n",
      "[EPOCH #4, step #1746] loss: 3.3296700045253185\n",
      "[EPOCH #4, step #1748] loss: 3.3298113053018126\n",
      "[EPOCH #4, step #1750] loss: 3.329681881082732\n",
      "[EPOCH #4, step #1752] loss: 3.3296705120574117\n",
      "[EPOCH #4, step #1754] loss: 3.329237239245336\n",
      "[EPOCH #4, step #1756] loss: 3.3291224304355542\n",
      "[EPOCH #4, step #1758] loss: 3.3289047248530212\n",
      "[EPOCH #4, step #1760] loss: 3.3288648565813332\n",
      "[EPOCH #4, step #1762] loss: 3.3286741772498587\n",
      "[EPOCH #4, step #1764] loss: 3.3284582906674394\n",
      "[EPOCH #4, step #1766] loss: 3.3282892239856126\n",
      "[EPOCH #4, step #1768] loss: 3.32838135213081\n",
      "[EPOCH #4, step #1770] loss: 3.328350822512273\n",
      "[EPOCH #4, step #1772] loss: 3.3281778542926874\n",
      "[EPOCH #4, step #1774] loss: 3.3282647679557265\n",
      "[EPOCH #4, step #1776] loss: 3.3280552163443406\n",
      "[EPOCH #4, step #1778] loss: 3.327697393531006\n",
      "[EPOCH #4, step #1780] loss: 3.327846422950449\n",
      "[EPOCH #4, step #1782] loss: 3.328008832118515\n",
      "[EPOCH #4, step #1784] loss: 3.327924802523701\n",
      "[EPOCH #4, step #1786] loss: 3.3276667445481123\n",
      "[EPOCH #4, step #1788] loss: 3.327424278333908\n",
      "[EPOCH #4, step #1790] loss: 3.3273002170837507\n",
      "[EPOCH #4, step #1792] loss: 3.327062332490537\n",
      "[EPOCH #4, step #1794] loss: 3.3270456052424184\n",
      "[EPOCH #4, step #1796] loss: 3.327183517138694\n",
      "[EPOCH #4, step #1798] loss: 3.327372981151519\n",
      "[EPOCH #4, step #1800] loss: 3.3274007130834145\n",
      "[EPOCH #4, step #1802] loss: 3.327464169683684\n",
      "[EPOCH #4, step #1804] loss: 3.3275552791901903\n",
      "[EPOCH #4, step #1806] loss: 3.327361158329806\n",
      "[EPOCH #4, step #1808] loss: 3.3273537361931576\n",
      "[EPOCH #4, step #1810] loss: 3.327373873785936\n",
      "[EPOCH #4, step #1812] loss: 3.3272107157730884\n",
      "[EPOCH #4, step #1814] loss: 3.3269405166636483\n",
      "[EPOCH #4, step #1816] loss: 3.326917899593129\n",
      "[EPOCH #4, step #1818] loss: 3.3268523229354683\n",
      "[EPOCH #4, step #1820] loss: 3.3266449071495563\n",
      "[EPOCH #4, step #1822] loss: 3.3268965280651064\n",
      "[EPOCH #4, step #1824] loss: 3.3270921025210862\n",
      "[EPOCH #4, step #1826] loss: 3.327078924977721\n",
      "[EPOCH #4, step #1828] loss: 3.3269563569860945\n",
      "[EPOCH #4, step #1830] loss: 3.3269145559053612\n",
      "[EPOCH #4, step #1832] loss: 3.3267932626242462\n",
      "[EPOCH #4, step #1834] loss: 3.326928586076326\n",
      "[EPOCH #4, step #1836] loss: 3.3268122355056704\n",
      "[EPOCH #4, step #1838] loss: 3.326501952752657\n",
      "[EPOCH #4, step #1840] loss: 3.3263622477674923\n",
      "[EPOCH #4, step #1842] loss: 3.326642131391454\n",
      "[EPOCH #4, step #1844] loss: 3.326126317280095\n",
      "[EPOCH #4, step #1846] loss: 3.3264309810056\n",
      "[EPOCH #4, step #1848] loss: 3.3264385311586784\n",
      "[EPOCH #4, step #1850] loss: 3.3262024868635924\n",
      "[EPOCH #4, step #1852] loss: 3.325874298248044\n",
      "[EPOCH #4, step #1854] loss: 3.326376597772069\n",
      "[EPOCH #4, step #1856] loss: 3.3264303557899733\n",
      "[EPOCH #4, step #1858] loss: 3.326398877702521\n",
      "[EPOCH #4, step #1860] loss: 3.326486035100495\n",
      "[EPOCH #4, step #1862] loss: 3.32607441606281\n",
      "[EPOCH #4, step #1864] loss: 3.3259637355804443\n",
      "[EPOCH #4, step #1866] loss: 3.3257265813732504\n",
      "[EPOCH #4, step #1868] loss: 3.3257912264079446\n",
      "[EPOCH #4, step #1870] loss: 3.3258508844594785\n",
      "[EPOCH #4, step #1872] loss: 3.325682760239666\n",
      "[EPOCH #4, step #1874] loss: 3.325680690383911\n",
      "[EPOCH #4, step #1876] loss: 3.3254788136571154\n",
      "[EPOCH #4, step #1878] loss: 3.325159824547963\n",
      "[EPOCH #4, step #1880] loss: 3.325015349441358\n",
      "[EPOCH #4, step #1882] loss: 3.3246375991509307\n",
      "[EPOCH #4, step #1884] loss: 3.324711349472127\n",
      "[EPOCH #4, step #1886] loss: 3.324710077751738\n",
      "[EPOCH #4, step #1888] loss: 3.3246129764457932\n",
      "[EPOCH #4, step #1890] loss: 3.3246522393572087\n",
      "[EPOCH #4, step #1892] loss: 3.3244756173659304\n",
      "[EPOCH #4, step #1894] loss: 3.324261653266041\n",
      "[EPOCH #4, step #1896] loss: 3.3242867227975608\n",
      "[EPOCH #4, step #1898] loss: 3.3240197487038143\n",
      "[EPOCH #4, step #1900] loss: 3.323614766884954\n",
      "[EPOCH #4, step #1902] loss: 3.32349804646707\n",
      "[EPOCH #4, step #1904] loss: 3.323612728894852\n",
      "[EPOCH #4, step #1906] loss: 3.323536224495258\n",
      "[EPOCH #4, step #1908] loss: 3.3232750163270643\n",
      "[EPOCH #4, step #1910] loss: 3.323351473411548\n",
      "[EPOCH #4, step #1912] loss: 3.3232261842916104\n",
      "[EPOCH #4, step #1914] loss: 3.3236706975234704\n",
      "[EPOCH #4, step #1916] loss: 3.323548824512281\n",
      "[EPOCH #4, step #1918] loss: 3.3236878635114278\n",
      "[EPOCH #4, step #1920] loss: 3.3237847229393123\n",
      "[EPOCH #4, step #1922] loss: 3.323770223653261\n",
      "[EPOCH #4, step #1924] loss: 3.32380490513591\n",
      "[EPOCH #4, step #1926] loss: 3.3234816916445467\n",
      "[EPOCH #4, step #1928] loss: 3.323214075366347\n",
      "[EPOCH #4, step #1930] loss: 3.322924222679474\n",
      "[EPOCH #4, step #1932] loss: 3.3226907478979815\n",
      "[EPOCH #4, step #1934] loss: 3.32258636785108\n",
      "[EPOCH #4, step #1936] loss: 3.322266598245072\n",
      "[EPOCH #4, step #1938] loss: 3.3220444130122875\n",
      "[EPOCH #4, step #1940] loss: 3.321760502750882\n",
      "[EPOCH #4, step #1942] loss: 3.32159456345327\n",
      "[EPOCH #4, step #1944] loss: 3.321020400309624\n",
      "[EPOCH #4, step #1946] loss: 3.32087210881508\n",
      "[EPOCH #4, step #1948] loss: 3.3208459602862885\n",
      "[EPOCH #4, step #1950] loss: 3.3207398609648235\n",
      "[EPOCH #4, step #1952] loss: 3.3206788433922663\n",
      "[EPOCH #4, step #1954] loss: 3.320412059452223\n",
      "[EPOCH #4, step #1956] loss: 3.3202571268281464\n",
      "[EPOCH #4, step #1958] loss: 3.3203356364602152\n",
      "[EPOCH #4, step #1960] loss: 3.3199592603219523\n",
      "[EPOCH #4, step #1962] loss: 3.320045675116416\n",
      "[EPOCH #4, step #1964] loss: 3.319972790531226\n",
      "[EPOCH #4, step #1966] loss: 3.3200249430729643\n",
      "[EPOCH #4, step #1968] loss: 3.3199294155899675\n",
      "[EPOCH #4, step #1970] loss: 3.319651571764431\n",
      "[EPOCH #4, step #1972] loss: 3.319385820152913\n",
      "[EPOCH #4, step #1974] loss: 3.319222922264775\n",
      "[EPOCH #4, step #1976] loss: 3.3192189971063253\n",
      "[EPOCH #4, step #1978] loss: 3.3192784654907412\n",
      "[EPOCH #4, step #1980] loss: 3.319453169034624\n",
      "[EPOCH #4, step #1982] loss: 3.319558055967138\n",
      "[EPOCH #4, step #1984] loss: 3.3194455684882866\n",
      "[EPOCH #4, step #1986] loss: 3.3196511188222946\n",
      "[EPOCH #4, step #1988] loss: 3.3193141614569677\n",
      "[EPOCH #4, step #1990] loss: 3.319206552850368\n",
      "[EPOCH #4, step #1992] loss: 3.3188847756182436\n",
      "[EPOCH #4, step #1994] loss: 3.3185672745668797\n",
      "[EPOCH #4, step #1996] loss: 3.318163472411032\n",
      "[EPOCH #4, step #1998] loss: 3.318067429243415\n",
      "[EPOCH #4, step #2000] loss: 3.3180547579117623\n",
      "[EPOCH #4, step #2002] loss: 3.317723284824693\n",
      "[EPOCH #4, step #2004] loss: 3.317828230489222\n",
      "[EPOCH #4, step #2006] loss: 3.317871304370897\n",
      "[EPOCH #4, step #2008] loss: 3.317666100648697\n",
      "[EPOCH #4, step #2010] loss: 3.317733422136615\n",
      "[EPOCH #4, step #2012] loss: 3.3176374966033464\n",
      "[EPOCH #4, step #2014] loss: 3.317516239464431\n",
      "[EPOCH #4, step #2016] loss: 3.3173134758381426\n",
      "[EPOCH #4, step #2018] loss: 3.3174002060741405\n",
      "[EPOCH #4, step #2020] loss: 3.31705615521657\n",
      "[EPOCH #4, step #2022] loss: 3.31712046214041\n",
      "[EPOCH #4, step #2024] loss: 3.3170503194832506\n",
      "[EPOCH #4, step #2026] loss: 3.3167749462776954\n",
      "[EPOCH #4, step #2028] loss: 3.3166961433735898\n",
      "[EPOCH #4, step #2030] loss: 3.3166173779277717\n",
      "[EPOCH #4, step #2032] loss: 3.3166463319972648\n",
      "[EPOCH #4, step #2034] loss: 3.3167960716406895\n",
      "[EPOCH #4, step #2036] loss: 3.3165470901867544\n",
      "[EPOCH #4, step #2038] loss: 3.3164258449904294\n",
      "[EPOCH #4, step #2040] loss: 3.316322250497043\n",
      "[EPOCH #4, step #2042] loss: 3.3166468640606133\n",
      "[EPOCH #4, step #2044] loss: 3.316709688181982\n",
      "[EPOCH #4, step #2046] loss: 3.3162636751073364\n",
      "[EPOCH #4, step #2048] loss: 3.316327155887237\n",
      "[EPOCH #4, step #2050] loss: 3.3164732253940903\n",
      "[EPOCH #4, step #2052] loss: 3.3163541225009703\n",
      "[EPOCH #4, step #2054] loss: 3.3163316398351443\n",
      "[EPOCH #4, step #2056] loss: 3.316380307810018\n",
      "[EPOCH #4, step #2058] loss: 3.3160865562757627\n",
      "[EPOCH #4, step #2060] loss: 3.3158985359584285\n",
      "[EPOCH #4, step #2062] loss: 3.3157344060907996\n",
      "[EPOCH #4, step #2064] loss: 3.3153133304586713\n",
      "[EPOCH #4, step #2066] loss: 3.3151974840676317\n",
      "[EPOCH #4, step #2068] loss: 3.3151594392915693\n",
      "[EPOCH #4, step #2070] loss: 3.3149697922209738\n",
      "[EPOCH #4, step #2072] loss: 3.3148158173945235\n",
      "[EPOCH #4, step #2074] loss: 3.3145695185374064\n",
      "[EPOCH #4, step #2076] loss: 3.314428923046239\n",
      "[EPOCH #4, step #2078] loss: 3.3145057097715274\n",
      "[EPOCH #4, step #2080] loss: 3.3143686433642716\n",
      "[EPOCH #4, step #2082] loss: 3.314360404667005\n",
      "[EPOCH #4, step #2084] loss: 3.3139753420575917\n",
      "[EPOCH #4, step #2086] loss: 3.313838907332299\n",
      "[EPOCH #4, step #2088] loss: 3.3140892813569796\n",
      "[EPOCH #4, step #2090] loss: 3.3140718431805722\n",
      "[EPOCH #4, step #2092] loss: 3.3140103510561825\n",
      "[EPOCH #4, step #2094] loss: 3.3138190450417966\n",
      "[EPOCH #4, step #2096] loss: 3.3135861941161586\n",
      "[EPOCH #4, step #2098] loss: 3.313201242881255\n",
      "[EPOCH #4, step #2100] loss: 3.3133196247469408\n",
      "[EPOCH #4, step #2102] loss: 3.3129839099026044\n",
      "[EPOCH #4, step #2104] loss: 3.3129978799480155\n",
      "[EPOCH #4, step #2106] loss: 3.3133412743836823\n",
      "[EPOCH #4, step #2108] loss: 3.313208289483307\n",
      "[EPOCH #4, step #2110] loss: 3.3132633781162046\n",
      "[EPOCH #4, step #2112] loss: 3.3132665503718983\n",
      "[EPOCH #4, step #2114] loss: 3.3130926253947806\n",
      "[EPOCH #4, step #2116] loss: 3.3127064163188185\n",
      "[EPOCH #4, step #2118] loss: 3.3126865582063325\n",
      "[EPOCH #4, step #2120] loss: 3.3125515071809546\n",
      "[EPOCH #4, step #2122] loss: 3.312811847907779\n",
      "[EPOCH #4, step #2124] loss: 3.312660347770242\n",
      "[EPOCH #4, step #2126] loss: 3.312491990503258\n",
      "[EPOCH #4, step #2128] loss: 3.3123611113788827\n",
      "[EPOCH #4, step #2130] loss: 3.3123338127404747\n",
      "[EPOCH #4, step #2132] loss: 3.3123168807827805\n",
      "[EPOCH #4, step #2134] loss: 3.312297301549264\n",
      "[EPOCH #4, step #2136] loss: 3.3124527158054393\n",
      "[EPOCH #4, step #2138] loss: 3.3123424856837747\n",
      "[EPOCH #4, step #2140] loss: 3.3123796096420466\n",
      "[EPOCH #4, step #2142] loss: 3.312404555913949\n",
      "[EPOCH #4, step #2144] loss: 3.3123875136697767\n",
      "[EPOCH #4, step #2146] loss: 3.3121857419922343\n",
      "[EPOCH #4, step #2148] loss: 3.312088265536607\n",
      "[EPOCH #4, step #2150] loss: 3.3120425047845634\n",
      "[EPOCH #4, step #2152] loss: 3.3116715222361806\n",
      "[EPOCH #4, step #2154] loss: 3.3117736053024256\n",
      "[EPOCH #4, step #2156] loss: 3.3116269450968043\n",
      "[EPOCH #4, step #2158] loss: 3.31142179951617\n",
      "[EPOCH #4, step #2160] loss: 3.3112852321847175\n",
      "[EPOCH #4, step #2162] loss: 3.3111207473074127\n",
      "[EPOCH #4, step #2164] loss: 3.3113760254399605\n",
      "[EPOCH #4, step #2166] loss: 3.311158083417089\n",
      "[EPOCH #4, step #2168] loss: 3.311050106600827\n",
      "[EPOCH #4, step #2170] loss: 3.311005784860134\n",
      "[EPOCH #4, step #2172] loss: 3.3108780524503563\n",
      "[EPOCH #4, step #2174] loss: 3.31094769247647\n",
      "[EPOCH #4, step #2176] loss: 3.3109615350678583\n",
      "[EPOCH #4, step #2178] loss: 3.3109556184333635\n",
      "[EPOCH #4, step #2180] loss: 3.3108137168779335\n",
      "[EPOCH #4, step #2182] loss: 3.3107327497502395\n",
      "[EPOCH #4, step #2184] loss: 3.3103560649557573\n",
      "[EPOCH #4, step #2186] loss: 3.3104466516567137\n",
      "[EPOCH #4, step #2188] loss: 3.310131067443297\n",
      "[EPOCH #4, step #2190] loss: 3.309828053865733\n",
      "[EPOCH #4, step #2192] loss: 3.3094894770775762\n",
      "[EPOCH #4, step #2194] loss: 3.3091284461879513\n",
      "[EPOCH #4, step #2196] loss: 3.309340493701836\n",
      "[EPOCH #4, step #2198] loss: 3.309326443578938\n",
      "[EPOCH #4, step #2200] loss: 3.3095019513615043\n",
      "[EPOCH #4, step #2202] loss: 3.3091753217452125\n",
      "[EPOCH #4, step #2204] loss: 3.3090447629119804\n",
      "[EPOCH #4, step #2206] loss: 3.308942291063586\n",
      "[EPOCH #4, step #2208] loss: 3.308772474999555\n",
      "[EPOCH #4, step #2210] loss: 3.3086309536503\n",
      "[EPOCH #4, step #2212] loss: 3.308525143949575\n",
      "[EPOCH #4, step #2214] loss: 3.3083637391471434\n",
      "[EPOCH #4, step #2216] loss: 3.308307216787962\n",
      "[EPOCH #4, step #2218] loss: 3.308189972610611\n",
      "[EPOCH #4, step #2220] loss: 3.3080633762235956\n",
      "[EPOCH #4, step #2222] loss: 3.308045383299786\n",
      "[EPOCH #4, step #2224] loss: 3.3078714106056126\n",
      "[EPOCH #4, step #2226] loss: 3.3076681536197876\n",
      "[EPOCH #4, step #2228] loss: 3.30721371331093\n",
      "[EPOCH #4, step #2230] loss: 3.3071488000415785\n",
      "[EPOCH #4, step #2232] loss: 3.3069134369272315\n",
      "[EPOCH #4, step #2234] loss: 3.3067440223907196\n",
      "[EPOCH #4, step #2236] loss: 3.3066381241095404\n",
      "[EPOCH #4, step #2238] loss: 3.3065356041182894\n",
      "[EPOCH #4, step #2240] loss: 3.3064308352685305\n",
      "[EPOCH #4, step #2242] loss: 3.306277137008885\n",
      "[EPOCH #4, step #2244] loss: 3.3064217100164672\n",
      "[EPOCH #4, step #2246] loss: 3.3062145342867164\n",
      "[EPOCH #4, step #2248] loss: 3.306132021984984\n",
      "[EPOCH #4, step #2250] loss: 3.306379352236578\n",
      "[EPOCH #4, step #2252] loss: 3.3062505573894096\n",
      "[EPOCH #4, step #2254] loss: 3.3059830435099467\n",
      "[EPOCH #4, step #2256] loss: 3.305816350492377\n",
      "[EPOCH #4, step #2258] loss: 3.305578174080243\n",
      "[EPOCH #4, step #2260] loss: 3.3055840214497745\n",
      "[EPOCH #4, step #2262] loss: 3.305543353902098\n",
      "[EPOCH #4, step #2264] loss: 3.3051988561684986\n",
      "[EPOCH #4, step #2266] loss: 3.305326131245193\n",
      "[EPOCH #4, step #2268] loss: 3.305319050221046\n",
      "[EPOCH #4, step #2270] loss: 3.305217629642226\n",
      "[EPOCH #4, step #2272] loss: 3.3051846230863946\n",
      "[EPOCH #4, step #2274] loss: 3.3049554002154005\n",
      "[EPOCH #4, step #2276] loss: 3.304763697719281\n",
      "[EPOCH #4, step #2278] loss: 3.3045160475400728\n",
      "[EPOCH #4, step #2280] loss: 3.3045042781963625\n",
      "[EPOCH #4, step #2282] loss: 3.3043726012730774\n",
      "[EPOCH #4, step #2284] loss: 3.30424768762985\n",
      "[EPOCH #4, step #2286] loss: 3.3043482597602942\n",
      "[EPOCH #4, step #2288] loss: 3.304202066961466\n",
      "[EPOCH #4, step #2290] loss: 3.304030011179977\n",
      "[EPOCH #4, step #2292] loss: 3.3037908963121496\n",
      "[EPOCH #4, step #2294] loss: 3.3033981742941996\n",
      "[EPOCH #4, step #2296] loss: 3.3033434446863783\n",
      "[EPOCH #4, step #2298] loss: 3.303294987095704\n",
      "[EPOCH #4, step #2300] loss: 3.3029621774763815\n",
      "[EPOCH #4, step #2302] loss: 3.3029403221695204\n",
      "[EPOCH #4, step #2304] loss: 3.3025498914615192\n",
      "[EPOCH #4, step #2306] loss: 3.302470513737765\n",
      "[EPOCH #4, step #2308] loss: 3.302477441240875\n",
      "[EPOCH #4, step #2310] loss: 3.302075009075711\n",
      "[EPOCH #4, step #2312] loss: 3.302098881667484\n",
      "[EPOCH #4, step #2314] loss: 3.302144815906335\n",
      "[EPOCH #4, step #2316] loss: 3.302004612876158\n",
      "[EPOCH #4, step #2318] loss: 3.3020314037311485\n",
      "[EPOCH #4, step #2320] loss: 3.3021071800534347\n",
      "[EPOCH #4, step #2322] loss: 3.3020335133610437\n",
      "[EPOCH #4, step #2324] loss: 3.302056508935908\n",
      "[EPOCH #4, step #2326] loss: 3.302048794230423\n",
      "[EPOCH #4, step #2328] loss: 3.3021025039341994\n",
      "[EPOCH #4, step #2330] loss: 3.3018125691980518\n",
      "[EPOCH #4, step #2332] loss: 3.3017086605631225\n",
      "[EPOCH #4, step #2334] loss: 3.301539591497221\n",
      "[EPOCH #4, step #2336] loss: 3.3015949289463093\n",
      "[EPOCH #4, step #2338] loss: 3.3016273522794934\n",
      "[EPOCH #4, step #2340] loss: 3.301713007426272\n",
      "[EPOCH #4, step #2342] loss: 3.3015687552161874\n",
      "[EPOCH #4, step #2344] loss: 3.3012487433866653\n",
      "[EPOCH #4, step #2346] loss: 3.3010837399913853\n",
      "[EPOCH #4, step #2348] loss: 3.3009545848744124\n",
      "[EPOCH #4, step #2350] loss: 3.300847169644069\n",
      "[EPOCH #4, step #2352] loss: 3.300750437565069\n",
      "[EPOCH #4, step #2354] loss: 3.300831831589879\n",
      "[EPOCH #4, step #2356] loss: 3.300724930716714\n",
      "[EPOCH #4, step #2358] loss: 3.300536479420357\n",
      "[EPOCH #4, step #2360] loss: 3.300502785481118\n",
      "[EPOCH #4, step #2362] loss: 3.300345186555582\n",
      "[EPOCH #4, step #2364] loss: 3.3000487882037497\n",
      "[EPOCH #4, step #2366] loss: 3.3001245029072344\n",
      "[EPOCH #4, step #2368] loss: 3.3001093654101186\n",
      "[EPOCH #4, step #2370] loss: 3.3000196393961043\n",
      "[EPOCH #4, step #2372] loss: 3.2997240789118467\n",
      "[EPOCH #4, step #2374] loss: 3.299767999950208\n",
      "[EPOCH #4, step #2376] loss: 3.299663100766193\n",
      "[EPOCH #4, step #2378] loss: 3.299707549717708\n",
      "[EPOCH #4, step #2380] loss: 3.299468930355394\n",
      "[EPOCH #4, step #2382] loss: 3.299267357255149\n",
      "[EPOCH #4, step #2384] loss: 3.2991467296952224\n",
      "[EPOCH #4, step #2386] loss: 3.2991853024003692\n",
      "[EPOCH #4, step #2388] loss: 3.2990652563782503\n",
      "[EPOCH #4, step #2390] loss: 3.2990511908585036\n",
      "[EPOCH #4, step #2392] loss: 3.2989051504410116\n",
      "[EPOCH #4, step #2394] loss: 3.2988853588980276\n",
      "[EPOCH #4, step #2396] loss: 3.2987499464836327\n",
      "[EPOCH #4, step #2398] loss: 3.2985693430493104\n",
      "[EPOCH #4, step #2400] loss: 3.2988209977640506\n",
      "[EPOCH #4, step #2402] loss: 3.298659406301631\n",
      "[EPOCH #4, step #2404] loss: 3.2984185010628493\n",
      "[EPOCH #4, step #2406] loss: 3.2985792196683485\n",
      "[EPOCH #4, step #2408] loss: 3.2983654433139975\n",
      "[EPOCH #4, step #2410] loss: 3.2983331477577784\n",
      "[EPOCH #4, step #2412] loss: 3.2983502394126454\n",
      "[EPOCH #4, step #2414] loss: 3.298316246332836\n",
      "[EPOCH #4, step #2416] loss: 3.298111592140087\n",
      "[EPOCH #4, step #2418] loss: 3.2978515355929012\n",
      "[EPOCH #4, step #2420] loss: 3.2977390813216942\n",
      "[EPOCH #4, step #2422] loss: 3.2975728807988562\n",
      "[EPOCH #4, step #2424] loss: 3.297640378794719\n",
      "[EPOCH #4, step #2426] loss: 3.297728617396628\n",
      "[EPOCH #4, step #2428] loss: 3.29760307095678\n",
      "[EPOCH #4, step #2430] loss: 3.2977187446192526\n",
      "[EPOCH #4, step #2432] loss: 3.2975484051921953\n",
      "[EPOCH #4, step #2434] loss: 3.2972736080569165\n",
      "[EPOCH #4, step #2436] loss: 3.2971831077329927\n",
      "[EPOCH #4, step #2438] loss: 3.2971030544579736\n",
      "[EPOCH #4, step #2440] loss: 3.296979987391777\n",
      "[EPOCH #4, step #2442] loss: 3.2965471873359506\n",
      "[EPOCH #4, step #2444] loss: 3.2961005278160234\n",
      "[EPOCH #4, step #2446] loss: 3.2959026907432505\n",
      "[EPOCH #4, step #2448] loss: 3.2957405809384555\n",
      "[EPOCH #4, step #2450] loss: 3.295755759398337\n",
      "[EPOCH #4, step #2452] loss: 3.2957949090188636\n",
      "[EPOCH #4, step #2454] loss: 3.2958270316696945\n",
      "[EPOCH #4, step #2456] loss: 3.295727901745968\n",
      "[EPOCH #4, step #2458] loss: 3.295586226383037\n",
      "[EPOCH #4, step #2460] loss: 3.295536601122004\n",
      "[EPOCH #4, step #2462] loss: 3.2954296788886657\n",
      "[EPOCH #4, step #2464] loss: 3.2955540334960753\n",
      "[EPOCH #4, step #2466] loss: 3.295612049528013\n",
      "[EPOCH #4, step #2468] loss: 3.295650991170983\n",
      "[EPOCH #4, step #2470] loss: 3.295655045129181\n",
      "[EPOCH #4, step #2472] loss: 3.295856314538415\n",
      "[EPOCH #4, step #2474] loss: 3.2958634537398215\n",
      "[EPOCH #4, step #2476] loss: 3.295646854403715\n",
      "[EPOCH #4, step #2478] loss: 3.295460051709291\n",
      "[EPOCH #4, step #2480] loss: 3.2953740033061694\n",
      "[EPOCH #4, step #2482] loss: 3.2953163675852855\n",
      "[EPOCH #4, step #2484] loss: 3.295144286913651\n",
      "[EPOCH #4, step #2486] loss: 3.2950429404457746\n",
      "[EPOCH #4, step #2488] loss: 3.294949687978454\n",
      "[EPOCH #4, step #2490] loss: 3.2948090751598946\n",
      "[EPOCH #4, step #2492] loss: 3.294740553223556\n",
      "[EPOCH #4, step #2494] loss: 3.294439084830886\n",
      "[EPOCH #4, step #2496] loss: 3.294416192822042\n",
      "[EPOCH #4, step #2498] loss: 3.2943936288237525\n",
      "[EPOCH #4, elapsed time: 2015.440[sec]] loss: 3.2943407535552978\n",
      "[EPOCH #5, step #0] loss: 3.567345142364502\n",
      "[EPOCH #5, step #2] loss: 3.2539528210957847\n",
      "[EPOCH #5, step #4] loss: 3.195161485671997\n",
      "[EPOCH #5, step #6] loss: 3.1939104284558977\n",
      "[EPOCH #5, step #8] loss: 3.2459601296318903\n",
      "[EPOCH #5, step #10] loss: 3.2330836816267534\n",
      "[EPOCH #5, step #12] loss: 3.2477475863236647\n",
      "[EPOCH #5, step #14] loss: 3.2758418560028075\n",
      "[EPOCH #5, step #16] loss: 3.247218566782334\n",
      "[EPOCH #5, step #18] loss: 3.22045888398823\n",
      "[EPOCH #5, step #20] loss: 3.189118124189831\n",
      "[EPOCH #5, step #22] loss: 3.192346728366354\n",
      "[EPOCH #5, step #24] loss: 3.215277795791626\n",
      "[EPOCH #5, step #26] loss: 3.2094328315169722\n",
      "[EPOCH #5, step #28] loss: 3.2133693201788542\n",
      "[EPOCH #5, step #30] loss: 3.202443499718943\n",
      "[EPOCH #5, step #32] loss: 3.2019670298605254\n",
      "[EPOCH #5, step #34] loss: 3.1863225391932897\n",
      "[EPOCH #5, step #36] loss: 3.1908587056237296\n",
      "[EPOCH #5, step #38] loss: 3.1893860743596005\n",
      "[EPOCH #5, step #40] loss: 3.2043140283445033\n",
      "[EPOCH #5, step #42] loss: 3.2084774250207944\n",
      "[EPOCH #5, step #44] loss: 3.2128515932295056\n",
      "[EPOCH #5, step #46] loss: 3.2189784405079296\n",
      "[EPOCH #5, step #48] loss: 3.215365794240212\n",
      "[EPOCH #5, step #50] loss: 3.1991307221206964\n",
      "[EPOCH #5, step #52] loss: 3.20729813035929\n",
      "[EPOCH #5, step #54] loss: 3.209396305951205\n",
      "[EPOCH #5, step #56] loss: 3.207040644528573\n",
      "[EPOCH #5, step #58] loss: 3.202544091111523\n",
      "[EPOCH #5, step #60] loss: 3.2111944526922507\n",
      "[EPOCH #5, step #62] loss: 3.21062727958437\n",
      "[EPOCH #5, step #64] loss: 3.213699909356924\n",
      "[EPOCH #5, step #66] loss: 3.223534057389444\n",
      "[EPOCH #5, step #68] loss: 3.222550958826922\n",
      "[EPOCH #5, step #70] loss: 3.222500458569594\n",
      "[EPOCH #5, step #72] loss: 3.2198049499563974\n",
      "[EPOCH #5, step #74] loss: 3.210045255025228\n",
      "[EPOCH #5, step #76] loss: 3.2153218411780022\n",
      "[EPOCH #5, step #78] loss: 3.205846119530593\n",
      "[EPOCH #5, step #80] loss: 3.2157466617631325\n",
      "[EPOCH #5, step #82] loss: 3.2156086140368356\n",
      "[EPOCH #5, step #84] loss: 3.216326966005213\n",
      "[EPOCH #5, step #86] loss: 3.2120202546832206\n",
      "[EPOCH #5, step #88] loss: 3.21231539597672\n",
      "[EPOCH #5, step #90] loss: 3.2150339425265133\n",
      "[EPOCH #5, step #92] loss: 3.217059786601733\n",
      "[EPOCH #5, step #94] loss: 3.2145829928548713\n",
      "[EPOCH #5, step #96] loss: 3.2090547748447693\n",
      "[EPOCH #5, step #98] loss: 3.211918421465941\n",
      "[EPOCH #5, step #100] loss: 3.212162378991004\n",
      "[EPOCH #5, step #102] loss: 3.212675708011516\n",
      "[EPOCH #5, step #104] loss: 3.2094023977007184\n",
      "[EPOCH #5, step #106] loss: 3.210539441242396\n",
      "[EPOCH #5, step #108] loss: 3.209076931717199\n",
      "[EPOCH #5, step #110] loss: 3.2164675437652313\n",
      "[EPOCH #5, step #112] loss: 3.213707533557858\n",
      "[EPOCH #5, step #114] loss: 3.215705274498981\n",
      "[EPOCH #5, step #116] loss: 3.2193194210019884\n",
      "[EPOCH #5, step #118] loss: 3.2203397350151\n",
      "[EPOCH #5, step #120] loss: 3.221876648831959\n",
      "[EPOCH #5, step #122] loss: 3.218608092486374\n",
      "[EPOCH #5, step #124] loss: 3.2180011234283445\n",
      "[EPOCH #5, step #126] loss: 3.219375187956442\n",
      "[EPOCH #5, step #128] loss: 3.2205330272053563\n",
      "[EPOCH #5, step #130] loss: 3.218597033551631\n",
      "[EPOCH #5, step #132] loss: 3.2152438163757324\n",
      "[EPOCH #5, step #134] loss: 3.2152619803393327\n",
      "[EPOCH #5, step #136] loss: 3.2136837322346485\n",
      "[EPOCH #5, step #138] loss: 3.2141665623342393\n",
      "[EPOCH #5, step #140] loss: 3.2171924993501486\n",
      "[EPOCH #5, step #142] loss: 3.2157898649469123\n",
      "[EPOCH #5, step #144] loss: 3.2242944487209977\n",
      "[EPOCH #5, step #146] loss: 3.2231987820190637\n",
      "[EPOCH #5, step #148] loss: 3.222126053483694\n",
      "[EPOCH #5, step #150] loss: 3.2234197468157637\n",
      "[EPOCH #5, step #152] loss: 3.2240491770451367\n",
      "[EPOCH #5, step #154] loss: 3.221825555063063\n",
      "[EPOCH #5, step #156] loss: 3.2235313798211944\n",
      "[EPOCH #5, step #158] loss: 3.2188917450934835\n",
      "[EPOCH #5, step #160] loss: 3.2202496025132836\n",
      "[EPOCH #5, step #162] loss: 3.2214550226012624\n",
      "[EPOCH #5, step #164] loss: 3.2260254787676264\n",
      "[EPOCH #5, step #166] loss: 3.2262816614733483\n",
      "[EPOCH #5, step #168] loss: 3.2238647458115977\n",
      "[EPOCH #5, step #170] loss: 3.2247267801162094\n",
      "[EPOCH #5, step #172] loss: 3.224241179537911\n",
      "[EPOCH #5, step #174] loss: 3.2205170999254498\n",
      "[EPOCH #5, step #176] loss: 3.2236542432321666\n",
      "[EPOCH #5, step #178] loss: 3.2195483426142006\n",
      "[EPOCH #5, step #180] loss: 3.217352460102482\n",
      "[EPOCH #5, step #182] loss: 3.2179584568315516\n",
      "[EPOCH #5, step #184] loss: 3.2207029188001477\n",
      "[EPOCH #5, step #186] loss: 3.219837594159784\n",
      "[EPOCH #5, step #188] loss: 3.2211445614143654\n",
      "[EPOCH #5, step #190] loss: 3.217946805254951\n",
      "[EPOCH #5, step #192] loss: 3.2171380186328\n",
      "[EPOCH #5, step #194] loss: 3.21997557419997\n",
      "[EPOCH #5, step #196] loss: 3.220437490395483\n",
      "[EPOCH #5, step #198] loss: 3.219066788802794\n",
      "[EPOCH #5, step #200] loss: 3.215922377002773\n",
      "[EPOCH #5, step #202] loss: 3.2158433392717334\n",
      "[EPOCH #5, step #204] loss: 3.2178149862987238\n",
      "[EPOCH #5, step #206] loss: 3.2162387532312513\n",
      "[EPOCH #5, step #208] loss: 3.2169375020351136\n",
      "[EPOCH #5, step #210] loss: 3.2153563070071254\n",
      "[EPOCH #5, step #212] loss: 3.2153208770662407\n",
      "[EPOCH #5, step #214] loss: 3.2152515256127647\n",
      "[EPOCH #5, step #216] loss: 3.2171829010484405\n",
      "[EPOCH #5, step #218] loss: 3.2143210145436467\n",
      "[EPOCH #5, step #220] loss: 3.212649442491488\n",
      "[EPOCH #5, step #222] loss: 3.2123119916616534\n",
      "[EPOCH #5, step #224] loss: 3.2107841724819606\n",
      "[EPOCH #5, step #226] loss: 3.207300847847556\n",
      "[EPOCH #5, step #228] loss: 3.205194469102085\n",
      "[EPOCH #5, step #230] loss: 3.202872000731431\n",
      "[EPOCH #5, step #232] loss: 3.2051698107576168\n",
      "[EPOCH #5, step #234] loss: 3.2063080655767564\n",
      "[EPOCH #5, step #236] loss: 3.2016971745068514\n",
      "[EPOCH #5, step #238] loss: 3.200795957732899\n",
      "[EPOCH #5, step #240] loss: 3.199249847301309\n",
      "[EPOCH #5, step #242] loss: 3.1995431120994158\n",
      "[EPOCH #5, step #244] loss: 3.198287938565624\n",
      "[EPOCH #5, step #246] loss: 3.1984149164516436\n",
      "[EPOCH #5, step #248] loss: 3.19837957788184\n",
      "[EPOCH #5, step #250] loss: 3.1956718015480803\n",
      "[EPOCH #5, step #252] loss: 3.193224641174196\n",
      "[EPOCH #5, step #254] loss: 3.1901240984598798\n",
      "[EPOCH #5, step #256] loss: 3.1888205569078023\n",
      "[EPOCH #5, step #258] loss: 3.1876800888753767\n",
      "[EPOCH #5, step #260] loss: 3.18824852380716\n",
      "[EPOCH #5, step #262] loss: 3.1887696161016312\n",
      "[EPOCH #5, step #264] loss: 3.188157938111503\n",
      "[EPOCH #5, step #266] loss: 3.1865120835965044\n",
      "[EPOCH #5, step #268] loss: 3.1863623339004232\n",
      "[EPOCH #5, step #270] loss: 3.1855167805928586\n",
      "[EPOCH #5, step #272] loss: 3.1844775405995573\n",
      "[EPOCH #5, step #274] loss: 3.1847410531477496\n",
      "[EPOCH #5, step #276] loss: 3.1844119070239016\n",
      "[EPOCH #5, step #278] loss: 3.1855426526838735\n",
      "[EPOCH #5, step #280] loss: 3.185202640146547\n",
      "[EPOCH #5, step #282] loss: 3.185045365309968\n",
      "[EPOCH #5, step #284] loss: 3.184552378403513\n",
      "[EPOCH #5, step #286] loss: 3.18297353023436\n",
      "[EPOCH #5, step #288] loss: 3.1839156819049874\n",
      "[EPOCH #5, step #290] loss: 3.1836897409249008\n",
      "[EPOCH #5, step #292] loss: 3.1837932388123393\n",
      "[EPOCH #5, step #294] loss: 3.184064921686205\n",
      "[EPOCH #5, step #296] loss: 3.184382996575198\n",
      "[EPOCH #5, step #298] loss: 3.1826981461566426\n",
      "[EPOCH #5, step #300] loss: 3.184253618170653\n",
      "[EPOCH #5, step #302] loss: 3.182002073073938\n",
      "[EPOCH #5, step #304] loss: 3.180493058532965\n",
      "[EPOCH #5, step #306] loss: 3.1812192896678315\n",
      "[EPOCH #5, step #308] loss: 3.182247109397715\n",
      "[EPOCH #5, step #310] loss: 3.1812562168219465\n",
      "[EPOCH #5, step #312] loss: 3.181761836853271\n",
      "[EPOCH #5, step #314] loss: 3.1820020486438083\n",
      "[EPOCH #5, step #316] loss: 3.180143326990988\n",
      "[EPOCH #5, step #318] loss: 3.18010652551083\n",
      "[EPOCH #5, step #320] loss: 3.180026815687756\n",
      "[EPOCH #5, step #322] loss: 3.1818848970135667\n",
      "[EPOCH #5, step #324] loss: 3.18163486627432\n",
      "[EPOCH #5, step #326] loss: 3.181207240539224\n",
      "[EPOCH #5, step #328] loss: 3.1796621761785815\n",
      "[EPOCH #5, step #330] loss: 3.1813148270921046\n",
      "[EPOCH #5, step #332] loss: 3.182597833352762\n",
      "[EPOCH #5, step #334] loss: 3.1825921229462124\n",
      "[EPOCH #5, step #336] loss: 3.1820361883067236\n",
      "[EPOCH #5, step #338] loss: 3.181196263406129\n",
      "[EPOCH #5, step #340] loss: 3.1799718697399686\n",
      "[EPOCH #5, step #342] loss: 3.1808285108460628\n",
      "[EPOCH #5, step #344] loss: 3.1799826317939206\n",
      "[EPOCH #5, step #346] loss: 3.179820136309357\n",
      "[EPOCH #5, step #348] loss: 3.1792371143242693\n",
      "[EPOCH #5, step #350] loss: 3.180181048874162\n",
      "[EPOCH #5, step #352] loss: 3.180261276261327\n",
      "[EPOCH #5, step #354] loss: 3.1811114123169806\n",
      "[EPOCH #5, step #356] loss: 3.1790330430038836\n",
      "[EPOCH #5, step #358] loss: 3.1791276433673743\n",
      "[EPOCH #5, step #360] loss: 3.179107480432188\n",
      "[EPOCH #5, step #362] loss: 3.177890505015686\n",
      "[EPOCH #5, step #364] loss: 3.17708279531296\n",
      "[EPOCH #5, step #366] loss: 3.1769552035942388\n",
      "[EPOCH #5, step #368] loss: 3.1777859974682814\n",
      "[EPOCH #5, step #370] loss: 3.1778453932296875\n",
      "[EPOCH #5, step #372] loss: 3.1787149599346334\n",
      "[EPOCH #5, step #374] loss: 3.1801942081451418\n",
      "[EPOCH #5, step #376] loss: 3.1808175888871006\n",
      "[EPOCH #5, step #378] loss: 3.18092780880689\n",
      "[EPOCH #5, step #380] loss: 3.180011821856962\n",
      "[EPOCH #5, step #382] loss: 3.179341870873155\n",
      "[EPOCH #5, step #384] loss: 3.179965242162927\n",
      "[EPOCH #5, step #386] loss: 3.1781760660560865\n",
      "[EPOCH #5, step #388] loss: 3.1790114448125686\n",
      "[EPOCH #5, step #390] loss: 3.177363708500972\n",
      "[EPOCH #5, step #392] loss: 3.1757421256931684\n",
      "[EPOCH #5, step #394] loss: 3.176319998729078\n",
      "[EPOCH #5, step #396] loss: 3.175479661307347\n",
      "[EPOCH #5, step #398] loss: 3.175161975965763\n",
      "[EPOCH #5, step #400] loss: 3.174521368935221\n",
      "[EPOCH #5, step #402] loss: 3.175082000846011\n",
      "[EPOCH #5, step #404] loss: 3.173850773587639\n",
      "[EPOCH #5, step #406] loss: 3.1748122237531207\n",
      "[EPOCH #5, step #408] loss: 3.175730006910478\n",
      "[EPOCH #5, step #410] loss: 3.1744409750267826\n",
      "[EPOCH #5, step #412] loss: 3.174473469251582\n",
      "[EPOCH #5, step #414] loss: 3.1742136708225113\n",
      "[EPOCH #5, step #416] loss: 3.1743878460616517\n",
      "[EPOCH #5, step #418] loss: 3.174415054639939\n",
      "[EPOCH #5, step #420] loss: 3.17373936136658\n",
      "[EPOCH #5, step #422] loss: 3.1733510809869068\n",
      "[EPOCH #5, step #424] loss: 3.172927954056684\n",
      "[EPOCH #5, step #426] loss: 3.1741848807145057\n",
      "[EPOCH #5, step #428] loss: 3.1725028956130945\n",
      "[EPOCH #5, step #430] loss: 3.1708423256044322\n",
      "[EPOCH #5, step #432] loss: 3.171479524696121\n",
      "[EPOCH #5, step #434] loss: 3.1714090632296155\n",
      "[EPOCH #5, step #436] loss: 3.1704308059177353\n",
      "[EPOCH #5, step #438] loss: 3.170298628492073\n",
      "[EPOCH #5, step #440] loss: 3.170364491793574\n",
      "[EPOCH #5, step #442] loss: 3.1704844836456783\n",
      "[EPOCH #5, step #444] loss: 3.1705819071008916\n",
      "[EPOCH #5, step #446] loss: 3.1704795680590125\n",
      "[EPOCH #5, step #448] loss: 3.1697930307324587\n",
      "[EPOCH #5, step #450] loss: 3.168933882152955\n",
      "[EPOCH #5, step #452] loss: 3.1689724132714683\n",
      "[EPOCH #5, step #454] loss: 3.168395079099215\n",
      "[EPOCH #5, step #456] loss: 3.1686949933383866\n",
      "[EPOCH #5, step #458] loss: 3.1701834030400695\n",
      "[EPOCH #5, step #460] loss: 3.170824472919721\n",
      "[EPOCH #5, step #462] loss: 3.169762124768086\n",
      "[EPOCH #5, step #464] loss: 3.171153472572245\n",
      "[EPOCH #5, step #466] loss: 3.1711366457397983\n",
      "[EPOCH #5, step #468] loss: 3.169965407995781\n",
      "[EPOCH #5, step #470] loss: 3.1697448428775603\n",
      "[EPOCH #5, step #472] loss: 3.169075717885701\n",
      "[EPOCH #5, step #474] loss: 3.1692526817321776\n",
      "[EPOCH #5, step #476] loss: 3.1686657499717215\n",
      "[EPOCH #5, step #478] loss: 3.1689240335173796\n",
      "[EPOCH #5, step #480] loss: 3.168436409777762\n",
      "[EPOCH #5, step #482] loss: 3.1686401574508003\n",
      "[EPOCH #5, step #484] loss: 3.168378278889607\n",
      "[EPOCH #5, step #486] loss: 3.1680599903913493\n",
      "[EPOCH #5, step #488] loss: 3.167790996516409\n",
      "[EPOCH #5, step #490] loss: 3.16893106176994\n",
      "[EPOCH #5, step #492] loss: 3.169360413754446\n",
      "[EPOCH #5, step #494] loss: 3.1694751546840476\n",
      "[EPOCH #5, step #496] loss: 3.1702289629270375\n",
      "[EPOCH #5, step #498] loss: 3.170186603236533\n",
      "[EPOCH #5, step #500] loss: 3.170254184338385\n",
      "[EPOCH #5, step #502] loss: 3.1704742060029956\n",
      "[EPOCH #5, step #504] loss: 3.170371151442575\n",
      "[EPOCH #5, step #506] loss: 3.171739258474617\n",
      "[EPOCH #5, step #508] loss: 3.1716903075722205\n",
      "[EPOCH #5, step #510] loss: 3.172341518905998\n",
      "[EPOCH #5, step #512] loss: 3.172437789612114\n",
      "[EPOCH #5, step #514] loss: 3.1716360332896407\n",
      "[EPOCH #5, step #516] loss: 3.171793440093847\n",
      "[EPOCH #5, step #518] loss: 3.1709833140547796\n",
      "[EPOCH #5, step #520] loss: 3.171296124723731\n",
      "[EPOCH #5, step #522] loss: 3.170926097702114\n",
      "[EPOCH #5, step #524] loss: 3.1711945615495956\n",
      "[EPOCH #5, step #526] loss: 3.1713270181949045\n",
      "[EPOCH #5, step #528] loss: 3.1719276742808984\n",
      "[EPOCH #5, step #530] loss: 3.1710095535788385\n",
      "[EPOCH #5, step #532] loss: 3.1709105619570104\n",
      "[EPOCH #5, step #534] loss: 3.1702728035294006\n",
      "[EPOCH #5, step #536] loss: 3.1701907507756126\n",
      "[EPOCH #5, step #538] loss: 3.1703337074874285\n",
      "[EPOCH #5, step #540] loss: 3.1702832250189648\n",
      "[EPOCH #5, step #542] loss: 3.170436318627598\n",
      "[EPOCH #5, step #544] loss: 3.171936662918931\n",
      "[EPOCH #5, step #546] loss: 3.172146651165141\n",
      "[EPOCH #5, step #548] loss: 3.1718744093820264\n",
      "[EPOCH #5, step #550] loss: 3.171672737533514\n",
      "[EPOCH #5, step #552] loss: 3.172547001519643\n",
      "[EPOCH #5, step #554] loss: 3.1725810695338894\n",
      "[EPOCH #5, step #556] loss: 3.171413193485253\n",
      "[EPOCH #5, step #558] loss: 3.1710834102255285\n",
      "[EPOCH #5, step #560] loss: 3.1702286882621507\n",
      "[EPOCH #5, step #562] loss: 3.1695658914996296\n",
      "[EPOCH #5, step #564] loss: 3.1688481972280855\n",
      "[EPOCH #5, step #566] loss: 3.169461953366665\n",
      "[EPOCH #5, step #568] loss: 3.1705832686700806\n",
      "[EPOCH #5, step #570] loss: 3.17028898908879\n",
      "[EPOCH #5, step #572] loss: 3.169943733781212\n",
      "[EPOCH #5, step #574] loss: 3.1705243666275686\n",
      "[EPOCH #5, step #576] loss: 3.1707985570567114\n",
      "[EPOCH #5, step #578] loss: 3.1704594710124385\n",
      "[EPOCH #5, step #580] loss: 3.170978713158691\n",
      "[EPOCH #5, step #582] loss: 3.170169904342442\n",
      "[EPOCH #5, step #584] loss: 3.1698667884891867\n",
      "[EPOCH #5, step #586] loss: 3.1713234923361107\n",
      "[EPOCH #5, step #588] loss: 3.172019846370548\n",
      "[EPOCH #5, step #590] loss: 3.1711158776646338\n",
      "[EPOCH #5, step #592] loss: 3.1705471118425237\n",
      "[EPOCH #5, step #594] loss: 3.171064391657084\n",
      "[EPOCH #5, step #596] loss: 3.170651307257775\n",
      "[EPOCH #5, step #598] loss: 3.170287376652178\n",
      "[EPOCH #5, step #600] loss: 3.169026944085881\n",
      "[EPOCH #5, step #602] loss: 3.1695183082599545\n",
      "[EPOCH #5, step #604] loss: 3.170025723039611\n",
      "[EPOCH #5, step #606] loss: 3.1696213257960864\n",
      "[EPOCH #5, step #608] loss: 3.1686332985293886\n",
      "[EPOCH #5, step #610] loss: 3.1684381321877386\n",
      "[EPOCH #5, step #612] loss: 3.168868586056384\n",
      "[EPOCH #5, step #614] loss: 3.168428087234497\n",
      "[EPOCH #5, step #616] loss: 3.16815695731721\n",
      "[EPOCH #5, step #618] loss: 3.167329810162546\n",
      "[EPOCH #5, step #620] loss: 3.167095205058222\n",
      "[EPOCH #5, step #622] loss: 3.1668913827470564\n",
      "[EPOCH #5, step #624] loss: 3.16759803314209\n",
      "[EPOCH #5, step #626] loss: 3.167578874782702\n",
      "[EPOCH #5, step #628] loss: 3.167672780814724\n",
      "[EPOCH #5, step #630] loss: 3.1676334356165916\n",
      "[EPOCH #5, step #632] loss: 3.1661042312121883\n",
      "[EPOCH #5, step #634] loss: 3.165596259109617\n",
      "[EPOCH #5, step #636] loss: 3.164963752545966\n",
      "[EPOCH #5, step #638] loss: 3.164847203077098\n",
      "[EPOCH #5, step #640] loss: 3.1646608789327924\n",
      "[EPOCH #5, step #642] loss: 3.1649699003477676\n",
      "[EPOCH #5, step #644] loss: 3.164630322493324\n",
      "[EPOCH #5, step #646] loss: 3.1651488614413985\n",
      "[EPOCH #5, step #648] loss: 3.1652034721315734\n",
      "[EPOCH #5, step #650] loss: 3.166003934066233\n",
      "[EPOCH #5, step #652] loss: 3.166687029974384\n",
      "[EPOCH #5, step #654] loss: 3.16678401022467\n",
      "[EPOCH #5, step #656] loss: 3.166561863738108\n",
      "[EPOCH #5, step #658] loss: 3.165434644869861\n",
      "[EPOCH #5, step #660] loss: 3.165987010081489\n",
      "[EPOCH #5, step #662] loss: 3.1661367283327726\n",
      "[EPOCH #5, step #664] loss: 3.1667146198731615\n",
      "[EPOCH #5, step #666] loss: 3.1655570981742023\n",
      "[EPOCH #5, step #668] loss: 3.1655193415814273\n",
      "[EPOCH #5, step #670] loss: 3.166158633153947\n",
      "[EPOCH #5, step #672] loss: 3.1674399588472952\n",
      "[EPOCH #5, step #674] loss: 3.1675680093412044\n",
      "[EPOCH #5, step #676] loss: 3.1665881430204723\n",
      "[EPOCH #5, step #678] loss: 3.165362974680927\n",
      "[EPOCH #5, step #680] loss: 3.16479350361705\n",
      "[EPOCH #5, step #682] loss: 3.1641369773563146\n",
      "[EPOCH #5, step #684] loss: 3.164486356025195\n",
      "[EPOCH #5, step #686] loss: 3.164538286311831\n",
      "[EPOCH #5, step #688] loss: 3.165110465577102\n",
      "[EPOCH #5, step #690] loss: 3.164746701286084\n",
      "[EPOCH #5, step #692] loss: 3.1646612640067096\n",
      "[EPOCH #5, step #694] loss: 3.164547502737251\n",
      "[EPOCH #5, step #696] loss: 3.164485976206863\n",
      "[EPOCH #5, step #698] loss: 3.1649418879987854\n",
      "[EPOCH #5, step #700] loss: 3.1648781228167526\n",
      "[EPOCH #5, step #702] loss: 3.164433696361558\n",
      "[EPOCH #5, step #704] loss: 3.163878269398466\n",
      "[EPOCH #5, step #706] loss: 3.1630910977278606\n",
      "[EPOCH #5, step #708] loss: 3.1628350259891183\n",
      "[EPOCH #5, step #710] loss: 3.162916334704843\n",
      "[EPOCH #5, step #712] loss: 3.162558379714987\n",
      "[EPOCH #5, step #714] loss: 3.1630232564219227\n",
      "[EPOCH #5, step #716] loss: 3.162507589890867\n",
      "[EPOCH #5, step #718] loss: 3.161294539880023\n",
      "[EPOCH #5, step #720] loss: 3.161341586820626\n",
      "[EPOCH #5, step #722] loss: 3.161829449823783\n",
      "[EPOCH #5, step #724] loss: 3.1613321777869916\n",
      "[EPOCH #5, step #726] loss: 3.1613951342633864\n",
      "[EPOCH #5, step #728] loss: 3.1615503053442766\n",
      "[EPOCH #5, step #730] loss: 3.1610469374545787\n",
      "[EPOCH #5, step #732] loss: 3.1615294538448486\n",
      "[EPOCH #5, step #734] loss: 3.161625720043572\n",
      "[EPOCH #5, step #736] loss: 3.1615952895486696\n",
      "[EPOCH #5, step #738] loss: 3.161261067822757\n",
      "[EPOCH #5, step #740] loss: 3.1616946235198564\n",
      "[EPOCH #5, step #742] loss: 3.161941652503341\n",
      "[EPOCH #5, step #744] loss: 3.1623406976661426\n",
      "[EPOCH #5, step #746] loss: 3.1619047106828395\n",
      "[EPOCH #5, step #748] loss: 3.1621515267044904\n",
      "[EPOCH #5, step #750] loss: 3.162367108341222\n",
      "[EPOCH #5, step #752] loss: 3.1618893355487354\n",
      "[EPOCH #5, step #754] loss: 3.162289449868613\n",
      "[EPOCH #5, step #756] loss: 3.1624082643415687\n",
      "[EPOCH #5, step #758] loss: 3.1619382589387954\n",
      "[EPOCH #5, step #760] loss: 3.1621261094152224\n",
      "[EPOCH #5, step #762] loss: 3.162363503894831\n",
      "[EPOCH #5, step #764] loss: 3.1629894571366655\n",
      "[EPOCH #5, step #766] loss: 3.1633073447425177\n",
      "[EPOCH #5, step #768] loss: 3.163199598054427\n",
      "[EPOCH #5, step #770] loss: 3.1636110091178486\n",
      "[EPOCH #5, step #772] loss: 3.1640994989856557\n",
      "[EPOCH #5, step #774] loss: 3.1645883289460213\n",
      "[EPOCH #5, step #776] loss: 3.1638930472934876\n",
      "[EPOCH #5, step #778] loss: 3.1641651212939554\n",
      "[EPOCH #5, step #780] loss: 3.164586985462301\n",
      "[EPOCH #5, step #782] loss: 3.164150041638663\n",
      "[EPOCH #5, step #784] loss: 3.163709872239714\n",
      "[EPOCH #5, step #786] loss: 3.1634678304422614\n",
      "[EPOCH #5, step #788] loss: 3.1633317228808\n",
      "[EPOCH #5, step #790] loss: 3.162988881244973\n",
      "[EPOCH #5, step #792] loss: 3.163055581673698\n",
      "[EPOCH #5, step #794] loss: 3.163052866593847\n",
      "[EPOCH #5, step #796] loss: 3.16264787192925\n",
      "[EPOCH #5, step #798] loss: 3.162450491113866\n",
      "[EPOCH #5, step #800] loss: 3.1623455972111927\n",
      "[EPOCH #5, step #802] loss: 3.1627025227172587\n",
      "[EPOCH #5, step #804] loss: 3.1629320719227287\n",
      "[EPOCH #5, step #806] loss: 3.1629373959301423\n",
      "[EPOCH #5, step #808] loss: 3.162430467947452\n",
      "[EPOCH #5, step #810] loss: 3.16165194999422\n",
      "[EPOCH #5, step #812] loss: 3.16129240309327\n",
      "[EPOCH #5, step #814] loss: 3.161894559275153\n",
      "[EPOCH #5, step #816] loss: 3.161768450731163\n",
      "[EPOCH #5, step #818] loss: 3.162264640514667\n",
      "[EPOCH #5, step #820] loss: 3.1624798063238706\n",
      "[EPOCH #5, step #822] loss: 3.162447515408874\n",
      "[EPOCH #5, step #824] loss: 3.16174283692331\n",
      "[EPOCH #5, step #826] loss: 3.1615956907837393\n",
      "[EPOCH #5, step #828] loss: 3.161469708880987\n",
      "[EPOCH #5, step #830] loss: 3.1614062123350286\n",
      "[EPOCH #5, step #832] loss: 3.1618971275109775\n",
      "[EPOCH #5, step #834] loss: 3.1626592387696224\n",
      "[EPOCH #5, step #836] loss: 3.162654542581155\n",
      "[EPOCH #5, step #838] loss: 3.161565280784725\n",
      "[EPOCH #5, step #840] loss: 3.161108075084074\n",
      "[EPOCH #5, step #842] loss: 3.1607550239789246\n",
      "[EPOCH #5, step #844] loss: 3.1602725153138653\n",
      "[EPOCH #5, step #846] loss: 3.1601391153887284\n",
      "[EPOCH #5, step #848] loss: 3.159794101726321\n",
      "[EPOCH #5, step #850] loss: 3.159045640786302\n",
      "[EPOCH #5, step #852] loss: 3.159065443354223\n",
      "[EPOCH #5, step #854] loss: 3.1586773309094167\n",
      "[EPOCH #5, step #856] loss: 3.1593123444876565\n",
      "[EPOCH #5, step #858] loss: 3.159503192646262\n",
      "[EPOCH #5, step #860] loss: 3.159987357158417\n",
      "[EPOCH #5, step #862] loss: 3.159550698579808\n",
      "[EPOCH #5, step #864] loss: 3.1589927270922358\n",
      "[EPOCH #5, step #866] loss: 3.1593874903286205\n",
      "[EPOCH #5, step #868] loss: 3.159657466260693\n",
      "[EPOCH #5, step #870] loss: 3.15976025809103\n",
      "[EPOCH #5, step #872] loss: 3.1598977643872725\n",
      "[EPOCH #5, step #874] loss: 3.159732815333775\n",
      "[EPOCH #5, step #876] loss: 3.159892863803198\n",
      "[EPOCH #5, step #878] loss: 3.158771868316251\n",
      "[EPOCH #5, step #880] loss: 3.1584962453528242\n",
      "[EPOCH #5, step #882] loss: 3.1582518639137898\n",
      "[EPOCH #5, step #884] loss: 3.15807198023392\n",
      "[EPOCH #5, step #886] loss: 3.1584719173534612\n",
      "[EPOCH #5, step #888] loss: 3.1580227086460897\n",
      "[EPOCH #5, step #890] loss: 3.158595554221225\n",
      "[EPOCH #5, step #892] loss: 3.1592594151534263\n",
      "[EPOCH #5, step #894] loss: 3.1591621143191886\n",
      "[EPOCH #5, step #896] loss: 3.158806226458172\n",
      "[EPOCH #5, step #898] loss: 3.159145324726126\n",
      "[EPOCH #5, step #900] loss: 3.158074692272055\n",
      "[EPOCH #5, step #902] loss: 3.1581760828413175\n",
      "[EPOCH #5, step #904] loss: 3.158113299680678\n",
      "[EPOCH #5, step #906] loss: 3.1579073511121556\n",
      "[EPOCH #5, step #908] loss: 3.1580087598269793\n",
      "[EPOCH #5, step #910] loss: 3.157817988442799\n",
      "[EPOCH #5, step #912] loss: 3.1571395825451853\n",
      "[EPOCH #5, step #914] loss: 3.1571296129070343\n",
      "[EPOCH #5, step #916] loss: 3.156857854277383\n",
      "[EPOCH #5, step #918] loss: 3.155949083324096\n",
      "[EPOCH #5, step #920] loss: 3.155932950921737\n",
      "[EPOCH #5, step #922] loss: 3.1553449511915477\n",
      "[EPOCH #5, step #924] loss: 3.155493159680753\n",
      "[EPOCH #5, step #926] loss: 3.1551402139818014\n",
      "[EPOCH #5, step #928] loss: 3.1549709998111295\n",
      "[EPOCH #5, step #930] loss: 3.154905861353644\n",
      "[EPOCH #5, step #932] loss: 3.1545190841821995\n",
      "[EPOCH #5, step #934] loss: 3.153955217861237\n",
      "[EPOCH #5, step #936] loss: 3.1539848840605615\n",
      "[EPOCH #5, step #938] loss: 3.1536635324216116\n",
      "[EPOCH #5, step #940] loss: 3.1537289170985776\n",
      "[EPOCH #5, step #942] loss: 3.1533481829492565\n",
      "[EPOCH #5, step #944] loss: 3.153252297356015\n",
      "[EPOCH #5, step #946] loss: 3.1528818431096948\n",
      "[EPOCH #5, step #948] loss: 3.15285856304229\n",
      "[EPOCH #5, step #950] loss: 3.152592356147325\n",
      "[EPOCH #5, step #952] loss: 3.1527905359098067\n",
      "[EPOCH #5, step #954] loss: 3.1523859398527296\n",
      "[EPOCH #5, step #956] loss: 3.1522136260224984\n",
      "[EPOCH #5, step #958] loss: 3.152030770050224\n",
      "[EPOCH #5, step #960] loss: 3.15126678946115\n",
      "[EPOCH #5, step #962] loss: 3.150454382287379\n",
      "[EPOCH #5, step #964] loss: 3.1506128548340477\n",
      "[EPOCH #5, step #966] loss: 3.1504848148854836\n",
      "[EPOCH #5, step #968] loss: 3.1501715670429147\n",
      "[EPOCH #5, step #970] loss: 3.1502986538668\n",
      "[EPOCH #5, step #972] loss: 3.149994776403304\n",
      "[EPOCH #5, step #974] loss: 3.1502988203977926\n",
      "[EPOCH #5, step #976] loss: 3.150375843536158\n",
      "[EPOCH #5, step #978] loss: 3.1501118839700326\n",
      "[EPOCH #5, step #980] loss: 3.1500627297023263\n",
      "[EPOCH #5, step #982] loss: 3.1498525586521153\n",
      "[EPOCH #5, step #984] loss: 3.1507535351109386\n",
      "[EPOCH #5, step #986] loss: 3.150752448745774\n",
      "[EPOCH #5, step #988] loss: 3.151134492413219\n",
      "[EPOCH #5, step #990] loss: 3.1511457182925597\n",
      "[EPOCH #5, step #992] loss: 3.1510363403043717\n",
      "[EPOCH #5, step #994] loss: 3.1507758303503297\n",
      "[EPOCH #5, step #996] loss: 3.150621615537071\n",
      "[EPOCH #5, step #998] loss: 3.1507796866519078\n",
      "[EPOCH #5, step #1000] loss: 3.1509568605508718\n",
      "[EPOCH #5, step #1002] loss: 3.151503982001977\n",
      "[EPOCH #5, step #1004] loss: 3.1514866228720444\n",
      "[EPOCH #5, step #1006] loss: 3.151127773339841\n",
      "[EPOCH #5, step #1008] loss: 3.15127826162325\n",
      "[EPOCH #5, step #1010] loss: 3.1510765076155245\n",
      "[EPOCH #5, step #1012] loss: 3.1514930101396534\n",
      "[EPOCH #5, step #1014] loss: 3.1515824703160176\n",
      "[EPOCH #5, step #1016] loss: 3.151825808025274\n",
      "[EPOCH #5, step #1018] loss: 3.1518713063884882\n",
      "[EPOCH #5, step #1020] loss: 3.1525956521888903\n",
      "[EPOCH #5, step #1022] loss: 3.152582430536563\n",
      "[EPOCH #5, step #1024] loss: 3.152001154364609\n",
      "[EPOCH #5, step #1026] loss: 3.151721873093023\n",
      "[EPOCH #5, step #1028] loss: 3.1513345697994253\n",
      "[EPOCH #5, step #1030] loss: 3.1512865261703182\n",
      "[EPOCH #5, step #1032] loss: 3.1511652372698125\n",
      "[EPOCH #5, step #1034] loss: 3.1508126588259344\n",
      "[EPOCH #5, step #1036] loss: 3.1511989009989607\n",
      "[EPOCH #5, step #1038] loss: 3.1503096976110405\n",
      "[EPOCH #5, step #1040] loss: 3.1499267863494405\n",
      "[EPOCH #5, step #1042] loss: 3.1494949149719704\n",
      "[EPOCH #5, step #1044] loss: 3.149460902966951\n",
      "[EPOCH #5, step #1046] loss: 3.1490862540324303\n",
      "[EPOCH #5, step #1048] loss: 3.1491681181668554\n",
      "[EPOCH #5, step #1050] loss: 3.149265294751023\n",
      "[EPOCH #5, step #1052] loss: 3.14924951677422\n",
      "[EPOCH #5, step #1054] loss: 3.1485945217982287\n",
      "[EPOCH #5, step #1056] loss: 3.14871193760391\n",
      "[EPOCH #5, step #1058] loss: 3.1494880762721595\n",
      "[EPOCH #5, step #1060] loss: 3.149402661552753\n",
      "[EPOCH #5, step #1062] loss: 3.148667773545517\n",
      "[EPOCH #5, step #1064] loss: 3.1480260510959535\n",
      "[EPOCH #5, step #1066] loss: 3.1480518817454715\n",
      "[EPOCH #5, step #1068] loss: 3.1484580376752636\n",
      "[EPOCH #5, step #1070] loss: 3.14822085141913\n",
      "[EPOCH #5, step #1072] loss: 3.147908293634292\n",
      "[EPOCH #5, step #1074] loss: 3.1473622481767523\n",
      "[EPOCH #5, step #1076] loss: 3.147171652748724\n",
      "[EPOCH #5, step #1078] loss: 3.1466320027235595\n",
      "[EPOCH #5, step #1080] loss: 3.1463159672316303\n",
      "[EPOCH #5, step #1082] loss: 3.1461725862402665\n",
      "[EPOCH #5, step #1084] loss: 3.1459870784513413\n",
      "[EPOCH #5, step #1086] loss: 3.146142559305944\n",
      "[EPOCH #5, step #1088] loss: 3.1463902870157203\n",
      "[EPOCH #5, step #1090] loss: 3.1464599850634496\n",
      "[EPOCH #5, step #1092] loss: 3.146551590934328\n",
      "[EPOCH #5, step #1094] loss: 3.146517578760783\n",
      "[EPOCH #5, step #1096] loss: 3.1470925192889454\n",
      "[EPOCH #5, step #1098] loss: 3.1467034521701662\n",
      "[EPOCH #5, step #1100] loss: 3.146455608423356\n",
      "[EPOCH #5, step #1102] loss: 3.1469200176211345\n",
      "[EPOCH #5, step #1104] loss: 3.1470373488119825\n",
      "[EPOCH #5, step #1106] loss: 3.146977255768677\n",
      "[EPOCH #5, step #1108] loss: 3.14717218121287\n",
      "[EPOCH #5, step #1110] loss: 3.1471100379281167\n",
      "[EPOCH #5, step #1112] loss: 3.1468511917306192\n",
      "[EPOCH #5, step #1114] loss: 3.1466475315692715\n",
      "[EPOCH #5, step #1116] loss: 3.14628155058585\n",
      "[EPOCH #5, step #1118] loss: 3.146452900551599\n",
      "[EPOCH #5, step #1120] loss: 3.145849163036704\n",
      "[EPOCH #5, step #1122] loss: 3.145364813579583\n",
      "[EPOCH #5, step #1124] loss: 3.145376998477512\n",
      "[EPOCH #5, step #1126] loss: 3.145226463979604\n",
      "[EPOCH #5, step #1128] loss: 3.14553833366813\n",
      "[EPOCH #5, step #1130] loss: 3.1457447978271835\n",
      "[EPOCH #5, step #1132] loss: 3.1457883089070604\n",
      "[EPOCH #5, step #1134] loss: 3.1456399671831847\n",
      "[EPOCH #5, step #1136] loss: 3.145901114875639\n",
      "[EPOCH #5, step #1138] loss: 3.1463690450884356\n",
      "[EPOCH #5, step #1140] loss: 3.1466250590960465\n",
      "[EPOCH #5, step #1142] loss: 3.14621097647299\n",
      "[EPOCH #5, step #1144] loss: 3.1461336904217583\n",
      "[EPOCH #5, step #1146] loss: 3.145959200189752\n",
      "[EPOCH #5, step #1148] loss: 3.145883611640897\n",
      "[EPOCH #5, step #1150] loss: 3.1456166481992454\n",
      "[EPOCH #5, step #1152] loss: 3.1459453533963337\n",
      "[EPOCH #5, step #1154] loss: 3.145636193783252\n",
      "[EPOCH #5, step #1156] loss: 3.1449076824386055\n",
      "[EPOCH #5, step #1158] loss: 3.1445410072649214\n",
      "[EPOCH #5, step #1160] loss: 3.143955899147408\n",
      "[EPOCH #5, step #1162] loss: 3.144213052628272\n",
      "[EPOCH #5, step #1164] loss: 3.14413626961442\n",
      "[EPOCH #5, step #1166] loss: 3.1439366467303462\n",
      "[EPOCH #5, step #1168] loss: 3.1433999650594613\n",
      "[EPOCH #5, step #1170] loss: 3.143426681969738\n",
      "[EPOCH #5, step #1172] loss: 3.143301075376818\n",
      "[EPOCH #5, step #1174] loss: 3.1429937208459733\n",
      "[EPOCH #5, step #1176] loss: 3.142553927236021\n",
      "[EPOCH #5, step #1178] loss: 3.142281806499297\n",
      "[EPOCH #5, step #1180] loss: 3.1424744690403306\n",
      "[EPOCH #5, step #1182] loss: 3.143046250307046\n",
      "[EPOCH #5, step #1184] loss: 3.142999034390671\n",
      "[EPOCH #5, step #1186] loss: 3.1428229818850277\n",
      "[EPOCH #5, step #1188] loss: 3.142425224698823\n",
      "[EPOCH #5, step #1190] loss: 3.1422914181508306\n",
      "[EPOCH #5, step #1192] loss: 3.1426118617285628\n",
      "[EPOCH #5, step #1194] loss: 3.1423774294274622\n",
      "[EPOCH #5, step #1196] loss: 3.1421540946689563\n",
      "[EPOCH #5, step #1198] loss: 3.1416369472770915\n",
      "[EPOCH #5, step #1200] loss: 3.1417636791931205\n",
      "[EPOCH #5, step #1202] loss: 3.1415775739839447\n",
      "[EPOCH #5, step #1204] loss: 3.1418975084154437\n",
      "[EPOCH #5, step #1206] loss: 3.1417696454254376\n",
      "[EPOCH #5, step #1208] loss: 3.141356970279842\n",
      "[EPOCH #5, step #1210] loss: 3.141280802885035\n",
      "[EPOCH #5, step #1212] loss: 3.1410650513138734\n",
      "[EPOCH #5, step #1214] loss: 3.1409789895815123\n",
      "[EPOCH #5, step #1216] loss: 3.141156522583158\n",
      "[EPOCH #5, step #1218] loss: 3.1405484302793005\n",
      "[EPOCH #5, step #1220] loss: 3.140533801085826\n",
      "[EPOCH #5, step #1222] loss: 3.1410008102582307\n",
      "[EPOCH #5, step #1224] loss: 3.141168342901736\n",
      "[EPOCH #5, step #1226] loss: 3.1411534612899694\n",
      "[EPOCH #5, step #1228] loss: 3.140976362833655\n",
      "[EPOCH #5, step #1230] loss: 3.1408277346195\n",
      "[EPOCH #5, step #1232] loss: 3.1410535762489857\n",
      "[EPOCH #5, step #1234] loss: 3.141105705330729\n",
      "[EPOCH #5, step #1236] loss: 3.1407418495816577\n",
      "[EPOCH #5, step #1238] loss: 3.1402086661264144\n",
      "[EPOCH #5, step #1240] loss: 3.140002548070227\n",
      "[EPOCH #5, step #1242] loss: 3.1400506985542376\n",
      "[EPOCH #5, step #1244] loss: 3.1399340618087583\n",
      "[EPOCH #5, step #1246] loss: 3.1399750319498487\n",
      "[EPOCH #5, step #1248] loss: 3.1399062830892155\n",
      "[EPOCH #5, step #1250] loss: 3.139714098662781\n",
      "[EPOCH #5, step #1252] loss: 3.1393103932535182\n",
      "[EPOCH #5, step #1254] loss: 3.139088892841719\n",
      "[EPOCH #5, step #1256] loss: 3.1387408703399635\n",
      "[EPOCH #5, step #1258] loss: 3.1383633882493798\n",
      "[EPOCH #5, step #1260] loss: 3.1377789824846527\n",
      "[EPOCH #5, step #1262] loss: 3.1379580871509543\n",
      "[EPOCH #5, step #1264] loss: 3.1380608924292765\n",
      "[EPOCH #5, step #1266] loss: 3.1378182781523574\n",
      "[EPOCH #5, step #1268] loss: 3.1378736993851297\n",
      "[EPOCH #5, step #1270] loss: 3.138036325351166\n",
      "[EPOCH #5, step #1272] loss: 3.1380149213142126\n",
      "[EPOCH #5, step #1274] loss: 3.138456432866115\n",
      "[EPOCH #5, step #1276] loss: 3.1381594639974546\n",
      "[EPOCH #5, step #1278] loss: 3.138181033220209\n",
      "[EPOCH #5, step #1280] loss: 3.138058715644616\n",
      "[EPOCH #5, step #1282] loss: 3.1382230905843542\n",
      "[EPOCH #5, step #1284] loss: 3.1385427356230147\n",
      "[EPOCH #5, step #1286] loss: 3.1387786029750466\n",
      "[EPOCH #5, step #1288] loss: 3.1386422293421092\n",
      "[EPOCH #5, step #1290] loss: 3.1391270976949346\n",
      "[EPOCH #5, step #1292] loss: 3.139269229338691\n",
      "[EPOCH #5, step #1294] loss: 3.1394201350488258\n",
      "[EPOCH #5, step #1296] loss: 3.1397017002473357\n",
      "[EPOCH #5, step #1298] loss: 3.139785815790307\n",
      "[EPOCH #5, step #1300] loss: 3.139582329030957\n",
      "[EPOCH #5, step #1302] loss: 3.1398160393569254\n",
      "[EPOCH #5, step #1304] loss: 3.139344203700508\n",
      "[EPOCH #5, step #1306] loss: 3.1394834120764292\n",
      "[EPOCH #5, step #1308] loss: 3.1394040029043455\n",
      "[EPOCH #5, step #1310] loss: 3.139505478191885\n",
      "[EPOCH #5, step #1312] loss: 3.1394829508555544\n",
      "[EPOCH #5, step #1314] loss: 3.139282156396728\n",
      "[EPOCH #5, step #1316] loss: 3.139229693553985\n",
      "[EPOCH #5, step #1318] loss: 3.139286603052748\n",
      "[EPOCH #5, step #1320] loss: 3.1391212326572484\n",
      "[EPOCH #5, step #1322] loss: 3.139060478902458\n",
      "[EPOCH #5, step #1324] loss: 3.139220910162296\n",
      "[EPOCH #5, step #1326] loss: 3.1388652301319757\n",
      "[EPOCH #5, step #1328] loss: 3.1388314991987585\n",
      "[EPOCH #5, step #1330] loss: 3.1386613192010158\n",
      "[EPOCH #5, step #1332] loss: 3.138503874323016\n",
      "[EPOCH #5, step #1334] loss: 3.1382710103238565\n",
      "[EPOCH #5, step #1336] loss: 3.1384228447434075\n",
      "[EPOCH #5, step #1338] loss: 3.1388794517588314\n",
      "[EPOCH #5, step #1340] loss: 3.138788469685804\n",
      "[EPOCH #5, step #1342] loss: 3.138575455899214\n",
      "[EPOCH #5, step #1344] loss: 3.1384898758289097\n",
      "[EPOCH #5, step #1346] loss: 3.138653753063992\n",
      "[EPOCH #5, step #1348] loss: 3.1382189397903795\n",
      "[EPOCH #5, step #1350] loss: 3.1384420629610053\n",
      "[EPOCH #5, step #1352] loss: 3.1383521932191702\n",
      "[EPOCH #5, step #1354] loss: 3.1382335873987404\n",
      "[EPOCH #5, step #1356] loss: 3.137850928148454\n",
      "[EPOCH #5, step #1358] loss: 3.1383126822353025\n",
      "[EPOCH #5, step #1360] loss: 3.138497958894515\n",
      "[EPOCH #5, step #1362] loss: 3.1385602690416143\n",
      "[EPOCH #5, step #1364] loss: 3.1387664103245996\n",
      "[EPOCH #5, step #1366] loss: 3.1388311183792705\n",
      "[EPOCH #5, step #1368] loss: 3.1389968318604833\n",
      "[EPOCH #5, step #1370] loss: 3.1390687462885305\n",
      "[EPOCH #5, step #1372] loss: 3.1390064985146076\n",
      "[EPOCH #5, step #1374] loss: 3.139041991320523\n",
      "[EPOCH #5, step #1376] loss: 3.1393535623709705\n",
      "[EPOCH #5, step #1378] loss: 3.1383724006904563\n",
      "[EPOCH #5, step #1380] loss: 3.1381954691014715\n",
      "[EPOCH #5, step #1382] loss: 3.1379352964013707\n",
      "[EPOCH #5, step #1384] loss: 3.1375572736512884\n",
      "[EPOCH #5, step #1386] loss: 3.13743448515289\n",
      "[EPOCH #5, step #1388] loss: 3.1373486857005726\n",
      "[EPOCH #5, step #1390] loss: 3.1372409125697605\n",
      "[EPOCH #5, step #1392] loss: 3.1374158407404367\n",
      "[EPOCH #5, step #1394] loss: 3.137327552269009\n",
      "[EPOCH #5, step #1396] loss: 3.137076343906378\n",
      "[EPOCH #5, step #1398] loss: 3.1373817849108114\n",
      "[EPOCH #5, step #1400] loss: 3.137613540373046\n",
      "[EPOCH #5, step #1402] loss: 3.1373078080474355\n",
      "[EPOCH #5, step #1404] loss: 3.1374629302381196\n",
      "[EPOCH #5, step #1406] loss: 3.137384529730574\n",
      "[EPOCH #5, step #1408] loss: 3.137622877416076\n",
      "[EPOCH #5, step #1410] loss: 3.1375864538886207\n",
      "[EPOCH #5, step #1412] loss: 3.137409433775225\n",
      "[EPOCH #5, step #1414] loss: 3.13718200302798\n",
      "[EPOCH #5, step #1416] loss: 3.136828189511996\n",
      "[EPOCH #5, step #1418] loss: 3.1360921826137464\n",
      "[EPOCH #5, step #1420] loss: 3.136136146769567\n",
      "[EPOCH #5, step #1422] loss: 3.135962040761115\n",
      "[EPOCH #5, step #1424] loss: 3.1359097012302333\n",
      "[EPOCH #5, step #1426] loss: 3.1353473989129816\n",
      "[EPOCH #5, step #1428] loss: 3.1351704520725385\n",
      "[EPOCH #5, step #1430] loss: 3.1353285704185545\n",
      "[EPOCH #5, step #1432] loss: 3.135363796750566\n",
      "[EPOCH #5, step #1434] loss: 3.135257427534575\n",
      "[EPOCH #5, step #1436] loss: 3.135442935516209\n",
      "[EPOCH #5, step #1438] loss: 3.135431251068592\n",
      "[EPOCH #5, step #1440] loss: 3.1357538541268344\n",
      "[EPOCH #5, step #1442] loss: 3.135454440067315\n",
      "[EPOCH #5, step #1444] loss: 3.135485343207125\n",
      "[EPOCH #5, step #1446] loss: 3.1357294120867665\n",
      "[EPOCH #5, step #1448] loss: 3.135826647898672\n",
      "[EPOCH #5, step #1450] loss: 3.135413584094636\n",
      "[EPOCH #5, step #1452] loss: 3.1351758591979433\n",
      "[EPOCH #5, step #1454] loss: 3.1350675153568437\n",
      "[EPOCH #5, step #1456] loss: 3.1346819224059788\n",
      "[EPOCH #5, step #1458] loss: 3.1342428018165993\n",
      "[EPOCH #5, step #1460] loss: 3.1339946197859643\n",
      "[EPOCH #5, step #1462] loss: 3.1340482146953446\n",
      "[EPOCH #5, step #1464] loss: 3.1338707595148185\n",
      "[EPOCH #5, step #1466] loss: 3.133740196280034\n",
      "[EPOCH #5, step #1468] loss: 3.1333638016588434\n",
      "[EPOCH #5, step #1470] loss: 3.1329688421323296\n",
      "[EPOCH #5, step #1472] loss: 3.132842276586777\n",
      "[EPOCH #5, step #1474] loss: 3.132306808374696\n",
      "[EPOCH #5, step #1476] loss: 3.1319056199705915\n",
      "[EPOCH #5, step #1478] loss: 3.1317720940340363\n",
      "[EPOCH #5, step #1480] loss: 3.1313400596963805\n",
      "[EPOCH #5, step #1482] loss: 3.1309621162054433\n",
      "[EPOCH #5, step #1484] loss: 3.1306917007523354\n",
      "[EPOCH #5, step #1486] loss: 3.130494584953857\n",
      "[EPOCH #5, step #1488] loss: 3.1308757776858585\n",
      "[EPOCH #5, step #1490] loss: 3.1307544855364693\n",
      "[EPOCH #5, step #1492] loss: 3.1303935707294133\n",
      "[EPOCH #5, step #1494] loss: 3.130052420925536\n",
      "[EPOCH #5, step #1496] loss: 3.130126829695208\n",
      "[EPOCH #5, step #1498] loss: 3.129730891831483\n",
      "[EPOCH #5, step #1500] loss: 3.130174272621099\n",
      "[EPOCH #5, step #1502] loss: 3.1301742984863097\n",
      "[EPOCH #5, step #1504] loss: 3.1299080793247667\n",
      "[EPOCH #5, step #1506] loss: 3.129860290882994\n",
      "[EPOCH #5, step #1508] loss: 3.1300655501500274\n",
      "[EPOCH #5, step #1510] loss: 3.1302070458309292\n",
      "[EPOCH #5, step #1512] loss: 3.130314565855229\n",
      "[EPOCH #5, step #1514] loss: 3.1303334897107415\n",
      "[EPOCH #5, step #1516] loss: 3.1299332445518075\n",
      "[EPOCH #5, step #1518] loss: 3.1301367858901785\n",
      "[EPOCH #5, step #1520] loss: 3.130374805775228\n",
      "[EPOCH #5, step #1522] loss: 3.1304159012579715\n",
      "[EPOCH #5, step #1524] loss: 3.130013307665215\n",
      "[EPOCH #5, step #1526] loss: 3.129857321541217\n",
      "[EPOCH #5, step #1528] loss: 3.129433639225732\n",
      "[EPOCH #5, step #1530] loss: 3.1296637104976264\n",
      "[EPOCH #5, step #1532] loss: 3.129820801273951\n",
      "[EPOCH #5, step #1534] loss: 3.1298700554751417\n",
      "[EPOCH #5, step #1536] loss: 3.129961170929938\n",
      "[EPOCH #5, step #1538] loss: 3.1300250568352714\n",
      "[EPOCH #5, step #1540] loss: 3.1299645670198295\n",
      "[EPOCH #5, step #1542] loss: 3.1300027531149786\n",
      "[EPOCH #5, step #1544] loss: 3.130307032298116\n",
      "[EPOCH #5, step #1546] loss: 3.1306011123509276\n",
      "[EPOCH #5, step #1548] loss: 3.130434769365078\n",
      "[EPOCH #5, step #1550] loss: 3.130585103247106\n",
      "[EPOCH #5, step #1552] loss: 3.130498463003695\n",
      "[EPOCH #5, step #1554] loss: 3.1305874042572315\n",
      "[EPOCH #5, step #1556] loss: 3.130872960418329\n",
      "[EPOCH #5, step #1558] loss: 3.130573149596062\n",
      "[EPOCH #5, step #1560] loss: 3.1303239087123735\n",
      "[EPOCH #5, step #1562] loss: 3.130062641581891\n",
      "[EPOCH #5, step #1564] loss: 3.1302324720084096\n",
      "[EPOCH #5, step #1566] loss: 3.130219458164344\n",
      "[EPOCH #5, step #1568] loss: 3.130004918674058\n",
      "[EPOCH #5, step #1570] loss: 3.1300820474181488\n",
      "[EPOCH #5, step #1572] loss: 3.129601402034141\n",
      "[EPOCH #5, step #1574] loss: 3.1295764723278228\n",
      "[EPOCH #5, step #1576] loss: 3.129940141358554\n",
      "[EPOCH #5, step #1578] loss: 3.1300845668616364\n",
      "[EPOCH #5, step #1580] loss: 3.1298550803928267\n",
      "[EPOCH #5, step #1582] loss: 3.129642482806969\n",
      "[EPOCH #5, step #1584] loss: 3.1296740840286112\n",
      "[EPOCH #5, step #1586] loss: 3.129546107326428\n",
      "[EPOCH #5, step #1588] loss: 3.1296632941073783\n",
      "[EPOCH #5, step #1590] loss: 3.1295761206403307\n",
      "[EPOCH #5, step #1592] loss: 3.129929779762752\n",
      "[EPOCH #5, step #1594] loss: 3.129573920229012\n",
      "[EPOCH #5, step #1596] loss: 3.1296776075548283\n",
      "[EPOCH #5, step #1598] loss: 3.1293528244001854\n",
      "[EPOCH #5, step #1600] loss: 3.1292502500354162\n",
      "[EPOCH #5, step #1602] loss: 3.129476602272324\n",
      "[EPOCH #5, step #1604] loss: 3.1293447424689558\n",
      "[EPOCH #5, step #1606] loss: 3.1290019331470957\n",
      "[EPOCH #5, step #1608] loss: 3.1291245194678723\n",
      "[EPOCH #5, step #1610] loss: 3.1290343127437144\n",
      "[EPOCH #5, step #1612] loss: 3.128869382771955\n",
      "[EPOCH #5, step #1614] loss: 3.129061196389213\n",
      "[EPOCH #5, step #1616] loss: 3.129016008506827\n",
      "[EPOCH #5, step #1618] loss: 3.1291584582738188\n",
      "[EPOCH #5, step #1620] loss: 3.129166636769967\n",
      "[EPOCH #5, step #1622] loss: 3.1285818826248817\n",
      "[EPOCH #5, step #1624] loss: 3.1282995871030366\n",
      "[EPOCH #5, step #1626] loss: 3.1280912015067335\n",
      "[EPOCH #5, step #1628] loss: 3.1282664030296368\n",
      "[EPOCH #5, step #1630] loss: 3.1283057611606955\n",
      "[EPOCH #5, step #1632] loss: 3.1281948826901402\n",
      "[EPOCH #5, step #1634] loss: 3.127893902110762\n",
      "[EPOCH #5, step #1636] loss: 3.1277535855952165\n",
      "[EPOCH #5, step #1638] loss: 3.1276988263098184\n",
      "[EPOCH #5, step #1640] loss: 3.127673912019282\n",
      "[EPOCH #5, step #1642] loss: 3.127516517389568\n",
      "[EPOCH #5, step #1644] loss: 3.1274486335939913\n",
      "[EPOCH #5, step #1646] loss: 3.127201199169657\n",
      "[EPOCH #5, step #1648] loss: 3.1269066899093154\n",
      "[EPOCH #5, step #1650] loss: 3.1270522077757974\n",
      "[EPOCH #5, step #1652] loss: 3.1266687451458957\n",
      "[EPOCH #5, step #1654] loss: 3.126394188872277\n",
      "[EPOCH #5, step #1656] loss: 3.1260615449823668\n",
      "[EPOCH #5, step #1658] loss: 3.1260463103535234\n",
      "[EPOCH #5, step #1660] loss: 3.1264772209900102\n",
      "[EPOCH #5, step #1662] loss: 3.126436403409874\n",
      "[EPOCH #5, step #1664] loss: 3.126308380304514\n",
      "[EPOCH #5, step #1666] loss: 3.126476923720023\n",
      "[EPOCH #5, step #1668] loss: 3.1261524417001807\n",
      "[EPOCH #5, step #1670] loss: 3.126396214441223\n",
      "[EPOCH #5, step #1672] loss: 3.1263368393373003\n",
      "[EPOCH #5, step #1674] loss: 3.1263146999700746\n",
      "[EPOCH #5, step #1676] loss: 3.1266020100672614\n",
      "[EPOCH #5, step #1678] loss: 3.1269653272316384\n",
      "[EPOCH #5, step #1680] loss: 3.1268866140171574\n",
      "[EPOCH #5, step #1682] loss: 3.1268542515544473\n",
      "[EPOCH #5, step #1684] loss: 3.126568457776078\n",
      "[EPOCH #5, step #1686] loss: 3.126450812244246\n",
      "[EPOCH #5, step #1688] loss: 3.126493135523415\n",
      "[EPOCH #5, step #1690] loss: 3.1267642918456455\n",
      "[EPOCH #5, step #1692] loss: 3.126908138103902\n",
      "[EPOCH #5, step #1694] loss: 3.1266566173868546\n",
      "[EPOCH #5, step #1696] loss: 3.1266434597280632\n",
      "[EPOCH #5, step #1698] loss: 3.126516631661337\n",
      "[EPOCH #5, step #1700] loss: 3.126599059393657\n",
      "[EPOCH #5, step #1702] loss: 3.1266205690219273\n",
      "[EPOCH #5, step #1704] loss: 3.126413409660988\n",
      "[EPOCH #5, step #1706] loss: 3.1267458907888868\n",
      "[EPOCH #5, step #1708] loss: 3.1268046771384874\n",
      "[EPOCH #5, step #1710] loss: 3.1270761076014755\n",
      "[EPOCH #5, step #1712] loss: 3.126915028967916\n",
      "[EPOCH #5, step #1714] loss: 3.1268841871367252\n",
      "[EPOCH #5, step #1716] loss: 3.126849715766618\n",
      "[EPOCH #5, step #1718] loss: 3.1265639135350733\n",
      "[EPOCH #5, step #1720] loss: 3.1262649618422547\n",
      "[EPOCH #5, step #1722] loss: 3.1262026931820257\n",
      "[EPOCH #5, step #1724] loss: 3.1262923685709634\n",
      "[EPOCH #5, step #1726] loss: 3.126316148694982\n",
      "[EPOCH #5, step #1728] loss: 3.12651463476063\n",
      "[EPOCH #5, step #1730] loss: 3.1261934216211187\n",
      "[EPOCH #5, step #1732] loss: 3.1258283852843007\n",
      "[EPOCH #5, step #1734] loss: 3.125455492855149\n",
      "[EPOCH #5, step #1736] loss: 3.1256354327303413\n",
      "[EPOCH #5, step #1738] loss: 3.125537573845651\n",
      "[EPOCH #5, step #1740] loss: 3.1255680186388344\n",
      "[EPOCH #5, step #1742] loss: 3.125644076643357\n",
      "[EPOCH #5, step #1744] loss: 3.1255982220002094\n",
      "[EPOCH #5, step #1746] loss: 3.1256187602186722\n",
      "[EPOCH #5, step #1748] loss: 3.125599339323224\n",
      "[EPOCH #5, step #1750] loss: 3.125394931049227\n",
      "[EPOCH #5, step #1752] loss: 3.1259970735701166\n",
      "[EPOCH #5, step #1754] loss: 3.1259160376002644\n",
      "[EPOCH #5, step #1756] loss: 3.125809279638865\n",
      "[EPOCH #5, step #1758] loss: 3.1256333487219536\n",
      "[EPOCH #5, step #1760] loss: 3.125516420057861\n",
      "[EPOCH #5, step #1762] loss: 3.125476495690868\n",
      "[EPOCH #5, step #1764] loss: 3.125416757432327\n",
      "[EPOCH #5, step #1766] loss: 3.125366630430065\n",
      "[EPOCH #5, step #1768] loss: 3.1254631172404443\n",
      "[EPOCH #5, step #1770] loss: 3.1253040834445187\n",
      "[EPOCH #5, step #1772] loss: 3.1253202554538166\n",
      "[EPOCH #5, step #1774] loss: 3.1254888226952353\n",
      "[EPOCH #5, step #1776] loss: 3.1254872696146108\n",
      "[EPOCH #5, step #1778] loss: 3.1254012200053722\n",
      "[EPOCH #5, step #1780] loss: 3.1255443420121\n",
      "[EPOCH #5, step #1782] loss: 3.1252454962545877\n",
      "[EPOCH #5, step #1784] loss: 3.124676410958213\n",
      "[EPOCH #5, step #1786] loss: 3.1245988970971603\n",
      "[EPOCH #5, step #1788] loss: 3.1247726436964687\n",
      "[EPOCH #5, step #1790] loss: 3.124732320765288\n",
      "[EPOCH #5, step #1792] loss: 3.1246341776063304\n",
      "[EPOCH #5, step #1794] loss: 3.1244386459127442\n",
      "[EPOCH #5, step #1796] loss: 3.12412398685398\n",
      "[EPOCH #5, step #1798] loss: 3.1240781359436647\n",
      "[EPOCH #5, step #1800] loss: 3.1238982406078213\n",
      "[EPOCH #5, step #1802] loss: 3.123986723683506\n",
      "[EPOCH #5, step #1804] loss: 3.1240775601025104\n",
      "[EPOCH #5, step #1806] loss: 3.1242460304686688\n",
      "[EPOCH #5, step #1808] loss: 3.1241147578784023\n",
      "[EPOCH #5, step #1810] loss: 3.1242922106742332\n",
      "[EPOCH #5, step #1812] loss: 3.1243488525594723\n",
      "[EPOCH #5, step #1814] loss: 3.1240132542024304\n",
      "[EPOCH #5, step #1816] loss: 3.1235955855842468\n",
      "[EPOCH #5, step #1818] loss: 3.1233794909378143\n",
      "[EPOCH #5, step #1820] loss: 3.1231814470348747\n",
      "[EPOCH #5, step #1822] loss: 3.123183429077701\n",
      "[EPOCH #5, step #1824] loss: 3.1230240939414666\n",
      "[EPOCH #5, step #1826] loss: 3.1228488197598097\n",
      "[EPOCH #5, step #1828] loss: 3.1226708877275655\n",
      "[EPOCH #5, step #1830] loss: 3.122307463983966\n",
      "[EPOCH #5, step #1832] loss: 3.122445415422946\n",
      "[EPOCH #5, step #1834] loss: 3.122220208924213\n",
      "[EPOCH #5, step #1836] loss: 3.122157311141004\n",
      "[EPOCH #5, step #1838] loss: 3.122113256107017\n",
      "[EPOCH #5, step #1840] loss: 3.122060353829769\n",
      "[EPOCH #5, step #1842] loss: 3.121544922814703\n",
      "[EPOCH #5, step #1844] loss: 3.12138761479034\n",
      "[EPOCH #5, step #1846] loss: 3.121240302040955\n",
      "[EPOCH #5, step #1848] loss: 3.1214132787344453\n",
      "[EPOCH #5, step #1850] loss: 3.1210718644367303\n",
      "[EPOCH #5, step #1852] loss: 3.120444599770239\n",
      "[EPOCH #5, step #1854] loss: 3.120170710864414\n",
      "[EPOCH #5, step #1856] loss: 3.1198852819721097\n",
      "[EPOCH #5, step #1858] loss: 3.1197823992078186\n",
      "[EPOCH #5, step #1860] loss: 3.1195936082576563\n",
      "[EPOCH #5, step #1862] loss: 3.1191698864974198\n",
      "[EPOCH #5, step #1864] loss: 3.119126523659632\n",
      "[EPOCH #5, step #1866] loss: 3.1192412201452844\n",
      "[EPOCH #5, step #1868] loss: 3.119138072683825\n",
      "[EPOCH #5, step #1870] loss: 3.1189555622306755\n",
      "[EPOCH #5, step #1872] loss: 3.118882523713364\n",
      "[EPOCH #5, step #1874] loss: 3.11873021291097\n",
      "[EPOCH #5, step #1876] loss: 3.118570433567354\n",
      "[EPOCH #5, step #1878] loss: 3.1187124330988585\n",
      "[EPOCH #5, step #1880] loss: 3.118784998782704\n",
      "[EPOCH #5, step #1882] loss: 3.118518705261684\n",
      "[EPOCH #5, step #1884] loss: 3.118259177726523\n",
      "[EPOCH #5, step #1886] loss: 3.118004142511567\n",
      "[EPOCH #5, step #1888] loss: 3.1179916924304467\n",
      "[EPOCH #5, step #1890] loss: 3.11823903095905\n",
      "[EPOCH #5, step #1892] loss: 3.118484175526397\n",
      "[EPOCH #5, step #1894] loss: 3.118107535027577\n",
      "[EPOCH #5, step #1896] loss: 3.117853743438037\n",
      "[EPOCH #5, step #1898] loss: 3.118026039862771\n",
      "[EPOCH #5, step #1900] loss: 3.11807069610383\n",
      "[EPOCH #5, step #1902] loss: 3.118241652525292\n",
      "[EPOCH #5, step #1904] loss: 3.118307396871211\n",
      "[EPOCH #5, step #1906] loss: 3.1183094647021963\n",
      "[EPOCH #5, step #1908] loss: 3.118267140755671\n",
      "[EPOCH #5, step #1910] loss: 3.1178040836320253\n",
      "[EPOCH #5, step #1912] loss: 3.1175753804818536\n",
      "[EPOCH #5, step #1914] loss: 3.1175447533709573\n",
      "[EPOCH #5, step #1916] loss: 3.1176679033628654\n",
      "[EPOCH #5, step #1918] loss: 3.117612635486756\n",
      "[EPOCH #5, step #1920] loss: 3.1173459118322304\n",
      "[EPOCH #5, step #1922] loss: 3.1168456424727022\n",
      "[EPOCH #5, step #1924] loss: 3.1164127582698673\n",
      "[EPOCH #5, step #1926] loss: 3.1163174686619945\n",
      "[EPOCH #5, step #1928] loss: 3.1165128322757547\n",
      "[EPOCH #5, step #1930] loss: 3.1161983878670547\n",
      "[EPOCH #5, step #1932] loss: 3.1163346334497852\n",
      "[EPOCH #5, step #1934] loss: 3.116058824598327\n",
      "[EPOCH #5, step #1936] loss: 3.1159612018543847\n",
      "[EPOCH #5, step #1938] loss: 3.1157586787274476\n",
      "[EPOCH #5, step #1940] loss: 3.115559999012935\n",
      "[EPOCH #5, step #1942] loss: 3.1157243038291362\n",
      "[EPOCH #5, step #1944] loss: 3.116024440971316\n",
      "[EPOCH #5, step #1946] loss: 3.1164310686271133\n",
      "[EPOCH #5, step #1948] loss: 3.1166688758572167\n",
      "[EPOCH #5, step #1950] loss: 3.1163337629065033\n",
      "[EPOCH #5, step #1952] loss: 3.1161107704447772\n",
      "[EPOCH #5, step #1954] loss: 3.1158702989368487\n",
      "[EPOCH #5, step #1956] loss: 3.116032774739565\n",
      "[EPOCH #5, step #1958] loss: 3.116015908911619\n",
      "[EPOCH #5, step #1960] loss: 3.1159075763017654\n",
      "[EPOCH #5, step #1962] loss: 3.1154663878560855\n",
      "[EPOCH #5, step #1964] loss: 3.1156394690351026\n",
      "[EPOCH #5, step #1966] loss: 3.115458115624727\n",
      "[EPOCH #5, step #1968] loss: 3.1155893532620764\n",
      "[EPOCH #5, step #1970] loss: 3.1151859883666946\n",
      "[EPOCH #5, step #1972] loss: 3.1152429942001985\n",
      "[EPOCH #5, step #1974] loss: 3.115382309322116\n",
      "[EPOCH #5, step #1976] loss: 3.115497099852767\n",
      "[EPOCH #5, step #1978] loss: 3.115499639583393\n",
      "[EPOCH #5, step #1980] loss: 3.1155630018541394\n",
      "[EPOCH #5, step #1982] loss: 3.1153412231939703\n",
      "[EPOCH #5, step #1984] loss: 3.115302427229413\n",
      "[EPOCH #5, step #1986] loss: 3.1150875854684172\n",
      "[EPOCH #5, step #1988] loss: 3.1148483097523285\n",
      "[EPOCH #5, step #1990] loss: 3.1150429202108034\n",
      "[EPOCH #5, step #1992] loss: 3.1148523155074592\n",
      "[EPOCH #5, step #1994] loss: 3.114566983674702\n",
      "[EPOCH #5, step #1996] loss: 3.1145431213398007\n",
      "[EPOCH #5, step #1998] loss: 3.1142543905553013\n",
      "[EPOCH #5, step #2000] loss: 3.1139445639681305\n",
      "[EPOCH #5, step #2002] loss: 3.1140565662698276\n",
      "[EPOCH #5, step #2004] loss: 3.113903193105189\n",
      "[EPOCH #5, step #2006] loss: 3.1140001104076407\n",
      "[EPOCH #5, step #2008] loss: 3.1139739341792803\n",
      "[EPOCH #5, step #2010] loss: 3.113946535645404\n",
      "[EPOCH #5, step #2012] loss: 3.113763887255688\n",
      "[EPOCH #5, step #2014] loss: 3.1132366663173174\n",
      "[EPOCH #5, step #2016] loss: 3.112955276128025\n",
      "[EPOCH #5, step #2018] loss: 3.1128977590884945\n",
      "[EPOCH #5, step #2020] loss: 3.1126371727669255\n",
      "[EPOCH #5, step #2022] loss: 3.1124878501279247\n",
      "[EPOCH #5, step #2024] loss: 3.112622837137293\n",
      "[EPOCH #5, step #2026] loss: 3.11229113280979\n",
      "[EPOCH #5, step #2028] loss: 3.112092548077068\n",
      "[EPOCH #5, step #2030] loss: 3.11234893662656\n",
      "[EPOCH #5, step #2032] loss: 3.112382902749583\n",
      "[EPOCH #5, step #2034] loss: 3.1122815521109017\n",
      "[EPOCH #5, step #2036] loss: 3.1123173775249215\n",
      "[EPOCH #5, step #2038] loss: 3.1120000204775717\n",
      "[EPOCH #5, step #2040] loss: 3.1119004968683375\n",
      "[EPOCH #5, step #2042] loss: 3.111783844900668\n",
      "[EPOCH #5, step #2044] loss: 3.111518727654641\n",
      "[EPOCH #5, step #2046] loss: 3.1118581481368937\n",
      "[EPOCH #5, step #2048] loss: 3.1118413465322083\n",
      "[EPOCH #5, step #2050] loss: 3.1122016284827314\n",
      "[EPOCH #5, step #2052] loss: 3.112170578268639\n",
      "[EPOCH #5, step #2054] loss: 3.1120409254320056\n",
      "[EPOCH #5, step #2056] loss: 3.1121107630203464\n",
      "[EPOCH #5, step #2058] loss: 3.1122794841434724\n",
      "[EPOCH #5, step #2060] loss: 3.1123546182039235\n",
      "[EPOCH #5, step #2062] loss: 3.112334064182239\n",
      "[EPOCH #5, step #2064] loss: 3.1119713829446938\n",
      "[EPOCH #5, step #2066] loss: 3.1118547042095552\n",
      "[EPOCH #5, step #2068] loss: 3.111727479461773\n",
      "[EPOCH #5, step #2070] loss: 3.1120231500401814\n",
      "[EPOCH #5, step #2072] loss: 3.1118872483111324\n",
      "[EPOCH #5, step #2074] loss: 3.111648863252387\n",
      "[EPOCH #5, step #2076] loss: 3.1116160525687913\n",
      "[EPOCH #5, step #2078] loss: 3.111607502721261\n",
      "[EPOCH #5, step #2080] loss: 3.111935043037081\n",
      "[EPOCH #5, step #2082] loss: 3.1118130659862486\n",
      "[EPOCH #5, step #2084] loss: 3.111725584094187\n",
      "[EPOCH #5, step #2086] loss: 3.111511194940155\n",
      "[EPOCH #5, step #2088] loss: 3.1114062141036807\n",
      "[EPOCH #5, step #2090] loss: 3.1114417193096715\n",
      "[EPOCH #5, step #2092] loss: 3.1115442592449525\n",
      "[EPOCH #5, step #2094] loss: 3.1114051598068637\n",
      "[EPOCH #5, step #2096] loss: 3.111484592166695\n",
      "[EPOCH #5, step #2098] loss: 3.1112665506474686\n",
      "[EPOCH #5, step #2100] loss: 3.1107495555078795\n",
      "[EPOCH #5, step #2102] loss: 3.110757132456295\n",
      "[EPOCH #5, step #2104] loss: 3.11057069748994\n",
      "[EPOCH #5, step #2106] loss: 3.110754153940086\n",
      "[EPOCH #5, step #2108] loss: 3.110706801660935\n",
      "[EPOCH #5, step #2110] loss: 3.1106112092549854\n",
      "[EPOCH #5, step #2112] loss: 3.1107988762618577\n",
      "[EPOCH #5, step #2114] loss: 3.1109103937802867\n",
      "[EPOCH #5, step #2116] loss: 3.1111129150111325\n",
      "[EPOCH #5, step #2118] loss: 3.111006597687243\n",
      "[EPOCH #5, step #2120] loss: 3.1112117732487325\n",
      "[EPOCH #5, step #2122] loss: 3.1112589128613752\n",
      "[EPOCH #5, step #2124] loss: 3.111170125400319\n",
      "[EPOCH #5, step #2126] loss: 3.1109547497355217\n",
      "[EPOCH #5, step #2128] loss: 3.110890476621894\n",
      "[EPOCH #5, step #2130] loss: 3.111077789184019\n",
      "[EPOCH #5, step #2132] loss: 3.110934354864372\n",
      "[EPOCH #5, step #2134] loss: 3.110820526819877\n",
      "[EPOCH #5, step #2136] loss: 3.110698074506832\n",
      "[EPOCH #5, step #2138] loss: 3.110640100476451\n",
      "[EPOCH #5, step #2140] loss: 3.1104955088585573\n",
      "[EPOCH #5, step #2142] loss: 3.110328476060733\n",
      "[EPOCH #5, step #2144] loss: 3.1104630442488164\n",
      "[EPOCH #5, step #2146] loss: 3.1105129786519377\n",
      "[EPOCH #5, step #2148] loss: 3.110334064528908\n",
      "[EPOCH #5, step #2150] loss: 3.110225984962637\n",
      "[EPOCH #5, step #2152] loss: 3.1101270310002818\n",
      "[EPOCH #5, step #2154] loss: 3.109997600081902\n",
      "[EPOCH #5, step #2156] loss: 3.109869042203335\n",
      "[EPOCH #5, step #2158] loss: 3.109616303896672\n",
      "[EPOCH #5, step #2160] loss: 3.109583112940861\n",
      "[EPOCH #5, step #2162] loss: 3.1094836043473806\n",
      "[EPOCH #5, step #2164] loss: 3.1094611259310683\n",
      "[EPOCH #5, step #2166] loss: 3.109385741048548\n",
      "[EPOCH #5, step #2168] loss: 3.1093528848905727\n",
      "[EPOCH #5, step #2170] loss: 3.1091556731372973\n",
      "[EPOCH #5, step #2172] loss: 3.1087714653655896\n",
      "[EPOCH #5, step #2174] loss: 3.108766323067676\n",
      "[EPOCH #5, step #2176] loss: 3.108638422172662\n",
      "[EPOCH #5, step #2178] loss: 3.108671646043761\n",
      "[EPOCH #5, step #2180] loss: 3.1085053063051133\n",
      "[EPOCH #5, step #2182] loss: 3.1086391511446174\n",
      "[EPOCH #5, step #2184] loss: 3.108756620005557\n",
      "[EPOCH #5, step #2186] loss: 3.1085489074225614\n",
      "[EPOCH #5, step #2188] loss: 3.108304571702416\n",
      "[EPOCH #5, step #2190] loss: 3.1082830454105115\n",
      "[EPOCH #5, step #2192] loss: 3.10811055114266\n",
      "[EPOCH #5, step #2194] loss: 3.1079151053635026\n",
      "[EPOCH #5, step #2196] loss: 3.1080392638715657\n",
      "[EPOCH #5, step #2198] loss: 3.1076837201831884\n",
      "[EPOCH #5, step #2200] loss: 3.1075482430213257\n",
      "[EPOCH #5, step #2202] loss: 3.10762078146257\n",
      "[EPOCH #5, step #2204] loss: 3.107495241100285\n",
      "[EPOCH #5, step #2206] loss: 3.1075662738011873\n",
      "[EPOCH #5, step #2208] loss: 3.1075961620033787\n",
      "[EPOCH #5, step #2210] loss: 3.107651059307269\n",
      "[EPOCH #5, step #2212] loss: 3.1075494999374893\n",
      "[EPOCH #5, step #2214] loss: 3.107400203020255\n",
      "[EPOCH #5, step #2216] loss: 3.1072393946675603\n",
      "[EPOCH #5, step #2218] loss: 3.107064179119198\n",
      "[EPOCH #5, step #2220] loss: 3.1070432399962735\n",
      "[EPOCH #5, step #2222] loss: 3.1068125380302836\n",
      "[EPOCH #5, step #2224] loss: 3.1068512226490492\n",
      "[EPOCH #5, step #2226] loss: 3.1064813252677284\n",
      "[EPOCH #5, step #2228] loss: 3.1061437856247203\n",
      "[EPOCH #5, step #2230] loss: 3.1059013589622193\n",
      "[EPOCH #5, step #2232] loss: 3.1057615168042316\n",
      "[EPOCH #5, step #2234] loss: 3.10569192995161\n",
      "[EPOCH #5, step #2236] loss: 3.105623200262664\n",
      "[EPOCH #5, step #2238] loss: 3.1054025170205692\n",
      "[EPOCH #5, step #2240] loss: 3.1054835882318814\n",
      "[EPOCH #5, step #2242] loss: 3.1055683949351893\n",
      "[EPOCH #5, step #2244] loss: 3.105586173752103\n",
      "[EPOCH #5, step #2246] loss: 3.1055599246812386\n",
      "[EPOCH #5, step #2248] loss: 3.1054821972743096\n",
      "[EPOCH #5, step #2250] loss: 3.105337658652937\n",
      "[EPOCH #5, step #2252] loss: 3.1053264014095503\n",
      "[EPOCH #5, step #2254] loss: 3.1053752552379263\n",
      "[EPOCH #5, step #2256] loss: 3.105459033888317\n",
      "[EPOCH #5, step #2258] loss: 3.105310748245084\n",
      "[EPOCH #5, step #2260] loss: 3.105143672752465\n",
      "[EPOCH #5, step #2262] loss: 3.1052615194788453\n",
      "[EPOCH #5, step #2264] loss: 3.1051963673522143\n",
      "[EPOCH #5, step #2266] loss: 3.1055607975554667\n",
      "[EPOCH #5, step #2268] loss: 3.105364694107782\n",
      "[EPOCH #5, step #2270] loss: 3.105133179996781\n",
      "[EPOCH #5, step #2272] loss: 3.105374001009161\n",
      "[EPOCH #5, step #2274] loss: 3.1051795404035967\n",
      "[EPOCH #5, step #2276] loss: 3.1051120102588787\n",
      "[EPOCH #5, step #2278] loss: 3.1050650820286454\n",
      "[EPOCH #5, step #2280] loss: 3.1048651065600645\n",
      "[EPOCH #5, step #2282] loss: 3.1047161097491043\n",
      "[EPOCH #5, step #2284] loss: 3.1044316644480765\n",
      "[EPOCH #5, step #2286] loss: 3.1044044802164894\n",
      "[EPOCH #5, step #2288] loss: 3.1042844380494965\n",
      "[EPOCH #5, step #2290] loss: 3.104095518094699\n",
      "[EPOCH #5, step #2292] loss: 3.104159486070243\n",
      "[EPOCH #5, step #2294] loss: 3.1042963145345386\n",
      "[EPOCH #5, step #2296] loss: 3.1041014838021477\n",
      "[EPOCH #5, step #2298] loss: 3.104099321593508\n",
      "[EPOCH #5, step #2300] loss: 3.1036625514596197\n",
      "[EPOCH #5, step #2302] loss: 3.103492507922147\n",
      "[EPOCH #5, step #2304] loss: 3.1036500633926556\n",
      "[EPOCH #5, step #2306] loss: 3.103887973226507\n",
      "[EPOCH #5, step #2308] loss: 3.1039551510445325\n",
      "[EPOCH #5, step #2310] loss: 3.103882147088705\n",
      "[EPOCH #5, step #2312] loss: 3.103816672624884\n",
      "[EPOCH #5, step #2314] loss: 3.103787688714639\n",
      "[EPOCH #5, step #2316] loss: 3.103739910924234\n",
      "[EPOCH #5, step #2318] loss: 3.103753473492417\n",
      "[EPOCH #5, step #2320] loss: 3.1035388324446638\n",
      "[EPOCH #5, step #2322] loss: 3.1034820107514625\n",
      "[EPOCH #5, step #2324] loss: 3.1035803204198036\n",
      "[EPOCH #5, step #2326] loss: 3.103188728948084\n",
      "[EPOCH #5, step #2328] loss: 3.10295565029028\n",
      "[EPOCH #5, step #2330] loss: 3.1028113937950708\n",
      "[EPOCH #5, step #2332] loss: 3.102707894636335\n",
      "[EPOCH #5, step #2334] loss: 3.1026456837991065\n",
      "[EPOCH #5, step #2336] loss: 3.1024068751598355\n",
      "[EPOCH #5, step #2338] loss: 3.102185594775627\n",
      "[EPOCH #5, step #2340] loss: 3.1021920301526187\n",
      "[EPOCH #5, step #2342] loss: 3.101991429880446\n",
      "[EPOCH #5, step #2344] loss: 3.101921014338414\n",
      "[EPOCH #5, step #2346] loss: 3.1019196406698857\n",
      "[EPOCH #5, step #2348] loss: 3.1017276665260054\n",
      "[EPOCH #5, step #2350] loss: 3.101512690596457\n",
      "[EPOCH #5, step #2352] loss: 3.101404574491904\n",
      "[EPOCH #5, step #2354] loss: 3.1015994189398053\n",
      "[EPOCH #5, step #2356] loss: 3.101631754578601\n",
      "[EPOCH #5, step #2358] loss: 3.101310857831042\n",
      "[EPOCH #5, step #2360] loss: 3.101153036943183\n",
      "[EPOCH #5, step #2362] loss: 3.101073001130274\n",
      "[EPOCH #5, step #2364] loss: 3.1009285300781055\n",
      "[EPOCH #5, step #2366] loss: 3.101027326740995\n",
      "[EPOCH #5, step #2368] loss: 3.1009225526304878\n",
      "[EPOCH #5, step #2370] loss: 3.1009372207797665\n",
      "[EPOCH #5, step #2372] loss: 3.100950697228922\n",
      "[EPOCH #5, step #2374] loss: 3.1008034656926204\n",
      "[EPOCH #5, step #2376] loss: 3.1007643901454234\n",
      "[EPOCH #5, step #2378] loss: 3.100473933181827\n",
      "[EPOCH #5, step #2380] loss: 3.1002897476258773\n",
      "[EPOCH #5, step #2382] loss: 3.1000682013003806\n",
      "[EPOCH #5, step #2384] loss: 3.100115455971324\n",
      "[EPOCH #5, step #2386] loss: 3.100217848179677\n",
      "[EPOCH #5, step #2388] loss: 3.1001156461243853\n",
      "[EPOCH #5, step #2390] loss: 3.100068881091888\n",
      "[EPOCH #5, step #2392] loss: 3.0998609582101557\n",
      "[EPOCH #5, step #2394] loss: 3.0999019037457747\n",
      "[EPOCH #5, step #2396] loss: 3.0999877668690274\n",
      "[EPOCH #5, step #2398] loss: 3.099832213287703\n",
      "[EPOCH #5, step #2400] loss: 3.0997728641109634\n",
      "[EPOCH #5, step #2402] loss: 3.100044499126217\n",
      "[EPOCH #5, step #2404] loss: 3.099836708651759\n",
      "[EPOCH #5, step #2406] loss: 3.0997456413708044\n",
      "[EPOCH #5, step #2408] loss: 3.099519865104102\n",
      "[EPOCH #5, step #2410] loss: 3.0994991726125733\n",
      "[EPOCH #5, step #2412] loss: 3.0996078818456\n",
      "[EPOCH #5, step #2414] loss: 3.0995770853251896\n",
      "[EPOCH #5, step #2416] loss: 3.0997368911597962\n",
      "[EPOCH #5, step #2418] loss: 3.099686781105398\n",
      "[EPOCH #5, step #2420] loss: 3.0996574162944492\n",
      "[EPOCH #5, step #2422] loss: 3.0997109279325565\n",
      "[EPOCH #5, step #2424] loss: 3.099791476849428\n",
      "[EPOCH #5, step #2426] loss: 3.0998067393143773\n",
      "[EPOCH #5, step #2428] loss: 3.0997495314573347\n",
      "[EPOCH #5, step #2430] loss: 3.099570029853843\n",
      "[EPOCH #5, step #2432] loss: 3.0994870207998617\n",
      "[EPOCH #5, step #2434] loss: 3.0994662834143982\n",
      "[EPOCH #5, step #2436] loss: 3.0995320584082338\n",
      "[EPOCH #5, step #2438] loss: 3.099640822009798\n",
      "[EPOCH #5, step #2440] loss: 3.0991607377491053\n",
      "[EPOCH #5, step #2442] loss: 3.0989807701188914\n",
      "[EPOCH #5, step #2444] loss: 3.09885952175273\n",
      "[EPOCH #5, step #2446] loss: 3.0988249501063474\n",
      "[EPOCH #5, step #2448] loss: 3.098660632122191\n",
      "[EPOCH #5, step #2450] loss: 3.098352087706461\n",
      "[EPOCH #5, step #2452] loss: 3.098388263657294\n",
      "[EPOCH #5, step #2454] loss: 3.098353607931351\n",
      "[EPOCH #5, step #2456] loss: 3.098453172106155\n",
      "[EPOCH #5, step #2458] loss: 3.098650158687838\n",
      "[EPOCH #5, step #2460] loss: 3.098429726856794\n",
      "[EPOCH #5, step #2462] loss: 3.098452912468858\n",
      "[EPOCH #5, step #2464] loss: 3.0985843389561403\n",
      "[EPOCH #5, step #2466] loss: 3.098565354925155\n",
      "[EPOCH #5, step #2468] loss: 3.0984105461278197\n",
      "[EPOCH #5, step #2470] loss: 3.098341959201098\n",
      "[EPOCH #5, step #2472] loss: 3.0979983951223073\n",
      "[EPOCH #5, step #2474] loss: 3.0980009322696263\n",
      "[EPOCH #5, step #2476] loss: 3.097977029059652\n",
      "[EPOCH #5, step #2478] loss: 3.0981058666618564\n",
      "[EPOCH #5, step #2480] loss: 3.0979668706811663\n",
      "[EPOCH #5, step #2482] loss: 3.0979756801972407\n",
      "[EPOCH #5, step #2484] loss: 3.098290914692869\n",
      "[EPOCH #5, step #2486] loss: 3.098297917799725\n",
      "[EPOCH #5, step #2488] loss: 3.0983025132053204\n",
      "[EPOCH #5, step #2490] loss: 3.0983674300334294\n",
      "[EPOCH #5, step #2492] loss: 3.0983535660063937\n",
      "[EPOCH #5, step #2494] loss: 3.0983872142248976\n",
      "[EPOCH #5, step #2496] loss: 3.098390524130513\n",
      "[EPOCH #5, step #2498] loss: 3.098651485092023\n",
      "[EPOCH #5, elapsed time: 2526.295[sec]] loss: 3.098613303947449\n",
      "[EPOCH #6, step #0] loss: 3.18060302734375\n",
      "[EPOCH #6, step #2] loss: 2.886693239212036\n",
      "[EPOCH #6, step #4] loss: 3.0066898345947264\n",
      "[EPOCH #6, step #6] loss: 3.0005340235573903\n",
      "[EPOCH #6, step #8] loss: 3.0304783715142145\n",
      "[EPOCH #6, step #10] loss: 3.059947967529297\n",
      "[EPOCH #6, step #12] loss: 3.090504059424767\n",
      "[EPOCH #6, step #14] loss: 3.079897673924764\n",
      "[EPOCH #6, step #16] loss: 3.0880737585179947\n",
      "[EPOCH #6, step #18] loss: 3.080912602575202\n",
      "[EPOCH #6, step #20] loss: 3.0627367269425165\n",
      "[EPOCH #6, step #22] loss: 3.045351453449415\n",
      "[EPOCH #6, step #24] loss: 3.0410035037994385\n",
      "[EPOCH #6, step #26] loss: 3.063849608103434\n",
      "[EPOCH #6, step #28] loss: 3.0623868827162117\n",
      "[EPOCH #6, step #30] loss: 3.0651976677679245\n",
      "[EPOCH #6, step #32] loss: 3.051401969158288\n",
      "[EPOCH #6, step #34] loss: 3.046811328615461\n",
      "[EPOCH #6, step #36] loss: 3.059502466304882\n",
      "[EPOCH #6, step #38] loss: 3.054672516309298\n",
      "[EPOCH #6, step #40] loss: 3.05221919897126\n",
      "[EPOCH #6, step #42] loss: 3.0638924643050793\n",
      "[EPOCH #6, step #44] loss: 3.0485994815826416\n",
      "[EPOCH #6, step #46] loss: 3.0479860813059707\n",
      "[EPOCH #6, step #48] loss: 3.0348926223054224\n",
      "[EPOCH #6, step #50] loss: 3.0438399034387924\n",
      "[EPOCH #6, step #52] loss: 3.052253399255141\n",
      "[EPOCH #6, step #54] loss: 3.0520984779704703\n",
      "[EPOCH #6, step #56] loss: 3.056260895310787\n",
      "[EPOCH #6, step #58] loss: 3.0548566559613763\n",
      "[EPOCH #6, step #60] loss: 3.0580497726065214\n",
      "[EPOCH #6, step #62] loss: 3.0614378830743214\n",
      "[EPOCH #6, step #64] loss: 3.0758360936091496\n",
      "[EPOCH #6, step #66] loss: 3.0775430665087344\n",
      "[EPOCH #6, step #68] loss: 3.07578010144441\n",
      "[EPOCH #6, step #70] loss: 3.0775684605182057\n",
      "[EPOCH #6, step #72] loss: 3.079352277598969\n",
      "[EPOCH #6, step #74] loss: 3.0787149111429852\n",
      "[EPOCH #6, step #76] loss: 3.0779409687240404\n",
      "[EPOCH #6, step #78] loss: 3.0731508037712\n",
      "[EPOCH #6, step #80] loss: 3.0741176193143116\n",
      "[EPOCH #6, step #82] loss: 3.068159738218928\n",
      "[EPOCH #6, step #84] loss: 3.069817498150994\n",
      "[EPOCH #6, step #86] loss: 3.069859934949327\n",
      "[EPOCH #6, step #88] loss: 3.0677385812395075\n",
      "[EPOCH #6, step #90] loss: 3.0662905881693074\n",
      "[EPOCH #6, step #92] loss: 3.070396623303813\n",
      "[EPOCH #6, step #94] loss: 3.069283437728882\n",
      "[EPOCH #6, step #96] loss: 3.067901525300803\n",
      "[EPOCH #6, step #98] loss: 3.0681662101938265\n",
      "[EPOCH #6, step #100] loss: 3.067335834597597\n",
      "[EPOCH #6, step #102] loss: 3.0667468529303097\n",
      "[EPOCH #6, step #104] loss: 3.06777891431536\n",
      "[EPOCH #6, step #106] loss: 3.061253982169606\n",
      "[EPOCH #6, step #108] loss: 3.0609554303895443\n",
      "[EPOCH #6, step #110] loss: 3.055212439717473\n",
      "[EPOCH #6, step #112] loss: 3.0577909545560855\n",
      "[EPOCH #6, step #114] loss: 3.0544552367666493\n",
      "[EPOCH #6, step #116] loss: 3.053147452509301\n",
      "[EPOCH #6, step #118] loss: 3.058419744507605\n",
      "[EPOCH #6, step #120] loss: 3.058635979644523\n",
      "[EPOCH #6, step #122] loss: 3.0555350043909337\n",
      "[EPOCH #6, step #124] loss: 3.0587965393066407\n",
      "[EPOCH #6, step #126] loss: 3.0627746544485017\n",
      "[EPOCH #6, step #128] loss: 3.0641303062438965\n",
      "[EPOCH #6, step #130] loss: 3.0597689825159904\n",
      "[EPOCH #6, step #132] loss: 3.0606245080331216\n",
      "[EPOCH #6, step #134] loss: 3.0599725670284696\n",
      "[EPOCH #6, step #136] loss: 3.0561064716673245\n",
      "[EPOCH #6, step #138] loss: 3.0520771287328046\n",
      "[EPOCH #6, step #140] loss: 3.053117386838223\n",
      "[EPOCH #6, step #142] loss: 3.053462898814595\n",
      "[EPOCH #6, step #144] loss: 3.0543673696189093\n",
      "[EPOCH #6, step #146] loss: 3.0532550763110726\n",
      "[EPOCH #6, step #148] loss: 3.0535234492897185\n",
      "[EPOCH #6, step #150] loss: 3.056032146049651\n",
      "[EPOCH #6, step #152] loss: 3.052873351215537\n",
      "[EPOCH #6, step #154] loss: 3.0532413436520485\n",
      "[EPOCH #6, step #156] loss: 3.0541091193059446\n",
      "[EPOCH #6, step #158] loss: 3.050084093081876\n",
      "[EPOCH #6, step #160] loss: 3.0521298861651687\n",
      "[EPOCH #6, step #162] loss: 3.0503625430943777\n",
      "[EPOCH #6, step #164] loss: 3.0499336300474225\n",
      "[EPOCH #6, step #166] loss: 3.0456644646421878\n",
      "[EPOCH #6, step #168] loss: 3.0437646250753008\n",
      "[EPOCH #6, step #170] loss: 3.0415445057272215\n",
      "[EPOCH #6, step #172] loss: 3.0403857575675657\n",
      "[EPOCH #6, step #174] loss: 3.0413032504490443\n",
      "[EPOCH #6, step #176] loss: 3.0398691212390103\n",
      "[EPOCH #6, step #178] loss: 3.043363469938992\n",
      "[EPOCH #6, step #180] loss: 3.044139818591966\n",
      "[EPOCH #6, step #182] loss: 3.0439228581600504\n",
      "[EPOCH #6, step #184] loss: 3.045106405825228\n",
      "[EPOCH #6, step #186] loss: 3.043460408634043\n",
      "[EPOCH #6, step #188] loss: 3.047056001330179\n",
      "[EPOCH #6, step #190] loss: 3.046700914492782\n",
      "[EPOCH #6, step #192] loss: 3.0476039827178796\n",
      "[EPOCH #6, step #194] loss: 3.0461736312279335\n",
      "[EPOCH #6, step #196] loss: 3.0458456683279898\n",
      "[EPOCH #6, step #198] loss: 3.046444716765054\n",
      "[EPOCH #6, step #200] loss: 3.047301800096806\n",
      "[EPOCH #6, step #202] loss: 3.044892550689246\n",
      "[EPOCH #6, step #204] loss: 3.0431177267214147\n",
      "[EPOCH #6, step #206] loss: 3.040346798689469\n",
      "[EPOCH #6, step #208] loss: 3.0417294878708687\n",
      "[EPOCH #6, step #210] loss: 3.039750241555309\n",
      "[EPOCH #6, step #212] loss: 3.038656277275981\n",
      "[EPOCH #6, step #214] loss: 3.038387184364851\n",
      "[EPOCH #6, step #216] loss: 3.037643326042984\n",
      "[EPOCH #6, step #218] loss: 3.0364447543610176\n",
      "[EPOCH #6, step #220] loss: 3.040829779335816\n",
      "[EPOCH #6, step #222] loss: 3.0384109479964048\n",
      "[EPOCH #6, step #224] loss: 3.0368039247724745\n",
      "[EPOCH #6, step #226] loss: 3.0371266566709276\n",
      "[EPOCH #6, step #228] loss: 3.037883234856951\n",
      "[EPOCH #6, step #230] loss: 3.03674975308505\n",
      "[EPOCH #6, step #232] loss: 3.033732603547911\n",
      "[EPOCH #6, step #234] loss: 3.0334127537747646\n",
      "[EPOCH #6, step #236] loss: 3.0349464346084916\n",
      "[EPOCH #6, step #238] loss: 3.0363129262644875\n",
      "[EPOCH #6, step #240] loss: 3.036481573373945\n",
      "[EPOCH #6, step #242] loss: 3.037721477908853\n",
      "[EPOCH #6, step #244] loss: 3.0387880821617284\n",
      "[EPOCH #6, step #246] loss: 3.03885906814081\n",
      "[EPOCH #6, step #248] loss: 3.037692008727047\n",
      "[EPOCH #6, step #250] loss: 3.0380258759654377\n",
      "[EPOCH #6, step #252] loss: 3.039093395466861\n",
      "[EPOCH #6, step #254] loss: 3.0379001636131138\n",
      "[EPOCH #6, step #256] loss: 3.035909308533724\n",
      "[EPOCH #6, step #258] loss: 3.034352510592192\n",
      "[EPOCH #6, step #260] loss: 3.033215383003498\n",
      "[EPOCH #6, step #262] loss: 3.034331327155516\n",
      "[EPOCH #6, step #264] loss: 3.032577158370108\n",
      "[EPOCH #6, step #266] loss: 3.032922991206137\n",
      "[EPOCH #6, step #268] loss: 3.0324911707839113\n",
      "[EPOCH #6, step #270] loss: 3.0301403313105397\n",
      "[EPOCH #6, step #272] loss: 3.028615413567959\n",
      "[EPOCH #6, step #274] loss: 3.0270696943456477\n",
      "[EPOCH #6, step #276] loss: 3.026054977940308\n",
      "[EPOCH #6, step #278] loss: 3.0249786718771876\n",
      "[EPOCH #6, step #280] loss: 3.023443015020513\n",
      "[EPOCH #6, step #282] loss: 3.0224015055612625\n",
      "[EPOCH #6, step #284] loss: 3.0217350089759156\n",
      "[EPOCH #6, step #286] loss: 3.0232232580616913\n",
      "[EPOCH #6, step #288] loss: 3.0219361757324643\n",
      "[EPOCH #6, step #290] loss: 3.02159700524766\n",
      "[EPOCH #6, step #292] loss: 3.021301246747222\n",
      "[EPOCH #6, step #294] loss: 3.0222233085309043\n",
      "[EPOCH #6, step #296] loss: 3.0219020177218248\n",
      "[EPOCH #6, step #298] loss: 3.0210040413017656\n",
      "[EPOCH #6, step #300] loss: 3.018190462327875\n",
      "[EPOCH #6, step #302] loss: 3.0159532040259234\n",
      "[EPOCH #6, step #304] loss: 3.0144004290221167\n",
      "[EPOCH #6, step #306] loss: 3.0152571729417734\n",
      "[EPOCH #6, step #308] loss: 3.015516796544146\n",
      "[EPOCH #6, step #310] loss: 3.0158467630098102\n",
      "[EPOCH #6, step #312] loss: 3.0138389401542494\n",
      "[EPOCH #6, step #314] loss: 3.0141596673026916\n",
      "[EPOCH #6, step #316] loss: 3.0152622292094424\n",
      "[EPOCH #6, step #318] loss: 3.0172559744138328\n",
      "[EPOCH #6, step #320] loss: 3.01840377819501\n",
      "[EPOCH #6, step #322] loss: 3.0177751406796576\n",
      "[EPOCH #6, step #324] loss: 3.0174305490347053\n",
      "[EPOCH #6, step #326] loss: 3.0166962474857995\n",
      "[EPOCH #6, step #328] loss: 3.015829003690586\n",
      "[EPOCH #6, step #330] loss: 3.014383757582604\n",
      "[EPOCH #6, step #332] loss: 3.015667534447289\n",
      "[EPOCH #6, step #334] loss: 3.015068330337752\n",
      "[EPOCH #6, step #336] loss: 3.014099222969938\n",
      "[EPOCH #6, step #338] loss: 3.012514940756964\n",
      "[EPOCH #6, step #340] loss: 3.012091794671201\n",
      "[EPOCH #6, step #342] loss: 3.0121501277556573\n",
      "[EPOCH #6, step #344] loss: 3.011337808249653\n",
      "[EPOCH #6, step #346] loss: 3.010463370369903\n",
      "[EPOCH #6, step #348] loss: 3.0092262012569133\n",
      "[EPOCH #6, step #350] loss: 3.0088777019087747\n",
      "[EPOCH #6, step #352] loss: 3.008913021249744\n",
      "[EPOCH #6, step #354] loss: 3.0101601009637537\n",
      "[EPOCH #6, step #356] loss: 3.0102413194854054\n",
      "[EPOCH #6, step #358] loss: 3.010649954044055\n",
      "[EPOCH #6, step #360] loss: 3.009812195215199\n",
      "[EPOCH #6, step #362] loss: 3.010515013345345\n",
      "[EPOCH #6, step #364] loss: 3.009098768234253\n",
      "[EPOCH #6, step #366] loss: 3.008991092687082\n",
      "[EPOCH #6, step #368] loss: 3.0092662046272256\n",
      "[EPOCH #6, step #370] loss: 3.0095571488383004\n",
      "[EPOCH #6, step #372] loss: 3.0084448237840995\n",
      "[EPOCH #6, step #374] loss: 3.0074470049540203\n",
      "[EPOCH #6, step #376] loss: 3.0086425185519756\n",
      "[EPOCH #6, step #378] loss: 3.006925855274251\n",
      "[EPOCH #6, step #380] loss: 3.0061347009003008\n",
      "[EPOCH #6, step #382] loss: 3.005443528177844\n",
      "[EPOCH #6, step #384] loss: 3.0059382636825758\n",
      "[EPOCH #6, step #386] loss: 3.0057412080986556\n",
      "[EPOCH #6, step #388] loss: 3.004220346558676\n",
      "[EPOCH #6, step #390] loss: 3.004254838694697\n",
      "[EPOCH #6, step #392] loss: 3.004065053760247\n",
      "[EPOCH #6, step #394] loss: 3.0038240052476715\n",
      "[EPOCH #6, step #396] loss: 3.003878211494657\n",
      "[EPOCH #6, step #398] loss: 3.0055065411971627\n",
      "[EPOCH #6, step #400] loss: 3.004357596585281\n",
      "[EPOCH #6, step #402] loss: 3.003236299117209\n",
      "[EPOCH #6, step #404] loss: 3.0037683133725768\n",
      "[EPOCH #6, step #406] loss: 3.0043098657078473\n",
      "[EPOCH #6, step #408] loss: 3.0038450382158053\n",
      "[EPOCH #6, step #410] loss: 3.002980099397274\n",
      "[EPOCH #6, step #412] loss: 3.0047522832348617\n",
      "[EPOCH #6, step #414] loss: 3.0041474566402204\n",
      "[EPOCH #6, step #416] loss: 3.0038034835879466\n",
      "[EPOCH #6, step #418] loss: 3.0022456327315448\n",
      "[EPOCH #6, step #420] loss: 3.001421526322172\n",
      "[EPOCH #6, step #422] loss: 3.0014139010832945\n",
      "[EPOCH #6, step #424] loss: 3.0010767886217904\n",
      "[EPOCH #6, step #426] loss: 3.0020355977275055\n",
      "[EPOCH #6, step #428] loss: 3.0017118287253215\n",
      "[EPOCH #6, step #430] loss: 3.0022978019271815\n",
      "[EPOCH #6, step #432] loss: 3.002063888875772\n",
      "[EPOCH #6, step #434] loss: 3.00001378991138\n",
      "[EPOCH #6, step #436] loss: 3.00025685264535\n",
      "[EPOCH #6, step #438] loss: 3.0019007999967604\n",
      "[EPOCH #6, step #440] loss: 3.001896416519234\n",
      "[EPOCH #6, step #442] loss: 2.999442602118843\n",
      "[EPOCH #6, step #444] loss: 2.998736572265625\n",
      "[EPOCH #6, step #446] loss: 2.9990161259969077\n",
      "[EPOCH #6, step #448] loss: 2.998355665822868\n",
      "[EPOCH #6, step #450] loss: 2.9995790421301933\n",
      "[EPOCH #6, step #452] loss: 3.000285913875824\n",
      "[EPOCH #6, step #454] loss: 2.999869833411751\n",
      "[EPOCH #6, step #456] loss: 3.001235669760005\n",
      "[EPOCH #6, step #458] loss: 3.00107064070525\n",
      "[EPOCH #6, step #460] loss: 3.001762359106101\n",
      "[EPOCH #6, step #462] loss: 3.002896728577418\n",
      "[EPOCH #6, step #464] loss: 3.0029257123188304\n",
      "[EPOCH #6, step #466] loss: 3.0037338733673096\n",
      "[EPOCH #6, step #468] loss: 3.003202537483752\n",
      "[EPOCH #6, step #470] loss: 3.004147598950979\n",
      "[EPOCH #6, step #472] loss: 3.0047236295381508\n",
      "[EPOCH #6, step #474] loss: 3.005607743012278\n",
      "[EPOCH #6, step #476] loss: 3.0070994380135208\n",
      "[EPOCH #6, step #478] loss: 3.0078409489609754\n",
      "[EPOCH #6, step #480] loss: 3.0087956693217066\n",
      "[EPOCH #6, step #482] loss: 3.0073667688152557\n",
      "[EPOCH #6, step #484] loss: 3.0081077968951355\n",
      "[EPOCH #6, step #486] loss: 3.008313607875816\n",
      "[EPOCH #6, step #488] loss: 3.009514176772416\n",
      "[EPOCH #6, step #490] loss: 3.0107402447042055\n",
      "[EPOCH #6, step #492] loss: 3.0103641383304556\n",
      "[EPOCH #6, step #494] loss: 3.0099063247141213\n",
      "[EPOCH #6, step #496] loss: 3.0089398423430906\n",
      "[EPOCH #6, step #498] loss: 3.0089092923548515\n",
      "[EPOCH #6, step #500] loss: 3.0083712251362447\n",
      "[EPOCH #6, step #502] loss: 3.0081480089760206\n",
      "[EPOCH #6, step #504] loss: 3.00807468395422\n",
      "[EPOCH #6, step #506] loss: 3.0071114402786043\n",
      "[EPOCH #6, step #508] loss: 3.008334978624505\n",
      "[EPOCH #6, step #510] loss: 3.009432512720037\n",
      "[EPOCH #6, step #512] loss: 3.0098001640907275\n",
      "[EPOCH #6, step #514] loss: 3.0097869248066136\n",
      "[EPOCH #6, step #516] loss: 3.009529926329563\n",
      "[EPOCH #6, step #518] loss: 3.00886358874841\n",
      "[EPOCH #6, step #520] loss: 3.0085622930252165\n",
      "[EPOCH #6, step #522] loss: 3.0085503316518225\n",
      "[EPOCH #6, step #524] loss: 3.0092629464467366\n",
      "[EPOCH #6, step #526] loss: 3.0088716593820184\n",
      "[EPOCH #6, step #528] loss: 3.009090246009466\n",
      "[EPOCH #6, step #530] loss: 3.00972198542004\n",
      "[EPOCH #6, step #532] loss: 3.0094492265475847\n",
      "[EPOCH #6, step #534] loss: 3.009669089985785\n",
      "[EPOCH #6, step #536] loss: 3.0086300479633183\n",
      "[EPOCH #6, step #538] loss: 3.00943703509881\n",
      "[EPOCH #6, step #540] loss: 3.0075908456403977\n",
      "[EPOCH #6, step #542] loss: 3.0076104211543804\n",
      "[EPOCH #6, step #544] loss: 3.007688423909179\n",
      "[EPOCH #6, step #546] loss: 3.0078765840373483\n",
      "[EPOCH #6, step #548] loss: 3.0071552677015574\n",
      "[EPOCH #6, step #550] loss: 3.007026790490817\n",
      "[EPOCH #6, step #552] loss: 3.0061310691385112\n",
      "[EPOCH #6, step #554] loss: 3.005453040148761\n",
      "[EPOCH #6, step #556] loss: 3.0045474727021086\n",
      "[EPOCH #6, step #558] loss: 3.0034870320867766\n",
      "[EPOCH #6, step #560] loss: 3.0040365876148516\n",
      "[EPOCH #6, step #562] loss: 3.0038171881680804\n",
      "[EPOCH #6, step #564] loss: 3.003955478583817\n",
      "[EPOCH #6, step #566] loss: 3.00326521056039\n",
      "[EPOCH #6, step #568] loss: 3.0024156235223916\n",
      "[EPOCH #6, step #570] loss: 3.0015631853594673\n",
      "[EPOCH #6, step #572] loss: 3.00075840034618\n",
      "[EPOCH #6, step #574] loss: 2.9986898156870967\n",
      "[EPOCH #6, step #576] loss: 2.998000446597253\n",
      "[EPOCH #6, step #578] loss: 2.9991825759307913\n",
      "[EPOCH #6, step #580] loss: 2.9987472888729862\n",
      "[EPOCH #6, step #582] loss: 2.9979390271940933\n",
      "[EPOCH #6, step #584] loss: 2.9981906780829797\n",
      "[EPOCH #6, step #586] loss: 2.9988612137620656\n",
      "[EPOCH #6, step #588] loss: 2.998159041024226\n",
      "[EPOCH #6, step #590] loss: 2.9988431575536323\n",
      "[EPOCH #6, step #592] loss: 2.9988061251970004\n",
      "[EPOCH #6, step #594] loss: 2.9980980099750165\n",
      "[EPOCH #6, step #596] loss: 2.997801101786807\n",
      "[EPOCH #6, step #598] loss: 2.9979176795940368\n",
      "[EPOCH #6, step #600] loss: 2.9966492049904314\n",
      "[EPOCH #6, step #602] loss: 2.9966558370226455\n",
      "[EPOCH #6, step #604] loss: 2.997021758654886\n",
      "[EPOCH #6, step #606] loss: 2.9979864718297367\n",
      "[EPOCH #6, step #608] loss: 2.9973469074136516\n",
      "[EPOCH #6, step #610] loss: 2.9979087104578848\n",
      "[EPOCH #6, step #612] loss: 2.997267300308626\n",
      "[EPOCH #6, step #614] loss: 2.9971422838970896\n",
      "[EPOCH #6, step #616] loss: 2.9961008809180854\n",
      "[EPOCH #6, step #618] loss: 2.9959789620462645\n",
      "[EPOCH #6, step #620] loss: 2.995818643754231\n",
      "[EPOCH #6, step #622] loss: 2.995854411423685\n",
      "[EPOCH #6, step #624] loss: 2.996456579589844\n",
      "[EPOCH #6, step #626] loss: 2.995281894051097\n",
      "[EPOCH #6, step #628] loss: 2.995670357265988\n",
      "[EPOCH #6, step #630] loss: 2.994787436846508\n",
      "[EPOCH #6, step #632] loss: 2.993495761877364\n",
      "[EPOCH #6, step #634] loss: 2.9940791561847595\n",
      "[EPOCH #6, step #636] loss: 2.9938580974866307\n",
      "[EPOCH #6, step #638] loss: 2.992954218704749\n",
      "[EPOCH #6, step #640] loss: 2.994009754773049\n",
      "[EPOCH #6, step #642] loss: 2.993295976941359\n",
      "[EPOCH #6, step #644] loss: 2.9934647648833517\n",
      "[EPOCH #6, step #646] loss: 2.9934463983709696\n",
      "[EPOCH #6, step #648] loss: 2.993371163017026\n",
      "[EPOCH #6, step #650] loss: 2.9920466535834858\n",
      "[EPOCH #6, step #652] loss: 2.991213236249424\n",
      "[EPOCH #6, step #654] loss: 2.9912145625543958\n",
      "[EPOCH #6, step #656] loss: 2.9915078618936524\n",
      "[EPOCH #6, step #658] loss: 2.9914932800894984\n",
      "[EPOCH #6, step #660] loss: 2.9918393691981975\n",
      "[EPOCH #6, step #662] loss: 2.9924618108240186\n",
      "[EPOCH #6, step #664] loss: 2.99219817398186\n",
      "[EPOCH #6, step #666] loss: 2.9927526063647405\n",
      "[EPOCH #6, step #668] loss: 2.9910627152709504\n",
      "[EPOCH #6, step #670] loss: 2.9909496161692544\n",
      "[EPOCH #6, step #672] loss: 2.9900846020782152\n",
      "[EPOCH #6, step #674] loss: 2.9896093209584556\n",
      "[EPOCH #6, step #676] loss: 2.989772598007405\n",
      "[EPOCH #6, step #678] loss: 2.9894124559169315\n",
      "[EPOCH #6, step #680] loss: 2.988238125645642\n",
      "[EPOCH #6, step #682] loss: 2.988551626791891\n",
      "[EPOCH #6, step #684] loss: 2.9884732538766237\n",
      "[EPOCH #6, step #686] loss: 2.9880730689352775\n",
      "[EPOCH #6, step #688] loss: 2.987468139180597\n",
      "[EPOCH #6, step #690] loss: 2.9875063571847122\n",
      "[EPOCH #6, step #692] loss: 2.987655931048923\n",
      "[EPOCH #6, step #694] loss: 2.98740023022933\n",
      "[EPOCH #6, step #696] loss: 2.987267709017826\n",
      "[EPOCH #6, step #698] loss: 2.9867162663537545\n",
      "[EPOCH #6, step #700] loss: 2.9867944414707464\n",
      "[EPOCH #6, step #702] loss: 2.9874836486230363\n",
      "[EPOCH #6, step #704] loss: 2.9880476035124865\n",
      "[EPOCH #6, step #706] loss: 2.9881967806917267\n",
      "[EPOCH #6, step #708] loss: 2.987226159011023\n",
      "[EPOCH #6, step #710] loss: 2.987202924682789\n",
      "[EPOCH #6, step #712] loss: 2.9868504482766856\n",
      "[EPOCH #6, step #714] loss: 2.986881332130699\n",
      "[EPOCH #6, step #716] loss: 2.985988207275731\n",
      "[EPOCH #6, step #718] loss: 2.985453778414136\n",
      "[EPOCH #6, step #720] loss: 2.9847722919903252\n",
      "[EPOCH #6, step #722] loss: 2.984686834024031\n",
      "[EPOCH #6, step #724] loss: 2.9845370213738804\n",
      "[EPOCH #6, step #726] loss: 2.984193929779808\n",
      "[EPOCH #6, step #728] loss: 2.984160805925911\n",
      "[EPOCH #6, step #730] loss: 2.9847617948430343\n",
      "[EPOCH #6, step #732] loss: 2.984513488993313\n",
      "[EPOCH #6, step #734] loss: 2.984612838589415\n",
      "[EPOCH #6, step #736] loss: 2.984191191568465\n",
      "[EPOCH #6, step #738] loss: 2.9843101149805507\n",
      "[EPOCH #6, step #740] loss: 2.9838570393370554\n",
      "[EPOCH #6, step #742] loss: 2.983754837015596\n",
      "[EPOCH #6, step #744] loss: 2.983687722442934\n",
      "[EPOCH #6, step #746] loss: 2.984525918641403\n",
      "[EPOCH #6, step #748] loss: 2.9846186122206726\n",
      "[EPOCH #6, step #750] loss: 2.9846738975311564\n",
      "[EPOCH #6, step #752] loss: 2.9844323752885797\n",
      "[EPOCH #6, step #754] loss: 2.983266042241987\n",
      "[EPOCH #6, step #756] loss: 2.983135938329457\n",
      "[EPOCH #6, step #758] loss: 2.983586150824003\n",
      "[EPOCH #6, step #760] loss: 2.9839619816367793\n",
      "[EPOCH #6, step #762] loss: 2.9841768326015647\n",
      "[EPOCH #6, step #764] loss: 2.9834056174833012\n",
      "[EPOCH #6, step #766] loss: 2.9839290105379543\n",
      "[EPOCH #6, step #768] loss: 2.983790658385298\n",
      "[EPOCH #6, step #770] loss: 2.984323998524212\n",
      "[EPOCH #6, step #772] loss: 2.9835668973441574\n",
      "[EPOCH #6, step #774] loss: 2.9838841385995187\n",
      "[EPOCH #6, step #776] loss: 2.9842202249180856\n",
      "[EPOCH #6, step #778] loss: 2.9837656483264574\n",
      "[EPOCH #6, step #780] loss: 2.9833299069642716\n",
      "[EPOCH #6, step #782] loss: 2.9835294355682334\n",
      "[EPOCH #6, step #784] loss: 2.9834733079193505\n",
      "[EPOCH #6, step #786] loss: 2.9836254228933643\n",
      "[EPOCH #6, step #788] loss: 2.983561041992729\n",
      "[EPOCH #6, step #790] loss: 2.9829766283143786\n",
      "[EPOCH #6, step #792] loss: 2.9834289301238477\n",
      "[EPOCH #6, step #794] loss: 2.983552148806974\n",
      "[EPOCH #6, step #796] loss: 2.9823470154550473\n",
      "[EPOCH #6, step #798] loss: 2.982918313507443\n",
      "[EPOCH #6, step #800] loss: 2.9827767204256093\n",
      "[EPOCH #6, step #802] loss: 2.9825154648325958\n",
      "[EPOCH #6, step #804] loss: 2.981776780075168\n",
      "[EPOCH #6, step #806] loss: 2.981728577702462\n",
      "[EPOCH #6, step #808] loss: 2.9812590545423245\n",
      "[EPOCH #6, step #810] loss: 2.9812361450289386\n",
      "[EPOCH #6, step #812] loss: 2.9814938223230003\n",
      "[EPOCH #6, step #814] loss: 2.9816782729025997\n",
      "[EPOCH #6, step #816] loss: 2.9813424440755107\n",
      "[EPOCH #6, step #818] loss: 2.981897244668851\n",
      "[EPOCH #6, step #820] loss: 2.9820627826430477\n",
      "[EPOCH #6, step #822] loss: 2.9817681254622133\n",
      "[EPOCH #6, step #824] loss: 2.9820208933859162\n",
      "[EPOCH #6, step #826] loss: 2.9819642399069477\n",
      "[EPOCH #6, step #828] loss: 2.9828356140629086\n",
      "[EPOCH #6, step #830] loss: 2.9824969389808738\n",
      "[EPOCH #6, step #832] loss: 2.9832778426350095\n",
      "[EPOCH #6, step #834] loss: 2.9829811047651096\n",
      "[EPOCH #6, step #836] loss: 2.9821098927528626\n",
      "[EPOCH #6, step #838] loss: 2.9813528359291523\n",
      "[EPOCH #6, step #840] loss: 2.9806113600305655\n",
      "[EPOCH #6, step #842] loss: 2.980771734479766\n",
      "[EPOCH #6, step #844] loss: 2.980137708483363\n",
      "[EPOCH #6, step #846] loss: 2.980127570198446\n",
      "[EPOCH #6, step #848] loss: 2.9802515512360843\n",
      "[EPOCH #6, step #850] loss: 2.9801768766306824\n",
      "[EPOCH #6, step #852] loss: 2.979825268317219\n",
      "[EPOCH #6, step #854] loss: 2.979633531514664\n",
      "[EPOCH #6, step #856] loss: 2.9789468298993285\n",
      "[EPOCH #6, step #858] loss: 2.9790564135705773\n",
      "[EPOCH #6, step #860] loss: 2.978759353030711\n",
      "[EPOCH #6, step #862] loss: 2.978563700186419\n",
      "[EPOCH #6, step #864] loss: 2.978478983234119\n",
      "[EPOCH #6, step #866] loss: 2.9787627030958905\n",
      "[EPOCH #6, step #868] loss: 2.978484277758143\n",
      "[EPOCH #6, step #870] loss: 2.977908487571778\n",
      "[EPOCH #6, step #872] loss: 2.978365847062136\n",
      "[EPOCH #6, step #874] loss: 2.9782509038107734\n",
      "[EPOCH #6, step #876] loss: 2.977831783153312\n",
      "[EPOCH #6, step #878] loss: 2.9775968191973585\n",
      "[EPOCH #6, step #880] loss: 2.9779066771573297\n",
      "[EPOCH #6, step #882] loss: 2.977674367068713\n",
      "[EPOCH #6, step #884] loss: 2.977844778696696\n",
      "[EPOCH #6, step #886] loss: 2.977216176814667\n",
      "[EPOCH #6, step #888] loss: 2.9774160205446294\n",
      "[EPOCH #6, step #890] loss: 2.9776813526346224\n",
      "[EPOCH #6, step #892] loss: 2.977364717912834\n",
      "[EPOCH #6, step #894] loss: 2.9771430409820385\n",
      "[EPOCH #6, step #896] loss: 2.977571011121191\n",
      "[EPOCH #6, step #898] loss: 2.9776658576905928\n",
      "[EPOCH #6, step #900] loss: 2.977619229093376\n",
      "[EPOCH #6, step #902] loss: 2.9776554472026633\n",
      "[EPOCH #6, step #904] loss: 2.9776831268605606\n",
      "[EPOCH #6, step #906] loss: 2.977250556567275\n",
      "[EPOCH #6, step #908] loss: 2.976953991700058\n",
      "[EPOCH #6, step #910] loss: 2.9766717731756382\n",
      "[EPOCH #6, step #912] loss: 2.976436552578361\n",
      "[EPOCH #6, step #914] loss: 2.9758023209910576\n",
      "[EPOCH #6, step #916] loss: 2.9761269347358295\n",
      "[EPOCH #6, step #918] loss: 2.976533095128388\n",
      "[EPOCH #6, step #920] loss: 2.977085388444534\n",
      "[EPOCH #6, step #922] loss: 2.9767619700757293\n",
      "[EPOCH #6, step #924] loss: 2.9768329133214175\n",
      "[EPOCH #6, step #926] loss: 2.9758785617132917\n",
      "[EPOCH #6, step #928] loss: 2.976111475951705\n",
      "[EPOCH #6, step #930] loss: 2.9763328081555063\n",
      "[EPOCH #6, step #932] loss: 2.975232752700838\n",
      "[EPOCH #6, step #934] loss: 2.9752222555843906\n",
      "[EPOCH #6, step #936] loss: 2.976255236974775\n",
      "[EPOCH #6, step #938] loss: 2.9763900477030534\n",
      "[EPOCH #6, step #940] loss: 2.9765623122548703\n",
      "[EPOCH #6, step #942] loss: 2.9765806281553977\n",
      "[EPOCH #6, step #944] loss: 2.975924315780559\n",
      "[EPOCH #6, step #946] loss: 2.9758720820909317\n",
      "[EPOCH #6, step #948] loss: 2.9759795452194293\n",
      "[EPOCH #6, step #950] loss: 2.9763146186351275\n",
      "[EPOCH #6, step #952] loss: 2.976199782532635\n",
      "[EPOCH #6, step #954] loss: 2.976006202298309\n",
      "[EPOCH #6, step #956] loss: 2.976440450614523\n",
      "[EPOCH #6, step #958] loss: 2.976590593365857\n",
      "[EPOCH #6, step #960] loss: 2.9762336036789305\n",
      "[EPOCH #6, step #962] loss: 2.975800591960998\n",
      "[EPOCH #6, step #964] loss: 2.9754964322006145\n",
      "[EPOCH #6, step #966] loss: 2.9753228005603525\n",
      "[EPOCH #6, step #968] loss: 2.9755405986026098\n",
      "[EPOCH #6, step #970] loss: 2.9757610118720605\n",
      "[EPOCH #6, step #972] loss: 2.975460049794855\n",
      "[EPOCH #6, step #974] loss: 2.9756974039322293\n",
      "[EPOCH #6, step #976] loss: 2.9758576941709802\n",
      "[EPOCH #6, step #978] loss: 2.976089333367664\n",
      "[EPOCH #6, step #980] loss: 2.975835427353263\n",
      "[EPOCH #6, step #982] loss: 2.9750497154398827\n",
      "[EPOCH #6, step #984] loss: 2.9755570104279494\n",
      "[EPOCH #6, step #986] loss: 2.9757947810635863\n",
      "[EPOCH #6, step #988] loss: 2.9761071337727856\n",
      "[EPOCH #6, step #990] loss: 2.9764507069477038\n",
      "[EPOCH #6, step #992] loss: 2.976826193349479\n",
      "[EPOCH #6, step #994] loss: 2.9765130356927614\n",
      "[EPOCH #6, step #996] loss: 2.9768372579228317\n",
      "[EPOCH #6, step #998] loss: 2.9770190966379895\n",
      "[EPOCH #6, step #1000] loss: 2.976959567208152\n",
      "[EPOCH #6, step #1002] loss: 2.9764070796110813\n",
      "[EPOCH #6, step #1004] loss: 2.9761526273850776\n",
      "[EPOCH #6, step #1006] loss: 2.9761111544520995\n",
      "[EPOCH #6, step #1008] loss: 2.9761420534434473\n",
      "[EPOCH #6, step #1010] loss: 2.97596699241125\n",
      "[EPOCH #6, step #1012] loss: 2.976205055946659\n",
      "[EPOCH #6, step #1014] loss: 2.9755045815641656\n",
      "[EPOCH #6, step #1016] loss: 2.9751139303693144\n",
      "[EPOCH #6, step #1018] loss: 2.9761978880345996\n",
      "[EPOCH #6, step #1020] loss: 2.975912783451809\n",
      "[EPOCH #6, step #1022] loss: 2.97498920609408\n",
      "[EPOCH #6, step #1024] loss: 2.974664765102107\n",
      "[EPOCH #6, step #1026] loss: 2.9746193247389305\n",
      "[EPOCH #6, step #1028] loss: 2.974693990193952\n",
      "[EPOCH #6, step #1030] loss: 2.9749840563876786\n",
      "[EPOCH #6, step #1032] loss: 2.9748018194145063\n",
      "[EPOCH #6, step #1034] loss: 2.97514626438491\n",
      "[EPOCH #6, step #1036] loss: 2.975217114304163\n",
      "[EPOCH #6, step #1038] loss: 2.9755725929436485\n",
      "[EPOCH #6, step #1040] loss: 2.975712743662047\n",
      "[EPOCH #6, step #1042] loss: 2.9759900896798386\n",
      "[EPOCH #6, step #1044] loss: 2.975035518208189\n",
      "[EPOCH #6, step #1046] loss: 2.9746849898964083\n",
      "[EPOCH #6, step #1048] loss: 2.974660916369341\n",
      "[EPOCH #6, step #1050] loss: 2.974320453649243\n",
      "[EPOCH #6, step #1052] loss: 2.974262682913828\n",
      "[EPOCH #6, step #1054] loss: 2.9739751411275277\n",
      "[EPOCH #6, step #1056] loss: 2.974164990061505\n",
      "[EPOCH #6, step #1058] loss: 2.9739581629056993\n",
      "[EPOCH #6, step #1060] loss: 2.974048576750472\n",
      "[EPOCH #6, step #1062] loss: 2.9737321924512834\n",
      "[EPOCH #6, step #1064] loss: 2.9739422359377006\n",
      "[EPOCH #6, step #1066] loss: 2.9736713862575543\n",
      "[EPOCH #6, step #1068] loss: 2.9732458303753075\n",
      "[EPOCH #6, step #1070] loss: 2.973125923024951\n",
      "[EPOCH #6, step #1072] loss: 2.9734206275193356\n",
      "[EPOCH #6, step #1074] loss: 2.973056616450465\n",
      "[EPOCH #6, step #1076] loss: 2.972908714466219\n",
      "[EPOCH #6, step #1078] loss: 2.9730313270593594\n",
      "[EPOCH #6, step #1080] loss: 2.9726073763968213\n",
      "[EPOCH #6, step #1082] loss: 2.9723885510656864\n",
      "[EPOCH #6, step #1084] loss: 2.97264827693113\n",
      "[EPOCH #6, step #1086] loss: 2.9725883564163813\n",
      "[EPOCH #6, step #1088] loss: 2.9724339398908657\n",
      "[EPOCH #6, step #1090] loss: 2.9719814552723216\n",
      "[EPOCH #6, step #1092] loss: 2.971542115835345\n",
      "[EPOCH #6, step #1094] loss: 2.971843822035071\n",
      "[EPOCH #6, step #1096] loss: 2.9712574714514592\n",
      "[EPOCH #6, step #1098] loss: 2.971382320306863\n",
      "[EPOCH #6, step #1100] loss: 2.9716043173454763\n",
      "[EPOCH #6, step #1102] loss: 2.971904695844607\n",
      "[EPOCH #6, step #1104] loss: 2.971885617070608\n",
      "[EPOCH #6, step #1106] loss: 2.9716912203257215\n",
      "[EPOCH #6, step #1108] loss: 2.9717570675505076\n",
      "[EPOCH #6, step #1110] loss: 2.971829541624397\n",
      "[EPOCH #6, step #1112] loss: 2.9719913275736682\n",
      "[EPOCH #6, step #1114] loss: 2.9721047672990193\n",
      "[EPOCH #6, step #1116] loss: 2.9724202819882275\n",
      "[EPOCH #6, step #1118] loss: 2.972454558748342\n",
      "[EPOCH #6, step #1120] loss: 2.972050455188666\n",
      "[EPOCH #6, step #1122] loss: 2.9723253553718303\n",
      "[EPOCH #6, step #1124] loss: 2.9727886170281304\n",
      "[EPOCH #6, step #1126] loss: 2.9728128224637724\n",
      "[EPOCH #6, step #1128] loss: 2.9726039843816903\n",
      "[EPOCH #6, step #1130] loss: 2.9726796192368186\n",
      "[EPOCH #6, step #1132] loss: 2.972485045048376\n",
      "[EPOCH #6, step #1134] loss: 2.972763878448419\n",
      "[EPOCH #6, step #1136] loss: 2.9727689450313464\n",
      "[EPOCH #6, step #1138] loss: 2.973106226029367\n",
      "[EPOCH #6, step #1140] loss: 2.972682246610222\n",
      "[EPOCH #6, step #1142] loss: 2.9723019591570945\n",
      "[EPOCH #6, step #1144] loss: 2.97186345012948\n",
      "[EPOCH #6, step #1146] loss: 2.971313560123327\n",
      "[EPOCH #6, step #1148] loss: 2.9710545658131493\n",
      "[EPOCH #6, step #1150] loss: 2.9710613138048054\n",
      "[EPOCH #6, step #1152] loss: 2.970207325603687\n",
      "[EPOCH #6, step #1154] loss: 2.9700796490623835\n",
      "[EPOCH #6, step #1156] loss: 2.970288339110418\n",
      "[EPOCH #6, step #1158] loss: 2.9703281405056416\n",
      "[EPOCH #6, step #1160] loss: 2.9701441732795972\n",
      "[EPOCH #6, step #1162] loss: 2.969787309011917\n",
      "[EPOCH #6, step #1164] loss: 2.969899791300041\n",
      "[EPOCH #6, step #1166] loss: 2.969818516480381\n",
      "[EPOCH #6, step #1168] loss: 2.969401118284214\n",
      "[EPOCH #6, step #1170] loss: 2.969621935835463\n",
      "[EPOCH #6, step #1172] loss: 2.9694288724117164\n",
      "[EPOCH #6, step #1174] loss: 2.9693600689096655\n",
      "[EPOCH #6, step #1176] loss: 2.9694397238826182\n",
      "[EPOCH #6, step #1178] loss: 2.969749324902121\n",
      "[EPOCH #6, step #1180] loss: 2.969753140418031\n",
      "[EPOCH #6, step #1182] loss: 2.9696567276223473\n",
      "[EPOCH #6, step #1184] loss: 2.9699397077037313\n",
      "[EPOCH #6, step #1186] loss: 2.9707063282851722\n",
      "[EPOCH #6, step #1188] loss: 2.970809672438266\n",
      "[EPOCH #6, step #1190] loss: 2.9706374379789797\n",
      "[EPOCH #6, step #1192] loss: 2.9706619805082592\n",
      "[EPOCH #6, step #1194] loss: 2.9710157452268082\n",
      "[EPOCH #6, step #1196] loss: 2.9708016910648585\n",
      "[EPOCH #6, step #1198] loss: 2.970553354385796\n",
      "[EPOCH #6, step #1200] loss: 2.9706454048744346\n",
      "[EPOCH #6, step #1202] loss: 2.970109756252514\n",
      "[EPOCH #6, step #1204] loss: 2.9699065916765774\n",
      "[EPOCH #6, step #1206] loss: 2.9697386866872133\n",
      "[EPOCH #6, step #1208] loss: 2.969766768864899\n",
      "[EPOCH #6, step #1210] loss: 2.9703968136296797\n",
      "[EPOCH #6, step #1212] loss: 2.9700444133834023\n",
      "[EPOCH #6, step #1214] loss: 2.9698733520115352\n",
      "[EPOCH #6, step #1216] loss: 2.9699252306092636\n",
      "[EPOCH #6, step #1218] loss: 2.969544355550489\n",
      "[EPOCH #6, step #1220] loss: 2.9696900293926642\n",
      "[EPOCH #6, step #1222] loss: 2.969420914755234\n",
      "[EPOCH #6, step #1224] loss: 2.969292969217106\n",
      "[EPOCH #6, step #1226] loss: 2.9690683045422244\n",
      "[EPOCH #6, step #1228] loss: 2.9690755645466393\n",
      "[EPOCH #6, step #1230] loss: 2.968686295175436\n",
      "[EPOCH #6, step #1232] loss: 2.9690635003215977\n",
      "[EPOCH #6, step #1234] loss: 2.9691873214505464\n",
      "[EPOCH #6, step #1236] loss: 2.9689167509564682\n",
      "[EPOCH #6, step #1238] loss: 2.969023674894861\n",
      "[EPOCH #6, step #1240] loss: 2.9692312931457323\n",
      "[EPOCH #6, step #1242] loss: 2.9690133334165223\n",
      "[EPOCH #6, step #1244] loss: 2.969265349514513\n",
      "[EPOCH #6, step #1246] loss: 2.96902666822279\n",
      "[EPOCH #6, step #1248] loss: 2.9690821172715762\n",
      "[EPOCH #6, step #1250] loss: 2.9689452347042655\n",
      "[EPOCH #6, step #1252] loss: 2.9690342023671388\n",
      "[EPOCH #6, step #1254] loss: 2.9687584814322423\n",
      "[EPOCH #6, step #1256] loss: 2.9681751980322546\n",
      "[EPOCH #6, step #1258] loss: 2.968049565225106\n",
      "[EPOCH #6, step #1260] loss: 2.967711357537193\n",
      "[EPOCH #6, step #1262] loss: 2.9677085551777624\n",
      "[EPOCH #6, step #1264] loss: 2.968146085173716\n",
      "[EPOCH #6, step #1266] loss: 2.9682168610564537\n",
      "[EPOCH #6, step #1268] loss: 2.9678995254191944\n",
      "[EPOCH #6, step #1270] loss: 2.96797778660814\n",
      "[EPOCH #6, step #1272] loss: 2.9679131251287947\n",
      "[EPOCH #6, step #1274] loss: 2.9674137465159096\n",
      "[EPOCH #6, step #1276] loss: 2.967736583065968\n",
      "[EPOCH #6, step #1278] loss: 2.967938631190463\n",
      "[EPOCH #6, step #1280] loss: 2.9680592364207734\n",
      "[EPOCH #6, step #1282] loss: 2.967862762516584\n",
      "[EPOCH #6, step #1284] loss: 2.967542555174475\n",
      "[EPOCH #6, step #1286] loss: 2.967541388791017\n",
      "[EPOCH #6, step #1288] loss: 2.967005969018692\n",
      "[EPOCH #6, step #1290] loss: 2.9670221436217625\n",
      "[EPOCH #6, step #1292] loss: 2.9669564885864492\n",
      "[EPOCH #6, step #1294] loss: 2.9671040036043146\n",
      "[EPOCH #6, step #1296] loss: 2.967062347929755\n",
      "[EPOCH #6, step #1298] loss: 2.9669929209629142\n",
      "[EPOCH #6, step #1300] loss: 2.967538979124968\n",
      "[EPOCH #6, step #1302] loss: 2.9669066710556278\n",
      "[EPOCH #6, step #1304] loss: 2.9675276502338863\n",
      "[EPOCH #6, step #1306] loss: 2.967072266518112\n",
      "[EPOCH #6, step #1308] loss: 2.966887919751627\n",
      "[EPOCH #6, step #1310] loss: 2.9668033430359912\n",
      "[EPOCH #6, step #1312] loss: 2.9670922841539116\n",
      "[EPOCH #6, step #1314] loss: 2.967183655568402\n",
      "[EPOCH #6, step #1316] loss: 2.9665848061091626\n",
      "[EPOCH #6, step #1318] loss: 2.966382715718325\n",
      "[EPOCH #6, step #1320] loss: 2.967278373322642\n",
      "[EPOCH #6, step #1322] loss: 2.96671380910203\n",
      "[EPOCH #6, step #1324] loss: 2.96668579659372\n",
      "[EPOCH #6, step #1326] loss: 2.9670325222101623\n",
      "[EPOCH #6, step #1328] loss: 2.9665175792056875\n",
      "[EPOCH #6, step #1330] loss: 2.9664768828743835\n",
      "[EPOCH #6, step #1332] loss: 2.966168339772951\n",
      "[EPOCH #6, step #1334] loss: 2.966152557987399\n",
      "[EPOCH #6, step #1336] loss: 2.9660982791398474\n",
      "[EPOCH #6, step #1338] loss: 2.9662599303635133\n",
      "[EPOCH #6, step #1340] loss: 2.9661546363304305\n",
      "[EPOCH #6, step #1342] loss: 2.966009749819428\n",
      "[EPOCH #6, step #1344] loss: 2.9657162503238945\n",
      "[EPOCH #6, step #1346] loss: 2.965955390873536\n",
      "[EPOCH #6, step #1348] loss: 2.9663164530797212\n",
      "[EPOCH #6, step #1350] loss: 2.9655599209399335\n",
      "[EPOCH #6, step #1352] loss: 2.965089115670057\n",
      "[EPOCH #6, step #1354] loss: 2.9649129040566757\n",
      "[EPOCH #6, step #1356] loss: 2.9649704368833065\n",
      "[EPOCH #6, step #1358] loss: 2.965026827398866\n",
      "[EPOCH #6, step #1360] loss: 2.9647287958076474\n",
      "[EPOCH #6, step #1362] loss: 2.9650607712550454\n",
      "[EPOCH #6, step #1364] loss: 2.9654537159007983\n",
      "[EPOCH #6, step #1366] loss: 2.965263729646595\n",
      "[EPOCH #6, step #1368] loss: 2.9650829487947585\n",
      "[EPOCH #6, step #1370] loss: 2.964850848474092\n",
      "[EPOCH #6, step #1372] loss: 2.9654188126607783\n",
      "[EPOCH #6, step #1374] loss: 2.965692743474787\n",
      "[EPOCH #6, step #1376] loss: 2.9653283779224626\n",
      "[EPOCH #6, step #1378] loss: 2.9650990210900368\n",
      "[EPOCH #6, step #1380] loss: 2.964912353435519\n",
      "[EPOCH #6, step #1382] loss: 2.9649066514755105\n",
      "[EPOCH #6, step #1384] loss: 2.9651572823094114\n",
      "[EPOCH #6, step #1386] loss: 2.9647594313013013\n",
      "[EPOCH #6, step #1388] loss: 2.964662304535626\n",
      "[EPOCH #6, step #1390] loss: 2.9646336830065114\n",
      "[EPOCH #6, step #1392] loss: 2.964800441342126\n",
      "[EPOCH #6, step #1394] loss: 2.9645395846349794\n",
      "[EPOCH #6, step #1396] loss: 2.9643653543318007\n",
      "[EPOCH #6, step #1398] loss: 2.964310883964446\n",
      "[EPOCH #6, step #1400] loss: 2.9644369655298726\n",
      "[EPOCH #6, step #1402] loss: 2.964349327304919\n",
      "[EPOCH #6, step #1404] loss: 2.964155525669084\n",
      "[EPOCH #6, step #1406] loss: 2.96405373216099\n",
      "[EPOCH #6, step #1408] loss: 2.963818119974996\n",
      "[EPOCH #6, step #1410] loss: 2.9635590070701507\n",
      "[EPOCH #6, step #1412] loss: 2.963537623506021\n",
      "[EPOCH #6, step #1414] loss: 2.963405394132904\n",
      "[EPOCH #6, step #1416] loss: 2.963092184100424\n",
      "[EPOCH #6, step #1418] loss: 2.962997754078839\n",
      "[EPOCH #6, step #1420] loss: 2.9628272261273936\n",
      "[EPOCH #6, step #1422] loss: 2.9627960530788395\n",
      "[EPOCH #6, step #1424] loss: 2.9628318907085216\n",
      "[EPOCH #6, step #1426] loss: 2.9625205322003647\n",
      "[EPOCH #6, step #1428] loss: 2.962540735808013\n",
      "[EPOCH #6, step #1430] loss: 2.9627580449432864\n",
      "[EPOCH #6, step #1432] loss: 2.9625347474198698\n",
      "[EPOCH #6, step #1434] loss: 2.9625890273250355\n",
      "[EPOCH #6, step #1436] loss: 2.962449398319507\n",
      "[EPOCH #6, step #1438] loss: 2.9622263996198495\n",
      "[EPOCH #6, step #1440] loss: 2.9621099264236226\n",
      "[EPOCH #6, step #1442] loss: 2.9621309822661464\n",
      "[EPOCH #6, step #1444] loss: 2.9616561127368968\n",
      "[EPOCH #6, step #1446] loss: 2.9612254567531857\n",
      "[EPOCH #6, step #1448] loss: 2.960849795364527\n",
      "[EPOCH #6, step #1450] loss: 2.9607611491218426\n",
      "[EPOCH #6, step #1452] loss: 2.960544018932482\n",
      "[EPOCH #6, step #1454] loss: 2.960484602852785\n",
      "[EPOCH #6, step #1456] loss: 2.9607947195075357\n",
      "[EPOCH #6, step #1458] loss: 2.961011426100754\n",
      "[EPOCH #6, step #1460] loss: 2.9612038585929166\n",
      "[EPOCH #6, step #1462] loss: 2.9614428672086515\n",
      "[EPOCH #6, step #1464] loss: 2.9612747542280387\n",
      "[EPOCH #6, step #1466] loss: 2.961274533834113\n",
      "[EPOCH #6, step #1468] loss: 2.961025891618878\n",
      "[EPOCH #6, step #1470] loss: 2.960556819113155\n",
      "[EPOCH #6, step #1472] loss: 2.960668241904855\n",
      "[EPOCH #6, step #1474] loss: 2.960802825669111\n",
      "[EPOCH #6, step #1476] loss: 2.9606297652141906\n",
      "[EPOCH #6, step #1478] loss: 2.960650749025996\n",
      "[EPOCH #6, step #1480] loss: 2.9609380856629244\n",
      "[EPOCH #6, step #1482] loss: 2.960758469672277\n",
      "[EPOCH #6, step #1484] loss: 2.9605064257226807\n",
      "[EPOCH #6, step #1486] loss: 2.960407801739065\n",
      "[EPOCH #6, step #1488] loss: 2.960349492533564\n",
      "[EPOCH #6, step #1490] loss: 2.9605861322580767\n",
      "[EPOCH #6, step #1492] loss: 2.960609119208324\n",
      "[EPOCH #6, step #1494] loss: 2.9606324702999665\n",
      "[EPOCH #6, step #1496] loss: 2.959788922715681\n",
      "[EPOCH #6, step #1498] loss: 2.9592930882513087\n",
      "[EPOCH #6, step #1500] loss: 2.959243350152887\n",
      "[EPOCH #6, step #1502] loss: 2.959360425502399\n",
      "[EPOCH #6, step #1504] loss: 2.9594161000362664\n",
      "[EPOCH #6, step #1506] loss: 2.9593707507385982\n",
      "[EPOCH #6, step #1508] loss: 2.9591207063458786\n",
      "[EPOCH #6, step #1510] loss: 2.9586879321867703\n",
      "[EPOCH #6, step #1512] loss: 2.9588701102565\n",
      "[EPOCH #6, step #1514] loss: 2.9590302366628114\n",
      "[EPOCH #6, step #1516] loss: 2.9587952840776137\n",
      "[EPOCH #6, step #1518] loss: 2.958536668228742\n",
      "[EPOCH #6, step #1520] loss: 2.9583619537516537\n",
      "[EPOCH #6, step #1522] loss: 2.957896774095371\n",
      "[EPOCH #6, step #1524] loss: 2.9577514357645005\n",
      "[EPOCH #6, step #1526] loss: 2.957911534175111\n",
      "[EPOCH #6, step #1528] loss: 2.957989031072533\n",
      "[EPOCH #6, step #1530] loss: 2.9579972112046433\n",
      "[EPOCH #6, step #1532] loss: 2.9578626042320613\n",
      "[EPOCH #6, step #1534] loss: 2.9572744513955875\n",
      "[EPOCH #6, step #1536] loss: 2.956989270181104\n",
      "[EPOCH #6, step #1538] loss: 2.957250223289921\n",
      "[EPOCH #6, step #1540] loss: 2.956846084167708\n",
      "[EPOCH #6, step #1542] loss: 2.9567641774633064\n",
      "[EPOCH #6, step #1544] loss: 2.9566210152647643\n",
      "[EPOCH #6, step #1546] loss: 2.9563939397228713\n",
      "[EPOCH #6, step #1548] loss: 2.9565844320342802\n",
      "[EPOCH #6, step #1550] loss: 2.956106358078662\n",
      "[EPOCH #6, step #1552] loss: 2.955813826857577\n",
      "[EPOCH #6, step #1554] loss: 2.9556895475295577\n",
      "[EPOCH #6, step #1556] loss: 2.955371774613436\n",
      "[EPOCH #6, step #1558] loss: 2.9549570025504592\n",
      "[EPOCH #6, step #1560] loss: 2.955177733716409\n",
      "[EPOCH #6, step #1562] loss: 2.955195175251439\n",
      "[EPOCH #6, step #1564] loss: 2.9551546907272583\n",
      "[EPOCH #6, step #1566] loss: 2.9552702039537264\n",
      "[EPOCH #6, step #1568] loss: 2.955116787558532\n",
      "[EPOCH #6, step #1570] loss: 2.9550131634494288\n",
      "[EPOCH #6, step #1572] loss: 2.9550816409540874\n",
      "[EPOCH #6, step #1574] loss: 2.9550708074418326\n",
      "[EPOCH #6, step #1576] loss: 2.9549778866934187\n",
      "[EPOCH #6, step #1578] loss: 2.9547841132177894\n",
      "[EPOCH #6, step #1580] loss: 2.9546654352577786\n",
      "[EPOCH #6, step #1582] loss: 2.954538755754241\n",
      "[EPOCH #6, step #1584] loss: 2.954177811619611\n",
      "[EPOCH #6, step #1586] loss: 2.954676574329648\n",
      "[EPOCH #6, step #1588] loss: 2.954965448289491\n",
      "[EPOCH #6, step #1590] loss: 2.9545394960699554\n",
      "[EPOCH #6, step #1592] loss: 2.9542593201674983\n",
      "[EPOCH #6, step #1594] loss: 2.9538724785688153\n",
      "[EPOCH #6, step #1596] loss: 2.953852846089496\n",
      "[EPOCH #6, step #1598] loss: 2.9541526735388093\n",
      "[EPOCH #6, step #1600] loss: 2.954018134165376\n",
      "[EPOCH #6, step #1602] loss: 2.95375530569537\n",
      "[EPOCH #6, step #1604] loss: 2.953567779249863\n",
      "[EPOCH #6, step #1606] loss: 2.9532380102581315\n",
      "[EPOCH #6, step #1608] loss: 2.953017506412722\n",
      "[EPOCH #6, step #1610] loss: 2.95320323888446\n",
      "[EPOCH #6, step #1612] loss: 2.953168924151927\n",
      "[EPOCH #6, step #1614] loss: 2.95327352001202\n",
      "[EPOCH #6, step #1616] loss: 2.9531567114403607\n",
      "[EPOCH #6, step #1618] loss: 2.953028810988833\n",
      "[EPOCH #6, step #1620] loss: 2.9533529472821733\n",
      "[EPOCH #6, step #1622] loss: 2.9530869850903767\n",
      "[EPOCH #6, step #1624] loss: 2.9525910170628475\n",
      "[EPOCH #6, step #1626] loss: 2.95244481245579\n",
      "[EPOCH #6, step #1628] loss: 2.952528526330741\n",
      "[EPOCH #6, step #1630] loss: 2.9525036709503043\n",
      "[EPOCH #6, step #1632] loss: 2.9526957122372908\n",
      "[EPOCH #6, step #1634] loss: 2.9526563976882794\n",
      "[EPOCH #6, step #1636] loss: 2.9528689984512098\n",
      "[EPOCH #6, step #1638] loss: 2.952649832353714\n",
      "[EPOCH #6, step #1640] loss: 2.9525829554330567\n",
      "[EPOCH #6, step #1642] loss: 2.952929220327283\n",
      "[EPOCH #6, step #1644] loss: 2.9528419561299146\n",
      "[EPOCH #6, step #1646] loss: 2.952540122022322\n",
      "[EPOCH #6, step #1648] loss: 2.9526070490108975\n",
      "[EPOCH #6, step #1650] loss: 2.9527568744934376\n",
      "[EPOCH #6, step #1652] loss: 2.952214960899053\n",
      "[EPOCH #6, step #1654] loss: 2.952134100980269\n",
      "[EPOCH #6, step #1656] loss: 2.9520286690706796\n",
      "[EPOCH #6, step #1658] loss: 2.952176910053182\n",
      "[EPOCH #6, step #1660] loss: 2.952426428539361\n",
      "[EPOCH #6, step #1662] loss: 2.9522748792020943\n",
      "[EPOCH #6, step #1664] loss: 2.9519967044795954\n",
      "[EPOCH #6, step #1666] loss: 2.9518146669356926\n",
      "[EPOCH #6, step #1668] loss: 2.9517156456386777\n",
      "[EPOCH #6, step #1670] loss: 2.95152184065768\n",
      "[EPOCH #6, step #1672] loss: 2.951350657867231\n",
      "[EPOCH #6, step #1674] loss: 2.950982954964709\n",
      "[EPOCH #6, step #1676] loss: 2.950662832425049\n",
      "[EPOCH #6, step #1678] loss: 2.950299829723865\n",
      "[EPOCH #6, step #1680] loss: 2.9503578851791734\n",
      "[EPOCH #6, step #1682] loss: 2.950252540750441\n",
      "[EPOCH #6, step #1684] loss: 2.9499041599760423\n",
      "[EPOCH #6, step #1686] loss: 2.9501707583542185\n",
      "[EPOCH #6, step #1688] loss: 2.949856550471891\n",
      "[EPOCH #6, step #1690] loss: 2.9496797779338166\n",
      "[EPOCH #6, step #1692] loss: 2.949603040895727\n",
      "[EPOCH #6, step #1694] loss: 2.9496410492247187\n",
      "[EPOCH #6, step #1696] loss: 2.9494103917530445\n",
      "[EPOCH #6, step #1698] loss: 2.949640785967202\n",
      "[EPOCH #6, step #1700] loss: 2.9494181835672424\n",
      "[EPOCH #6, step #1702] loss: 2.94948530463142\n",
      "[EPOCH #6, step #1704] loss: 2.949407618486287\n",
      "[EPOCH #6, step #1706] loss: 2.9494653172708074\n",
      "[EPOCH #6, step #1708] loss: 2.949230723244325\n",
      "[EPOCH #6, step #1710] loss: 2.9493239111262133\n",
      "[EPOCH #6, step #1712] loss: 2.94921386916945\n",
      "[EPOCH #6, step #1714] loss: 2.9494119118671027\n",
      "[EPOCH #6, step #1716] loss: 2.948870967138487\n",
      "[EPOCH #6, step #1718] loss: 2.948898414597392\n",
      "[EPOCH #6, step #1720] loss: 2.9487855175357445\n",
      "[EPOCH #6, step #1722] loss: 2.9487568661008403\n",
      "[EPOCH #6, step #1724] loss: 2.948570400735606\n",
      "[EPOCH #6, step #1726] loss: 2.948821237339888\n",
      "[EPOCH #6, step #1728] loss: 2.9487347171236284\n",
      "[EPOCH #6, step #1730] loss: 2.948589538026586\n",
      "[EPOCH #6, step #1732] loss: 2.9486174837949988\n",
      "[EPOCH #6, step #1734] loss: 2.9485820401985983\n",
      "[EPOCH #6, step #1736] loss: 2.9482772963858226\n",
      "[EPOCH #6, step #1738] loss: 2.9480958863741504\n",
      "[EPOCH #6, step #1740] loss: 2.947881383912307\n",
      "[EPOCH #6, step #1742] loss: 2.9476868156995573\n",
      "[EPOCH #6, step #1744] loss: 2.947681439435243\n",
      "[EPOCH #6, step #1746] loss: 2.947387089098803\n",
      "[EPOCH #6, step #1748] loss: 2.9471334887614176\n",
      "[EPOCH #6, step #1750] loss: 2.946723058249595\n",
      "[EPOCH #6, step #1752] loss: 2.946916376055137\n",
      "[EPOCH #6, step #1754] loss: 2.946690553138059\n",
      "[EPOCH #6, step #1756] loss: 2.9464332719519524\n",
      "[EPOCH #6, step #1758] loss: 2.9462103972453972\n",
      "[EPOCH #6, step #1760] loss: 2.9463300704956055\n",
      "[EPOCH #6, step #1762] loss: 2.9456993052720075\n",
      "[EPOCH #6, step #1764] loss: 2.9453120097897885\n",
      "[EPOCH #6, step #1766] loss: 2.945320901455148\n",
      "[EPOCH #6, step #1768] loss: 2.945041388020534\n",
      "[EPOCH #6, step #1770] loss: 2.9448119425490913\n",
      "[EPOCH #6, step #1772] loss: 2.945059576884408\n",
      "[EPOCH #6, step #1774] loss: 2.944961729184003\n",
      "[EPOCH #6, step #1776] loss: 2.944868244478122\n",
      "[EPOCH #6, step #1778] loss: 2.944881414683633\n",
      "[EPOCH #6, step #1780] loss: 2.944957604105723\n",
      "[EPOCH #6, step #1782] loss: 2.944959540348406\n",
      "[EPOCH #6, step #1784] loss: 2.945181740165091\n",
      "[EPOCH #6, step #1786] loss: 2.9452131780486703\n",
      "[EPOCH #6, step #1788] loss: 2.9452340694830497\n",
      "[EPOCH #6, step #1790] loss: 2.945385346127781\n",
      "[EPOCH #6, step #1792] loss: 2.9451601499960667\n",
      "[EPOCH #6, step #1794] loss: 2.945236827005583\n",
      "[EPOCH #6, step #1796] loss: 2.945018493804125\n",
      "[EPOCH #6, step #1798] loss: 2.9448438723131045\n",
      "[EPOCH #6, step #1800] loss: 2.944488239182425\n",
      "[EPOCH #6, step #1802] loss: 2.944438046636809\n",
      "[EPOCH #6, step #1804] loss: 2.9446275815408978\n",
      "[EPOCH #6, step #1806] loss: 2.9447642382034362\n",
      "[EPOCH #6, step #1808] loss: 2.9445391468345425\n",
      "[EPOCH #6, step #1810] loss: 2.944144929989078\n",
      "[EPOCH #6, step #1812] loss: 2.943977080848555\n",
      "[EPOCH #6, step #1814] loss: 2.943744223965101\n",
      "[EPOCH #6, step #1816] loss: 2.944135380368608\n",
      "[EPOCH #6, step #1818] loss: 2.944452976118804\n",
      "[EPOCH #6, step #1820] loss: 2.94450738664383\n",
      "[EPOCH #6, step #1822] loss: 2.9440423601352443\n",
      "[EPOCH #6, step #1824] loss: 2.943597932057838\n",
      "[EPOCH #6, step #1826] loss: 2.9434970929835362\n",
      "[EPOCH #6, step #1828] loss: 2.9434375929793353\n",
      "[EPOCH #6, step #1830] loss: 2.9434441581311477\n",
      "[EPOCH #6, step #1832] loss: 2.9436091693840716\n",
      "[EPOCH #6, step #1834] loss: 2.9432511685654643\n",
      "[EPOCH #6, step #1836] loss: 2.9429986161515966\n",
      "[EPOCH #6, step #1838] loss: 2.943219273553198\n",
      "[EPOCH #6, step #1840] loss: 2.9430723740703577\n",
      "[EPOCH #6, step #1842] loss: 2.9432200398447717\n",
      "[EPOCH #6, step #1844] loss: 2.9430918909346833\n",
      "[EPOCH #6, step #1846] loss: 2.9433644081233448\n",
      "[EPOCH #6, step #1848] loss: 2.9435790926137444\n",
      "[EPOCH #6, step #1850] loss: 2.9432544781670966\n",
      "[EPOCH #6, step #1852] loss: 2.9429254482967173\n",
      "[EPOCH #6, step #1854] loss: 2.9426649890498653\n",
      "[EPOCH #6, step #1856] loss: 2.942906870146111\n",
      "[EPOCH #6, step #1858] loss: 2.9425515669401516\n",
      "[EPOCH #6, step #1860] loss: 2.9425061989189283\n",
      "[EPOCH #6, step #1862] loss: 2.942606564305255\n",
      "[EPOCH #6, step #1864] loss: 2.9428651686967537\n",
      "[EPOCH #6, step #1866] loss: 2.943058269191184\n",
      "[EPOCH #6, step #1868] loss: 2.9425878682960604\n",
      "[EPOCH #6, step #1870] loss: 2.942397962082904\n",
      "[EPOCH #6, step #1872] loss: 2.9422718512458212\n",
      "[EPOCH #6, step #1874] loss: 2.9421603061676027\n",
      "[EPOCH #6, step #1876] loss: 2.9420150989030485\n",
      "[EPOCH #6, step #1878] loss: 2.941804981155558\n",
      "[EPOCH #6, step #1880] loss: 2.9416651815762234\n",
      "[EPOCH #6, step #1882] loss: 2.9413490825932644\n",
      "[EPOCH #6, step #1884] loss: 2.941351374011457\n",
      "[EPOCH #6, step #1886] loss: 2.94127779684183\n",
      "[EPOCH #6, step #1888] loss: 2.941215991216592\n",
      "[EPOCH #6, step #1890] loss: 2.940776682606076\n",
      "[EPOCH #6, step #1892] loss: 2.9407224585880254\n",
      "[EPOCH #6, step #1894] loss: 2.9405022730613446\n",
      "[EPOCH #6, step #1896] loss: 2.9406824520404675\n",
      "[EPOCH #6, step #1898] loss: 2.940577785111277\n",
      "[EPOCH #6, step #1900] loss: 2.9404612511851047\n",
      "[EPOCH #6, step #1902] loss: 2.9402436019869396\n",
      "[EPOCH #6, step #1904] loss: 2.940073596774124\n",
      "[EPOCH #6, step #1906] loss: 2.9401340839684043\n",
      "[EPOCH #6, step #1908] loss: 2.9398090791927074\n",
      "[EPOCH #6, step #1910] loss: 2.9398682589059346\n",
      "[EPOCH #6, step #1912] loss: 2.939818064953355\n",
      "[EPOCH #6, step #1914] loss: 2.9397207293746987\n",
      "[EPOCH #6, step #1916] loss: 2.9397982348360987\n",
      "[EPOCH #6, step #1918] loss: 2.939682291099465\n",
      "[EPOCH #6, step #1920] loss: 2.939706170267267\n",
      "[EPOCH #6, step #1922] loss: 2.9396758910212366\n",
      "[EPOCH #6, step #1924] loss: 2.9398188469626687\n",
      "[EPOCH #6, step #1926] loss: 2.9396923413595886\n",
      "[EPOCH #6, step #1928] loss: 2.9397242721836454\n",
      "[EPOCH #6, step #1930] loss: 2.9395859282230354\n",
      "[EPOCH #6, step #1932] loss: 2.9393303119266707\n",
      "[EPOCH #6, step #1934] loss: 2.939736608756605\n",
      "[EPOCH #6, step #1936] loss: 2.9399293271548737\n",
      "[EPOCH #6, step #1938] loss: 2.9398639464021774\n",
      "[EPOCH #6, step #1940] loss: 2.9401280836982866\n",
      "[EPOCH #6, step #1942] loss: 2.9401312977520386\n",
      "[EPOCH #6, step #1944] loss: 2.9400379062005366\n",
      "[EPOCH #6, step #1946] loss: 2.9400029291418437\n",
      "[EPOCH #6, step #1948] loss: 2.9398216809781164\n",
      "[EPOCH #6, step #1950] loss: 2.939711847041339\n",
      "[EPOCH #6, step #1952] loss: 2.9397381248073704\n",
      "[EPOCH #6, step #1954] loss: 2.9396296910922546\n",
      "[EPOCH #6, step #1956] loss: 2.939739386768565\n",
      "[EPOCH #6, step #1958] loss: 2.939841716249358\n",
      "[EPOCH #6, step #1960] loss: 2.939549611576475\n",
      "[EPOCH #6, step #1962] loss: 2.939664397140091\n",
      "[EPOCH #6, step #1964] loss: 2.9399315353568274\n",
      "[EPOCH #6, step #1966] loss: 2.9397204354988724\n",
      "[EPOCH #6, step #1968] loss: 2.939712004470244\n",
      "[EPOCH #6, step #1970] loss: 2.9396079957092067\n",
      "[EPOCH #6, step #1972] loss: 2.9395317955181435\n",
      "[EPOCH #6, step #1974] loss: 2.9393484486205668\n",
      "[EPOCH #6, step #1976] loss: 2.9394163389548424\n",
      "[EPOCH #6, step #1978] loss: 2.939257431054368\n",
      "[EPOCH #6, step #1980] loss: 2.9392772441798543\n",
      "[EPOCH #6, step #1982] loss: 2.939026450846331\n",
      "[EPOCH #6, step #1984] loss: 2.9391208102180615\n",
      "[EPOCH #6, step #1986] loss: 2.9388935787928543\n",
      "[EPOCH #6, step #1988] loss: 2.9387975895806377\n",
      "[EPOCH #6, step #1990] loss: 2.938677972791663\n",
      "[EPOCH #6, step #1992] loss: 2.938322386308585\n",
      "[EPOCH #6, step #1994] loss: 2.93811116828058\n",
      "[EPOCH #6, step #1996] loss: 2.938186735407257\n",
      "[EPOCH #6, step #1998] loss: 2.9379472637128807\n",
      "[EPOCH #6, step #2000] loss: 2.937771598795901\n",
      "[EPOCH #6, step #2002] loss: 2.9376040952418725\n",
      "[EPOCH #6, step #2004] loss: 2.9377447455303924\n",
      "[EPOCH #6, step #2006] loss: 2.9375745122802157\n",
      "[EPOCH #6, step #2008] loss: 2.937726649673143\n",
      "[EPOCH #6, step #2010] loss: 2.9375774119399427\n",
      "[EPOCH #6, step #2012] loss: 2.9375202466289143\n",
      "[EPOCH #6, step #2014] loss: 2.937660247102269\n",
      "[EPOCH #6, step #2016] loss: 2.9378240310619774\n",
      "[EPOCH #6, step #2018] loss: 2.937711286686505\n",
      "[EPOCH #6, step #2020] loss: 2.9376311475601837\n",
      "[EPOCH #6, step #2022] loss: 2.9372965781569658\n",
      "[EPOCH #6, step #2024] loss: 2.9372765230249476\n",
      "[EPOCH #6, step #2026] loss: 2.936759112912796\n",
      "[EPOCH #6, step #2028] loss: 2.936938500510113\n",
      "[EPOCH #6, step #2030] loss: 2.937009016320601\n",
      "[EPOCH #6, step #2032] loss: 2.937039676230938\n",
      "[EPOCH #6, step #2034] loss: 2.9368719423139416\n",
      "[EPOCH #6, step #2036] loss: 2.9366624670164456\n",
      "[EPOCH #6, step #2038] loss: 2.936659755398094\n",
      "[EPOCH #6, step #2040] loss: 2.936584516228092\n",
      "[EPOCH #6, step #2042] loss: 2.9365966519595244\n",
      "[EPOCH #6, step #2044] loss: 2.9365844803509327\n",
      "[EPOCH #6, step #2046] loss: 2.9365437377879373\n",
      "[EPOCH #6, step #2048] loss: 2.936861181445329\n",
      "[EPOCH #6, step #2050] loss: 2.936661521729349\n",
      "[EPOCH #6, step #2052] loss: 2.936819424817345\n",
      "[EPOCH #6, step #2054] loss: 2.9369482467354358\n",
      "[EPOCH #6, step #2056] loss: 2.936767816891297\n",
      "[EPOCH #6, step #2058] loss: 2.936325239868868\n",
      "[EPOCH #6, step #2060] loss: 2.9364482823186333\n",
      "[EPOCH #6, step #2062] loss: 2.936304394388684\n",
      "[EPOCH #6, step #2064] loss: 2.9363499383949483\n",
      "[EPOCH #6, step #2066] loss: 2.9360218336458765\n",
      "[EPOCH #6, step #2068] loss: 2.9356486619872824\n",
      "[EPOCH #6, step #2070] loss: 2.9355827516429613\n",
      "[EPOCH #6, step #2072] loss: 2.9357101836758885\n",
      "[EPOCH #6, step #2074] loss: 2.935588889524161\n",
      "[EPOCH #6, step #2076] loss: 2.9353296148358026\n",
      "[EPOCH #6, step #2078] loss: 2.9350784212537198\n",
      "[EPOCH #6, step #2080] loss: 2.9352345654507315\n",
      "[EPOCH #6, step #2082] loss: 2.934958952296198\n",
      "[EPOCH #6, step #2084] loss: 2.9351832577364623\n",
      "[EPOCH #6, step #2086] loss: 2.93502431653822\n",
      "[EPOCH #6, step #2088] loss: 2.9348553727836117\n",
      "[EPOCH #6, step #2090] loss: 2.934523041769399\n",
      "[EPOCH #6, step #2092] loss: 2.934310735724386\n",
      "[EPOCH #6, step #2094] loss: 2.9341330503222482\n",
      "[EPOCH #6, step #2096] loss: 2.9340707934010752\n",
      "[EPOCH #6, step #2098] loss: 2.9341738158149226\n",
      "[EPOCH #6, step #2100] loss: 2.9344625032725418\n",
      "[EPOCH #6, step #2102] loss: 2.9341742281566843\n",
      "[EPOCH #6, step #2104] loss: 2.9343200862549264\n",
      "[EPOCH #6, step #2106] loss: 2.934639203814347\n",
      "[EPOCH #6, step #2108] loss: 2.934702558956083\n",
      "[EPOCH #6, step #2110] loss: 2.934904517183254\n",
      "[EPOCH #6, step #2112] loss: 2.935022436494913\n",
      "[EPOCH #6, step #2114] loss: 2.935120346078354\n",
      "[EPOCH #6, step #2116] loss: 2.935051086211351\n",
      "[EPOCH #6, step #2118] loss: 2.9351547341574022\n",
      "[EPOCH #6, step #2120] loss: 2.935215891110116\n",
      "[EPOCH #6, step #2122] loss: 2.93487127457258\n",
      "[EPOCH #6, step #2124] loss: 2.9349821007672476\n",
      "[EPOCH #6, step #2126] loss: 2.9347359128664174\n",
      "[EPOCH #6, step #2128] loss: 2.9347309798576173\n",
      "[EPOCH #6, step #2130] loss: 2.934636884315201\n",
      "[EPOCH #6, step #2132] loss: 2.9345272178667785\n",
      "[EPOCH #6, step #2134] loss: 2.934660434834572\n",
      "[EPOCH #6, step #2136] loss: 2.9346389500515784\n",
      "[EPOCH #6, step #2138] loss: 2.934694677716719\n",
      "[EPOCH #6, step #2140] loss: 2.9344111198245337\n",
      "[EPOCH #6, step #2142] loss: 2.9342878936219314\n",
      "[EPOCH #6, step #2144] loss: 2.9341105981306597\n",
      "[EPOCH #6, step #2146] loss: 2.9340497700069803\n",
      "[EPOCH #6, step #2148] loss: 2.933765806337466\n",
      "[EPOCH #6, step #2150] loss: 2.9336179806874663\n",
      "[EPOCH #6, step #2152] loss: 2.9336128376607724\n",
      "[EPOCH #6, step #2154] loss: 2.933377234841721\n",
      "[EPOCH #6, step #2156] loss: 2.9331950145459693\n",
      "[EPOCH #6, step #2158] loss: 2.933346206250705\n",
      "[EPOCH #6, step #2160] loss: 2.933339784014065\n",
      "[EPOCH #6, step #2162] loss: 2.933072983088782\n",
      "[EPOCH #6, step #2164] loss: 2.9330916484013443\n",
      "[EPOCH #6, step #2166] loss: 2.932916104215931\n",
      "[EPOCH #6, step #2168] loss: 2.9330663141318323\n",
      "[EPOCH #6, step #2170] loss: 2.9331475506724987\n",
      "[EPOCH #6, step #2172] loss: 2.9331431976946827\n",
      "[EPOCH #6, step #2174] loss: 2.9330144542387164\n",
      "[EPOCH #6, step #2176] loss: 2.9332012192722194\n",
      "[EPOCH #6, step #2178] loss: 2.9335361226210086\n",
      "[EPOCH #6, step #2180] loss: 2.9334415749965705\n",
      "[EPOCH #6, step #2182] loss: 2.9336851709106346\n",
      "[EPOCH #6, step #2184] loss: 2.9335719770915993\n",
      "[EPOCH #6, step #2186] loss: 2.9334317161767625\n",
      "[EPOCH #6, step #2188] loss: 2.9335344287563863\n",
      "[EPOCH #6, step #2190] loss: 2.933301607259927\n",
      "[EPOCH #6, step #2192] loss: 2.933453512148285\n",
      "[EPOCH #6, step #2194] loss: 2.9335298786945385\n",
      "[EPOCH #6, step #2196] loss: 2.9334211917047237\n",
      "[EPOCH #6, step #2198] loss: 2.9333863725657894\n",
      "[EPOCH #6, step #2200] loss: 2.9332616267449096\n",
      "[EPOCH #6, step #2202] loss: 2.933056574110221\n",
      "[EPOCH #6, step #2204] loss: 2.9330217862075147\n",
      "[EPOCH #6, step #2206] loss: 2.933095001990729\n",
      "[EPOCH #6, step #2208] loss: 2.9329430546464828\n",
      "[EPOCH #6, step #2210] loss: 2.933130508739449\n",
      "[EPOCH #6, step #2212] loss: 2.933443888247525\n",
      "[EPOCH #6, step #2214] loss: 2.933841470671023\n",
      "[EPOCH #6, step #2216] loss: 2.9337951241176192\n",
      "[EPOCH #6, step #2218] loss: 2.9336918613404612\n",
      "[EPOCH #6, step #2220] loss: 2.9336015011264847\n",
      "[EPOCH #6, step #2222] loss: 2.933550422276348\n",
      "[EPOCH #6, step #2224] loss: 2.9336907846472235\n",
      "[EPOCH #6, step #2226] loss: 2.9336895980158353\n",
      "[EPOCH #6, step #2228] loss: 2.9335652413845277\n",
      "[EPOCH #6, step #2230] loss: 2.9335696675861858\n",
      "[EPOCH #6, step #2232] loss: 2.933357218589902\n",
      "[EPOCH #6, step #2234] loss: 2.9332093437246027\n",
      "[EPOCH #6, step #2236] loss: 2.9330797648397895\n",
      "[EPOCH #6, step #2238] loss: 2.933391154477936\n",
      "[EPOCH #6, step #2240] loss: 2.9332446300892996\n",
      "[EPOCH #6, step #2242] loss: 2.9329187018606633\n",
      "[EPOCH #6, step #2244] loss: 2.9328407836650685\n",
      "[EPOCH #6, step #2246] loss: 2.9328319095854343\n",
      "[EPOCH #6, step #2248] loss: 2.9325409297044143\n",
      "[EPOCH #6, step #2250] loss: 2.932465642995169\n",
      "[EPOCH #6, step #2252] loss: 2.9325045955165248\n",
      "[EPOCH #6, step #2254] loss: 2.9328072391433886\n",
      "[EPOCH #6, step #2256] loss: 2.9327961125625253\n",
      "[EPOCH #6, step #2258] loss: 2.932876878209006\n",
      "[EPOCH #6, step #2260] loss: 2.9327500986346413\n",
      "[EPOCH #6, step #2262] loss: 2.932801492541857\n",
      "[EPOCH #6, step #2264] loss: 2.932673019973384\n",
      "[EPOCH #6, step #2266] loss: 2.9323908829405068\n",
      "[EPOCH #6, step #2268] loss: 2.9325990424696284\n",
      "[EPOCH #6, step #2270] loss: 2.9326427816452303\n",
      "[EPOCH #6, step #2272] loss: 2.9325451221541585\n",
      "[EPOCH #6, step #2274] loss: 2.9323263789795257\n",
      "[EPOCH #6, step #2276] loss: 2.932440008151725\n",
      "[EPOCH #6, step #2278] loss: 2.932249972568159\n",
      "[EPOCH #6, step #2280] loss: 2.931910136560242\n",
      "[EPOCH #6, step #2282] loss: 2.9318895549874426\n",
      "[EPOCH #6, step #2284] loss: 2.9318369468922687\n",
      "[EPOCH #6, step #2286] loss: 2.931927976308038\n",
      "[EPOCH #6, step #2288] loss: 2.932027212341262\n",
      "[EPOCH #6, step #2290] loss: 2.931785233413117\n",
      "[EPOCH #6, step #2292] loss: 2.931999812415215\n",
      "[EPOCH #6, step #2294] loss: 2.931854698289194\n",
      "[EPOCH #6, step #2296] loss: 2.9317391231156558\n",
      "[EPOCH #6, step #2298] loss: 2.9317284810537876\n",
      "[EPOCH #6, step #2300] loss: 2.9318496435945423\n",
      "[EPOCH #6, step #2302] loss: 2.932307088369915\n",
      "[EPOCH #6, step #2304] loss: 2.932605397623687\n",
      "[EPOCH #6, step #2306] loss: 2.932703919569858\n",
      "[EPOCH #6, step #2308] loss: 2.932818750635067\n",
      "[EPOCH #6, step #2310] loss: 2.932700421375818\n",
      "[EPOCH #6, step #2312] loss: 2.932716607944408\n",
      "[EPOCH #6, step #2314] loss: 2.93254007119082\n",
      "[EPOCH #6, step #2316] loss: 2.9325210013984346\n",
      "[EPOCH #6, step #2318] loss: 2.9323794832513372\n",
      "[EPOCH #6, step #2320] loss: 2.932231273079987\n",
      "[EPOCH #6, step #2322] loss: 2.93192629941414\n",
      "[EPOCH #6, step #2324] loss: 2.9319232448454824\n",
      "[EPOCH #6, step #2326] loss: 2.9317513250925535\n",
      "[EPOCH #6, step #2328] loss: 2.9317466691616216\n",
      "[EPOCH #6, step #2330] loss: 2.931498691995785\n",
      "[EPOCH #6, step #2332] loss: 2.9312994201143465\n",
      "[EPOCH #6, step #2334] loss: 2.9311307307739582\n",
      "[EPOCH #6, step #2336] loss: 2.9308467877436564\n",
      "[EPOCH #6, step #2338] loss: 2.9308399801429594\n",
      "[EPOCH #6, step #2340] loss: 2.930884933634631\n",
      "[EPOCH #6, step #2342] loss: 2.93067424632116\n",
      "[EPOCH #6, step #2344] loss: 2.930790075716942\n",
      "[EPOCH #6, step #2346] loss: 2.93074105991726\n",
      "[EPOCH #6, step #2348] loss: 2.9306530285612378\n",
      "[EPOCH #6, step #2350] loss: 2.930504855273988\n",
      "[EPOCH #6, step #2352] loss: 2.930479798882351\n",
      "[EPOCH #6, step #2354] loss: 2.9304049397729766\n",
      "[EPOCH #6, step #2356] loss: 2.9301999871590203\n",
      "[EPOCH #6, step #2358] loss: 2.9299900890558948\n",
      "[EPOCH #6, step #2360] loss: 2.9300941657535304\n",
      "[EPOCH #6, step #2362] loss: 2.9300897021541847\n",
      "[EPOCH #6, step #2364] loss: 2.9301004051910144\n",
      "[EPOCH #6, step #2366] loss: 2.9300902119456436\n",
      "[EPOCH #6, step #2368] loss: 2.9300497436684463\n",
      "[EPOCH #6, step #2370] loss: 2.9301373322067357\n",
      "[EPOCH #6, step #2372] loss: 2.930011434993109\n",
      "[EPOCH #6, step #2374] loss: 2.929897812090422\n",
      "[EPOCH #6, step #2376] loss: 2.929724330003391\n",
      "[EPOCH #6, step #2378] loss: 2.929440814339348\n",
      "[EPOCH #6, step #2380] loss: 2.929358943076456\n",
      "[EPOCH #6, step #2382] loss: 2.9293762834143147\n",
      "[EPOCH #6, step #2384] loss: 2.929055823220147\n",
      "[EPOCH #6, step #2386] loss: 2.929146056500848\n",
      "[EPOCH #6, step #2388] loss: 2.929360205381672\n",
      "[EPOCH #6, step #2390] loss: 2.9293722550971695\n",
      "[EPOCH #6, step #2392] loss: 2.9293846041898175\n",
      "[EPOCH #6, step #2394] loss: 2.929414483749294\n",
      "[EPOCH #6, step #2396] loss: 2.929290615821014\n",
      "[EPOCH #6, step #2398] loss: 2.9294090328637936\n",
      "[EPOCH #6, step #2400] loss: 2.92962472183612\n",
      "[EPOCH #6, step #2402] loss: 2.9292509810804477\n",
      "[EPOCH #6, step #2404] loss: 2.9290299693165105\n",
      "[EPOCH #6, step #2406] loss: 2.9288940394028717\n",
      "[EPOCH #6, step #2408] loss: 2.9287273760107158\n",
      "[EPOCH #6, step #2410] loss: 2.9284815492594407\n",
      "[EPOCH #6, step #2412] loss: 2.928326456466751\n",
      "[EPOCH #6, step #2414] loss: 2.928147064430126\n",
      "[EPOCH #6, step #2416] loss: 2.928004487763272\n",
      "[EPOCH #6, step #2418] loss: 2.928148718302089\n",
      "[EPOCH #6, step #2420] loss: 2.927960572189558\n",
      "[EPOCH #6, step #2422] loss: 2.9274455676431064\n",
      "[EPOCH #6, step #2424] loss: 2.9274178623907345\n",
      "[EPOCH #6, step #2426] loss: 2.9274435151394473\n",
      "[EPOCH #6, step #2428] loss: 2.9274529969068945\n",
      "[EPOCH #6, step #2430] loss: 2.9274025656764078\n",
      "[EPOCH #6, step #2432] loss: 2.927328764436865\n",
      "[EPOCH #6, step #2434] loss: 2.927302707343131\n",
      "[EPOCH #6, step #2436] loss: 2.9269928084957733\n",
      "[EPOCH #6, step #2438] loss: 2.9268148348144742\n",
      "[EPOCH #6, step #2440] loss: 2.926707402353939\n",
      "[EPOCH #6, step #2442] loss: 2.926841769216493\n",
      "[EPOCH #6, step #2444] loss: 2.9265952417455567\n",
      "[EPOCH #6, step #2446] loss: 2.9265759077956837\n",
      "[EPOCH #6, step #2448] loss: 2.9264949882892064\n",
      "[EPOCH #6, step #2450] loss: 2.92665350198843\n",
      "[EPOCH #6, step #2452] loss: 2.926470602477175\n",
      "[EPOCH #6, step #2454] loss: 2.9261251642844828\n",
      "[EPOCH #6, step #2456] loss: 2.925962384561237\n",
      "[EPOCH #6, step #2458] loss: 2.925712988695608\n",
      "[EPOCH #6, step #2460] loss: 2.9257134334288297\n",
      "[EPOCH #6, step #2462] loss: 2.9255028973252997\n",
      "[EPOCH #6, step #2464] loss: 2.925221286293943\n",
      "[EPOCH #6, step #2466] loss: 2.9248788061053057\n",
      "[EPOCH #6, step #2468] loss: 2.9247896251238132\n",
      "[EPOCH #6, step #2470] loss: 2.9245923250515613\n",
      "[EPOCH #6, step #2472] loss: 2.9245561482305718\n",
      "[EPOCH #6, step #2474] loss: 2.924348863736548\n",
      "[EPOCH #6, step #2476] loss: 2.9242676659654503\n",
      "[EPOCH #6, step #2478] loss: 2.9240984147284577\n",
      "[EPOCH #6, step #2480] loss: 2.9239196899387925\n",
      "[EPOCH #6, step #2482] loss: 2.923493928406155\n",
      "[EPOCH #6, step #2484] loss: 2.9234288276081353\n",
      "[EPOCH #6, step #2486] loss: 2.9232396945255466\n",
      "[EPOCH #6, step #2488] loss: 2.922926897789973\n",
      "[EPOCH #6, step #2490] loss: 2.922937679558765\n",
      "[EPOCH #6, step #2492] loss: 2.9228969518314916\n",
      "[EPOCH #6, step #2494] loss: 2.922854381381629\n",
      "[EPOCH #6, step #2496] loss: 2.922791781118024\n",
      "[EPOCH #6, step #2498] loss: 2.9228694668861808\n",
      "[EPOCH #6, elapsed time: 3059.704[sec]] loss: 2.9227760993003846\n",
      "[EPOCH #7, step #0] loss: 2.716512441635132\n",
      "[EPOCH #7, step #2] loss: 2.7892262935638428\n",
      "[EPOCH #7, step #4] loss: 2.745847225189209\n",
      "[EPOCH #7, step #6] loss: 2.8474837711879184\n",
      "[EPOCH #7, step #8] loss: 2.814083867602878\n",
      "[EPOCH #7, step #10] loss: 2.79287407614968\n",
      "[EPOCH #7, step #12] loss: 2.805248792354877\n",
      "[EPOCH #7, step #14] loss: 2.774551264444987\n",
      "[EPOCH #7, step #16] loss: 2.7875913171207203\n",
      "[EPOCH #7, step #18] loss: 2.8095145852942216\n",
      "[EPOCH #7, step #20] loss: 2.802675826208932\n",
      "[EPOCH #7, step #22] loss: 2.7917506280152695\n",
      "[EPOCH #7, step #24] loss: 2.7972518253326415\n",
      "[EPOCH #7, step #26] loss: 2.811054892010159\n",
      "[EPOCH #7, step #28] loss: 2.820741398581143\n",
      "[EPOCH #7, step #30] loss: 2.8090756631666616\n",
      "[EPOCH #7, step #32] loss: 2.816907875465624\n",
      "[EPOCH #7, step #34] loss: 2.8093905993870325\n",
      "[EPOCH #7, step #36] loss: 2.8142567067532926\n",
      "[EPOCH #7, step #38] loss: 2.818276521487114\n",
      "[EPOCH #7, step #40] loss: 2.8247459109236552\n",
      "[EPOCH #7, step #42] loss: 2.821540915688803\n",
      "[EPOCH #7, step #44] loss: 2.810458877351549\n",
      "[EPOCH #7, step #46] loss: 2.8075969067025692\n",
      "[EPOCH #7, step #48] loss: 2.8168307469815623\n",
      "[EPOCH #7, step #50] loss: 2.8205225935169294\n",
      "[EPOCH #7, step #52] loss: 2.817231110806735\n",
      "[EPOCH #7, step #54] loss: 2.8097133896567605\n",
      "[EPOCH #7, step #56] loss: 2.8006931396952846\n",
      "[EPOCH #7, step #58] loss: 2.7999134710279563\n",
      "[EPOCH #7, step #60] loss: 2.8080232065232074\n",
      "[EPOCH #7, step #62] loss: 2.8119511225866893\n",
      "[EPOCH #7, step #64] loss: 2.809687409034142\n",
      "[EPOCH #7, step #66] loss: 2.8108557373730103\n",
      "[EPOCH #7, step #68] loss: 2.802204640015312\n",
      "[EPOCH #7, step #70] loss: 2.800250486588814\n",
      "[EPOCH #7, step #72] loss: 2.802274080171977\n",
      "[EPOCH #7, step #74] loss: 2.802933511734009\n",
      "[EPOCH #7, step #76] loss: 2.807513416587532\n",
      "[EPOCH #7, step #78] loss: 2.8070707834219633\n",
      "[EPOCH #7, step #80] loss: 2.7982205461572716\n",
      "[EPOCH #7, step #82] loss: 2.794936050851661\n",
      "[EPOCH #7, step #84] loss: 2.7948144604178036\n",
      "[EPOCH #7, step #86] loss: 2.802101565503526\n",
      "[EPOCH #7, step #88] loss: 2.8046187443679638\n",
      "[EPOCH #7, step #90] loss: 2.8071898208869683\n",
      "[EPOCH #7, step #92] loss: 2.8074030209613103\n",
      "[EPOCH #7, step #94] loss: 2.8061492919921873\n",
      "[EPOCH #7, step #96] loss: 2.806442921923608\n",
      "[EPOCH #7, step #98] loss: 2.8050332840042884\n",
      "[EPOCH #7, step #100] loss: 2.804487174100215\n",
      "[EPOCH #7, step #102] loss: 2.803116275268851\n",
      "[EPOCH #7, step #104] loss: 2.7986497969854445\n",
      "[EPOCH #7, step #106] loss: 2.8052371038454713\n",
      "[EPOCH #7, step #108] loss: 2.8026941347559657\n",
      "[EPOCH #7, step #110] loss: 2.7980033964724154\n",
      "[EPOCH #7, step #112] loss: 2.796497226816363\n",
      "[EPOCH #7, step #114] loss: 2.7926970875781514\n",
      "[EPOCH #7, step #116] loss: 2.792481776995537\n",
      "[EPOCH #7, step #118] loss: 2.7943737707218204\n",
      "[EPOCH #7, step #120] loss: 2.79600846077785\n",
      "[EPOCH #7, step #122] loss: 2.8042489687601724\n",
      "[EPOCH #7, step #124] loss: 2.8033803539276123\n",
      "[EPOCH #7, step #126] loss: 2.8028603257156735\n",
      "[EPOCH #7, step #128] loss: 2.8029353138088258\n",
      "[EPOCH #7, step #130] loss: 2.8033597505729615\n",
      "[EPOCH #7, step #132] loss: 2.8044706789174474\n",
      "[EPOCH #7, step #134] loss: 2.8077491495344375\n",
      "[EPOCH #7, step #136] loss: 2.805444759173985\n",
      "[EPOCH #7, step #138] loss: 2.8044685785718957\n",
      "[EPOCH #7, step #140] loss: 2.7994296855114875\n",
      "[EPOCH #7, step #142] loss: 2.802459981891659\n",
      "[EPOCH #7, step #144] loss: 2.801907539367676\n",
      "[EPOCH #7, step #146] loss: 2.8068353367500563\n",
      "[EPOCH #7, step #148] loss: 2.806653856431078\n",
      "[EPOCH #7, step #150] loss: 2.807684756272676\n",
      "[EPOCH #7, step #152] loss: 2.8092561718685176\n",
      "[EPOCH #7, step #154] loss: 2.811234138857934\n",
      "[EPOCH #7, step #156] loss: 2.809039222207039\n",
      "[EPOCH #7, step #158] loss: 2.81152121825788\n",
      "[EPOCH #7, step #160] loss: 2.808417546823158\n",
      "[EPOCH #7, step #162] loss: 2.807207201156148\n",
      "[EPOCH #7, step #164] loss: 2.811915163560347\n",
      "[EPOCH #7, step #166] loss: 2.8157459347547884\n",
      "[EPOCH #7, step #168] loss: 2.8149522084456224\n",
      "[EPOCH #7, step #170] loss: 2.8138882277304664\n",
      "[EPOCH #7, step #172] loss: 2.8143450345607164\n",
      "[EPOCH #7, step #174] loss: 2.815019642966134\n",
      "[EPOCH #7, step #176] loss: 2.8172350280028953\n",
      "[EPOCH #7, step #178] loss: 2.816160191370788\n",
      "[EPOCH #7, step #180] loss: 2.817565210616391\n",
      "[EPOCH #7, step #182] loss: 2.81535839383068\n",
      "[EPOCH #7, step #184] loss: 2.8112128902126003\n",
      "[EPOCH #7, step #186] loss: 2.8084783146088137\n",
      "[EPOCH #7, step #188] loss: 2.809621360566881\n",
      "[EPOCH #7, step #190] loss: 2.8079136591307154\n",
      "[EPOCH #7, step #192] loss: 2.8067789324824672\n",
      "[EPOCH #7, step #194] loss: 2.8072912472944993\n",
      "[EPOCH #7, step #196] loss: 2.8097646986772564\n",
      "[EPOCH #7, step #198] loss: 2.8106029165450055\n",
      "[EPOCH #7, step #200] loss: 2.8095282630540837\n",
      "[EPOCH #7, step #202] loss: 2.809082571508849\n",
      "[EPOCH #7, step #204] loss: 2.808483144713611\n",
      "[EPOCH #7, step #206] loss: 2.8093825941500454\n",
      "[EPOCH #7, step #208] loss: 2.8094712524322802\n",
      "[EPOCH #7, step #210] loss: 2.807607712903859\n",
      "[EPOCH #7, step #212] loss: 2.812025718286004\n",
      "[EPOCH #7, step #214] loss: 2.810631579022075\n",
      "[EPOCH #7, step #216] loss: 2.8083613819790325\n",
      "[EPOCH #7, step #218] loss: 2.810748248339788\n",
      "[EPOCH #7, step #220] loss: 2.809403442149788\n",
      "[EPOCH #7, step #222] loss: 2.806712659485137\n",
      "[EPOCH #7, step #224] loss: 2.8067534160614014\n",
      "[EPOCH #7, step #226] loss: 2.804648138878104\n",
      "[EPOCH #7, step #228] loss: 2.8035298872202246\n",
      "[EPOCH #7, step #230] loss: 2.803378746107027\n",
      "[EPOCH #7, step #232] loss: 2.8071934859640097\n",
      "[EPOCH #7, step #234] loss: 2.806524593272108\n",
      "[EPOCH #7, step #236] loss: 2.8068108598894206\n",
      "[EPOCH #7, step #238] loss: 2.805309244778366\n",
      "[EPOCH #7, step #240] loss: 2.8062652690776653\n",
      "[EPOCH #7, step #242] loss: 2.8025133384108054\n",
      "[EPOCH #7, step #244] loss: 2.8011715295363446\n",
      "[EPOCH #7, step #246] loss: 2.8019834867855797\n",
      "[EPOCH #7, step #248] loss: 2.8010351954693773\n",
      "[EPOCH #7, step #250] loss: 2.8004383290431414\n",
      "[EPOCH #7, step #252] loss: 2.798323023460599\n",
      "[EPOCH #7, step #254] loss: 2.799648316701253\n",
      "[EPOCH #7, step #256] loss: 2.799972305038096\n",
      "[EPOCH #7, step #258] loss: 2.799379806260805\n",
      "[EPOCH #7, step #260] loss: 2.801196352275395\n",
      "[EPOCH #7, step #262] loss: 2.801923858802128\n",
      "[EPOCH #7, step #264] loss: 2.803066200580237\n",
      "[EPOCH #7, step #266] loss: 2.804001117913464\n",
      "[EPOCH #7, step #268] loss: 2.8037269195216297\n",
      "[EPOCH #7, step #270] loss: 2.803881112059984\n",
      "[EPOCH #7, step #272] loss: 2.805005059574113\n",
      "[EPOCH #7, step #274] loss: 2.804554126045921\n",
      "[EPOCH #7, step #276] loss: 2.806978460683719\n",
      "[EPOCH #7, step #278] loss: 2.8079446977184666\n",
      "[EPOCH #7, step #280] loss: 2.8082547603552874\n",
      "[EPOCH #7, step #282] loss: 2.808033109132477\n",
      "[EPOCH #7, step #284] loss: 2.8116792369307135\n",
      "[EPOCH #7, step #286] loss: 2.8127370611715814\n",
      "[EPOCH #7, step #288] loss: 2.813748433928176\n",
      "[EPOCH #7, step #290] loss: 2.8127640153943876\n",
      "[EPOCH #7, step #292] loss: 2.812505899435831\n",
      "[EPOCH #7, step #294] loss: 2.8114047163623876\n",
      "[EPOCH #7, step #296] loss: 2.8122215632236367\n",
      "[EPOCH #7, step #298] loss: 2.811766548698961\n",
      "[EPOCH #7, step #300] loss: 2.813814268555752\n",
      "[EPOCH #7, step #302] loss: 2.812621288960523\n",
      "[EPOCH #7, step #304] loss: 2.8133144495917146\n",
      "[EPOCH #7, step #306] loss: 2.813731242468769\n",
      "[EPOCH #7, step #308] loss: 2.814719097513983\n",
      "[EPOCH #7, step #310] loss: 2.8138971512723967\n",
      "[EPOCH #7, step #312] loss: 2.8137692818626427\n",
      "[EPOCH #7, step #314] loss: 2.815294165081448\n",
      "[EPOCH #7, step #316] loss: 2.814610645221987\n",
      "[EPOCH #7, step #318] loss: 2.8144312450504603\n",
      "[EPOCH #7, step #320] loss: 2.8147308143128487\n",
      "[EPOCH #7, step #322] loss: 2.8153340085741165\n",
      "[EPOCH #7, step #324] loss: 2.816051183113685\n",
      "[EPOCH #7, step #326] loss: 2.815753421287653\n",
      "[EPOCH #7, step #328] loss: 2.8161372160114415\n",
      "[EPOCH #7, step #330] loss: 2.815815989704651\n",
      "[EPOCH #7, step #332] loss: 2.8154704033791482\n",
      "[EPOCH #7, step #334] loss: 2.8187351290859395\n",
      "[EPOCH #7, step #336] loss: 2.81891037165588\n",
      "[EPOCH #7, step #338] loss: 2.8181220781838294\n",
      "[EPOCH #7, step #340] loss: 2.8197710290332694\n",
      "[EPOCH #7, step #342] loss: 2.821082471063464\n",
      "[EPOCH #7, step #344] loss: 2.8224576079327126\n",
      "[EPOCH #7, step #346] loss: 2.820142374945649\n",
      "[EPOCH #7, step #348] loss: 2.820971916603154\n",
      "[EPOCH #7, step #350] loss: 2.8206199770979055\n",
      "[EPOCH #7, step #352] loss: 2.81971254362263\n",
      "[EPOCH #7, step #354] loss: 2.8199628285958735\n",
      "[EPOCH #7, step #356] loss: 2.8195789948898873\n",
      "[EPOCH #7, step #358] loss: 2.819261896909113\n",
      "[EPOCH #7, step #360] loss: 2.8199835503860853\n",
      "[EPOCH #7, step #362] loss: 2.821610534815092\n",
      "[EPOCH #7, step #364] loss: 2.820442133080469\n",
      "[EPOCH #7, step #366] loss: 2.821084280429809\n",
      "[EPOCH #7, step #368] loss: 2.822552513623948\n",
      "[EPOCH #7, step #370] loss: 2.8217001115536755\n",
      "[EPOCH #7, step #372] loss: 2.821422821075603\n",
      "[EPOCH #7, step #374] loss: 2.8218549455006916\n",
      "[EPOCH #7, step #376] loss: 2.8227060625344436\n",
      "[EPOCH #7, step #378] loss: 2.8233390709970116\n",
      "[EPOCH #7, step #380] loss: 2.822144525257621\n",
      "[EPOCH #7, step #382] loss: 2.822819849218463\n",
      "[EPOCH #7, step #384] loss: 2.822836800364705\n",
      "[EPOCH #7, step #386] loss: 2.8227332907437663\n",
      "[EPOCH #7, step #388] loss: 2.820379036557705\n",
      "[EPOCH #7, step #390] loss: 2.817474280171992\n",
      "[EPOCH #7, step #392] loss: 2.81700516080735\n",
      "[EPOCH #7, step #394] loss: 2.8174186480196215\n",
      "[EPOCH #7, step #396] loss: 2.8172217511410076\n",
      "[EPOCH #7, step #398] loss: 2.8165651458247862\n",
      "[EPOCH #7, step #400] loss: 2.8171492731779293\n",
      "[EPOCH #7, step #402] loss: 2.8179420723808613\n",
      "[EPOCH #7, step #404] loss: 2.818680543369717\n",
      "[EPOCH #7, step #406] loss: 2.8169600070255103\n",
      "[EPOCH #7, step #408] loss: 2.817490696324113\n",
      "[EPOCH #7, step #410] loss: 2.8181852142886235\n",
      "[EPOCH #7, step #412] loss: 2.8192627860039257\n",
      "[EPOCH #7, step #414] loss: 2.818747421345079\n",
      "[EPOCH #7, step #416] loss: 2.818548218237696\n",
      "[EPOCH #7, step #418] loss: 2.817209656028019\n",
      "[EPOCH #7, step #420] loss: 2.817046165183151\n",
      "[EPOCH #7, step #422] loss: 2.8183953404144755\n",
      "[EPOCH #7, step #424] loss: 2.81536178336424\n",
      "[EPOCH #7, step #426] loss: 2.8170080662332038\n",
      "[EPOCH #7, step #428] loss: 2.817681470673123\n",
      "[EPOCH #7, step #430] loss: 2.8178924288937774\n",
      "[EPOCH #7, step #432] loss: 2.819578018529861\n",
      "[EPOCH #7, step #434] loss: 2.819690991270131\n",
      "[EPOCH #7, step #436] loss: 2.8194207454982556\n",
      "[EPOCH #7, step #438] loss: 2.8187594269837226\n",
      "[EPOCH #7, step #440] loss: 2.818441607514206\n",
      "[EPOCH #7, step #442] loss: 2.8178365340889444\n",
      "[EPOCH #7, step #444] loss: 2.8199525053581493\n",
      "[EPOCH #7, step #446] loss: 2.820334823606265\n",
      "[EPOCH #7, step #448] loss: 2.8202599122423373\n",
      "[EPOCH #7, step #450] loss: 2.820468439231162\n",
      "[EPOCH #7, step #452] loss: 2.822144461783352\n",
      "[EPOCH #7, step #454] loss: 2.8219832333889636\n",
      "[EPOCH #7, step #456] loss: 2.8232057243259523\n",
      "[EPOCH #7, step #458] loss: 2.822607197532986\n",
      "[EPOCH #7, step #460] loss: 2.8225569587984727\n",
      "[EPOCH #7, step #462] loss: 2.8224037849619887\n",
      "[EPOCH #7, step #464] loss: 2.8221794146363455\n",
      "[EPOCH #7, step #466] loss: 2.8222482783891403\n",
      "[EPOCH #7, step #468] loss: 2.8215732119485004\n",
      "[EPOCH #7, step #470] loss: 2.822669439001954\n",
      "[EPOCH #7, step #472] loss: 2.8226388874316064\n",
      "[EPOCH #7, step #474] loss: 2.8226920255861785\n",
      "[EPOCH #7, step #476] loss: 2.8226635463582643\n",
      "[EPOCH #7, step #478] loss: 2.822273651841787\n",
      "[EPOCH #7, step #480] loss: 2.8224666715907456\n",
      "[EPOCH #7, step #482] loss: 2.8222857279313525\n",
      "[EPOCH #7, step #484] loss: 2.8223016264512366\n",
      "[EPOCH #7, step #486] loss: 2.821394124559798\n",
      "[EPOCH #7, step #488] loss: 2.8223169900644534\n",
      "[EPOCH #7, step #490] loss: 2.8233600087661124\n",
      "[EPOCH #7, step #492] loss: 2.823944159260144\n",
      "[EPOCH #7, step #494] loss: 2.8228165580768776\n",
      "[EPOCH #7, step #496] loss: 2.823324825442293\n",
      "[EPOCH #7, step #498] loss: 2.822979087342241\n",
      "[EPOCH #7, step #500] loss: 2.821811093303734\n",
      "[EPOCH #7, step #502] loss: 2.823218223588841\n",
      "[EPOCH #7, step #504] loss: 2.824026868603017\n",
      "[EPOCH #7, step #506] loss: 2.824275353721378\n",
      "[EPOCH #7, step #508] loss: 2.82496276187522\n",
      "[EPOCH #7, step #510] loss: 2.8243944665923744\n",
      "[EPOCH #7, step #512] loss: 2.8235659731758966\n",
      "[EPOCH #7, step #514] loss: 2.82326355790629\n",
      "[EPOCH #7, step #516] loss: 2.823265314332752\n",
      "[EPOCH #7, step #518] loss: 2.8251075655049673\n",
      "[EPOCH #7, step #520] loss: 2.824620031578298\n",
      "[EPOCH #7, step #522] loss: 2.824836766286744\n",
      "[EPOCH #7, step #524] loss: 2.825304264568147\n",
      "[EPOCH #7, step #526] loss: 2.8261381247464348\n",
      "[EPOCH #7, step #528] loss: 2.826267671269595\n",
      "[EPOCH #7, step #530] loss: 2.8259531865685674\n",
      "[EPOCH #7, step #532] loss: 2.8258376316102765\n",
      "[EPOCH #7, step #534] loss: 2.8271546268017493\n",
      "[EPOCH #7, step #536] loss: 2.826396528125031\n",
      "[EPOCH #7, step #538] loss: 2.8260904838070133\n",
      "[EPOCH #7, step #540] loss: 2.826018350402\n",
      "[EPOCH #7, step #542] loss: 2.8251118991475956\n",
      "[EPOCH #7, step #544] loss: 2.824356896067978\n",
      "[EPOCH #7, step #546] loss: 2.824048987036431\n",
      "[EPOCH #7, step #548] loss: 2.8241825718263027\n",
      "[EPOCH #7, step #550] loss: 2.823539421259816\n",
      "[EPOCH #7, step #552] loss: 2.823676366486989\n",
      "[EPOCH #7, step #554] loss: 2.8242021442533614\n",
      "[EPOCH #7, step #556] loss: 2.824591461375115\n",
      "[EPOCH #7, step #558] loss: 2.8250380106177015\n",
      "[EPOCH #7, step #560] loss: 2.8235009623933816\n",
      "[EPOCH #7, step #562] loss: 2.8231005929079616\n",
      "[EPOCH #7, step #564] loss: 2.823243495004367\n",
      "[EPOCH #7, step #566] loss: 2.8223677419480824\n",
      "[EPOCH #7, step #568] loss: 2.821569261944776\n",
      "[EPOCH #7, step #570] loss: 2.8224650993029834\n",
      "[EPOCH #7, step #572] loss: 2.8223511604738487\n",
      "[EPOCH #7, step #574] loss: 2.823622787931691\n",
      "[EPOCH #7, step #576] loss: 2.823661692840801\n",
      "[EPOCH #7, step #578] loss: 2.823420848047589\n",
      "[EPOCH #7, step #580] loss: 2.8229443269834666\n",
      "[EPOCH #7, step #582] loss: 2.8233451346385947\n",
      "[EPOCH #7, step #584] loss: 2.8232473456961475\n",
      "[EPOCH #7, step #586] loss: 2.822589396008844\n",
      "[EPOCH #7, step #588] loss: 2.8219486806914844\n",
      "[EPOCH #7, step #590] loss: 2.82128798638907\n",
      "[EPOCH #7, step #592] loss: 2.8217755379202396\n",
      "[EPOCH #7, step #594] loss: 2.821081534353625\n",
      "[EPOCH #7, step #596] loss: 2.82170187548377\n",
      "[EPOCH #7, step #598] loss: 2.8218549326783626\n",
      "[EPOCH #7, step #600] loss: 2.8214414879406946\n",
      "[EPOCH #7, step #602] loss: 2.8216833358578026\n",
      "[EPOCH #7, step #604] loss: 2.821957558836819\n",
      "[EPOCH #7, step #606] loss: 2.8207988124310086\n",
      "[EPOCH #7, step #608] loss: 2.820154357426272\n",
      "[EPOCH #7, step #610] loss: 2.8207414483867965\n",
      "[EPOCH #7, step #612] loss: 2.8207573363675964\n",
      "[EPOCH #7, step #614] loss: 2.8215296786005903\n",
      "[EPOCH #7, step #616] loss: 2.8210204151886207\n",
      "[EPOCH #7, step #618] loss: 2.8208638136914552\n",
      "[EPOCH #7, step #620] loss: 2.8214669194966313\n",
      "[EPOCH #7, step #622] loss: 2.8215886247291992\n",
      "[EPOCH #7, step #624] loss: 2.823110157966614\n",
      "[EPOCH #7, step #626] loss: 2.8230243936490025\n",
      "[EPOCH #7, step #628] loss: 2.8236087632672016\n",
      "[EPOCH #7, step #630] loss: 2.823773096745063\n",
      "[EPOCH #7, step #632] loss: 2.8239252264089116\n",
      "[EPOCH #7, step #634] loss: 2.823801025818652\n",
      "[EPOCH #7, step #636] loss: 2.8238618053858473\n",
      "[EPOCH #7, step #638] loss: 2.8253566448304204\n",
      "[EPOCH #7, step #640] loss: 2.825093879528611\n",
      "[EPOCH #7, step #642] loss: 2.8245176581164726\n",
      "[EPOCH #7, step #644] loss: 2.8245510509771896\n",
      "[EPOCH #7, step #646] loss: 2.8247976754511344\n",
      "[EPOCH #7, step #648] loss: 2.8244596840971607\n",
      "[EPOCH #7, step #650] loss: 2.825960344433235\n",
      "[EPOCH #7, step #652] loss: 2.8260509009383172\n",
      "[EPOCH #7, step #654] loss: 2.8261427244157282\n",
      "[EPOCH #7, step #656] loss: 2.8259039924932217\n",
      "[EPOCH #7, step #658] loss: 2.8257245928817887\n",
      "[EPOCH #7, step #660] loss: 2.824815753548661\n",
      "[EPOCH #7, step #662] loss: 2.8259106079737344\n",
      "[EPOCH #7, step #664] loss: 2.82528639467139\n",
      "[EPOCH #7, step #666] loss: 2.8253510068024115\n",
      "[EPOCH #7, step #668] loss: 2.825360193559051\n",
      "[EPOCH #7, step #670] loss: 2.8257545254091925\n",
      "[EPOCH #7, step #672] loss: 2.8260594811871713\n",
      "[EPOCH #7, step #674] loss: 2.8257536589657817\n",
      "[EPOCH #7, step #676] loss: 2.8258289133956547\n",
      "[EPOCH #7, step #678] loss: 2.8252700598847356\n",
      "[EPOCH #7, step #680] loss: 2.8251779592334785\n",
      "[EPOCH #7, step #682] loss: 2.825372622442455\n",
      "[EPOCH #7, step #684] loss: 2.825805110130867\n",
      "[EPOCH #7, step #686] loss: 2.825542992205946\n",
      "[EPOCH #7, step #688] loss: 2.8251614613872134\n",
      "[EPOCH #7, step #690] loss: 2.8244627527838677\n",
      "[EPOCH #7, step #692] loss: 2.8250821006590496\n",
      "[EPOCH #7, step #694] loss: 2.8255902298920446\n",
      "[EPOCH #7, step #696] loss: 2.825175682988707\n",
      "[EPOCH #7, step #698] loss: 2.8249216333820413\n",
      "[EPOCH #7, step #700] loss: 2.825335404842284\n",
      "[EPOCH #7, step #702] loss: 2.825688932732193\n",
      "[EPOCH #7, step #704] loss: 2.8251460313797\n",
      "[EPOCH #7, step #706] loss: 2.8246487213833498\n",
      "[EPOCH #7, step #708] loss: 2.8234043724950513\n",
      "[EPOCH #7, step #710] loss: 2.8236413556982862\n",
      "[EPOCH #7, step #712] loss: 2.8241833368156937\n",
      "[EPOCH #7, step #714] loss: 2.8239379204236545\n",
      "[EPOCH #7, step #716] loss: 2.8239928124838793\n",
      "[EPOCH #7, step #718] loss: 2.8239894670969257\n",
      "[EPOCH #7, step #720] loss: 2.8233076297625095\n",
      "[EPOCH #7, step #722] loss: 2.823084759844124\n",
      "[EPOCH #7, step #724] loss: 2.8236626011749792\n",
      "[EPOCH #7, step #726] loss: 2.822816745615071\n",
      "[EPOCH #7, step #728] loss: 2.8225727282433843\n",
      "[EPOCH #7, step #730] loss: 2.8235455956896094\n",
      "[EPOCH #7, step #732] loss: 2.8227647624269516\n",
      "[EPOCH #7, step #734] loss: 2.822022458647384\n",
      "[EPOCH #7, step #736] loss: 2.821246749025187\n",
      "[EPOCH #7, step #738] loss: 2.8214609650378297\n",
      "[EPOCH #7, step #740] loss: 2.8205674207805784\n",
      "[EPOCH #7, step #742] loss: 2.820880303472722\n",
      "[EPOCH #7, step #744] loss: 2.8216849799124186\n",
      "[EPOCH #7, step #746] loss: 2.8221590728006527\n",
      "[EPOCH #7, step #748] loss: 2.8221179195971926\n",
      "[EPOCH #7, step #750] loss: 2.8219811540151563\n",
      "[EPOCH #7, step #752] loss: 2.822372596893969\n",
      "[EPOCH #7, step #754] loss: 2.8221175091156105\n",
      "[EPOCH #7, step #756] loss: 2.8214020938507947\n",
      "[EPOCH #7, step #758] loss: 2.8217591980229253\n",
      "[EPOCH #7, step #760] loss: 2.822581735296412\n",
      "[EPOCH #7, step #762] loss: 2.8217201303217077\n",
      "[EPOCH #7, step #764] loss: 2.8222801234987047\n",
      "[EPOCH #7, step #766] loss: 2.821514323140061\n",
      "[EPOCH #7, step #768] loss: 2.8210966718832444\n",
      "[EPOCH #7, step #770] loss: 2.8201692483149925\n",
      "[EPOCH #7, step #772] loss: 2.8201670703727553\n",
      "[EPOCH #7, step #774] loss: 2.8201079493184245\n",
      "[EPOCH #7, step #776] loss: 2.8198706178591517\n",
      "[EPOCH #7, step #778] loss: 2.8194686817112875\n",
      "[EPOCH #7, step #780] loss: 2.819447435429093\n",
      "[EPOCH #7, step #782] loss: 2.819958005828419\n",
      "[EPOCH #7, step #784] loss: 2.819313369283251\n",
      "[EPOCH #7, step #786] loss: 2.818979348887937\n",
      "[EPOCH #7, step #788] loss: 2.818689096563216\n",
      "[EPOCH #7, step #790] loss: 2.81897822629034\n",
      "[EPOCH #7, step #792] loss: 2.818939903044009\n",
      "[EPOCH #7, step #794] loss: 2.8188063053215076\n",
      "[EPOCH #7, step #796] loss: 2.818455818306697\n",
      "[EPOCH #7, step #798] loss: 2.8189337192399333\n",
      "[EPOCH #7, step #800] loss: 2.8188534031497703\n",
      "[EPOCH #7, step #802] loss: 2.8198930960366617\n",
      "[EPOCH #7, step #804] loss: 2.82005475900188\n",
      "[EPOCH #7, step #806] loss: 2.8196663683675034\n",
      "[EPOCH #7, step #808] loss: 2.819342151855214\n",
      "[EPOCH #7, step #810] loss: 2.8195894177539134\n",
      "[EPOCH #7, step #812] loss: 2.8195169448559283\n",
      "[EPOCH #7, step #814] loss: 2.819590855376121\n",
      "[EPOCH #7, step #816] loss: 2.8185807778756504\n",
      "[EPOCH #7, step #818] loss: 2.8189175735899816\n",
      "[EPOCH #7, step #820] loss: 2.818868922112775\n",
      "[EPOCH #7, step #822] loss: 2.818590988799984\n",
      "[EPOCH #7, step #824] loss: 2.818368211370526\n",
      "[EPOCH #7, step #826] loss: 2.81922132432677\n",
      "[EPOCH #7, step #828] loss: 2.8191182652198505\n",
      "[EPOCH #7, step #830] loss: 2.8194543940926287\n",
      "[EPOCH #7, step #832] loss: 2.8194447523978003\n",
      "[EPOCH #7, step #834] loss: 2.820272839569046\n",
      "[EPOCH #7, step #836] loss: 2.8205653574304344\n",
      "[EPOCH #7, step #838] loss: 2.820194023442638\n",
      "[EPOCH #7, step #840] loss: 2.819681979388034\n",
      "[EPOCH #7, step #842] loss: 2.8197754092629412\n",
      "[EPOCH #7, step #844] loss: 2.8201036578804786\n",
      "[EPOCH #7, step #846] loss: 2.8198554956364097\n",
      "[EPOCH #7, step #848] loss: 2.820579696600232\n",
      "[EPOCH #7, step #850] loss: 2.820359824126812\n",
      "[EPOCH #7, step #852] loss: 2.8201023686812605\n",
      "[EPOCH #7, step #854] loss: 2.8202756219440035\n",
      "[EPOCH #7, step #856] loss: 2.8195432992076093\n",
      "[EPOCH #7, step #858] loss: 2.8197922394356154\n",
      "[EPOCH #7, step #860] loss: 2.82046827912746\n",
      "[EPOCH #7, step #862] loss: 2.8205831823039578\n",
      "[EPOCH #7, step #864] loss: 2.8205595902624845\n",
      "[EPOCH #7, step #866] loss: 2.8204810705976917\n",
      "[EPOCH #7, step #868] loss: 2.8206039055307386\n",
      "[EPOCH #7, step #870] loss: 2.820646300107822\n",
      "[EPOCH #7, step #872] loss: 2.8212256389248687\n",
      "[EPOCH #7, step #874] loss: 2.820878967148917\n",
      "[EPOCH #7, step #876] loss: 2.819828511779637\n",
      "[EPOCH #7, step #878] loss: 2.8205594670650496\n",
      "[EPOCH #7, step #880] loss: 2.8204417903902312\n",
      "[EPOCH #7, step #882] loss: 2.820183390129193\n",
      "[EPOCH #7, step #884] loss: 2.82039578526707\n",
      "[EPOCH #7, step #886] loss: 2.820237005576743\n",
      "[EPOCH #7, step #888] loss: 2.820635007256464\n",
      "[EPOCH #7, step #890] loss: 2.820965358972817\n",
      "[EPOCH #7, step #892] loss: 2.820936086196515\n",
      "[EPOCH #7, step #894] loss: 2.821542834569622\n",
      "[EPOCH #7, step #896] loss: 2.8215179061942806\n",
      "[EPOCH #7, step #898] loss: 2.8207161616165197\n",
      "[EPOCH #7, step #900] loss: 2.8206643966935188\n",
      "[EPOCH #7, step #902] loss: 2.8206695561129127\n",
      "[EPOCH #7, step #904] loss: 2.8212141101531563\n",
      "[EPOCH #7, step #906] loss: 2.8209265830629846\n",
      "[EPOCH #7, step #908] loss: 2.8209156157291106\n",
      "[EPOCH #7, step #910] loss: 2.8207951946394636\n",
      "[EPOCH #7, step #912] loss: 2.820502300643712\n",
      "[EPOCH #7, step #914] loss: 2.8208070328978243\n",
      "[EPOCH #7, step #916] loss: 2.8202116982107466\n",
      "[EPOCH #7, step #918] loss: 2.8195783833814003\n",
      "[EPOCH #7, step #920] loss: 2.819386845820631\n",
      "[EPOCH #7, step #922] loss: 2.8195768785889976\n",
      "[EPOCH #7, step #924] loss: 2.8193655389064065\n",
      "[EPOCH #7, step #926] loss: 2.819530696802026\n",
      "[EPOCH #7, step #928] loss: 2.819662554913368\n",
      "[EPOCH #7, step #930] loss: 2.8191349246448145\n",
      "[EPOCH #7, step #932] loss: 2.819097238977111\n",
      "[EPOCH #7, step #934] loss: 2.819026357094872\n",
      "[EPOCH #7, step #936] loss: 2.818747165617846\n",
      "[EPOCH #7, step #938] loss: 2.8182209235029863\n",
      "[EPOCH #7, step #940] loss: 2.8183962983355384\n",
      "[EPOCH #7, step #942] loss: 2.818869442980211\n",
      "[EPOCH #7, step #944] loss: 2.8194918686750703\n",
      "[EPOCH #7, step #946] loss: 2.8201409636228614\n",
      "[EPOCH #7, step #948] loss: 2.8198738825459375\n",
      "[EPOCH #7, step #950] loss: 2.8197051076106843\n",
      "[EPOCH #7, step #952] loss: 2.8192969170347215\n",
      "[EPOCH #7, step #954] loss: 2.8193638435833117\n",
      "[EPOCH #7, step #956] loss: 2.818181350562515\n",
      "[EPOCH #7, step #958] loss: 2.818425953698979\n",
      "[EPOCH #7, step #960] loss: 2.8190291766445545\n",
      "[EPOCH #7, step #962] loss: 2.8184724908751493\n",
      "[EPOCH #7, step #964] loss: 2.818193908058918\n",
      "[EPOCH #7, step #966] loss: 2.8177210779199924\n",
      "[EPOCH #7, step #968] loss: 2.8178022331005526\n",
      "[EPOCH #7, step #970] loss: 2.817578602279129\n",
      "[EPOCH #7, step #972] loss: 2.817208126907113\n",
      "[EPOCH #7, step #974] loss: 2.8172302901439177\n",
      "[EPOCH #7, step #976] loss: 2.8175053637981904\n",
      "[EPOCH #7, step #978] loss: 2.817801673273509\n",
      "[EPOCH #7, step #980] loss: 2.817881991739302\n",
      "[EPOCH #7, step #982] loss: 2.8181489045113053\n",
      "[EPOCH #7, step #984] loss: 2.817923973538549\n",
      "[EPOCH #7, step #986] loss: 2.8183873368855545\n",
      "[EPOCH #7, step #988] loss: 2.818270947501681\n",
      "[EPOCH #7, step #990] loss: 2.8182345223354646\n",
      "[EPOCH #7, step #992] loss: 2.817885788785967\n",
      "[EPOCH #7, step #994] loss: 2.817633991385225\n",
      "[EPOCH #7, step #996] loss: 2.8177086285865656\n",
      "[EPOCH #7, step #998] loss: 2.8173135720693074\n",
      "[EPOCH #7, step #1000] loss: 2.817014284305401\n",
      "[EPOCH #7, step #1002] loss: 2.8173466990975773\n",
      "[EPOCH #7, step #1004] loss: 2.817706789899228\n",
      "[EPOCH #7, step #1006] loss: 2.8175409557566033\n",
      "[EPOCH #7, step #1008] loss: 2.817254920190106\n",
      "[EPOCH #7, step #1010] loss: 2.817203221995564\n",
      "[EPOCH #7, step #1012] loss: 2.8172862456793375\n",
      "[EPOCH #7, step #1014] loss: 2.816882558174321\n",
      "[EPOCH #7, step #1016] loss: 2.8164938063513683\n",
      "[EPOCH #7, step #1018] loss: 2.815895100922065\n",
      "[EPOCH #7, step #1020] loss: 2.816093174647631\n",
      "[EPOCH #7, step #1022] loss: 2.81608122651295\n",
      "[EPOCH #7, step #1024] loss: 2.8157056592150433\n",
      "[EPOCH #7, step #1026] loss: 2.8149969491893616\n",
      "[EPOCH #7, step #1028] loss: 2.814728868946042\n",
      "[EPOCH #7, step #1030] loss: 2.8145259647665384\n",
      "[EPOCH #7, step #1032] loss: 2.814752250996356\n",
      "[EPOCH #7, step #1034] loss: 2.81444956553731\n",
      "[EPOCH #7, step #1036] loss: 2.8145232819085413\n",
      "[EPOCH #7, step #1038] loss: 2.81423168324644\n",
      "[EPOCH #7, step #1040] loss: 2.8141432699392213\n",
      "[EPOCH #7, step #1042] loss: 2.8138111138275232\n",
      "[EPOCH #7, step #1044] loss: 2.8133206978939365\n",
      "[EPOCH #7, step #1046] loss: 2.812784875361489\n",
      "[EPOCH #7, step #1048] loss: 2.8129404152541984\n",
      "[EPOCH #7, step #1050] loss: 2.812734342551481\n",
      "[EPOCH #7, step #1052] loss: 2.8129543361500797\n",
      "[EPOCH #7, step #1054] loss: 2.813012693956565\n",
      "[EPOCH #7, step #1056] loss: 2.812769936973911\n",
      "[EPOCH #7, step #1058] loss: 2.8117270766844493\n",
      "[EPOCH #7, step #1060] loss: 2.8109748988192\n",
      "[EPOCH #7, step #1062] loss: 2.8107757164640237\n",
      "[EPOCH #7, step #1064] loss: 2.810786461046604\n",
      "[EPOCH #7, step #1066] loss: 2.810696969438962\n",
      "[EPOCH #7, step #1068] loss: 2.811189395897404\n",
      "[EPOCH #7, step #1070] loss: 2.811147078078668\n",
      "[EPOCH #7, step #1072] loss: 2.8104988682081182\n",
      "[EPOCH #7, step #1074] loss: 2.810392930230429\n",
      "[EPOCH #7, step #1076] loss: 2.8105925776500222\n",
      "[EPOCH #7, step #1078] loss: 2.810389361633428\n",
      "[EPOCH #7, step #1080] loss: 2.810722410403171\n",
      "[EPOCH #7, step #1082] loss: 2.810012818703691\n",
      "[EPOCH #7, step #1084] loss: 2.8097539991827056\n",
      "[EPOCH #7, step #1086] loss: 2.8096565452319497\n",
      "[EPOCH #7, step #1088] loss: 2.8094835638233673\n",
      "[EPOCH #7, step #1090] loss: 2.8096709917926876\n",
      "[EPOCH #7, step #1092] loss: 2.8098057971999717\n",
      "[EPOCH #7, step #1094] loss: 2.8097084398139014\n",
      "[EPOCH #7, step #1096] loss: 2.809978894787478\n",
      "[EPOCH #7, step #1098] loss: 2.8096308556331953\n",
      "[EPOCH #7, step #1100] loss: 2.8097980851806583\n",
      "[EPOCH #7, step #1102] loss: 2.8092061703786566\n",
      "[EPOCH #7, step #1104] loss: 2.8091168356157534\n",
      "[EPOCH #7, step #1106] loss: 2.8095722304019395\n",
      "[EPOCH #7, step #1108] loss: 2.80909754909622\n",
      "[EPOCH #7, step #1110] loss: 2.809002503524698\n",
      "[EPOCH #7, step #1112] loss: 2.808922312009045\n",
      "[EPOCH #7, step #1114] loss: 2.8084809328943092\n",
      "[EPOCH #7, step #1116] loss: 2.8081593436648404\n",
      "[EPOCH #7, step #1118] loss: 2.808049531575289\n",
      "[EPOCH #7, step #1120] loss: 2.8075786023986433\n",
      "[EPOCH #7, step #1122] loss: 2.8070566331501636\n",
      "[EPOCH #7, step #1124] loss: 2.8066326546139186\n",
      "[EPOCH #7, step #1126] loss: 2.806492304103821\n",
      "[EPOCH #7, step #1128] loss: 2.806200450452901\n",
      "[EPOCH #7, step #1130] loss: 2.8066273121365817\n",
      "[EPOCH #7, step #1132] loss: 2.8065101328089717\n",
      "[EPOCH #7, step #1134] loss: 2.8067118058645777\n",
      "[EPOCH #7, step #1136] loss: 2.806370114063944\n",
      "[EPOCH #7, step #1138] loss: 2.806659224370365\n",
      "[EPOCH #7, step #1140] loss: 2.806694744554765\n",
      "[EPOCH #7, step #1142] loss: 2.806255319091383\n",
      "[EPOCH #7, step #1144] loss: 2.8057671936318345\n",
      "[EPOCH #7, step #1146] loss: 2.8055566581519873\n",
      "[EPOCH #7, step #1148] loss: 2.80538833608204\n",
      "[EPOCH #7, step #1150] loss: 2.805541917202682\n",
      "[EPOCH #7, step #1152] loss: 2.8058080698031502\n",
      "[EPOCH #7, step #1154] loss: 2.8054914488936915\n",
      "[EPOCH #7, step #1156] loss: 2.8054428613690745\n",
      "[EPOCH #7, step #1158] loss: 2.8054850827629347\n",
      "[EPOCH #7, step #1160] loss: 2.8053463599889263\n",
      "[EPOCH #7, step #1162] loss: 2.805605025303743\n",
      "[EPOCH #7, step #1164] loss: 2.8060767267906614\n",
      "[EPOCH #7, step #1166] loss: 2.806105298677263\n",
      "[EPOCH #7, step #1168] loss: 2.8060200832357154\n",
      "[EPOCH #7, step #1170] loss: 2.8060732679831277\n",
      "[EPOCH #7, step #1172] loss: 2.8060914008716997\n",
      "[EPOCH #7, step #1174] loss: 2.806454407915156\n",
      "[EPOCH #7, step #1176] loss: 2.8064766509510646\n",
      "[EPOCH #7, step #1178] loss: 2.8061839860814217\n",
      "[EPOCH #7, step #1180] loss: 2.806500703575851\n",
      "[EPOCH #7, step #1182] loss: 2.8058940378771124\n",
      "[EPOCH #7, step #1184] loss: 2.805748003947584\n",
      "[EPOCH #7, step #1186] loss: 2.805853125621214\n",
      "[EPOCH #7, step #1188] loss: 2.805909547813807\n",
      "[EPOCH #7, step #1190] loss: 2.8061320397355396\n",
      "[EPOCH #7, step #1192] loss: 2.8066585863326043\n",
      "[EPOCH #7, step #1194] loss: 2.806862675694741\n",
      "[EPOCH #7, step #1196] loss: 2.8062781917122672\n",
      "[EPOCH #7, step #1198] loss: 2.8069691950326368\n",
      "[EPOCH #7, step #1200] loss: 2.806639323127359\n",
      "[EPOCH #7, step #1202] loss: 2.8062743595611623\n",
      "[EPOCH #7, step #1204] loss: 2.806122675970877\n",
      "[EPOCH #7, step #1206] loss: 2.8061967719756775\n",
      "[EPOCH #7, step #1208] loss: 2.80634638314606\n",
      "[EPOCH #7, step #1210] loss: 2.806204176460978\n",
      "[EPOCH #7, step #1212] loss: 2.8062534306723523\n",
      "[EPOCH #7, step #1214] loss: 2.8056187331431195\n",
      "[EPOCH #7, step #1216] loss: 2.8053691244164547\n",
      "[EPOCH #7, step #1218] loss: 2.805543680284921\n",
      "[EPOCH #7, step #1220] loss: 2.8054514278846137\n",
      "[EPOCH #7, step #1222] loss: 2.805483075116174\n",
      "[EPOCH #7, step #1224] loss: 2.8056544517984197\n",
      "[EPOCH #7, step #1226] loss: 2.8057480264506696\n",
      "[EPOCH #7, step #1228] loss: 2.805370874187634\n",
      "[EPOCH #7, step #1230] loss: 2.805623139916737\n",
      "[EPOCH #7, step #1232] loss: 2.805366328356233\n",
      "[EPOCH #7, step #1234] loss: 2.805435017921664\n",
      "[EPOCH #7, step #1236] loss: 2.804645561844279\n",
      "[EPOCH #7, step #1238] loss: 2.8045247097569574\n",
      "[EPOCH #7, step #1240] loss: 2.8043361799453748\n",
      "[EPOCH #7, step #1242] loss: 2.804330398647035\n",
      "[EPOCH #7, step #1244] loss: 2.804241194973988\n",
      "[EPOCH #7, step #1246] loss: 2.8036589681767614\n",
      "[EPOCH #7, step #1248] loss: 2.8034497847835764\n",
      "[EPOCH #7, step #1250] loss: 2.8030824331547337\n",
      "[EPOCH #7, step #1252] loss: 2.803750016835815\n",
      "[EPOCH #7, step #1254] loss: 2.8034684357890094\n",
      "[EPOCH #7, step #1256] loss: 2.8034834095477676\n",
      "[EPOCH #7, step #1258] loss: 2.803542036400417\n",
      "[EPOCH #7, step #1260] loss: 2.803099837216189\n",
      "[EPOCH #7, step #1262] loss: 2.8034291646826013\n",
      "[EPOCH #7, step #1264] loss: 2.803806901072325\n",
      "[EPOCH #7, step #1266] loss: 2.804030669045994\n",
      "[EPOCH #7, step #1268] loss: 2.8037281316316816\n",
      "[EPOCH #7, step #1270] loss: 2.804327031742579\n",
      "[EPOCH #7, step #1272] loss: 2.804611118590841\n",
      "[EPOCH #7, step #1274] loss: 2.8044877746058448\n",
      "[EPOCH #7, step #1276] loss: 2.8040940347087506\n",
      "[EPOCH #7, step #1278] loss: 2.8046306421087532\n",
      "[EPOCH #7, step #1280] loss: 2.8046365065280576\n",
      "[EPOCH #7, step #1282] loss: 2.804358335555947\n",
      "[EPOCH #7, step #1284] loss: 2.804355610576585\n",
      "[EPOCH #7, step #1286] loss: 2.8041858819444325\n",
      "[EPOCH #7, step #1288] loss: 2.804410030899166\n",
      "[EPOCH #7, step #1290] loss: 2.8040808547291065\n",
      "[EPOCH #7, step #1292] loss: 2.803975105470036\n",
      "[EPOCH #7, step #1294] loss: 2.8033162277177492\n",
      "[EPOCH #7, step #1296] loss: 2.8033006035004013\n",
      "[EPOCH #7, step #1298] loss: 2.8028382080348297\n",
      "[EPOCH #7, step #1300] loss: 2.802893629631201\n",
      "[EPOCH #7, step #1302] loss: 2.8029108230462003\n",
      "[EPOCH #7, step #1304] loss: 2.8025315693968555\n",
      "[EPOCH #7, step #1306] loss: 2.802194217734421\n",
      "[EPOCH #7, step #1308] loss: 2.8021740254051726\n",
      "[EPOCH #7, step #1310] loss: 2.8022222655315967\n",
      "[EPOCH #7, step #1312] loss: 2.801887397083361\n",
      "[EPOCH #7, step #1314] loss: 2.8017597771416147\n",
      "[EPOCH #7, step #1316] loss: 2.801790333192459\n",
      "[EPOCH #7, step #1318] loss: 2.802360679273627\n",
      "[EPOCH #7, step #1320] loss: 2.802166130577047\n",
      "[EPOCH #7, step #1322] loss: 2.8020630852345345\n",
      "[EPOCH #7, step #1324] loss: 2.8018505987131372\n",
      "[EPOCH #7, step #1326] loss: 2.802007728532103\n",
      "[EPOCH #7, step #1328] loss: 2.801764501674988\n",
      "[EPOCH #7, step #1330] loss: 2.8016521303748654\n",
      "[EPOCH #7, step #1332] loss: 2.8019804525268053\n",
      "[EPOCH #7, step #1334] loss: 2.801679064361344\n",
      "[EPOCH #7, step #1336] loss: 2.801191159478746\n",
      "[EPOCH #7, step #1338] loss: 2.8010215558072717\n",
      "[EPOCH #7, step #1340] loss: 2.8009708953561576\n",
      "[EPOCH #7, step #1342] loss: 2.8007890024206485\n",
      "[EPOCH #7, step #1344] loss: 2.7999863176097657\n",
      "[EPOCH #7, step #1346] loss: 2.799432980899202\n",
      "[EPOCH #7, step #1348] loss: 2.7994682417700605\n",
      "[EPOCH #7, step #1350] loss: 2.7991846828968945\n",
      "[EPOCH #7, step #1352] loss: 2.7993516210089413\n",
      "[EPOCH #7, step #1354] loss: 2.7993045812163406\n",
      "[EPOCH #7, step #1356] loss: 2.7991813473079517\n",
      "[EPOCH #7, step #1358] loss: 2.7993461254153558\n",
      "[EPOCH #7, step #1360] loss: 2.7989092959278565\n",
      "[EPOCH #7, step #1362] loss: 2.798370798807851\n",
      "[EPOCH #7, step #1364] loss: 2.7983040310087657\n",
      "[EPOCH #7, step #1366] loss: 2.798151597892968\n",
      "[EPOCH #7, step #1368] loss: 2.7983081730897625\n",
      "[EPOCH #7, step #1370] loss: 2.7982721417424976\n",
      "[EPOCH #7, step #1372] loss: 2.798658196802827\n",
      "[EPOCH #7, step #1374] loss: 2.7988574504852295\n",
      "[EPOCH #7, step #1376] loss: 2.7986193865039857\n",
      "[EPOCH #7, step #1378] loss: 2.7985745178261383\n",
      "[EPOCH #7, step #1380] loss: 2.798528978912663\n",
      "[EPOCH #7, step #1382] loss: 2.798719245458287\n",
      "[EPOCH #7, step #1384] loss: 2.7987892508937136\n",
      "[EPOCH #7, step #1386] loss: 2.7987145867034866\n",
      "[EPOCH #7, step #1388] loss: 2.7984557091717757\n",
      "[EPOCH #7, step #1390] loss: 2.798639294914339\n",
      "[EPOCH #7, step #1392] loss: 2.798219190256594\n",
      "[EPOCH #7, step #1394] loss: 2.797967932301183\n",
      "[EPOCH #7, step #1396] loss: 2.798119698410471\n",
      "[EPOCH #7, step #1398] loss: 2.7981515719773005\n",
      "[EPOCH #7, step #1400] loss: 2.797887073764624\n",
      "[EPOCH #7, step #1402] loss: 2.7977153270990613\n",
      "[EPOCH #7, step #1404] loss: 2.7976616913737775\n",
      "[EPOCH #7, step #1406] loss: 2.7977618839017193\n",
      "[EPOCH #7, step #1408] loss: 2.798180002113705\n",
      "[EPOCH #7, step #1410] loss: 2.7981910629529296\n",
      "[EPOCH #7, step #1412] loss: 2.7978823924014016\n",
      "[EPOCH #7, step #1414] loss: 2.7977517419484816\n",
      "[EPOCH #7, step #1416] loss: 2.7976249326007334\n",
      "[EPOCH #7, step #1418] loss: 2.797268201970483\n",
      "[EPOCH #7, step #1420] loss: 2.797219828096265\n",
      "[EPOCH #7, step #1422] loss: 2.796358427277603\n",
      "[EPOCH #7, step #1424] loss: 2.7961289721204525\n",
      "[EPOCH #7, step #1426] loss: 2.7963282942521297\n",
      "[EPOCH #7, step #1428] loss: 2.796337757767957\n",
      "[EPOCH #7, step #1430] loss: 2.796017264003607\n",
      "[EPOCH #7, step #1432] loss: 2.795845377386989\n",
      "[EPOCH #7, step #1434] loss: 2.795729292145174\n",
      "[EPOCH #7, step #1436] loss: 2.795460487042522\n",
      "[EPOCH #7, step #1438] loss: 2.7955547778286647\n",
      "[EPOCH #7, step #1440] loss: 2.7957739000267487\n",
      "[EPOCH #7, step #1442] loss: 2.7956296593797596\n",
      "[EPOCH #7, step #1444] loss: 2.795458279431485\n",
      "[EPOCH #7, step #1446] loss: 2.795147298942703\n",
      "[EPOCH #7, step #1448] loss: 2.79516741725969\n",
      "[EPOCH #7, step #1450] loss: 2.795154115645989\n",
      "[EPOCH #7, step #1452] loss: 2.7946545658485693\n",
      "[EPOCH #7, step #1454] loss: 2.794818684079803\n",
      "[EPOCH #7, step #1456] loss: 2.7944222700129493\n",
      "[EPOCH #7, step #1458] loss: 2.7947124058126667\n",
      "[EPOCH #7, step #1460] loss: 2.794926139363518\n",
      "[EPOCH #7, step #1462] loss: 2.7949484265673594\n",
      "[EPOCH #7, step #1464] loss: 2.7946880736855517\n",
      "[EPOCH #7, step #1466] loss: 2.7945768149758816\n",
      "[EPOCH #7, step #1468] loss: 2.7946552846446338\n",
      "[EPOCH #7, step #1470] loss: 2.7944087796596992\n",
      "[EPOCH #7, step #1472] loss: 2.7941206115812003\n",
      "[EPOCH #7, step #1474] loss: 2.794250078928673\n",
      "[EPOCH #7, step #1476] loss: 2.7936350488146173\n",
      "[EPOCH #7, step #1478] loss: 2.793277578066941\n",
      "[EPOCH #7, step #1480] loss: 2.7935657619544574\n",
      "[EPOCH #7, step #1482] loss: 2.793257542341365\n",
      "[EPOCH #7, step #1484] loss: 2.792928845874388\n",
      "[EPOCH #7, step #1486] loss: 2.792973549236126\n",
      "[EPOCH #7, step #1488] loss: 2.793304450965072\n",
      "[EPOCH #7, step #1490] loss: 2.7932386218422134\n",
      "[EPOCH #7, step #1492] loss: 2.792547729058467\n",
      "[EPOCH #7, step #1494] loss: 2.7926251078927797\n",
      "[EPOCH #7, step #1496] loss: 2.7928026148535525\n",
      "[EPOCH #7, step #1498] loss: 2.7926174418142113\n",
      "[EPOCH #7, step #1500] loss: 2.7922785421119856\n",
      "[EPOCH #7, step #1502] loss: 2.7922741479264523\n",
      "[EPOCH #7, step #1504] loss: 2.7921607758119653\n",
      "[EPOCH #7, step #1506] loss: 2.7921298607818006\n",
      "[EPOCH #7, step #1508] loss: 2.792018584102254\n",
      "[EPOCH #7, step #1510] loss: 2.7918606534215646\n",
      "[EPOCH #7, step #1512] loss: 2.7914812575092554\n",
      "[EPOCH #7, step #1514] loss: 2.7922728174197005\n",
      "[EPOCH #7, step #1516] loss: 2.7924269041735323\n",
      "[EPOCH #7, step #1518] loss: 2.7923273367658896\n",
      "[EPOCH #7, step #1520] loss: 2.7926269380925595\n",
      "[EPOCH #7, step #1522] loss: 2.7925474879308037\n",
      "[EPOCH #7, step #1524] loss: 2.7921064846632913\n",
      "[EPOCH #7, step #1526] loss: 2.791928902512371\n",
      "[EPOCH #7, step #1528] loss: 2.7917354148224804\n",
      "[EPOCH #7, step #1530] loss: 2.7916368409592214\n",
      "[EPOCH #7, step #1532] loss: 2.791243778127358\n",
      "[EPOCH #7, step #1534] loss: 2.790827411238456\n",
      "[EPOCH #7, step #1536] loss: 2.790417063212969\n",
      "[EPOCH #7, step #1538] loss: 2.7899392424968252\n",
      "[EPOCH #7, step #1540] loss: 2.790137864721819\n",
      "[EPOCH #7, step #1542] loss: 2.7905324760846173\n",
      "[EPOCH #7, step #1544] loss: 2.7898742247553705\n",
      "[EPOCH #7, step #1546] loss: 2.789582848086539\n",
      "[EPOCH #7, step #1548] loss: 2.7892893882164116\n",
      "[EPOCH #7, step #1550] loss: 2.7890655191232128\n",
      "[EPOCH #7, step #1552] loss: 2.7891232245058992\n",
      "[EPOCH #7, step #1554] loss: 2.788951082858242\n",
      "[EPOCH #7, step #1556] loss: 2.7885384912588846\n",
      "[EPOCH #7, step #1558] loss: 2.788505370453277\n",
      "[EPOCH #7, step #1560] loss: 2.7882042745990985\n",
      "[EPOCH #7, step #1562] loss: 2.7881249744619074\n",
      "[EPOCH #7, step #1564] loss: 2.788498121100112\n",
      "[EPOCH #7, step #1566] loss: 2.788217572475134\n",
      "[EPOCH #7, step #1568] loss: 2.788222613419751\n",
      "[EPOCH #7, step #1570] loss: 2.7885211704643877\n",
      "[EPOCH #7, step #1572] loss: 2.787920505698896\n",
      "[EPOCH #7, step #1574] loss: 2.787649940990266\n",
      "[EPOCH #7, step #1576] loss: 2.787348053995083\n",
      "[EPOCH #7, step #1578] loss: 2.787332709262913\n",
      "[EPOCH #7, step #1580] loss: 2.78701886227431\n",
      "[EPOCH #7, step #1582] loss: 2.787065554854995\n",
      "[EPOCH #7, step #1584] loss: 2.7870610502616087\n",
      "[EPOCH #7, step #1586] loss: 2.786898104064331\n",
      "[EPOCH #7, step #1588] loss: 2.7864791441443884\n",
      "[EPOCH #7, step #1590] loss: 2.786216854150006\n",
      "[EPOCH #7, step #1592] loss: 2.7856949057432367\n",
      "[EPOCH #7, step #1594] loss: 2.785538808604393\n",
      "[EPOCH #7, step #1596] loss: 2.7856367559229946\n",
      "[EPOCH #7, step #1598] loss: 2.7851611753043866\n",
      "[EPOCH #7, step #1600] loss: 2.7849110156427987\n",
      "[EPOCH #7, step #1602] loss: 2.785168687254655\n",
      "[EPOCH #7, step #1604] loss: 2.7850644910075584\n",
      "[EPOCH #7, step #1606] loss: 2.7850088297986955\n",
      "[EPOCH #7, step #1608] loss: 2.7848050891426945\n",
      "[EPOCH #7, step #1610] loss: 2.7850697053137363\n",
      "[EPOCH #7, step #1612] loss: 2.7843764782395337\n",
      "[EPOCH #7, step #1614] loss: 2.7837873354784843\n",
      "[EPOCH #7, step #1616] loss: 2.783953965189432\n",
      "[EPOCH #7, step #1618] loss: 2.7836182004806065\n",
      "[EPOCH #7, step #1620] loss: 2.7836043035300113\n",
      "[EPOCH #7, step #1622] loss: 2.7832469611864212\n",
      "[EPOCH #7, step #1624] loss: 2.7833068240972665\n",
      "[EPOCH #7, step #1626] loss: 2.783115781225452\n",
      "[EPOCH #7, step #1628] loss: 2.7829304046613297\n",
      "[EPOCH #7, step #1630] loss: 2.7826618825928846\n",
      "[EPOCH #7, step #1632] loss: 2.7824766854165306\n",
      "[EPOCH #7, step #1634] loss: 2.7823312706174472\n",
      "[EPOCH #7, step #1636] loss: 2.7821107903266724\n",
      "[EPOCH #7, step #1638] loss: 2.782009441216884\n",
      "[EPOCH #7, step #1640] loss: 2.781837564427122\n",
      "[EPOCH #7, step #1642] loss: 2.7817134265847416\n",
      "[EPOCH #7, step #1644] loss: 2.7812840133452488\n",
      "[EPOCH #7, step #1646] loss: 2.7811766929458543\n",
      "[EPOCH #7, step #1648] loss: 2.7811199782326987\n",
      "[EPOCH #7, step #1650] loss: 2.781235473434684\n",
      "[EPOCH #7, step #1652] loss: 2.781470338215052\n",
      "[EPOCH #7, step #1654] loss: 2.7815541173036005\n",
      "[EPOCH #7, step #1656] loss: 2.7814195411494502\n",
      "[EPOCH #7, step #1658] loss: 2.7815330092485877\n",
      "[EPOCH #7, step #1660] loss: 2.781349342103323\n",
      "[EPOCH #7, step #1662] loss: 2.7808907732358557\n",
      "[EPOCH #7, step #1664] loss: 2.7808808792818773\n",
      "[EPOCH #7, step #1666] loss: 2.780723867476451\n",
      "[EPOCH #7, step #1668] loss: 2.780777586299263\n",
      "[EPOCH #7, step #1670] loss: 2.7804255643196267\n",
      "[EPOCH #7, step #1672] loss: 2.7802826439771406\n",
      "[EPOCH #7, step #1674] loss: 2.7803311276080005\n",
      "[EPOCH #7, step #1676] loss: 2.780207410125983\n",
      "[EPOCH #7, step #1678] loss: 2.780269743290027\n",
      "[EPOCH #7, step #1680] loss: 2.7803497822918684\n",
      "[EPOCH #7, step #1682] loss: 2.7804079594813285\n",
      "[EPOCH #7, step #1684] loss: 2.780591818486901\n",
      "[EPOCH #7, step #1686] loss: 2.7804803875825357\n",
      "[EPOCH #7, step #1688] loss: 2.780908358245294\n",
      "[EPOCH #7, step #1690] loss: 2.781085875173915\n",
      "[EPOCH #7, step #1692] loss: 2.7812207012013155\n",
      "[EPOCH #7, step #1694] loss: 2.7812162920437027\n",
      "[EPOCH #7, step #1696] loss: 2.7811622790329302\n",
      "[EPOCH #7, step #1698] loss: 2.7812701340210024\n",
      "[EPOCH #7, step #1700] loss: 2.7812255588718755\n",
      "[EPOCH #7, step #1702] loss: 2.781302275758453\n",
      "[EPOCH #7, step #1704] loss: 2.781099763503872\n",
      "[EPOCH #7, step #1706] loss: 2.7810202911016044\n",
      "[EPOCH #7, step #1708] loss: 2.781102618883757\n",
      "[EPOCH #7, step #1710] loss: 2.7810925834712616\n",
      "[EPOCH #7, step #1712] loss: 2.7809781245300105\n",
      "[EPOCH #7, step #1714] loss: 2.7807313448486104\n",
      "[EPOCH #7, step #1716] loss: 2.78053583728066\n",
      "[EPOCH #7, step #1718] loss: 2.780647594267161\n",
      "[EPOCH #7, step #1720] loss: 2.7808231652856636\n",
      "[EPOCH #7, step #1722] loss: 2.7805172278309587\n",
      "[EPOCH #7, step #1724] loss: 2.780683974183124\n",
      "[EPOCH #7, step #1726] loss: 2.780790916190509\n",
      "[EPOCH #7, step #1728] loss: 2.780582401709725\n",
      "[EPOCH #7, step #1730] loss: 2.7804969943100013\n",
      "[EPOCH #7, step #1732] loss: 2.7802718670053146\n",
      "[EPOCH #7, step #1734] loss: 2.7803663198130275\n",
      "[EPOCH #7, step #1736] loss: 2.7799207783321846\n",
      "[EPOCH #7, step #1738] loss: 2.779621110488931\n",
      "[EPOCH #7, step #1740] loss: 2.7795102499737814\n",
      "[EPOCH #7, step #1742] loss: 2.779196837888117\n",
      "[EPOCH #7, step #1744] loss: 2.779297137260437\n",
      "[EPOCH #7, step #1746] loss: 2.7790825531424015\n",
      "[EPOCH #7, step #1748] loss: 2.7786979611905527\n",
      "[EPOCH #7, step #1750] loss: 2.778872057957216\n",
      "[EPOCH #7, step #1752] loss: 2.778755728952285\n",
      "[EPOCH #7, step #1754] loss: 2.7786913600742307\n",
      "[EPOCH #7, step #1756] loss: 2.778398871421814\n",
      "[EPOCH #7, step #1758] loss: 2.778527005075256\n",
      "[EPOCH #7, step #1760] loss: 2.778280645998143\n",
      "[EPOCH #7, step #1762] loss: 2.7787448581618746\n",
      "[EPOCH #7, step #1764] loss: 2.77858116275528\n",
      "[EPOCH #7, step #1766] loss: 2.7788706301428467\n",
      "[EPOCH #7, step #1768] loss: 2.778841925246895\n",
      "[EPOCH #7, step #1770] loss: 2.7789324725300224\n",
      "[EPOCH #7, step #1772] loss: 2.7787765780882987\n",
      "[EPOCH #7, step #1774] loss: 2.778782794643456\n",
      "[EPOCH #7, step #1776] loss: 2.778406924254182\n",
      "[EPOCH #7, step #1778] loss: 2.7783449516998644\n",
      "[EPOCH #7, step #1780] loss: 2.778347029503914\n",
      "[EPOCH #7, step #1782] loss: 2.7784293273561\n",
      "[EPOCH #7, step #1784] loss: 2.7788420887554395\n",
      "[EPOCH #7, step #1786] loss: 2.779029488296701\n",
      "[EPOCH #7, step #1788] loss: 2.778959479060101\n",
      "[EPOCH #7, step #1790] loss: 2.778927525017662\n",
      "[EPOCH #7, step #1792] loss: 2.77856077080124\n",
      "[EPOCH #7, step #1794] loss: 2.7785052964282233\n",
      "[EPOCH #7, step #1796] loss: 2.7787019242561057\n",
      "[EPOCH #7, step #1798] loss: 2.778593186407105\n",
      "[EPOCH #7, step #1800] loss: 2.778472706518327\n",
      "[EPOCH #7, step #1802] loss: 2.778474509087921\n",
      "[EPOCH #7, step #1804] loss: 2.7781881403064466\n",
      "[EPOCH #7, step #1806] loss: 2.77786019056887\n",
      "[EPOCH #7, step #1808] loss: 2.7778027957153952\n",
      "[EPOCH #7, step #1810] loss: 2.7781570355975123\n",
      "[EPOCH #7, step #1812] loss: 2.778293004367342\n",
      "[EPOCH #7, step #1814] loss: 2.7782838024712135\n",
      "[EPOCH #7, step #1816] loss: 2.7782941893948654\n",
      "[EPOCH #7, step #1818] loss: 2.778575326073884\n",
      "[EPOCH #7, step #1820] loss: 2.7784679431564396\n",
      "[EPOCH #7, step #1822] loss: 2.7787395658168696\n",
      "[EPOCH #7, step #1824] loss: 2.7785822793228987\n",
      "[EPOCH #7, step #1826] loss: 2.7786935644849247\n",
      "[EPOCH #7, step #1828] loss: 2.778827511918812\n",
      "[EPOCH #7, step #1830] loss: 2.7788873410889\n",
      "[EPOCH #7, step #1832] loss: 2.779151532601868\n",
      "[EPOCH #7, step #1834] loss: 2.7791907325427605\n",
      "[EPOCH #7, step #1836] loss: 2.7793038206121228\n",
      "[EPOCH #7, step #1838] loss: 2.779430946686658\n",
      "[EPOCH #7, step #1840] loss: 2.7792796117983585\n",
      "[EPOCH #7, step #1842] loss: 2.778776876640527\n",
      "[EPOCH #7, step #1844] loss: 2.778859566673031\n",
      "[EPOCH #7, step #1846] loss: 2.779151952324781\n",
      "[EPOCH #7, step #1848] loss: 2.779165125525017\n",
      "[EPOCH #7, step #1850] loss: 2.7792716127418298\n",
      "[EPOCH #7, step #1852] loss: 2.779023459262611\n",
      "[EPOCH #7, step #1854] loss: 2.77919065849479\n",
      "[EPOCH #7, step #1856] loss: 2.7791858163005765\n",
      "[EPOCH #7, step #1858] loss: 2.77904007439975\n",
      "[EPOCH #7, step #1860] loss: 2.778942550336847\n",
      "[EPOCH #7, step #1862] loss: 2.7791907982485817\n",
      "[EPOCH #7, step #1864] loss: 2.7791817557076666\n",
      "[EPOCH #7, step #1866] loss: 2.7791699344740235\n",
      "[EPOCH #7, step #1868] loss: 2.779179848917925\n",
      "[EPOCH #7, step #1870] loss: 2.779206897472074\n",
      "[EPOCH #7, step #1872] loss: 2.7791421260034346\n",
      "[EPOCH #7, step #1874] loss: 2.7790585460027057\n",
      "[EPOCH #7, step #1876] loss: 2.7788656245029917\n",
      "[EPOCH #7, step #1878] loss: 2.778844651863764\n",
      "[EPOCH #7, step #1880] loss: 2.778867541761363\n",
      "[EPOCH #7, step #1882] loss: 2.7790306693875784\n",
      "[EPOCH #7, step #1884] loss: 2.779161580171762\n",
      "[EPOCH #7, step #1886] loss: 2.7790455820071487\n",
      "[EPOCH #7, step #1888] loss: 2.7788308168479916\n",
      "[EPOCH #7, step #1890] loss: 2.7787655794954627\n",
      "[EPOCH #7, step #1892] loss: 2.778772736187656\n",
      "[EPOCH #7, step #1894] loss: 2.7791586807346595\n",
      "[EPOCH #7, step #1896] loss: 2.7789099062500844\n",
      "[EPOCH #7, step #1898] loss: 2.7792297654430635\n",
      "[EPOCH #7, step #1900] loss: 2.779428004779545\n",
      "[EPOCH #7, step #1902] loss: 2.7793835099596635\n",
      "[EPOCH #7, step #1904] loss: 2.7791421783252024\n",
      "[EPOCH #7, step #1906] loss: 2.7791400200169187\n",
      "[EPOCH #7, step #1908] loss: 2.7791251077771872\n",
      "[EPOCH #7, step #1910] loss: 2.7789623346208963\n",
      "[EPOCH #7, step #1912] loss: 2.7785690657704896\n",
      "[EPOCH #7, step #1914] loss: 2.7780683232972265\n",
      "[EPOCH #7, step #1916] loss: 2.7779881774477495\n",
      "[EPOCH #7, step #1918] loss: 2.7779882666715547\n",
      "[EPOCH #7, step #1920] loss: 2.7777626660266064\n",
      "[EPOCH #7, step #1922] loss: 2.7775997057347883\n",
      "[EPOCH #7, step #1924] loss: 2.777723155888644\n",
      "[EPOCH #7, step #1926] loss: 2.777790984095349\n",
      "[EPOCH #7, step #1928] loss: 2.778149411553481\n",
      "[EPOCH #7, step #1930] loss: 2.7784009401443894\n",
      "[EPOCH #7, step #1932] loss: 2.778568394925393\n",
      "[EPOCH #7, step #1934] loss: 2.778673122157114\n",
      "[EPOCH #7, step #1936] loss: 2.7782475079958378\n",
      "[EPOCH #7, step #1938] loss: 2.778221649567819\n",
      "[EPOCH #7, step #1940] loss: 2.777873340370359\n",
      "[EPOCH #7, step #1942] loss: 2.777590229225355\n",
      "[EPOCH #7, step #1944] loss: 2.77770460142268\n",
      "[EPOCH #7, step #1946] loss: 2.7776326350083274\n",
      "[EPOCH #7, step #1948] loss: 2.777595775747617\n",
      "[EPOCH #7, step #1950] loss: 2.7775406202617394\n",
      "[EPOCH #7, step #1952] loss: 2.777490341962452\n",
      "[EPOCH #7, step #1954] loss: 2.7772755767378356\n",
      "[EPOCH #7, step #1956] loss: 2.7772002749499096\n",
      "[EPOCH #7, step #1958] loss: 2.777048609644981\n",
      "[EPOCH #7, step #1960] loss: 2.777070895498471\n",
      "[EPOCH #7, step #1962] loss: 2.777034679542557\n",
      "[EPOCH #7, step #1964] loss: 2.7767829777933564\n",
      "[EPOCH #7, step #1966] loss: 2.7768032552629904\n",
      "[EPOCH #7, step #1968] loss: 2.7768687099415135\n",
      "[EPOCH #7, step #1970] loss: 2.7766693932099247\n",
      "[EPOCH #7, step #1972] loss: 2.7764614557047755\n",
      "[EPOCH #7, step #1974] loss: 2.77653538734098\n",
      "[EPOCH #7, step #1976] loss: 2.7764053509340303\n",
      "[EPOCH #7, step #1978] loss: 2.776310058541223\n",
      "[EPOCH #7, step #1980] loss: 2.776235707476547\n",
      "[EPOCH #7, step #1982] loss: 2.7761267165132564\n",
      "[EPOCH #7, step #1984] loss: 2.7760202022883993\n",
      "[EPOCH #7, step #1986] loss: 2.7757498610241664\n",
      "[EPOCH #7, step #1988] loss: 2.775711195081727\n",
      "[EPOCH #7, step #1990] loss: 2.7758295009748113\n",
      "[EPOCH #7, step #1992] loss: 2.7752921423957506\n",
      "[EPOCH #7, step #1994] loss: 2.7754006229845203\n",
      "[EPOCH #7, step #1996] loss: 2.77518152480252\n",
      "[EPOCH #7, step #1998] loss: 2.7753082281234804\n",
      "[EPOCH #7, step #2000] loss: 2.7752866540653356\n",
      "[EPOCH #7, step #2002] loss: 2.7751893483574723\n",
      "[EPOCH #7, step #2004] loss: 2.7752446323856153\n",
      "[EPOCH #7, step #2006] loss: 2.7753652720292172\n",
      "[EPOCH #7, step #2008] loss: 2.7753006501124236\n",
      "[EPOCH #7, step #2010] loss: 2.7750686720080306\n",
      "[EPOCH #7, step #2012] loss: 2.7747111556782276\n",
      "[EPOCH #7, step #2014] loss: 2.7747722375481656\n",
      "[EPOCH #7, step #2016] loss: 2.7748118982967553\n",
      "[EPOCH #7, step #2018] loss: 2.7749574993907253\n",
      "[EPOCH #7, step #2020] loss: 2.775049814960852\n",
      "[EPOCH #7, step #2022] loss: 2.7749212084580224\n",
      "[EPOCH #7, step #2024] loss: 2.774950274773586\n",
      "[EPOCH #7, step #2026] loss: 2.7745682795058344\n",
      "[EPOCH #7, step #2028] loss: 2.774317686930262\n",
      "[EPOCH #7, step #2030] loss: 2.7740363054003168\n",
      "[EPOCH #7, step #2032] loss: 2.773806559588014\n",
      "[EPOCH #7, step #2034] loss: 2.7738879879218064\n",
      "[EPOCH #7, step #2036] loss: 2.7739360867965206\n",
      "[EPOCH #7, step #2038] loss: 2.773879660935657\n",
      "[EPOCH #7, step #2040] loss: 2.7740461491650663\n",
      "[EPOCH #7, step #2042] loss: 2.7741071239033577\n",
      "[EPOCH #7, step #2044] loss: 2.773913416536047\n",
      "[EPOCH #7, step #2046] loss: 2.7736763064897403\n",
      "[EPOCH #7, step #2048] loss: 2.773533739015031\n",
      "[EPOCH #7, step #2050] loss: 2.773661235726095\n",
      "[EPOCH #7, step #2052] loss: 2.773674765332292\n",
      "[EPOCH #7, step #2054] loss: 2.773760358028458\n",
      "[EPOCH #7, step #2056] loss: 2.773577700845814\n",
      "[EPOCH #7, step #2058] loss: 2.7739156244911576\n",
      "[EPOCH #7, step #2060] loss: 2.773868741311245\n",
      "[EPOCH #7, step #2062] loss: 2.7736020690887457\n",
      "[EPOCH #7, step #2064] loss: 2.773456493647855\n",
      "[EPOCH #7, step #2066] loss: 2.7732252844532272\n",
      "[EPOCH #7, step #2068] loss: 2.7730233585736555\n",
      "[EPOCH #7, step #2070] loss: 2.7726231485331825\n",
      "[EPOCH #7, step #2072] loss: 2.7721580239349786\n",
      "[EPOCH #7, step #2074] loss: 2.7719576656962017\n",
      "[EPOCH #7, step #2076] loss: 2.771537459522242\n",
      "[EPOCH #7, step #2078] loss: 2.771480571025263\n",
      "[EPOCH #7, step #2080] loss: 2.7713207845101273\n",
      "[EPOCH #7, step #2082] loss: 2.7715776135471653\n",
      "[EPOCH #7, step #2084] loss: 2.771816255205827\n",
      "[EPOCH #7, step #2086] loss: 2.7717806892527537\n",
      "[EPOCH #7, step #2088] loss: 2.7715944519677533\n",
      "[EPOCH #7, step #2090] loss: 2.771550291123885\n",
      "[EPOCH #7, step #2092] loss: 2.77167997466168\n",
      "[EPOCH #7, step #2094] loss: 2.7715948980577236\n",
      "[EPOCH #7, step #2096] loss: 2.7713330047268157\n",
      "[EPOCH #7, step #2098] loss: 2.771478419930893\n",
      "[EPOCH #7, step #2100] loss: 2.771764948786809\n",
      "[EPOCH #7, step #2102] loss: 2.771860957939286\n",
      "[EPOCH #7, step #2104] loss: 2.7721581387123417\n",
      "[EPOCH #7, step #2106] loss: 2.7720599418349554\n",
      "[EPOCH #7, step #2108] loss: 2.771999678322352\n",
      "[EPOCH #7, step #2110] loss: 2.772151485826663\n",
      "[EPOCH #7, step #2112] loss: 2.772079050117796\n",
      "[EPOCH #7, step #2114] loss: 2.7718032176894782\n",
      "[EPOCH #7, step #2116] loss: 2.771733676874812\n",
      "[EPOCH #7, step #2118] loss: 2.771301693767801\n",
      "[EPOCH #7, step #2120] loss: 2.7713201009457205\n",
      "[EPOCH #7, step #2122] loss: 2.77136282021293\n",
      "[EPOCH #7, step #2124] loss: 2.771161858783049\n",
      "[EPOCH #7, step #2126] loss: 2.77123496758865\n",
      "[EPOCH #7, step #2128] loss: 2.771462269879776\n",
      "[EPOCH #7, step #2130] loss: 2.7715609121188374\n",
      "[EPOCH #7, step #2132] loss: 2.77154310248125\n",
      "[EPOCH #7, step #2134] loss: 2.771309607760409\n",
      "[EPOCH #7, step #2136] loss: 2.7714247591427457\n",
      "[EPOCH #7, step #2138] loss: 2.771095653904437\n",
      "[EPOCH #7, step #2140] loss: 2.7712643168229802\n",
      "[EPOCH #7, step #2142] loss: 2.7712695085162378\n",
      "[EPOCH #7, step #2144] loss: 2.7709061653186113\n",
      "[EPOCH #7, step #2146] loss: 2.7709292695307988\n",
      "[EPOCH #7, step #2148] loss: 2.7709174673742556\n",
      "[EPOCH #7, step #2150] loss: 2.770804648341716\n",
      "[EPOCH #7, step #2152] loss: 2.7707551406584834\n",
      "[EPOCH #7, step #2154] loss: 2.7707645240903176\n",
      "[EPOCH #7, step #2156] loss: 2.770747120810373\n",
      "[EPOCH #7, step #2158] loss: 2.770800356127256\n",
      "[EPOCH #7, step #2160] loss: 2.7707887520562826\n",
      "[EPOCH #7, step #2162] loss: 2.7710449580401115\n",
      "[EPOCH #7, step #2164] loss: 2.771131558506373\n",
      "[EPOCH #7, step #2166] loss: 2.7711654121445575\n",
      "[EPOCH #7, step #2168] loss: 2.770754680758855\n",
      "[EPOCH #7, step #2170] loss: 2.770707631484532\n",
      "[EPOCH #7, step #2172] loss: 2.770608199065147\n",
      "[EPOCH #7, step #2174] loss: 2.770331016134942\n",
      "[EPOCH #7, step #2176] loss: 2.769963864673427\n",
      "[EPOCH #7, step #2178] loss: 2.770086545526243\n",
      "[EPOCH #7, step #2180] loss: 2.769947237238213\n",
      "[EPOCH #7, step #2182] loss: 2.769840665929535\n",
      "[EPOCH #7, step #2184] loss: 2.7699814454368923\n",
      "[EPOCH #7, step #2186] loss: 2.7701167497233707\n",
      "[EPOCH #7, step #2188] loss: 2.7701088753177894\n",
      "[EPOCH #7, step #2190] loss: 2.770079983635506\n",
      "[EPOCH #7, step #2192] loss: 2.7700943295073954\n",
      "[EPOCH #7, step #2194] loss: 2.7701506156856217\n",
      "[EPOCH #7, step #2196] loss: 2.7698732547234775\n",
      "[EPOCH #7, step #2198] loss: 2.769914407792987\n",
      "[EPOCH #7, step #2200] loss: 2.7699993948457675\n",
      "[EPOCH #7, step #2202] loss: 2.770122318824096\n",
      "[EPOCH #7, step #2204] loss: 2.7701968520136377\n",
      "[EPOCH #7, step #2206] loss: 2.7702814284416686\n",
      "[EPOCH #7, step #2208] loss: 2.770165583999948\n",
      "[EPOCH #7, step #2210] loss: 2.77000241024038\n",
      "[EPOCH #7, step #2212] loss: 2.770108114848889\n",
      "[EPOCH #7, step #2214] loss: 2.7700167673705125\n",
      "[EPOCH #7, step #2216] loss: 2.769973920119685\n",
      "[EPOCH #7, step #2218] loss: 2.7698944857551364\n",
      "[EPOCH #7, step #2220] loss: 2.7700484984632765\n",
      "[EPOCH #7, step #2222] loss: 2.770166911416047\n",
      "[EPOCH #7, step #2224] loss: 2.7701471513576723\n",
      "[EPOCH #7, step #2226] loss: 2.7700884902643206\n",
      "[EPOCH #7, step #2228] loss: 2.7704294406549446\n",
      "[EPOCH #7, step #2230] loss: 2.770514488380514\n",
      "[EPOCH #7, step #2232] loss: 2.770551830730361\n",
      "[EPOCH #7, step #2234] loss: 2.7704037047072543\n",
      "[EPOCH #7, step #2236] loss: 2.770500089688444\n",
      "[EPOCH #7, step #2238] loss: 2.770348915887656\n",
      "[EPOCH #7, step #2240] loss: 2.7701557840634967\n",
      "[EPOCH #7, step #2242] loss: 2.770087158100657\n",
      "[EPOCH #7, step #2244] loss: 2.769971401123268\n",
      "[EPOCH #7, step #2246] loss: 2.7698267088182567\n",
      "[EPOCH #7, step #2248] loss: 2.7694809133076785\n",
      "[EPOCH #7, step #2250] loss: 2.7694220931092564\n",
      "[EPOCH #7, step #2252] loss: 2.7694890726104715\n",
      "[EPOCH #7, step #2254] loss: 2.769798778641779\n",
      "[EPOCH #7, step #2256] loss: 2.769908508105145\n",
      "[EPOCH #7, step #2258] loss: 2.769948492487113\n",
      "[EPOCH #7, step #2260] loss: 2.7700936002891603\n",
      "[EPOCH #7, step #2262] loss: 2.7701276579737613\n",
      "[EPOCH #7, step #2264] loss: 2.7703309027038134\n",
      "[EPOCH #7, step #2266] loss: 2.77008145703163\n",
      "[EPOCH #7, step #2268] loss: 2.769889961259908\n",
      "[EPOCH #7, step #2270] loss: 2.769843444116627\n",
      "[EPOCH #7, step #2272] loss: 2.769902893535062\n",
      "[EPOCH #7, step #2274] loss: 2.770022283229199\n",
      "[EPOCH #7, step #2276] loss: 2.7697371806708877\n",
      "[EPOCH #7, step #2278] loss: 2.7697894043334483\n",
      "[EPOCH #7, step #2280] loss: 2.769583491106297\n",
      "[EPOCH #7, step #2282] loss: 2.7693334663326783\n",
      "[EPOCH #7, step #2284] loss: 2.7695398885259483\n",
      "[EPOCH #7, step #2286] loss: 2.7696640454477026\n",
      "[EPOCH #7, step #2288] loss: 2.7697439794198764\n",
      "[EPOCH #7, step #2290] loss: 2.7695290264423527\n",
      "[EPOCH #7, step #2292] loss: 2.769402106724293\n",
      "[EPOCH #7, step #2294] loss: 2.7693486355488597\n",
      "[EPOCH #7, step #2296] loss: 2.7694422329411488\n",
      "[EPOCH #7, step #2298] loss: 2.769327588214103\n",
      "[EPOCH #7, step #2300] loss: 2.7690410817617543\n",
      "[EPOCH #7, step #2302] loss: 2.7692190705824045\n",
      "[EPOCH #7, step #2304] loss: 2.7691490116967556\n",
      "[EPOCH #7, step #2306] loss: 2.7689723223899936\n",
      "[EPOCH #7, step #2308] loss: 2.768655131264856\n",
      "[EPOCH #7, step #2310] loss: 2.768446872008409\n",
      "[EPOCH #7, step #2312] loss: 2.768099056762171\n",
      "[EPOCH #7, step #2314] loss: 2.768557007678384\n",
      "[EPOCH #7, step #2316] loss: 2.768365812908744\n",
      "[EPOCH #7, step #2318] loss: 2.7683896538819566\n",
      "[EPOCH #7, step #2320] loss: 2.7684802365477665\n",
      "[EPOCH #7, step #2322] loss: 2.7682562616946007\n",
      "[EPOCH #7, step #2324] loss: 2.7681239146058276\n",
      "[EPOCH #7, step #2326] loss: 2.7679665503094113\n",
      "[EPOCH #7, step #2328] loss: 2.7677628525647546\n",
      "[EPOCH #7, step #2330] loss: 2.7676696357477484\n",
      "[EPOCH #7, step #2332] loss: 2.7676319074998634\n",
      "[EPOCH #7, step #2334] loss: 2.767505038678008\n",
      "[EPOCH #7, step #2336] loss: 2.7673921977346354\n",
      "[EPOCH #7, step #2338] loss: 2.767033395985346\n",
      "[EPOCH #7, step #2340] loss: 2.7669903649982355\n",
      "[EPOCH #7, step #2342] loss: 2.7669784883836166\n",
      "[EPOCH #7, step #2344] loss: 2.7666432462521455\n",
      "[EPOCH #7, step #2346] loss: 2.766516380783442\n",
      "[EPOCH #7, step #2348] loss: 2.7664033118690923\n",
      "[EPOCH #7, step #2350] loss: 2.766368554785423\n",
      "[EPOCH #7, step #2352] loss: 2.7660818297053416\n",
      "[EPOCH #7, step #2354] loss: 2.7660025160783417\n",
      "[EPOCH #7, step #2356] loss: 2.766242255434223\n",
      "[EPOCH #7, step #2358] loss: 2.7663664111852544\n",
      "[EPOCH #7, step #2360] loss: 2.7662919055905597\n",
      "[EPOCH #7, step #2362] loss: 2.7663105419516514\n",
      "[EPOCH #7, step #2364] loss: 2.7662134511778267\n",
      "[EPOCH #7, step #2366] loss: 2.766202019849406\n",
      "[EPOCH #7, step #2368] loss: 2.766084462844556\n",
      "[EPOCH #7, step #2370] loss: 2.7660336314953113\n",
      "[EPOCH #7, step #2372] loss: 2.7657655342892156\n",
      "[EPOCH #7, step #2374] loss: 2.765858938066583\n",
      "[EPOCH #7, step #2376] loss: 2.765796935152095\n",
      "[EPOCH #7, step #2378] loss: 2.7657048836030995\n",
      "[EPOCH #7, step #2380] loss: 2.7654239925603212\n",
      "[EPOCH #7, step #2382] loss: 2.76535670211022\n",
      "[EPOCH #7, step #2384] loss: 2.7654389256951193\n",
      "[EPOCH #7, step #2386] loss: 2.7654496420363675\n",
      "[EPOCH #7, step #2388] loss: 2.7653701058388154\n",
      "[EPOCH #7, step #2390] loss: 2.765384284535595\n",
      "[EPOCH #7, step #2392] loss: 2.7655255116531654\n",
      "[EPOCH #7, step #2394] loss: 2.7653233476869747\n",
      "[EPOCH #7, step #2396] loss: 2.7653137261438827\n",
      "[EPOCH #7, step #2398] loss: 2.7653766003883398\n",
      "[EPOCH #7, step #2400] loss: 2.7652306654511865\n",
      "[EPOCH #7, step #2402] loss: 2.765437078585091\n",
      "[EPOCH #7, step #2404] loss: 2.7652749404094323\n",
      "[EPOCH #7, step #2406] loss: 2.765400752468529\n",
      "[EPOCH #7, step #2408] loss: 2.765448808818499\n",
      "[EPOCH #7, step #2410] loss: 2.76566104417221\n",
      "[EPOCH #7, step #2412] loss: 2.7653222987625146\n",
      "[EPOCH #7, step #2414] loss: 2.7653526367854875\n",
      "[EPOCH #7, step #2416] loss: 2.765457512230532\n",
      "[EPOCH #7, step #2418] loss: 2.7649180056290863\n",
      "[EPOCH #7, step #2420] loss: 2.7648528696632937\n",
      "[EPOCH #7, step #2422] loss: 2.764729896164413\n",
      "[EPOCH #7, step #2424] loss: 2.7647997383235654\n",
      "[EPOCH #7, step #2426] loss: 2.7646844113958586\n",
      "[EPOCH #7, step #2428] loss: 2.7647921934987645\n",
      "[EPOCH #7, step #2430] loss: 2.7646546616862215\n",
      "[EPOCH #7, step #2432] loss: 2.764376855121931\n",
      "[EPOCH #7, step #2434] loss: 2.7643377682022\n",
      "[EPOCH #7, step #2436] loss: 2.7643252177271727\n",
      "[EPOCH #7, step #2438] loss: 2.7643849900532276\n",
      "[EPOCH #7, step #2440] loss: 2.7642720493807356\n",
      "[EPOCH #7, step #2442] loss: 2.764030352802097\n",
      "[EPOCH #7, step #2444] loss: 2.764386718941125\n",
      "[EPOCH #7, step #2446] loss: 2.7644210289486293\n",
      "[EPOCH #7, step #2448] loss: 2.764355473637143\n",
      "[EPOCH #7, step #2450] loss: 2.763983494794792\n",
      "[EPOCH #7, step #2452] loss: 2.76401874020884\n",
      "[EPOCH #7, step #2454] loss: 2.7643354000239166\n",
      "[EPOCH #7, step #2456] loss: 2.764429007403289\n",
      "[EPOCH #7, step #2458] loss: 2.764620187467751\n",
      "[EPOCH #7, step #2460] loss: 2.7644442880313504\n",
      "[EPOCH #7, step #2462] loss: 2.764563092263888\n",
      "[EPOCH #7, step #2464] loss: 2.7644372366504784\n",
      "[EPOCH #7, step #2466] loss: 2.7642974539425484\n",
      "[EPOCH #7, step #2468] loss: 2.76439579163741\n",
      "[EPOCH #7, step #2470] loss: 2.7644009148239945\n",
      "[EPOCH #7, step #2472] loss: 2.7642972852072156\n",
      "[EPOCH #7, step #2474] loss: 2.764236164285679\n",
      "[EPOCH #7, step #2476] loss: 2.764092483008442\n",
      "[EPOCH #7, step #2478] loss: 2.764178147764156\n",
      "[EPOCH #7, step #2480] loss: 2.764035816972941\n",
      "[EPOCH #7, step #2482] loss: 2.763984508395339\n",
      "[EPOCH #7, step #2484] loss: 2.7640491358950823\n",
      "[EPOCH #7, step #2486] loss: 2.764084515822763\n",
      "[EPOCH #7, step #2488] loss: 2.764023255324833\n",
      "[EPOCH #7, step #2490] loss: 2.763640676909592\n",
      "[EPOCH #7, step #2492] loss: 2.763889757830409\n",
      "[EPOCH #7, step #2494] loss: 2.7638204080547264\n",
      "[EPOCH #7, step #2496] loss: 2.763594036728657\n",
      "[EPOCH #7, step #2498] loss: 2.7634497597104026\n",
      "[EPOCH #7, elapsed time: 3594.484[sec]] loss: 2.7634661554336546\n",
      "[EPOCH #8, step #0] loss: 2.906907796859741\n",
      "[EPOCH #8, step #2] loss: 2.743389368057251\n",
      "[EPOCH #8, step #4] loss: 2.8046824455261232\n",
      "[EPOCH #8, step #6] loss: 2.74654449735369\n",
      "[EPOCH #8, step #8] loss: 2.758374664518568\n",
      "[EPOCH #8, step #10] loss: 2.7029681855982\n",
      "[EPOCH #8, step #12] loss: 2.754520031122061\n",
      "[EPOCH #8, step #14] loss: 2.728927008310954\n",
      "[EPOCH #8, step #16] loss: 2.7166222404031193\n",
      "[EPOCH #8, step #18] loss: 2.691300316860801\n",
      "[EPOCH #8, step #20] loss: 2.680660667873564\n",
      "[EPOCH #8, step #22] loss: 2.705799403397933\n",
      "[EPOCH #8, step #24] loss: 2.7171335792541504\n",
      "[EPOCH #8, step #26] loss: 2.7219777372148304\n",
      "[EPOCH #8, step #28] loss: 2.7013467755810967\n",
      "[EPOCH #8, step #30] loss: 2.705909921276954\n",
      "[EPOCH #8, step #32] loss: 2.710810581843058\n",
      "[EPOCH #8, step #34] loss: 2.703732034138271\n",
      "[EPOCH #8, step #36] loss: 2.6999139334704423\n",
      "[EPOCH #8, step #38] loss: 2.711574279344999\n",
      "[EPOCH #8, step #40] loss: 2.699573912271639\n",
      "[EPOCH #8, step #42] loss: 2.7069220598353896\n",
      "[EPOCH #8, step #44] loss: 2.69519051445855\n",
      "[EPOCH #8, step #46] loss: 2.685816805413429\n",
      "[EPOCH #8, step #48] loss: 2.6830218032914765\n",
      "[EPOCH #8, step #50] loss: 2.6886588498657824\n",
      "[EPOCH #8, step #52] loss: 2.6856424988440746\n",
      "[EPOCH #8, step #54] loss: 2.6843679168007593\n",
      "[EPOCH #8, step #56] loss: 2.6715914199226782\n",
      "[EPOCH #8, step #58] loss: 2.6719431998366017\n",
      "[EPOCH #8, step #60] loss: 2.679070195213693\n",
      "[EPOCH #8, step #62] loss: 2.675105749614655\n",
      "[EPOCH #8, step #64] loss: 2.6823974242577187\n",
      "[EPOCH #8, step #66] loss: 2.687050097024263\n",
      "[EPOCH #8, step #68] loss: 2.6795087931812676\n",
      "[EPOCH #8, step #70] loss: 2.6783359487291793\n",
      "[EPOCH #8, step #72] loss: 2.6747556941149986\n",
      "[EPOCH #8, step #74] loss: 2.6755177561442056\n",
      "[EPOCH #8, step #76] loss: 2.670053704992517\n",
      "[EPOCH #8, step #78] loss: 2.6618953777264944\n",
      "[EPOCH #8, step #80] loss: 2.6654128086419755\n",
      "[EPOCH #8, step #82] loss: 2.6651040014014185\n",
      "[EPOCH #8, step #84] loss: 2.6565553272471707\n",
      "[EPOCH #8, step #86] loss: 2.652787452456595\n",
      "[EPOCH #8, step #88] loss: 2.6524128485261724\n",
      "[EPOCH #8, step #90] loss: 2.645384662753933\n",
      "[EPOCH #8, step #92] loss: 2.6457448185131116\n",
      "[EPOCH #8, step #94] loss: 2.653077431728965\n",
      "[EPOCH #8, step #96] loss: 2.653616715952293\n",
      "[EPOCH #8, step #98] loss: 2.6545328226956455\n",
      "[EPOCH #8, step #100] loss: 2.6594574097359533\n",
      "[EPOCH #8, step #102] loss: 2.6576956684149584\n",
      "[EPOCH #8, step #104] loss: 2.6551215353466215\n",
      "[EPOCH #8, step #106] loss: 2.6529299767217904\n",
      "[EPOCH #8, step #108] loss: 2.651167038383834\n",
      "[EPOCH #8, step #110] loss: 2.650059850366266\n",
      "[EPOCH #8, step #112] loss: 2.652180515559374\n",
      "[EPOCH #8, step #114] loss: 2.6516894858816396\n",
      "[EPOCH #8, step #116] loss: 2.652970768447615\n",
      "[EPOCH #8, step #118] loss: 2.6476105401495924\n",
      "[EPOCH #8, step #120] loss: 2.6490954584326625\n",
      "[EPOCH #8, step #122] loss: 2.6488743506795993\n",
      "[EPOCH #8, step #124] loss: 2.6439430618286135\n",
      "[EPOCH #8, step #126] loss: 2.643767557744905\n",
      "[EPOCH #8, step #128] loss: 2.6423321860705236\n",
      "[EPOCH #8, step #130] loss: 2.64346884225161\n",
      "[EPOCH #8, step #132] loss: 2.6469312198180006\n",
      "[EPOCH #8, step #134] loss: 2.6438435978359647\n",
      "[EPOCH #8, step #136] loss: 2.6495418322347377\n",
      "[EPOCH #8, step #138] loss: 2.652590477209297\n",
      "[EPOCH #8, step #140] loss: 2.6506399685609425\n",
      "[EPOCH #8, step #142] loss: 2.6497861555406264\n",
      "[EPOCH #8, step #144] loss: 2.6502418830476957\n",
      "[EPOCH #8, step #146] loss: 2.6524064200265065\n",
      "[EPOCH #8, step #148] loss: 2.651639600728182\n",
      "[EPOCH #8, step #150] loss: 2.6515938240960732\n",
      "[EPOCH #8, step #152] loss: 2.6525379676444856\n",
      "[EPOCH #8, step #154] loss: 2.6561631648771225\n",
      "[EPOCH #8, step #156] loss: 2.6559918898685724\n",
      "[EPOCH #8, step #158] loss: 2.657523182203185\n",
      "[EPOCH #8, step #160] loss: 2.6574685914175853\n",
      "[EPOCH #8, step #162] loss: 2.6592110475879505\n",
      "[EPOCH #8, step #164] loss: 2.6588834502480245\n",
      "[EPOCH #8, step #166] loss: 2.6605241869738\n",
      "[EPOCH #8, step #168] loss: 2.6553343957697852\n",
      "[EPOCH #8, step #170] loss: 2.654613859472219\n",
      "[EPOCH #8, step #172] loss: 2.656277553883591\n",
      "[EPOCH #8, step #174] loss: 2.6575775275911604\n",
      "[EPOCH #8, step #176] loss: 2.658301488827851\n",
      "[EPOCH #8, step #178] loss: 2.659802469461324\n",
      "[EPOCH #8, step #180] loss: 2.661524818088468\n",
      "[EPOCH #8, step #182] loss: 2.664987496990975\n",
      "[EPOCH #8, step #184] loss: 2.6638727826041144\n",
      "[EPOCH #8, step #186] loss: 2.661997455326631\n",
      "[EPOCH #8, step #188] loss: 2.663533102898371\n",
      "[EPOCH #8, step #190] loss: 2.6626023316258536\n",
      "[EPOCH #8, step #192] loss: 2.6639445822473635\n",
      "[EPOCH #8, step #194] loss: 2.6655778744281866\n",
      "[EPOCH #8, step #196] loss: 2.665870092241897\n",
      "[EPOCH #8, step #198] loss: 2.6635160128674915\n",
      "[EPOCH #8, step #200] loss: 2.6628370884046033\n",
      "[EPOCH #8, step #202] loss: 2.6645885224412815\n",
      "[EPOCH #8, step #204] loss: 2.665005102971705\n",
      "[EPOCH #8, step #206] loss: 2.663651312606922\n",
      "[EPOCH #8, step #208] loss: 2.6620310499337303\n",
      "[EPOCH #8, step #210] loss: 2.6631048499690415\n",
      "[EPOCH #8, step #212] loss: 2.6633697110162653\n",
      "[EPOCH #8, step #214] loss: 2.664415112761564\n",
      "[EPOCH #8, step #216] loss: 2.665486887852717\n",
      "[EPOCH #8, step #218] loss: 2.663469528498715\n",
      "[EPOCH #8, step #220] loss: 2.661091718738435\n",
      "[EPOCH #8, step #222] loss: 2.660106943861786\n",
      "[EPOCH #8, step #224] loss: 2.662877911991543\n",
      "[EPOCH #8, step #226] loss: 2.6636892284065614\n",
      "[EPOCH #8, step #228] loss: 2.662085017262588\n",
      "[EPOCH #8, step #230] loss: 2.663660181033147\n",
      "[EPOCH #8, step #232] loss: 2.662965133466434\n",
      "[EPOCH #8, step #234] loss: 2.6630778135137354\n",
      "[EPOCH #8, step #236] loss: 2.663076655774177\n",
      "[EPOCH #8, step #238] loss: 2.6628493998339984\n",
      "[EPOCH #8, step #240] loss: 2.660635337295374\n",
      "[EPOCH #8, step #242] loss: 2.6599849962893827\n",
      "[EPOCH #8, step #244] loss: 2.6616126717353352\n",
      "[EPOCH #8, step #246] loss: 2.6633671811717723\n",
      "[EPOCH #8, step #248] loss: 2.663697603237198\n",
      "[EPOCH #8, step #250] loss: 2.6651874324714995\n",
      "[EPOCH #8, step #252] loss: 2.668489803438601\n",
      "[EPOCH #8, step #254] loss: 2.6678045249452778\n",
      "[EPOCH #8, step #256] loss: 2.6682171102627708\n",
      "[EPOCH #8, step #258] loss: 2.67090778323214\n",
      "[EPOCH #8, step #260] loss: 2.6677224256983205\n",
      "[EPOCH #8, step #262] loss: 2.6653582365340607\n",
      "[EPOCH #8, step #264] loss: 2.664361871413465\n",
      "[EPOCH #8, step #266] loss: 2.6647454785943476\n",
      "[EPOCH #8, step #268] loss: 2.6629301407080157\n",
      "[EPOCH #8, step #270] loss: 2.661613316993432\n",
      "[EPOCH #8, step #272] loss: 2.6642017526067656\n",
      "[EPOCH #8, step #274] loss: 2.664376704909585\n",
      "[EPOCH #8, step #276] loss: 2.664435604849447\n",
      "[EPOCH #8, step #278] loss: 2.665640054637813\n",
      "[EPOCH #8, step #280] loss: 2.6648240102143474\n",
      "[EPOCH #8, step #282] loss: 2.66209848314629\n",
      "[EPOCH #8, step #284] loss: 2.661435179543077\n",
      "[EPOCH #8, step #286] loss: 2.658969975099331\n",
      "[EPOCH #8, step #288] loss: 2.660413316789383\n",
      "[EPOCH #8, step #290] loss: 2.662096624521865\n",
      "[EPOCH #8, step #292] loss: 2.663789450918855\n",
      "[EPOCH #8, step #294] loss: 2.666910585710558\n",
      "[EPOCH #8, step #296] loss: 2.6665462977958447\n",
      "[EPOCH #8, step #298] loss: 2.667607639545581\n",
      "[EPOCH #8, step #300] loss: 2.6666048709736314\n",
      "[EPOCH #8, step #302] loss: 2.665731948987879\n",
      "[EPOCH #8, step #304] loss: 2.6676889978471348\n",
      "[EPOCH #8, step #306] loss: 2.670312710227718\n",
      "[EPOCH #8, step #308] loss: 2.6685145622704023\n",
      "[EPOCH #8, step #310] loss: 2.670644608724539\n",
      "[EPOCH #8, step #312] loss: 2.670050734148239\n",
      "[EPOCH #8, step #314] loss: 2.6713486289221144\n",
      "[EPOCH #8, step #316] loss: 2.670927388810961\n",
      "[EPOCH #8, step #318] loss: 2.6706812310741985\n",
      "[EPOCH #8, step #320] loss: 2.6731491649633625\n",
      "[EPOCH #8, step #322] loss: 2.6721889902563656\n",
      "[EPOCH #8, step #324] loss: 2.67371054319235\n",
      "[EPOCH #8, step #326] loss: 2.674550126816519\n",
      "[EPOCH #8, step #328] loss: 2.6749954444659156\n",
      "[EPOCH #8, step #330] loss: 2.6756564133837144\n",
      "[EPOCH #8, step #332] loss: 2.676990568100869\n",
      "[EPOCH #8, step #334] loss: 2.677237987162462\n",
      "[EPOCH #8, step #336] loss: 2.6780063529396623\n",
      "[EPOCH #8, step #338] loss: 2.6786708167168944\n",
      "[EPOCH #8, step #340] loss: 2.6775954164717555\n",
      "[EPOCH #8, step #342] loss: 2.6785555445418066\n",
      "[EPOCH #8, step #344] loss: 2.6783851972524673\n",
      "[EPOCH #8, step #346] loss: 2.6785710005664\n",
      "[EPOCH #8, step #348] loss: 2.6784385640846624\n",
      "[EPOCH #8, step #350] loss: 2.6768650380294887\n",
      "[EPOCH #8, step #352] loss: 2.677817168046665\n",
      "[EPOCH #8, step #354] loss: 2.677350323300966\n",
      "[EPOCH #8, step #356] loss: 2.678846732241099\n",
      "[EPOCH #8, step #358] loss: 2.6786983614180415\n",
      "[EPOCH #8, step #360] loss: 2.677454701751223\n",
      "[EPOCH #8, step #362] loss: 2.67486617552019\n",
      "[EPOCH #8, step #364] loss: 2.675520223787386\n",
      "[EPOCH #8, step #366] loss: 2.6752386739533343\n",
      "[EPOCH #8, step #368] loss: 2.6748032166059748\n",
      "[EPOCH #8, step #370] loss: 2.6741467065245637\n",
      "[EPOCH #8, step #372] loss: 2.672735018321081\n",
      "[EPOCH #8, step #374] loss: 2.6702947142918902\n",
      "[EPOCH #8, step #376] loss: 2.671535472022444\n",
      "[EPOCH #8, step #378] loss: 2.6714673492084393\n",
      "[EPOCH #8, step #380] loss: 2.6714981224906102\n",
      "[EPOCH #8, step #382] loss: 2.670157739761293\n",
      "[EPOCH #8, step #384] loss: 2.6718555521655394\n",
      "[EPOCH #8, step #386] loss: 2.6715207392547176\n",
      "[EPOCH #8, step #388] loss: 2.6702514347502997\n",
      "[EPOCH #8, step #390] loss: 2.6706608186292526\n",
      "[EPOCH #8, step #392] loss: 2.670697617166825\n",
      "[EPOCH #8, step #394] loss: 2.6710506713843043\n",
      "[EPOCH #8, step #396] loss: 2.6707266370955884\n",
      "[EPOCH #8, step #398] loss: 2.6688851189792606\n",
      "[EPOCH #8, step #400] loss: 2.6678347049508604\n",
      "[EPOCH #8, step #402] loss: 2.668495337069774\n",
      "[EPOCH #8, step #404] loss: 2.6683290784741627\n",
      "[EPOCH #8, step #406] loss: 2.6696358386070194\n",
      "[EPOCH #8, step #408] loss: 2.66874894040721\n",
      "[EPOCH #8, step #410] loss: 2.6680906036474408\n",
      "[EPOCH #8, step #412] loss: 2.667472329901725\n",
      "[EPOCH #8, step #414] loss: 2.666588457808437\n",
      "[EPOCH #8, step #416] loss: 2.6660437592499546\n",
      "[EPOCH #8, step #418] loss: 2.666559195177083\n",
      "[EPOCH #8, step #420] loss: 2.6662645733554684\n",
      "[EPOCH #8, step #422] loss: 2.6657650631370275\n",
      "[EPOCH #8, step #424] loss: 2.6653341559802786\n",
      "[EPOCH #8, step #426] loss: 2.6656611443124274\n",
      "[EPOCH #8, step #428] loss: 2.666141664787328\n",
      "[EPOCH #8, step #430] loss: 2.6658558599356987\n",
      "[EPOCH #8, step #432] loss: 2.666933976750451\n",
      "[EPOCH #8, step #434] loss: 2.667026857123978\n",
      "[EPOCH #8, step #436] loss: 2.667615946970488\n",
      "[EPOCH #8, step #438] loss: 2.6679663177503268\n",
      "[EPOCH #8, step #440] loss: 2.6686710941007616\n",
      "[EPOCH #8, step #442] loss: 2.6686228142365915\n",
      "[EPOCH #8, step #444] loss: 2.6676713040705478\n",
      "[EPOCH #8, step #446] loss: 2.6677554333770037\n",
      "[EPOCH #8, step #448] loss: 2.668064653475194\n",
      "[EPOCH #8, step #450] loss: 2.6664006136473426\n",
      "[EPOCH #8, step #452] loss: 2.665699233808791\n",
      "[EPOCH #8, step #454] loss: 2.6652087188029028\n",
      "[EPOCH #8, step #456] loss: 2.664231530686176\n",
      "[EPOCH #8, step #458] loss: 2.6631639858216762\n",
      "[EPOCH #8, step #460] loss: 2.6627988254170614\n",
      "[EPOCH #8, step #462] loss: 2.6624826038372955\n",
      "[EPOCH #8, step #464] loss: 2.661584726713037\n",
      "[EPOCH #8, step #466] loss: 2.6599886379098994\n",
      "[EPOCH #8, step #468] loss: 2.6596442888032144\n",
      "[EPOCH #8, step #470] loss: 2.6582175219894215\n",
      "[EPOCH #8, step #472] loss: 2.6582750349165774\n",
      "[EPOCH #8, step #474] loss: 2.658902729185004\n",
      "[EPOCH #8, step #476] loss: 2.658219804054036\n",
      "[EPOCH #8, step #478] loss: 2.657339729446459\n",
      "[EPOCH #8, step #480] loss: 2.6571985289857194\n",
      "[EPOCH #8, step #482] loss: 2.6586430618234798\n",
      "[EPOCH #8, step #484] loss: 2.659693818485614\n",
      "[EPOCH #8, step #486] loss: 2.6606453593506707\n",
      "[EPOCH #8, step #488] loss: 2.659403541824325\n",
      "[EPOCH #8, step #490] loss: 2.6604110585210767\n",
      "[EPOCH #8, step #492] loss: 2.6596242977687843\n",
      "[EPOCH #8, step #494] loss: 2.660210694929566\n",
      "[EPOCH #8, step #496] loss: 2.659645814770904\n",
      "[EPOCH #8, step #498] loss: 2.658672432383459\n",
      "[EPOCH #8, step #500] loss: 2.658881164834409\n",
      "[EPOCH #8, step #502] loss: 2.660130959381877\n",
      "[EPOCH #8, step #504] loss: 2.6608269169779106\n",
      "[EPOCH #8, step #506] loss: 2.6614279462505843\n",
      "[EPOCH #8, step #508] loss: 2.661947972413833\n",
      "[EPOCH #8, step #510] loss: 2.6616474987242786\n",
      "[EPOCH #8, step #512] loss: 2.662481078627514\n",
      "[EPOCH #8, step #514] loss: 2.6627726538667402\n",
      "[EPOCH #8, step #516] loss: 2.6627929429712793\n",
      "[EPOCH #8, step #518] loss: 2.662964619423383\n",
      "[EPOCH #8, step #520] loss: 2.6629679708700493\n",
      "[EPOCH #8, step #522] loss: 2.6614756563653454\n",
      "[EPOCH #8, step #524] loss: 2.6617586633137296\n",
      "[EPOCH #8, step #526] loss: 2.660246581461217\n",
      "[EPOCH #8, step #528] loss: 2.659539987324316\n",
      "[EPOCH #8, step #530] loss: 2.6597223926174216\n",
      "[EPOCH #8, step #532] loss: 2.6603602394601418\n",
      "[EPOCH #8, step #534] loss: 2.66057887366999\n",
      "[EPOCH #8, step #536] loss: 2.6615308314506345\n",
      "[EPOCH #8, step #538] loss: 2.660484153176062\n",
      "[EPOCH #8, step #540] loss: 2.6608723816281104\n",
      "[EPOCH #8, step #542] loss: 2.660315754883417\n",
      "[EPOCH #8, step #544] loss: 2.6591261914017004\n",
      "[EPOCH #8, step #546] loss: 2.6580263925426837\n",
      "[EPOCH #8, step #548] loss: 2.656619672783954\n",
      "[EPOCH #8, step #550] loss: 2.6560455249139054\n",
      "[EPOCH #8, step #552] loss: 2.656235761064733\n",
      "[EPOCH #8, step #554] loss: 2.656045623083372\n",
      "[EPOCH #8, step #556] loss: 2.656199774793491\n",
      "[EPOCH #8, step #558] loss: 2.655689314354298\n",
      "[EPOCH #8, step #560] loss: 2.6573870910892725\n",
      "[EPOCH #8, step #562] loss: 2.657463530028904\n",
      "[EPOCH #8, step #564] loss: 2.6575172958120836\n",
      "[EPOCH #8, step #566] loss: 2.6586491588562255\n",
      "[EPOCH #8, step #568] loss: 2.657965117682472\n",
      "[EPOCH #8, step #570] loss: 2.6580953704496606\n",
      "[EPOCH #8, step #572] loss: 2.6578289848763696\n",
      "[EPOCH #8, step #574] loss: 2.657351567434228\n",
      "[EPOCH #8, step #576] loss: 2.6574870389297063\n",
      "[EPOCH #8, step #578] loss: 2.65891356357021\n",
      "[EPOCH #8, step #580] loss: 2.659368959638625\n",
      "[EPOCH #8, step #582] loss: 2.6588593676405132\n",
      "[EPOCH #8, step #584] loss: 2.6584554474577944\n",
      "[EPOCH #8, step #586] loss: 2.6584553099165986\n",
      "[EPOCH #8, step #588] loss: 2.658568740295838\n",
      "[EPOCH #8, step #590] loss: 2.6578866073927903\n",
      "[EPOCH #8, step #592] loss: 2.659269183522332\n",
      "[EPOCH #8, step #594] loss: 2.6589761183041483\n",
      "[EPOCH #8, step #596] loss: 2.659074499579131\n",
      "[EPOCH #8, step #598] loss: 2.659953635403628\n",
      "[EPOCH #8, step #600] loss: 2.659235091257016\n",
      "[EPOCH #8, step #602] loss: 2.6595843753609096\n",
      "[EPOCH #8, step #604] loss: 2.659725248912149\n",
      "[EPOCH #8, step #606] loss: 2.6590825963452387\n",
      "[EPOCH #8, step #608] loss: 2.6594539305259444\n",
      "[EPOCH #8, step #610] loss: 2.659942428531116\n",
      "[EPOCH #8, step #612] loss: 2.6598793913839693\n",
      "[EPOCH #8, step #614] loss: 2.6593517212363764\n",
      "[EPOCH #8, step #616] loss: 2.659146909195948\n",
      "[EPOCH #8, step #618] loss: 2.6586793191213407\n",
      "[EPOCH #8, step #620] loss: 2.6588365968298797\n",
      "[EPOCH #8, step #622] loss: 2.6572993255159063\n",
      "[EPOCH #8, step #624] loss: 2.6558389110565184\n",
      "[EPOCH #8, step #626] loss: 2.656228522934982\n",
      "[EPOCH #8, step #628] loss: 2.655515338733958\n",
      "[EPOCH #8, step #630] loss: 2.6562341974956674\n",
      "[EPOCH #8, step #632] loss: 2.65639568768783\n",
      "[EPOCH #8, step #634] loss: 2.6564394853246496\n",
      "[EPOCH #8, step #636] loss: 2.6558526969592275\n",
      "[EPOCH #8, step #638] loss: 2.6544532999746115\n",
      "[EPOCH #8, step #640] loss: 2.655206785559096\n",
      "[EPOCH #8, step #642] loss: 2.655565179896021\n",
      "[EPOCH #8, step #644] loss: 2.655469516266224\n",
      "[EPOCH #8, step #646] loss: 2.6549456569105616\n",
      "[EPOCH #8, step #648] loss: 2.654492624000702\n",
      "[EPOCH #8, step #650] loss: 2.6545692262927876\n",
      "[EPOCH #8, step #652] loss: 2.6551466097692984\n",
      "[EPOCH #8, step #654] loss: 2.6557740229686706\n",
      "[EPOCH #8, step #656] loss: 2.656064764731188\n",
      "[EPOCH #8, step #658] loss: 2.655980199530201\n",
      "[EPOCH #8, step #660] loss: 2.6557556107617724\n",
      "[EPOCH #8, step #662] loss: 2.6553868765564888\n",
      "[EPOCH #8, step #664] loss: 2.655222471853844\n",
      "[EPOCH #8, step #666] loss: 2.6544623106852105\n",
      "[EPOCH #8, step #668] loss: 2.6553809097529526\n",
      "[EPOCH #8, step #670] loss: 2.6544881137046303\n",
      "[EPOCH #8, step #672] loss: 2.6545741937135694\n",
      "[EPOCH #8, step #674] loss: 2.654252447905364\n",
      "[EPOCH #8, step #676] loss: 2.654008112770768\n",
      "[EPOCH #8, step #678] loss: 2.654283773916635\n",
      "[EPOCH #8, step #680] loss: 2.6534090679297537\n",
      "[EPOCH #8, step #682] loss: 2.6542642961309384\n",
      "[EPOCH #8, step #684] loss: 2.6537377012907153\n",
      "[EPOCH #8, step #686] loss: 2.654333443967883\n",
      "[EPOCH #8, step #688] loss: 2.653641937086994\n",
      "[EPOCH #8, step #690] loss: 2.6535733663915035\n",
      "[EPOCH #8, step #692] loss: 2.6533543509666364\n",
      "[EPOCH #8, step #694] loss: 2.6526341259908333\n",
      "[EPOCH #8, step #696] loss: 2.653060094184821\n",
      "[EPOCH #8, step #698] loss: 2.652949968291625\n",
      "[EPOCH #8, step #700] loss: 2.652801471157863\n",
      "[EPOCH #8, step #702] loss: 2.652951231043505\n",
      "[EPOCH #8, step #704] loss: 2.6526469690579892\n",
      "[EPOCH #8, step #706] loss: 2.653020839542783\n",
      "[EPOCH #8, step #708] loss: 2.6528444441484633\n",
      "[EPOCH #8, step #710] loss: 2.652098801233262\n",
      "[EPOCH #8, step #712] loss: 2.6520946193042345\n",
      "[EPOCH #8, step #714] loss: 2.6520581605551126\n",
      "[EPOCH #8, step #716] loss: 2.6521975046421193\n",
      "[EPOCH #8, step #718] loss: 2.6523580594255134\n",
      "[EPOCH #8, step #720] loss: 2.653188640962196\n",
      "[EPOCH #8, step #722] loss: 2.653829372770064\n",
      "[EPOCH #8, step #724] loss: 2.6539181419898723\n",
      "[EPOCH #8, step #726] loss: 2.653898069586354\n",
      "[EPOCH #8, step #728] loss: 2.6535219514975004\n",
      "[EPOCH #8, step #730] loss: 2.653655114806628\n",
      "[EPOCH #8, step #732] loss: 2.6526957342114\n",
      "[EPOCH #8, step #734] loss: 2.653414709065236\n",
      "[EPOCH #8, step #736] loss: 2.6533950060969937\n",
      "[EPOCH #8, step #738] loss: 2.653489694221094\n",
      "[EPOCH #8, step #740] loss: 2.6537163135332937\n",
      "[EPOCH #8, step #742] loss: 2.6530484444039346\n",
      "[EPOCH #8, step #744] loss: 2.652650618713174\n",
      "[EPOCH #8, step #746] loss: 2.652197103104598\n",
      "[EPOCH #8, step #748] loss: 2.652270818743432\n",
      "[EPOCH #8, step #750] loss: 2.6516661866209637\n",
      "[EPOCH #8, step #752] loss: 2.652295105010865\n",
      "[EPOCH #8, step #754] loss: 2.6519685644187674\n",
      "[EPOCH #8, step #756] loss: 2.6518949148991937\n",
      "[EPOCH #8, step #758] loss: 2.6513044391224976\n",
      "[EPOCH #8, step #760] loss: 2.650432696010374\n",
      "[EPOCH #8, step #762] loss: 2.650823760938832\n",
      "[EPOCH #8, step #764] loss: 2.650347509103663\n",
      "[EPOCH #8, step #766] loss: 2.6506643275083124\n",
      "[EPOCH #8, step #768] loss: 2.650380003901855\n",
      "[EPOCH #8, step #770] loss: 2.649536019169403\n",
      "[EPOCH #8, step #772] loss: 2.6489356857993163\n",
      "[EPOCH #8, step #774] loss: 2.6493165676055415\n",
      "[EPOCH #8, step #776] loss: 2.6498235792420237\n",
      "[EPOCH #8, step #778] loss: 2.6488558457965876\n",
      "[EPOCH #8, step #780] loss: 2.6490888398679666\n",
      "[EPOCH #8, step #782] loss: 2.6489653613223276\n",
      "[EPOCH #8, step #784] loss: 2.648632348874572\n",
      "[EPOCH #8, step #786] loss: 2.6496669123708974\n",
      "[EPOCH #8, step #788] loss: 2.6494592721320225\n",
      "[EPOCH #8, step #790] loss: 2.6490393014985\n",
      "[EPOCH #8, step #792] loss: 2.6482921856799613\n",
      "[EPOCH #8, step #794] loss: 2.6479804463356547\n",
      "[EPOCH #8, step #796] loss: 2.6477584011731214\n",
      "[EPOCH #8, step #798] loss: 2.6474781873378346\n",
      "[EPOCH #8, step #800] loss: 2.6482523396964672\n",
      "[EPOCH #8, step #802] loss: 2.648012198517064\n",
      "[EPOCH #8, step #804] loss: 2.6486954219593026\n",
      "[EPOCH #8, step #806] loss: 2.648914252219738\n",
      "[EPOCH #8, step #808] loss: 2.648983010992279\n",
      "[EPOCH #8, step #810] loss: 2.6492453969362777\n",
      "[EPOCH #8, step #812] loss: 2.649353974713024\n",
      "[EPOCH #8, step #814] loss: 2.648949482835875\n",
      "[EPOCH #8, step #816] loss: 2.649022976508777\n",
      "[EPOCH #8, step #818] loss: 2.649396962880797\n",
      "[EPOCH #8, step #820] loss: 2.6488158528610213\n",
      "[EPOCH #8, step #822] loss: 2.6489104578590625\n",
      "[EPOCH #8, step #824] loss: 2.649199416709669\n",
      "[EPOCH #8, step #826] loss: 2.6492020850314195\n",
      "[EPOCH #8, step #828] loss: 2.650030823467149\n",
      "[EPOCH #8, step #830] loss: 2.6491808879820162\n",
      "[EPOCH #8, step #832] loss: 2.64876211905966\n",
      "[EPOCH #8, step #834] loss: 2.6486904803864255\n",
      "[EPOCH #8, step #836] loss: 2.6486502693545435\n",
      "[EPOCH #8, step #838] loss: 2.6489425359096233\n",
      "[EPOCH #8, step #840] loss: 2.649386151934067\n",
      "[EPOCH #8, step #842] loss: 2.649429566495359\n",
      "[EPOCH #8, step #844] loss: 2.6490817826175124\n",
      "[EPOCH #8, step #846] loss: 2.6491049574567125\n",
      "[EPOCH #8, step #848] loss: 2.64922847259171\n",
      "[EPOCH #8, step #850] loss: 2.6487493918449143\n",
      "[EPOCH #8, step #852] loss: 2.648866222723707\n",
      "[EPOCH #8, step #854] loss: 2.648507137465895\n",
      "[EPOCH #8, step #856] loss: 2.6486393807232034\n",
      "[EPOCH #8, step #858] loss: 2.6481451014006927\n",
      "[EPOCH #8, step #860] loss: 2.648787710586353\n",
      "[EPOCH #8, step #862] loss: 2.6490160968599286\n",
      "[EPOCH #8, step #864] loss: 2.6484713601239154\n",
      "[EPOCH #8, step #866] loss: 2.6482199607835923\n",
      "[EPOCH #8, step #868] loss: 2.6490231731818654\n",
      "[EPOCH #8, step #870] loss: 2.649708488094273\n",
      "[EPOCH #8, step #872] loss: 2.649138244976293\n",
      "[EPOCH #8, step #874] loss: 2.650138762337821\n",
      "[EPOCH #8, step #876] loss: 2.6506061350062335\n",
      "[EPOCH #8, step #878] loss: 2.651354920742048\n",
      "[EPOCH #8, step #880] loss: 2.6515521543115277\n",
      "[EPOCH #8, step #882] loss: 2.6519172404927547\n",
      "[EPOCH #8, step #884] loss: 2.652399288328354\n",
      "[EPOCH #8, step #886] loss: 2.6516767488929034\n",
      "[EPOCH #8, step #888] loss: 2.6518075165786144\n",
      "[EPOCH #8, step #890] loss: 2.651437381435056\n",
      "[EPOCH #8, step #892] loss: 2.651641638922398\n",
      "[EPOCH #8, step #894] loss: 2.6520145223127396\n",
      "[EPOCH #8, step #896] loss: 2.651398183111363\n",
      "[EPOCH #8, step #898] loss: 2.651277900537739\n",
      "[EPOCH #8, step #900] loss: 2.6518590343117583\n",
      "[EPOCH #8, step #902] loss: 2.6523826775756785\n",
      "[EPOCH #8, step #904] loss: 2.6529366660513274\n",
      "[EPOCH #8, step #906] loss: 2.6533645725302817\n",
      "[EPOCH #8, step #908] loss: 2.6534687183608843\n",
      "[EPOCH #8, step #910] loss: 2.652849603693781\n",
      "[EPOCH #8, step #912] loss: 2.6532250321577306\n",
      "[EPOCH #8, step #914] loss: 2.653573089219182\n",
      "[EPOCH #8, step #916] loss: 2.653093285363009\n",
      "[EPOCH #8, step #918] loss: 2.6527652471965752\n",
      "[EPOCH #8, step #920] loss: 2.6523007353794044\n",
      "[EPOCH #8, step #922] loss: 2.6519119330113785\n",
      "[EPOCH #8, step #924] loss: 2.65243487035906\n",
      "[EPOCH #8, step #926] loss: 2.6522475974845268\n",
      "[EPOCH #8, step #928] loss: 2.6523151085887453\n",
      "[EPOCH #8, step #930] loss: 2.6529501041459476\n",
      "[EPOCH #8, step #932] loss: 2.6534959149386212\n",
      "[EPOCH #8, step #934] loss: 2.65356980453838\n",
      "[EPOCH #8, step #936] loss: 2.6538194451031845\n",
      "[EPOCH #8, step #938] loss: 2.652990594458656\n",
      "[EPOCH #8, step #940] loss: 2.6537190810020115\n",
      "[EPOCH #8, step #942] loss: 2.654352107584034\n",
      "[EPOCH #8, step #944] loss: 2.6544604030235734\n",
      "[EPOCH #8, step #946] loss: 2.654134946362899\n",
      "[EPOCH #8, step #948] loss: 2.6544400732434337\n",
      "[EPOCH #8, step #950] loss: 2.654195324855648\n",
      "[EPOCH #8, step #952] loss: 2.6541572684130914\n",
      "[EPOCH #8, step #954] loss: 2.654039063503605\n",
      "[EPOCH #8, step #956] loss: 2.653845514374218\n",
      "[EPOCH #8, step #958] loss: 2.65359219358661\n",
      "[EPOCH #8, step #960] loss: 2.653281419383872\n",
      "[EPOCH #8, step #962] loss: 2.653427251650413\n",
      "[EPOCH #8, step #964] loss: 2.65329862221535\n",
      "[EPOCH #8, step #966] loss: 2.6532008520942933\n",
      "[EPOCH #8, step #968] loss: 2.6530999858066884\n",
      "[EPOCH #8, step #970] loss: 2.6530212269507034\n",
      "[EPOCH #8, step #972] loss: 2.6538640674804737\n",
      "[EPOCH #8, step #974] loss: 2.654090663102957\n",
      "[EPOCH #8, step #976] loss: 2.6541382821091855\n",
      "[EPOCH #8, step #978] loss: 2.6531932518358006\n",
      "[EPOCH #8, step #980] loss: 2.6528897320701685\n",
      "[EPOCH #8, step #982] loss: 2.6525472436528483\n",
      "[EPOCH #8, step #984] loss: 2.652953554652064\n",
      "[EPOCH #8, step #986] loss: 2.652456137305456\n",
      "[EPOCH #8, step #988] loss: 2.6528773092042326\n",
      "[EPOCH #8, step #990] loss: 2.652994274130743\n",
      "[EPOCH #8, step #992] loss: 2.653273132392407\n",
      "[EPOCH #8, step #994] loss: 2.6535936785702727\n",
      "[EPOCH #8, step #996] loss: 2.65298966144248\n",
      "[EPOCH #8, step #998] loss: 2.6533041006332643\n",
      "[EPOCH #8, step #1000] loss: 2.6536263229844574\n",
      "[EPOCH #8, step #1002] loss: 2.6528143665250967\n",
      "[EPOCH #8, step #1004] loss: 2.6527013926956786\n",
      "[EPOCH #8, step #1006] loss: 2.652819927422979\n",
      "[EPOCH #8, step #1008] loss: 2.653092901227023\n",
      "[EPOCH #8, step #1010] loss: 2.653198350077213\n",
      "[EPOCH #8, step #1012] loss: 2.6534532896975773\n",
      "[EPOCH #8, step #1014] loss: 2.653076020954865\n",
      "[EPOCH #8, step #1016] loss: 2.652464562695521\n",
      "[EPOCH #8, step #1018] loss: 2.653347619382392\n",
      "[EPOCH #8, step #1020] loss: 2.6533636524908455\n",
      "[EPOCH #8, step #1022] loss: 2.653684766294903\n",
      "[EPOCH #8, step #1024] loss: 2.653079298414835\n",
      "[EPOCH #8, step #1026] loss: 2.6528751386987897\n",
      "[EPOCH #8, step #1028] loss: 2.652721558761782\n",
      "[EPOCH #8, step #1030] loss: 2.6528026108367135\n",
      "[EPOCH #8, step #1032] loss: 2.6529179292172915\n",
      "[EPOCH #8, step #1034] loss: 2.652677749205327\n",
      "[EPOCH #8, step #1036] loss: 2.652806248821196\n",
      "[EPOCH #8, step #1038] loss: 2.6526815883234445\n",
      "[EPOCH #8, step #1040] loss: 2.6530194973052406\n",
      "[EPOCH #8, step #1042] loss: 2.652851837936321\n",
      "[EPOCH #8, step #1044] loss: 2.652489872412248\n",
      "[EPOCH #8, step #1046] loss: 2.651958293081355\n",
      "[EPOCH #8, step #1048] loss: 2.6520334509466807\n",
      "[EPOCH #8, step #1050] loss: 2.651883885817342\n",
      "[EPOCH #8, step #1052] loss: 2.6520144759419977\n",
      "[EPOCH #8, step #1054] loss: 2.651647910235617\n",
      "[EPOCH #8, step #1056] loss: 2.651626304623758\n",
      "[EPOCH #8, step #1058] loss: 2.6511791514494827\n",
      "[EPOCH #8, step #1060] loss: 2.651830755125004\n",
      "[EPOCH #8, step #1062] loss: 2.6514528133010145\n",
      "[EPOCH #8, step #1064] loss: 2.65129640460574\n",
      "[EPOCH #8, step #1066] loss: 2.65130446408548\n",
      "[EPOCH #8, step #1068] loss: 2.6512027425783833\n",
      "[EPOCH #8, step #1070] loss: 2.650314183350927\n",
      "[EPOCH #8, step #1072] loss: 2.64999872584934\n",
      "[EPOCH #8, step #1074] loss: 2.6496531021872234\n",
      "[EPOCH #8, step #1076] loss: 2.649863763218581\n",
      "[EPOCH #8, step #1078] loss: 2.649868150128602\n",
      "[EPOCH #8, step #1080] loss: 2.649512521102404\n",
      "[EPOCH #8, step #1082] loss: 2.6488555488163743\n",
      "[EPOCH #8, step #1084] loss: 2.6490324024780554\n",
      "[EPOCH #8, step #1086] loss: 2.6492965431967894\n",
      "[EPOCH #8, step #1088] loss: 2.649437891659767\n",
      "[EPOCH #8, step #1090] loss: 2.649452120748602\n",
      "[EPOCH #8, step #1092] loss: 2.649657618748629\n",
      "[EPOCH #8, step #1094] loss: 2.649878909272146\n",
      "[EPOCH #8, step #1096] loss: 2.6501529914417805\n",
      "[EPOCH #8, step #1098] loss: 2.6501552763583986\n",
      "[EPOCH #8, step #1100] loss: 2.649843804517949\n",
      "[EPOCH #8, step #1102] loss: 2.649999195515623\n",
      "[EPOCH #8, step #1104] loss: 2.649854335094469\n",
      "[EPOCH #8, step #1106] loss: 2.6493481738995945\n",
      "[EPOCH #8, step #1108] loss: 2.649266724117819\n",
      "[EPOCH #8, step #1110] loss: 2.6488594744894334\n",
      "[EPOCH #8, step #1112] loss: 2.64860205316158\n",
      "[EPOCH #8, step #1114] loss: 2.648201329398048\n",
      "[EPOCH #8, step #1116] loss: 2.6480900946747754\n",
      "[EPOCH #8, step #1118] loss: 2.647733417763254\n",
      "[EPOCH #8, step #1120] loss: 2.6470617222849753\n",
      "[EPOCH #8, step #1122] loss: 2.6470281014140973\n",
      "[EPOCH #8, step #1124] loss: 2.6475701787736683\n",
      "[EPOCH #8, step #1126] loss: 2.6478460647410382\n",
      "[EPOCH #8, step #1128] loss: 2.6477240580600165\n",
      "[EPOCH #8, step #1130] loss: 2.647623735861268\n",
      "[EPOCH #8, step #1132] loss: 2.647492835506968\n",
      "[EPOCH #8, step #1134] loss: 2.6468458923474283\n",
      "[EPOCH #8, step #1136] loss: 2.6466234053240183\n",
      "[EPOCH #8, step #1138] loss: 2.646812279042285\n",
      "[EPOCH #8, step #1140] loss: 2.646255601403172\n",
      "[EPOCH #8, step #1142] loss: 2.646188335885943\n",
      "[EPOCH #8, step #1144] loss: 2.6461005837636224\n",
      "[EPOCH #8, step #1146] loss: 2.6459539736886595\n",
      "[EPOCH #8, step #1148] loss: 2.64543526851166\n",
      "[EPOCH #8, step #1150] loss: 2.6449862050554422\n",
      "[EPOCH #8, step #1152] loss: 2.645067944282671\n",
      "[EPOCH #8, step #1154] loss: 2.644621057221384\n",
      "[EPOCH #8, step #1156] loss: 2.6448201465524264\n",
      "[EPOCH #8, step #1158] loss: 2.6447986258423666\n",
      "[EPOCH #8, step #1160] loss: 2.64473421197837\n",
      "[EPOCH #8, step #1162] loss: 2.645089870470921\n",
      "[EPOCH #8, step #1164] loss: 2.6446186526138895\n",
      "[EPOCH #8, step #1166] loss: 2.6447021699707634\n",
      "[EPOCH #8, step #1168] loss: 2.644504019294262\n",
      "[EPOCH #8, step #1170] loss: 2.644364582382645\n",
      "[EPOCH #8, step #1172] loss: 2.643987671696825\n",
      "[EPOCH #8, step #1174] loss: 2.643635535341628\n",
      "[EPOCH #8, step #1176] loss: 2.643991217941375\n",
      "[EPOCH #8, step #1178] loss: 2.6443393733968565\n",
      "[EPOCH #8, step #1180] loss: 2.6439941888336\n",
      "[EPOCH #8, step #1182] loss: 2.644088201772733\n",
      "[EPOCH #8, step #1184] loss: 2.644251295484068\n",
      "[EPOCH #8, step #1186] loss: 2.6450545219382824\n",
      "[EPOCH #8, step #1188] loss: 2.645390961529128\n",
      "[EPOCH #8, step #1190] loss: 2.645651243595793\n",
      "[EPOCH #8, step #1192] loss: 2.645478497806559\n",
      "[EPOCH #8, step #1194] loss: 2.64576199543526\n",
      "[EPOCH #8, step #1196] loss: 2.6456759296662624\n",
      "[EPOCH #8, step #1198] loss: 2.6458013791457327\n",
      "[EPOCH #8, step #1200] loss: 2.6457627595810966\n",
      "[EPOCH #8, step #1202] loss: 2.6457974674893934\n",
      "[EPOCH #8, step #1204] loss: 2.645152911506748\n",
      "[EPOCH #8, step #1206] loss: 2.6448332101921452\n",
      "[EPOCH #8, step #1208] loss: 2.644892885430575\n",
      "[EPOCH #8, step #1210] loss: 2.6447523457269644\n",
      "[EPOCH #8, step #1212] loss: 2.6450488940802668\n",
      "[EPOCH #8, step #1214] loss: 2.6448369353886987\n",
      "[EPOCH #8, step #1216] loss: 2.6447923628149606\n",
      "[EPOCH #8, step #1218] loss: 2.6452458078886663\n",
      "[EPOCH #8, step #1220] loss: 2.6452251630762773\n",
      "[EPOCH #8, step #1222] loss: 2.6447756463937457\n",
      "[EPOCH #8, step #1224] loss: 2.644721183971483\n",
      "[EPOCH #8, step #1226] loss: 2.645270046997381\n",
      "[EPOCH #8, step #1228] loss: 2.645375337515351\n",
      "[EPOCH #8, step #1230] loss: 2.644980749204622\n",
      "[EPOCH #8, step #1232] loss: 2.645463729233444\n",
      "[EPOCH #8, step #1234] loss: 2.6457502442332896\n",
      "[EPOCH #8, step #1236] loss: 2.6456643528965276\n",
      "[EPOCH #8, step #1238] loss: 2.6459675770406283\n",
      "[EPOCH #8, step #1240] loss: 2.6461296542626442\n",
      "[EPOCH #8, step #1242] loss: 2.645896833171215\n",
      "[EPOCH #8, step #1244] loss: 2.6459786120188764\n",
      "[EPOCH #8, step #1246] loss: 2.645829446237376\n",
      "[EPOCH #8, step #1248] loss: 2.6458004878176222\n",
      "[EPOCH #8, step #1250] loss: 2.645456812841048\n",
      "[EPOCH #8, step #1252] loss: 2.645912606147224\n",
      "[EPOCH #8, step #1254] loss: 2.6459838739904273\n",
      "[EPOCH #8, step #1256] loss: 2.6460126948527334\n",
      "[EPOCH #8, step #1258] loss: 2.6454415141447276\n",
      "[EPOCH #8, step #1260] loss: 2.645449299362328\n",
      "[EPOCH #8, step #1262] loss: 2.6456030136238273\n",
      "[EPOCH #8, step #1264] loss: 2.645391212056277\n",
      "[EPOCH #8, step #1266] loss: 2.6452146174875693\n",
      "[EPOCH #8, step #1268] loss: 2.6452956137645893\n",
      "[EPOCH #8, step #1270] loss: 2.6452139965855728\n",
      "[EPOCH #8, step #1272] loss: 2.6445518440836917\n",
      "[EPOCH #8, step #1274] loss: 2.6440804919074563\n",
      "[EPOCH #8, step #1276] loss: 2.6442797835580802\n",
      "[EPOCH #8, step #1278] loss: 2.6440863549662716\n",
      "[EPOCH #8, step #1280] loss: 2.643766931032036\n",
      "[EPOCH #8, step #1282] loss: 2.6439339605422107\n",
      "[EPOCH #8, step #1284] loss: 2.644316013128377\n",
      "[EPOCH #8, step #1286] loss: 2.6439745981932243\n",
      "[EPOCH #8, step #1288] loss: 2.6441154779622127\n",
      "[EPOCH #8, step #1290] loss: 2.643966465011112\n",
      "[EPOCH #8, step #1292] loss: 2.6437201114560134\n",
      "[EPOCH #8, step #1294] loss: 2.6440506596362727\n",
      "[EPOCH #8, step #1296] loss: 2.6438548684395915\n",
      "[EPOCH #8, step #1298] loss: 2.644652549811195\n",
      "[EPOCH #8, step #1300] loss: 2.6443054591757256\n",
      "[EPOCH #8, step #1302] loss: 2.6442432961643245\n",
      "[EPOCH #8, step #1304] loss: 2.644133912375147\n",
      "[EPOCH #8, step #1306] loss: 2.6438867839676057\n",
      "[EPOCH #8, step #1308] loss: 2.6436687433783383\n",
      "[EPOCH #8, step #1310] loss: 2.6439209866396443\n",
      "[EPOCH #8, step #1312] loss: 2.644413378069806\n",
      "[EPOCH #8, step #1314] loss: 2.6445126830851624\n",
      "[EPOCH #8, step #1316] loss: 2.644679981556098\n",
      "[EPOCH #8, step #1318] loss: 2.6447856328630195\n",
      "[EPOCH #8, step #1320] loss: 2.644186674781499\n",
      "[EPOCH #8, step #1322] loss: 2.6435199440742028\n",
      "[EPOCH #8, step #1324] loss: 2.64320763542967\n",
      "[EPOCH #8, step #1326] loss: 2.6434301894323755\n",
      "[EPOCH #8, step #1328] loss: 2.643080552867519\n",
      "[EPOCH #8, step #1330] loss: 2.6427134563831527\n",
      "[EPOCH #8, step #1332] loss: 2.6424558932675692\n",
      "[EPOCH #8, step #1334] loss: 2.6417054166508076\n",
      "[EPOCH #8, step #1336] loss: 2.6415106181163974\n",
      "[EPOCH #8, step #1338] loss: 2.641413639782969\n",
      "[EPOCH #8, step #1340] loss: 2.642116468491437\n",
      "[EPOCH #8, step #1342] loss: 2.6422298069064154\n",
      "[EPOCH #8, step #1344] loss: 2.6423631594526724\n",
      "[EPOCH #8, step #1346] loss: 2.642757638525591\n",
      "[EPOCH #8, step #1348] loss: 2.642797898062076\n",
      "[EPOCH #8, step #1350] loss: 2.643778642753951\n",
      "[EPOCH #8, step #1352] loss: 2.643334049607592\n",
      "[EPOCH #8, step #1354] loss: 2.643361559389262\n",
      "[EPOCH #8, step #1356] loss: 2.643697683039885\n",
      "[EPOCH #8, step #1358] loss: 2.643831010334978\n",
      "[EPOCH #8, step #1360] loss: 2.6433096359443526\n",
      "[EPOCH #8, step #1362] loss: 2.64340342184418\n",
      "[EPOCH #8, step #1364] loss: 2.643317889468574\n",
      "[EPOCH #8, step #1366] loss: 2.6434296461117905\n",
      "[EPOCH #8, step #1368] loss: 2.6437514744334365\n",
      "[EPOCH #8, step #1370] loss: 2.644122408742369\n",
      "[EPOCH #8, step #1372] loss: 2.644621050106029\n",
      "[EPOCH #8, step #1374] loss: 2.6449337572617964\n",
      "[EPOCH #8, step #1376] loss: 2.644815018147598\n",
      "[EPOCH #8, step #1378] loss: 2.6446944156187526\n",
      "[EPOCH #8, step #1380] loss: 2.6451463455915625\n",
      "[EPOCH #8, step #1382] loss: 2.6449692054494776\n",
      "[EPOCH #8, step #1384] loss: 2.6452333383181466\n",
      "[EPOCH #8, step #1386] loss: 2.6450945756894355\n",
      "[EPOCH #8, step #1388] loss: 2.6451283838355857\n",
      "[EPOCH #8, step #1390] loss: 2.6452331241303257\n",
      "[EPOCH #8, step #1392] loss: 2.645565638675676\n",
      "[EPOCH #8, step #1394] loss: 2.645188781095662\n",
      "[EPOCH #8, step #1396] loss: 2.6448221687939477\n",
      "[EPOCH #8, step #1398] loss: 2.6448536592351273\n",
      "[EPOCH #8, step #1400] loss: 2.644641664690158\n",
      "[EPOCH #8, step #1402] loss: 2.6443246945430787\n",
      "[EPOCH #8, step #1404] loss: 2.6439225341077375\n",
      "[EPOCH #8, step #1406] loss: 2.644044578541401\n",
      "[EPOCH #8, step #1408] loss: 2.6437574564945283\n",
      "[EPOCH #8, step #1410] loss: 2.644076074969253\n",
      "[EPOCH #8, step #1412] loss: 2.644527033551399\n",
      "[EPOCH #8, step #1414] loss: 2.644552601689585\n",
      "[EPOCH #8, step #1416] loss: 2.6448234434942166\n",
      "[EPOCH #8, step #1418] loss: 2.6452497629484215\n",
      "[EPOCH #8, step #1420] loss: 2.6453024708494848\n",
      "[EPOCH #8, step #1422] loss: 2.645278195302753\n",
      "[EPOCH #8, step #1424] loss: 2.645612784770497\n",
      "[EPOCH #8, step #1426] loss: 2.6458128877010223\n",
      "[EPOCH #8, step #1428] loss: 2.6464499214297827\n",
      "[EPOCH #8, step #1430] loss: 2.6460303397215306\n",
      "[EPOCH #8, step #1432] loss: 2.646067980195955\n",
      "[EPOCH #8, step #1434] loss: 2.6464154411276044\n",
      "[EPOCH #8, step #1436] loss: 2.6461776167299487\n",
      "[EPOCH #8, step #1438] loss: 2.646425292589666\n",
      "[EPOCH #8, step #1440] loss: 2.6461470388522335\n",
      "[EPOCH #8, step #1442] loss: 2.6462197229421065\n",
      "[EPOCH #8, step #1444] loss: 2.6461017658141244\n",
      "[EPOCH #8, step #1446] loss: 2.6461937984434916\n",
      "[EPOCH #8, step #1448] loss: 2.646537635308286\n",
      "[EPOCH #8, step #1450] loss: 2.647183728826038\n",
      "[EPOCH #8, step #1452] loss: 2.6468996189416725\n",
      "[EPOCH #8, step #1454] loss: 2.6463296267584835\n",
      "[EPOCH #8, step #1456] loss: 2.6460572971247123\n",
      "[EPOCH #8, step #1458] loss: 2.645780345525866\n",
      "[EPOCH #8, step #1460] loss: 2.6463530186020616\n",
      "[EPOCH #8, step #1462] loss: 2.6461814807362534\n",
      "[EPOCH #8, step #1464] loss: 2.6459393239265414\n",
      "[EPOCH #8, step #1466] loss: 2.6460691291455434\n",
      "[EPOCH #8, step #1468] loss: 2.6459695129186787\n",
      "[EPOCH #8, step #1470] loss: 2.6463494248976924\n",
      "[EPOCH #8, step #1472] loss: 2.6460226844624444\n",
      "[EPOCH #8, step #1474] loss: 2.6465267181396483\n",
      "[EPOCH #8, step #1476] loss: 2.6464946064984547\n",
      "[EPOCH #8, step #1478] loss: 2.6465675929174624\n",
      "[EPOCH #8, step #1480] loss: 2.646315247202789\n",
      "[EPOCH #8, step #1482] loss: 2.646055092943414\n",
      "[EPOCH #8, step #1484] loss: 2.6459803881468598\n",
      "[EPOCH #8, step #1486] loss: 2.6460182498426508\n",
      "[EPOCH #8, step #1488] loss: 2.6460527200039157\n",
      "[EPOCH #8, step #1490] loss: 2.64579748179911\n",
      "[EPOCH #8, step #1492] loss: 2.6455140121815113\n",
      "[EPOCH #8, step #1494] loss: 2.6454087754954463\n",
      "[EPOCH #8, step #1496] loss: 2.645749905464565\n",
      "[EPOCH #8, step #1498] loss: 2.6458835307560897\n",
      "[EPOCH #8, step #1500] loss: 2.6458106399932597\n",
      "[EPOCH #8, step #1502] loss: 2.6463015225436477\n",
      "[EPOCH #8, step #1504] loss: 2.6459100853169084\n",
      "[EPOCH #8, step #1506] loss: 2.645797512589817\n",
      "[EPOCH #8, step #1508] loss: 2.6460610489880034\n",
      "[EPOCH #8, step #1510] loss: 2.646147970329603\n",
      "[EPOCH #8, step #1512] loss: 2.646334889860084\n",
      "[EPOCH #8, step #1514] loss: 2.6463876376451045\n",
      "[EPOCH #8, step #1516] loss: 2.6466814767552114\n",
      "[EPOCH #8, step #1518] loss: 2.646677720224959\n",
      "[EPOCH #8, step #1520] loss: 2.6465583618811133\n",
      "[EPOCH #8, step #1522] loss: 2.6463808679925087\n",
      "[EPOCH #8, step #1524] loss: 2.6460312962141193\n",
      "[EPOCH #8, step #1526] loss: 2.6460844742838043\n",
      "[EPOCH #8, step #1528] loss: 2.6461269529603366\n",
      "[EPOCH #8, step #1530] loss: 2.6461692360940905\n",
      "[EPOCH #8, step #1532] loss: 2.646198868984812\n",
      "[EPOCH #8, step #1534] loss: 2.645785420725322\n",
      "[EPOCH #8, step #1536] loss: 2.645864354222334\n",
      "[EPOCH #8, step #1538] loss: 2.645931046066383\n",
      "[EPOCH #8, step #1540] loss: 2.64543272287021\n",
      "[EPOCH #8, step #1542] loss: 2.6449484239517678\n",
      "[EPOCH #8, step #1544] loss: 2.644366982916798\n",
      "[EPOCH #8, step #1546] loss: 2.6445064961563487\n",
      "[EPOCH #8, step #1548] loss: 2.644591914137538\n",
      "[EPOCH #8, step #1550] loss: 2.6445734801406173\n",
      "[EPOCH #8, step #1552] loss: 2.644393916830123\n",
      "[EPOCH #8, step #1554] loss: 2.643786141880072\n",
      "[EPOCH #8, step #1556] loss: 2.6438558416329827\n",
      "[EPOCH #8, step #1558] loss: 2.643907146089883\n",
      "[EPOCH #8, step #1560] loss: 2.64412779146704\n",
      "[EPOCH #8, step #1562] loss: 2.6442283599405663\n",
      "[EPOCH #8, step #1564] loss: 2.6440032595643603\n",
      "[EPOCH #8, step #1566] loss: 2.643568107636019\n",
      "[EPOCH #8, step #1568] loss: 2.643536698142004\n",
      "[EPOCH #8, step #1570] loss: 2.6432498579644457\n",
      "[EPOCH #8, step #1572] loss: 2.6427367282989898\n",
      "[EPOCH #8, step #1574] loss: 2.64265648546673\n",
      "[EPOCH #8, step #1576] loss: 2.6426733438924814\n",
      "[EPOCH #8, step #1578] loss: 2.6425537405473056\n",
      "[EPOCH #8, step #1580] loss: 2.6422611903269635\n",
      "[EPOCH #8, step #1582] loss: 2.641893417038499\n",
      "[EPOCH #8, step #1584] loss: 2.6418107820234087\n",
      "[EPOCH #8, step #1586] loss: 2.641792240049678\n",
      "[EPOCH #8, step #1588] loss: 2.641412335795528\n",
      "[EPOCH #8, step #1590] loss: 2.6410073105604073\n",
      "[EPOCH #8, step #1592] loss: 2.640917406543126\n",
      "[EPOCH #8, step #1594] loss: 2.6413576764372824\n",
      "[EPOCH #8, step #1596] loss: 2.64128718916595\n",
      "[EPOCH #8, step #1598] loss: 2.64103116282379\n",
      "[EPOCH #8, step #1600] loss: 2.64103641158562\n",
      "[EPOCH #8, step #1602] loss: 2.64086134182388\n",
      "[EPOCH #8, step #1604] loss: 2.640655023063826\n",
      "[EPOCH #8, step #1606] loss: 2.640473711171652\n",
      "[EPOCH #8, step #1608] loss: 2.640601872064224\n",
      "[EPOCH #8, step #1610] loss: 2.640534919067468\n",
      "[EPOCH #8, step #1612] loss: 2.640623761198939\n",
      "[EPOCH #8, step #1614] loss: 2.6402953243846126\n",
      "[EPOCH #8, step #1616] loss: 2.6401637213865623\n",
      "[EPOCH #8, step #1618] loss: 2.640268839164013\n",
      "[EPOCH #8, step #1620] loss: 2.640441237813819\n",
      "[EPOCH #8, step #1622] loss: 2.640628757553195\n",
      "[EPOCH #8, step #1624] loss: 2.6405835035764254\n",
      "[EPOCH #8, step #1626] loss: 2.6410372481436983\n",
      "[EPOCH #8, step #1628] loss: 2.641151194048484\n",
      "[EPOCH #8, step #1630] loss: 2.6408148738666957\n",
      "[EPOCH #8, step #1632] loss: 2.6407093519968847\n",
      "[EPOCH #8, step #1634] loss: 2.640541783604053\n",
      "[EPOCH #8, step #1636] loss: 2.640406112519429\n",
      "[EPOCH #8, step #1638] loss: 2.640291734611646\n",
      "[EPOCH #8, step #1640] loss: 2.640305351150392\n",
      "[EPOCH #8, step #1642] loss: 2.6406701960653627\n",
      "[EPOCH #8, step #1644] loss: 2.6400549097264068\n",
      "[EPOCH #8, step #1646] loss: 2.639915572561925\n",
      "[EPOCH #8, step #1648] loss: 2.639793245339842\n",
      "[EPOCH #8, step #1650] loss: 2.6396049068307676\n",
      "[EPOCH #8, step #1652] loss: 2.639652599512413\n",
      "[EPOCH #8, step #1654] loss: 2.639816287204938\n",
      "[EPOCH #8, step #1656] loss: 2.6398076664343897\n",
      "[EPOCH #8, step #1658] loss: 2.6400151307357227\n",
      "[EPOCH #8, step #1660] loss: 2.6398829345886856\n",
      "[EPOCH #8, step #1662] loss: 2.6399674571857923\n",
      "[EPOCH #8, step #1664] loss: 2.6401539120946205\n",
      "[EPOCH #8, step #1666] loss: 2.640344098290785\n",
      "[EPOCH #8, step #1668] loss: 2.6400690094448978\n",
      "[EPOCH #8, step #1670] loss: 2.640160316054083\n",
      "[EPOCH #8, step #1672] loss: 2.6400185128706197\n",
      "[EPOCH #8, step #1674] loss: 2.639416757982169\n",
      "[EPOCH #8, step #1676] loss: 2.6392515968124854\n",
      "[EPOCH #8, step #1678] loss: 2.638764683443425\n",
      "[EPOCH #8, step #1680] loss: 2.6383118365649167\n",
      "[EPOCH #8, step #1682] loss: 2.637990662404206\n",
      "[EPOCH #8, step #1684] loss: 2.6386253276281613\n",
      "[EPOCH #8, step #1686] loss: 2.638369916668289\n",
      "[EPOCH #8, step #1688] loss: 2.6379454521260506\n",
      "[EPOCH #8, step #1690] loss: 2.6381406290583325\n",
      "[EPOCH #8, step #1692] loss: 2.638157671749838\n",
      "[EPOCH #8, step #1694] loss: 2.6379502349898525\n",
      "[EPOCH #8, step #1696] loss: 2.6375400939968383\n",
      "[EPOCH #8, step #1698] loss: 2.637298444216921\n",
      "[EPOCH #8, step #1700] loss: 2.637624285068321\n",
      "[EPOCH #8, step #1702] loss: 2.637310237794922\n",
      "[EPOCH #8, step #1704] loss: 2.637350726057707\n",
      "[EPOCH #8, step #1706] loss: 2.637593314880925\n",
      "[EPOCH #8, step #1708] loss: 2.6378507965695026\n",
      "[EPOCH #8, step #1710] loss: 2.6379790510927843\n",
      "[EPOCH #8, step #1712] loss: 2.637986688118404\n",
      "[EPOCH #8, step #1714] loss: 2.6377480572236176\n",
      "[EPOCH #8, step #1716] loss: 2.6369852190039915\n",
      "[EPOCH #8, step #1718] loss: 2.637047879081469\n",
      "[EPOCH #8, step #1720] loss: 2.6371581128417994\n",
      "[EPOCH #8, step #1722] loss: 2.63706576782676\n",
      "[EPOCH #8, step #1724] loss: 2.6370047798018525\n",
      "[EPOCH #8, step #1726] loss: 2.636881491664385\n",
      "[EPOCH #8, step #1728] loss: 2.63709438219451\n",
      "[EPOCH #8, step #1730] loss: 2.6368824452902113\n",
      "[EPOCH #8, step #1732] loss: 2.637004207133972\n",
      "[EPOCH #8, step #1734] loss: 2.6370924024142175\n",
      "[EPOCH #8, step #1736] loss: 2.637176407502174\n",
      "[EPOCH #8, step #1738] loss: 2.637261045945657\n",
      "[EPOCH #8, step #1740] loss: 2.6373099463893928\n",
      "[EPOCH #8, step #1742] loss: 2.636992799845907\n",
      "[EPOCH #8, step #1744] loss: 2.636726586046738\n",
      "[EPOCH #8, step #1746] loss: 2.6364109391270873\n",
      "[EPOCH #8, step #1748] loss: 2.636730916640498\n",
      "[EPOCH #8, step #1750] loss: 2.636655199874952\n",
      "[EPOCH #8, step #1752] loss: 2.6369851839862\n",
      "[EPOCH #8, step #1754] loss: 2.6370319372568374\n",
      "[EPOCH #8, step #1756] loss: 2.637467979570648\n",
      "[EPOCH #8, step #1758] loss: 2.6374532451949517\n",
      "[EPOCH #8, step #1760] loss: 2.637400323528244\n",
      "[EPOCH #8, step #1762] loss: 2.6371734344479174\n",
      "[EPOCH #8, step #1764] loss: 2.6371177882040526\n",
      "[EPOCH #8, step #1766] loss: 2.637145026430412\n",
      "[EPOCH #8, step #1768] loss: 2.6369752682421153\n",
      "[EPOCH #8, step #1770] loss: 2.6370173613275263\n",
      "[EPOCH #8, step #1772] loss: 2.6370515711080267\n",
      "[EPOCH #8, step #1774] loss: 2.6370926728718715\n",
      "[EPOCH #8, step #1776] loss: 2.6370479120722496\n",
      "[EPOCH #8, step #1778] loss: 2.6369398566964906\n",
      "[EPOCH #8, step #1780] loss: 2.6371242324667388\n",
      "[EPOCH #8, step #1782] loss: 2.6368208837455667\n",
      "[EPOCH #8, step #1784] loss: 2.636831678729765\n",
      "[EPOCH #8, step #1786] loss: 2.636691149280401\n",
      "[EPOCH #8, step #1788] loss: 2.6368824154255175\n",
      "[EPOCH #8, step #1790] loss: 2.6368365380299417\n",
      "[EPOCH #8, step #1792] loss: 2.637048643990329\n",
      "[EPOCH #8, step #1794] loss: 2.636983777221531\n",
      "[EPOCH #8, step #1796] loss: 2.637126287156234\n",
      "[EPOCH #8, step #1798] loss: 2.636891896953975\n",
      "[EPOCH #8, step #1800] loss: 2.6367184091845464\n",
      "[EPOCH #8, step #1802] loss: 2.636648727336065\n",
      "[EPOCH #8, step #1804] loss: 2.63629236835522\n",
      "[EPOCH #8, step #1806] loss: 2.635636520768373\n",
      "[EPOCH #8, step #1808] loss: 2.6355198926198145\n",
      "[EPOCH #8, step #1810] loss: 2.635406213001544\n",
      "[EPOCH #8, step #1812] loss: 2.6353794753189845\n",
      "[EPOCH #8, step #1814] loss: 2.6354298252047914\n",
      "[EPOCH #8, step #1816] loss: 2.635308794156496\n",
      "[EPOCH #8, step #1818] loss: 2.6357135174364883\n",
      "[EPOCH #8, step #1820] loss: 2.635654839429798\n",
      "[EPOCH #8, step #1822] loss: 2.6355187941957685\n",
      "[EPOCH #8, step #1824] loss: 2.635403092332082\n",
      "[EPOCH #8, step #1826] loss: 2.635461367018313\n",
      "[EPOCH #8, step #1828] loss: 2.6355925450369333\n",
      "[EPOCH #8, step #1830] loss: 2.635487781138709\n",
      "[EPOCH #8, step #1832] loss: 2.6354221549114762\n",
      "[EPOCH #8, step #1834] loss: 2.6351173227424516\n",
      "[EPOCH #8, step #1836] loss: 2.635328975201432\n",
      "[EPOCH #8, step #1838] loss: 2.6354908972346567\n",
      "[EPOCH #8, step #1840] loss: 2.6353517479381114\n",
      "[EPOCH #8, step #1842] loss: 2.6351469572768935\n",
      "[EPOCH #8, step #1844] loss: 2.6346911388361036\n",
      "[EPOCH #8, step #1846] loss: 2.634630182141798\n",
      "[EPOCH #8, step #1848] loss: 2.634317364739108\n",
      "[EPOCH #8, step #1850] loss: 2.634277910686454\n",
      "[EPOCH #8, step #1852] loss: 2.634378422741239\n",
      "[EPOCH #8, step #1854] loss: 2.634262088366917\n",
      "[EPOCH #8, step #1856] loss: 2.6341328466201768\n",
      "[EPOCH #8, step #1858] loss: 2.634012522204965\n",
      "[EPOCH #8, step #1860] loss: 2.6343416817274097\n",
      "[EPOCH #8, step #1862] loss: 2.6342941111796527\n",
      "[EPOCH #8, step #1864] loss: 2.634392128617131\n",
      "[EPOCH #8, step #1866] loss: 2.6343305705381574\n",
      "[EPOCH #8, step #1868] loss: 2.634156412782358\n",
      "[EPOCH #8, step #1870] loss: 2.634694800218881\n",
      "[EPOCH #8, step #1872] loss: 2.6346999327893315\n",
      "[EPOCH #8, step #1874] loss: 2.6347267143885293\n",
      "[EPOCH #8, step #1876] loss: 2.6347068324645404\n",
      "[EPOCH #8, step #1878] loss: 2.6344648767114003\n",
      "[EPOCH #8, step #1880] loss: 2.6342640722260584\n",
      "[EPOCH #8, step #1882] loss: 2.6342207783406804\n",
      "[EPOCH #8, step #1884] loss: 2.634253925670047\n",
      "[EPOCH #8, step #1886] loss: 2.6342150852297372\n",
      "[EPOCH #8, step #1888] loss: 2.6339723817124576\n",
      "[EPOCH #8, step #1890] loss: 2.6339470789837245\n",
      "[EPOCH #8, step #1892] loss: 2.6342286545324756\n",
      "[EPOCH #8, step #1894] loss: 2.634162523941503\n",
      "[EPOCH #8, step #1896] loss: 2.633858353260887\n",
      "[EPOCH #8, step #1898] loss: 2.6335227458711796\n",
      "[EPOCH #8, step #1900] loss: 2.633869920950824\n",
      "[EPOCH #8, step #1902] loss: 2.633709699369642\n",
      "[EPOCH #8, step #1904] loss: 2.633571361869652\n",
      "[EPOCH #8, step #1906] loss: 2.633280541738041\n",
      "[EPOCH #8, step #1908] loss: 2.6334670529807656\n",
      "[EPOCH #8, step #1910] loss: 2.633456372827962\n",
      "[EPOCH #8, step #1912] loss: 2.633932733373747\n",
      "[EPOCH #8, step #1914] loss: 2.634004210243026\n",
      "[EPOCH #8, step #1916] loss: 2.633610865008912\n",
      "[EPOCH #8, step #1918] loss: 2.633615761824484\n",
      "[EPOCH #8, step #1920] loss: 2.633572963362619\n",
      "[EPOCH #8, step #1922] loss: 2.6334732168364265\n",
      "[EPOCH #8, step #1924] loss: 2.6332368815409675\n",
      "[EPOCH #8, step #1926] loss: 2.632963058363296\n",
      "[EPOCH #8, step #1928] loss: 2.632946396504368\n",
      "[EPOCH #8, step #1930] loss: 2.632814091206338\n",
      "[EPOCH #8, step #1932] loss: 2.6327661531179976\n",
      "[EPOCH #8, step #1934] loss: 2.63297070280218\n",
      "[EPOCH #8, step #1936] loss: 2.6329476240681937\n",
      "[EPOCH #8, step #1938] loss: 2.632581454629195\n",
      "[EPOCH #8, step #1940] loss: 2.632684424573278\n",
      "[EPOCH #8, step #1942] loss: 2.6323425673481364\n",
      "[EPOCH #8, step #1944] loss: 2.632174243473455\n",
      "[EPOCH #8, step #1946] loss: 2.632128795539041\n",
      "[EPOCH #8, step #1948] loss: 2.631711870477773\n",
      "[EPOCH #8, step #1950] loss: 2.6317741587979557\n",
      "[EPOCH #8, step #1952] loss: 2.6317114454626855\n",
      "[EPOCH #8, step #1954] loss: 2.6317641751540592\n",
      "[EPOCH #8, step #1956] loss: 2.6313827697513172\n",
      "[EPOCH #8, step #1958] loss: 2.6313489365176075\n",
      "[EPOCH #8, step #1960] loss: 2.631486436957185\n",
      "[EPOCH #8, step #1962] loss: 2.631281585336278\n",
      "[EPOCH #8, step #1964] loss: 2.631313432506629\n",
      "[EPOCH #8, step #1966] loss: 2.6317119401423654\n",
      "[EPOCH #8, step #1968] loss: 2.631740722213075\n",
      "[EPOCH #8, step #1970] loss: 2.631854880285529\n",
      "[EPOCH #8, step #1972] loss: 2.6317480136704092\n",
      "[EPOCH #8, step #1974] loss: 2.631620294413989\n",
      "[EPOCH #8, step #1976] loss: 2.631941860048953\n",
      "[EPOCH #8, step #1978] loss: 2.631973618808089\n",
      "[EPOCH #8, step #1980] loss: 2.631668022038779\n",
      "[EPOCH #8, step #1982] loss: 2.6314393409381776\n",
      "[EPOCH #8, step #1984] loss: 2.631098434066292\n",
      "[EPOCH #8, step #1986] loss: 2.6312894710176966\n",
      "[EPOCH #8, step #1988] loss: 2.6314927437846056\n",
      "[EPOCH #8, step #1990] loss: 2.6313469638062865\n",
      "[EPOCH #8, step #1992] loss: 2.631147976024511\n",
      "[EPOCH #8, step #1994] loss: 2.631197646446993\n",
      "[EPOCH #8, step #1996] loss: 2.631150065449756\n",
      "[EPOCH #8, step #1998] loss: 2.630960895217258\n",
      "[EPOCH #8, step #2000] loss: 2.631014220122395\n",
      "[EPOCH #8, step #2002] loss: 2.6308297819931745\n",
      "[EPOCH #8, step #2004] loss: 2.6310244988919496\n",
      "[EPOCH #8, step #2006] loss: 2.6311938026738986\n",
      "[EPOCH #8, step #2008] loss: 2.6310737842110745\n",
      "[EPOCH #8, step #2010] loss: 2.6311273731917426\n",
      "[EPOCH #8, step #2012] loss: 2.6310593001118834\n",
      "[EPOCH #8, step #2014] loss: 2.631088280796117\n",
      "[EPOCH #8, step #2016] loss: 2.6309520175212318\n",
      "[EPOCH #8, step #2018] loss: 2.63106452568502\n",
      "[EPOCH #8, step #2020] loss: 2.6310480080401173\n",
      "[EPOCH #8, step #2022] loss: 2.6311378899153306\n",
      "[EPOCH #8, step #2024] loss: 2.631007932792475\n",
      "[EPOCH #8, step #2026] loss: 2.630889746198292\n",
      "[EPOCH #8, step #2028] loss: 2.6306054276630406\n",
      "[EPOCH #8, step #2030] loss: 2.6306864013817437\n",
      "[EPOCH #8, step #2032] loss: 2.630786989395453\n",
      "[EPOCH #8, step #2034] loss: 2.6304887731186586\n",
      "[EPOCH #8, step #2036] loss: 2.630368260056819\n",
      "[EPOCH #8, step #2038] loss: 2.630475157379461\n",
      "[EPOCH #8, step #2040] loss: 2.630452249343345\n",
      "[EPOCH #8, step #2042] loss: 2.6303340494195093\n",
      "[EPOCH #8, step #2044] loss: 2.630587280000626\n",
      "[EPOCH #8, step #2046] loss: 2.630474439468626\n",
      "[EPOCH #8, step #2048] loss: 2.630017673579468\n",
      "[EPOCH #8, step #2050] loss: 2.6299895721200266\n",
      "[EPOCH #8, step #2052] loss: 2.629645580845929\n",
      "[EPOCH #8, step #2054] loss: 2.6294103475672777\n",
      "[EPOCH #8, step #2056] loss: 2.629332897381465\n",
      "[EPOCH #8, step #2058] loss: 2.629180505300043\n",
      "[EPOCH #8, step #2060] loss: 2.629243221923832\n",
      "[EPOCH #8, step #2062] loss: 2.6292838709942647\n",
      "[EPOCH #8, step #2064] loss: 2.6291952906162916\n",
      "[EPOCH #8, step #2066] loss: 2.6293444402216712\n",
      "[EPOCH #8, step #2068] loss: 2.629456841525045\n",
      "[EPOCH #8, step #2070] loss: 2.6291964903135683\n",
      "[EPOCH #8, step #2072] loss: 2.629065231890478\n",
      "[EPOCH #8, step #2074] loss: 2.629162156151002\n",
      "[EPOCH #8, step #2076] loss: 2.629421683131472\n",
      "[EPOCH #8, step #2078] loss: 2.629469600017395\n",
      "[EPOCH #8, step #2080] loss: 2.629285635884022\n",
      "[EPOCH #8, step #2082] loss: 2.6293089802426555\n",
      "[EPOCH #8, step #2084] loss: 2.6296309804458984\n",
      "[EPOCH #8, step #2086] loss: 2.6296114799904378\n",
      "[EPOCH #8, step #2088] loss: 2.6293060179815844\n",
      "[EPOCH #8, step #2090] loss: 2.629315183984783\n",
      "[EPOCH #8, step #2092] loss: 2.6292309178385618\n",
      "[EPOCH #8, step #2094] loss: 2.629607415426887\n",
      "[EPOCH #8, step #2096] loss: 2.629156625492549\n",
      "[EPOCH #8, step #2098] loss: 2.6289719606706674\n",
      "[EPOCH #8, step #2100] loss: 2.6287535810289016\n",
      "[EPOCH #8, step #2102] loss: 2.6287898063319557\n",
      "[EPOCH #8, step #2104] loss: 2.6288626882072865\n",
      "[EPOCH #8, step #2106] loss: 2.628913730764819\n",
      "[EPOCH #8, step #2108] loss: 2.6288251171975747\n",
      "[EPOCH #8, step #2110] loss: 2.6289841644801215\n",
      "[EPOCH #8, step #2112] loss: 2.629177571527776\n",
      "[EPOCH #8, step #2114] loss: 2.629267084006722\n",
      "[EPOCH #8, step #2116] loss: 2.629177445727922\n",
      "[EPOCH #8, step #2118] loss: 2.6292980493043268\n",
      "[EPOCH #8, step #2120] loss: 2.6292297637220936\n",
      "[EPOCH #8, step #2122] loss: 2.6294476491238115\n",
      "[EPOCH #8, step #2124] loss: 2.629328969113967\n",
      "[EPOCH #8, step #2126] loss: 2.629247816336452\n",
      "[EPOCH #8, step #2128] loss: 2.628971810237854\n",
      "[EPOCH #8, step #2130] loss: 2.628950358388123\n",
      "[EPOCH #8, step #2132] loss: 2.6286903838847535\n",
      "[EPOCH #8, step #2134] loss: 2.6285489481561917\n",
      "[EPOCH #8, step #2136] loss: 2.628491215411335\n",
      "[EPOCH #8, step #2138] loss: 2.6288422252486496\n",
      "[EPOCH #8, step #2140] loss: 2.6288076316235722\n",
      "[EPOCH #8, step #2142] loss: 2.628903791440518\n",
      "[EPOCH #8, step #2144] loss: 2.6288479054168667\n",
      "[EPOCH #8, step #2146] loss: 2.6287666407084544\n",
      "[EPOCH #8, step #2148] loss: 2.628491603313018\n",
      "[EPOCH #8, step #2150] loss: 2.6282537169148346\n",
      "[EPOCH #8, step #2152] loss: 2.6283394766031063\n",
      "[EPOCH #8, step #2154] loss: 2.6285429867680277\n",
      "[EPOCH #8, step #2156] loss: 2.628484026999953\n",
      "[EPOCH #8, step #2158] loss: 2.6287214654968425\n",
      "[EPOCH #8, step #2160] loss: 2.6286628776432903\n",
      "[EPOCH #8, step #2162] loss: 2.6286287927759835\n",
      "[EPOCH #8, step #2164] loss: 2.6287021467922465\n",
      "[EPOCH #8, step #2166] loss: 2.6290737216682767\n",
      "[EPOCH #8, step #2168] loss: 2.6289136849993\n",
      "[EPOCH #8, step #2170] loss: 2.6286625250974924\n",
      "[EPOCH #8, step #2172] loss: 2.628748558602243\n",
      "[EPOCH #8, step #2174] loss: 2.628579670094896\n",
      "[EPOCH #8, step #2176] loss: 2.628529579802615\n",
      "[EPOCH #8, step #2178] loss: 2.6286837582524734\n",
      "[EPOCH #8, step #2180] loss: 2.6285097235553256\n",
      "[EPOCH #8, step #2182] loss: 2.62847348898854\n",
      "[EPOCH #8, step #2184] loss: 2.6285578562411347\n",
      "[EPOCH #8, step #2186] loss: 2.6283907346873727\n",
      "[EPOCH #8, step #2188] loss: 2.6281827760102163\n",
      "[EPOCH #8, step #2190] loss: 2.628556430149383\n",
      "[EPOCH #8, step #2192] loss: 2.6284219000473232\n",
      "[EPOCH #8, step #2194] loss: 2.6286042654975943\n",
      "[EPOCH #8, step #2196] loss: 2.6289269811845553\n",
      "[EPOCH #8, step #2198] loss: 2.629036674774902\n",
      "[EPOCH #8, step #2200] loss: 2.629314814573632\n",
      "[EPOCH #8, step #2202] loss: 2.6294552492543453\n",
      "[EPOCH #8, step #2204] loss: 2.6293067387712785\n",
      "[EPOCH #8, step #2206] loss: 2.629515082629817\n",
      "[EPOCH #8, step #2208] loss: 2.6294913909833535\n",
      "[EPOCH #8, step #2210] loss: 2.6294555558925405\n",
      "[EPOCH #8, step #2212] loss: 2.629352518028659\n",
      "[EPOCH #8, step #2214] loss: 2.629107677694368\n",
      "[EPOCH #8, step #2216] loss: 2.6289597812621617\n",
      "[EPOCH #8, step #2218] loss: 2.628825657751282\n",
      "[EPOCH #8, step #2220] loss: 2.6285129056112124\n",
      "[EPOCH #8, step #2222] loss: 2.628788278063192\n",
      "[EPOCH #8, step #2224] loss: 2.6290074406313093\n",
      "[EPOCH #8, step #2226] loss: 2.628801905311273\n",
      "[EPOCH #8, step #2228] loss: 2.6287009690363026\n",
      "[EPOCH #8, step #2230] loss: 2.628669725838716\n",
      "[EPOCH #8, step #2232] loss: 2.628596662140405\n",
      "[EPOCH #8, step #2234] loss: 2.628226316641908\n",
      "[EPOCH #8, step #2236] loss: 2.628307567145817\n",
      "[EPOCH #8, step #2238] loss: 2.6285032371475845\n",
      "[EPOCH #8, step #2240] loss: 2.6287054171364312\n",
      "[EPOCH #8, step #2242] loss: 2.628429788539732\n",
      "[EPOCH #8, step #2244] loss: 2.628106246015808\n",
      "[EPOCH #8, step #2246] loss: 2.6280469392000647\n",
      "[EPOCH #8, step #2248] loss: 2.6281418163758374\n",
      "[EPOCH #8, step #2250] loss: 2.6282254469124595\n",
      "[EPOCH #8, step #2252] loss: 2.6282035343074504\n",
      "[EPOCH #8, step #2254] loss: 2.6284902710608\n",
      "[EPOCH #8, step #2256] loss: 2.6283991637354567\n",
      "[EPOCH #8, step #2258] loss: 2.628428187556054\n",
      "[EPOCH #8, step #2260] loss: 2.6282665199645057\n",
      "[EPOCH #8, step #2262] loss: 2.6280737005921524\n",
      "[EPOCH #8, step #2264] loss: 2.628090777355051\n",
      "[EPOCH #8, step #2266] loss: 2.627959865644528\n",
      "[EPOCH #8, step #2268] loss: 2.62769931594198\n",
      "[EPOCH #8, step #2270] loss: 2.6275726081200603\n",
      "[EPOCH #8, step #2272] loss: 2.6273459959177\n",
      "[EPOCH #8, step #2274] loss: 2.6271817457806934\n",
      "[EPOCH #8, step #2276] loss: 2.6273996967153166\n",
      "[EPOCH #8, step #2278] loss: 2.62737657459957\n",
      "[EPOCH #8, step #2280] loss: 2.6273262195553713\n",
      "[EPOCH #8, step #2282] loss: 2.6272600972229485\n",
      "[EPOCH #8, step #2284] loss: 2.627255613276943\n",
      "[EPOCH #8, step #2286] loss: 2.6271567949312558\n",
      "[EPOCH #8, step #2288] loss: 2.627036852105417\n",
      "[EPOCH #8, step #2290] loss: 2.6271019191109213\n",
      "[EPOCH #8, step #2292] loss: 2.6271683663402747\n",
      "[EPOCH #8, step #2294] loss: 2.627048354886456\n",
      "[EPOCH #8, step #2296] loss: 2.627191895342517\n",
      "[EPOCH #8, step #2298] loss: 2.627326454168405\n",
      "[EPOCH #8, step #2300] loss: 2.6274252812378514\n",
      "[EPOCH #8, step #2302] loss: 2.6275954921505424\n",
      "[EPOCH #8, step #2304] loss: 2.6276658818416636\n",
      "[EPOCH #8, step #2306] loss: 2.6275660252746795\n",
      "[EPOCH #8, step #2308] loss: 2.6272648714899036\n",
      "[EPOCH #8, step #2310] loss: 2.6269956991714816\n",
      "[EPOCH #8, step #2312] loss: 2.626863256760402\n",
      "[EPOCH #8, step #2314] loss: 2.626902020621248\n",
      "[EPOCH #8, step #2316] loss: 2.626887199741836\n",
      "[EPOCH #8, step #2318] loss: 2.626832865702278\n",
      "[EPOCH #8, step #2320] loss: 2.6265788572402617\n",
      "[EPOCH #8, step #2322] loss: 2.626382292420301\n",
      "[EPOCH #8, step #2324] loss: 2.6263290514997255\n",
      "[EPOCH #8, step #2326] loss: 2.6265005003909057\n",
      "[EPOCH #8, step #2328] loss: 2.6266725014186614\n",
      "[EPOCH #8, step #2330] loss: 2.6267127440447258\n",
      "[EPOCH #8, step #2332] loss: 2.6267283221349866\n",
      "[EPOCH #8, step #2334] loss: 2.626936165934201\n",
      "[EPOCH #8, step #2336] loss: 2.6269298023171643\n",
      "[EPOCH #8, step #2338] loss: 2.6270289212121267\n",
      "[EPOCH #8, step #2340] loss: 2.626900734019453\n",
      "[EPOCH #8, step #2342] loss: 2.6267523202843206\n",
      "[EPOCH #8, step #2344] loss: 2.62694029960551\n",
      "[EPOCH #8, step #2346] loss: 2.6268720814762188\n",
      "[EPOCH #8, step #2348] loss: 2.6268846994767854\n",
      "[EPOCH #8, step #2350] loss: 2.62701923377663\n",
      "[EPOCH #8, step #2352] loss: 2.6268630444218237\n",
      "[EPOCH #8, step #2354] loss: 2.6267348441348712\n",
      "[EPOCH #8, step #2356] loss: 2.6266568184505847\n",
      "[EPOCH #8, step #2358] loss: 2.626724156549089\n",
      "[EPOCH #8, step #2360] loss: 2.6267805935618536\n",
      "[EPOCH #8, step #2362] loss: 2.626499294326611\n",
      "[EPOCH #8, step #2364] loss: 2.626590232919689\n",
      "[EPOCH #8, step #2366] loss: 2.6264129323097136\n",
      "[EPOCH #8, step #2368] loss: 2.6263352597298226\n",
      "[EPOCH #8, step #2370] loss: 2.626276257419224\n",
      "[EPOCH #8, step #2372] loss: 2.6259641841248627\n",
      "[EPOCH #8, step #2374] loss: 2.6261305165541797\n",
      "[EPOCH #8, step #2376] loss: 2.626256466212772\n",
      "[EPOCH #8, step #2378] loss: 2.6262648946450207\n",
      "[EPOCH #8, step #2380] loss: 2.626369832794689\n",
      "[EPOCH #8, step #2382] loss: 2.6262731207952847\n",
      "[EPOCH #8, step #2384] loss: 2.6261771515980206\n",
      "[EPOCH #8, step #2386] loss: 2.625994019993789\n",
      "[EPOCH #8, step #2388] loss: 2.626074728480739\n",
      "[EPOCH #8, step #2390] loss: 2.626037378682097\n",
      "[EPOCH #8, step #2392] loss: 2.6261073218894415\n",
      "[EPOCH #8, step #2394] loss: 2.6260097096508876\n",
      "[EPOCH #8, step #2396] loss: 2.625832608902907\n",
      "[EPOCH #8, step #2398] loss: 2.6256223729671464\n",
      "[EPOCH #8, step #2400] loss: 2.6256269634092715\n",
      "[EPOCH #8, step #2402] loss: 2.625632194792088\n",
      "[EPOCH #8, step #2404] loss: 2.6252104184731624\n",
      "[EPOCH #8, step #2406] loss: 2.62481757913034\n",
      "[EPOCH #8, step #2408] loss: 2.6246285552847874\n",
      "[EPOCH #8, step #2410] loss: 2.6247277844748225\n",
      "[EPOCH #8, step #2412] loss: 2.6251146085421375\n",
      "[EPOCH #8, step #2414] loss: 2.6252245565872507\n",
      "[EPOCH #8, step #2416] loss: 2.6253063609198595\n",
      "[EPOCH #8, step #2418] loss: 2.6250747034203763\n",
      "[EPOCH #8, step #2420] loss: 2.6249663833250243\n",
      "[EPOCH #8, step #2422] loss: 2.6251070469408746\n",
      "[EPOCH #8, step #2424] loss: 2.6252207275764228\n",
      "[EPOCH #8, step #2426] loss: 2.625273965197824\n",
      "[EPOCH #8, step #2428] loss: 2.6252088234129145\n",
      "[EPOCH #8, step #2430] loss: 2.6251389449243927\n",
      "[EPOCH #8, step #2432] loss: 2.6248713944411994\n",
      "[EPOCH #8, step #2434] loss: 2.6249167223485834\n",
      "[EPOCH #8, step #2436] loss: 2.6247226236587573\n",
      "[EPOCH #8, step #2438] loss: 2.6247450273610764\n",
      "[EPOCH #8, step #2440] loss: 2.6249008755467065\n",
      "[EPOCH #8, step #2442] loss: 2.6248192519278883\n",
      "[EPOCH #8, step #2444] loss: 2.6246775342886677\n",
      "[EPOCH #8, step #2446] loss: 2.624467149723974\n",
      "[EPOCH #8, step #2448] loss: 2.624401238802843\n",
      "[EPOCH #8, step #2450] loss: 2.624413667674553\n",
      "[EPOCH #8, step #2452] loss: 2.624487424402202\n",
      "[EPOCH #8, step #2454] loss: 2.624543305909804\n",
      "[EPOCH #8, step #2456] loss: 2.6247025175117895\n",
      "[EPOCH #8, step #2458] loss: 2.6245299440033314\n",
      "[EPOCH #8, step #2460] loss: 2.624614840598186\n",
      "[EPOCH #8, step #2462] loss: 2.6249978865156125\n",
      "[EPOCH #8, step #2464] loss: 2.6250503152669324\n",
      "[EPOCH #8, step #2466] loss: 2.624708613790768\n",
      "[EPOCH #8, step #2468] loss: 2.624710503016565\n",
      "[EPOCH #8, step #2470] loss: 2.6248356975171787\n",
      "[EPOCH #8, step #2472] loss: 2.6246976549211802\n",
      "[EPOCH #8, step #2474] loss: 2.625009737737251\n",
      "[EPOCH #8, step #2476] loss: 2.625137629170162\n",
      "[EPOCH #8, step #2478] loss: 2.6249235013455525\n",
      "[EPOCH #8, step #2480] loss: 2.6250591387147146\n",
      "[EPOCH #8, step #2482] loss: 2.6251033585829164\n",
      "[EPOCH #8, step #2484] loss: 2.6246333404805817\n",
      "[EPOCH #8, step #2486] loss: 2.624731101182555\n",
      "[EPOCH #8, step #2488] loss: 2.624527832119759\n",
      "[EPOCH #8, step #2490] loss: 2.624480643601649\n",
      "[EPOCH #8, step #2492] loss: 2.6245264900385785\n",
      "[EPOCH #8, step #2494] loss: 2.6241679544678194\n",
      "[EPOCH #8, step #2496] loss: 2.6242295453010867\n",
      "[EPOCH #8, step #2498] loss: 2.6241742060536524\n",
      "[EPOCH #8, elapsed time: 4106.564[sec]] loss: 2.624008395528793\n",
      "[EPOCH #9, step #0] loss: 2.2485511302948\n",
      "[EPOCH #9, step #2] loss: 2.4652864138285318\n",
      "[EPOCH #9, step #4] loss: 2.532258081436157\n",
      "[EPOCH #9, step #6] loss: 2.5389940398080006\n",
      "[EPOCH #9, step #8] loss: 2.5492442184024386\n",
      "[EPOCH #9, step #10] loss: 2.5783722400665283\n",
      "[EPOCH #9, step #12] loss: 2.5867785673875074\n",
      "[EPOCH #9, step #14] loss: 2.5949029445648195\n",
      "[EPOCH #9, step #16] loss: 2.585659980773926\n",
      "[EPOCH #9, step #18] loss: 2.6022118016293176\n",
      "[EPOCH #9, step #20] loss: 2.5973359176090787\n",
      "[EPOCH #9, step #22] loss: 2.5715604968692944\n",
      "[EPOCH #9, step #24] loss: 2.551928930282593\n",
      "[EPOCH #9, step #26] loss: 2.558262330514413\n",
      "[EPOCH #9, step #28] loss: 2.565936696940455\n",
      "[EPOCH #9, step #30] loss: 2.5752515408300583\n",
      "[EPOCH #9, step #32] loss: 2.5990124543507895\n",
      "[EPOCH #9, step #34] loss: 2.5982353823525566\n",
      "[EPOCH #9, step #36] loss: 2.5949332134143726\n",
      "[EPOCH #9, step #38] loss: 2.617021713501368\n",
      "[EPOCH #9, step #40] loss: 2.620604701158477\n",
      "[EPOCH #9, step #42] loss: 2.627744142399278\n",
      "[EPOCH #9, step #44] loss: 2.6181347423129613\n",
      "[EPOCH #9, step #46] loss: 2.6147208010896725\n",
      "[EPOCH #9, step #48] loss: 2.6252291689113694\n",
      "[EPOCH #9, step #50] loss: 2.6213925960017184\n",
      "[EPOCH #9, step #52] loss: 2.61444180416611\n",
      "[EPOCH #9, step #54] loss: 2.61869611306624\n",
      "[EPOCH #9, step #56] loss: 2.6276288701776873\n",
      "[EPOCH #9, step #58] loss: 2.611031976796813\n",
      "[EPOCH #9, step #60] loss: 2.602902783722174\n",
      "[EPOCH #9, step #62] loss: 2.6012068513839965\n",
      "[EPOCH #9, step #64] loss: 2.595034305865948\n",
      "[EPOCH #9, step #66] loss: 2.588348420698251\n",
      "[EPOCH #9, step #68] loss: 2.5826916418213774\n",
      "[EPOCH #9, step #70] loss: 2.5758367491440035\n",
      "[EPOCH #9, step #72] loss: 2.565864094316143\n",
      "[EPOCH #9, step #74] loss: 2.562981925010681\n",
      "[EPOCH #9, step #76] loss: 2.557022731025498\n",
      "[EPOCH #9, step #78] loss: 2.557915652854533\n",
      "[EPOCH #9, step #80] loss: 2.5544769366582236\n",
      "[EPOCH #9, step #82] loss: 2.5505204330007714\n",
      "[EPOCH #9, step #84] loss: 2.546647140559028\n",
      "[EPOCH #9, step #86] loss: 2.5508102041551437\n",
      "[EPOCH #9, step #88] loss: 2.5510768448368886\n",
      "[EPOCH #9, step #90] loss: 2.560945729632954\n",
      "[EPOCH #9, step #92] loss: 2.5589283756030503\n",
      "[EPOCH #9, step #94] loss: 2.5567498922348024\n",
      "[EPOCH #9, step #96] loss: 2.5523769916947354\n",
      "[EPOCH #9, step #98] loss: 2.552605577189513\n",
      "[EPOCH #9, step #100] loss: 2.5476176184002717\n",
      "[EPOCH #9, step #102] loss: 2.549116837168203\n",
      "[EPOCH #9, step #104] loss: 2.5476713441667105\n",
      "[EPOCH #9, step #106] loss: 2.548657215644266\n",
      "[EPOCH #9, step #108] loss: 2.5499755625331075\n",
      "[EPOCH #9, step #110] loss: 2.547143597860594\n",
      "[EPOCH #9, step #112] loss: 2.5476076951069113\n",
      "[EPOCH #9, step #114] loss: 2.551237922129424\n",
      "[EPOCH #9, step #116] loss: 2.545998531529027\n",
      "[EPOCH #9, step #118] loss: 2.5499409096581593\n",
      "[EPOCH #9, step #120] loss: 2.5472719994458286\n",
      "[EPOCH #9, step #122] loss: 2.5445767001407904\n",
      "[EPOCH #9, step #124] loss: 2.54307103061676\n",
      "[EPOCH #9, step #126] loss: 2.5411980912441345\n",
      "[EPOCH #9, step #128] loss: 2.541526142940965\n",
      "[EPOCH #9, step #130] loss: 2.5447531356156325\n",
      "[EPOCH #9, step #132] loss: 2.5435273136411394\n",
      "[EPOCH #9, step #134] loss: 2.542493639168916\n",
      "[EPOCH #9, step #136] loss: 2.5416923343700213\n",
      "[EPOCH #9, step #138] loss: 2.5443805027351103\n",
      "[EPOCH #9, step #140] loss: 2.543726974345268\n",
      "[EPOCH #9, step #142] loss: 2.541857998687904\n",
      "[EPOCH #9, step #144] loss: 2.5458289335513937\n",
      "[EPOCH #9, step #146] loss: 2.544479740720217\n",
      "[EPOCH #9, step #148] loss: 2.544891427027299\n",
      "[EPOCH #9, step #150] loss: 2.547538036542223\n",
      "[EPOCH #9, step #152] loss: 2.5474335656446567\n",
      "[EPOCH #9, step #154] loss: 2.5440658469353954\n",
      "[EPOCH #9, step #156] loss: 2.5441302471100147\n",
      "[EPOCH #9, step #158] loss: 2.542658986535462\n",
      "[EPOCH #9, step #160] loss: 2.542302043541618\n",
      "[EPOCH #9, step #162] loss: 2.540573760044355\n",
      "[EPOCH #9, step #164] loss: 2.541630265929482\n",
      "[EPOCH #9, step #166] loss: 2.540973682603436\n",
      "[EPOCH #9, step #168] loss: 2.5433355696807953\n",
      "[EPOCH #9, step #170] loss: 2.5452513520480595\n",
      "[EPOCH #9, step #172] loss: 2.5465932739952395\n",
      "[EPOCH #9, step #174] loss: 2.5472996595927646\n",
      "[EPOCH #9, step #176] loss: 2.5441177598500655\n",
      "[EPOCH #9, step #178] loss: 2.5424204851661982\n",
      "[EPOCH #9, step #180] loss: 2.542412285646681\n",
      "[EPOCH #9, step #182] loss: 2.540267246668456\n",
      "[EPOCH #9, step #184] loss: 2.540126999648842\n",
      "[EPOCH #9, step #186] loss: 2.5402468417417556\n",
      "[EPOCH #9, step #188] loss: 2.5407863350772355\n",
      "[EPOCH #9, step #190] loss: 2.5374175584753145\n",
      "[EPOCH #9, step #192] loss: 2.535621488032563\n",
      "[EPOCH #9, step #194] loss: 2.5335635252487965\n",
      "[EPOCH #9, step #196] loss: 2.5316137256961184\n",
      "[EPOCH #9, step #198] loss: 2.5366169513769483\n",
      "[EPOCH #9, step #200] loss: 2.539281699787918\n",
      "[EPOCH #9, step #202] loss: 2.539166310150635\n",
      "[EPOCH #9, step #204] loss: 2.536778255206783\n",
      "[EPOCH #9, step #206] loss: 2.538282389226167\n",
      "[EPOCH #9, step #208] loss: 2.5391088073903862\n",
      "[EPOCH #9, step #210] loss: 2.538364910401439\n",
      "[EPOCH #9, step #212] loss: 2.5414997104188086\n",
      "[EPOCH #9, step #214] loss: 2.540986763599307\n",
      "[EPOCH #9, step #216] loss: 2.5375006654844854\n",
      "[EPOCH #9, step #218] loss: 2.537253116908139\n",
      "[EPOCH #9, step #220] loss: 2.5355193577201116\n",
      "[EPOCH #9, step #222] loss: 2.533305825139375\n",
      "[EPOCH #9, step #224] loss: 2.5350548961427477\n",
      "[EPOCH #9, step #226] loss: 2.5376395648796652\n",
      "[EPOCH #9, step #228] loss: 2.5368925468369863\n",
      "[EPOCH #9, step #230] loss: 2.5401824805643654\n",
      "[EPOCH #9, step #232] loss: 2.5413654704973934\n",
      "[EPOCH #9, step #234] loss: 2.5405478644878308\n",
      "[EPOCH #9, step #236] loss: 2.5413722866195165\n",
      "[EPOCH #9, step #238] loss: 2.5405273582147254\n",
      "[EPOCH #9, step #240] loss: 2.5404580544633983\n",
      "[EPOCH #9, step #242] loss: 2.5401971394142495\n",
      "[EPOCH #9, step #244] loss: 2.5413049128590797\n",
      "[EPOCH #9, step #246] loss: 2.54176711601767\n",
      "[EPOCH #9, step #248] loss: 2.5451975026762628\n",
      "[EPOCH #9, step #250] loss: 2.545433117099017\n",
      "[EPOCH #9, step #252] loss: 2.545309382936229\n",
      "[EPOCH #9, step #254] loss: 2.5442747924842086\n",
      "[EPOCH #9, step #256] loss: 2.542970308070053\n",
      "[EPOCH #9, step #258] loss: 2.5422255739742265\n",
      "[EPOCH #9, step #260] loss: 2.5440850198497262\n",
      "[EPOCH #9, step #262] loss: 2.5439502000808716\n",
      "[EPOCH #9, step #264] loss: 2.541798484100486\n",
      "[EPOCH #9, step #266] loss: 2.540640911805942\n",
      "[EPOCH #9, step #268] loss: 2.5408453289904114\n",
      "[EPOCH #9, step #270] loss: 2.539554151221835\n",
      "[EPOCH #9, step #272] loss: 2.5388079427537464\n",
      "[EPOCH #9, step #274] loss: 2.539251080859791\n",
      "[EPOCH #9, step #276] loss: 2.5400748050600184\n",
      "[EPOCH #9, step #278] loss: 2.539854470546955\n",
      "[EPOCH #9, step #280] loss: 2.539794348737099\n",
      "[EPOCH #9, step #282] loss: 2.538561795288598\n",
      "[EPOCH #9, step #284] loss: 2.5389163381174993\n",
      "[EPOCH #9, step #286] loss: 2.5365761202802224\n",
      "[EPOCH #9, step #288] loss: 2.534710278973035\n",
      "[EPOCH #9, step #290] loss: 2.5346915603093674\n",
      "[EPOCH #9, step #292] loss: 2.531560836798502\n",
      "[EPOCH #9, step #294] loss: 2.5297393107818347\n",
      "[EPOCH #9, step #296] loss: 2.5288789396735556\n",
      "[EPOCH #9, step #298] loss: 2.5267777351232676\n",
      "[EPOCH #9, step #300] loss: 2.5277182426167486\n",
      "[EPOCH #9, step #302] loss: 2.5260219050712713\n",
      "[EPOCH #9, step #304] loss: 2.5265921698241938\n",
      "[EPOCH #9, step #306] loss: 2.5259854230507965\n",
      "[EPOCH #9, step #308] loss: 2.523380916481265\n",
      "[EPOCH #9, step #310] loss: 2.5221948535496015\n",
      "[EPOCH #9, step #312] loss: 2.523556114004824\n",
      "[EPOCH #9, step #314] loss: 2.5240102847417196\n",
      "[EPOCH #9, step #316] loss: 2.522547729007829\n",
      "[EPOCH #9, step #318] loss: 2.523116879702362\n",
      "[EPOCH #9, step #320] loss: 2.523209758636736\n",
      "[EPOCH #9, step #322] loss: 2.523350384582307\n",
      "[EPOCH #9, step #324] loss: 2.523792448410621\n",
      "[EPOCH #9, step #326] loss: 2.5220317734855393\n",
      "[EPOCH #9, step #328] loss: 2.5235956428985826\n",
      "[EPOCH #9, step #330] loss: 2.5221209947436236\n",
      "[EPOCH #9, step #332] loss: 2.5212955571509696\n",
      "[EPOCH #9, step #334] loss: 2.5218856138969534\n",
      "[EPOCH #9, step #336] loss: 2.5199064645993605\n",
      "[EPOCH #9, step #338] loss: 2.518326361270781\n",
      "[EPOCH #9, step #340] loss: 2.519162973001206\n",
      "[EPOCH #9, step #342] loss: 2.5182772245768557\n",
      "[EPOCH #9, step #344] loss: 2.516286984733913\n",
      "[EPOCH #9, step #346] loss: 2.516599835854786\n",
      "[EPOCH #9, step #348] loss: 2.5155494349733805\n",
      "[EPOCH #9, step #350] loss: 2.5164105022734726\n",
      "[EPOCH #9, step #352] loss: 2.5151339901067717\n",
      "[EPOCH #9, step #354] loss: 2.512355925331653\n",
      "[EPOCH #9, step #356] loss: 2.5129728150300954\n",
      "[EPOCH #9, step #358] loss: 2.5123005205542266\n",
      "[EPOCH #9, step #360] loss: 2.511618548813289\n",
      "[EPOCH #9, step #362] loss: 2.5113432269451046\n",
      "[EPOCH #9, step #364] loss: 2.5126385721441817\n",
      "[EPOCH #9, step #366] loss: 2.512142170352572\n",
      "[EPOCH #9, step #368] loss: 2.510662181590631\n",
      "[EPOCH #9, step #370] loss: 2.511262229189397\n",
      "[EPOCH #9, step #372] loss: 2.509974744939932\n",
      "[EPOCH #9, step #374] loss: 2.51114710299174\n",
      "[EPOCH #9, step #376] loss: 2.509718246105811\n",
      "[EPOCH #9, step #378] loss: 2.510946710380212\n",
      "[EPOCH #9, step #380] loss: 2.5111144296140497\n",
      "[EPOCH #9, step #382] loss: 2.5105058399877724\n",
      "[EPOCH #9, step #384] loss: 2.5106037579573592\n",
      "[EPOCH #9, step #386] loss: 2.5120670314907105\n",
      "[EPOCH #9, step #388] loss: 2.5136636590589903\n",
      "[EPOCH #9, step #390] loss: 2.514824029429794\n",
      "[EPOCH #9, step #392] loss: 2.514241463658767\n",
      "[EPOCH #9, step #394] loss: 2.513758905024468\n",
      "[EPOCH #9, step #396] loss: 2.5136886687963376\n",
      "[EPOCH #9, step #398] loss: 2.512024920685847\n",
      "[EPOCH #9, step #400] loss: 2.512328316148677\n",
      "[EPOCH #9, step #402] loss: 2.5106594609859267\n",
      "[EPOCH #9, step #404] loss: 2.5100362924881923\n",
      "[EPOCH #9, step #406] loss: 2.509433434694932\n",
      "[EPOCH #9, step #408] loss: 2.509614556809218\n",
      "[EPOCH #9, step #410] loss: 2.5088666720982014\n",
      "[EPOCH #9, step #412] loss: 2.509604773278964\n",
      "[EPOCH #9, step #414] loss: 2.5090993364173246\n",
      "[EPOCH #9, step #416] loss: 2.510056492236021\n",
      "[EPOCH #9, step #418] loss: 2.5095128438353256\n",
      "[EPOCH #9, step #420] loss: 2.508672253253058\n",
      "[EPOCH #9, step #422] loss: 2.508564021288644\n",
      "[EPOCH #9, step #424] loss: 2.508498640060425\n",
      "[EPOCH #9, step #426] loss: 2.5089834021181914\n",
      "[EPOCH #9, step #428] loss: 2.509788486507389\n",
      "[EPOCH #9, step #430] loss: 2.50998579266453\n",
      "[EPOCH #9, step #432] loss: 2.5106757458032694\n",
      "[EPOCH #9, step #434] loss: 2.512250799420236\n",
      "[EPOCH #9, step #436] loss: 2.5125829895246494\n",
      "[EPOCH #9, step #438] loss: 2.511871529059964\n",
      "[EPOCH #9, step #440] loss: 2.5127286689351744\n",
      "[EPOCH #9, step #442] loss: 2.512605758606715\n",
      "[EPOCH #9, step #444] loss: 2.5130400620149764\n",
      "[EPOCH #9, step #446] loss: 2.5129744974558785\n",
      "[EPOCH #9, step #448] loss: 2.511740910714878\n",
      "[EPOCH #9, step #450] loss: 2.5137717945877043\n",
      "[EPOCH #9, step #452] loss: 2.513202771445773\n",
      "[EPOCH #9, step #454] loss: 2.5129536020886767\n",
      "[EPOCH #9, step #456] loss: 2.5142076140681295\n",
      "[EPOCH #9, step #458] loss: 2.5159347197588753\n",
      "[EPOCH #9, step #460] loss: 2.5159081797279144\n",
      "[EPOCH #9, step #462] loss: 2.515880966289512\n",
      "[EPOCH #9, step #464] loss: 2.515766590385027\n",
      "[EPOCH #9, step #466] loss: 2.515217420631098\n",
      "[EPOCH #9, step #468] loss: 2.5157040751564987\n",
      "[EPOCH #9, step #470] loss: 2.5168539161641634\n",
      "[EPOCH #9, step #472] loss: 2.516538236408355\n",
      "[EPOCH #9, step #474] loss: 2.516756739365427\n",
      "[EPOCH #9, step #476] loss: 2.5161806122561923\n",
      "[EPOCH #9, step #478] loss: 2.5159622169486666\n",
      "[EPOCH #9, step #480] loss: 2.5163700109707836\n",
      "[EPOCH #9, step #482] loss: 2.5152775831597687\n",
      "[EPOCH #9, step #484] loss: 2.5151296532031187\n",
      "[EPOCH #9, step #486] loss: 2.5146894983687194\n",
      "[EPOCH #9, step #488] loss: 2.515538271707016\n",
      "[EPOCH #9, step #490] loss: 2.5155023936098804\n",
      "[EPOCH #9, step #492] loss: 2.515672650830499\n",
      "[EPOCH #9, step #494] loss: 2.514573689422222\n",
      "[EPOCH #9, step #496] loss: 2.513450584900931\n",
      "[EPOCH #9, step #498] loss: 2.514667161480936\n",
      "[EPOCH #9, step #500] loss: 2.5154404818654776\n",
      "[EPOCH #9, step #502] loss: 2.516560415387391\n",
      "[EPOCH #9, step #504] loss: 2.515704063613816\n",
      "[EPOCH #9, step #506] loss: 2.5159127122081477\n",
      "[EPOCH #9, step #508] loss: 2.5150459053942638\n",
      "[EPOCH #9, step #510] loss: 2.5166262126948737\n",
      "[EPOCH #9, step #512] loss: 2.514843658861826\n",
      "[EPOCH #9, step #514] loss: 2.514921459873903\n",
      "[EPOCH #9, step #516] loss: 2.5151544491142555\n",
      "[EPOCH #9, step #518] loss: 2.515445543621776\n",
      "[EPOCH #9, step #520] loss: 2.516488115755473\n",
      "[EPOCH #9, step #522] loss: 2.515549861450268\n",
      "[EPOCH #9, step #524] loss: 2.5162511682510376\n",
      "[EPOCH #9, step #526] loss: 2.516286123635873\n",
      "[EPOCH #9, step #528] loss: 2.5164263750970477\n",
      "[EPOCH #9, step #530] loss: 2.5161429342801513\n",
      "[EPOCH #9, step #532] loss: 2.515303728280774\n",
      "[EPOCH #9, step #534] loss: 2.5157037309397046\n",
      "[EPOCH #9, step #536] loss: 2.515201907584121\n",
      "[EPOCH #9, step #538] loss: 2.514577259822768\n",
      "[EPOCH #9, step #540] loss: 2.514781164594146\n",
      "[EPOCH #9, step #542] loss: 2.513141966875965\n",
      "[EPOCH #9, step #544] loss: 2.5144556874528936\n",
      "[EPOCH #9, step #546] loss: 2.51616712483889\n",
      "[EPOCH #9, step #548] loss: 2.516121467605966\n",
      "[EPOCH #9, step #550] loss: 2.515714099099978\n",
      "[EPOCH #9, step #552] loss: 2.515322650535197\n",
      "[EPOCH #9, step #554] loss: 2.515826343201302\n",
      "[EPOCH #9, step #556] loss: 2.516281759075459\n",
      "[EPOCH #9, step #558] loss: 2.5166826386784398\n",
      "[EPOCH #9, step #560] loss: 2.5172786153786535\n",
      "[EPOCH #9, step #562] loss: 2.5174189979610815\n",
      "[EPOCH #9, step #564] loss: 2.5179040885604587\n",
      "[EPOCH #9, step #566] loss: 2.518281478099722\n",
      "[EPOCH #9, step #568] loss: 2.519031126805056\n",
      "[EPOCH #9, step #570] loss: 2.5192529297125525\n",
      "[EPOCH #9, step #572] loss: 2.519961894494701\n",
      "[EPOCH #9, step #574] loss: 2.519590744557588\n",
      "[EPOCH #9, step #576] loss: 2.5199429416573853\n",
      "[EPOCH #9, step #578] loss: 2.519648504380735\n",
      "[EPOCH #9, step #580] loss: 2.519290904990572\n",
      "[EPOCH #9, step #582] loss: 2.5186995468254154\n",
      "[EPOCH #9, step #584] loss: 2.517947735134353\n",
      "[EPOCH #9, step #586] loss: 2.51821936760891\n",
      "[EPOCH #9, step #588] loss: 2.5188001365936876\n",
      "[EPOCH #9, step #590] loss: 2.5181157143184576\n",
      "[EPOCH #9, step #592] loss: 2.5184194231515793\n",
      "[EPOCH #9, step #594] loss: 2.518528062956674\n",
      "[EPOCH #9, step #596] loss: 2.5177441000738736\n",
      "[EPOCH #9, step #598] loss: 2.518054818669225\n",
      "[EPOCH #9, step #600] loss: 2.51861909641799\n",
      "[EPOCH #9, step #602] loss: 2.5177507058502626\n",
      "[EPOCH #9, step #604] loss: 2.5179897192095924\n",
      "[EPOCH #9, step #606] loss: 2.517919126609601\n",
      "[EPOCH #9, step #608] loss: 2.5179280927420056\n",
      "[EPOCH #9, step #610] loss: 2.517690661105704\n",
      "[EPOCH #9, step #612] loss: 2.51768124998102\n",
      "[EPOCH #9, step #614] loss: 2.5183407533459548\n",
      "[EPOCH #9, step #616] loss: 2.5178344267114054\n",
      "[EPOCH #9, step #618] loss: 2.5177916765983346\n",
      "[EPOCH #9, step #620] loss: 2.518099794641209\n",
      "[EPOCH #9, step #622] loss: 2.5179659652480346\n",
      "[EPOCH #9, step #624] loss: 2.516850124168396\n",
      "[EPOCH #9, step #626] loss: 2.516391171793048\n",
      "[EPOCH #9, step #628] loss: 2.5157956561526738\n",
      "[EPOCH #9, step #630] loss: 2.515488877727188\n",
      "[EPOCH #9, step #632] loss: 2.515740738472479\n",
      "[EPOCH #9, step #634] loss: 2.5155638112796574\n",
      "[EPOCH #9, step #636] loss: 2.5151698746524014\n",
      "[EPOCH #9, step #638] loss: 2.5160171429689315\n",
      "[EPOCH #9, step #640] loss: 2.5159440367902497\n",
      "[EPOCH #9, step #642] loss: 2.515192286037546\n",
      "[EPOCH #9, step #644] loss: 2.51451898304991\n",
      "[EPOCH #9, step #646] loss: 2.514883833838025\n",
      "[EPOCH #9, step #648] loss: 2.5144840445834427\n",
      "[EPOCH #9, step #650] loss: 2.5143632158156364\n",
      "[EPOCH #9, step #652] loss: 2.5136732399737487\n",
      "[EPOCH #9, step #654] loss: 2.5136712454657517\n",
      "[EPOCH #9, step #656] loss: 2.514156713696194\n",
      "[EPOCH #9, step #658] loss: 2.5142091917883103\n",
      "[EPOCH #9, step #660] loss: 2.5141457607814655\n",
      "[EPOCH #9, step #662] loss: 2.514176729218093\n",
      "[EPOCH #9, step #664] loss: 2.5134075338679147\n",
      "[EPOCH #9, step #666] loss: 2.5127630932577727\n",
      "[EPOCH #9, step #668] loss: 2.513945101087938\n",
      "[EPOCH #9, step #670] loss: 2.513203244450906\n",
      "[EPOCH #9, step #672] loss: 2.5136842878222643\n",
      "[EPOCH #9, step #674] loss: 2.513775809076097\n",
      "[EPOCH #9, step #676] loss: 2.5145439134918957\n",
      "[EPOCH #9, step #678] loss: 2.5146970178311983\n",
      "[EPOCH #9, step #680] loss: 2.5152203100193264\n",
      "[EPOCH #9, step #682] loss: 2.5157937317606645\n",
      "[EPOCH #9, step #684] loss: 2.515990119606909\n",
      "[EPOCH #9, step #686] loss: 2.516128689788141\n",
      "[EPOCH #9, step #688] loss: 2.5151665710745426\n",
      "[EPOCH #9, step #690] loss: 2.515053229290566\n",
      "[EPOCH #9, step #692] loss: 2.514931667246688\n",
      "[EPOCH #9, step #694] loss: 2.5149422733046167\n",
      "[EPOCH #9, step #696] loss: 2.5152787322464425\n",
      "[EPOCH #9, step #698] loss: 2.5154552829794277\n",
      "[EPOCH #9, step #700] loss: 2.5153487805122996\n",
      "[EPOCH #9, step #702] loss: 2.5157944788125635\n",
      "[EPOCH #9, step #704] loss: 2.51546800542385\n",
      "[EPOCH #9, step #706] loss: 2.5151930966505405\n",
      "[EPOCH #9, step #708] loss: 2.514874818294778\n",
      "[EPOCH #9, step #710] loss: 2.515652075263183\n",
      "[EPOCH #9, step #712] loss: 2.5154915278957737\n",
      "[EPOCH #9, step #714] loss: 2.5161495777276848\n",
      "[EPOCH #9, step #716] loss: 2.516812255193\n",
      "[EPOCH #9, step #718] loss: 2.517448449333785\n",
      "[EPOCH #9, step #720] loss: 2.5173492492815988\n",
      "[EPOCH #9, step #722] loss: 2.517031825099908\n",
      "[EPOCH #9, step #724] loss: 2.51742340893581\n",
      "[EPOCH #9, step #726] loss: 2.5165535929770386\n",
      "[EPOCH #9, step #728] loss: 2.516606214278683\n",
      "[EPOCH #9, step #730] loss: 2.515752908958456\n",
      "[EPOCH #9, step #732] loss: 2.5155640056643933\n",
      "[EPOCH #9, step #734] loss: 2.5153579642172574\n",
      "[EPOCH #9, step #736] loss: 2.5148749019915244\n",
      "[EPOCH #9, step #738] loss: 2.515354746410747\n",
      "[EPOCH #9, step #740] loss: 2.515880025028378\n",
      "[EPOCH #9, step #742] loss: 2.515420444079074\n",
      "[EPOCH #9, step #744] loss: 2.5162418674302582\n",
      "[EPOCH #9, step #746] loss: 2.516359711427446\n",
      "[EPOCH #9, step #748] loss: 2.517249898216594\n",
      "[EPOCH #9, step #750] loss: 2.5170483422501584\n",
      "[EPOCH #9, step #752] loss: 2.5170493748083533\n",
      "[EPOCH #9, step #754] loss: 2.516186233703664\n",
      "[EPOCH #9, step #756] loss: 2.517366970703498\n",
      "[EPOCH #9, step #758] loss: 2.5176104234926626\n",
      "[EPOCH #9, step #760] loss: 2.5181751296648685\n",
      "[EPOCH #9, step #762] loss: 2.517313148997246\n",
      "[EPOCH #9, step #764] loss: 2.5168624477448804\n",
      "[EPOCH #9, step #766] loss: 2.51730370443834\n",
      "[EPOCH #9, step #768] loss: 2.5169841125510604\n",
      "[EPOCH #9, step #770] loss: 2.5177730968180954\n",
      "[EPOCH #9, step #772] loss: 2.5175533431930344\n",
      "[EPOCH #9, step #774] loss: 2.51751772803645\n",
      "[EPOCH #9, step #776] loss: 2.516976371695176\n",
      "[EPOCH #9, step #778] loss: 2.516692111213645\n",
      "[EPOCH #9, step #780] loss: 2.51618796930423\n",
      "[EPOCH #9, step #782] loss: 2.5166159676409317\n",
      "[EPOCH #9, step #784] loss: 2.516973966398057\n",
      "[EPOCH #9, step #786] loss: 2.5172196614545364\n",
      "[EPOCH #9, step #788] loss: 2.5174262768415443\n",
      "[EPOCH #9, step #790] loss: 2.5179671933768524\n",
      "[EPOCH #9, step #792] loss: 2.5176257696308073\n",
      "[EPOCH #9, step #794] loss: 2.518108234465497\n",
      "[EPOCH #9, step #796] loss: 2.5179040198643206\n",
      "[EPOCH #9, step #798] loss: 2.517602274504412\n",
      "[EPOCH #9, step #800] loss: 2.5171918642803672\n",
      "[EPOCH #9, step #802] loss: 2.5168927864891804\n",
      "[EPOCH #9, step #804] loss: 2.5169778773503273\n",
      "[EPOCH #9, step #806] loss: 2.516713147712906\n",
      "[EPOCH #9, step #808] loss: 2.5175721447901025\n",
      "[EPOCH #9, step #810] loss: 2.517179907176703\n",
      "[EPOCH #9, step #812] loss: 2.5172524217603245\n",
      "[EPOCH #9, step #814] loss: 2.517263899551579\n",
      "[EPOCH #9, step #816] loss: 2.5170990303067566\n",
      "[EPOCH #9, step #818] loss: 2.51691930081527\n",
      "[EPOCH #9, step #820] loss: 2.51595052993254\n",
      "[EPOCH #9, step #822] loss: 2.5164176566053276\n",
      "[EPOCH #9, step #824] loss: 2.516670942017526\n",
      "[EPOCH #9, step #826] loss: 2.516854122154946\n",
      "[EPOCH #9, step #828] loss: 2.517205106622491\n",
      "[EPOCH #9, step #830] loss: 2.5169645841945094\n",
      "[EPOCH #9, step #832] loss: 2.5166519647028123\n",
      "[EPOCH #9, step #834] loss: 2.5165669355563773\n",
      "[EPOCH #9, step #836] loss: 2.5166336302261625\n",
      "[EPOCH #9, step #838] loss: 2.516926007844836\n",
      "[EPOCH #9, step #840] loss: 2.516476936204255\n",
      "[EPOCH #9, step #842] loss: 2.5162593206901143\n",
      "[EPOCH #9, step #844] loss: 2.515715104165162\n",
      "[EPOCH #9, step #846] loss: 2.5157664934043478\n",
      "[EPOCH #9, step #848] loss: 2.5161532428997564\n",
      "[EPOCH #9, step #850] loss: 2.5155562998685377\n",
      "[EPOCH #9, step #852] loss: 2.515655910843003\n",
      "[EPOCH #9, step #854] loss: 2.5159306654456066\n",
      "[EPOCH #9, step #856] loss: 2.514776184233373\n",
      "[EPOCH #9, step #858] loss: 2.51514620719883\n",
      "[EPOCH #9, step #860] loss: 2.515009914402624\n",
      "[EPOCH #9, step #862] loss: 2.514489450985145\n",
      "[EPOCH #9, step #864] loss: 2.5149722035909665\n",
      "[EPOCH #9, step #866] loss: 2.514968787097601\n",
      "[EPOCH #9, step #868] loss: 2.5145660700540136\n",
      "[EPOCH #9, step #870] loss: 2.514497008854705\n",
      "[EPOCH #9, step #872] loss: 2.5139155906773376\n",
      "[EPOCH #9, step #874] loss: 2.514032840183803\n",
      "[EPOCH #9, step #876] loss: 2.5139997769380784\n",
      "[EPOCH #9, step #878] loss: 2.514010854141704\n",
      "[EPOCH #9, step #880] loss: 2.5135280368817923\n",
      "[EPOCH #9, step #882] loss: 2.5130937947287295\n",
      "[EPOCH #9, step #884] loss: 2.513089890399222\n",
      "[EPOCH #9, step #886] loss: 2.5135570161103398\n",
      "[EPOCH #9, step #888] loss: 2.5128064362082894\n",
      "[EPOCH #9, step #890] loss: 2.5127674342539708\n",
      "[EPOCH #9, step #892] loss: 2.51218670666685\n",
      "[EPOCH #9, step #894] loss: 2.512273179219422\n",
      "[EPOCH #9, step #896] loss: 2.5120587657260787\n",
      "[EPOCH #9, step #898] loss: 2.511424221371915\n",
      "[EPOCH #9, step #900] loss: 2.511991493974489\n",
      "[EPOCH #9, step #902] loss: 2.5127354394293833\n",
      "[EPOCH #9, step #904] loss: 2.5130848673825765\n",
      "[EPOCH #9, step #906] loss: 2.51347175690673\n",
      "[EPOCH #9, step #908] loss: 2.5131880903925965\n",
      "[EPOCH #9, step #910] loss: 2.512662013720733\n",
      "[EPOCH #9, step #912] loss: 2.512724318352874\n",
      "[EPOCH #9, step #914] loss: 2.5116810381738213\n",
      "[EPOCH #9, step #916] loss: 2.5120894113309773\n",
      "[EPOCH #9, step #918] loss: 2.512045879488541\n",
      "[EPOCH #9, step #920] loss: 2.511899448502465\n",
      "[EPOCH #9, step #922] loss: 2.511438135981947\n",
      "[EPOCH #9, step #924] loss: 2.5110763279167383\n",
      "[EPOCH #9, step #926] loss: 2.5105297315982296\n",
      "[EPOCH #9, step #928] loss: 2.5107946562690038\n",
      "[EPOCH #9, step #930] loss: 2.5102969345293547\n",
      "[EPOCH #9, step #932] loss: 2.5105878910706614\n",
      "[EPOCH #9, step #934] loss: 2.5107152347258705\n",
      "[EPOCH #9, step #936] loss: 2.5101314141885194\n",
      "[EPOCH #9, step #938] loss: 2.5099660927495258\n",
      "[EPOCH #9, step #940] loss: 2.510187139799947\n",
      "[EPOCH #9, step #942] loss: 2.5102294587381064\n",
      "[EPOCH #9, step #944] loss: 2.51056940580802\n",
      "[EPOCH #9, step #946] loss: 2.510220347513241\n",
      "[EPOCH #9, step #948] loss: 2.509846706912942\n",
      "[EPOCH #9, step #950] loss: 2.5097749656933965\n",
      "[EPOCH #9, step #952] loss: 2.509938770176106\n",
      "[EPOCH #9, step #954] loss: 2.510594422405303\n",
      "[EPOCH #9, step #956] loss: 2.5097240401410508\n",
      "[EPOCH #9, step #958] loss: 2.5096509164515823\n",
      "[EPOCH #9, step #960] loss: 2.509796476140851\n",
      "[EPOCH #9, step #962] loss: 2.5093984023309077\n",
      "[EPOCH #9, step #964] loss: 2.509469365208878\n",
      "[EPOCH #9, step #966] loss: 2.509494614453202\n",
      "[EPOCH #9, step #968] loss: 2.5094255642010084\n",
      "[EPOCH #9, step #970] loss: 2.5091323595950583\n",
      "[EPOCH #9, step #972] loss: 2.508768491240224\n",
      "[EPOCH #9, step #974] loss: 2.5089332723617552\n",
      "[EPOCH #9, step #976] loss: 2.5088214328857625\n",
      "[EPOCH #9, step #978] loss: 2.5089145742957997\n",
      "[EPOCH #9, step #980] loss: 2.5085228953764953\n",
      "[EPOCH #9, step #982] loss: 2.5089910771330155\n",
      "[EPOCH #9, step #984] loss: 2.5086018120576887\n",
      "[EPOCH #9, step #986] loss: 2.5083134721477705\n",
      "[EPOCH #9, step #988] loss: 2.5073964703070986\n",
      "[EPOCH #9, step #990] loss: 2.5071750537658675\n",
      "[EPOCH #9, step #992] loss: 2.5073324403493906\n",
      "[EPOCH #9, step #994] loss: 2.5073093302884892\n",
      "[EPOCH #9, step #996] loss: 2.507893278103774\n",
      "[EPOCH #9, step #998] loss: 2.50856372746858\n",
      "[EPOCH #9, step #1000] loss: 2.50828091807656\n",
      "[EPOCH #9, step #1002] loss: 2.5087375841730255\n",
      "[EPOCH #9, step #1004] loss: 2.5092516653573336\n",
      "[EPOCH #9, step #1006] loss: 2.5095335761271973\n",
      "[EPOCH #9, step #1008] loss: 2.509756311434584\n",
      "[EPOCH #9, step #1010] loss: 2.510288341934438\n",
      "[EPOCH #9, step #1012] loss: 2.5107030923839617\n",
      "[EPOCH #9, step #1014] loss: 2.5103261812567124\n",
      "[EPOCH #9, step #1016] loss: 2.5103929873881907\n",
      "[EPOCH #9, step #1018] loss: 2.5104579641259805\n",
      "[EPOCH #9, step #1020] loss: 2.5107891628487686\n",
      "[EPOCH #9, step #1022] loss: 2.510895494491823\n",
      "[EPOCH #9, step #1024] loss: 2.5106754853085773\n",
      "[EPOCH #9, step #1026] loss: 2.5107394742408538\n",
      "[EPOCH #9, step #1028] loss: 2.5107149636432657\n",
      "[EPOCH #9, step #1030] loss: 2.5100043607382494\n",
      "[EPOCH #9, step #1032] loss: 2.5103794472492216\n",
      "[EPOCH #9, step #1034] loss: 2.5103978586657614\n",
      "[EPOCH #9, step #1036] loss: 2.5102188174496964\n",
      "[EPOCH #9, step #1038] loss: 2.5107269481010914\n",
      "[EPOCH #9, step #1040] loss: 2.5106102063264215\n",
      "[EPOCH #9, step #1042] loss: 2.5103753441703627\n",
      "[EPOCH #9, step #1044] loss: 2.5100053092509365\n",
      "[EPOCH #9, step #1046] loss: 2.50975658547457\n",
      "[EPOCH #9, step #1048] loss: 2.5093816990393245\n",
      "[EPOCH #9, step #1050] loss: 2.5098670527097955\n",
      "[EPOCH #9, step #1052] loss: 2.509915225299788\n",
      "[EPOCH #9, step #1054] loss: 2.509256018507537\n",
      "[EPOCH #9, step #1056] loss: 2.509673207462567\n",
      "[EPOCH #9, step #1058] loss: 2.510084891116653\n",
      "[EPOCH #9, step #1060] loss: 2.5098860272812913\n",
      "[EPOCH #9, step #1062] loss: 2.5096993367849154\n",
      "[EPOCH #9, step #1064] loss: 2.5094404753385016\n",
      "[EPOCH #9, step #1066] loss: 2.5099294464947914\n",
      "[EPOCH #9, step #1068] loss: 2.5099013003375177\n",
      "[EPOCH #9, step #1070] loss: 2.5100649193444062\n",
      "[EPOCH #9, step #1072] loss: 2.5098546835605164\n",
      "[EPOCH #9, step #1074] loss: 2.510181908053021\n",
      "[EPOCH #9, step #1076] loss: 2.5102837980070265\n",
      "[EPOCH #9, step #1078] loss: 2.509967303033003\n",
      "[EPOCH #9, step #1080] loss: 2.5099588748374324\n",
      "[EPOCH #9, step #1082] loss: 2.509152602290843\n",
      "[EPOCH #9, step #1084] loss: 2.5087306831289546\n",
      "[EPOCH #9, step #1086] loss: 2.508332978944331\n",
      "[EPOCH #9, step #1088] loss: 2.508085920572062\n",
      "[EPOCH #9, step #1090] loss: 2.50792969354897\n",
      "[EPOCH #9, step #1092] loss: 2.507800731109242\n",
      "[EPOCH #9, step #1094] loss: 2.507419467081218\n",
      "[EPOCH #9, step #1096] loss: 2.507555390882188\n",
      "[EPOCH #9, step #1098] loss: 2.507582281805148\n",
      "[EPOCH #9, step #1100] loss: 2.508369688333759\n",
      "[EPOCH #9, step #1102] loss: 2.5085407163701268\n",
      "[EPOCH #9, step #1104] loss: 2.5084928687341614\n",
      "[EPOCH #9, step #1106] loss: 2.509304269327165\n",
      "[EPOCH #9, step #1108] loss: 2.5093690886811375\n",
      "[EPOCH #9, step #1110] loss: 2.5092637090399714\n",
      "[EPOCH #9, step #1112] loss: 2.5092354542697106\n",
      "[EPOCH #9, step #1114] loss: 2.508885016462728\n",
      "[EPOCH #9, step #1116] loss: 2.508756976951524\n",
      "[EPOCH #9, step #1118] loss: 2.5089507663324544\n",
      "[EPOCH #9, step #1120] loss: 2.5088937282562256\n",
      "[EPOCH #9, step #1122] loss: 2.508568115777876\n",
      "[EPOCH #9, step #1124] loss: 2.5083536989423965\n",
      "[EPOCH #9, step #1126] loss: 2.5083734858004307\n",
      "[EPOCH #9, step #1128] loss: 2.5076067955542496\n",
      "[EPOCH #9, step #1130] loss: 2.5083174582185417\n",
      "[EPOCH #9, step #1132] loss: 2.507831262153329\n",
      "[EPOCH #9, step #1134] loss: 2.507741819604378\n",
      "[EPOCH #9, step #1136] loss: 2.5077712434158057\n",
      "[EPOCH #9, step #1138] loss: 2.507925091656391\n",
      "[EPOCH #9, step #1140] loss: 2.5076228073038207\n",
      "[EPOCH #9, step #1142] loss: 2.5070934462526444\n",
      "[EPOCH #9, step #1144] loss: 2.5070495876162333\n",
      "[EPOCH #9, step #1146] loss: 2.5076286416523543\n",
      "[EPOCH #9, step #1148] loss: 2.5082046049796984\n",
      "[EPOCH #9, step #1150] loss: 2.5082366551449775\n",
      "[EPOCH #9, step #1152] loss: 2.50776467008996\n",
      "[EPOCH #9, step #1154] loss: 2.5079260382301363\n",
      "[EPOCH #9, step #1156] loss: 2.508266234047576\n",
      "[EPOCH #9, step #1158] loss: 2.5081542698446277\n",
      "[EPOCH #9, step #1160] loss: 2.50842732073006\n",
      "[EPOCH #9, step #1162] loss: 2.5082418906309436\n",
      "[EPOCH #9, step #1164] loss: 2.508598698464586\n",
      "[EPOCH #9, step #1166] loss: 2.508305639513763\n",
      "[EPOCH #9, step #1168] loss: 2.5080957443312357\n",
      "[EPOCH #9, step #1170] loss: 2.5077711499521205\n",
      "[EPOCH #9, step #1172] loss: 2.507726867892045\n",
      "[EPOCH #9, step #1174] loss: 2.5078182319884603\n",
      "[EPOCH #9, step #1176] loss: 2.507527872780773\n",
      "[EPOCH #9, step #1178] loss: 2.507367072012386\n",
      "[EPOCH #9, step #1180] loss: 2.507501344172052\n",
      "[EPOCH #9, step #1182] loss: 2.5072907478448605\n",
      "[EPOCH #9, step #1184] loss: 2.5073218343630117\n",
      "[EPOCH #9, step #1186] loss: 2.5068315371004792\n",
      "[EPOCH #9, step #1188] loss: 2.506878396660666\n",
      "[EPOCH #9, step #1190] loss: 2.5065299958165808\n",
      "[EPOCH #9, step #1192] loss: 2.506336813300773\n",
      "[EPOCH #9, step #1194] loss: 2.506369083795587\n",
      "[EPOCH #9, step #1196] loss: 2.506928896844238\n",
      "[EPOCH #9, step #1198] loss: 2.506492212675729\n",
      "[EPOCH #9, step #1200] loss: 2.5062520057335185\n",
      "[EPOCH #9, step #1202] loss: 2.5061044393731273\n",
      "[EPOCH #9, step #1204] loss: 2.506277448606689\n",
      "[EPOCH #9, step #1206] loss: 2.506297478521769\n",
      "[EPOCH #9, step #1208] loss: 2.5062720817016904\n",
      "[EPOCH #9, step #1210] loss: 2.5056802227317942\n",
      "[EPOCH #9, step #1212] loss: 2.506072881196219\n",
      "[EPOCH #9, step #1214] loss: 2.506555380546507\n",
      "[EPOCH #9, step #1216] loss: 2.5067568535479543\n",
      "[EPOCH #9, step #1218] loss: 2.506977184861287\n",
      "[EPOCH #9, step #1220] loss: 2.5072738365693525\n",
      "[EPOCH #9, step #1222] loss: 2.5068874978083424\n",
      "[EPOCH #9, step #1224] loss: 2.506608881366496\n",
      "[EPOCH #9, step #1226] loss: 2.5069573845626283\n",
      "[EPOCH #9, step #1228] loss: 2.5069126274839855\n",
      "[EPOCH #9, step #1230] loss: 2.5060528284354873\n",
      "[EPOCH #9, step #1232] loss: 2.505637811628281\n",
      "[EPOCH #9, step #1234] loss: 2.506052068563608\n",
      "[EPOCH #9, step #1236] loss: 2.5065638382972586\n",
      "[EPOCH #9, step #1238] loss: 2.5070905829745977\n",
      "[EPOCH #9, step #1240] loss: 2.506939025582276\n",
      "[EPOCH #9, step #1242] loss: 2.5070332748124606\n",
      "[EPOCH #9, step #1244] loss: 2.507311376701876\n",
      "[EPOCH #9, step #1246] loss: 2.5071497755043013\n",
      "[EPOCH #9, step #1248] loss: 2.5073269929191033\n",
      "[EPOCH #9, step #1250] loss: 2.5071787933270326\n",
      "[EPOCH #9, step #1252] loss: 2.507448731663697\n",
      "[EPOCH #9, step #1254] loss: 2.507770641866433\n",
      "[EPOCH #9, step #1256] loss: 2.507021930356204\n",
      "[EPOCH #9, step #1258] loss: 2.5070703840142112\n",
      "[EPOCH #9, step #1260] loss: 2.506862153333865\n",
      "[EPOCH #9, step #1262] loss: 2.5066244430421176\n",
      "[EPOCH #9, step #1264] loss: 2.506778362899901\n",
      "[EPOCH #9, step #1266] loss: 2.506577788513292\n",
      "[EPOCH #9, step #1268] loss: 2.506589853829338\n",
      "[EPOCH #9, step #1270] loss: 2.5068605248145848\n",
      "[EPOCH #9, step #1272] loss: 2.5065833362929952\n",
      "[EPOCH #9, step #1274] loss: 2.506237522761027\n",
      "[EPOCH #9, step #1276] loss: 2.506247599421765\n",
      "[EPOCH #9, step #1278] loss: 2.5061095752596763\n",
      "[EPOCH #9, step #1280] loss: 2.506215384004639\n",
      "[EPOCH #9, step #1282] loss: 2.5057376341622786\n",
      "[EPOCH #9, step #1284] loss: 2.505588298641754\n",
      "[EPOCH #9, step #1286] loss: 2.5057617769559966\n",
      "[EPOCH #9, step #1288] loss: 2.505751113913797\n",
      "[EPOCH #9, step #1290] loss: 2.505908948520096\n",
      "[EPOCH #9, step #1292] loss: 2.5056453475819387\n",
      "[EPOCH #9, step #1294] loss: 2.505375287523601\n",
      "[EPOCH #9, step #1296] loss: 2.504974991335902\n",
      "[EPOCH #9, step #1298] loss: 2.5051768758463986\n",
      "[EPOCH #9, step #1300] loss: 2.504770823023486\n",
      "[EPOCH #9, step #1302] loss: 2.5044048648564887\n",
      "[EPOCH #9, step #1304] loss: 2.504309833826233\n",
      "[EPOCH #9, step #1306] loss: 2.504222262243141\n",
      "[EPOCH #9, step #1308] loss: 2.504169726207841\n",
      "[EPOCH #9, step #1310] loss: 2.504333609574447\n",
      "[EPOCH #9, step #1312] loss: 2.5043394393078353\n",
      "[EPOCH #9, step #1314] loss: 2.5045983992601983\n",
      "[EPOCH #9, step #1316] loss: 2.504508926548013\n",
      "[EPOCH #9, step #1318] loss: 2.504384265332804\n",
      "[EPOCH #9, step #1320] loss: 2.5045584424890235\n",
      "[EPOCH #9, step #1322] loss: 2.5042189238022785\n",
      "[EPOCH #9, step #1324] loss: 2.504693135675394\n",
      "[EPOCH #9, step #1326] loss: 2.504196325458794\n",
      "[EPOCH #9, step #1328] loss: 2.504290544152529\n",
      "[EPOCH #9, step #1330] loss: 2.5044840023447748\n",
      "[EPOCH #9, step #1332] loss: 2.504269354878202\n",
      "[EPOCH #9, step #1334] loss: 2.5041662878758006\n",
      "[EPOCH #9, step #1336] loss: 2.50415729299444\n",
      "[EPOCH #9, step #1338] loss: 2.503887670978492\n",
      "[EPOCH #9, step #1340] loss: 2.50373676177017\n",
      "[EPOCH #9, step #1342] loss: 2.5037871401254934\n",
      "[EPOCH #9, step #1344] loss: 2.5044397951501898\n",
      "[EPOCH #9, step #1346] loss: 2.5042706705856608\n",
      "[EPOCH #9, step #1348] loss: 2.5040760508636972\n",
      "[EPOCH #9, step #1350] loss: 2.5037785059959248\n",
      "[EPOCH #9, step #1352] loss: 2.5036879274815167\n",
      "[EPOCH #9, step #1354] loss: 2.5035113364568056\n",
      "[EPOCH #9, step #1356] loss: 2.503830012101502\n",
      "[EPOCH #9, step #1358] loss: 2.5036242871358168\n",
      "[EPOCH #9, step #1360] loss: 2.5040676916109823\n",
      "[EPOCH #9, step #1362] loss: 2.503683518418825\n",
      "[EPOCH #9, step #1364] loss: 2.504149521663512\n",
      "[EPOCH #9, step #1366] loss: 2.5044895932895908\n",
      "[EPOCH #9, step #1368] loss: 2.504524022841471\n",
      "[EPOCH #9, step #1370] loss: 2.504519929510238\n",
      "[EPOCH #9, step #1372] loss: 2.50447321215947\n",
      "[EPOCH #9, step #1374] loss: 2.5046460455114192\n",
      "[EPOCH #9, step #1376] loss: 2.504801298971183\n",
      "[EPOCH #9, step #1378] loss: 2.5047534760398396\n",
      "[EPOCH #9, step #1380] loss: 2.504628821786636\n",
      "[EPOCH #9, step #1382] loss: 2.5042697014536275\n",
      "[EPOCH #9, step #1384] loss: 2.503963462196102\n",
      "[EPOCH #9, step #1386] loss: 2.504051830068972\n",
      "[EPOCH #9, step #1388] loss: 2.503567931976483\n",
      "[EPOCH #9, step #1390] loss: 2.5036108636067635\n",
      "[EPOCH #9, step #1392] loss: 2.5033369603468545\n",
      "[EPOCH #9, step #1394] loss: 2.5033575980894027\n",
      "[EPOCH #9, step #1396] loss: 2.503542377510153\n",
      "[EPOCH #9, step #1398] loss: 2.5036546054101145\n",
      "[EPOCH #9, step #1400] loss: 2.503898893570066\n",
      "[EPOCH #9, step #1402] loss: 2.503331559773266\n",
      "[EPOCH #9, step #1404] loss: 2.5027537071832135\n",
      "[EPOCH #9, step #1406] loss: 2.5028930265342586\n",
      "[EPOCH #9, step #1408] loss: 2.5024954632210172\n",
      "[EPOCH #9, step #1410] loss: 2.502553954435358\n",
      "[EPOCH #9, step #1412] loss: 2.5022261751010246\n",
      "[EPOCH #9, step #1414] loss: 2.502273402786929\n",
      "[EPOCH #9, step #1416] loss: 2.502201525106679\n",
      "[EPOCH #9, step #1418] loss: 2.5025101048245744\n",
      "[EPOCH #9, step #1420] loss: 2.502283180120711\n",
      "[EPOCH #9, step #1422] loss: 2.5020470645171358\n",
      "[EPOCH #9, step #1424] loss: 2.502423369675352\n",
      "[EPOCH #9, step #1426] loss: 2.5022517222161884\n",
      "[EPOCH #9, step #1428] loss: 2.5024368019684617\n",
      "[EPOCH #9, step #1430] loss: 2.5021472996052623\n",
      "[EPOCH #9, step #1432] loss: 2.5018749239556204\n",
      "[EPOCH #9, step #1434] loss: 2.501766895417137\n",
      "[EPOCH #9, step #1436] loss: 2.5019783100156046\n",
      "[EPOCH #9, step #1438] loss: 2.5018706358995098\n",
      "[EPOCH #9, step #1440] loss: 2.5016574966336687\n",
      "[EPOCH #9, step #1442] loss: 2.502018325376742\n",
      "[EPOCH #9, step #1444] loss: 2.501398713943455\n",
      "[EPOCH #9, step #1446] loss: 2.5010538525472614\n",
      "[EPOCH #9, step #1448] loss: 2.5008953966051237\n",
      "[EPOCH #9, step #1450] loss: 2.5004487965207196\n",
      "[EPOCH #9, step #1452] loss: 2.500571615435055\n",
      "[EPOCH #9, step #1454] loss: 2.50044106937356\n",
      "[EPOCH #9, step #1456] loss: 2.500291960241047\n",
      "[EPOCH #9, step #1458] loss: 2.500368859442723\n",
      "[EPOCH #9, step #1460] loss: 2.5004764147444507\n",
      "[EPOCH #9, step #1462] loss: 2.5004532354300104\n",
      "[EPOCH #9, step #1464] loss: 2.500740513866672\n",
      "[EPOCH #9, step #1466] loss: 2.500619669470888\n",
      "[EPOCH #9, step #1468] loss: 2.50050532006341\n",
      "[EPOCH #9, step #1470] loss: 2.5006775697990795\n",
      "[EPOCH #9, step #1472] loss: 2.500835658495554\n",
      "[EPOCH #9, step #1474] loss: 2.5009822891526303\n",
      "[EPOCH #9, step #1476] loss: 2.5007926149794435\n",
      "[EPOCH #9, step #1478] loss: 2.501052774957421\n",
      "[EPOCH #9, step #1480] loss: 2.500843815108073\n",
      "[EPOCH #9, step #1482] loss: 2.5004846667889717\n",
      "[EPOCH #9, step #1484] loss: 2.5005446730238017\n",
      "[EPOCH #9, step #1486] loss: 2.50056199932868\n",
      "[EPOCH #9, step #1488] loss: 2.500477475156073\n",
      "[EPOCH #9, step #1490] loss: 2.500346721298018\n",
      "[EPOCH #9, step #1492] loss: 2.500028697979666\n",
      "[EPOCH #9, step #1494] loss: 2.499778350858784\n",
      "[EPOCH #9, step #1496] loss: 2.49956551335538\n",
      "[EPOCH #9, step #1498] loss: 2.500231871134126\n",
      "[EPOCH #9, step #1500] loss: 2.500415686922499\n",
      "[EPOCH #9, step #1502] loss: 2.500587679827443\n",
      "[EPOCH #9, step #1504] loss: 2.5009767428585064\n",
      "[EPOCH #9, step #1506] loss: 2.5006012521837433\n",
      "[EPOCH #9, step #1508] loss: 2.5002268780296886\n",
      "[EPOCH #9, step #1510] loss: 2.500237070512172\n",
      "[EPOCH #9, step #1512] loss: 2.500244974617287\n",
      "[EPOCH #9, step #1514] loss: 2.5002191446795323\n",
      "[EPOCH #9, step #1516] loss: 2.499997199878303\n",
      "[EPOCH #9, step #1518] loss: 2.4997835726703443\n",
      "[EPOCH #9, step #1520] loss: 2.499411942142158\n",
      "[EPOCH #9, step #1522] loss: 2.499358250683104\n",
      "[EPOCH #9, step #1524] loss: 2.499969389165034\n",
      "[EPOCH #9, step #1526] loss: 2.499573451362565\n",
      "[EPOCH #9, step #1528] loss: 2.4996354123047553\n",
      "[EPOCH #9, step #1530] loss: 2.4995389554642293\n",
      "[EPOCH #9, step #1532] loss: 2.4994365842375035\n",
      "[EPOCH #9, step #1534] loss: 2.4995720877321226\n",
      "[EPOCH #9, step #1536] loss: 2.499343764417421\n",
      "[EPOCH #9, step #1538] loss: 2.498813630002439\n",
      "[EPOCH #9, step #1540] loss: 2.499370087825347\n",
      "[EPOCH #9, step #1542] loss: 2.4999025380232855\n",
      "[EPOCH #9, step #1544] loss: 2.4998134410111263\n",
      "[EPOCH #9, step #1546] loss: 2.500028549430443\n",
      "[EPOCH #9, step #1548] loss: 2.4997466117663105\n",
      "[EPOCH #9, step #1550] loss: 2.4996230593809843\n",
      "[EPOCH #9, step #1552] loss: 2.499851630797942\n",
      "[EPOCH #9, step #1554] loss: 2.5000301814155947\n",
      "[EPOCH #9, step #1556] loss: 2.499979058595215\n",
      "[EPOCH #9, step #1558] loss: 2.500076954834273\n",
      "[EPOCH #9, step #1560] loss: 2.4998835986581542\n",
      "[EPOCH #9, step #1562] loss: 2.4998229220366524\n",
      "[EPOCH #9, step #1564] loss: 2.4999969210487585\n",
      "[EPOCH #9, step #1566] loss: 2.4999290929908726\n",
      "[EPOCH #9, step #1568] loss: 2.4997326786006004\n",
      "[EPOCH #9, step #1570] loss: 2.499404200924801\n",
      "[EPOCH #9, step #1572] loss: 2.4997344785485387\n",
      "[EPOCH #9, step #1574] loss: 2.4995309463379876\n",
      "[EPOCH #9, step #1576] loss: 2.4988763385281656\n",
      "[EPOCH #9, step #1578] loss: 2.4990381798916332\n",
      "[EPOCH #9, step #1580] loss: 2.499024914609413\n",
      "[EPOCH #9, step #1582] loss: 2.4991233671155824\n",
      "[EPOCH #9, step #1584] loss: 2.4993715978195237\n",
      "[EPOCH #9, step #1586] loss: 2.4990728530931863\n",
      "[EPOCH #9, step #1588] loss: 2.499084317211538\n",
      "[EPOCH #9, step #1590] loss: 2.4988599927975352\n",
      "[EPOCH #9, step #1592] loss: 2.4987950613868364\n",
      "[EPOCH #9, step #1594] loss: 2.498403839780993\n",
      "[EPOCH #9, step #1596] loss: 2.4984159124741048\n",
      "[EPOCH #9, step #1598] loss: 2.4986153658365295\n",
      "[EPOCH #9, step #1600] loss: 2.4981177975281113\n",
      "[EPOCH #9, step #1602] loss: 2.4983831435832395\n",
      "[EPOCH #9, step #1604] loss: 2.498120459366439\n",
      "[EPOCH #9, step #1606] loss: 2.4982295292241274\n",
      "[EPOCH #9, step #1608] loss: 2.497704609200553\n",
      "[EPOCH #9, step #1610] loss: 2.4975951688767664\n",
      "[EPOCH #9, step #1612] loss: 2.497347131990455\n",
      "[EPOCH #9, step #1614] loss: 2.4969831997396037\n",
      "[EPOCH #9, step #1616] loss: 2.497055425935862\n",
      "[EPOCH #9, step #1618] loss: 2.496977627682347\n",
      "[EPOCH #9, step #1620] loss: 2.4969329608214776\n",
      "[EPOCH #9, step #1622] loss: 2.4971257067725605\n",
      "[EPOCH #9, step #1624] loss: 2.497123599932744\n",
      "[EPOCH #9, step #1626] loss: 2.4975122260256053\n",
      "[EPOCH #9, step #1628] loss: 2.4974745907177582\n",
      "[EPOCH #9, step #1630] loss: 2.4973592519175414\n",
      "[EPOCH #9, step #1632] loss: 2.497781078361399\n",
      "[EPOCH #9, step #1634] loss: 2.497943912952318\n",
      "[EPOCH #9, step #1636] loss: 2.4977362629984237\n",
      "[EPOCH #9, step #1638] loss: 2.4977056454273896\n",
      "[EPOCH #9, step #1640] loss: 2.4978578541788803\n",
      "[EPOCH #9, step #1642] loss: 2.498092289821302\n",
      "[EPOCH #9, step #1644] loss: 2.4983460173418455\n",
      "[EPOCH #9, step #1646] loss: 2.4979369629493395\n",
      "[EPOCH #9, step #1648] loss: 2.4977118405809975\n",
      "[EPOCH #9, step #1650] loss: 2.497664488351107\n",
      "[EPOCH #9, step #1652] loss: 2.4977428134974753\n",
      "[EPOCH #9, step #1654] loss: 2.4977036439400067\n",
      "[EPOCH #9, step #1656] loss: 2.498006911254749\n",
      "[EPOCH #9, step #1658] loss: 2.4977711796976125\n",
      "[EPOCH #9, step #1660] loss: 2.4977527555394503\n",
      "[EPOCH #9, step #1662] loss: 2.4977760651135976\n",
      "[EPOCH #9, step #1664] loss: 2.4976732880503567\n",
      "[EPOCH #9, step #1666] loss: 2.4973016712718477\n",
      "[EPOCH #9, step #1668] loss: 2.4974164794918448\n",
      "[EPOCH #9, step #1670] loss: 2.4975094089673564\n",
      "[EPOCH #9, step #1672] loss: 2.4977299458098425\n",
      "[EPOCH #9, step #1674] loss: 2.4975761018582245\n",
      "[EPOCH #9, step #1676] loss: 2.497162720171838\n",
      "[EPOCH #9, step #1678] loss: 2.4973842587195527\n",
      "[EPOCH #9, step #1680] loss: 2.497460934252061\n",
      "[EPOCH #9, step #1682] loss: 2.4973094367725963\n",
      "[EPOCH #9, step #1684] loss: 2.497307687909384\n",
      "[EPOCH #9, step #1686] loss: 2.4970014223207295\n",
      "[EPOCH #9, step #1688] loss: 2.4969823776158164\n",
      "[EPOCH #9, step #1690] loss: 2.497241439303303\n",
      "[EPOCH #9, step #1692] loss: 2.4970125847150078\n",
      "[EPOCH #9, step #1694] loss: 2.496876091169397\n",
      "[EPOCH #9, step #1696] loss: 2.496624372886361\n",
      "[EPOCH #9, step #1698] loss: 2.4966952686382786\n",
      "[EPOCH #9, step #1700] loss: 2.4971210584438666\n",
      "[EPOCH #9, step #1702] loss: 2.497242874141588\n",
      "[EPOCH #9, step #1704] loss: 2.4972977736828263\n",
      "[EPOCH #9, step #1706] loss: 2.4973430758550563\n",
      "[EPOCH #9, step #1708] loss: 2.4974336711337792\n",
      "[EPOCH #9, step #1710] loss: 2.4977650473091355\n",
      "[EPOCH #9, step #1712] loss: 2.49744121143154\n",
      "[EPOCH #9, step #1714] loss: 2.4974439376992317\n",
      "[EPOCH #9, step #1716] loss: 2.497357575991991\n",
      "[EPOCH #9, step #1718] loss: 2.497120679915818\n",
      "[EPOCH #9, step #1720] loss: 2.497314013484465\n",
      "[EPOCH #9, step #1722] loss: 2.497197871213726\n",
      "[EPOCH #9, step #1724] loss: 2.4971702605399533\n",
      "[EPOCH #9, step #1726] loss: 2.4971877163935066\n",
      "[EPOCH #9, step #1728] loss: 2.4969739528526937\n",
      "[EPOCH #9, step #1730] loss: 2.496824998307407\n",
      "[EPOCH #9, step #1732] loss: 2.4962493621470676\n",
      "[EPOCH #9, step #1734] loss: 2.4961330469472265\n",
      "[EPOCH #9, step #1736] loss: 2.496210466188882\n",
      "[EPOCH #9, step #1738] loss: 2.4960297332405017\n",
      "[EPOCH #9, step #1740] loss: 2.496204240715141\n",
      "[EPOCH #9, step #1742] loss: 2.4962022814064\n",
      "[EPOCH #9, step #1744] loss: 2.496479021375705\n",
      "[EPOCH #9, step #1746] loss: 2.496453273958251\n",
      "[EPOCH #9, step #1748] loss: 2.496406550881793\n",
      "[EPOCH #9, step #1750] loss: 2.496139606906645\n",
      "[EPOCH #9, step #1752] loss: 2.4955079598353374\n",
      "[EPOCH #9, step #1754] loss: 2.4951740692144107\n",
      "[EPOCH #9, step #1756] loss: 2.4951249470952295\n",
      "[EPOCH #9, step #1758] loss: 2.4948565375066196\n",
      "[EPOCH #9, step #1760] loss: 2.494932441194243\n",
      "[EPOCH #9, step #1762] loss: 2.494915384023756\n",
      "[EPOCH #9, step #1764] loss: 2.4954354486789647\n",
      "[EPOCH #9, step #1766] loss: 2.4951405860504727\n",
      "[EPOCH #9, step #1768] loss: 2.495445050042251\n",
      "[EPOCH #9, step #1770] loss: 2.495511365502248\n",
      "[EPOCH #9, step #1772] loss: 2.4958933907851484\n",
      "[EPOCH #9, step #1774] loss: 2.495684376501701\n",
      "[EPOCH #9, step #1776] loss: 2.4955255199699637\n",
      "[EPOCH #9, step #1778] loss: 2.495435963526678\n",
      "[EPOCH #9, step #1780] loss: 2.495492998968678\n",
      "[EPOCH #9, step #1782] loss: 2.4955590100884772\n",
      "[EPOCH #9, step #1784] loss: 2.495569435822196\n",
      "[EPOCH #9, step #1786] loss: 2.495305558390369\n",
      "[EPOCH #9, step #1788] loss: 2.4950634002552277\n",
      "[EPOCH #9, step #1790] loss: 2.4951358762019042\n",
      "[EPOCH #9, step #1792] loss: 2.4954493805741174\n",
      "[EPOCH #9, step #1794] loss: 2.4951591411340868\n",
      "[EPOCH #9, step #1796] loss: 2.4950754822262406\n",
      "[EPOCH #9, step #1798] loss: 2.494842547387001\n",
      "[EPOCH #9, step #1800] loss: 2.494885878520565\n",
      "[EPOCH #9, step #1802] loss: 2.494613083547443\n",
      "[EPOCH #9, step #1804] loss: 2.4947304912551287\n",
      "[EPOCH #9, step #1806] loss: 2.494967561633665\n",
      "[EPOCH #9, step #1808] loss: 2.4952795286083695\n",
      "[EPOCH #9, step #1810] loss: 2.495395195477579\n",
      "[EPOCH #9, step #1812] loss: 2.4952987056375537\n",
      "[EPOCH #9, step #1814] loss: 2.495516417440304\n",
      "[EPOCH #9, step #1816] loss: 2.495593373501242\n",
      "[EPOCH #9, step #1818] loss: 2.4956039253206552\n",
      "[EPOCH #9, step #1820] loss: 2.4954754239841193\n",
      "[EPOCH #9, step #1822] loss: 2.4953656027229423\n",
      "[EPOCH #9, step #1824] loss: 2.4951209872389493\n",
      "[EPOCH #9, step #1826] loss: 2.495039536056456\n",
      "[EPOCH #9, step #1828] loss: 2.495163038234492\n",
      "[EPOCH #9, step #1830] loss: 2.495344304634794\n",
      "[EPOCH #9, step #1832] loss: 2.495384407056464\n",
      "[EPOCH #9, step #1834] loss: 2.49560288505918\n",
      "[EPOCH #9, step #1836] loss: 2.495496574730476\n",
      "[EPOCH #9, step #1838] loss: 2.495277510640931\n",
      "[EPOCH #9, step #1840] loss: 2.4954366869799536\n",
      "[EPOCH #9, step #1842] loss: 2.4958387359742296\n",
      "[EPOCH #9, step #1844] loss: 2.495709061105723\n",
      "[EPOCH #9, step #1846] loss: 2.4957452097259214\n",
      "[EPOCH #9, step #1848] loss: 2.4955977703056313\n",
      "[EPOCH #9, step #1850] loss: 2.4951357021646072\n",
      "[EPOCH #9, step #1852] loss: 2.4949930187051383\n",
      "[EPOCH #9, step #1854] loss: 2.495029791281872\n",
      "[EPOCH #9, step #1856] loss: 2.4949434950715057\n",
      "[EPOCH #9, step #1858] loss: 2.4952608344374068\n",
      "[EPOCH #9, step #1860] loss: 2.495317524123871\n",
      "[EPOCH #9, step #1862] loss: 2.4953065694690197\n",
      "[EPOCH #9, step #1864] loss: 2.495570318245057\n",
      "[EPOCH #9, step #1866] loss: 2.4953786339680653\n",
      "[EPOCH #9, step #1868] loss: 2.495485835562676\n",
      "[EPOCH #9, step #1870] loss: 2.4954014340548003\n",
      "[EPOCH #9, step #1872] loss: 2.4952174791090638\n",
      "[EPOCH #9, step #1874] loss: 2.495049910100301\n",
      "[EPOCH #9, step #1876] loss: 2.4951024243472166\n",
      "[EPOCH #9, step #1878] loss: 2.495296503268004\n",
      "[EPOCH #9, step #1880] loss: 2.4949626405463454\n",
      "[EPOCH #9, step #1882] loss: 2.4946910375239555\n",
      "[EPOCH #9, step #1884] loss: 2.4951128965979863\n",
      "[EPOCH #9, step #1886] loss: 2.4951966949790383\n",
      "[EPOCH #9, step #1888] loss: 2.494997920025714\n",
      "[EPOCH #9, step #1890] loss: 2.494811603721647\n",
      "[EPOCH #9, step #1892] loss: 2.4952404724499946\n",
      "[EPOCH #9, step #1894] loss: 2.4949236359004923\n",
      "[EPOCH #9, step #1896] loss: 2.49519036855582\n",
      "[EPOCH #9, step #1898] loss: 2.4955066464460796\n",
      "[EPOCH #9, step #1900] loss: 2.4955936347353402\n",
      "[EPOCH #9, step #1902] loss: 2.4953853489534517\n",
      "[EPOCH #9, step #1904] loss: 2.4950359087290725\n",
      "[EPOCH #9, step #1906] loss: 2.4949860999767983\n",
      "[EPOCH #9, step #1908] loss: 2.4949596720631053\n",
      "[EPOCH #9, step #1910] loss: 2.49478954940738\n",
      "[EPOCH #9, step #1912] loss: 2.4944618886139027\n",
      "[EPOCH #9, step #1914] loss: 2.494394415912678\n",
      "[EPOCH #9, step #1916] loss: 2.494122918471733\n",
      "[EPOCH #9, step #1918] loss: 2.4939438770561555\n",
      "[EPOCH #9, step #1920] loss: 2.493498392926722\n",
      "[EPOCH #9, step #1922] loss: 2.49367965086016\n",
      "[EPOCH #9, step #1924] loss: 2.493471698946767\n",
      "[EPOCH #9, step #1926] loss: 2.4933258418784465\n",
      "[EPOCH #9, step #1928] loss: 2.493209014907904\n",
      "[EPOCH #9, step #1930] loss: 2.493118007772022\n",
      "[EPOCH #9, step #1932] loss: 2.4934190579541164\n",
      "[EPOCH #9, step #1934] loss: 2.493580082035804\n",
      "[EPOCH #9, step #1936] loss: 2.493467494699225\n",
      "[EPOCH #9, step #1938] loss: 2.4936239443346664\n",
      "[EPOCH #9, step #1940] loss: 2.4934715194716888\n",
      "[EPOCH #9, step #1942] loss: 2.4932429575147053\n",
      "[EPOCH #9, step #1944] loss: 2.4934144224176675\n",
      "[EPOCH #9, step #1946] loss: 2.493489207704678\n",
      "[EPOCH #9, step #1948] loss: 2.493587008435155\n",
      "[EPOCH #9, step #1950] loss: 2.4934898090631394\n",
      "[EPOCH #9, step #1952] loss: 2.4934420908528967\n",
      "[EPOCH #9, step #1954] loss: 2.493734756516069\n",
      "[EPOCH #9, step #1956] loss: 2.493858836229565\n",
      "[EPOCH #9, step #1958] loss: 2.4939696780877068\n",
      "[EPOCH #9, step #1960] loss: 2.4940951038902357\n",
      "[EPOCH #9, step #1962] loss: 2.494152283644227\n",
      "[EPOCH #9, step #1964] loss: 2.494051037186581\n",
      "[EPOCH #9, step #1966] loss: 2.493852181366754\n",
      "[EPOCH #9, step #1968] loss: 2.494177656103476\n",
      "[EPOCH #9, step #1970] loss: 2.4940388200852786\n",
      "[EPOCH #9, step #1972] loss: 2.493925831551124\n",
      "[EPOCH #9, step #1974] loss: 2.4940635379960265\n",
      "[EPOCH #9, step #1976] loss: 2.493959449612256\n",
      "[EPOCH #9, step #1978] loss: 2.494014157075482\n",
      "[EPOCH #9, step #1980] loss: 2.4940112821987217\n",
      "[EPOCH #9, step #1982] loss: 2.49400569890042\n",
      "[EPOCH #9, step #1984] loss: 2.4937821844062515\n",
      "[EPOCH #9, step #1986] loss: 2.4934687184279567\n",
      "[EPOCH #9, step #1988] loss: 2.4933573373182747\n",
      "[EPOCH #9, step #1990] loss: 2.4933775087387224\n",
      "[EPOCH #9, step #1992] loss: 2.493447874218031\n",
      "[EPOCH #9, step #1994] loss: 2.493329197601567\n",
      "[EPOCH #9, step #1996] loss: 2.493173964750665\n",
      "[EPOCH #9, step #1998] loss: 2.493369408462452\n",
      "[EPOCH #9, step #2000] loss: 2.493056085156179\n",
      "[EPOCH #9, step #2002] loss: 2.4930966347381585\n",
      "[EPOCH #9, step #2004] loss: 2.4930736607744213\n",
      "[EPOCH #9, step #2006] loss: 2.4932929041020953\n",
      "[EPOCH #9, step #2008] loss: 2.4934544881936507\n",
      "[EPOCH #9, step #2010] loss: 2.4931486502386098\n",
      "[EPOCH #9, step #2012] loss: 2.493104876005644\n",
      "[EPOCH #9, step #2014] loss: 2.493282254990514\n",
      "[EPOCH #9, step #2016] loss: 2.4933222334870737\n",
      "[EPOCH #9, step #2018] loss: 2.4933010113009018\n",
      "[EPOCH #9, step #2020] loss: 2.4934803184927365\n",
      "[EPOCH #9, step #2022] loss: 2.4932533080661528\n",
      "[EPOCH #9, step #2024] loss: 2.493213791023066\n",
      "[EPOCH #9, step #2026] loss: 2.493156492680708\n",
      "[EPOCH #9, step #2028] loss: 2.4929988563442653\n",
      "[EPOCH #9, step #2030] loss: 2.4934376234024516\n",
      "[EPOCH #9, step #2032] loss: 2.493606620566691\n",
      "[EPOCH #9, step #2034] loss: 2.4934302828528665\n",
      "[EPOCH #9, step #2036] loss: 2.4933537201490483\n",
      "[EPOCH #9, step #2038] loss: 2.493253667135926\n",
      "[EPOCH #9, step #2040] loss: 2.493098422804631\n",
      "[EPOCH #9, step #2042] loss: 2.492814375090354\n",
      "[EPOCH #9, step #2044] loss: 2.4930886459234\n",
      "[EPOCH #9, step #2046] loss: 2.493324320725132\n",
      "[EPOCH #9, step #2048] loss: 2.493240231767173\n",
      "[EPOCH #9, step #2050] loss: 2.4931716283666163\n",
      "[EPOCH #9, step #2052] loss: 2.4934233727829085\n",
      "[EPOCH #9, step #2054] loss: 2.493782549240873\n",
      "[EPOCH #9, step #2056] loss: 2.4936915516679474\n",
      "[EPOCH #9, step #2058] loss: 2.4935971437118885\n",
      "[EPOCH #9, step #2060] loss: 2.4934541834956634\n",
      "[EPOCH #9, step #2062] loss: 2.4934005717080137\n",
      "[EPOCH #9, step #2064] loss: 2.4934420885243083\n",
      "[EPOCH #9, step #2066] loss: 2.4933626576212795\n",
      "[EPOCH #9, step #2068] loss: 2.493392411322338\n",
      "[EPOCH #9, step #2070] loss: 2.4937220102689626\n",
      "[EPOCH #9, step #2072] loss: 2.4936444386156986\n",
      "[EPOCH #9, step #2074] loss: 2.494036821859429\n",
      "[EPOCH #9, step #2076] loss: 2.493682334959134\n",
      "[EPOCH #9, step #2078] loss: 2.4936252381722475\n",
      "[EPOCH #9, step #2080] loss: 2.4936337617084074\n",
      "[EPOCH #9, step #2082] loss: 2.4937732703286297\n",
      "[EPOCH #9, step #2084] loss: 2.4936678668577894\n",
      "[EPOCH #9, step #2086] loss: 2.493145016088518\n",
      "[EPOCH #9, step #2088] loss: 2.493451701105354\n",
      "[EPOCH #9, step #2090] loss: 2.493357660666657\n",
      "[EPOCH #9, step #2092] loss: 2.4934484377695623\n",
      "[EPOCH #9, step #2094] loss: 2.4933823033562708\n",
      "[EPOCH #9, step #2096] loss: 2.4934488372911883\n",
      "[EPOCH #9, step #2098] loss: 2.4934567289729523\n",
      "[EPOCH #9, step #2100] loss: 2.49334337744243\n",
      "[EPOCH #9, step #2102] loss: 2.49303935983325\n",
      "[EPOCH #9, step #2104] loss: 2.492873119118661\n",
      "[EPOCH #9, step #2106] loss: 2.492675641389837\n",
      "[EPOCH #9, step #2108] loss: 2.4926798865940967\n",
      "[EPOCH #9, step #2110] loss: 2.492811137835938\n",
      "[EPOCH #9, step #2112] loss: 2.492806135056654\n",
      "[EPOCH #9, step #2114] loss: 2.492687563185996\n",
      "[EPOCH #9, step #2116] loss: 2.492658429287715\n",
      "[EPOCH #9, step #2118] loss: 2.4924979762346915\n",
      "[EPOCH #9, step #2120] loss: 2.492492322031477\n",
      "[EPOCH #9, step #2122] loss: 2.4923370991795344\n",
      "[EPOCH #9, step #2124] loss: 2.4925737789378446\n",
      "[EPOCH #9, step #2126] loss: 2.492279717268717\n",
      "[EPOCH #9, step #2128] loss: 2.4922684954051513\n",
      "[EPOCH #9, step #2130] loss: 2.49238153239026\n",
      "[EPOCH #9, step #2132] loss: 2.4922409397975636\n",
      "[EPOCH #9, step #2134] loss: 2.4922237598923944\n",
      "[EPOCH #9, step #2136] loss: 2.4919780794013366\n",
      "[EPOCH #9, step #2138] loss: 2.4922185950103124\n",
      "[EPOCH #9, step #2140] loss: 2.492619265857449\n",
      "[EPOCH #9, step #2142] loss: 2.4923839876710727\n",
      "[EPOCH #9, step #2144] loss: 2.4926587932315463\n",
      "[EPOCH #9, step #2146] loss: 2.4927730455363024\n",
      "[EPOCH #9, step #2148] loss: 2.4928962920864772\n",
      "[EPOCH #9, step #2150] loss: 2.49260052266868\n",
      "[EPOCH #9, step #2152] loss: 2.4928625036382255\n",
      "[EPOCH #9, step #2154] loss: 2.4928230138499887\n",
      "[EPOCH #9, step #2156] loss: 2.492720933329689\n",
      "[EPOCH #9, step #2158] loss: 2.492585376767772\n",
      "[EPOCH #9, step #2160] loss: 2.4925202634918198\n",
      "[EPOCH #9, step #2162] loss: 2.4928333329426926\n",
      "[EPOCH #9, step #2164] loss: 2.4928880882042934\n",
      "[EPOCH #9, step #2166] loss: 2.492891691882983\n",
      "[EPOCH #9, step #2168] loss: 2.4928033416751565\n",
      "[EPOCH #9, step #2170] loss: 2.4928190395174243\n",
      "[EPOCH #9, step #2172] loss: 2.49256649688812\n",
      "[EPOCH #9, step #2174] loss: 2.492827782466494\n",
      "[EPOCH #9, step #2176] loss: 2.492581772596178\n",
      "[EPOCH #9, step #2178] loss: 2.4928206652334493\n",
      "[EPOCH #9, step #2180] loss: 2.4926870416906217\n",
      "[EPOCH #9, step #2182] loss: 2.4925371920139594\n",
      "[EPOCH #9, step #2184] loss: 2.492517395914283\n",
      "[EPOCH #9, step #2186] loss: 2.4926586905515626\n",
      "[EPOCH #9, step #2188] loss: 2.492793804437072\n",
      "[EPOCH #9, step #2190] loss: 2.492989403208006\n",
      "[EPOCH #9, step #2192] loss: 2.492805007707567\n",
      "[EPOCH #9, step #2194] loss: 2.492750732230706\n",
      "[EPOCH #9, step #2196] loss: 2.492454851601522\n",
      "[EPOCH #9, step #2198] loss: 2.492187963772384\n",
      "[EPOCH #9, step #2200] loss: 2.4923938520384725\n",
      "[EPOCH #9, step #2202] loss: 2.492067870528818\n",
      "[EPOCH #9, step #2204] loss: 2.492064071999115\n",
      "[EPOCH #9, step #2206] loss: 2.4917987694176387\n",
      "[EPOCH #9, step #2208] loss: 2.4921011026221844\n",
      "[EPOCH #9, step #2210] loss: 2.4921148613209856\n",
      "[EPOCH #9, step #2212] loss: 2.492103216015695\n",
      "[EPOCH #9, step #2214] loss: 2.4920394220954947\n",
      "[EPOCH #9, step #2216] loss: 2.492026150253478\n",
      "[EPOCH #9, step #2218] loss: 2.4920363503031067\n",
      "[EPOCH #9, step #2220] loss: 2.4919122398463203\n",
      "[EPOCH #9, step #2222] loss: 2.4916229462012267\n",
      "[EPOCH #9, step #2224] loss: 2.4915541944075166\n",
      "[EPOCH #9, step #2226] loss: 2.491464519746966\n",
      "[EPOCH #9, step #2228] loss: 2.4915810444794624\n",
      "[EPOCH #9, step #2230] loss: 2.4913747865808538\n",
      "[EPOCH #9, step #2232] loss: 2.491600009127684\n",
      "[EPOCH #9, step #2234] loss: 2.4916448852893223\n",
      "[EPOCH #9, step #2236] loss: 2.4917463770816517\n",
      "[EPOCH #9, step #2238] loss: 2.491700800096632\n",
      "[EPOCH #9, step #2240] loss: 2.4915153831841956\n",
      "[EPOCH #9, step #2242] loss: 2.4915644923225875\n",
      "[EPOCH #9, step #2244] loss: 2.4910394332456693\n",
      "[EPOCH #9, step #2246] loss: 2.490926711730125\n",
      "[EPOCH #9, step #2248] loss: 2.4907620799652785\n",
      "[EPOCH #9, step #2250] loss: 2.4906041868418285\n",
      "[EPOCH #9, step #2252] loss: 2.4903471433370314\n",
      "[EPOCH #9, step #2254] loss: 2.49007600770557\n",
      "[EPOCH #9, step #2256] loss: 2.4903823895743846\n",
      "[EPOCH #9, step #2258] loss: 2.490533691372899\n",
      "[EPOCH #9, step #2260] loss: 2.490606621322986\n",
      "[EPOCH #9, step #2262] loss: 2.490132239609759\n",
      "[EPOCH #9, step #2264] loss: 2.490364572859758\n",
      "[EPOCH #9, step #2266] loss: 2.490542708328762\n",
      "[EPOCH #9, step #2268] loss: 2.49081592861384\n",
      "[EPOCH #9, step #2270] loss: 2.490755653601814\n",
      "[EPOCH #9, step #2272] loss: 2.4907351185768856\n",
      "[EPOCH #9, step #2274] loss: 2.4907343780077422\n",
      "[EPOCH #9, step #2276] loss: 2.490822684047617\n",
      "[EPOCH #9, step #2278] loss: 2.490922593871665\n",
      "[EPOCH #9, step #2280] loss: 2.4907807444125507\n",
      "[EPOCH #9, step #2282] loss: 2.490750114227459\n",
      "[EPOCH #9, step #2284] loss: 2.4906245360489225\n",
      "[EPOCH #9, step #2286] loss: 2.4900799401211957\n",
      "[EPOCH #9, step #2288] loss: 2.490133700802004\n",
      "[EPOCH #9, step #2290] loss: 2.490182629114465\n",
      "[EPOCH #9, step #2292] loss: 2.49018917008877\n",
      "[EPOCH #9, step #2294] loss: 2.490246797491003\n",
      "[EPOCH #9, step #2296] loss: 2.490042477054704\n",
      "[EPOCH #9, step #2298] loss: 2.4900939330270675\n",
      "[EPOCH #9, step #2300] loss: 2.48991515267574\n",
      "[EPOCH #9, step #2302] loss: 2.4898240083308516\n",
      "[EPOCH #9, step #2304] loss: 2.4898735995406445\n",
      "[EPOCH #9, step #2306] loss: 2.4901839918422657\n",
      "[EPOCH #9, step #2308] loss: 2.4897973244713727\n",
      "[EPOCH #9, step #2310] loss: 2.489641667598772\n",
      "[EPOCH #9, step #2312] loss: 2.4894174962037576\n",
      "[EPOCH #9, step #2314] loss: 2.4895523411666343\n",
      "[EPOCH #9, step #2316] loss: 2.4892852670116365\n",
      "[EPOCH #9, step #2318] loss: 2.48935072444646\n",
      "[EPOCH #9, step #2320] loss: 2.489234877629097\n",
      "[EPOCH #9, step #2322] loss: 2.48924505269276\n",
      "[EPOCH #9, step #2324] loss: 2.4894833379663446\n",
      "[EPOCH #9, step #2326] loss: 2.4894996343583164\n",
      "[EPOCH #9, step #2328] loss: 2.4894913541446586\n",
      "[EPOCH #9, step #2330] loss: 2.4895711362950026\n",
      "[EPOCH #9, step #2332] loss: 2.4895942932129724\n",
      "[EPOCH #9, step #2334] loss: 2.4890275870962366\n",
      "[EPOCH #9, step #2336] loss: 2.489058190091941\n",
      "[EPOCH #9, step #2338] loss: 2.4888516430061767\n",
      "[EPOCH #9, step #2340] loss: 2.48880240291879\n",
      "[EPOCH #9, step #2342] loss: 2.488547936240883\n",
      "[EPOCH #9, step #2344] loss: 2.48837420238869\n",
      "[EPOCH #9, step #2346] loss: 2.4883428455465744\n",
      "[EPOCH #9, step #2348] loss: 2.488432583224271\n",
      "[EPOCH #9, step #2350] loss: 2.4882351444001807\n",
      "[EPOCH #9, step #2352] loss: 2.4881062402757643\n",
      "[EPOCH #9, step #2354] loss: 2.4883833670059334\n",
      "[EPOCH #9, step #2356] loss: 2.4882975455609024\n",
      "[EPOCH #9, step #2358] loss: 2.488030744387266\n",
      "[EPOCH #9, step #2360] loss: 2.487907604714765\n",
      "[EPOCH #9, step #2362] loss: 2.4879645544040825\n",
      "[EPOCH #9, step #2364] loss: 2.487971138147673\n",
      "[EPOCH #9, step #2366] loss: 2.4877680462525773\n",
      "[EPOCH #9, step #2368] loss: 2.4878878443992907\n",
      "[EPOCH #9, step #2370] loss: 2.487595582752477\n",
      "[EPOCH #9, step #2372] loss: 2.4874168877555407\n",
      "[EPOCH #9, step #2374] loss: 2.4872692872599553\n",
      "[EPOCH #9, step #2376] loss: 2.487370308527788\n",
      "[EPOCH #9, step #2378] loss: 2.4873382275021343\n",
      "[EPOCH #9, step #2380] loss: 2.4873381083074713\n",
      "[EPOCH #9, step #2382] loss: 2.4871956163026985\n",
      "[EPOCH #9, step #2384] loss: 2.487141709007807\n",
      "[EPOCH #9, step #2386] loss: 2.4870701983327588\n",
      "[EPOCH #9, step #2388] loss: 2.4871761636686105\n",
      "[EPOCH #9, step #2390] loss: 2.486861760772855\n",
      "[EPOCH #9, step #2392] loss: 2.4866916033895854\n",
      "[EPOCH #9, step #2394] loss: 2.4866072535763704\n",
      "[EPOCH #9, step #2396] loss: 2.4868259064396274\n",
      "[EPOCH #9, step #2398] loss: 2.4866834706989813\n",
      "[EPOCH #9, step #2400] loss: 2.486415578791719\n",
      "[EPOCH #9, step #2402] loss: 2.486627360507443\n",
      "[EPOCH #9, step #2404] loss: 2.486679562659868\n",
      "[EPOCH #9, step #2406] loss: 2.4866174372291487\n",
      "[EPOCH #9, step #2408] loss: 2.486639100963914\n",
      "[EPOCH #9, step #2410] loss: 2.48650225288687\n",
      "[EPOCH #9, step #2412] loss: 2.486305910425467\n",
      "[EPOCH #9, step #2414] loss: 2.4862173037005753\n",
      "[EPOCH #9, step #2416] loss: 2.4858024105534455\n",
      "[EPOCH #9, step #2418] loss: 2.4858282954794357\n",
      "[EPOCH #9, step #2420] loss: 2.4858529989210254\n",
      "[EPOCH #9, step #2422] loss: 2.485779415316391\n",
      "[EPOCH #9, step #2424] loss: 2.4856384742382875\n",
      "[EPOCH #9, step #2426] loss: 2.4856965131213453\n",
      "[EPOCH #9, step #2428] loss: 2.4856644342248946\n",
      "[EPOCH #9, step #2430] loss: 2.4858567792169843\n",
      "[EPOCH #9, step #2432] loss: 2.4857720447772333\n",
      "[EPOCH #9, step #2434] loss: 2.486096604697758\n",
      "[EPOCH #9, step #2436] loss: 2.48606219798461\n",
      "[EPOCH #9, step #2438] loss: 2.486086419294388\n",
      "[EPOCH #9, step #2440] loss: 2.486222736564927\n",
      "[EPOCH #9, step #2442] loss: 2.486525261446047\n",
      "[EPOCH #9, step #2444] loss: 2.486619566115865\n",
      "[EPOCH #9, step #2446] loss: 2.4866935565708412\n",
      "[EPOCH #9, step #2448] loss: 2.486384514547358\n",
      "[EPOCH #9, step #2450] loss: 2.4863629043467044\n",
      "[EPOCH #9, step #2452] loss: 2.486292566807961\n",
      "[EPOCH #9, step #2454] loss: 2.486192913502151\n",
      "[EPOCH #9, step #2456] loss: 2.4860929602474324\n",
      "[EPOCH #9, step #2458] loss: 2.4860573259976495\n",
      "[EPOCH #9, step #2460] loss: 2.4859454300964523\n",
      "[EPOCH #9, step #2462] loss: 2.485913891594825\n",
      "[EPOCH #9, step #2464] loss: 2.4858320000689123\n",
      "[EPOCH #9, step #2466] loss: 2.4859935606738843\n",
      "[EPOCH #9, step #2468] loss: 2.485798755460734\n",
      "[EPOCH #9, step #2470] loss: 2.4856891446343226\n",
      "[EPOCH #9, step #2472] loss: 2.4854604990145863\n",
      "[EPOCH #9, step #2474] loss: 2.4856171634462143\n",
      "[EPOCH #9, step #2476] loss: 2.485475828871883\n",
      "[EPOCH #9, step #2478] loss: 2.485392029653782\n",
      "[EPOCH #9, step #2480] loss: 2.485256122562588\n",
      "[EPOCH #9, step #2482] loss: 2.4850699562148804\n",
      "[EPOCH #9, step #2484] loss: 2.48504545995647\n",
      "[EPOCH #9, step #2486] loss: 2.484992236605983\n",
      "[EPOCH #9, step #2488] loss: 2.4851522089822935\n",
      "[EPOCH #9, step #2490] loss: 2.485020187043703\n",
      "[EPOCH #9, step #2492] loss: 2.4847742463516225\n",
      "[EPOCH #9, step #2494] loss: 2.4848516066232045\n",
      "[EPOCH #9, step #2496] loss: 2.484787231404446\n",
      "[EPOCH #9, step #2498] loss: 2.485076842712564\n",
      "[EPOCH #9, elapsed time: 4621.367[sec]] loss: 2.485195212507248\n",
      "[EPOCH #10, step #0] loss: 2.8415679931640625\n",
      "[EPOCH #10, step #2] loss: 2.722128391265869\n",
      "[EPOCH #10, step #4] loss: 2.5095088958740233\n",
      "[EPOCH #10, step #6] loss: 2.5273567949022566\n",
      "[EPOCH #10, step #8] loss: 2.5358955330318875\n",
      "[EPOCH #10, step #10] loss: 2.5192507830533115\n",
      "[EPOCH #10, step #12] loss: 2.497685725872333\n",
      "[EPOCH #10, step #14] loss: 2.4810619831085203\n",
      "[EPOCH #10, step #16] loss: 2.4752280712127686\n",
      "[EPOCH #10, step #18] loss: 2.4546410347286023\n",
      "[EPOCH #10, step #20] loss: 2.4349854503359114\n",
      "[EPOCH #10, step #22] loss: 2.4400190425955732\n",
      "[EPOCH #10, step #24] loss: 2.4503724336624146\n",
      "[EPOCH #10, step #26] loss: 2.45135728959684\n",
      "[EPOCH #10, step #28] loss: 2.482723889679744\n",
      "[EPOCH #10, step #30] loss: 2.4921194545684324\n",
      "[EPOCH #10, step #32] loss: 2.484887133945118\n",
      "[EPOCH #10, step #34] loss: 2.4849472761154177\n",
      "[EPOCH #10, step #36] loss: 2.4754182680233106\n",
      "[EPOCH #10, step #38] loss: 2.4775021779231534\n",
      "[EPOCH #10, step #40] loss: 2.452220945823483\n",
      "[EPOCH #10, step #42] loss: 2.4457750431326932\n",
      "[EPOCH #10, step #44] loss: 2.4388161341349286\n",
      "[EPOCH #10, step #46] loss: 2.4404511400993836\n",
      "[EPOCH #10, step #48] loss: 2.442416166772648\n",
      "[EPOCH #10, step #50] loss: 2.4551158231847428\n",
      "[EPOCH #10, step #52] loss: 2.4499673978337704\n",
      "[EPOCH #10, step #54] loss: 2.4406173445961694\n",
      "[EPOCH #10, step #56] loss: 2.440441503859403\n",
      "[EPOCH #10, step #58] loss: 2.434422183845003\n",
      "[EPOCH #10, step #60] loss: 2.443745517339863\n",
      "[EPOCH #10, step #62] loss: 2.4431593853329856\n",
      "[EPOCH #10, step #64] loss: 2.452015940959637\n",
      "[EPOCH #10, step #66] loss: 2.452750908794688\n",
      "[EPOCH #10, step #68] loss: 2.4540433589962944\n",
      "[EPOCH #10, step #70] loss: 2.451836372765017\n",
      "[EPOCH #10, step #72] loss: 2.4622025081556136\n",
      "[EPOCH #10, step #74] loss: 2.453683025042216\n",
      "[EPOCH #10, step #76] loss: 2.4600746213615716\n",
      "[EPOCH #10, step #78] loss: 2.461057217815254\n",
      "[EPOCH #10, step #80] loss: 2.464311898490529\n",
      "[EPOCH #10, step #82] loss: 2.464340087879135\n",
      "[EPOCH #10, step #84] loss: 2.461663511220147\n",
      "[EPOCH #10, step #86] loss: 2.4599915551043106\n",
      "[EPOCH #10, step #88] loss: 2.457975595184926\n",
      "[EPOCH #10, step #90] loss: 2.445807763508388\n",
      "[EPOCH #10, step #92] loss: 2.451510465273293\n",
      "[EPOCH #10, step #94] loss: 2.4502593793367087\n",
      "[EPOCH #10, step #96] loss: 2.4529193701203336\n",
      "[EPOCH #10, step #98] loss: 2.4456217577963164\n",
      "[EPOCH #10, step #100] loss: 2.443980830730778\n",
      "[EPOCH #10, step #102] loss: 2.4415101449466445\n",
      "[EPOCH #10, step #104] loss: 2.4380269572848365\n",
      "[EPOCH #10, step #106] loss: 2.4388511225441905\n",
      "[EPOCH #10, step #108] loss: 2.4399508511254546\n",
      "[EPOCH #10, step #110] loss: 2.444104033547479\n",
      "[EPOCH #10, step #112] loss: 2.449706605050416\n",
      "[EPOCH #10, step #114] loss: 2.4529653341873834\n",
      "[EPOCH #10, step #116] loss: 2.447718214784932\n",
      "[EPOCH #10, step #118] loss: 2.44946253399889\n",
      "[EPOCH #10, step #120] loss: 2.4417304027179054\n",
      "[EPOCH #10, step #122] loss: 2.444980753146536\n",
      "[EPOCH #10, step #124] loss: 2.4443636474609374\n",
      "[EPOCH #10, step #126] loss: 2.4477111035444605\n",
      "[EPOCH #10, step #128] loss: 2.451507387235183\n",
      "[EPOCH #10, step #130] loss: 2.4526178673023487\n",
      "[EPOCH #10, step #132] loss: 2.452108465639272\n",
      "[EPOCH #10, step #134] loss: 2.453296403531675\n",
      "[EPOCH #10, step #136] loss: 2.4555045566419613\n",
      "[EPOCH #10, step #138] loss: 2.4537875034826264\n",
      "[EPOCH #10, step #140] loss: 2.453423688597713\n",
      "[EPOCH #10, step #142] loss: 2.4560774147927344\n",
      "[EPOCH #10, step #144] loss: 2.4571887764437443\n",
      "[EPOCH #10, step #146] loss: 2.4569331212919585\n",
      "[EPOCH #10, step #148] loss: 2.4530186805149055\n",
      "[EPOCH #10, step #150] loss: 2.44975768098768\n",
      "[EPOCH #10, step #152] loss: 2.443639628248277\n",
      "[EPOCH #10, step #154] loss: 2.442384200711404\n",
      "[EPOCH #10, step #156] loss: 2.450052729837454\n",
      "[EPOCH #10, step #158] loss: 2.4507554184715703\n",
      "[EPOCH #10, step #160] loss: 2.448708534981153\n",
      "[EPOCH #10, step #162] loss: 2.452060608044724\n",
      "[EPOCH #10, step #164] loss: 2.4558889656355887\n",
      "[EPOCH #10, step #166] loss: 2.4565046540277446\n",
      "[EPOCH #10, step #168] loss: 2.454242241453137\n",
      "[EPOCH #10, step #170] loss: 2.4550519442697714\n",
      "[EPOCH #10, step #172] loss: 2.4521572334917985\n",
      "[EPOCH #10, step #174] loss: 2.4488337414605277\n",
      "[EPOCH #10, step #176] loss: 2.4446351568577653\n",
      "[EPOCH #10, step #178] loss: 2.4441837292143753\n",
      "[EPOCH #10, step #180] loss: 2.445341007485574\n",
      "[EPOCH #10, step #182] loss: 2.4473468449597804\n",
      "[EPOCH #10, step #184] loss: 2.4444511233149346\n",
      "[EPOCH #10, step #186] loss: 2.446084934122422\n",
      "[EPOCH #10, step #188] loss: 2.4481802983258767\n",
      "[EPOCH #10, step #190] loss: 2.4469412796160315\n",
      "[EPOCH #10, step #192] loss: 2.4463944558652573\n",
      "[EPOCH #10, step #194] loss: 2.4475153495103883\n",
      "[EPOCH #10, step #196] loss: 2.4465632922758305\n",
      "[EPOCH #10, step #198] loss: 2.447257021563736\n",
      "[EPOCH #10, step #200] loss: 2.4458021002622385\n",
      "[EPOCH #10, step #202] loss: 2.443923563792788\n",
      "[EPOCH #10, step #204] loss: 2.44432855466517\n",
      "[EPOCH #10, step #206] loss: 2.4440993203057184\n",
      "[EPOCH #10, step #208] loss: 2.4469939179397655\n",
      "[EPOCH #10, step #210] loss: 2.448504808389745\n",
      "[EPOCH #10, step #212] loss: 2.4455202336602366\n",
      "[EPOCH #10, step #214] loss: 2.445930039050967\n",
      "[EPOCH #10, step #216] loss: 2.4442911307383244\n",
      "[EPOCH #10, step #218] loss: 2.446857375641392\n",
      "[EPOCH #10, step #220] loss: 2.4460224301566904\n",
      "[EPOCH #10, step #222] loss: 2.44504459075329\n",
      "[EPOCH #10, step #224] loss: 2.4438537708918253\n",
      "[EPOCH #10, step #226] loss: 2.441100615236728\n",
      "[EPOCH #10, step #228] loss: 2.4399714636490333\n",
      "[EPOCH #10, step #230] loss: 2.4396506769832595\n",
      "[EPOCH #10, step #232] loss: 2.4390694102504225\n",
      "[EPOCH #10, step #234] loss: 2.4380665657368112\n",
      "[EPOCH #10, step #236] loss: 2.4366381711597684\n",
      "[EPOCH #10, step #238] loss: 2.4355491704023033\n",
      "[EPOCH #10, step #240] loss: 2.435017523429206\n",
      "[EPOCH #10, step #242] loss: 2.436529439172627\n",
      "[EPOCH #10, step #244] loss: 2.437711761435684\n",
      "[EPOCH #10, step #246] loss: 2.4337939873398073\n",
      "[EPOCH #10, step #248] loss: 2.4321362986622086\n",
      "[EPOCH #10, step #250] loss: 2.4361716784329053\n",
      "[EPOCH #10, step #252] loss: 2.436358248763405\n",
      "[EPOCH #10, step #254] loss: 2.435757659930809\n",
      "[EPOCH #10, step #256] loss: 2.4330935993083256\n",
      "[EPOCH #10, step #258] loss: 2.4322949878037208\n",
      "[EPOCH #10, step #260] loss: 2.4322854828560487\n",
      "[EPOCH #10, step #262] loss: 2.4338007675830857\n",
      "[EPOCH #10, step #264] loss: 2.4353231335585974\n",
      "[EPOCH #10, step #266] loss: 2.4349044275640996\n",
      "[EPOCH #10, step #268] loss: 2.4337411595986236\n",
      "[EPOCH #10, step #270] loss: 2.435093409460849\n",
      "[EPOCH #10, step #272] loss: 2.4356887676776986\n",
      "[EPOCH #10, step #274] loss: 2.4365692862597377\n",
      "[EPOCH #10, step #276] loss: 2.436439203871717\n",
      "[EPOCH #10, step #278] loss: 2.4341696107686634\n",
      "[EPOCH #10, step #280] loss: 2.4341038304291587\n",
      "[EPOCH #10, step #282] loss: 2.434013684731069\n",
      "[EPOCH #10, step #284] loss: 2.4385243763003435\n",
      "[EPOCH #10, step #286] loss: 2.437290638996749\n",
      "[EPOCH #10, step #288] loss: 2.436329809852125\n",
      "[EPOCH #10, step #290] loss: 2.4366059012429413\n",
      "[EPOCH #10, step #292] loss: 2.436442375589963\n",
      "[EPOCH #10, step #294] loss: 2.4365307593749743\n",
      "[EPOCH #10, step #296] loss: 2.4352141185240312\n",
      "[EPOCH #10, step #298] loss: 2.435469847060366\n",
      "[EPOCH #10, step #300] loss: 2.4349820689109474\n",
      "[EPOCH #10, step #302] loss: 2.4351055342765533\n",
      "[EPOCH #10, step #304] loss: 2.4346392283674145\n",
      "[EPOCH #10, step #306] loss: 2.4355803176712136\n",
      "[EPOCH #10, step #308] loss: 2.433335996754347\n",
      "[EPOCH #10, step #310] loss: 2.4313666322223626\n",
      "[EPOCH #10, step #312] loss: 2.4318184037558948\n",
      "[EPOCH #10, step #314] loss: 2.4318238455151753\n",
      "[EPOCH #10, step #316] loss: 2.4301195392849317\n",
      "[EPOCH #10, step #318] loss: 2.4306730192656802\n",
      "[EPOCH #10, step #320] loss: 2.429745466166939\n",
      "[EPOCH #10, step #322] loss: 2.429102751492716\n",
      "[EPOCH #10, step #324] loss: 2.4266328404499933\n",
      "[EPOCH #10, step #326] loss: 2.4283783490504693\n",
      "[EPOCH #10, step #328] loss: 2.4275772365030908\n",
      "[EPOCH #10, step #330] loss: 2.427223159107197\n",
      "[EPOCH #10, step #332] loss: 2.4255198376314775\n",
      "[EPOCH #10, step #334] loss: 2.425514015155052\n",
      "[EPOCH #10, step #336] loss: 2.423580848498585\n",
      "[EPOCH #10, step #338] loss: 2.4226388991054884\n",
      "[EPOCH #10, step #340] loss: 2.420920010535948\n",
      "[EPOCH #10, step #342] loss: 2.4221986806774973\n",
      "[EPOCH #10, step #344] loss: 2.4225270146908966\n",
      "[EPOCH #10, step #346] loss: 2.423839807510376\n",
      "[EPOCH #10, step #348] loss: 2.4230255383816695\n",
      "[EPOCH #10, step #350] loss: 2.4244832612170795\n",
      "[EPOCH #10, step #352] loss: 2.424211578396157\n",
      "[EPOCH #10, step #354] loss: 2.425283180827826\n",
      "[EPOCH #10, step #356] loss: 2.4268980907792805\n",
      "[EPOCH #10, step #358] loss: 2.42730257371674\n",
      "[EPOCH #10, step #360] loss: 2.4280910307020362\n",
      "[EPOCH #10, step #362] loss: 2.4269977417202364\n",
      "[EPOCH #10, step #364] loss: 2.425251322903045\n",
      "[EPOCH #10, step #366] loss: 2.426058640921798\n",
      "[EPOCH #10, step #368] loss: 2.4256770626962347\n",
      "[EPOCH #10, step #370] loss: 2.4276693108268184\n",
      "[EPOCH #10, step #372] loss: 2.428545664526502\n",
      "[EPOCH #10, step #374] loss: 2.4263842776616413\n",
      "[EPOCH #10, step #376] loss: 2.425717770895212\n",
      "[EPOCH #10, step #378] loss: 2.4243014962817875\n",
      "[EPOCH #10, step #380] loss: 2.4237813758724944\n",
      "[EPOCH #10, step #382] loss: 2.4225730587857197\n",
      "[EPOCH #10, step #384] loss: 2.4231407428716683\n",
      "[EPOCH #10, step #386] loss: 2.4232815892197364\n",
      "[EPOCH #10, step #388] loss: 2.424818903437617\n",
      "[EPOCH #10, step #390] loss: 2.423896932540952\n",
      "[EPOCH #10, step #392] loss: 2.423049782068675\n",
      "[EPOCH #10, step #394] loss: 2.4232497628731062\n",
      "[EPOCH #10, step #396] loss: 2.423455931077376\n",
      "[EPOCH #10, step #398] loss: 2.4221117024433645\n",
      "[EPOCH #10, step #400] loss: 2.4205589086337578\n",
      "[EPOCH #10, step #402] loss: 2.418597875990288\n",
      "[EPOCH #10, step #404] loss: 2.417747182904938\n",
      "[EPOCH #10, step #406] loss: 2.4172755772710137\n",
      "[EPOCH #10, step #408] loss: 2.4183288556147904\n",
      "[EPOCH #10, step #410] loss: 2.4179631367217014\n",
      "[EPOCH #10, step #412] loss: 2.418528910987891\n",
      "[EPOCH #10, step #414] loss: 2.420444327377411\n",
      "[EPOCH #10, step #416] loss: 2.4191417270998876\n",
      "[EPOCH #10, step #418] loss: 2.4202472054019464\n",
      "[EPOCH #10, step #420] loss: 2.419237675972619\n",
      "[EPOCH #10, step #422] loss: 2.419654857464152\n",
      "[EPOCH #10, step #424] loss: 2.419421298644122\n",
      "[EPOCH #10, step #426] loss: 2.41844585740315\n",
      "[EPOCH #10, step #428] loss: 2.418865109934951\n",
      "[EPOCH #10, step #430] loss: 2.4205173395072777\n",
      "[EPOCH #10, step #432] loss: 2.4209668878594943\n",
      "[EPOCH #10, step #434] loss: 2.421045718247863\n",
      "[EPOCH #10, step #436] loss: 2.4204672152172235\n",
      "[EPOCH #10, step #438] loss: 2.4217340294483853\n",
      "[EPOCH #10, step #440] loss: 2.421728999706623\n",
      "[EPOCH #10, step #442] loss: 2.4206417048219633\n",
      "[EPOCH #10, step #444] loss: 2.4195073524217925\n",
      "[EPOCH #10, step #446] loss: 2.419879918663827\n",
      "[EPOCH #10, step #448] loss: 2.419578961646371\n",
      "[EPOCH #10, step #450] loss: 2.419050436590833\n",
      "[EPOCH #10, step #452] loss: 2.41878081946973\n",
      "[EPOCH #10, step #454] loss: 2.4176696541545155\n",
      "[EPOCH #10, step #456] loss: 2.4195300275439506\n",
      "[EPOCH #10, step #458] loss: 2.418293265735402\n",
      "[EPOCH #10, step #460] loss: 2.417753223741908\n",
      "[EPOCH #10, step #462] loss: 2.417266605224774\n",
      "[EPOCH #10, step #464] loss: 2.419452553410684\n",
      "[EPOCH #10, step #466] loss: 2.4195521761058996\n",
      "[EPOCH #10, step #468] loss: 2.418492500970104\n",
      "[EPOCH #10, step #470] loss: 2.4186016371801906\n",
      "[EPOCH #10, step #472] loss: 2.418082215317208\n",
      "[EPOCH #10, step #474] loss: 2.4180258688173795\n",
      "[EPOCH #10, step #476] loss: 2.417217688740424\n",
      "[EPOCH #10, step #478] loss: 2.417915725757782\n",
      "[EPOCH #10, step #480] loss: 2.417309370209422\n",
      "[EPOCH #10, step #482] loss: 2.417596735816071\n",
      "[EPOCH #10, step #484] loss: 2.417528993813033\n",
      "[EPOCH #10, step #486] loss: 2.4185881827646214\n",
      "[EPOCH #10, step #488] loss: 2.419115476813053\n",
      "[EPOCH #10, step #490] loss: 2.418840295428414\n",
      "[EPOCH #10, step #492] loss: 2.4185425758845422\n",
      "[EPOCH #10, step #494] loss: 2.4176008332859387\n",
      "[EPOCH #10, step #496] loss: 2.416682382224791\n",
      "[EPOCH #10, step #498] loss: 2.416357463490748\n",
      "[EPOCH #10, step #500] loss: 2.4160070707222183\n",
      "[EPOCH #10, step #502] loss: 2.41681126974686\n",
      "[EPOCH #10, step #504] loss: 2.4151050935877434\n",
      "[EPOCH #10, step #506] loss: 2.4144013238376414\n",
      "[EPOCH #10, step #508] loss: 2.4135113057546858\n",
      "[EPOCH #10, step #510] loss: 2.414096481412824\n",
      "[EPOCH #10, step #512] loss: 2.414591033556308\n",
      "[EPOCH #10, step #514] loss: 2.4146192374738673\n",
      "[EPOCH #10, step #516] loss: 2.4144581074410296\n",
      "[EPOCH #10, step #518] loss: 2.4159031295592617\n",
      "[EPOCH #10, step #520] loss: 2.4161297680091494\n",
      "[EPOCH #10, step #522] loss: 2.4154857718465887\n",
      "[EPOCH #10, step #524] loss: 2.4157009020305815\n",
      "[EPOCH #10, step #526] loss: 2.4152007577993837\n",
      "[EPOCH #10, step #528] loss: 2.416404484350424\n",
      "[EPOCH #10, step #530] loss: 2.416811336007271\n",
      "[EPOCH #10, step #532] loss: 2.416500313867995\n",
      "[EPOCH #10, step #534] loss: 2.415247897567036\n",
      "[EPOCH #10, step #536] loss: 2.4146632957280905\n",
      "[EPOCH #10, step #538] loss: 2.415194556531747\n",
      "[EPOCH #10, step #540] loss: 2.4142182953035984\n",
      "[EPOCH #10, step #542] loss: 2.4148365941934604\n",
      "[EPOCH #10, step #544] loss: 2.413921951591422\n",
      "[EPOCH #10, step #546] loss: 2.4148966150266378\n",
      "[EPOCH #10, step #548] loss: 2.4147441348091503\n",
      "[EPOCH #10, step #550] loss: 2.4143659410805536\n",
      "[EPOCH #10, step #552] loss: 2.41291343001733\n",
      "[EPOCH #10, step #554] loss: 2.412577838725872\n",
      "[EPOCH #10, step #556] loss: 2.4123530751712874\n",
      "[EPOCH #10, step #558] loss: 2.413032338103156\n",
      "[EPOCH #10, step #560] loss: 2.4144809921795036\n",
      "[EPOCH #10, step #562] loss: 2.4146527689261292\n",
      "[EPOCH #10, step #564] loss: 2.4148107836731767\n",
      "[EPOCH #10, step #566] loss: 2.414578915903808\n",
      "[EPOCH #10, step #568] loss: 2.414133134751412\n",
      "[EPOCH #10, step #570] loss: 2.413298530879246\n",
      "[EPOCH #10, step #572] loss: 2.4123211799491764\n",
      "[EPOCH #10, step #574] loss: 2.4116397536319236\n",
      "[EPOCH #10, step #576] loss: 2.411698710980407\n",
      "[EPOCH #10, step #578] loss: 2.4133100066983846\n",
      "[EPOCH #10, step #580] loss: 2.4130690017788834\n",
      "[EPOCH #10, step #582] loss: 2.4131549036523285\n",
      "[EPOCH #10, step #584] loss: 2.413035190411103\n",
      "[EPOCH #10, step #586] loss: 2.413075181653999\n",
      "[EPOCH #10, step #588] loss: 2.4122636658226493\n",
      "[EPOCH #10, step #590] loss: 2.4133491116731904\n",
      "[EPOCH #10, step #592] loss: 2.4137609949803474\n",
      "[EPOCH #10, step #594] loss: 2.414535206706584\n",
      "[EPOCH #10, step #596] loss: 2.4143900671596303\n",
      "[EPOCH #10, step #598] loss: 2.4140485945050427\n",
      "[EPOCH #10, step #600] loss: 2.41518903730713\n",
      "[EPOCH #10, step #602] loss: 2.415643175640707\n",
      "[EPOCH #10, step #604] loss: 2.4145828530808124\n",
      "[EPOCH #10, step #606] loss: 2.414929950060522\n",
      "[EPOCH #10, step #608] loss: 2.414927001852903\n",
      "[EPOCH #10, step #610] loss: 2.414970938390679\n",
      "[EPOCH #10, step #612] loss: 2.4144561010706096\n",
      "[EPOCH #10, step #614] loss: 2.4147923163282194\n",
      "[EPOCH #10, step #616] loss: 2.415854239579731\n",
      "[EPOCH #10, step #618] loss: 2.4139596154501057\n",
      "[EPOCH #10, step #620] loss: 2.414233566866213\n",
      "[EPOCH #10, step #622] loss: 2.413485961205313\n",
      "[EPOCH #10, step #624] loss: 2.4126765970230104\n",
      "[EPOCH #10, step #626] loss: 2.4124470496672004\n",
      "[EPOCH #10, step #628] loss: 2.410704589420737\n",
      "[EPOCH #10, step #630] loss: 2.411388716304737\n",
      "[EPOCH #10, step #632] loss: 2.4118921223786582\n",
      "[EPOCH #10, step #634] loss: 2.412310355667054\n",
      "[EPOCH #10, step #636] loss: 2.4122137602307547\n",
      "[EPOCH #10, step #638] loss: 2.4117682314068314\n",
      "[EPOCH #10, step #640] loss: 2.4113668597618614\n",
      "[EPOCH #10, step #642] loss: 2.4109377010057726\n",
      "[EPOCH #10, step #644] loss: 2.410315751105316\n",
      "[EPOCH #10, step #646] loss: 2.4091257479680928\n",
      "[EPOCH #10, step #648] loss: 2.4086364695030293\n",
      "[EPOCH #10, step #650] loss: 2.4072783581122823\n",
      "[EPOCH #10, step #652] loss: 2.406532818471491\n",
      "[EPOCH #10, step #654] loss: 2.405944578884212\n",
      "[EPOCH #10, step #656] loss: 2.4062656532502427\n",
      "[EPOCH #10, step #658] loss: 2.4063526527653694\n",
      "[EPOCH #10, step #660] loss: 2.406309142956755\n",
      "[EPOCH #10, step #662] loss: 2.405904099772239\n",
      "[EPOCH #10, step #664] loss: 2.4047661015861914\n",
      "[EPOCH #10, step #666] loss: 2.4058985561802646\n",
      "[EPOCH #10, step #668] loss: 2.407675150620385\n",
      "[EPOCH #10, step #670] loss: 2.407704133568151\n",
      "[EPOCH #10, step #672] loss: 2.407297941586238\n",
      "[EPOCH #10, step #674] loss: 2.4076114479700723\n",
      "[EPOCH #10, step #676] loss: 2.407947855298593\n",
      "[EPOCH #10, step #678] loss: 2.4068310027269972\n",
      "[EPOCH #10, step #680] loss: 2.407319333409773\n",
      "[EPOCH #10, step #682] loss: 2.40635396830334\n",
      "[EPOCH #10, step #684] loss: 2.4065617679679483\n",
      "[EPOCH #10, step #686] loss: 2.40698080673662\n",
      "[EPOCH #10, step #688] loss: 2.406283863743089\n",
      "[EPOCH #10, step #690] loss: 2.405939439961258\n",
      "[EPOCH #10, step #692] loss: 2.405764306606496\n",
      "[EPOCH #10, step #694] loss: 2.405332032210535\n",
      "[EPOCH #10, step #696] loss: 2.4045111929498066\n",
      "[EPOCH #10, step #698] loss: 2.4050304270609253\n",
      "[EPOCH #10, step #700] loss: 2.405049441884486\n",
      "[EPOCH #10, step #702] loss: 2.405323204410873\n",
      "[EPOCH #10, step #704] loss: 2.405709022664009\n",
      "[EPOCH #10, step #706] loss: 2.4054310755142905\n",
      "[EPOCH #10, step #708] loss: 2.4048965923876957\n",
      "[EPOCH #10, step #710] loss: 2.4039643878842876\n",
      "[EPOCH #10, step #712] loss: 2.4040217300952733\n",
      "[EPOCH #10, step #714] loss: 2.403548554273752\n",
      "[EPOCH #10, step #716] loss: 2.4041613330402134\n",
      "[EPOCH #10, step #718] loss: 2.4042013157392246\n",
      "[EPOCH #10, step #720] loss: 2.402875594226398\n",
      "[EPOCH #10, step #722] loss: 2.4013553961678658\n",
      "[EPOCH #10, step #724] loss: 2.4009371038963057\n",
      "[EPOCH #10, step #726] loss: 2.4008041066021506\n",
      "[EPOCH #10, step #728] loss: 2.4007381351232855\n",
      "[EPOCH #10, step #730] loss: 2.4020054707285805\n",
      "[EPOCH #10, step #732] loss: 2.4020987475877895\n",
      "[EPOCH #10, step #734] loss: 2.4016423716837045\n",
      "[EPOCH #10, step #736] loss: 2.4014411394761086\n",
      "[EPOCH #10, step #738] loss: 2.4003925710634224\n",
      "[EPOCH #10, step #740] loss: 2.4026037729703464\n",
      "[EPOCH #10, step #742] loss: 2.4025826046636896\n",
      "[EPOCH #10, step #744] loss: 2.403287955098504\n",
      "[EPOCH #10, step #746] loss: 2.403195568516232\n",
      "[EPOCH #10, step #748] loss: 2.402848145672094\n",
      "[EPOCH #10, step #750] loss: 2.402761146009524\n",
      "[EPOCH #10, step #752] loss: 2.4019159973063475\n",
      "[EPOCH #10, step #754] loss: 2.401533047726612\n",
      "[EPOCH #10, step #756] loss: 2.401600268431982\n",
      "[EPOCH #10, step #758] loss: 2.4015185281693228\n",
      "[EPOCH #10, step #760] loss: 2.4018177968913714\n",
      "[EPOCH #10, step #762] loss: 2.402350564302967\n",
      "[EPOCH #10, step #764] loss: 2.402151744973426\n",
      "[EPOCH #10, step #766] loss: 2.4018275761075873\n",
      "[EPOCH #10, step #768] loss: 2.4023133624824653\n",
      "[EPOCH #10, step #770] loss: 2.401652208252794\n",
      "[EPOCH #10, step #772] loss: 2.401606072892193\n",
      "[EPOCH #10, step #774] loss: 2.4013810183925015\n",
      "[EPOCH #10, step #776] loss: 2.40185314700717\n",
      "[EPOCH #10, step #778] loss: 2.4023477114517053\n",
      "[EPOCH #10, step #780] loss: 2.4025732904634465\n",
      "[EPOCH #10, step #782] loss: 2.4023904171635517\n",
      "[EPOCH #10, step #784] loss: 2.402192084956321\n",
      "[EPOCH #10, step #786] loss: 2.4027519469945826\n",
      "[EPOCH #10, step #788] loss: 2.402966559915337\n",
      "[EPOCH #10, step #790] loss: 2.402295361125816\n",
      "[EPOCH #10, step #792] loss: 2.4023473557427732\n",
      "[EPOCH #10, step #794] loss: 2.4029043350579604\n",
      "[EPOCH #10, step #796] loss: 2.4019370309382193\n",
      "[EPOCH #10, step #798] loss: 2.4017913627982588\n",
      "[EPOCH #10, step #800] loss: 2.401471554414461\n",
      "[EPOCH #10, step #802] loss: 2.401939618038211\n",
      "[EPOCH #10, step #804] loss: 2.4022415712013006\n",
      "[EPOCH #10, step #806] loss: 2.402910570820616\n",
      "[EPOCH #10, step #808] loss: 2.4036203176335733\n",
      "[EPOCH #10, step #810] loss: 2.4033223727187454\n",
      "[EPOCH #10, step #812] loss: 2.4046533984598346\n",
      "[EPOCH #10, step #814] loss: 2.404535440725783\n",
      "[EPOCH #10, step #816] loss: 2.4048452844234545\n",
      "[EPOCH #10, step #818] loss: 2.4042588802775473\n",
      "[EPOCH #10, step #820] loss: 2.4043771465571004\n",
      "[EPOCH #10, step #822] loss: 2.404055097413092\n",
      "[EPOCH #10, step #824] loss: 2.4036415337071273\n",
      "[EPOCH #10, step #826] loss: 2.4044241118171628\n",
      "[EPOCH #10, step #828] loss: 2.405076320841459\n",
      "[EPOCH #10, step #830] loss: 2.4053307753033875\n",
      "[EPOCH #10, step #832] loss: 2.4051133284047874\n",
      "[EPOCH #10, step #834] loss: 2.404869948175853\n",
      "[EPOCH #10, step #836] loss: 2.404565540265866\n",
      "[EPOCH #10, step #838] loss: 2.4044788065627305\n",
      "[EPOCH #10, step #840] loss: 2.4050778390111027\n",
      "[EPOCH #10, step #842] loss: 2.4045765009639104\n",
      "[EPOCH #10, step #844] loss: 2.404283171997973\n",
      "[EPOCH #10, step #846] loss: 2.403401657850993\n",
      "[EPOCH #10, step #848] loss: 2.4027722939164393\n",
      "[EPOCH #10, step #850] loss: 2.4024512559070432\n",
      "[EPOCH #10, step #852] loss: 2.4026075864313357\n",
      "[EPOCH #10, step #854] loss: 2.4022148055639883\n",
      "[EPOCH #10, step #856] loss: 2.402124597839881\n",
      "[EPOCH #10, step #858] loss: 2.4023639613174863\n",
      "[EPOCH #10, step #860] loss: 2.402615889578054\n",
      "[EPOCH #10, step #862] loss: 2.402943870421771\n",
      "[EPOCH #10, step #864] loss: 2.40278372488959\n",
      "[EPOCH #10, step #866] loss: 2.4028989105488603\n",
      "[EPOCH #10, step #868] loss: 2.402051031658098\n",
      "[EPOCH #10, step #870] loss: 2.402055827813088\n",
      "[EPOCH #10, step #872] loss: 2.4014163108762325\n",
      "[EPOCH #10, step #874] loss: 2.4014143490110125\n",
      "[EPOCH #10, step #876] loss: 2.4013117286743024\n",
      "[EPOCH #10, step #878] loss: 2.40128153528641\n",
      "[EPOCH #10, step #880] loss: 2.4012948514113495\n",
      "[EPOCH #10, step #882] loss: 2.4008800845724\n",
      "[EPOCH #10, step #884] loss: 2.4010897579839674\n",
      "[EPOCH #10, step #886] loss: 2.4012220096695653\n",
      "[EPOCH #10, step #888] loss: 2.401077183615102\n",
      "[EPOCH #10, step #890] loss: 2.401365398691693\n",
      "[EPOCH #10, step #892] loss: 2.400823297853032\n",
      "[EPOCH #10, step #894] loss: 2.400529021790574\n",
      "[EPOCH #10, step #896] loss: 2.4002518853216266\n",
      "[EPOCH #10, step #898] loss: 2.4003841789466254\n",
      "[EPOCH #10, step #900] loss: 2.400607938110233\n",
      "[EPOCH #10, step #902] loss: 2.400349340037518\n",
      "[EPOCH #10, step #904] loss: 2.400466082240995\n",
      "[EPOCH #10, step #906] loss: 2.399928522215131\n",
      "[EPOCH #10, step #908] loss: 2.3996357707956313\n",
      "[EPOCH #10, step #910] loss: 2.399193120185944\n",
      "[EPOCH #10, step #912] loss: 2.398579750760884\n",
      "[EPOCH #10, step #914] loss: 2.3992338514067435\n",
      "[EPOCH #10, step #916] loss: 2.3991294011164905\n",
      "[EPOCH #10, step #918] loss: 2.3992912585120467\n",
      "[EPOCH #10, step #920] loss: 2.399344459548188\n",
      "[EPOCH #10, step #922] loss: 2.399706660732546\n",
      "[EPOCH #10, step #924] loss: 2.398726154920217\n",
      "[EPOCH #10, step #926] loss: 2.398546253207432\n",
      "[EPOCH #10, step #928] loss: 2.397967837855172\n",
      "[EPOCH #10, step #930] loss: 2.396882190740198\n",
      "[EPOCH #10, step #932] loss: 2.39737705006349\n",
      "[EPOCH #10, step #934] loss: 2.396969627569066\n",
      "[EPOCH #10, step #936] loss: 2.397492632285762\n",
      "[EPOCH #10, step #938] loss: 2.3976804899077573\n",
      "[EPOCH #10, step #940] loss: 2.397485212995953\n",
      "[EPOCH #10, step #942] loss: 2.397409623273483\n",
      "[EPOCH #10, step #944] loss: 2.3975933197314148\n",
      "[EPOCH #10, step #946] loss: 2.397189728058127\n",
      "[EPOCH #10, step #948] loss: 2.396738688862864\n",
      "[EPOCH #10, step #950] loss: 2.3960993582016537\n",
      "[EPOCH #10, step #952] loss: 2.395500594521369\n",
      "[EPOCH #10, step #954] loss: 2.3953646086897527\n",
      "[EPOCH #10, step #956] loss: 2.395279038662447\n",
      "[EPOCH #10, step #958] loss: 2.3947301881778227\n",
      "[EPOCH #10, step #960] loss: 2.394205819183532\n",
      "[EPOCH #10, step #962] loss: 2.393773654539637\n",
      "[EPOCH #10, step #964] loss: 2.3929973640590134\n",
      "[EPOCH #10, step #966] loss: 2.392316680413121\n",
      "[EPOCH #10, step #968] loss: 2.3925741326575185\n",
      "[EPOCH #10, step #970] loss: 2.3923934407140885\n",
      "[EPOCH #10, step #972] loss: 2.3922579903519288\n",
      "[EPOCH #10, step #974] loss: 2.392580017921252\n",
      "[EPOCH #10, step #976] loss: 2.3922678850812336\n",
      "[EPOCH #10, step #978] loss: 2.392167028538175\n",
      "[EPOCH #10, step #980] loss: 2.3912821599832004\n",
      "[EPOCH #10, step #982] loss: 2.3914872390935282\n",
      "[EPOCH #10, step #984] loss: 2.3913447328025312\n",
      "[EPOCH #10, step #986] loss: 2.3912644684616677\n",
      "[EPOCH #10, step #988] loss: 2.3915023870005285\n",
      "[EPOCH #10, step #990] loss: 2.391452787261678\n",
      "[EPOCH #10, step #992] loss: 2.391416498901621\n",
      "[EPOCH #10, step #994] loss: 2.391397791891242\n",
      "[EPOCH #10, step #996] loss: 2.39111878627999\n",
      "[EPOCH #10, step #998] loss: 2.39095911953423\n",
      "[EPOCH #10, step #1000] loss: 2.3910103810059797\n",
      "[EPOCH #10, step #1002] loss: 2.3910927129528696\n",
      "[EPOCH #10, step #1004] loss: 2.391045784238559\n",
      "[EPOCH #10, step #1006] loss: 2.3911062462445876\n",
      "[EPOCH #10, step #1008] loss: 2.391356006840648\n",
      "[EPOCH #10, step #1010] loss: 2.391091747996126\n",
      "[EPOCH #10, step #1012] loss: 2.3913080957070036\n",
      "[EPOCH #10, step #1014] loss: 2.3911402867932625\n",
      "[EPOCH #10, step #1016] loss: 2.3904787058206667\n",
      "[EPOCH #10, step #1018] loss: 2.3907281841216306\n",
      "[EPOCH #10, step #1020] loss: 2.390677019034263\n",
      "[EPOCH #10, step #1022] loss: 2.390228011507909\n",
      "[EPOCH #10, step #1024] loss: 2.3900836871309976\n",
      "[EPOCH #10, step #1026] loss: 2.390010536935801\n",
      "[EPOCH #10, step #1028] loss: 2.3895446889254512\n",
      "[EPOCH #10, step #1030] loss: 2.3901046422011176\n",
      "[EPOCH #10, step #1032] loss: 2.390466460299977\n",
      "[EPOCH #10, step #1034] loss: 2.3905205852167617\n",
      "[EPOCH #10, step #1036] loss: 2.390478372228985\n",
      "[EPOCH #10, step #1038] loss: 2.3903749623587776\n",
      "[EPOCH #10, step #1040] loss: 2.38964993076526\n",
      "[EPOCH #10, step #1042] loss: 2.389167863479168\n",
      "[EPOCH #10, step #1044] loss: 2.3887412403188826\n",
      "[EPOCH #10, step #1046] loss: 2.388751150088415\n",
      "[EPOCH #10, step #1048] loss: 2.3891732093831037\n",
      "[EPOCH #10, step #1050] loss: 2.3887845055473975\n",
      "[EPOCH #10, step #1052] loss: 2.3885175336120477\n",
      "[EPOCH #10, step #1054] loss: 2.3886483010522563\n",
      "[EPOCH #10, step #1056] loss: 2.3886836970202068\n",
      "[EPOCH #10, step #1058] loss: 2.3882214914975695\n",
      "[EPOCH #10, step #1060] loss: 2.3883362191673947\n",
      "[EPOCH #10, step #1062] loss: 2.3880911902896886\n",
      "[EPOCH #10, step #1064] loss: 2.388219780765229\n",
      "[EPOCH #10, step #1066] loss: 2.3873669636394785\n",
      "[EPOCH #10, step #1068] loss: 2.3869560083794306\n",
      "[EPOCH #10, step #1070] loss: 2.3875946706973092\n",
      "[EPOCH #10, step #1072] loss: 2.3876769247170597\n",
      "[EPOCH #10, step #1074] loss: 2.3878008170460547\n",
      "[EPOCH #10, step #1076] loss: 2.3881069801422656\n",
      "[EPOCH #10, step #1078] loss: 2.388101342654648\n",
      "[EPOCH #10, step #1080] loss: 2.388063795361444\n",
      "[EPOCH #10, step #1082] loss: 2.3881015925085998\n",
      "[EPOCH #10, step #1084] loss: 2.388282604041737\n",
      "[EPOCH #10, step #1086] loss: 2.3881061493856928\n",
      "[EPOCH #10, step #1088] loss: 2.387625946048425\n",
      "[EPOCH #10, step #1090] loss: 2.3876217412467837\n",
      "[EPOCH #10, step #1092] loss: 2.3873850965543504\n",
      "[EPOCH #10, step #1094] loss: 2.387625843204864\n",
      "[EPOCH #10, step #1096] loss: 2.3876346385576777\n",
      "[EPOCH #10, step #1098] loss: 2.387920995101373\n",
      "[EPOCH #10, step #1100] loss: 2.3887462592146593\n",
      "[EPOCH #10, step #1102] loss: 2.3887197895689867\n",
      "[EPOCH #10, step #1104] loss: 2.388280739719512\n",
      "[EPOCH #10, step #1106] loss: 2.3885046936093737\n",
      "[EPOCH #10, step #1108] loss: 2.3878007034012816\n",
      "[EPOCH #10, step #1110] loss: 2.3879559010025835\n",
      "[EPOCH #10, step #1112] loss: 2.3879232415184712\n",
      "[EPOCH #10, step #1114] loss: 2.3880603413945356\n",
      "[EPOCH #10, step #1116] loss: 2.3879397982663093\n",
      "[EPOCH #10, step #1118] loss: 2.387242150796749\n",
      "[EPOCH #10, step #1120] loss: 2.3866222350327275\n",
      "[EPOCH #10, step #1122] loss: 2.386567171301464\n",
      "[EPOCH #10, step #1124] loss: 2.3861123621198868\n",
      "[EPOCH #10, step #1126] loss: 2.3864718192218146\n",
      "[EPOCH #10, step #1128] loss: 2.3868165261139374\n",
      "[EPOCH #10, step #1130] loss: 2.3865154847753036\n",
      "[EPOCH #10, step #1132] loss: 2.3866771332268577\n",
      "[EPOCH #10, step #1134] loss: 2.386181791448383\n",
      "[EPOCH #10, step #1136] loss: 2.385738148118911\n",
      "[EPOCH #10, step #1138] loss: 2.3859596092309525\n",
      "[EPOCH #10, step #1140] loss: 2.386740014074561\n",
      "[EPOCH #10, step #1142] loss: 2.3866129619242953\n",
      "[EPOCH #10, step #1144] loss: 2.3863755310466717\n",
      "[EPOCH #10, step #1146] loss: 2.386705112436489\n",
      "[EPOCH #10, step #1148] loss: 2.387266843291964\n",
      "[EPOCH #10, step #1150] loss: 2.386795910724239\n",
      "[EPOCH #10, step #1152] loss: 2.3866151292119353\n",
      "[EPOCH #10, step #1154] loss: 2.3865382174908856\n",
      "[EPOCH #10, step #1156] loss: 2.3860484979847123\n",
      "[EPOCH #10, step #1158] loss: 2.3857090295235386\n",
      "[EPOCH #10, step #1160] loss: 2.386527855677609\n",
      "[EPOCH #10, step #1162] loss: 2.386156104908662\n",
      "[EPOCH #10, step #1164] loss: 2.3864094351494263\n",
      "[EPOCH #10, step #1166] loss: 2.3860546872466677\n",
      "[EPOCH #10, step #1168] loss: 2.38572518472696\n",
      "[EPOCH #10, step #1170] loss: 2.386066693713989\n",
      "[EPOCH #10, step #1172] loss: 2.386941190062683\n",
      "[EPOCH #10, step #1174] loss: 2.386614523136869\n",
      "[EPOCH #10, step #1176] loss: 2.38619898271034\n",
      "[EPOCH #10, step #1178] loss: 2.386099953687828\n",
      "[EPOCH #10, step #1180] loss: 2.385922231884148\n",
      "[EPOCH #10, step #1182] loss: 2.385007228875503\n",
      "[EPOCH #10, step #1184] loss: 2.3851861734430497\n",
      "[EPOCH #10, step #1186] loss: 2.3853292386875298\n",
      "[EPOCH #10, step #1188] loss: 2.3852985536881715\n",
      "[EPOCH #10, step #1190] loss: 2.3850529540195673\n",
      "[EPOCH #10, step #1192] loss: 2.3849512971157\n",
      "[EPOCH #10, step #1194] loss: 2.3850182622047646\n",
      "[EPOCH #10, step #1196] loss: 2.3848879159044603\n",
      "[EPOCH #10, step #1198] loss: 2.3844706788472676\n",
      "[EPOCH #10, step #1200] loss: 2.3841015876679497\n",
      "[EPOCH #10, step #1202] loss: 2.3837832372979335\n",
      "[EPOCH #10, step #1204] loss: 2.383625791973098\n",
      "[EPOCH #10, step #1206] loss: 2.3840860717041785\n",
      "[EPOCH #10, step #1208] loss: 2.3835010200221247\n",
      "[EPOCH #10, step #1210] loss: 2.383472132840302\n",
      "[EPOCH #10, step #1212] loss: 2.382766529045514\n",
      "[EPOCH #10, step #1214] loss: 2.3825269289958624\n",
      "[EPOCH #10, step #1216] loss: 2.382450025494998\n",
      "[EPOCH #10, step #1218] loss: 2.381909544591145\n",
      "[EPOCH #10, step #1220] loss: 2.381614632044143\n",
      "[EPOCH #10, step #1222] loss: 2.3817006924653383\n",
      "[EPOCH #10, step #1224] loss: 2.3812424633454303\n",
      "[EPOCH #10, step #1226] loss: 2.3812401789227637\n",
      "[EPOCH #10, step #1228] loss: 2.3808676120806167\n",
      "[EPOCH #10, step #1230] loss: 2.38046569401999\n",
      "[EPOCH #10, step #1232] loss: 2.380637937315286\n",
      "[EPOCH #10, step #1234] loss: 2.3809621071525915\n",
      "[EPOCH #10, step #1236] loss: 2.380792851012468\n",
      "[EPOCH #10, step #1238] loss: 2.381052367816152\n",
      "[EPOCH #10, step #1240] loss: 2.381416324066789\n",
      "[EPOCH #10, step #1242] loss: 2.381081451261034\n",
      "[EPOCH #10, step #1244] loss: 2.3809922271943\n",
      "[EPOCH #10, step #1246] loss: 2.38128307540606\n",
      "[EPOCH #10, step #1248] loss: 2.3814128063696685\n",
      "[EPOCH #10, step #1250] loss: 2.3813969683018232\n",
      "[EPOCH #10, step #1252] loss: 2.381459327288275\n",
      "[EPOCH #10, step #1254] loss: 2.3816978456489593\n",
      "[EPOCH #10, step #1256] loss: 2.381752726570803\n",
      "[EPOCH #10, step #1258] loss: 2.381863849138437\n",
      "[EPOCH #10, step #1260] loss: 2.3813702160172006\n",
      "[EPOCH #10, step #1262] loss: 2.3812175641811186\n",
      "[EPOCH #10, step #1264] loss: 2.381240675760352\n",
      "[EPOCH #10, step #1266] loss: 2.380834809324359\n",
      "[EPOCH #10, step #1268] loss: 2.381217624278779\n",
      "[EPOCH #10, step #1270] loss: 2.3809684758857887\n",
      "[EPOCH #10, step #1272] loss: 2.381105009908294\n",
      "[EPOCH #10, step #1274] loss: 2.381255769636117\n",
      "[EPOCH #10, step #1276] loss: 2.3810738928166795\n",
      "[EPOCH #10, step #1278] loss: 2.3805653010615155\n",
      "[EPOCH #10, step #1280] loss: 2.3808487209838223\n",
      "[EPOCH #10, step #1282] loss: 2.3808930405210167\n",
      "[EPOCH #10, step #1284] loss: 2.381018783146305\n",
      "[EPOCH #10, step #1286] loss: 2.380177423763201\n",
      "[EPOCH #10, step #1288] loss: 2.3799105267639398\n",
      "[EPOCH #10, step #1290] loss: 2.3796379138664348\n",
      "[EPOCH #10, step #1292] loss: 2.3792333268234183\n",
      "[EPOCH #10, step #1294] loss: 2.3790758818733186\n",
      "[EPOCH #10, step #1296] loss: 2.3793526645247165\n",
      "[EPOCH #10, step #1298] loss: 2.379083097577554\n",
      "[EPOCH #10, step #1300] loss: 2.379106395616612\n",
      "[EPOCH #10, step #1302] loss: 2.3786807116049578\n",
      "[EPOCH #10, step #1304] loss: 2.379113524992347\n",
      "[EPOCH #10, step #1306] loss: 2.379567211515227\n",
      "[EPOCH #10, step #1308] loss: 2.379841826452018\n",
      "[EPOCH #10, step #1310] loss: 2.379540899980168\n",
      "[EPOCH #10, step #1312] loss: 2.379714435143772\n",
      "[EPOCH #10, step #1314] loss: 2.3797670635433703\n",
      "[EPOCH #10, step #1316] loss: 2.3796208197181663\n",
      "[EPOCH #10, step #1318] loss: 2.379636998516398\n",
      "[EPOCH #10, step #1320] loss: 2.3793685476857545\n",
      "[EPOCH #10, step #1322] loss: 2.3793243173388756\n",
      "[EPOCH #10, step #1324] loss: 2.3793536235701365\n",
      "[EPOCH #10, step #1326] loss: 2.3798023122724232\n",
      "[EPOCH #10, step #1328] loss: 2.380488436144936\n",
      "[EPOCH #10, step #1330] loss: 2.3804002083127074\n",
      "[EPOCH #10, step #1332] loss: 2.380329487561643\n",
      "[EPOCH #10, step #1334] loss: 2.379897996548856\n",
      "[EPOCH #10, step #1336] loss: 2.379990250741535\n",
      "[EPOCH #10, step #1338] loss: 2.3797246296072827\n",
      "[EPOCH #10, step #1340] loss: 2.38009718378296\n",
      "[EPOCH #10, step #1342] loss: 2.3804258468518573\n",
      "[EPOCH #10, step #1344] loss: 2.3803144310486806\n",
      "[EPOCH #10, step #1346] loss: 2.380083269513618\n",
      "[EPOCH #10, step #1348] loss: 2.3800589295119337\n",
      "[EPOCH #10, step #1350] loss: 2.3805756186838947\n",
      "[EPOCH #10, step #1352] loss: 2.3805512318501894\n",
      "[EPOCH #10, step #1354] loss: 2.3810935329247225\n",
      "[EPOCH #10, step #1356] loss: 2.381132253321463\n",
      "[EPOCH #10, step #1358] loss: 2.381475729921269\n",
      "[EPOCH #10, step #1360] loss: 2.381808638222335\n",
      "[EPOCH #10, step #1362] loss: 2.3816825370095884\n",
      "[EPOCH #10, step #1364] loss: 2.3815768634006655\n",
      "[EPOCH #10, step #1366] loss: 2.381404117240292\n",
      "[EPOCH #10, step #1368] loss: 2.381542859328237\n",
      "[EPOCH #10, step #1370] loss: 2.3818449152376773\n",
      "[EPOCH #10, step #1372] loss: 2.381898241414697\n",
      "[EPOCH #10, step #1374] loss: 2.381721112424677\n",
      "[EPOCH #10, step #1376] loss: 2.381882763376423\n",
      "[EPOCH #10, step #1378] loss: 2.3814802915830384\n",
      "[EPOCH #10, step #1380] loss: 2.3812675854160164\n",
      "[EPOCH #10, step #1382] loss: 2.381265909707986\n",
      "[EPOCH #10, step #1384] loss: 2.3812714163577082\n",
      "[EPOCH #10, step #1386] loss: 2.381062398991657\n",
      "[EPOCH #10, step #1388] loss: 2.3809831099513628\n",
      "[EPOCH #10, step #1390] loss: 2.3813521039305963\n",
      "[EPOCH #10, step #1392] loss: 2.381237248593924\n",
      "[EPOCH #10, step #1394] loss: 2.3811607398439905\n",
      "[EPOCH #10, step #1396] loss: 2.380966729749162\n",
      "[EPOCH #10, step #1398] loss: 2.380574151564701\n",
      "[EPOCH #10, step #1400] loss: 2.381045437131415\n",
      "[EPOCH #10, step #1402] loss: 2.3811247216236224\n",
      "[EPOCH #10, step #1404] loss: 2.381508309815702\n",
      "[EPOCH #10, step #1406] loss: 2.3811387171877474\n",
      "[EPOCH #10, step #1408] loss: 2.381203830453671\n",
      "[EPOCH #10, step #1410] loss: 2.380612230233315\n",
      "[EPOCH #10, step #1412] loss: 2.380499526278313\n",
      "[EPOCH #10, step #1414] loss: 2.380089912144961\n",
      "[EPOCH #10, step #1416] loss: 2.380424886500238\n",
      "[EPOCH #10, step #1418] loss: 2.3800874878773812\n",
      "[EPOCH #10, step #1420] loss: 2.3799137411446405\n",
      "[EPOCH #10, step #1422] loss: 2.3794687702382693\n",
      "[EPOCH #10, step #1424] loss: 2.3795061762291088\n",
      "[EPOCH #10, step #1426] loss: 2.379759953752129\n",
      "[EPOCH #10, step #1428] loss: 2.379536011737906\n",
      "[EPOCH #10, step #1430] loss: 2.379509659433265\n",
      "[EPOCH #10, step #1432] loss: 2.37986095701991\n",
      "[EPOCH #10, step #1434] loss: 2.3795720092095562\n",
      "[EPOCH #10, step #1436] loss: 2.3793744194731583\n",
      "[EPOCH #10, step #1438] loss: 2.3798040208756883\n",
      "[EPOCH #10, step #1440] loss: 2.379450534798055\n",
      "[EPOCH #10, step #1442] loss: 2.379715369958805\n",
      "[EPOCH #10, step #1444] loss: 2.3797316242666806\n",
      "[EPOCH #10, step #1446] loss: 2.3799338653817537\n",
      "[EPOCH #10, step #1448] loss: 2.3799247738408416\n",
      "[EPOCH #10, step #1450] loss: 2.379793846878325\n",
      "[EPOCH #10, step #1452] loss: 2.379355919664676\n",
      "[EPOCH #10, step #1454] loss: 2.379558997055919\n",
      "[EPOCH #10, step #1456] loss: 2.379370725146695\n",
      "[EPOCH #10, step #1458] loss: 2.3787274743041573\n",
      "[EPOCH #10, step #1460] loss: 2.3786697500295464\n",
      "[EPOCH #10, step #1462] loss: 2.3785567332520032\n",
      "[EPOCH #10, step #1464] loss: 2.3782087581556404\n",
      "[EPOCH #10, step #1466] loss: 2.3778948978899934\n",
      "[EPOCH #10, step #1468] loss: 2.377829690463207\n",
      "[EPOCH #10, step #1470] loss: 2.3775497597954374\n",
      "[EPOCH #10, step #1472] loss: 2.377270622959124\n",
      "[EPOCH #10, step #1474] loss: 2.3771669835559393\n",
      "[EPOCH #10, step #1476] loss: 2.3768100440703943\n",
      "[EPOCH #10, step #1478] loss: 2.3767484702960795\n",
      "[EPOCH #10, step #1480] loss: 2.3767404487050925\n",
      "[EPOCH #10, step #1482] loss: 2.3765468433429002\n",
      "[EPOCH #10, step #1484] loss: 2.3767100197698934\n",
      "[EPOCH #10, step #1486] loss: 2.376291247607079\n",
      "[EPOCH #10, step #1488] loss: 2.3762033482059044\n",
      "[EPOCH #10, step #1490] loss: 2.375984227313522\n",
      "[EPOCH #10, step #1492] loss: 2.3756858467337114\n",
      "[EPOCH #10, step #1494] loss: 2.3749033249341522\n",
      "[EPOCH #10, step #1496] loss: 2.3748315131576683\n",
      "[EPOCH #10, step #1498] loss: 2.3745376421182134\n",
      "[EPOCH #10, step #1500] loss: 2.3753067214515986\n",
      "[EPOCH #10, step #1502] loss: 2.3755686617817626\n",
      "[EPOCH #10, step #1504] loss: 2.3751981879389565\n",
      "[EPOCH #10, step #1506] loss: 2.37527648882116\n",
      "[EPOCH #10, step #1508] loss: 2.3753230707624877\n",
      "[EPOCH #10, step #1510] loss: 2.3749885167766296\n",
      "[EPOCH #10, step #1512] loss: 2.3751380429390796\n",
      "[EPOCH #10, step #1514] loss: 2.375223387822066\n",
      "[EPOCH #10, step #1516] loss: 2.3751841700226364\n",
      "[EPOCH #10, step #1518] loss: 2.3749122986909668\n",
      "[EPOCH #10, step #1520] loss: 2.3751572093863302\n",
      "[EPOCH #10, step #1522] loss: 2.375354736475904\n",
      "[EPOCH #10, step #1524] loss: 2.375702850310529\n",
      "[EPOCH #10, step #1526] loss: 2.3751729601883156\n",
      "[EPOCH #10, step #1528] loss: 2.3750997769279056\n",
      "[EPOCH #10, step #1530] loss: 2.3748371467957847\n",
      "[EPOCH #10, step #1532] loss: 2.374699590024183\n",
      "[EPOCH #10, step #1534] loss: 2.3743729244225964\n",
      "[EPOCH #10, step #1536] loss: 2.3746773696364563\n",
      "[EPOCH #10, step #1538] loss: 2.3748687590926867\n",
      "[EPOCH #10, step #1540] loss: 2.3750508692572443\n",
      "[EPOCH #10, step #1542] loss: 2.3754260296645446\n",
      "[EPOCH #10, step #1544] loss: 2.375491634773205\n",
      "[EPOCH #10, step #1546] loss: 2.375432310754743\n",
      "[EPOCH #10, step #1548] loss: 2.375413557650429\n",
      "[EPOCH #10, step #1550] loss: 2.374963838849661\n",
      "[EPOCH #10, step #1552] loss: 2.375433891954072\n",
      "[EPOCH #10, step #1554] loss: 2.3752513670078046\n",
      "[EPOCH #10, step #1556] loss: 2.3747965786498404\n",
      "[EPOCH #10, step #1558] loss: 2.3752315172100005\n",
      "[EPOCH #10, step #1560] loss: 2.3751948630481405\n",
      "[EPOCH #10, step #1562] loss: 2.3757039757012866\n",
      "[EPOCH #10, step #1564] loss: 2.3757489345325067\n",
      "[EPOCH #10, step #1566] loss: 2.3755956582377955\n",
      "[EPOCH #10, step #1568] loss: 2.3755004353550606\n",
      "[EPOCH #10, step #1570] loss: 2.375391256498122\n",
      "[EPOCH #10, step #1572] loss: 2.3751653246415776\n",
      "[EPOCH #10, step #1574] loss: 2.3752549691427323\n",
      "[EPOCH #10, step #1576] loss: 2.3751257661028458\n",
      "[EPOCH #10, step #1578] loss: 2.3748932998341954\n",
      "[EPOCH #10, step #1580] loss: 2.3747091328773524\n",
      "[EPOCH #10, step #1582] loss: 2.374574856824387\n",
      "[EPOCH #10, step #1584] loss: 2.3744077913392605\n",
      "[EPOCH #10, step #1586] loss: 2.374492079413906\n",
      "[EPOCH #10, step #1588] loss: 2.374396715095165\n",
      "[EPOCH #10, step #1590] loss: 2.3740046071526693\n",
      "[EPOCH #10, step #1592] loss: 2.3735797326668058\n",
      "[EPOCH #10, step #1594] loss: 2.3736732654063304\n",
      "[EPOCH #10, step #1596] loss: 2.3739978258656054\n",
      "[EPOCH #10, step #1598] loss: 2.373915868300509\n",
      "[EPOCH #10, step #1600] loss: 2.3737773779851805\n",
      "[EPOCH #10, step #1602] loss: 2.37392161707542\n",
      "[EPOCH #10, step #1604] loss: 2.3740247926236684\n",
      "[EPOCH #10, step #1606] loss: 2.373888253794743\n",
      "[EPOCH #10, step #1608] loss: 2.3736373713625523\n",
      "[EPOCH #10, step #1610] loss: 2.3739170644092384\n",
      "[EPOCH #10, step #1612] loss: 2.3745025683099708\n",
      "[EPOCH #10, step #1614] loss: 2.3743760892112187\n",
      "[EPOCH #10, step #1616] loss: 2.37482023217019\n",
      "[EPOCH #10, step #1618] loss: 2.374996504936784\n",
      "[EPOCH #10, step #1620] loss: 2.375113338912291\n",
      "[EPOCH #10, step #1622] loss: 2.374729536303898\n",
      "[EPOCH #10, step #1624] loss: 2.3746166925430297\n",
      "[EPOCH #10, step #1626] loss: 2.374599222691424\n",
      "[EPOCH #10, step #1628] loss: 2.3750305917088865\n",
      "[EPOCH #10, step #1630] loss: 2.3750428415967377\n",
      "[EPOCH #10, step #1632] loss: 2.3746994765930505\n",
      "[EPOCH #10, step #1634] loss: 2.3746727576678683\n",
      "[EPOCH #10, step #1636] loss: 2.374744736208884\n",
      "[EPOCH #10, step #1638] loss: 2.3747110075162197\n",
      "[EPOCH #10, step #1640] loss: 2.3743814292439303\n",
      "[EPOCH #10, step #1642] loss: 2.3742811382361033\n",
      "[EPOCH #10, step #1644] loss: 2.3744559741672413\n",
      "[EPOCH #10, step #1646] loss: 2.3741335652420283\n",
      "[EPOCH #10, step #1648] loss: 2.373982700960357\n",
      "[EPOCH #10, step #1650] loss: 2.374372955743361\n",
      "[EPOCH #10, step #1652] loss: 2.3746509963789637\n",
      "[EPOCH #10, step #1654] loss: 2.374377336602917\n",
      "[EPOCH #10, step #1656] loss: 2.3737656216917804\n",
      "[EPOCH #10, step #1658] loss: 2.3738017076465865\n",
      "[EPOCH #10, step #1660] loss: 2.3737464994640685\n",
      "[EPOCH #10, step #1662] loss: 2.3739815810611287\n",
      "[EPOCH #10, step #1664] loss: 2.373864061481602\n",
      "[EPOCH #10, step #1666] loss: 2.3737558722138474\n",
      "[EPOCH #10, step #1668] loss: 2.3734246303108084\n",
      "[EPOCH #10, step #1670] loss: 2.3734671324759025\n",
      "[EPOCH #10, step #1672] loss: 2.3735996332983733\n",
      "[EPOCH #10, step #1674] loss: 2.3738153456218205\n",
      "[EPOCH #10, step #1676] loss: 2.3735436541592003\n",
      "[EPOCH #10, step #1678] loss: 2.3735385500582433\n",
      "[EPOCH #10, step #1680] loss: 2.3739010918927574\n",
      "[EPOCH #10, step #1682] loss: 2.373705166050599\n",
      "[EPOCH #10, step #1684] loss: 2.3735833785654177\n",
      "[EPOCH #10, step #1686] loss: 2.3738263070971994\n",
      "[EPOCH #10, step #1688] loss: 2.3739598894909757\n",
      "[EPOCH #10, step #1690] loss: 2.374080019191762\n",
      "[EPOCH #10, step #1692] loss: 2.374082387092194\n",
      "[EPOCH #10, step #1694] loss: 2.374226732802602\n",
      "[EPOCH #10, step #1696] loss: 2.374235073608304\n",
      "[EPOCH #10, step #1698] loss: 2.3740616611623286\n",
      "[EPOCH #10, step #1700] loss: 2.374110920789451\n",
      "[EPOCH #10, step #1702] loss: 2.3743312433755754\n",
      "[EPOCH #10, step #1704] loss: 2.3741428473827777\n",
      "[EPOCH #10, step #1706] loss: 2.3738963595593123\n",
      "[EPOCH #10, step #1708] loss: 2.3741590978110163\n",
      "[EPOCH #10, step #1710] loss: 2.374203974012044\n",
      "[EPOCH #10, step #1712] loss: 2.374124653772242\n",
      "[EPOCH #10, step #1714] loss: 2.373968063916131\n",
      "[EPOCH #10, step #1716] loss: 2.3743044667696633\n",
      "[EPOCH #10, step #1718] loss: 2.3742545160046147\n",
      "[EPOCH #10, step #1720] loss: 2.3739041700257872\n",
      "[EPOCH #10, step #1722] loss: 2.374009516235015\n",
      "[EPOCH #10, step #1724] loss: 2.373806024150572\n",
      "[EPOCH #10, step #1726] loss: 2.373789626252948\n",
      "[EPOCH #10, step #1728] loss: 2.3736606165465073\n",
      "[EPOCH #10, step #1730] loss: 2.373902739850446\n",
      "[EPOCH #10, step #1732] loss: 2.3742584231542287\n",
      "[EPOCH #10, step #1734] loss: 2.374568328390204\n",
      "[EPOCH #10, step #1736] loss: 2.3745070227138187\n",
      "[EPOCH #10, step #1738] loss: 2.374681743004323\n",
      "[EPOCH #10, step #1740] loss: 2.3747943478846674\n",
      "[EPOCH #10, step #1742] loss: 2.3746826792337807\n",
      "[EPOCH #10, step #1744] loss: 2.3746823640129286\n",
      "[EPOCH #10, step #1746] loss: 2.374588793731104\n",
      "[EPOCH #10, step #1748] loss: 2.3745982209364302\n",
      "[EPOCH #10, step #1750] loss: 2.3744738829061007\n",
      "[EPOCH #10, step #1752] loss: 2.374358694552015\n",
      "[EPOCH #10, step #1754] loss: 2.374576367815675\n",
      "[EPOCH #10, step #1756] loss: 2.3748020720061214\n",
      "[EPOCH #10, step #1758] loss: 2.375041875058511\n",
      "[EPOCH #10, step #1760] loss: 2.375227662800795\n",
      "[EPOCH #10, step #1762] loss: 2.375167928226144\n",
      "[EPOCH #10, step #1764] loss: 2.3750729096172214\n",
      "[EPOCH #10, step #1766] loss: 2.37518918359084\n",
      "[EPOCH #10, step #1768] loss: 2.3752645797955916\n",
      "[EPOCH #10, step #1770] loss: 2.3755602189068874\n",
      "[EPOCH #10, step #1772] loss: 2.3751601058752336\n",
      "[EPOCH #10, step #1774] loss: 2.375003844583538\n",
      "[EPOCH #10, step #1776] loss: 2.37501763646765\n",
      "[EPOCH #10, step #1778] loss: 2.3750745011153285\n",
      "[EPOCH #10, step #1780] loss: 2.3752666022388\n",
      "[EPOCH #10, step #1782] loss: 2.374884674339166\n",
      "[EPOCH #10, step #1784] loss: 2.37484796274276\n",
      "[EPOCH #10, step #1786] loss: 2.37440402653208\n",
      "[EPOCH #10, step #1788] loss: 2.374162169526315\n",
      "[EPOCH #10, step #1790] loss: 2.3734575058081373\n",
      "[EPOCH #10, step #1792] loss: 2.374002153356183\n",
      "[EPOCH #10, step #1794] loss: 2.374027578013853\n",
      "[EPOCH #10, step #1796] loss: 2.374151471461199\n",
      "[EPOCH #10, step #1798] loss: 2.373942579276831\n",
      "[EPOCH #10, step #1800] loss: 2.373880104910063\n",
      "[EPOCH #10, step #1802] loss: 2.374093168256551\n",
      "[EPOCH #10, step #1804] loss: 2.373561769245074\n",
      "[EPOCH #10, step #1806] loss: 2.3734828739055427\n",
      "[EPOCH #10, step #1808] loss: 2.373588975521001\n",
      "[EPOCH #10, step #1810] loss: 2.373609207994302\n",
      "[EPOCH #10, step #1812] loss: 2.373557571344328\n",
      "[EPOCH #10, step #1814] loss: 2.373031201375746\n",
      "[EPOCH #10, step #1816] loss: 2.3731497843054274\n",
      "[EPOCH #10, step #1818] loss: 2.3734598184693576\n",
      "[EPOCH #10, step #1820] loss: 2.3735836663788192\n",
      "[EPOCH #10, step #1822] loss: 2.373823524763868\n",
      "[EPOCH #10, step #1824] loss: 2.373647077508169\n",
      "[EPOCH #10, step #1826] loss: 2.373247161156895\n",
      "[EPOCH #10, step #1828] loss: 2.3733029422243805\n",
      "[EPOCH #10, step #1830] loss: 2.373179229408714\n",
      "[EPOCH #10, step #1832] loss: 2.3731636404665974\n",
      "[EPOCH #10, step #1834] loss: 2.373137865599235\n",
      "[EPOCH #10, step #1836] loss: 2.3729100747152585\n",
      "[EPOCH #10, step #1838] loss: 2.372827111216198\n",
      "[EPOCH #10, step #1840] loss: 2.3731020284955235\n",
      "[EPOCH #10, step #1842] loss: 2.3732481205262896\n",
      "[EPOCH #10, step #1844] loss: 2.3732228962063466\n",
      "[EPOCH #10, step #1846] loss: 2.3730274680245547\n",
      "[EPOCH #10, step #1848] loss: 2.373274287576608\n",
      "[EPOCH #10, step #1850] loss: 2.3732281057722564\n",
      "[EPOCH #10, step #1852] loss: 2.373080231663477\n",
      "[EPOCH #10, step #1854] loss: 2.372950285849867\n",
      "[EPOCH #10, step #1856] loss: 2.3729599900443388\n",
      "[EPOCH #10, step #1858] loss: 2.3729232070008677\n",
      "[EPOCH #10, step #1860] loss: 2.3730537515375834\n",
      "[EPOCH #10, step #1862] loss: 2.3730313554606126\n",
      "[EPOCH #10, step #1864] loss: 2.3728854058575055\n",
      "[EPOCH #10, step #1866] loss: 2.37287492648637\n",
      "[EPOCH #10, step #1868] loss: 2.37274121912869\n",
      "[EPOCH #10, step #1870] loss: 2.3725696633933766\n",
      "[EPOCH #10, step #1872] loss: 2.372603834916485\n",
      "[EPOCH #10, step #1874] loss: 2.37225083433787\n",
      "[EPOCH #10, step #1876] loss: 2.3725390892176152\n",
      "[EPOCH #10, step #1878] loss: 2.3728352451400596\n",
      "[EPOCH #10, step #1880] loss: 2.3730383677916094\n",
      "[EPOCH #10, step #1882] loss: 2.373302401916435\n",
      "[EPOCH #10, step #1884] loss: 2.3731729132427146\n",
      "[EPOCH #10, step #1886] loss: 2.373200702932567\n",
      "[EPOCH #10, step #1888] loss: 2.373194341056242\n",
      "[EPOCH #10, step #1890] loss: 2.3732507761542223\n",
      "[EPOCH #10, step #1892] loss: 2.3735184223010815\n",
      "[EPOCH #10, step #1894] loss: 2.3731275959820106\n",
      "[EPOCH #10, step #1896] loss: 2.3729543624328953\n",
      "[EPOCH #10, step #1898] loss: 2.373014539087867\n",
      "[EPOCH #10, step #1900] loss: 2.3728547285632797\n",
      "[EPOCH #10, step #1902] loss: 2.372537074437344\n",
      "[EPOCH #10, step #1904] loss: 2.3726405968503377\n",
      "[EPOCH #10, step #1906] loss: 2.3727517910633775\n",
      "[EPOCH #10, step #1908] loss: 2.3726300993410314\n",
      "[EPOCH #10, step #1910] loss: 2.3725416992173525\n",
      "[EPOCH #10, step #1912] loss: 2.372276611372992\n",
      "[EPOCH #10, step #1914] loss: 2.372156265074528\n",
      "[EPOCH #10, step #1916] loss: 2.372031167266141\n",
      "[EPOCH #10, step #1918] loss: 2.371792881982037\n",
      "[EPOCH #10, step #1920] loss: 2.3714857535831384\n",
      "[EPOCH #10, step #1922] loss: 2.371081103338776\n",
      "[EPOCH #10, step #1924] loss: 2.3712596123559133\n",
      "[EPOCH #10, step #1926] loss: 2.3712124458915778\n",
      "[EPOCH #10, step #1928] loss: 2.3711713856523553\n",
      "[EPOCH #10, step #1930] loss: 2.3711417163980246\n",
      "[EPOCH #10, step #1932] loss: 2.3710197714160777\n",
      "[EPOCH #10, step #1934] loss: 2.3709465458103542\n",
      "[EPOCH #10, step #1936] loss: 2.370915566145543\n",
      "[EPOCH #10, step #1938] loss: 2.3706012563400503\n",
      "[EPOCH #10, step #1940] loss: 2.3705102532011892\n",
      "[EPOCH #10, step #1942] loss: 2.3704234575157734\n",
      "[EPOCH #10, step #1944] loss: 2.3705998615005024\n",
      "[EPOCH #10, step #1946] loss: 2.370365775176422\n",
      "[EPOCH #10, step #1948] loss: 2.3702606748715005\n",
      "[EPOCH #10, step #1950] loss: 2.370057850174877\n",
      "[EPOCH #10, step #1952] loss: 2.3699385024191355\n",
      "[EPOCH #10, step #1954] loss: 2.369829375725573\n",
      "[EPOCH #10, step #1956] loss: 2.37008612516527\n",
      "[EPOCH #10, step #1958] loss: 2.370045783813052\n",
      "[EPOCH #10, step #1960] loss: 2.370258218290124\n",
      "[EPOCH #10, step #1962] loss: 2.370496825605889\n",
      "[EPOCH #10, step #1964] loss: 2.3703220135079692\n",
      "[EPOCH #10, step #1966] loss: 2.3703798701694065\n",
      "[EPOCH #10, step #1968] loss: 2.370306691462283\n",
      "[EPOCH #10, step #1970] loss: 2.370551630726083\n",
      "[EPOCH #10, step #1972] loss: 2.3702925237011803\n",
      "[EPOCH #10, step #1974] loss: 2.370067157564284\n",
      "[EPOCH #10, step #1976] loss: 2.3700969582805143\n",
      "[EPOCH #10, step #1978] loss: 2.369810307429498\n",
      "[EPOCH #10, step #1980] loss: 2.3692108005781716\n",
      "[EPOCH #10, step #1982] loss: 2.369079853751355\n",
      "[EPOCH #10, step #1984] loss: 2.3690517065206764\n",
      "[EPOCH #10, step #1986] loss: 2.369192601210158\n",
      "[EPOCH #10, step #1988] loss: 2.369036461612937\n",
      "[EPOCH #10, step #1990] loss: 2.3694678579126394\n",
      "[EPOCH #10, step #1992] loss: 2.370086757848446\n",
      "[EPOCH #10, step #1994] loss: 2.3703326536001716\n",
      "[EPOCH #10, step #1996] loss: 2.3703964377380813\n",
      "[EPOCH #10, step #1998] loss: 2.3703159926950246\n",
      "[EPOCH #10, step #2000] loss: 2.3706421661472272\n",
      "[EPOCH #10, step #2002] loss: 2.370665277770562\n",
      "[EPOCH #10, step #2004] loss: 2.3708720364178206\n",
      "[EPOCH #10, step #2006] loss: 2.37095696687342\n",
      "[EPOCH #10, step #2008] loss: 2.370570549506818\n",
      "[EPOCH #10, step #2010] loss: 2.3702706366495847\n",
      "[EPOCH #10, step #2012] loss: 2.3703428708198233\n",
      "[EPOCH #10, step #2014] loss: 2.3701397602966345\n",
      "[EPOCH #10, step #2016] loss: 2.370449276979926\n",
      "[EPOCH #10, step #2018] loss: 2.370591392075443\n",
      "[EPOCH #10, step #2020] loss: 2.370448170706283\n",
      "[EPOCH #10, step #2022] loss: 2.3702877020989086\n",
      "[EPOCH #10, step #2024] loss: 2.370298350357715\n",
      "[EPOCH #10, step #2026] loss: 2.370553347825651\n",
      "[EPOCH #10, step #2028] loss: 2.3702312702025727\n",
      "[EPOCH #10, step #2030] loss: 2.3702859475306255\n",
      "[EPOCH #10, step #2032] loss: 2.3702134657422134\n",
      "[EPOCH #10, step #2034] loss: 2.369981446195879\n",
      "[EPOCH #10, step #2036] loss: 2.3700738485150907\n",
      "[EPOCH #10, step #2038] loss: 2.37027372905821\n",
      "[EPOCH #10, step #2040] loss: 2.3703354597091675\n",
      "[EPOCH #10, step #2042] loss: 2.370109020292438\n",
      "[EPOCH #10, step #2044] loss: 2.3701776281254214\n",
      "[EPOCH #10, step #2046] loss: 2.3701888216840503\n",
      "[EPOCH #10, step #2048] loss: 2.3702569657735792\n",
      "[EPOCH #10, step #2050] loss: 2.3701070140827465\n",
      "[EPOCH #10, step #2052] loss: 2.3704488196143045\n",
      "[EPOCH #10, step #2054] loss: 2.370552677307686\n",
      "[EPOCH #10, step #2056] loss: 2.370588346888385\n",
      "[EPOCH #10, step #2058] loss: 2.3704531838906626\n",
      "[EPOCH #10, step #2060] loss: 2.37046826261736\n",
      "[EPOCH #10, step #2062] loss: 2.3704221864608788\n",
      "[EPOCH #10, step #2064] loss: 2.370140921232487\n",
      "[EPOCH #10, step #2066] loss: 2.370361160470716\n",
      "[EPOCH #10, step #2068] loss: 2.370276846074436\n",
      "[EPOCH #10, step #2070] loss: 2.3704624909930962\n",
      "[EPOCH #10, step #2072] loss: 2.370525285982591\n",
      "[EPOCH #10, step #2074] loss: 2.3703303465211247\n",
      "[EPOCH #10, step #2076] loss: 2.370524816405159\n",
      "[EPOCH #10, step #2078] loss: 2.3705404471640064\n",
      "[EPOCH #10, step #2080] loss: 2.370456282133554\n",
      "[EPOCH #10, step #2082] loss: 2.3699602767703514\n",
      "[EPOCH #10, step #2084] loss: 2.3700176304764597\n",
      "[EPOCH #10, step #2086] loss: 2.369724588583803\n",
      "[EPOCH #10, step #2088] loss: 2.3694500947694794\n",
      "[EPOCH #10, step #2090] loss: 2.3694051359328054\n",
      "[EPOCH #10, step #2092] loss: 2.3696952700557974\n",
      "[EPOCH #10, step #2094] loss: 2.369607528297315\n",
      "[EPOCH #10, step #2096] loss: 2.36935576286325\n",
      "[EPOCH #10, step #2098] loss: 2.369061077873499\n",
      "[EPOCH #10, step #2100] loss: 2.368986497715165\n",
      "[EPOCH #10, step #2102] loss: 2.3690508643729427\n",
      "[EPOCH #10, step #2104] loss: 2.36882897606938\n",
      "[EPOCH #10, step #2106] loss: 2.368906580502239\n",
      "[EPOCH #10, step #2108] loss: 2.3687999464991876\n",
      "[EPOCH #10, step #2110] loss: 2.3687709613978045\n",
      "[EPOCH #10, step #2112] loss: 2.368841868297669\n",
      "[EPOCH #10, step #2114] loss: 2.3687950817969394\n",
      "[EPOCH #10, step #2116] loss: 2.3686239956457995\n",
      "[EPOCH #10, step #2118] loss: 2.368250432471275\n",
      "[EPOCH #10, step #2120] loss: 2.368059168329558\n",
      "[EPOCH #10, step #2122] loss: 2.3678111620686044\n",
      "[EPOCH #10, step #2124] loss: 2.3674990825092093\n",
      "[EPOCH #10, step #2126] loss: 2.3678440539333594\n",
      "[EPOCH #10, step #2128] loss: 2.3678696334166056\n",
      "[EPOCH #10, step #2130] loss: 2.3679666948228975\n",
      "[EPOCH #10, step #2132] loss: 2.3679734488579793\n",
      "[EPOCH #10, step #2134] loss: 2.368022988886688\n",
      "[EPOCH #10, step #2136] loss: 2.3678430248545217\n",
      "[EPOCH #10, step #2138] loss: 2.367828583539006\n",
      "[EPOCH #10, step #2140] loss: 2.367887124064257\n",
      "[EPOCH #10, step #2142] loss: 2.3677567892190288\n",
      "[EPOCH #10, step #2144] loss: 2.3679401290444506\n",
      "[EPOCH #10, step #2146] loss: 2.3678239177535954\n",
      "[EPOCH #10, step #2148] loss: 2.3678688317911742\n",
      "[EPOCH #10, step #2150] loss: 2.36763584469707\n",
      "[EPOCH #10, step #2152] loss: 2.367371261867323\n",
      "[EPOCH #10, step #2154] loss: 2.367565863259707\n",
      "[EPOCH #10, step #2156] loss: 2.367643906277642\n",
      "[EPOCH #10, step #2158] loss: 2.367993156188834\n",
      "[EPOCH #10, step #2160] loss: 2.3680193539517504\n",
      "[EPOCH #10, step #2162] loss: 2.3678849190404665\n",
      "[EPOCH #10, step #2164] loss: 2.3678204307930573\n",
      "[EPOCH #10, step #2166] loss: 2.367864332333324\n",
      "[EPOCH #10, step #2168] loss: 2.3678809962771683\n",
      "[EPOCH #10, step #2170] loss: 2.3674886140994684\n",
      "[EPOCH #10, step #2172] loss: 2.36738752089938\n",
      "[EPOCH #10, step #2174] loss: 2.367649563975718\n",
      "[EPOCH #10, step #2176] loss: 2.367551166747325\n",
      "[EPOCH #10, step #2178] loss: 2.367187977821907\n",
      "[EPOCH #10, step #2180] loss: 2.367144295623793\n",
      "[EPOCH #10, step #2182] loss: 2.3674152069991736\n",
      "[EPOCH #10, step #2184] loss: 2.367332862225495\n",
      "[EPOCH #10, step #2186] loss: 2.3672336296889136\n",
      "[EPOCH #10, step #2188] loss: 2.367057356512018\n",
      "[EPOCH #10, step #2190] loss: 2.3670454193391195\n",
      "[EPOCH #10, step #2192] loss: 2.366546353356674\n",
      "[EPOCH #10, step #2194] loss: 2.366849927478608\n",
      "[EPOCH #10, step #2196] loss: 2.3668270545706838\n",
      "[EPOCH #10, step #2198] loss: 2.366889921574768\n",
      "[EPOCH #10, step #2200] loss: 2.367146457286923\n",
      "[EPOCH #10, step #2202] loss: 2.36706595560447\n",
      "[EPOCH #10, step #2204] loss: 2.3671446962962075\n",
      "[EPOCH #10, step #2206] loss: 2.367135431899385\n",
      "[EPOCH #10, step #2208] loss: 2.3670695418953196\n",
      "[EPOCH #10, step #2210] loss: 2.366788481274971\n",
      "[EPOCH #10, step #2212] loss: 2.366610401311289\n",
      "[EPOCH #10, step #2214] loss: 2.3664843260030985\n",
      "[EPOCH #10, step #2216] loss: 2.3663383399144347\n",
      "[EPOCH #10, step #2218] loss: 2.366254033350418\n",
      "[EPOCH #10, step #2220] loss: 2.366220107007703\n",
      "[EPOCH #10, step #2222] loss: 2.366202985387743\n",
      "[EPOCH #10, step #2224] loss: 2.3659614315461575\n",
      "[EPOCH #10, step #2226] loss: 2.3659340611583297\n",
      "[EPOCH #10, step #2228] loss: 2.3656627140327546\n",
      "[EPOCH #10, step #2230] loss: 2.3654196453650185\n",
      "[EPOCH #10, step #2232] loss: 2.3650285463615006\n",
      "[EPOCH #10, step #2234] loss: 2.364650413707332\n",
      "[EPOCH #10, step #2236] loss: 2.364857248765419\n",
      "[EPOCH #10, step #2238] loss: 2.364814302068355\n",
      "[EPOCH #10, step #2240] loss: 2.3648655616189154\n",
      "[EPOCH #10, step #2242] loss: 2.3648721433568096\n",
      "[EPOCH #10, step #2244] loss: 2.3649578373256928\n",
      "[EPOCH #10, step #2246] loss: 2.3647983935232633\n",
      "[EPOCH #10, step #2248] loss: 2.3648213192641654\n",
      "[EPOCH #10, step #2250] loss: 2.365060930249957\n",
      "[EPOCH #10, step #2252] loss: 2.3651103992965874\n",
      "[EPOCH #10, step #2254] loss: 2.364602861118951\n",
      "[EPOCH #10, step #2256] loss: 2.364620175940514\n",
      "[EPOCH #10, step #2258] loss: 2.3646329222341826\n",
      "[EPOCH #10, step #2260] loss: 2.3648017619574615\n",
      "[EPOCH #10, step #2262] loss: 2.364313001396695\n",
      "[EPOCH #10, step #2264] loss: 2.3644146031891276\n",
      "[EPOCH #10, step #2266] loss: 2.364426616429757\n",
      "[EPOCH #10, step #2268] loss: 2.364378486661041\n",
      "[EPOCH #10, step #2270] loss: 2.3640924516305795\n",
      "[EPOCH #10, step #2272] loss: 2.364026188588174\n",
      "[EPOCH #10, step #2274] loss: 2.364155544972682\n",
      "[EPOCH #10, step #2276] loss: 2.3639643650909345\n",
      "[EPOCH #10, step #2278] loss: 2.3637223396451916\n",
      "[EPOCH #10, step #2280] loss: 2.3636323255909373\n",
      "[EPOCH #10, step #2282] loss: 2.363458786520371\n",
      "[EPOCH #10, step #2284] loss: 2.3630868318044382\n",
      "[EPOCH #10, step #2286] loss: 2.363061234687268\n",
      "[EPOCH #10, step #2288] loss: 2.363042292401175\n",
      "[EPOCH #10, step #2290] loss: 2.363016614951405\n",
      "[EPOCH #10, step #2292] loss: 2.363050592138005\n",
      "[EPOCH #10, step #2294] loss: 2.3632111211747646\n",
      "[EPOCH #10, step #2296] loss: 2.363396680713167\n",
      "[EPOCH #10, step #2298] loss: 2.363127977913387\n",
      "[EPOCH #10, step #2300] loss: 2.3633857332380477\n",
      "[EPOCH #10, step #2302] loss: 2.3632105397391308\n",
      "[EPOCH #10, step #2304] loss: 2.3631098444704897\n",
      "[EPOCH #10, step #2306] loss: 2.3631460639269877\n",
      "[EPOCH #10, step #2308] loss: 2.363171765121767\n",
      "[EPOCH #10, step #2310] loss: 2.3636253145751063\n",
      "[EPOCH #10, step #2312] loss: 2.3635670677490994\n",
      "[EPOCH #10, step #2314] loss: 2.3636363189627234\n",
      "[EPOCH #10, step #2316] loss: 2.363584119027475\n",
      "[EPOCH #10, step #2318] loss: 2.3634157754985257\n",
      "[EPOCH #10, step #2320] loss: 2.3635770899116455\n",
      "[EPOCH #10, step #2322] loss: 2.3635413921243713\n",
      "[EPOCH #10, step #2324] loss: 2.3639590119290097\n",
      "[EPOCH #10, step #2326] loss: 2.3637020449091244\n",
      "[EPOCH #10, step #2328] loss: 2.36384189487169\n",
      "[EPOCH #10, step #2330] loss: 2.363869816947014\n",
      "[EPOCH #10, step #2332] loss: 2.3637842786092387\n",
      "[EPOCH #10, step #2334] loss: 2.363860294956722\n",
      "[EPOCH #10, step #2336] loss: 2.3637545307222267\n",
      "[EPOCH #10, step #2338] loss: 2.3635545752404234\n",
      "[EPOCH #10, step #2340] loss: 2.3637853626102934\n",
      "[EPOCH #10, step #2342] loss: 2.363926349111566\n",
      "[EPOCH #10, step #2344] loss: 2.3638751380733334\n",
      "[EPOCH #10, step #2346] loss: 2.363692548359309\n",
      "[EPOCH #10, step #2348] loss: 2.36390601791895\n",
      "[EPOCH #10, step #2350] loss: 2.3639308921533257\n",
      "[EPOCH #10, step #2352] loss: 2.3639272938269125\n",
      "[EPOCH #10, step #2354] loss: 2.36361684409423\n",
      "[EPOCH #10, step #2356] loss: 2.3636597200728695\n",
      "[EPOCH #10, step #2358] loss: 2.363775835597146\n",
      "[EPOCH #10, step #2360] loss: 2.363649186467983\n",
      "[EPOCH #10, step #2362] loss: 2.3635213629855376\n",
      "[EPOCH #10, step #2364] loss: 2.3634636137500626\n",
      "[EPOCH #10, step #2366] loss: 2.3635591484093195\n",
      "[EPOCH #10, step #2368] loss: 2.363761847257715\n",
      "[EPOCH #10, step #2370] loss: 2.36380748932797\n",
      "[EPOCH #10, step #2372] loss: 2.363647767827323\n",
      "[EPOCH #10, step #2374] loss: 2.363611464199267\n",
      "[EPOCH #10, step #2376] loss: 2.363759203974219\n",
      "[EPOCH #10, step #2378] loss: 2.364009955040594\n",
      "[EPOCH #10, step #2380] loss: 2.364086786622212\n",
      "[EPOCH #10, step #2382] loss: 2.364235649827244\n",
      "[EPOCH #10, step #2384] loss: 2.3640950410371055\n",
      "[EPOCH #10, step #2386] loss: 2.363951512096215\n",
      "[EPOCH #10, step #2388] loss: 2.3637839530790736\n",
      "[EPOCH #10, step #2390] loss: 2.363590141710802\n",
      "[EPOCH #10, step #2392] loss: 2.36371442353033\n",
      "[EPOCH #10, step #2394] loss: 2.363520776503768\n",
      "[EPOCH #10, step #2396] loss: 2.363520959490878\n",
      "[EPOCH #10, step #2398] loss: 2.363424191677655\n",
      "[EPOCH #10, step #2400] loss: 2.363337522395101\n",
      "[EPOCH #10, step #2402] loss: 2.3635082108449597\n",
      "[EPOCH #10, step #2404] loss: 2.363690088147185\n",
      "[EPOCH #10, step #2406] loss: 2.3635663680630103\n",
      "[EPOCH #10, step #2408] loss: 2.3634709435510852\n",
      "[EPOCH #10, step #2410] loss: 2.3634801164597015\n",
      "[EPOCH #10, step #2412] loss: 2.36372581750488\n",
      "[EPOCH #10, step #2414] loss: 2.363478767847176\n",
      "[EPOCH #10, step #2416] loss: 2.3634655566860636\n",
      "[EPOCH #10, step #2418] loss: 2.3634602513476906\n",
      "[EPOCH #10, step #2420] loss: 2.3631400544502577\n",
      "[EPOCH #10, step #2422] loss: 2.3630736181670065\n",
      "[EPOCH #10, step #2424] loss: 2.3630805121254674\n",
      "[EPOCH #10, step #2426] loss: 2.362891575167294\n",
      "[EPOCH #10, step #2428] loss: 2.3629928335529042\n",
      "[EPOCH #10, step #2430] loss: 2.3631123842794874\n",
      "[EPOCH #10, step #2432] loss: 2.362855291444972\n",
      "[EPOCH #10, step #2434] loss: 2.362643456605915\n",
      "[EPOCH #10, step #2436] loss: 2.362664619820696\n",
      "[EPOCH #10, step #2438] loss: 2.362899140189446\n",
      "[EPOCH #10, step #2440] loss: 2.362735432418142\n",
      "[EPOCH #10, step #2442] loss: 2.362637257898044\n",
      "[EPOCH #10, step #2444] loss: 2.362556042895483\n",
      "[EPOCH #10, step #2446] loss: 2.3624176595178876\n",
      "[EPOCH #10, step #2448] loss: 2.3624047849459666\n",
      "[EPOCH #10, step #2450] loss: 2.362191966094566\n",
      "[EPOCH #10, step #2452] loss: 2.362328411655138\n",
      "[EPOCH #10, step #2454] loss: 2.3621079249683077\n",
      "[EPOCH #10, step #2456] loss: 2.3620165473424084\n",
      "[EPOCH #10, step #2458] loss: 2.3617856163666375\n",
      "[EPOCH #10, step #2460] loss: 2.3611921924539137\n",
      "[EPOCH #10, step #2462] loss: 2.361141686075546\n",
      "[EPOCH #10, step #2464] loss: 2.3607638489160285\n",
      "[EPOCH #10, step #2466] loss: 2.3606825098606756\n",
      "[EPOCH #10, step #2468] loss: 2.360643300946399\n",
      "[EPOCH #10, step #2470] loss: 2.360574261035479\n",
      "[EPOCH #10, step #2472] loss: 2.360630798812246\n",
      "[EPOCH #10, step #2474] loss: 2.3604876433960116\n",
      "[EPOCH #10, step #2476] loss: 2.3603896893557876\n",
      "[EPOCH #10, step #2478] loss: 2.3603503419392147\n",
      "[EPOCH #10, step #2480] loss: 2.3604591418446574\n",
      "[EPOCH #10, step #2482] loss: 2.360475810938577\n",
      "[EPOCH #10, step #2484] loss: 2.3603911872840744\n",
      "[EPOCH #10, step #2486] loss: 2.3602325330549423\n",
      "[EPOCH #10, step #2488] loss: 2.3603115590426182\n",
      "[EPOCH #10, step #2490] loss: 2.3605008549309314\n",
      "[EPOCH #10, step #2492] loss: 2.36044307439814\n",
      "[EPOCH #10, step #2494] loss: 2.36018331299325\n",
      "[EPOCH #10, step #2496] loss: 2.3599139703575687\n",
      "[EPOCH #10, step #2498] loss: 2.3598634202559503\n",
      "[EPOCH #10, elapsed time: 5130.757[sec]] loss: 2.3598089111328124\n",
      "[EPOCH #11, step #0] loss: 1.917252540588379\n",
      "[EPOCH #11, step #2] loss: 2.253870964050293\n",
      "[EPOCH #11, step #4] loss: 2.163708806037903\n",
      "[EPOCH #11, step #6] loss: 2.1836384534835815\n",
      "[EPOCH #11, step #8] loss: 2.175160871611701\n",
      "[EPOCH #11, step #10] loss: 2.211186549880288\n",
      "[EPOCH #11, step #12] loss: 2.237739847256587\n",
      "[EPOCH #11, step #14] loss: 2.243289613723755\n",
      "[EPOCH #11, step #16] loss: 2.291188394322115\n",
      "[EPOCH #11, step #18] loss: 2.2891061682450142\n",
      "[EPOCH #11, step #20] loss: 2.3011026836576915\n",
      "[EPOCH #11, step #22] loss: 2.251820761224498\n",
      "[EPOCH #11, step #24] loss: 2.253290042877197\n",
      "[EPOCH #11, step #26] loss: 2.2647792586573847\n",
      "[EPOCH #11, step #28] loss: 2.2464347173427712\n",
      "[EPOCH #11, step #30] loss: 2.239305450070289\n",
      "[EPOCH #11, step #32] loss: 2.2420524033633145\n",
      "[EPOCH #11, step #34] loss: 2.235049479348319\n",
      "[EPOCH #11, step #36] loss: 2.2421965502403878\n",
      "[EPOCH #11, step #38] loss: 2.229510796375764\n",
      "[EPOCH #11, step #40] loss: 2.2114911253859355\n",
      "[EPOCH #11, step #42] loss: 2.227614314057106\n",
      "[EPOCH #11, step #44] loss: 2.2310507721371122\n",
      "[EPOCH #11, step #46] loss: 2.2417517266374953\n",
      "[EPOCH #11, step #48] loss: 2.2487299928859787\n",
      "[EPOCH #11, step #50] loss: 2.2439179584091784\n",
      "[EPOCH #11, step #52] loss: 2.250250332760361\n",
      "[EPOCH #11, step #54] loss: 2.2407209439711138\n",
      "[EPOCH #11, step #56] loss: 2.237090035488731\n",
      "[EPOCH #11, step #58] loss: 2.2392118260011835\n",
      "[EPOCH #11, step #60] loss: 2.243039963675327\n",
      "[EPOCH #11, step #62] loss: 2.233310103416443\n",
      "[EPOCH #11, step #64] loss: 2.2492753487366897\n",
      "[EPOCH #11, step #66] loss: 2.247710026911835\n",
      "[EPOCH #11, step #68] loss: 2.246080645616504\n",
      "[EPOCH #11, step #70] loss: 2.247078967766023\n",
      "[EPOCH #11, step #72] loss: 2.2497325743714423\n",
      "[EPOCH #11, step #74] loss: 2.242972396214803\n",
      "[EPOCH #11, step #76] loss: 2.2369041783469066\n",
      "[EPOCH #11, step #78] loss: 2.2443805284137968\n",
      "[EPOCH #11, step #80] loss: 2.2395925875063294\n",
      "[EPOCH #11, step #82] loss: 2.240868111690843\n",
      "[EPOCH #11, step #84] loss: 2.244898428636439\n",
      "[EPOCH #11, step #86] loss: 2.2387408840245215\n",
      "[EPOCH #11, step #88] loss: 2.239810036809257\n",
      "[EPOCH #11, step #90] loss: 2.2487174639335046\n",
      "[EPOCH #11, step #92] loss: 2.240993074191514\n",
      "[EPOCH #11, step #94] loss: 2.239702292492515\n",
      "[EPOCH #11, step #96] loss: 2.2422628869715426\n",
      "[EPOCH #11, step #98] loss: 2.2411988961576212\n",
      "[EPOCH #11, step #100] loss: 2.2429014456154097\n",
      "[EPOCH #11, step #102] loss: 2.2451151806173972\n",
      "[EPOCH #11, step #104] loss: 2.2437812896001907\n",
      "[EPOCH #11, step #106] loss: 2.246563851276291\n",
      "[EPOCH #11, step #108] loss: 2.2464173977528143\n",
      "[EPOCH #11, step #110] loss: 2.2440462466832756\n",
      "[EPOCH #11, step #112] loss: 2.2383822002242098\n",
      "[EPOCH #11, step #114] loss: 2.2368038260418435\n",
      "[EPOCH #11, step #116] loss: 2.2356872925391564\n",
      "[EPOCH #11, step #118] loss: 2.240039727267097\n",
      "[EPOCH #11, step #120] loss: 2.237596403468739\n",
      "[EPOCH #11, step #122] loss: 2.2422022121708567\n",
      "[EPOCH #11, step #124] loss: 2.2413741130828857\n",
      "[EPOCH #11, step #126] loss: 2.249428125817006\n",
      "[EPOCH #11, step #128] loss: 2.25031200305436\n",
      "[EPOCH #11, step #130] loss: 2.242527678722644\n",
      "[EPOCH #11, step #132] loss: 2.2396554364297625\n",
      "[EPOCH #11, step #134] loss: 2.2384694152408176\n",
      "[EPOCH #11, step #136] loss: 2.2438576099646355\n",
      "[EPOCH #11, step #138] loss: 2.2433939683351585\n",
      "[EPOCH #11, step #140] loss: 2.2389105034212693\n",
      "[EPOCH #11, step #142] loss: 2.2375654448996056\n",
      "[EPOCH #11, step #144] loss: 2.2384140433936284\n",
      "[EPOCH #11, step #146] loss: 2.2388094501430484\n",
      "[EPOCH #11, step #148] loss: 2.2366782306824753\n",
      "[EPOCH #11, step #150] loss: 2.238129892096614\n",
      "[EPOCH #11, step #152] loss: 2.236909814130247\n",
      "[EPOCH #11, step #154] loss: 2.2354494963922806\n",
      "[EPOCH #11, step #156] loss: 2.238534328284537\n",
      "[EPOCH #11, step #158] loss: 2.2421962487622626\n",
      "[EPOCH #11, step #160] loss: 2.2443706241453656\n",
      "[EPOCH #11, step #162] loss: 2.2437675620880597\n",
      "[EPOCH #11, step #164] loss: 2.245714295271671\n",
      "[EPOCH #11, step #166] loss: 2.2506974307362904\n",
      "[EPOCH #11, step #168] loss: 2.248995907207918\n",
      "[EPOCH #11, step #170] loss: 2.25144935002801\n",
      "[EPOCH #11, step #172] loss: 2.2501767060660214\n",
      "[EPOCH #11, step #174] loss: 2.251769449370248\n",
      "[EPOCH #11, step #176] loss: 2.2550978936718007\n",
      "[EPOCH #11, step #178] loss: 2.256674283709606\n",
      "[EPOCH #11, step #180] loss: 2.2556706653774112\n",
      "[EPOCH #11, step #182] loss: 2.2592226358059326\n",
      "[EPOCH #11, step #184] loss: 2.2601900004051827\n",
      "[EPOCH #11, step #186] loss: 2.2649342994638944\n",
      "[EPOCH #11, step #188] loss: 2.262245077304739\n",
      "[EPOCH #11, step #190] loss: 2.2611445138591746\n",
      "[EPOCH #11, step #192] loss: 2.260420135265805\n",
      "[EPOCH #11, step #194] loss: 2.2603253823060254\n",
      "[EPOCH #11, step #196] loss: 2.261526897473989\n",
      "[EPOCH #11, step #198] loss: 2.259995512626878\n",
      "[EPOCH #11, step #200] loss: 2.2550235607137727\n",
      "[EPOCH #11, step #202] loss: 2.2541138638416536\n",
      "[EPOCH #11, step #204] loss: 2.2564898543241547\n",
      "[EPOCH #11, step #206] loss: 2.25848020390036\n",
      "[EPOCH #11, step #208] loss: 2.2601807203019066\n",
      "[EPOCH #11, step #210] loss: 2.2626249739344084\n",
      "[EPOCH #11, step #212] loss: 2.262855103877788\n",
      "[EPOCH #11, step #214] loss: 2.2632052798603857\n",
      "[EPOCH #11, step #216] loss: 2.2626045343513312\n",
      "[EPOCH #11, step #218] loss: 2.260138032643218\n",
      "[EPOCH #11, step #220] loss: 2.2601150819079368\n",
      "[EPOCH #11, step #222] loss: 2.2574773652671163\n",
      "[EPOCH #11, step #224] loss: 2.2603383429845176\n",
      "[EPOCH #11, step #226] loss: 2.2610198164826447\n",
      "[EPOCH #11, step #228] loss: 2.261752411267643\n",
      "[EPOCH #11, step #230] loss: 2.2626999265703804\n",
      "[EPOCH #11, step #232] loss: 2.262969208889253\n",
      "[EPOCH #11, step #234] loss: 2.2598486347401394\n",
      "[EPOCH #11, step #236] loss: 2.262155311017097\n",
      "[EPOCH #11, step #238] loss: 2.2625615422196965\n",
      "[EPOCH #11, step #240] loss: 2.264110760570067\n",
      "[EPOCH #11, step #242] loss: 2.267242278091211\n",
      "[EPOCH #11, step #244] loss: 2.268392910762709\n",
      "[EPOCH #11, step #246] loss: 2.2689207058686476\n",
      "[EPOCH #11, step #248] loss: 2.2693012234676315\n",
      "[EPOCH #11, step #250] loss: 2.270000646313823\n",
      "[EPOCH #11, step #252] loss: 2.271164260362919\n",
      "[EPOCH #11, step #254] loss: 2.2726714110841937\n",
      "[EPOCH #11, step #256] loss: 2.27342174164516\n",
      "[EPOCH #11, step #258] loss: 2.272907380892043\n",
      "[EPOCH #11, step #260] loss: 2.2760605341629963\n",
      "[EPOCH #11, step #262] loss: 2.2753869385773693\n",
      "[EPOCH #11, step #264] loss: 2.277050735815516\n",
      "[EPOCH #11, step #266] loss: 2.2776722457078513\n",
      "[EPOCH #11, step #268] loss: 2.2752918448146833\n",
      "[EPOCH #11, step #270] loss: 2.2758558056011413\n",
      "[EPOCH #11, step #272] loss: 2.276566593201606\n",
      "[EPOCH #11, step #274] loss: 2.2772564441507512\n",
      "[EPOCH #11, step #276] loss: 2.2774082689078705\n",
      "[EPOCH #11, step #278] loss: 2.2778427733315363\n",
      "[EPOCH #11, step #280] loss: 2.2764595085191557\n",
      "[EPOCH #11, step #282] loss: 2.27557844197371\n",
      "[EPOCH #11, step #284] loss: 2.2716924495864332\n",
      "[EPOCH #11, step #286] loss: 2.2726715188408564\n",
      "[EPOCH #11, step #288] loss: 2.2718756862990173\n",
      "[EPOCH #11, step #290] loss: 2.271086265541024\n",
      "[EPOCH #11, step #292] loss: 2.2705271402723555\n",
      "[EPOCH #11, step #294] loss: 2.272150844234531\n",
      "[EPOCH #11, step #296] loss: 2.270196799477343\n",
      "[EPOCH #11, step #298] loss: 2.2694135924246797\n",
      "[EPOCH #11, step #300] loss: 2.2688463320367758\n",
      "[EPOCH #11, step #302] loss: 2.2671770246902314\n",
      "[EPOCH #11, step #304] loss: 2.2674077463931726\n",
      "[EPOCH #11, step #306] loss: 2.2676753718223943\n",
      "[EPOCH #11, step #308] loss: 2.2673828617268783\n",
      "[EPOCH #11, step #310] loss: 2.2677558832996527\n",
      "[EPOCH #11, step #312] loss: 2.269120987992698\n",
      "[EPOCH #11, step #314] loss: 2.267871700392829\n",
      "[EPOCH #11, step #316] loss: 2.267454871995968\n",
      "[EPOCH #11, step #318] loss: 2.2672054539653574\n",
      "[EPOCH #11, step #320] loss: 2.2667446177325146\n",
      "[EPOCH #11, step #322] loss: 2.267144058880053\n",
      "[EPOCH #11, step #324] loss: 2.265477870794443\n",
      "[EPOCH #11, step #326] loss: 2.265888262961618\n",
      "[EPOCH #11, step #328] loss: 2.266305029211073\n",
      "[EPOCH #11, step #330] loss: 2.2663309970291\n",
      "[EPOCH #11, step #332] loss: 2.2665349076818058\n",
      "[EPOCH #11, step #334] loss: 2.266117253232358\n",
      "[EPOCH #11, step #336] loss: 2.267027752335772\n",
      "[EPOCH #11, step #338] loss: 2.2665991596767685\n",
      "[EPOCH #11, step #340] loss: 2.2658734996297842\n",
      "[EPOCH #11, step #342] loss: 2.266241867062649\n",
      "[EPOCH #11, step #344] loss: 2.2658586795779243\n",
      "[EPOCH #11, step #346] loss: 2.265092402782495\n",
      "[EPOCH #11, step #348] loss: 2.2659415812751966\n",
      "[EPOCH #11, step #350] loss: 2.2659435085421613\n",
      "[EPOCH #11, step #352] loss: 2.2638676315123907\n",
      "[EPOCH #11, step #354] loss: 2.2625269359266253\n",
      "[EPOCH #11, step #356] loss: 2.261947437494743\n",
      "[EPOCH #11, step #358] loss: 2.261469701538511\n",
      "[EPOCH #11, step #360] loss: 2.2610888520766492\n",
      "[EPOCH #11, step #362] loss: 2.2609093793495956\n",
      "[EPOCH #11, step #364] loss: 2.2607109422553076\n",
      "[EPOCH #11, step #366] loss: 2.2612240905657774\n",
      "[EPOCH #11, step #368] loss: 2.262286008535039\n",
      "[EPOCH #11, step #370] loss: 2.2601998427486163\n",
      "[EPOCH #11, step #372] loss: 2.2585198658720738\n",
      "[EPOCH #11, step #374] loss: 2.2582969172795613\n",
      "[EPOCH #11, step #376] loss: 2.2596546765663894\n",
      "[EPOCH #11, step #378] loss: 2.2582676847880623\n",
      "[EPOCH #11, step #380] loss: 2.2593123966001776\n",
      "[EPOCH #11, step #382] loss: 2.2588621894622283\n",
      "[EPOCH #11, step #384] loss: 2.2596773070174376\n",
      "[EPOCH #11, step #386] loss: 2.260312881580619\n",
      "[EPOCH #11, step #388] loss: 2.257775779861411\n",
      "[EPOCH #11, step #390] loss: 2.258367141494361\n",
      "[EPOCH #11, step #392] loss: 2.2587370205168202\n",
      "[EPOCH #11, step #394] loss: 2.2586951110936417\n",
      "[EPOCH #11, step #396] loss: 2.259076062017484\n",
      "[EPOCH #11, step #398] loss: 2.258271183883935\n",
      "[EPOCH #11, step #400] loss: 2.2581930059447255\n",
      "[EPOCH #11, step #402] loss: 2.257642458449522\n",
      "[EPOCH #11, step #404] loss: 2.258057428878031\n",
      "[EPOCH #11, step #406] loss: 2.2588119126069164\n",
      "[EPOCH #11, step #408] loss: 2.2578010127713455\n",
      "[EPOCH #11, step #410] loss: 2.257475713743781\n",
      "[EPOCH #11, step #412] loss: 2.2573382825597434\n",
      "[EPOCH #11, step #414] loss: 2.2568108685045356\n",
      "[EPOCH #11, step #416] loss: 2.257481032995869\n",
      "[EPOCH #11, step #418] loss: 2.255323676334645\n",
      "[EPOCH #11, step #420] loss: 2.2553153491076836\n",
      "[EPOCH #11, step #422] loss: 2.2550711031501174\n",
      "[EPOCH #11, step #424] loss: 2.2535892609988943\n",
      "[EPOCH #11, step #426] loss: 2.253730829761514\n",
      "[EPOCH #11, step #428] loss: 2.2537903632873144\n",
      "[EPOCH #11, step #430] loss: 2.2542827679773496\n",
      "[EPOCH #11, step #432] loss: 2.252857491821395\n",
      "[EPOCH #11, step #434] loss: 2.253477264820844\n",
      "[EPOCH #11, step #436] loss: 2.253625490027107\n",
      "[EPOCH #11, step #438] loss: 2.25255785227365\n",
      "[EPOCH #11, step #440] loss: 2.2521829240176143\n",
      "[EPOCH #11, step #442] loss: 2.2514917920459205\n",
      "[EPOCH #11, step #444] loss: 2.2519097837169517\n",
      "[EPOCH #11, step #446] loss: 2.2505200471920723\n",
      "[EPOCH #11, step #448] loss: 2.250126132189829\n",
      "[EPOCH #11, step #450] loss: 2.2515236525207825\n",
      "[EPOCH #11, step #452] loss: 2.2505477851063476\n",
      "[EPOCH #11, step #454] loss: 2.250813557289459\n",
      "[EPOCH #11, step #456] loss: 2.2506117729441604\n",
      "[EPOCH #11, step #458] loss: 2.2508502964879953\n",
      "[EPOCH #11, step #460] loss: 2.249424085441225\n",
      "[EPOCH #11, step #462] loss: 2.2506775652615607\n",
      "[EPOCH #11, step #464] loss: 2.252560923945519\n",
      "[EPOCH #11, step #466] loss: 2.2514743564981465\n",
      "[EPOCH #11, step #468] loss: 2.251759850902598\n",
      "[EPOCH #11, step #470] loss: 2.250833321022633\n",
      "[EPOCH #11, step #472] loss: 2.251081739369205\n",
      "[EPOCH #11, step #474] loss: 2.2515352690847297\n",
      "[EPOCH #11, step #476] loss: 2.2532430139977477\n",
      "[EPOCH #11, step #478] loss: 2.251582998074669\n",
      "[EPOCH #11, step #480] loss: 2.2507427824262276\n",
      "[EPOCH #11, step #482] loss: 2.2511351424467985\n",
      "[EPOCH #11, step #484] loss: 2.250830095822049\n",
      "[EPOCH #11, step #486] loss: 2.2507303324078634\n",
      "[EPOCH #11, step #488] loss: 2.2506643687289185\n",
      "[EPOCH #11, step #490] loss: 2.2508162461570227\n",
      "[EPOCH #11, step #492] loss: 2.2503767313386556\n",
      "[EPOCH #11, step #494] loss: 2.2506584572069572\n",
      "[EPOCH #11, step #496] loss: 2.249596465761273\n",
      "[EPOCH #11, step #498] loss: 2.2504251165714915\n",
      "[EPOCH #11, step #500] loss: 2.249802831642166\n",
      "[EPOCH #11, step #502] loss: 2.2506493043235944\n",
      "[EPOCH #11, step #504] loss: 2.2509973917857256\n",
      "[EPOCH #11, step #506] loss: 2.2503858266262378\n",
      "[EPOCH #11, step #508] loss: 2.2500035959517324\n",
      "[EPOCH #11, step #510] loss: 2.249790802393874\n",
      "[EPOCH #11, step #512] loss: 2.250785317337304\n",
      "[EPOCH #11, step #514] loss: 2.250656494122107\n",
      "[EPOCH #11, step #516] loss: 2.2514987683619014\n",
      "[EPOCH #11, step #518] loss: 2.252857952448674\n",
      "[EPOCH #11, step #520] loss: 2.254436272806032\n",
      "[EPOCH #11, step #522] loss: 2.2537067608897132\n",
      "[EPOCH #11, step #524] loss: 2.253310586157299\n",
      "[EPOCH #11, step #526] loss: 2.25333708083607\n",
      "[EPOCH #11, step #528] loss: 2.254224056332233\n",
      "[EPOCH #11, step #530] loss: 2.2540029107738575\n",
      "[EPOCH #11, step #532] loss: 2.2546066220213725\n",
      "[EPOCH #11, step #534] loss: 2.2547428688156272\n",
      "[EPOCH #11, step #536] loss: 2.2545227311842932\n",
      "[EPOCH #11, step #538] loss: 2.2541834825929774\n",
      "[EPOCH #11, step #540] loss: 2.2540688530133965\n",
      "[EPOCH #11, step #542] loss: 2.2546120153167193\n",
      "[EPOCH #11, step #544] loss: 2.254757732207622\n",
      "[EPOCH #11, step #546] loss: 2.2544731023760556\n",
      "[EPOCH #11, step #548] loss: 2.254398070832202\n",
      "[EPOCH #11, step #550] loss: 2.253165936296951\n",
      "[EPOCH #11, step #552] loss: 2.252711079435366\n",
      "[EPOCH #11, step #554] loss: 2.252362765707411\n",
      "[EPOCH #11, step #556] loss: 2.252061316740149\n",
      "[EPOCH #11, step #558] loss: 2.2523415176087926\n",
      "[EPOCH #11, step #560] loss: 2.252456403883596\n",
      "[EPOCH #11, step #562] loss: 2.2521102189170743\n",
      "[EPOCH #11, step #564] loss: 2.250710790558199\n",
      "[EPOCH #11, step #566] loss: 2.2500587682875377\n",
      "[EPOCH #11, step #568] loss: 2.248955709443989\n",
      "[EPOCH #11, step #570] loss: 2.248977393694809\n",
      "[EPOCH #11, step #572] loss: 2.2488818549360903\n",
      "[EPOCH #11, step #574] loss: 2.2497448653760164\n",
      "[EPOCH #11, step #576] loss: 2.2497428899414618\n",
      "[EPOCH #11, step #578] loss: 2.250560610405522\n",
      "[EPOCH #11, step #580] loss: 2.2512464217597974\n",
      "[EPOCH #11, step #582] loss: 2.251779309063383\n",
      "[EPOCH #11, step #584] loss: 2.2516998309355514\n",
      "[EPOCH #11, step #586] loss: 2.251322538929863\n",
      "[EPOCH #11, step #588] loss: 2.2515877274786877\n",
      "[EPOCH #11, step #590] loss: 2.2515323168130092\n",
      "[EPOCH #11, step #592] loss: 2.2510697288818746\n",
      "[EPOCH #11, step #594] loss: 2.2512154116350063\n",
      "[EPOCH #11, step #596] loss: 2.2509892891399823\n",
      "[EPOCH #11, step #598] loss: 2.2513666449484724\n",
      "[EPOCH #11, step #600] loss: 2.2516459282146712\n",
      "[EPOCH #11, step #602] loss: 2.25159952434932\n",
      "[EPOCH #11, step #604] loss: 2.253158484411634\n",
      "[EPOCH #11, step #606] loss: 2.253587512836425\n",
      "[EPOCH #11, step #608] loss: 2.2532261672669835\n",
      "[EPOCH #11, step #610] loss: 2.2538384509359757\n",
      "[EPOCH #11, step #612] loss: 2.2541918610670826\n",
      "[EPOCH #11, step #614] loss: 2.2535512941639597\n",
      "[EPOCH #11, step #616] loss: 2.2536715527987363\n",
      "[EPOCH #11, step #618] loss: 2.252909027894595\n",
      "[EPOCH #11, step #620] loss: 2.2536176214663497\n",
      "[EPOCH #11, step #622] loss: 2.2534368003734997\n",
      "[EPOCH #11, step #624] loss: 2.254701817321777\n",
      "[EPOCH #11, step #626] loss: 2.2544222653767707\n",
      "[EPOCH #11, step #628] loss: 2.254950351669603\n",
      "[EPOCH #11, step #630] loss: 2.2543027113810203\n",
      "[EPOCH #11, step #632] loss: 2.2544382552588345\n",
      "[EPOCH #11, step #634] loss: 2.2545378170614168\n",
      "[EPOCH #11, step #636] loss: 2.2543684998337103\n",
      "[EPOCH #11, step #638] loss: 2.2539644565940464\n",
      "[EPOCH #11, step #640] loss: 2.2528729526189486\n",
      "[EPOCH #11, step #642] loss: 2.252484332347176\n",
      "[EPOCH #11, step #644] loss: 2.252323351719583\n",
      "[EPOCH #11, step #646] loss: 2.252920089954571\n",
      "[EPOCH #11, step #648] loss: 2.252850475957838\n",
      "[EPOCH #11, step #650] loss: 2.2536501386381698\n",
      "[EPOCH #11, step #652] loss: 2.254726064150403\n",
      "[EPOCH #11, step #654] loss: 2.254566945738465\n",
      "[EPOCH #11, step #656] loss: 2.255526618870426\n",
      "[EPOCH #11, step #658] loss: 2.2542750564077374\n",
      "[EPOCH #11, step #660] loss: 2.2532729529035973\n",
      "[EPOCH #11, step #662] loss: 2.253711923394987\n",
      "[EPOCH #11, step #664] loss: 2.2542679438913673\n",
      "[EPOCH #11, step #666] loss: 2.25497923261937\n",
      "[EPOCH #11, step #668] loss: 2.253729244162327\n",
      "[EPOCH #11, step #670] loss: 2.2532166528630717\n",
      "[EPOCH #11, step #672] loss: 2.252809558899583\n",
      "[EPOCH #11, step #674] loss: 2.252791468302409\n",
      "[EPOCH #11, step #676] loss: 2.2522765845280452\n",
      "[EPOCH #11, step #678] loss: 2.2522282008745536\n",
      "[EPOCH #11, step #680] loss: 2.2526292405289525\n",
      "[EPOCH #11, step #682] loss: 2.2528636472989665\n",
      "[EPOCH #11, step #684] loss: 2.2526821402737696\n",
      "[EPOCH #11, step #686] loss: 2.252910624598485\n",
      "[EPOCH #11, step #688] loss: 2.253775349030128\n",
      "[EPOCH #11, step #690] loss: 2.253607522906512\n",
      "[EPOCH #11, step #692] loss: 2.253616280713983\n",
      "[EPOCH #11, step #694] loss: 2.252272395435855\n",
      "[EPOCH #11, step #696] loss: 2.251377886131812\n",
      "[EPOCH #11, step #698] loss: 2.2513280909119415\n",
      "[EPOCH #11, step #700] loss: 2.2523231069303615\n",
      "[EPOCH #11, step #702] loss: 2.2529516130219482\n",
      "[EPOCH #11, step #704] loss: 2.252779331105821\n",
      "[EPOCH #11, step #706] loss: 2.2537429550243737\n",
      "[EPOCH #11, step #708] loss: 2.252461237194508\n",
      "[EPOCH #11, step #710] loss: 2.252713206951125\n",
      "[EPOCH #11, step #712] loss: 2.252793807468441\n",
      "[EPOCH #11, step #714] loss: 2.251869888572426\n",
      "[EPOCH #11, step #716] loss: 2.2512787412566286\n",
      "[EPOCH #11, step #718] loss: 2.2508898575548004\n",
      "[EPOCH #11, step #720] loss: 2.250865446380372\n",
      "[EPOCH #11, step #722] loss: 2.2507849667906594\n",
      "[EPOCH #11, step #724] loss: 2.25057349550313\n",
      "[EPOCH #11, step #726] loss: 2.2506941747140687\n",
      "[EPOCH #11, step #728] loss: 2.2500163050181907\n",
      "[EPOCH #11, step #730] loss: 2.249609208302687\n",
      "[EPOCH #11, step #732] loss: 2.2492070708723704\n",
      "[EPOCH #11, step #734] loss: 2.2498428231193905\n",
      "[EPOCH #11, step #736] loss: 2.250379681101971\n",
      "[EPOCH #11, step #738] loss: 2.250944708293765\n",
      "[EPOCH #11, step #740] loss: 2.25069242611266\n",
      "[EPOCH #11, step #742] loss: 2.2511617572599594\n",
      "[EPOCH #11, step #744] loss: 2.2514763156839663\n",
      "[EPOCH #11, step #746] loss: 2.2505475558749484\n",
      "[EPOCH #11, step #748] loss: 2.250062392295919\n",
      "[EPOCH #11, step #750] loss: 2.2505735171619015\n",
      "[EPOCH #11, step #752] loss: 2.2506368570277098\n",
      "[EPOCH #11, step #754] loss: 2.250465747852199\n",
      "[EPOCH #11, step #756] loss: 2.25033642074076\n",
      "[EPOCH #11, step #758] loss: 2.2501074314431553\n",
      "[EPOCH #11, step #760] loss: 2.2498374779496966\n",
      "[EPOCH #11, step #762] loss: 2.249288641609652\n",
      "[EPOCH #11, step #764] loss: 2.248709688622967\n",
      "[EPOCH #11, step #766] loss: 2.2483509695048127\n",
      "[EPOCH #11, step #768] loss: 2.2473135547923175\n",
      "[EPOCH #11, step #770] loss: 2.246665212430843\n",
      "[EPOCH #11, step #772] loss: 2.247176588892474\n",
      "[EPOCH #11, step #774] loss: 2.2482386662883145\n",
      "[EPOCH #11, step #776] loss: 2.2487792023667343\n",
      "[EPOCH #11, step #778] loss: 2.249044611457071\n",
      "[EPOCH #11, step #780] loss: 2.248237485311706\n",
      "[EPOCH #11, step #782] loss: 2.248541916314974\n",
      "[EPOCH #11, step #784] loss: 2.249047485886106\n",
      "[EPOCH #11, step #786] loss: 2.2494465595885185\n",
      "[EPOCH #11, step #788] loss: 2.249129488138796\n",
      "[EPOCH #11, step #790] loss: 2.2494691230554498\n",
      "[EPOCH #11, step #792] loss: 2.2495132372027538\n",
      "[EPOCH #11, step #794] loss: 2.249664184132462\n",
      "[EPOCH #11, step #796] loss: 2.2492665761387634\n",
      "[EPOCH #11, step #798] loss: 2.2493239096616473\n",
      "[EPOCH #11, step #800] loss: 2.249777579277791\n",
      "[EPOCH #11, step #802] loss: 2.250430735080952\n",
      "[EPOCH #11, step #804] loss: 2.250747571672712\n",
      "[EPOCH #11, step #806] loss: 2.2507405310610706\n",
      "[EPOCH #11, step #808] loss: 2.2518199117870354\n",
      "[EPOCH #11, step #810] loss: 2.25185727132381\n",
      "[EPOCH #11, step #812] loss: 2.2515436119112433\n",
      "[EPOCH #11, step #814] loss: 2.2507593804341886\n",
      "[EPOCH #11, step #816] loss: 2.2512023066657263\n",
      "[EPOCH #11, step #818] loss: 2.2504465654219463\n",
      "[EPOCH #11, step #820] loss: 2.2506366323466422\n",
      "[EPOCH #11, step #822] loss: 2.25044956227554\n",
      "[EPOCH #11, step #824] loss: 2.2507054581786647\n",
      "[EPOCH #11, step #826] loss: 2.250768124552707\n",
      "[EPOCH #11, step #828] loss: 2.2505809303072017\n",
      "[EPOCH #11, step #830] loss: 2.251454554166461\n",
      "[EPOCH #11, step #832] loss: 2.2521774863280886\n",
      "[EPOCH #11, step #834] loss: 2.252222285584775\n",
      "[EPOCH #11, step #836] loss: 2.251995713052784\n",
      "[EPOCH #11, step #838] loss: 2.2524463186957413\n",
      "[EPOCH #11, step #840] loss: 2.252338321824136\n",
      "[EPOCH #11, step #842] loss: 2.2518143313069645\n",
      "[EPOCH #11, step #844] loss: 2.252659440887045\n",
      "[EPOCH #11, step #846] loss: 2.2520778849105203\n",
      "[EPOCH #11, step #848] loss: 2.2526889745984118\n",
      "[EPOCH #11, step #850] loss: 2.253031793968658\n",
      "[EPOCH #11, step #852] loss: 2.2527909358528824\n",
      "[EPOCH #11, step #854] loss: 2.2526935330608433\n",
      "[EPOCH #11, step #856] loss: 2.252848833138634\n",
      "[EPOCH #11, step #858] loss: 2.2529544759546085\n",
      "[EPOCH #11, step #860] loss: 2.253083143915449\n",
      "[EPOCH #11, step #862] loss: 2.253253428574095\n",
      "[EPOCH #11, step #864] loss: 2.253276796423631\n",
      "[EPOCH #11, step #866] loss: 2.2525301778467743\n",
      "[EPOCH #11, step #868] loss: 2.2516144044928774\n",
      "[EPOCH #11, step #870] loss: 2.251643628395247\n",
      "[EPOCH #11, step #872] loss: 2.2516674042294254\n",
      "[EPOCH #11, step #874] loss: 2.251786701747349\n",
      "[EPOCH #11, step #876] loss: 2.252087879615879\n",
      "[EPOCH #11, step #878] loss: 2.2515587025534987\n",
      "[EPOCH #11, step #880] loss: 2.25249932762172\n",
      "[EPOCH #11, step #882] loss: 2.2528117329455988\n",
      "[EPOCH #11, step #884] loss: 2.2537032504539707\n",
      "[EPOCH #11, step #886] loss: 2.252948271381546\n",
      "[EPOCH #11, step #888] loss: 2.253554098115327\n",
      "[EPOCH #11, step #890] loss: 2.2537541901891345\n",
      "[EPOCH #11, step #892] loss: 2.2538414149642123\n",
      "[EPOCH #11, step #894] loss: 2.253664095175333\n",
      "[EPOCH #11, step #896] loss: 2.2536256143214843\n",
      "[EPOCH #11, step #898] loss: 2.2538304755897225\n",
      "[EPOCH #11, step #900] loss: 2.2542299292857586\n",
      "[EPOCH #11, step #902] loss: 2.254230422963072\n",
      "[EPOCH #11, step #904] loss: 2.2536903847646976\n",
      "[EPOCH #11, step #906] loss: 2.2537450204216265\n",
      "[EPOCH #11, step #908] loss: 2.2539800265178953\n",
      "[EPOCH #11, step #910] loss: 2.2531714956271007\n",
      "[EPOCH #11, step #912] loss: 2.2532612351702705\n",
      "[EPOCH #11, step #914] loss: 2.2533128187304636\n",
      "[EPOCH #11, step #916] loss: 2.2536458804017196\n",
      "[EPOCH #11, step #918] loss: 2.254115239191107\n",
      "[EPOCH #11, step #920] loss: 2.25488708992605\n",
      "[EPOCH #11, step #922] loss: 2.2546373755546973\n",
      "[EPOCH #11, step #924] loss: 2.2543555477503183\n",
      "[EPOCH #11, step #926] loss: 2.254173001425166\n",
      "[EPOCH #11, step #928] loss: 2.2541716307947017\n",
      "[EPOCH #11, step #930] loss: 2.2538435461697848\n",
      "[EPOCH #11, step #932] loss: 2.25264855136442\n",
      "[EPOCH #11, step #934] loss: 2.253019620263003\n",
      "[EPOCH #11, step #936] loss: 2.2531905932512966\n",
      "[EPOCH #11, step #938] loss: 2.2526821399522157\n",
      "[EPOCH #11, step #940] loss: 2.2524139739248374\n",
      "[EPOCH #11, step #942] loss: 2.2533691338997253\n",
      "[EPOCH #11, step #944] loss: 2.25387895750621\n",
      "[EPOCH #11, step #946] loss: 2.253965642912964\n",
      "[EPOCH #11, step #948] loss: 2.2545724085937437\n",
      "[EPOCH #11, step #950] loss: 2.2544389382772514\n",
      "[EPOCH #11, step #952] loss: 2.254065223405644\n",
      "[EPOCH #11, step #954] loss: 2.2547603876802933\n",
      "[EPOCH #11, step #956] loss: 2.254621066768092\n",
      "[EPOCH #11, step #958] loss: 2.254920415510351\n",
      "[EPOCH #11, step #960] loss: 2.2551321856809334\n",
      "[EPOCH #11, step #962] loss: 2.2550295491084875\n",
      "[EPOCH #11, step #964] loss: 2.255535417764298\n",
      "[EPOCH #11, step #966] loss: 2.2546269701333426\n",
      "[EPOCH #11, step #968] loss: 2.254786672729949\n",
      "[EPOCH #11, step #970] loss: 2.254787205176545\n",
      "[EPOCH #11, step #972] loss: 2.2546347165279252\n",
      "[EPOCH #11, step #974] loss: 2.2543568995060066\n",
      "[EPOCH #11, step #976] loss: 2.254082480741011\n",
      "[EPOCH #11, step #978] loss: 2.253950561030527\n",
      "[EPOCH #11, step #980] loss: 2.2542461648993535\n",
      "[EPOCH #11, step #982] loss: 2.254279986766687\n",
      "[EPOCH #11, step #984] loss: 2.253941895998069\n",
      "[EPOCH #11, step #986] loss: 2.2541241072110734\n",
      "[EPOCH #11, step #988] loss: 2.2541541697643885\n",
      "[EPOCH #11, step #990] loss: 2.254376751262653\n",
      "[EPOCH #11, step #992] loss: 2.2538528928583843\n",
      "[EPOCH #11, step #994] loss: 2.2531833461780644\n",
      "[EPOCH #11, step #996] loss: 2.2526714345038594\n",
      "[EPOCH #11, step #998] loss: 2.253265179909982\n",
      "[EPOCH #11, step #1000] loss: 2.2531564037997525\n",
      "[EPOCH #11, step #1002] loss: 2.253598328958361\n",
      "[EPOCH #11, step #1004] loss: 2.253305885210559\n",
      "[EPOCH #11, step #1006] loss: 2.253710865856046\n",
      "[EPOCH #11, step #1008] loss: 2.253782926158697\n",
      "[EPOCH #11, step #1010] loss: 2.2541134904565254\n",
      "[EPOCH #11, step #1012] loss: 2.2536519734080427\n",
      "[EPOCH #11, step #1014] loss: 2.254554265355829\n",
      "[EPOCH #11, step #1016] loss: 2.255063225503282\n",
      "[EPOCH #11, step #1018] loss: 2.2548547200529567\n",
      "[EPOCH #11, step #1020] loss: 2.254525731989966\n",
      "[EPOCH #11, step #1022] loss: 2.2546351697088336\n",
      "[EPOCH #11, step #1024] loss: 2.2548693991870414\n",
      "[EPOCH #11, step #1026] loss: 2.255481398210089\n",
      "[EPOCH #11, step #1028] loss: 2.2554880905429404\n",
      "[EPOCH #11, step #1030] loss: 2.2552263917099724\n",
      "[EPOCH #11, step #1032] loss: 2.2558328722245697\n",
      "[EPOCH #11, step #1034] loss: 2.25594227809261\n",
      "[EPOCH #11, step #1036] loss: 2.2570094938103464\n",
      "[EPOCH #11, step #1038] loss: 2.2575076590144256\n",
      "[EPOCH #11, step #1040] loss: 2.258597908056664\n",
      "[EPOCH #11, step #1042] loss: 2.2590872347640625\n",
      "[EPOCH #11, step #1044] loss: 2.2590311664143248\n",
      "[EPOCH #11, step #1046] loss: 2.259446114956365\n",
      "[EPOCH #11, step #1048] loss: 2.2597721686695054\n",
      "[EPOCH #11, step #1050] loss: 2.2594072771117757\n",
      "[EPOCH #11, step #1052] loss: 2.2596498217224963\n",
      "[EPOCH #11, step #1054] loss: 2.259915976275765\n",
      "[EPOCH #11, step #1056] loss: 2.2597173999364126\n",
      "[EPOCH #11, step #1058] loss: 2.2600079577862937\n",
      "[EPOCH #11, step #1060] loss: 2.259301022917004\n",
      "[EPOCH #11, step #1062] loss: 2.2594329599827274\n",
      "[EPOCH #11, step #1064] loss: 2.259602408789693\n",
      "[EPOCH #11, step #1066] loss: 2.259780275788169\n",
      "[EPOCH #11, step #1068] loss: 2.259319352033096\n",
      "[EPOCH #11, step #1070] loss: 2.259251560261047\n",
      "[EPOCH #11, step #1072] loss: 2.2592565726700613\n",
      "[EPOCH #11, step #1074] loss: 2.2590220537851025\n",
      "[EPOCH #11, step #1076] loss: 2.2587852139326854\n",
      "[EPOCH #11, step #1078] loss: 2.2591944593760127\n",
      "[EPOCH #11, step #1080] loss: 2.2593433488639385\n",
      "[EPOCH #11, step #1082] loss: 2.259179084254764\n",
      "[EPOCH #11, step #1084] loss: 2.2584794908075287\n",
      "[EPOCH #11, step #1086] loss: 2.2581408063314767\n",
      "[EPOCH #11, step #1088] loss: 2.2587333021085123\n",
      "[EPOCH #11, step #1090] loss: 2.2585898564563336\n",
      "[EPOCH #11, step #1092] loss: 2.2584512183563707\n",
      "[EPOCH #11, step #1094] loss: 2.2588008765216285\n",
      "[EPOCH #11, step #1096] loss: 2.258697828816194\n",
      "[EPOCH #11, step #1098] loss: 2.258691087649886\n",
      "[EPOCH #11, step #1100] loss: 2.259237985844833\n",
      "[EPOCH #11, step #1102] loss: 2.2588847759952353\n",
      "[EPOCH #11, step #1104] loss: 2.258737117025108\n",
      "[EPOCH #11, step #1106] loss: 2.2585793818669373\n",
      "[EPOCH #11, step #1108] loss: 2.258758000364381\n",
      "[EPOCH #11, step #1110] loss: 2.258870393279219\n",
      "[EPOCH #11, step #1112] loss: 2.259137572625255\n",
      "[EPOCH #11, step #1114] loss: 2.2592868336647616\n",
      "[EPOCH #11, step #1116] loss: 2.2591063472556554\n",
      "[EPOCH #11, step #1118] loss: 2.2592981790622715\n",
      "[EPOCH #11, step #1120] loss: 2.258906747909873\n",
      "[EPOCH #11, step #1122] loss: 2.2590284861312417\n",
      "[EPOCH #11, step #1124] loss: 2.2595196022457547\n",
      "[EPOCH #11, step #1126] loss: 2.2587669394983054\n",
      "[EPOCH #11, step #1128] loss: 2.2593220452274023\n",
      "[EPOCH #11, step #1130] loss: 2.2595106815469674\n",
      "[EPOCH #11, step #1132] loss: 2.259719844634619\n",
      "[EPOCH #11, step #1134] loss: 2.2587659533328424\n",
      "[EPOCH #11, step #1136] loss: 2.259004145310233\n",
      "[EPOCH #11, step #1138] loss: 2.258316492804108\n",
      "[EPOCH #11, step #1140] loss: 2.258213669035541\n",
      "[EPOCH #11, step #1142] loss: 2.2577978958712266\n",
      "[EPOCH #11, step #1144] loss: 2.2577917872557993\n",
      "[EPOCH #11, step #1146] loss: 2.2583159888008937\n",
      "[EPOCH #11, step #1148] loss: 2.2584515175059945\n",
      "[EPOCH #11, step #1150] loss: 2.2581843903124796\n",
      "[EPOCH #11, step #1152] loss: 2.257609071570278\n",
      "[EPOCH #11, step #1154] loss: 2.2578424906833865\n",
      "[EPOCH #11, step #1156] loss: 2.2581486511354107\n",
      "[EPOCH #11, step #1158] loss: 2.2586671068711563\n",
      "[EPOCH #11, step #1160] loss: 2.258657663778228\n",
      "[EPOCH #11, step #1162] loss: 2.2587986909820414\n",
      "[EPOCH #11, step #1164] loss: 2.2585679604771824\n",
      "[EPOCH #11, step #1166] loss: 2.2590394769863074\n",
      "[EPOCH #11, step #1168] loss: 2.2592728794691803\n",
      "[EPOCH #11, step #1170] loss: 2.260000783087961\n",
      "[EPOCH #11, step #1172] loss: 2.2607001020475423\n",
      "[EPOCH #11, step #1174] loss: 2.2609844209792764\n",
      "[EPOCH #11, step #1176] loss: 2.261107988649237\n",
      "[EPOCH #11, step #1178] loss: 2.2611462645251637\n",
      "[EPOCH #11, step #1180] loss: 2.2605982702935177\n",
      "[EPOCH #11, step #1182] loss: 2.2608602778546807\n",
      "[EPOCH #11, step #1184] loss: 2.2611029852291704\n",
      "[EPOCH #11, step #1186] loss: 2.260404715240755\n",
      "[EPOCH #11, step #1188] loss: 2.2604782261499543\n",
      "[EPOCH #11, step #1190] loss: 2.2604983184239527\n",
      "[EPOCH #11, step #1192] loss: 2.259823801231704\n",
      "[EPOCH #11, step #1194] loss: 2.2596829748552714\n",
      "[EPOCH #11, step #1196] loss: 2.2595667650825098\n",
      "[EPOCH #11, step #1198] loss: 2.2596876455208377\n",
      "[EPOCH #11, step #1200] loss: 2.2595390438735734\n",
      "[EPOCH #11, step #1202] loss: 2.2599275224127577\n",
      "[EPOCH #11, step #1204] loss: 2.2599758143246915\n",
      "[EPOCH #11, step #1206] loss: 2.260309954665373\n",
      "[EPOCH #11, step #1208] loss: 2.2601479418125896\n",
      "[EPOCH #11, step #1210] loss: 2.260089629548921\n",
      "[EPOCH #11, step #1212] loss: 2.260573656423369\n",
      "[EPOCH #11, step #1214] loss: 2.260228460315814\n",
      "[EPOCH #11, step #1216] loss: 2.2600213365664517\n",
      "[EPOCH #11, step #1218] loss: 2.259779523297154\n",
      "[EPOCH #11, step #1220] loss: 2.2599175558238613\n",
      "[EPOCH #11, step #1222] loss: 2.2599462371133723\n",
      "[EPOCH #11, step #1224] loss: 2.2594196515180625\n",
      "[EPOCH #11, step #1226] loss: 2.2601497149020555\n",
      "[EPOCH #11, step #1228] loss: 2.2604780244672074\n",
      "[EPOCH #11, step #1230] loss: 2.2601094425063515\n",
      "[EPOCH #11, step #1232] loss: 2.2595048241758384\n",
      "[EPOCH #11, step #1234] loss: 2.2591948665588006\n",
      "[EPOCH #11, step #1236] loss: 2.258435577178252\n",
      "[EPOCH #11, step #1238] loss: 2.2584763433396384\n",
      "[EPOCH #11, step #1240] loss: 2.258268302338052\n",
      "[EPOCH #11, step #1242] loss: 2.2581235712224785\n",
      "[EPOCH #11, step #1244] loss: 2.258178736981618\n",
      "[EPOCH #11, step #1246] loss: 2.2579842435902564\n",
      "[EPOCH #11, step #1248] loss: 2.258011816595916\n",
      "[EPOCH #11, step #1250] loss: 2.2579067489035505\n",
      "[EPOCH #11, step #1252] loss: 2.257224295487522\n",
      "[EPOCH #11, step #1254] loss: 2.2569675044709467\n",
      "[EPOCH #11, step #1256] loss: 2.256391761031716\n",
      "[EPOCH #11, step #1258] loss: 2.255888107184667\n",
      "[EPOCH #11, step #1260] loss: 2.255799593195662\n",
      "[EPOCH #11, step #1262] loss: 2.2561981402402442\n",
      "[EPOCH #11, step #1264] loss: 2.256561397281089\n",
      "[EPOCH #11, step #1266] loss: 2.2564129928198966\n",
      "[EPOCH #11, step #1268] loss: 2.2564538260723683\n",
      "[EPOCH #11, step #1270] loss: 2.2562821223733933\n",
      "[EPOCH #11, step #1272] loss: 2.2567847171170636\n",
      "[EPOCH #11, step #1274] loss: 2.2570518047669355\n",
      "[EPOCH #11, step #1276] loss: 2.257436043318119\n",
      "[EPOCH #11, step #1278] loss: 2.257734508137856\n",
      "[EPOCH #11, step #1280] loss: 2.2578815720585714\n",
      "[EPOCH #11, step #1282] loss: 2.2573467457749743\n",
      "[EPOCH #11, step #1284] loss: 2.257573234710248\n",
      "[EPOCH #11, step #1286] loss: 2.2573007028419654\n",
      "[EPOCH #11, step #1288] loss: 2.257552455154105\n",
      "[EPOCH #11, step #1290] loss: 2.2574282282549314\n",
      "[EPOCH #11, step #1292] loss: 2.257555924638334\n",
      "[EPOCH #11, step #1294] loss: 2.257726654122695\n",
      "[EPOCH #11, step #1296] loss: 2.257229994790041\n",
      "[EPOCH #11, step #1298] loss: 2.2572256827739867\n",
      "[EPOCH #11, step #1300] loss: 2.2568395046157894\n",
      "[EPOCH #11, step #1302] loss: 2.2570000128478886\n",
      "[EPOCH #11, step #1304] loss: 2.2572923210845595\n",
      "[EPOCH #11, step #1306] loss: 2.257056722954748\n",
      "[EPOCH #11, step #1308] loss: 2.2567279770503617\n",
      "[EPOCH #11, step #1310] loss: 2.2571351089884906\n",
      "[EPOCH #11, step #1312] loss: 2.257101349856049\n",
      "[EPOCH #11, step #1314] loss: 2.2571400141987965\n",
      "[EPOCH #11, step #1316] loss: 2.257579242449958\n",
      "[EPOCH #11, step #1318] loss: 2.2574876735750884\n",
      "[EPOCH #11, step #1320] loss: 2.257421845111948\n",
      "[EPOCH #11, step #1322] loss: 2.257548401415213\n",
      "[EPOCH #11, step #1324] loss: 2.257399587811164\n",
      "[EPOCH #11, step #1326] loss: 2.2577579736529927\n",
      "[EPOCH #11, step #1328] loss: 2.257137536733468\n",
      "[EPOCH #11, step #1330] loss: 2.2570646863338375\n",
      "[EPOCH #11, step #1332] loss: 2.2569272731894046\n",
      "[EPOCH #11, step #1334] loss: 2.2572252485189543\n",
      "[EPOCH #11, step #1336] loss: 2.2570815796092454\n",
      "[EPOCH #11, step #1338] loss: 2.2569622243848464\n",
      "[EPOCH #11, step #1340] loss: 2.256455921042241\n",
      "[EPOCH #11, step #1342] loss: 2.256631448920414\n",
      "[EPOCH #11, step #1344] loss: 2.257005989684491\n",
      "[EPOCH #11, step #1346] loss: 2.2574008709426803\n",
      "[EPOCH #11, step #1348] loss: 2.257412056997142\n",
      "[EPOCH #11, step #1350] loss: 2.257482851813406\n",
      "[EPOCH #11, step #1352] loss: 2.2565266151209715\n",
      "[EPOCH #11, step #1354] loss: 2.256590610412654\n",
      "[EPOCH #11, step #1356] loss: 2.2560283015911073\n",
      "[EPOCH #11, step #1358] loss: 2.25598599991437\n",
      "[EPOCH #11, step #1360] loss: 2.2560499566692713\n",
      "[EPOCH #11, step #1362] loss: 2.255976128123389\n",
      "[EPOCH #11, step #1364] loss: 2.25610632451026\n",
      "[EPOCH #11, step #1366] loss: 2.2561492435933905\n",
      "[EPOCH #11, step #1368] loss: 2.2565646498110974\n",
      "[EPOCH #11, step #1370] loss: 2.256268787784006\n",
      "[EPOCH #11, step #1372] loss: 2.255981444010141\n",
      "[EPOCH #11, step #1374] loss: 2.2561500626477327\n",
      "[EPOCH #11, step #1376] loss: 2.256140240829928\n",
      "[EPOCH #11, step #1378] loss: 2.256150484517314\n",
      "[EPOCH #11, step #1380] loss: 2.2558516779298112\n",
      "[EPOCH #11, step #1382] loss: 2.25609900446276\n",
      "[EPOCH #11, step #1384] loss: 2.2561024915440417\n",
      "[EPOCH #11, step #1386] loss: 2.2558527766326044\n",
      "[EPOCH #11, step #1388] loss: 2.255783265404258\n",
      "[EPOCH #11, step #1390] loss: 2.25558531635704\n",
      "[EPOCH #11, step #1392] loss: 2.25544533828823\n",
      "[EPOCH #11, step #1394] loss: 2.255590728021437\n",
      "[EPOCH #11, step #1396] loss: 2.255289897973314\n",
      "[EPOCH #11, step #1398] loss: 2.2558480479872336\n",
      "[EPOCH #11, step #1400] loss: 2.255417066076498\n",
      "[EPOCH #11, step #1402] loss: 2.255084565683339\n",
      "[EPOCH #11, step #1404] loss: 2.2549050808801345\n",
      "[EPOCH #11, step #1406] loss: 2.254566935418596\n",
      "[EPOCH #11, step #1408] loss: 2.255050432013653\n",
      "[EPOCH #11, step #1410] loss: 2.2551180036417735\n",
      "[EPOCH #11, step #1412] loss: 2.254980231799391\n",
      "[EPOCH #11, step #1414] loss: 2.254879185420464\n",
      "[EPOCH #11, step #1416] loss: 2.2547068771713623\n",
      "[EPOCH #11, step #1418] loss: 2.2548908620253676\n",
      "[EPOCH #11, step #1420] loss: 2.2547003228760034\n",
      "[EPOCH #11, step #1422] loss: 2.25529046495951\n",
      "[EPOCH #11, step #1424] loss: 2.255518399707058\n",
      "[EPOCH #11, step #1426] loss: 2.255484832193606\n",
      "[EPOCH #11, step #1428] loss: 2.2557120570942937\n",
      "[EPOCH #11, step #1430] loss: 2.2554225174386047\n",
      "[EPOCH #11, step #1432] loss: 2.255237037455046\n",
      "[EPOCH #11, step #1434] loss: 2.2550856736478906\n",
      "[EPOCH #11, step #1436] loss: 2.2552612659080045\n",
      "[EPOCH #11, step #1438] loss: 2.2554252051578123\n",
      "[EPOCH #11, step #1440] loss: 2.2551406253798816\n",
      "[EPOCH #11, step #1442] loss: 2.2553552783204713\n",
      "[EPOCH #11, step #1444] loss: 2.255376032974481\n",
      "[EPOCH #11, step #1446] loss: 2.25530144825588\n",
      "[EPOCH #11, step #1448] loss: 2.254981866205372\n",
      "[EPOCH #11, step #1450] loss: 2.254585528850227\n",
      "[EPOCH #11, step #1452] loss: 2.2539306486054937\n",
      "[EPOCH #11, step #1454] loss: 2.253993481049423\n",
      "[EPOCH #11, step #1456] loss: 2.2540877274478555\n",
      "[EPOCH #11, step #1458] loss: 2.2542109950263667\n",
      "[EPOCH #11, step #1460] loss: 2.2543619405236006\n",
      "[EPOCH #11, step #1462] loss: 2.254403875204935\n",
      "[EPOCH #11, step #1464] loss: 2.2539432935747272\n",
      "[EPOCH #11, step #1466] loss: 2.254149242737867\n",
      "[EPOCH #11, step #1468] loss: 2.2537743574587807\n",
      "[EPOCH #11, step #1470] loss: 2.254133494349259\n",
      "[EPOCH #11, step #1472] loss: 2.2540781929310048\n",
      "[EPOCH #11, step #1474] loss: 2.2539497849900845\n",
      "[EPOCH #11, step #1476] loss: 2.2540591625886424\n",
      "[EPOCH #11, step #1478] loss: 2.253617113631186\n",
      "[EPOCH #11, step #1480] loss: 2.2542997175257886\n",
      "[EPOCH #11, step #1482] loss: 2.254324091903599\n",
      "[EPOCH #11, step #1484] loss: 2.2546203659038353\n",
      "[EPOCH #11, step #1486] loss: 2.255005167968817\n",
      "[EPOCH #11, step #1488] loss: 2.254662475784486\n",
      "[EPOCH #11, step #1490] loss: 2.2543424002521393\n",
      "[EPOCH #11, step #1492] loss: 2.254851469958459\n",
      "[EPOCH #11, step #1494] loss: 2.254664911314795\n",
      "[EPOCH #11, step #1496] loss: 2.254783057656858\n",
      "[EPOCH #11, step #1498] loss: 2.254634943781414\n",
      "[EPOCH #11, step #1500] loss: 2.2540350826004203\n",
      "[EPOCH #11, step #1502] loss: 2.2540451376262065\n",
      "[EPOCH #11, step #1504] loss: 2.2542421359952503\n",
      "[EPOCH #11, step #1506] loss: 2.2541224627441023\n",
      "[EPOCH #11, step #1508] loss: 2.2541396534150606\n",
      "[EPOCH #11, step #1510] loss: 2.2541832821326566\n",
      "[EPOCH #11, step #1512] loss: 2.253615446620167\n",
      "[EPOCH #11, step #1514] loss: 2.2533055450263197\n",
      "[EPOCH #11, step #1516] loss: 2.2535674763731683\n",
      "[EPOCH #11, step #1518] loss: 2.253959882251521\n",
      "[EPOCH #11, step #1520] loss: 2.253864371721718\n",
      "[EPOCH #11, step #1522] loss: 2.2535240912390475\n",
      "[EPOCH #11, step #1524] loss: 2.2533903983381927\n",
      "[EPOCH #11, step #1526] loss: 2.2535075430941878\n",
      "[EPOCH #11, step #1528] loss: 2.2535206850562086\n",
      "[EPOCH #11, step #1530] loss: 2.2536233893256807\n",
      "[EPOCH #11, step #1532] loss: 2.2535992334344694\n",
      "[EPOCH #11, step #1534] loss: 2.253463413583339\n",
      "[EPOCH #11, step #1536] loss: 2.2536370675906627\n",
      "[EPOCH #11, step #1538] loss: 2.2539123498130884\n",
      "[EPOCH #11, step #1540] loss: 2.254377655283651\n",
      "[EPOCH #11, step #1542] loss: 2.2538689403509213\n",
      "[EPOCH #11, step #1544] loss: 2.253507804561973\n",
      "[EPOCH #11, step #1546] loss: 2.2531813210491682\n",
      "[EPOCH #11, step #1548] loss: 2.2532154629506014\n",
      "[EPOCH #11, step #1550] loss: 2.2531600710962914\n",
      "[EPOCH #11, step #1552] loss: 2.2531446794195475\n",
      "[EPOCH #11, step #1554] loss: 2.2529758095357963\n",
      "[EPOCH #11, step #1556] loss: 2.252708370056226\n",
      "[EPOCH #11, step #1558] loss: 2.2528058013677446\n",
      "[EPOCH #11, step #1560] loss: 2.252785877338363\n",
      "[EPOCH #11, step #1562] loss: 2.252590787387855\n",
      "[EPOCH #11, step #1564] loss: 2.2524430978031584\n",
      "[EPOCH #11, step #1566] loss: 2.252277562628906\n",
      "[EPOCH #11, step #1568] loss: 2.2518602893031883\n",
      "[EPOCH #11, step #1570] loss: 2.2522626794272362\n",
      "[EPOCH #11, step #1572] loss: 2.2522741587239317\n",
      "[EPOCH #11, step #1574] loss: 2.2531429423983136\n",
      "[EPOCH #11, step #1576] loss: 2.253638479629497\n",
      "[EPOCH #11, step #1578] loss: 2.253668459251457\n",
      "[EPOCH #11, step #1580] loss: 2.2536953887481013\n",
      "[EPOCH #11, step #1582] loss: 2.2532703783869064\n",
      "[EPOCH #11, step #1584] loss: 2.2530622309314716\n",
      "[EPOCH #11, step #1586] loss: 2.252698399919944\n",
      "[EPOCH #11, step #1588] loss: 2.252630801152853\n",
      "[EPOCH #11, step #1590] loss: 2.2524652087710924\n",
      "[EPOCH #11, step #1592] loss: 2.2525332690183277\n",
      "[EPOCH #11, step #1594] loss: 2.2523739389491304\n",
      "[EPOCH #11, step #1596] loss: 2.2524881795114027\n",
      "[EPOCH #11, step #1598] loss: 2.252711631791006\n",
      "[EPOCH #11, step #1600] loss: 2.252479199317751\n",
      "[EPOCH #11, step #1602] loss: 2.252345162559433\n",
      "[EPOCH #11, step #1604] loss: 2.2522195216651273\n",
      "[EPOCH #11, step #1606] loss: 2.2523032067796795\n",
      "[EPOCH #11, step #1608] loss: 2.2520716768232765\n",
      "[EPOCH #11, step #1610] loss: 2.251964178979212\n",
      "[EPOCH #11, step #1612] loss: 2.251537466448283\n",
      "[EPOCH #11, step #1614] loss: 2.2518338204168313\n",
      "[EPOCH #11, step #1616] loss: 2.2517916618782428\n",
      "[EPOCH #11, step #1618] loss: 2.2517742967075445\n",
      "[EPOCH #11, step #1620] loss: 2.2516066481639103\n",
      "[EPOCH #11, step #1622] loss: 2.251836641365117\n",
      "[EPOCH #11, step #1624] loss: 2.2519405355453492\n",
      "[EPOCH #11, step #1626] loss: 2.25193862374311\n",
      "[EPOCH #11, step #1628] loss: 2.2517272988442922\n",
      "[EPOCH #11, step #1630] loss: 2.2517567369413114\n",
      "[EPOCH #11, step #1632] loss: 2.2516407512552665\n",
      "[EPOCH #11, step #1634] loss: 2.2514696344323113\n",
      "[EPOCH #11, step #1636] loss: 2.2513163759712773\n",
      "[EPOCH #11, step #1638] loss: 2.2511326264433196\n",
      "[EPOCH #11, step #1640] loss: 2.25093131876079\n",
      "[EPOCH #11, step #1642] loss: 2.250770844705063\n",
      "[EPOCH #11, step #1644] loss: 2.2508205730502002\n",
      "[EPOCH #11, step #1646] loss: 2.25088244253169\n",
      "[EPOCH #11, step #1648] loss: 2.2507671806001173\n",
      "[EPOCH #11, step #1650] loss: 2.250520731953691\n",
      "[EPOCH #11, step #1652] loss: 2.250656559549529\n",
      "[EPOCH #11, step #1654] loss: 2.2505049225066722\n",
      "[EPOCH #11, step #1656] loss: 2.2504899010430925\n",
      "[EPOCH #11, step #1658] loss: 2.250284266730545\n",
      "[EPOCH #11, step #1660] loss: 2.2502984887932094\n",
      "[EPOCH #11, step #1662] loss: 2.2501896809040605\n",
      "[EPOCH #11, step #1664] loss: 2.250157141399097\n",
      "[EPOCH #11, step #1666] loss: 2.2501549521247712\n",
      "[EPOCH #11, step #1668] loss: 2.2497517696178337\n",
      "[EPOCH #11, step #1670] loss: 2.2499743413240307\n",
      "[EPOCH #11, step #1672] loss: 2.249622051899688\n",
      "[EPOCH #11, step #1674] loss: 2.249865967835953\n",
      "[EPOCH #11, step #1676] loss: 2.249631869771613\n",
      "[EPOCH #11, step #1678] loss: 2.2495369510752874\n",
      "[EPOCH #11, step #1680] loss: 2.249671933907685\n",
      "[EPOCH #11, step #1682] loss: 2.2496360517015646\n",
      "[EPOCH #11, step #1684] loss: 2.249324193411128\n",
      "[EPOCH #11, step #1686] loss: 2.248892671693057\n",
      "[EPOCH #11, step #1688] loss: 2.248903974899531\n",
      "[EPOCH #11, step #1690] loss: 2.2488453304323484\n",
      "[EPOCH #11, step #1692] loss: 2.2490470470652664\n",
      "[EPOCH #11, step #1694] loss: 2.2493291050986906\n",
      "[EPOCH #11, step #1696] loss: 2.2495228000156446\n",
      "[EPOCH #11, step #1698] loss: 2.2495475970274423\n",
      "[EPOCH #11, step #1700] loss: 2.2499715354006686\n",
      "[EPOCH #11, step #1702] loss: 2.2498273084391864\n",
      "[EPOCH #11, step #1704] loss: 2.249481266334959\n",
      "[EPOCH #11, step #1706] loss: 2.2497566521482013\n",
      "[EPOCH #11, step #1708] loss: 2.2492318648633516\n",
      "[EPOCH #11, step #1710] loss: 2.2490662766227523\n",
      "[EPOCH #11, step #1712] loss: 2.2490517843277638\n",
      "[EPOCH #11, step #1714] loss: 2.248967025578891\n",
      "[EPOCH #11, step #1716] loss: 2.248963022204284\n",
      "[EPOCH #11, step #1718] loss: 2.24884389575794\n",
      "[EPOCH #11, step #1720] loss: 2.2489353277044613\n",
      "[EPOCH #11, step #1722] loss: 2.248496347088075\n",
      "[EPOCH #11, step #1724] loss: 2.24839941183726\n",
      "[EPOCH #11, step #1726] loss: 2.2486979389163064\n",
      "[EPOCH #11, step #1728] loss: 2.248888674673143\n",
      "[EPOCH #11, step #1730] loss: 2.248789890386823\n",
      "[EPOCH #11, step #1732] loss: 2.2485816546829187\n",
      "[EPOCH #11, step #1734] loss: 2.2483700422457384\n",
      "[EPOCH #11, step #1736] loss: 2.2486807700197247\n",
      "[EPOCH #11, step #1738] loss: 2.2486512370326177\n",
      "[EPOCH #11, step #1740] loss: 2.2485846236545006\n",
      "[EPOCH #11, step #1742] loss: 2.2486274141179234\n",
      "[EPOCH #11, step #1744] loss: 2.248675914070326\n",
      "[EPOCH #11, step #1746] loss: 2.248794071593828\n",
      "[EPOCH #11, step #1748] loss: 2.248873699045372\n",
      "[EPOCH #11, step #1750] loss: 2.248532573268592\n",
      "[EPOCH #11, step #1752] loss: 2.2485662774229076\n",
      "[EPOCH #11, step #1754] loss: 2.248707563313324\n",
      "[EPOCH #11, step #1756] loss: 2.248747255561972\n",
      "[EPOCH #11, step #1758] loss: 2.2491170011371833\n",
      "[EPOCH #11, step #1760] loss: 2.248622969833712\n",
      "[EPOCH #11, step #1762] loss: 2.248619302118359\n",
      "[EPOCH #11, step #1764] loss: 2.2489598639626003\n",
      "[EPOCH #11, step #1766] loss: 2.249071991571816\n",
      "[EPOCH #11, step #1768] loss: 2.249005835833962\n",
      "[EPOCH #11, step #1770] loss: 2.2488824402390732\n",
      "[EPOCH #11, step #1772] loss: 2.248859560496378\n",
      "[EPOCH #11, step #1774] loss: 2.249063767513759\n",
      "[EPOCH #11, step #1776] loss: 2.2485399911023958\n",
      "[EPOCH #11, step #1778] loss: 2.248777397500457\n",
      "[EPOCH #11, step #1780] loss: 2.2489005004603295\n",
      "[EPOCH #11, step #1782] loss: 2.2489325135728984\n",
      "[EPOCH #11, step #1784] loss: 2.2485459281616853\n",
      "[EPOCH #11, step #1786] loss: 2.2485251905001538\n",
      "[EPOCH #11, step #1788] loss: 2.2481660045945757\n",
      "[EPOCH #11, step #1790] loss: 2.2479288198640397\n",
      "[EPOCH #11, step #1792] loss: 2.2476170181363773\n",
      "[EPOCH #11, step #1794] loss: 2.2478550496539698\n",
      "[EPOCH #11, step #1796] loss: 2.247546624460682\n",
      "[EPOCH #11, step #1798] loss: 2.2473160660618077\n",
      "[EPOCH #11, step #1800] loss: 2.247242813901991\n",
      "[EPOCH #11, step #1802] loss: 2.247030361057055\n",
      "[EPOCH #11, step #1804] loss: 2.247201891288863\n",
      "[EPOCH #11, step #1806] loss: 2.2469005247605858\n",
      "[EPOCH #11, step #1808] loss: 2.2462863887852236\n",
      "[EPOCH #11, step #1810] loss: 2.2462111056542144\n",
      "[EPOCH #11, step #1812] loss: 2.246195702018885\n",
      "[EPOCH #11, step #1814] loss: 2.246073909764776\n",
      "[EPOCH #11, step #1816] loss: 2.245875691803327\n",
      "[EPOCH #11, step #1818] loss: 2.246031582584874\n",
      "[EPOCH #11, step #1820] loss: 2.2461412604335638\n",
      "[EPOCH #11, step #1822] loss: 2.245935544951957\n",
      "[EPOCH #11, step #1824] loss: 2.2459242491526146\n",
      "[EPOCH #11, step #1826] loss: 2.246016775250239\n",
      "[EPOCH #11, step #1828] loss: 2.245675398522612\n",
      "[EPOCH #11, step #1830] loss: 2.2457223599364626\n",
      "[EPOCH #11, step #1832] loss: 2.2458749744193645\n",
      "[EPOCH #11, step #1834] loss: 2.245692979867192\n",
      "[EPOCH #11, step #1836] loss: 2.2456055948379965\n",
      "[EPOCH #11, step #1838] loss: 2.24563897680238\n",
      "[EPOCH #11, step #1840] loss: 2.245956267370341\n",
      "[EPOCH #11, step #1842] loss: 2.24577712385278\n",
      "[EPOCH #11, step #1844] loss: 2.2459218003885533\n",
      "[EPOCH #11, step #1846] loss: 2.245719881204895\n",
      "[EPOCH #11, step #1848] loss: 2.2460037651675786\n",
      "[EPOCH #11, step #1850] loss: 2.2455803679492523\n",
      "[EPOCH #11, step #1852] loss: 2.245417221648849\n",
      "[EPOCH #11, step #1854] loss: 2.24579925087263\n",
      "[EPOCH #11, step #1856] loss: 2.245691177340432\n",
      "[EPOCH #11, step #1858] loss: 2.24574726585934\n",
      "[EPOCH #11, step #1860] loss: 2.2458051803738504\n",
      "[EPOCH #11, step #1862] loss: 2.245321441899687\n",
      "[EPOCH #11, step #1864] loss: 2.245135141569552\n",
      "[EPOCH #11, step #1866] loss: 2.245322755331909\n",
      "[EPOCH #11, step #1868] loss: 2.245067886517863\n",
      "[EPOCH #11, step #1870] loss: 2.245046453384204\n",
      "[EPOCH #11, step #1872] loss: 2.2453050276078583\n",
      "[EPOCH #11, step #1874] loss: 2.245658095296224\n",
      "[EPOCH #11, step #1876] loss: 2.2460786341096597\n",
      "[EPOCH #11, step #1878] loss: 2.2463021369739185\n",
      "[EPOCH #11, step #1880] loss: 2.2461279365751476\n",
      "[EPOCH #11, step #1882] loss: 2.2458878926501527\n",
      "[EPOCH #11, step #1884] loss: 2.2456716529254255\n",
      "[EPOCH #11, step #1886] loss: 2.245753322193467\n",
      "[EPOCH #11, step #1888] loss: 2.2456350870521185\n",
      "[EPOCH #11, step #1890] loss: 2.2455030871345403\n",
      "[EPOCH #11, step #1892] loss: 2.2458846700676394\n",
      "[EPOCH #11, step #1894] loss: 2.2457981144218144\n",
      "[EPOCH #11, step #1896] loss: 2.245724811450896\n",
      "[EPOCH #11, step #1898] loss: 2.245474510220492\n",
      "[EPOCH #11, step #1900] loss: 2.245406890718138\n",
      "[EPOCH #11, step #1902] loss: 2.245133398835808\n",
      "[EPOCH #11, step #1904] loss: 2.244950044937334\n",
      "[EPOCH #11, step #1906] loss: 2.244960110413822\n",
      "[EPOCH #11, step #1908] loss: 2.244530752480748\n",
      "[EPOCH #11, step #1910] loss: 2.2447291084261605\n",
      "[EPOCH #11, step #1912] loss: 2.2446985598079086\n",
      "[EPOCH #11, step #1914] loss: 2.2449600916307215\n",
      "[EPOCH #11, step #1916] loss: 2.2450081679618292\n",
      "[EPOCH #11, step #1918] loss: 2.244785189628601\n",
      "[EPOCH #11, step #1920] loss: 2.2445737050263475\n",
      "[EPOCH #11, step #1922] loss: 2.244269010801211\n",
      "[EPOCH #11, step #1924] loss: 2.244663480473803\n",
      "[EPOCH #11, step #1926] loss: 2.244781381241324\n",
      "[EPOCH #11, step #1928] loss: 2.244687694598505\n",
      "[EPOCH #11, step #1930] loss: 2.2448252937078848\n",
      "[EPOCH #11, step #1932] loss: 2.245013813558047\n",
      "[EPOCH #11, step #1934] loss: 2.2453157726184343\n",
      "[EPOCH #11, step #1936] loss: 2.245297967802943\n",
      "[EPOCH #11, step #1938] loss: 2.245233313025366\n",
      "[EPOCH #11, step #1940] loss: 2.245474208267247\n",
      "[EPOCH #11, step #1942] loss: 2.245423587829994\n",
      "[EPOCH #11, step #1944] loss: 2.245433752273226\n",
      "[EPOCH #11, step #1946] loss: 2.2455577842382266\n",
      "[EPOCH #11, step #1948] loss: 2.245363382329202\n",
      "[EPOCH #11, step #1950] loss: 2.2449696539977095\n",
      "[EPOCH #11, step #1952] loss: 2.245387393574927\n",
      "[EPOCH #11, step #1954] loss: 2.245199083855085\n",
      "[EPOCH #11, step #1956] loss: 2.2448859875702896\n",
      "[EPOCH #11, step #1958] loss: 2.2445229677718292\n",
      "[EPOCH #11, step #1960] loss: 2.244684595954716\n",
      "[EPOCH #11, step #1962] loss: 2.244568788209741\n",
      "[EPOCH #11, step #1964] loss: 2.2446288228944966\n",
      "[EPOCH #11, step #1966] loss: 2.244362533425824\n",
      "[EPOCH #11, step #1968] loss: 2.244498064579729\n",
      "[EPOCH #11, step #1970] loss: 2.244170799284402\n",
      "[EPOCH #11, step #1972] loss: 2.244224425928277\n",
      "[EPOCH #11, step #1974] loss: 2.2440703039531464\n",
      "[EPOCH #11, step #1976] loss: 2.2437649887501743\n",
      "[EPOCH #11, step #1978] loss: 2.2440011298915485\n",
      "[EPOCH #11, step #1980] loss: 2.2441605072560664\n",
      "[EPOCH #11, step #1982] loss: 2.244081472124166\n",
      "[EPOCH #11, step #1984] loss: 2.2439902604076662\n",
      "[EPOCH #11, step #1986] loss: 2.243717730795251\n",
      "[EPOCH #11, step #1988] loss: 2.243854573649219\n",
      "[EPOCH #11, step #1990] loss: 2.2438395419712345\n",
      "[EPOCH #11, step #1992] loss: 2.243900854744268\n",
      "[EPOCH #11, step #1994] loss: 2.243841832502743\n",
      "[EPOCH #11, step #1996] loss: 2.243846425785682\n",
      "[EPOCH #11, step #1998] loss: 2.2436723814063098\n",
      "[EPOCH #11, step #2000] loss: 2.2436885282077057\n",
      "[EPOCH #11, step #2002] loss: 2.243581124680434\n",
      "[EPOCH #11, step #2004] loss: 2.243210230028243\n",
      "[EPOCH #11, step #2006] loss: 2.243062767866065\n",
      "[EPOCH #11, step #2008] loss: 2.2428512167966206\n",
      "[EPOCH #11, step #2010] loss: 2.2430734095556826\n",
      "[EPOCH #11, step #2012] loss: 2.2428947607794627\n",
      "[EPOCH #11, step #2014] loss: 2.2428074533235347\n",
      "[EPOCH #11, step #2016] loss: 2.2429365498864775\n",
      "[EPOCH #11, step #2018] loss: 2.2428190268875055\n",
      "[EPOCH #11, step #2020] loss: 2.2427875979120104\n",
      "[EPOCH #11, step #2022] loss: 2.2427112712049273\n",
      "[EPOCH #11, step #2024] loss: 2.2425684609825227\n",
      "[EPOCH #11, step #2026] loss: 2.242707608542421\n",
      "[EPOCH #11, step #2028] loss: 2.2428266673090422\n",
      "[EPOCH #11, step #2030] loss: 2.242839373138255\n",
      "[EPOCH #11, step #2032] loss: 2.2427683033734427\n",
      "[EPOCH #11, step #2034] loss: 2.2429623027398486\n",
      "[EPOCH #11, step #2036] loss: 2.243016034174504\n",
      "[EPOCH #11, step #2038] loss: 2.2430536894309516\n",
      "[EPOCH #11, step #2040] loss: 2.242967010186853\n",
      "[EPOCH #11, step #2042] loss: 2.243389766238451\n",
      "[EPOCH #11, step #2044] loss: 2.2435902171146607\n",
      "[EPOCH #11, step #2046] loss: 2.24382985878643\n",
      "[EPOCH #11, step #2048] loss: 2.2436361113893164\n",
      "[EPOCH #11, step #2050] loss: 2.243352649794271\n",
      "[EPOCH #11, step #2052] loss: 2.2430337777209757\n",
      "[EPOCH #11, step #2054] loss: 2.2429713438317145\n",
      "[EPOCH #11, step #2056] loss: 2.242758164952899\n",
      "[EPOCH #11, step #2058] loss: 2.24246531038854\n",
      "[EPOCH #11, step #2060] loss: 2.242365222426076\n",
      "[EPOCH #11, step #2062] loss: 2.242346599040769\n",
      "[EPOCH #11, step #2064] loss: 2.242768546397692\n",
      "[EPOCH #11, step #2066] loss: 2.2428125036356814\n",
      "[EPOCH #11, step #2068] loss: 2.2428234356391137\n",
      "[EPOCH #11, step #2070] loss: 2.2427982891429052\n",
      "[EPOCH #11, step #2072] loss: 2.242833714409261\n",
      "[EPOCH #11, step #2074] loss: 2.242972914569349\n",
      "[EPOCH #11, step #2076] loss: 2.243294705894628\n",
      "[EPOCH #11, step #2078] loss: 2.24349631719603\n",
      "[EPOCH #11, step #2080] loss: 2.2432009358637495\n",
      "[EPOCH #11, step #2082] loss: 2.243076413569402\n",
      "[EPOCH #11, step #2084] loss: 2.2432355597722444\n",
      "[EPOCH #11, step #2086] loss: 2.243305681251029\n",
      "[EPOCH #11, step #2088] loss: 2.242950106306245\n",
      "[EPOCH #11, step #2090] loss: 2.242867066038105\n",
      "[EPOCH #11, step #2092] loss: 2.2424402955725498\n",
      "[EPOCH #11, step #2094] loss: 2.2426367820020507\n",
      "[EPOCH #11, step #2096] loss: 2.2426143336648536\n",
      "[EPOCH #11, step #2098] loss: 2.242838878697472\n",
      "[EPOCH #11, step #2100] loss: 2.2427967234148065\n",
      "[EPOCH #11, step #2102] loss: 2.242525323934913\n",
      "[EPOCH #11, step #2104] loss: 2.2425044080140757\n",
      "[EPOCH #11, step #2106] loss: 2.2426804893097154\n",
      "[EPOCH #11, step #2108] loss: 2.2424859069093475\n",
      "[EPOCH #11, step #2110] loss: 2.242325091633058\n",
      "[EPOCH #11, step #2112] loss: 2.2421008398111995\n",
      "[EPOCH #11, step #2114] loss: 2.241869975094536\n",
      "[EPOCH #11, step #2116] loss: 2.241692617979036\n",
      "[EPOCH #11, step #2118] loss: 2.2413563733958255\n",
      "[EPOCH #11, step #2120] loss: 2.2412323779736076\n",
      "[EPOCH #11, step #2122] loss: 2.241341415576872\n",
      "[EPOCH #11, step #2124] loss: 2.2410771849576165\n",
      "[EPOCH #11, step #2126] loss: 2.2409966623048914\n",
      "[EPOCH #11, step #2128] loss: 2.240975050144545\n",
      "[EPOCH #11, step #2130] loss: 2.240772730025368\n",
      "[EPOCH #11, step #2132] loss: 2.2407117790310696\n",
      "[EPOCH #11, step #2134] loss: 2.240755817370895\n",
      "[EPOCH #11, step #2136] loss: 2.2408662365037366\n",
      "[EPOCH #11, step #2138] loss: 2.240729480382715\n",
      "[EPOCH #11, step #2140] loss: 2.2407914587183013\n",
      "[EPOCH #11, step #2142] loss: 2.240588087207849\n",
      "[EPOCH #11, step #2144] loss: 2.240762806105447\n",
      "[EPOCH #11, step #2146] loss: 2.240855865662854\n",
      "[EPOCH #11, step #2148] loss: 2.2408425836243593\n",
      "[EPOCH #11, step #2150] loss: 2.240877055667379\n",
      "[EPOCH #11, step #2152] loss: 2.240453535991107\n",
      "[EPOCH #11, step #2154] loss: 2.24052624110556\n",
      "[EPOCH #11, step #2156] loss: 2.240672363359507\n",
      "[EPOCH #11, step #2158] loss: 2.240799221798136\n",
      "[EPOCH #11, step #2160] loss: 2.2408270124813185\n",
      "[EPOCH #11, step #2162] loss: 2.240544451148324\n",
      "[EPOCH #11, step #2164] loss: 2.2408432321240115\n",
      "[EPOCH #11, step #2166] loss: 2.2406399646661335\n",
      "[EPOCH #11, step #2168] loss: 2.2403648494849726\n",
      "[EPOCH #11, step #2170] loss: 2.2400904953177765\n",
      "[EPOCH #11, step #2172] loss: 2.240013092769986\n",
      "[EPOCH #11, step #2174] loss: 2.2402032688294335\n",
      "[EPOCH #11, step #2176] loss: 2.2402530033543506\n",
      "[EPOCH #11, step #2178] loss: 2.240329709606687\n",
      "[EPOCH #11, step #2180] loss: 2.2403655921248653\n",
      "[EPOCH #11, step #2182] loss: 2.239965492522449\n",
      "[EPOCH #11, step #2184] loss: 2.2399165875306117\n",
      "[EPOCH #11, step #2186] loss: 2.2401334806070734\n",
      "[EPOCH #11, step #2188] loss: 2.240018630909996\n",
      "[EPOCH #11, step #2190] loss: 2.2396135657740097\n",
      "[EPOCH #11, step #2192] loss: 2.239550473752002\n",
      "[EPOCH #11, step #2194] loss: 2.2393873238074753\n",
      "[EPOCH #11, step #2196] loss: 2.239495739645995\n",
      "[EPOCH #11, step #2198] loss: 2.2394119868662314\n",
      "[EPOCH #11, step #2200] loss: 2.239683673957\n",
      "[EPOCH #11, step #2202] loss: 2.2394600046584676\n",
      "[EPOCH #11, step #2204] loss: 2.239264835846397\n",
      "[EPOCH #11, step #2206] loss: 2.2390184269590945\n",
      "[EPOCH #11, step #2208] loss: 2.238841021098719\n",
      "[EPOCH #11, step #2210] loss: 2.2386028942399734\n",
      "[EPOCH #11, step #2212] loss: 2.2381625028417167\n",
      "[EPOCH #11, step #2214] loss: 2.2380240867692245\n",
      "[EPOCH #11, step #2216] loss: 2.2379610165852815\n",
      "[EPOCH #11, step #2218] loss: 2.237835189467779\n",
      "[EPOCH #11, step #2220] loss: 2.2378869395919447\n",
      "[EPOCH #11, step #2222] loss: 2.2380413993006614\n",
      "[EPOCH #11, step #2224] loss: 2.2378854921962437\n",
      "[EPOCH #11, step #2226] loss: 2.237850558345608\n",
      "[EPOCH #11, step #2228] loss: 2.2382188167418\n",
      "[EPOCH #11, step #2230] loss: 2.2380023876256017\n",
      "[EPOCH #11, step #2232] loss: 2.238025679750609\n",
      "[EPOCH #11, step #2234] loss: 2.238022032093415\n",
      "[EPOCH #11, step #2236] loss: 2.238172403605431\n",
      "[EPOCH #11, step #2238] loss: 2.238245607646995\n",
      "[EPOCH #11, step #2240] loss: 2.2385055832647947\n",
      "[EPOCH #11, step #2242] loss: 2.23848362687545\n",
      "[EPOCH #11, step #2244] loss: 2.2382845682662422\n",
      "[EPOCH #11, step #2246] loss: 2.238323440114604\n",
      "[EPOCH #11, step #2248] loss: 2.238600179745177\n",
      "[EPOCH #11, step #2250] loss: 2.2384405458095284\n",
      "[EPOCH #11, step #2252] loss: 2.2384720525898194\n",
      "[EPOCH #11, step #2254] loss: 2.2384583987047826\n",
      "[EPOCH #11, step #2256] loss: 2.2382145331504866\n",
      "[EPOCH #11, step #2258] loss: 2.2378499542205086\n",
      "[EPOCH #11, step #2260] loss: 2.237656223146539\n",
      "[EPOCH #11, step #2262] loss: 2.2374719720575804\n",
      "[EPOCH #11, step #2264] loss: 2.2371089547938334\n",
      "[EPOCH #11, step #2266] loss: 2.236998727156509\n",
      "[EPOCH #11, step #2268] loss: 2.236748669524716\n",
      "[EPOCH #11, step #2270] loss: 2.2365836179608136\n",
      "[EPOCH #11, step #2272] loss: 2.236823625728206\n",
      "[EPOCH #11, step #2274] loss: 2.2368078785152226\n",
      "[EPOCH #11, step #2276] loss: 2.2369219511289264\n",
      "[EPOCH #11, step #2278] loss: 2.2369022032523063\n",
      "[EPOCH #11, step #2280] loss: 2.2368743516854264\n",
      "[EPOCH #11, step #2282] loss: 2.2367938342347147\n",
      "[EPOCH #11, step #2284] loss: 2.23708373842928\n",
      "[EPOCH #11, step #2286] loss: 2.237275071836321\n",
      "[EPOCH #11, step #2288] loss: 2.237196594255363\n",
      "[EPOCH #11, step #2290] loss: 2.237220262919176\n",
      "[EPOCH #11, step #2292] loss: 2.237381733248861\n",
      "[EPOCH #11, step #2294] loss: 2.237782067411086\n",
      "[EPOCH #11, step #2296] loss: 2.2376379251583898\n",
      "[EPOCH #11, step #2298] loss: 2.237513066271483\n",
      "[EPOCH #11, step #2300] loss: 2.2376592050475277\n",
      "[EPOCH #11, step #2302] loss: 2.237364580307222\n",
      "[EPOCH #11, step #2304] loss: 2.2374846074172576\n",
      "[EPOCH #11, step #2306] loss: 2.2376485363353007\n",
      "[EPOCH #11, step #2308] loss: 2.2375235731542857\n",
      "[EPOCH #11, step #2310] loss: 2.2375704345121266\n",
      "[EPOCH #11, step #2312] loss: 2.2376079355747835\n",
      "[EPOCH #11, step #2314] loss: 2.2375639600836177\n",
      "[EPOCH #11, step #2316] loss: 2.237339974118555\n",
      "[EPOCH #11, step #2318] loss: 2.2372030738922684\n",
      "[EPOCH #11, step #2320] loss: 2.2370794593954026\n",
      "[EPOCH #11, step #2322] loss: 2.2368408010994316\n",
      "[EPOCH #11, step #2324] loss: 2.2366537859106574\n",
      "[EPOCH #11, step #2326] loss: 2.236275621427709\n",
      "[EPOCH #11, step #2328] loss: 2.236111995077481\n",
      "[EPOCH #11, step #2330] loss: 2.2360675204521288\n",
      "[EPOCH #11, step #2332] loss: 2.2360671969171353\n",
      "[EPOCH #11, step #2334] loss: 2.235950878192322\n",
      "[EPOCH #11, step #2336] loss: 2.2358326474774532\n",
      "[EPOCH #11, step #2338] loss: 2.2356567115241415\n",
      "[EPOCH #11, step #2340] loss: 2.235762511853834\n",
      "[EPOCH #11, step #2342] loss: 2.2356694990683965\n",
      "[EPOCH #11, step #2344] loss: 2.235615530197046\n",
      "[EPOCH #11, step #2346] loss: 2.2354601664801175\n",
      "[EPOCH #11, step #2348] loss: 2.2352314075037185\n",
      "[EPOCH #11, step #2350] loss: 2.2351179524007527\n",
      "[EPOCH #11, step #2352] loss: 2.2350268596494343\n",
      "[EPOCH #11, step #2354] loss: 2.2352138335537757\n",
      "[EPOCH #11, step #2356] loss: 2.2350976118659083\n",
      "[EPOCH #11, step #2358] loss: 2.2352307301145733\n",
      "[EPOCH #11, step #2360] loss: 2.234955714800155\n",
      "[EPOCH #11, step #2362] loss: 2.235179363394813\n",
      "[EPOCH #11, step #2364] loss: 2.235288365295523\n",
      "[EPOCH #11, step #2366] loss: 2.2350461873315184\n",
      "[EPOCH #11, step #2368] loss: 2.234936439673978\n",
      "[EPOCH #11, step #2370] loss: 2.2350250994389893\n",
      "[EPOCH #11, step #2372] loss: 2.2351487908140295\n",
      "[EPOCH #11, step #2374] loss: 2.234828346854762\n",
      "[EPOCH #11, step #2376] loss: 2.2348603378788585\n",
      "[EPOCH #11, step #2378] loss: 2.234864887142943\n",
      "[EPOCH #11, step #2380] loss: 2.234763087869842\n",
      "[EPOCH #11, step #2382] loss: 2.2349799398709584\n",
      "[EPOCH #11, step #2384] loss: 2.234846217327398\n",
      "[EPOCH #11, step #2386] loss: 2.2347287169349808\n",
      "[EPOCH #11, step #2388] loss: 2.2345624686085865\n",
      "[EPOCH #11, step #2390] loss: 2.2343241534737652\n",
      "[EPOCH #11, step #2392] loss: 2.2343212000455908\n",
      "[EPOCH #11, step #2394] loss: 2.2342105554389557\n",
      "[EPOCH #11, step #2396] loss: 2.2340705051589222\n",
      "[EPOCH #11, step #2398] loss: 2.234088124111823\n",
      "[EPOCH #11, step #2400] loss: 2.2344209516311575\n",
      "[EPOCH #11, step #2402] loss: 2.234229729863142\n",
      "[EPOCH #11, step #2404] loss: 2.234028894043762\n",
      "[EPOCH #11, step #2406] loss: 2.2338089500664178\n",
      "[EPOCH #11, step #2408] loss: 2.234117967204565\n",
      "[EPOCH #11, step #2410] loss: 2.23400255670591\n",
      "[EPOCH #11, step #2412] loss: 2.233977625689169\n",
      "[EPOCH #11, step #2414] loss: 2.2339617122034108\n",
      "[EPOCH #11, step #2416] loss: 2.2339884846675084\n",
      "[EPOCH #11, step #2418] loss: 2.233801782845761\n",
      "[EPOCH #11, step #2420] loss: 2.233616810059656\n",
      "[EPOCH #11, step #2422] loss: 2.2336245508563946\n",
      "[EPOCH #11, step #2424] loss: 2.2334248581620835\n",
      "[EPOCH #11, step #2426] loss: 2.2333734384720643\n",
      "[EPOCH #11, step #2428] loss: 2.2333906184208643\n",
      "[EPOCH #11, step #2430] loss: 2.2333628363885882\n",
      "[EPOCH #11, step #2432] loss: 2.233427240728009\n",
      "[EPOCH #11, step #2434] loss: 2.233367467024488\n",
      "[EPOCH #11, step #2436] loss: 2.2334954444629322\n",
      "[EPOCH #11, step #2438] loss: 2.2333837266631087\n",
      "[EPOCH #11, step #2440] loss: 2.233494341886224\n",
      "[EPOCH #11, step #2442] loss: 2.233505671452754\n",
      "[EPOCH #11, step #2444] loss: 2.2334665722154643\n",
      "[EPOCH #11, step #2446] loss: 2.233523312178153\n",
      "[EPOCH #11, step #2448] loss: 2.233563794219382\n",
      "[EPOCH #11, step #2450] loss: 2.2335918147629106\n",
      "[EPOCH #11, step #2452] loss: 2.2334370429400177\n",
      "[EPOCH #11, step #2454] loss: 2.233570752852803\n",
      "[EPOCH #11, step #2456] loss: 2.2335517045487996\n",
      "[EPOCH #11, step #2458] loss: 2.2337532564118994\n",
      "[EPOCH #11, step #2460] loss: 2.2336740939416617\n",
      "[EPOCH #11, step #2462] loss: 2.2337828637911836\n",
      "[EPOCH #11, step #2464] loss: 2.233824209073978\n",
      "[EPOCH #11, step #2466] loss: 2.234062535781149\n",
      "[EPOCH #11, step #2468] loss: 2.2341229852851754\n",
      "[EPOCH #11, step #2470] loss: 2.2340368881055768\n",
      "[EPOCH #11, step #2472] loss: 2.2339395235966344\n",
      "[EPOCH #11, step #2474] loss: 2.233909284321949\n",
      "[EPOCH #11, step #2476] loss: 2.233600282986702\n",
      "[EPOCH #11, step #2478] loss: 2.233462115890223\n",
      "[EPOCH #11, step #2480] loss: 2.233602558350861\n",
      "[EPOCH #11, step #2482] loss: 2.2337554137264104\n",
      "[EPOCH #11, step #2484] loss: 2.233632705916821\n",
      "[EPOCH #11, step #2486] loss: 2.233509273331569\n",
      "[EPOCH #11, step #2488] loss: 2.233768638572141\n",
      "[EPOCH #11, step #2490] loss: 2.233907461022814\n",
      "[EPOCH #11, step #2492] loss: 2.2337802126376065\n",
      "[EPOCH #11, step #2494] loss: 2.2337212320320115\n",
      "[EPOCH #11, step #2496] loss: 2.23354389078387\n",
      "[EPOCH #11, step #2498] loss: 2.2334589584678017\n",
      "[EPOCH #11, elapsed time: 5625.470[sec]] loss: 2.233370426416397\n",
      "[EPOCH #12, step #0] loss: 2.1160993576049805\n",
      "[EPOCH #12, step #2] loss: 2.07396407922109\n",
      "[EPOCH #12, step #4] loss: 2.1250435590744017\n",
      "[EPOCH #12, step #6] loss: 2.1728838682174683\n",
      "[EPOCH #12, step #8] loss: 2.2264487081103854\n",
      "[EPOCH #12, step #10] loss: 2.298825361511924\n",
      "[EPOCH #12, step #12] loss: 2.298753472474905\n",
      "[EPOCH #12, step #14] loss: 2.275535782178243\n",
      "[EPOCH #12, step #16] loss: 2.2140802705989167\n",
      "[EPOCH #12, step #18] loss: 2.202523287973906\n",
      "[EPOCH #12, step #20] loss: 2.1983325765246438\n",
      "[EPOCH #12, step #22] loss: 2.2200192316718725\n",
      "[EPOCH #12, step #24] loss: 2.2018477725982666\n",
      "[EPOCH #12, step #26] loss: 2.1878168936128968\n",
      "[EPOCH #12, step #28] loss: 2.19903708737472\n",
      "[EPOCH #12, step #30] loss: 2.225129239020809\n",
      "[EPOCH #12, step #32] loss: 2.196213039484891\n",
      "[EPOCH #12, step #34] loss: 2.1860663890838623\n",
      "[EPOCH #12, step #36] loss: 2.1979264697513066\n",
      "[EPOCH #12, step #38] loss: 2.1965901943353505\n",
      "[EPOCH #12, step #40] loss: 2.194276716650986\n",
      "[EPOCH #12, step #42] loss: 2.2042934728223225\n",
      "[EPOCH #12, step #44] loss: 2.2064980083041723\n",
      "[EPOCH #12, step #46] loss: 2.2138094496219716\n",
      "[EPOCH #12, step #48] loss: 2.2153708156274288\n",
      "[EPOCH #12, step #50] loss: 2.2066984784369374\n",
      "[EPOCH #12, step #52] loss: 2.204684059574919\n",
      "[EPOCH #12, step #54] loss: 2.195144055106423\n",
      "[EPOCH #12, step #56] loss: 2.184113667722334\n",
      "[EPOCH #12, step #58] loss: 2.1857963315511153\n",
      "[EPOCH #12, step #60] loss: 2.191260245979809\n",
      "[EPOCH #12, step #62] loss: 2.193889298136272\n",
      "[EPOCH #12, step #64] loss: 2.1827825454565195\n",
      "[EPOCH #12, step #66] loss: 2.1905271348668567\n",
      "[EPOCH #12, step #68] loss: 2.182447721992714\n",
      "[EPOCH #12, step #70] loss: 2.1802325685259323\n",
      "[EPOCH #12, step #72] loss: 2.187614829572913\n",
      "[EPOCH #12, step #74] loss: 2.1800507990519207\n",
      "[EPOCH #12, step #76] loss: 2.1785068651298425\n",
      "[EPOCH #12, step #78] loss: 2.17349374294281\n",
      "[EPOCH #12, step #80] loss: 2.172958410816428\n",
      "[EPOCH #12, step #82] loss: 2.175174171666065\n",
      "[EPOCH #12, step #84] loss: 2.1768032536787145\n",
      "[EPOCH #12, step #86] loss: 2.1761456412830573\n",
      "[EPOCH #12, step #88] loss: 2.173222750760196\n",
      "[EPOCH #12, step #90] loss: 2.17071588746794\n",
      "[EPOCH #12, step #92] loss: 2.1635757966708113\n",
      "[EPOCH #12, step #94] loss: 2.1630324200579993\n",
      "[EPOCH #12, step #96] loss: 2.1562105380382732\n",
      "[EPOCH #12, step #98] loss: 2.158732219175859\n",
      "[EPOCH #12, step #100] loss: 2.1610994952740055\n",
      "[EPOCH #12, step #102] loss: 2.171090741759365\n",
      "[EPOCH #12, step #104] loss: 2.1718833991459436\n",
      "[EPOCH #12, step #106] loss: 2.172510505836701\n",
      "[EPOCH #12, step #108] loss: 2.17211446849578\n",
      "[EPOCH #12, step #110] loss: 2.1707727286192746\n",
      "[EPOCH #12, step #112] loss: 2.1646118986923084\n",
      "[EPOCH #12, step #114] loss: 2.1648441998854926\n",
      "[EPOCH #12, step #116] loss: 2.1617215036327004\n",
      "[EPOCH #12, step #118] loss: 2.159234529783746\n",
      "[EPOCH #12, step #120] loss: 2.1580484534098097\n",
      "[EPOCH #12, step #122] loss: 2.160097194880974\n",
      "[EPOCH #12, step #124] loss: 2.158880497932434\n",
      "[EPOCH #12, step #126] loss: 2.1576706884414194\n",
      "[EPOCH #12, step #128] loss: 2.1608232758765995\n",
      "[EPOCH #12, step #130] loss: 2.1550133892598042\n",
      "[EPOCH #12, step #132] loss: 2.1628362280981883\n",
      "[EPOCH #12, step #134] loss: 2.160906363416601\n",
      "[EPOCH #12, step #136] loss: 2.1615433457994113\n",
      "[EPOCH #12, step #138] loss: 2.1581066160750906\n",
      "[EPOCH #12, step #140] loss: 2.156096897226699\n",
      "[EPOCH #12, step #142] loss: 2.1558188933592577\n",
      "[EPOCH #12, step #144] loss: 2.15857627885095\n",
      "[EPOCH #12, step #146] loss: 2.157387844559287\n",
      "[EPOCH #12, step #148] loss: 2.1562509832766232\n",
      "[EPOCH #12, step #150] loss: 2.161950680593781\n",
      "[EPOCH #12, step #152] loss: 2.167969467593174\n",
      "[EPOCH #12, step #154] loss: 2.1658146219868812\n",
      "[EPOCH #12, step #156] loss: 2.165726665478603\n",
      "[EPOCH #12, step #158] loss: 2.167480986823076\n",
      "[EPOCH #12, step #160] loss: 2.1679784799954906\n",
      "[EPOCH #12, step #162] loss: 2.168137502816557\n",
      "[EPOCH #12, step #164] loss: 2.1671819260626126\n",
      "[EPOCH #12, step #166] loss: 2.1711226301992723\n",
      "[EPOCH #12, step #168] loss: 2.174676455689605\n",
      "[EPOCH #12, step #170] loss: 2.172156946700916\n",
      "[EPOCH #12, step #172] loss: 2.1721469584227986\n",
      "[EPOCH #12, step #174] loss: 2.1722399854660033\n",
      "[EPOCH #12, step #176] loss: 2.1698245402783325\n",
      "[EPOCH #12, step #178] loss: 2.169283117661929\n",
      "[EPOCH #12, step #180] loss: 2.169108949972121\n",
      "[EPOCH #12, step #182] loss: 2.168157929931182\n",
      "[EPOCH #12, step #184] loss: 2.1691363650399285\n",
      "[EPOCH #12, step #186] loss: 2.164544271912804\n",
      "[EPOCH #12, step #188] loss: 2.1665593978589173\n",
      "[EPOCH #12, step #190] loss: 2.16631339482612\n",
      "[EPOCH #12, step #192] loss: 2.164728912047154\n",
      "[EPOCH #12, step #194] loss: 2.164627504348755\n",
      "[EPOCH #12, step #196] loss: 2.1634388121251527\n",
      "[EPOCH #12, step #198] loss: 2.1620344253041637\n",
      "[EPOCH #12, step #200] loss: 2.162022399665111\n",
      "[EPOCH #12, step #202] loss: 2.161796177549315\n",
      "[EPOCH #12, step #204] loss: 2.164822186493292\n",
      "[EPOCH #12, step #206] loss: 2.1658758339674575\n",
      "[EPOCH #12, step #208] loss: 2.1648845855128824\n",
      "[EPOCH #12, step #210] loss: 2.1677868456637124\n",
      "[EPOCH #12, step #212] loss: 2.1704394022623696\n",
      "[EPOCH #12, step #214] loss: 2.17364524907844\n",
      "[EPOCH #12, step #216] loss: 2.174979449417185\n",
      "[EPOCH #12, step #218] loss: 2.173801453146216\n",
      "[EPOCH #12, step #220] loss: 2.173429924438442\n",
      "[EPOCH #12, step #222] loss: 2.1729570188864464\n",
      "[EPOCH #12, step #224] loss: 2.1768369256125557\n",
      "[EPOCH #12, step #226] loss: 2.1751586414118695\n",
      "[EPOCH #12, step #228] loss: 2.1745022592586203\n",
      "[EPOCH #12, step #230] loss: 2.1766441714712035\n",
      "[EPOCH #12, step #232] loss: 2.1753858512051627\n",
      "[EPOCH #12, step #234] loss: 2.1758850863639343\n",
      "[EPOCH #12, step #236] loss: 2.1755434787726102\n",
      "[EPOCH #12, step #238] loss: 2.17750540787206\n",
      "[EPOCH #12, step #240] loss: 2.178198999883723\n",
      "[EPOCH #12, step #242] loss: 2.177789941246127\n",
      "[EPOCH #12, step #244] loss: 2.176362909589495\n",
      "[EPOCH #12, step #246] loss: 2.1762400271921507\n",
      "[EPOCH #12, step #248] loss: 2.174268534384578\n",
      "[EPOCH #12, step #250] loss: 2.1733876571237327\n",
      "[EPOCH #12, step #252] loss: 2.175562128719134\n",
      "[EPOCH #12, step #254] loss: 2.175818454518038\n",
      "[EPOCH #12, step #256] loss: 2.172681641022055\n",
      "[EPOCH #12, step #258] loss: 2.1710991224266847\n",
      "[EPOCH #12, step #260] loss: 2.1689911989416655\n",
      "[EPOCH #12, step #262] loss: 2.168656785678501\n",
      "[EPOCH #12, step #264] loss: 2.166086778100931\n",
      "[EPOCH #12, step #266] loss: 2.1662495752398887\n",
      "[EPOCH #12, step #268] loss: 2.16836521084867\n",
      "[EPOCH #12, step #270] loss: 2.1652432350215\n",
      "[EPOCH #12, step #272] loss: 2.1649849903889193\n",
      "[EPOCH #12, step #274] loss: 2.1629459476470947\n",
      "[EPOCH #12, step #276] loss: 2.16303700746612\n",
      "[EPOCH #12, step #278] loss: 2.162380330878774\n",
      "[EPOCH #12, step #280] loss: 2.1610833296147955\n",
      "[EPOCH #12, step #282] loss: 2.1621111496598475\n",
      "[EPOCH #12, step #284] loss: 2.1608835985786037\n",
      "[EPOCH #12, step #286] loss: 2.1603920214682923\n",
      "[EPOCH #12, step #288] loss: 2.160419296640838\n",
      "[EPOCH #12, step #290] loss: 2.158274425264077\n",
      "[EPOCH #12, step #292] loss: 2.156732236972848\n",
      "[EPOCH #12, step #294] loss: 2.1564354338888396\n",
      "[EPOCH #12, step #296] loss: 2.1565911537067657\n",
      "[EPOCH #12, step #298] loss: 2.1560153171768954\n",
      "[EPOCH #12, step #300] loss: 2.1555334468220555\n",
      "[EPOCH #12, step #302] loss: 2.1549113213819244\n",
      "[EPOCH #12, step #304] loss: 2.1517187544556915\n",
      "[EPOCH #12, step #306] loss: 2.151747512118436\n",
      "[EPOCH #12, step #308] loss: 2.1512750217443917\n",
      "[EPOCH #12, step #310] loss: 2.1500609089707257\n",
      "[EPOCH #12, step #312] loss: 2.1514043282396114\n",
      "[EPOCH #12, step #314] loss: 2.1515522593543643\n",
      "[EPOCH #12, step #316] loss: 2.1541983645045044\n",
      "[EPOCH #12, step #318] loss: 2.155555098408068\n",
      "[EPOCH #12, step #320] loss: 2.157876436955461\n",
      "[EPOCH #12, step #322] loss: 2.1564082383371357\n",
      "[EPOCH #12, step #324] loss: 2.1581172605661245\n",
      "[EPOCH #12, step #326] loss: 2.1570871765825\n",
      "[EPOCH #12, step #328] loss: 2.157246397259025\n",
      "[EPOCH #12, step #330] loss: 2.1585171680075885\n",
      "[EPOCH #12, step #332] loss: 2.158662739100757\n",
      "[EPOCH #12, step #334] loss: 2.1575307394141583\n",
      "[EPOCH #12, step #336] loss: 2.157213049755606\n",
      "[EPOCH #12, step #338] loss: 2.1567780844933164\n",
      "[EPOCH #12, step #340] loss: 2.155236244900835\n",
      "[EPOCH #12, step #342] loss: 2.1571483813638936\n",
      "[EPOCH #12, step #344] loss: 2.1570122957229616\n",
      "[EPOCH #12, step #346] loss: 2.1581597276654643\n",
      "[EPOCH #12, step #348] loss: 2.1561048963350005\n",
      "[EPOCH #12, step #350] loss: 2.157675869104869\n",
      "[EPOCH #12, step #352] loss: 2.1593617302162453\n",
      "[EPOCH #12, step #354] loss: 2.1595289472123267\n",
      "[EPOCH #12, step #356] loss: 2.1586316092675473\n",
      "[EPOCH #12, step #358] loss: 2.156672138357561\n",
      "[EPOCH #12, step #360] loss: 2.1565317949099554\n",
      "[EPOCH #12, step #362] loss: 2.156142488655637\n",
      "[EPOCH #12, step #364] loss: 2.1566792628536486\n",
      "[EPOCH #12, step #366] loss: 2.1568619188235956\n",
      "[EPOCH #12, step #368] loss: 2.157898907092852\n",
      "[EPOCH #12, step #370] loss: 2.1590690378230217\n",
      "[EPOCH #12, step #372] loss: 2.159591346579646\n",
      "[EPOCH #12, step #374] loss: 2.1582020076115924\n",
      "[EPOCH #12, step #376] loss: 2.1583177515303107\n",
      "[EPOCH #12, step #378] loss: 2.157405345295224\n",
      "[EPOCH #12, step #380] loss: 2.157945224306402\n",
      "[EPOCH #12, step #382] loss: 2.157077133811174\n",
      "[EPOCH #12, step #384] loss: 2.1582366918588614\n",
      "[EPOCH #12, step #386] loss: 2.157785246230527\n",
      "[EPOCH #12, step #388] loss: 2.1562685767298797\n",
      "[EPOCH #12, step #390] loss: 2.155607074118026\n",
      "[EPOCH #12, step #392] loss: 2.154932294183105\n",
      "[EPOCH #12, step #394] loss: 2.1547200320642204\n",
      "[EPOCH #12, step #396] loss: 2.156014552044328\n",
      "[EPOCH #12, step #398] loss: 2.157730674086358\n",
      "[EPOCH #12, step #400] loss: 2.158407513637495\n",
      "[EPOCH #12, step #402] loss: 2.1578805283932176\n",
      "[EPOCH #12, step #404] loss: 2.1587493934749085\n",
      "[EPOCH #12, step #406] loss: 2.157134273128369\n",
      "[EPOCH #12, step #408] loss: 2.157603620316988\n",
      "[EPOCH #12, step #410] loss: 2.157535586043866\n",
      "[EPOCH #12, step #412] loss: 2.1591531583818337\n",
      "[EPOCH #12, step #414] loss: 2.1581954217818846\n",
      "[EPOCH #12, step #416] loss: 2.1591681653647115\n",
      "[EPOCH #12, step #418] loss: 2.1588972937804702\n",
      "[EPOCH #12, step #420] loss: 2.158997072743124\n",
      "[EPOCH #12, step #422] loss: 2.158995371620142\n",
      "[EPOCH #12, step #424] loss: 2.160319789718179\n",
      "[EPOCH #12, step #426] loss: 2.16055425631637\n",
      "[EPOCH #12, step #428] loss: 2.159899758292245\n",
      "[EPOCH #12, step #430] loss: 2.158532635241816\n",
      "[EPOCH #12, step #432] loss: 2.1573646208981168\n",
      "[EPOCH #12, step #434] loss: 2.1578352588346634\n",
      "[EPOCH #12, step #436] loss: 2.158814067425935\n",
      "[EPOCH #12, step #438] loss: 2.159984039554292\n",
      "[EPOCH #12, step #440] loss: 2.1598326970660495\n",
      "[EPOCH #12, step #442] loss: 2.159696469188544\n",
      "[EPOCH #12, step #444] loss: 2.1610269353630835\n",
      "[EPOCH #12, step #446] loss: 2.1619459430643375\n",
      "[EPOCH #12, step #448] loss: 2.1636693196201113\n",
      "[EPOCH #12, step #450] loss: 2.1658962222266354\n",
      "[EPOCH #12, step #452] loss: 2.164199640682465\n",
      "[EPOCH #12, step #454] loss: 2.163770176552154\n",
      "[EPOCH #12, step #456] loss: 2.163951194260261\n",
      "[EPOCH #12, step #458] loss: 2.1638652875792226\n",
      "[EPOCH #12, step #460] loss: 2.163189898085439\n",
      "[EPOCH #12, step #462] loss: 2.1626330392664506\n",
      "[EPOCH #12, step #464] loss: 2.162538365138474\n",
      "[EPOCH #12, step #466] loss: 2.1624164471534386\n",
      "[EPOCH #12, step #468] loss: 2.16305064977105\n",
      "[EPOCH #12, step #470] loss: 2.162710898494518\n",
      "[EPOCH #12, step #472] loss: 2.1621795126550043\n",
      "[EPOCH #12, step #474] loss: 2.1623880649867813\n",
      "[EPOCH #12, step #476] loss: 2.162890240081451\n",
      "[EPOCH #12, step #478] loss: 2.1635298691612195\n",
      "[EPOCH #12, step #480] loss: 2.1621030668211083\n",
      "[EPOCH #12, step #482] loss: 2.1610113411956693\n",
      "[EPOCH #12, step #484] loss: 2.1617634780628165\n",
      "[EPOCH #12, step #486] loss: 2.162584745663637\n",
      "[EPOCH #12, step #488] loss: 2.161651789288823\n",
      "[EPOCH #12, step #490] loss: 2.160838899932908\n",
      "[EPOCH #12, step #492] loss: 2.16055797103936\n",
      "[EPOCH #12, step #494] loss: 2.159595553080241\n",
      "[EPOCH #12, step #496] loss: 2.1588997617813663\n",
      "[EPOCH #12, step #498] loss: 2.1599592553350875\n",
      "[EPOCH #12, step #500] loss: 2.1597193836452004\n",
      "[EPOCH #12, step #502] loss: 2.1601514676456186\n",
      "[EPOCH #12, step #504] loss: 2.1599434906893435\n",
      "[EPOCH #12, step #506] loss: 2.1608505716925777\n",
      "[EPOCH #12, step #508] loss: 2.1613277004837754\n",
      "[EPOCH #12, step #510] loss: 2.161225724593534\n",
      "[EPOCH #12, step #512] loss: 2.160230581988136\n",
      "[EPOCH #12, step #514] loss: 2.1596219565104513\n",
      "[EPOCH #12, step #516] loss: 2.161619924945573\n",
      "[EPOCH #12, step #518] loss: 2.1610237550643596\n",
      "[EPOCH #12, step #520] loss: 2.161306776835685\n",
      "[EPOCH #12, step #522] loss: 2.1616874668839783\n",
      "[EPOCH #12, step #524] loss: 2.160158284732274\n",
      "[EPOCH #12, step #526] loss: 2.161038429732567\n",
      "[EPOCH #12, step #528] loss: 2.1600166525417106\n",
      "[EPOCH #12, step #530] loss: 2.1604659570812506\n",
      "[EPOCH #12, step #532] loss: 2.1609781199950886\n",
      "[EPOCH #12, step #534] loss: 2.1603114823314633\n",
      "[EPOCH #12, step #536] loss: 2.1613542696173185\n",
      "[EPOCH #12, step #538] loss: 2.161558333929483\n",
      "[EPOCH #12, step #540] loss: 2.1611619253475873\n",
      "[EPOCH #12, step #542] loss: 2.1610768708515344\n",
      "[EPOCH #12, step #544] loss: 2.161223968672096\n",
      "[EPOCH #12, step #546] loss: 2.161421353246002\n",
      "[EPOCH #12, step #548] loss: 2.1612911065853795\n",
      "[EPOCH #12, step #550] loss: 2.161261568917553\n",
      "[EPOCH #12, step #552] loss: 2.161924304410303\n",
      "[EPOCH #12, step #554] loss: 2.1622312898034446\n",
      "[EPOCH #12, step #556] loss: 2.1612880521017517\n",
      "[EPOCH #12, step #558] loss: 2.1610005622686344\n",
      "[EPOCH #12, step #560] loss: 2.1617693884062468\n",
      "[EPOCH #12, step #562] loss: 2.1620791468696527\n",
      "[EPOCH #12, step #564] loss: 2.1618505184629324\n",
      "[EPOCH #12, step #566] loss: 2.1604737943232166\n",
      "[EPOCH #12, step #568] loss: 2.161306910648916\n",
      "[EPOCH #12, step #570] loss: 2.161486272010202\n",
      "[EPOCH #12, step #572] loss: 2.1616883798003403\n",
      "[EPOCH #12, step #574] loss: 2.1609713158400163\n",
      "[EPOCH #12, step #576] loss: 2.161002629551152\n",
      "[EPOCH #12, step #578] loss: 2.160696568060827\n",
      "[EPOCH #12, step #580] loss: 2.1611887150910554\n",
      "[EPOCH #12, step #582] loss: 2.1614833274795506\n",
      "[EPOCH #12, step #584] loss: 2.1617038221440765\n",
      "[EPOCH #12, step #586] loss: 2.1618761309570105\n",
      "[EPOCH #12, step #588] loss: 2.1618920866216587\n",
      "[EPOCH #12, step #590] loss: 2.1634875477469713\n",
      "[EPOCH #12, step #592] loss: 2.164277962448223\n",
      "[EPOCH #12, step #594] loss: 2.164153481331192\n",
      "[EPOCH #12, step #596] loss: 2.164618096359611\n",
      "[EPOCH #12, step #598] loss: 2.1649401960070422\n",
      "[EPOCH #12, step #600] loss: 2.164820649857926\n",
      "[EPOCH #12, step #602] loss: 2.1641229594722513\n",
      "[EPOCH #12, step #604] loss: 2.1631098873359114\n",
      "[EPOCH #12, step #606] loss: 2.162662077578524\n",
      "[EPOCH #12, step #608] loss: 2.1621026474071057\n",
      "[EPOCH #12, step #610] loss: 2.161526469083933\n",
      "[EPOCH #12, step #612] loss: 2.161920052562608\n",
      "[EPOCH #12, step #614] loss: 2.1627224373623606\n",
      "[EPOCH #12, step #616] loss: 2.162221413377425\n",
      "[EPOCH #12, step #618] loss: 2.1615317158629708\n",
      "[EPOCH #12, step #620] loss: 2.160248085496506\n",
      "[EPOCH #12, step #622] loss: 2.1602830976773992\n",
      "[EPOCH #12, step #624] loss: 2.1601106645584105\n",
      "[EPOCH #12, step #626] loss: 2.1607531921335004\n",
      "[EPOCH #12, step #628] loss: 2.160494898385198\n",
      "[EPOCH #12, step #630] loss: 2.159282656743674\n",
      "[EPOCH #12, step #632] loss: 2.159439987104274\n",
      "[EPOCH #12, step #634] loss: 2.1596923114746573\n",
      "[EPOCH #12, step #636] loss: 2.1600968646853462\n",
      "[EPOCH #12, step #638] loss: 2.159510958176077\n",
      "[EPOCH #12, step #640] loss: 2.1589735216357964\n",
      "[EPOCH #12, step #642] loss: 2.1604225557662464\n",
      "[EPOCH #12, step #644] loss: 2.159828084014183\n",
      "[EPOCH #12, step #646] loss: 2.160004851254282\n",
      "[EPOCH #12, step #648] loss: 2.1606105832362945\n",
      "[EPOCH #12, step #650] loss: 2.1616421518604145\n",
      "[EPOCH #12, step #652] loss: 2.1611492113534014\n",
      "[EPOCH #12, step #654] loss: 2.161014793301357\n",
      "[EPOCH #12, step #656] loss: 2.160100329412173\n",
      "[EPOCH #12, step #658] loss: 2.1604867014067306\n",
      "[EPOCH #12, step #660] loss: 2.1593336032847232\n",
      "[EPOCH #12, step #662] loss: 2.159945490673117\n",
      "[EPOCH #12, step #664] loss: 2.1595886596163414\n",
      "[EPOCH #12, step #666] loss: 2.1596374568910615\n",
      "[EPOCH #12, step #668] loss: 2.15912378457986\n",
      "[EPOCH #12, step #670] loss: 2.1595244151824633\n",
      "[EPOCH #12, step #672] loss: 2.1587190470405\n",
      "[EPOCH #12, step #674] loss: 2.1590321477254233\n",
      "[EPOCH #12, step #676] loss: 2.1591445114270975\n",
      "[EPOCH #12, step #678] loss: 2.1594179108497498\n",
      "[EPOCH #12, step #680] loss: 2.1586565595016256\n",
      "[EPOCH #12, step #682] loss: 2.1576243794330914\n",
      "[EPOCH #12, step #684] loss: 2.157343477054234\n",
      "[EPOCH #12, step #686] loss: 2.1573964891822404\n",
      "[EPOCH #12, step #688] loss: 2.1572997035412724\n",
      "[EPOCH #12, step #690] loss: 2.157415396742814\n",
      "[EPOCH #12, step #692] loss: 2.15742540583122\n",
      "[EPOCH #12, step #694] loss: 2.1575327161404725\n",
      "[EPOCH #12, step #696] loss: 2.1579571883681856\n",
      "[EPOCH #12, step #698] loss: 2.158214725479377\n",
      "[EPOCH #12, step #700] loss: 2.1577856222675122\n",
      "[EPOCH #12, step #702] loss: 2.1569900838274028\n",
      "[EPOCH #12, step #704] loss: 2.1581968182367635\n",
      "[EPOCH #12, step #706] loss: 2.157514645995986\n",
      "[EPOCH #12, step #708] loss: 2.156569579088133\n",
      "[EPOCH #12, step #710] loss: 2.157015979541505\n",
      "[EPOCH #12, step #712] loss: 2.156421977540721\n",
      "[EPOCH #12, step #714] loss: 2.1566303588293647\n",
      "[EPOCH #12, step #716] loss: 2.157499592839591\n",
      "[EPOCH #12, step #718] loss: 2.156384017437655\n",
      "[EPOCH #12, step #720] loss: 2.1558155061137163\n",
      "[EPOCH #12, step #722] loss: 2.1566789456917537\n",
      "[EPOCH #12, step #724] loss: 2.155843666339743\n",
      "[EPOCH #12, step #726] loss: 2.1564371920353445\n",
      "[EPOCH #12, step #728] loss: 2.1556004629213623\n",
      "[EPOCH #12, step #730] loss: 2.1561213627396465\n",
      "[EPOCH #12, step #732] loss: 2.1563404733454874\n",
      "[EPOCH #12, step #734] loss: 2.157040084949156\n",
      "[EPOCH #12, step #736] loss: 2.156962480279775\n",
      "[EPOCH #12, step #738] loss: 2.1569573342074237\n",
      "[EPOCH #12, step #740] loss: 2.156501927839117\n",
      "[EPOCH #12, step #742] loss: 2.156255707445568\n",
      "[EPOCH #12, step #744] loss: 2.155878037574307\n",
      "[EPOCH #12, step #746] loss: 2.1561123147068253\n",
      "[EPOCH #12, step #748] loss: 2.1564345222926424\n",
      "[EPOCH #12, step #750] loss: 2.156362797861569\n",
      "[EPOCH #12, step #752] loss: 2.1559122878400134\n",
      "[EPOCH #12, step #754] loss: 2.1555691049588437\n",
      "[EPOCH #12, step #756] loss: 2.155558980912797\n",
      "[EPOCH #12, step #758] loss: 2.1564929232452856\n",
      "[EPOCH #12, step #760] loss: 2.1576368371697825\n",
      "[EPOCH #12, step #762] loss: 2.157184762692233\n",
      "[EPOCH #12, step #764] loss: 2.157610976773929\n",
      "[EPOCH #12, step #766] loss: 2.1577313853988747\n",
      "[EPOCH #12, step #768] loss: 2.157986611476645\n",
      "[EPOCH #12, step #770] loss: 2.1582338135839283\n",
      "[EPOCH #12, step #772] loss: 2.1587295797478796\n",
      "[EPOCH #12, step #774] loss: 2.1585587464609453\n",
      "[EPOCH #12, step #776] loss: 2.158072246087564\n",
      "[EPOCH #12, step #778] loss: 2.1585252422729413\n",
      "[EPOCH #12, step #780] loss: 2.1585139773414017\n",
      "[EPOCH #12, step #782] loss: 2.1593326222089666\n",
      "[EPOCH #12, step #784] loss: 2.1598788221930243\n",
      "[EPOCH #12, step #786] loss: 2.1587982277706588\n",
      "[EPOCH #12, step #788] loss: 2.158428201052928\n",
      "[EPOCH #12, step #790] loss: 2.158559279707078\n",
      "[EPOCH #12, step #792] loss: 2.1581225796575656\n",
      "[EPOCH #12, step #794] loss: 2.1576623775674113\n",
      "[EPOCH #12, step #796] loss: 2.158276372153307\n",
      "[EPOCH #12, step #798] loss: 2.1587989936036074\n",
      "[EPOCH #12, step #800] loss: 2.1579473378804144\n",
      "[EPOCH #12, step #802] loss: 2.157822943565112\n",
      "[EPOCH #12, step #804] loss: 2.1580270663551664\n",
      "[EPOCH #12, step #806] loss: 2.1572348771632974\n",
      "[EPOCH #12, step #808] loss: 2.1568772452428697\n",
      "[EPOCH #12, step #810] loss: 2.1565690059697142\n",
      "[EPOCH #12, step #812] loss: 2.1559832553582\n",
      "[EPOCH #12, step #814] loss: 2.1553232740039476\n",
      "[EPOCH #12, step #816] loss: 2.155700203838372\n",
      "[EPOCH #12, step #818] loss: 2.1550768545404604\n",
      "[EPOCH #12, step #820] loss: 2.155309836263343\n",
      "[EPOCH #12, step #822] loss: 2.1546611257196195\n",
      "[EPOCH #12, step #824] loss: 2.154170166506912\n",
      "[EPOCH #12, step #826] loss: 2.15380943196284\n",
      "[EPOCH #12, step #828] loss: 2.1537081296538845\n",
      "[EPOCH #12, step #830] loss: 2.154014057631097\n",
      "[EPOCH #12, step #832] loss: 2.154371628240377\n",
      "[EPOCH #12, step #834] loss: 2.1540943681123013\n",
      "[EPOCH #12, step #836] loss: 2.154551738051958\n",
      "[EPOCH #12, step #838] loss: 2.15451970259538\n",
      "[EPOCH #12, step #840] loss: 2.154286404285363\n",
      "[EPOCH #12, step #842] loss: 2.154125630643444\n",
      "[EPOCH #12, step #844] loss: 2.1545773304425753\n",
      "[EPOCH #12, step #846] loss: 2.1550133877127062\n",
      "[EPOCH #12, step #848] loss: 2.154076511222426\n",
      "[EPOCH #12, step #850] loss: 2.153606409892072\n",
      "[EPOCH #12, step #852] loss: 2.15332279660917\n",
      "[EPOCH #12, step #854] loss: 2.1525056712111534\n",
      "[EPOCH #12, step #856] loss: 2.152292838591817\n",
      "[EPOCH #12, step #858] loss: 2.1528973371241507\n",
      "[EPOCH #12, step #860] loss: 2.1524488027364397\n",
      "[EPOCH #12, step #862] loss: 2.1520754445607526\n",
      "[EPOCH #12, step #864] loss: 2.152346808648523\n",
      "[EPOCH #12, step #866] loss: 2.151971544636437\n",
      "[EPOCH #12, step #868] loss: 2.1517611667942536\n",
      "[EPOCH #12, step #870] loss: 2.1518691007633843\n",
      "[EPOCH #12, step #872] loss: 2.1516227571961535\n",
      "[EPOCH #12, step #874] loss: 2.151520878791809\n",
      "[EPOCH #12, step #876] loss: 2.1514339842573404\n",
      "[EPOCH #12, step #878] loss: 2.1513300507548725\n",
      "[EPOCH #12, step #880] loss: 2.1512963639214955\n",
      "[EPOCH #12, step #882] loss: 2.1514862242533423\n",
      "[EPOCH #12, step #884] loss: 2.151788394195212\n",
      "[EPOCH #12, step #886] loss: 2.151673797287022\n",
      "[EPOCH #12, step #888] loss: 2.152102169491711\n",
      "[EPOCH #12, step #890] loss: 2.1526981205517464\n",
      "[EPOCH #12, step #892] loss: 2.1518095008202924\n",
      "[EPOCH #12, step #894] loss: 2.15139935296341\n",
      "[EPOCH #12, step #896] loss: 2.151564157660324\n",
      "[EPOCH #12, step #898] loss: 2.1509196105867923\n",
      "[EPOCH #12, step #900] loss: 2.1517296017340892\n",
      "[EPOCH #12, step #902] loss: 2.1512773529371683\n",
      "[EPOCH #12, step #904] loss: 2.151300672536397\n",
      "[EPOCH #12, step #906] loss: 2.150851254032097\n",
      "[EPOCH #12, step #908] loss: 2.150360841431109\n",
      "[EPOCH #12, step #910] loss: 2.1500606153458848\n",
      "[EPOCH #12, step #912] loss: 2.1496288858656034\n",
      "[EPOCH #12, step #914] loss: 2.1490730216594343\n",
      "[EPOCH #12, step #916] loss: 2.1492927116032123\n",
      "[EPOCH #12, step #918] loss: 2.148417139209004\n",
      "[EPOCH #12, step #920] loss: 2.1490295034278097\n",
      "[EPOCH #12, step #922] loss: 2.1487797985614185\n",
      "[EPOCH #12, step #924] loss: 2.1493089699100802\n",
      "[EPOCH #12, step #926] loss: 2.14917583553022\n",
      "[EPOCH #12, step #928] loss: 2.1494346361755685\n",
      "[EPOCH #12, step #930] loss: 2.1488149870351103\n",
      "[EPOCH #12, step #932] loss: 2.149248145145363\n",
      "[EPOCH #12, step #934] loss: 2.1493485234000467\n",
      "[EPOCH #12, step #936] loss: 2.149196009244074\n",
      "[EPOCH #12, step #938] loss: 2.1488234558806254\n",
      "[EPOCH #12, step #940] loss: 2.148691750738243\n",
      "[EPOCH #12, step #942] loss: 2.1483851757181034\n",
      "[EPOCH #12, step #944] loss: 2.1489551990751234\n",
      "[EPOCH #12, step #946] loss: 2.148917473986383\n",
      "[EPOCH #12, step #948] loss: 2.1490067836482107\n",
      "[EPOCH #12, step #950] loss: 2.149419242400602\n",
      "[EPOCH #12, step #952] loss: 2.1500229546555945\n",
      "[EPOCH #12, step #954] loss: 2.1499801075271288\n",
      "[EPOCH #12, step #956] loss: 2.150856346545922\n",
      "[EPOCH #12, step #958] loss: 2.150767052882158\n",
      "[EPOCH #12, step #960] loss: 2.1503848386976894\n",
      "[EPOCH #12, step #962] loss: 2.149403121612525\n",
      "[EPOCH #12, step #964] loss: 2.150042752404287\n",
      "[EPOCH #12, step #966] loss: 2.1492383732790783\n",
      "[EPOCH #12, step #968] loss: 2.150053385610551\n",
      "[EPOCH #12, step #970] loss: 2.1498934740141173\n",
      "[EPOCH #12, step #972] loss: 2.149405472202634\n",
      "[EPOCH #12, step #974] loss: 2.149239776684688\n",
      "[EPOCH #12, step #976] loss: 2.1485308348949514\n",
      "[EPOCH #12, step #978] loss: 2.1485474471295816\n",
      "[EPOCH #12, step #980] loss: 2.1482932844657783\n",
      "[EPOCH #12, step #982] loss: 2.1473964111972315\n",
      "[EPOCH #12, step #984] loss: 2.1473619502207955\n",
      "[EPOCH #12, step #986] loss: 2.1472422182861917\n",
      "[EPOCH #12, step #988] loss: 2.1472781907439353\n",
      "[EPOCH #12, step #990] loss: 2.1473633400968057\n",
      "[EPOCH #12, step #992] loss: 2.1473337381868083\n",
      "[EPOCH #12, step #994] loss: 2.1474512902935547\n",
      "[EPOCH #12, step #996] loss: 2.147300251867013\n",
      "[EPOCH #12, step #998] loss: 2.1464853842814526\n",
      "[EPOCH #12, step #1000] loss: 2.1466682316897274\n",
      "[EPOCH #12, step #1002] loss: 2.1468909086282566\n",
      "[EPOCH #12, step #1004] loss: 2.1470923563734217\n",
      "[EPOCH #12, step #1006] loss: 2.1476004999704372\n",
      "[EPOCH #12, step #1008] loss: 2.1475152151790198\n",
      "[EPOCH #12, step #1010] loss: 2.147626240104879\n",
      "[EPOCH #12, step #1012] loss: 2.147670736199894\n",
      "[EPOCH #12, step #1014] loss: 2.1475728690330618\n",
      "[EPOCH #12, step #1016] loss: 2.1480465690177684\n",
      "[EPOCH #12, step #1018] loss: 2.1480605133148356\n",
      "[EPOCH #12, step #1020] loss: 2.1479236243637487\n",
      "[EPOCH #12, step #1022] loss: 2.148030616204643\n",
      "[EPOCH #12, step #1024] loss: 2.1482581841073385\n",
      "[EPOCH #12, step #1026] loss: 2.148231055279205\n",
      "[EPOCH #12, step #1028] loss: 2.148843605849671\n",
      "[EPOCH #12, step #1030] loss: 2.148340922091102\n",
      "[EPOCH #12, step #1032] loss: 2.1484972864014367\n",
      "[EPOCH #12, step #1034] loss: 2.148034950846059\n",
      "[EPOCH #12, step #1036] loss: 2.1478933866136676\n",
      "[EPOCH #12, step #1038] loss: 2.147468111971689\n",
      "[EPOCH #12, step #1040] loss: 2.1478909446457966\n",
      "[EPOCH #12, step #1042] loss: 2.1480294038556793\n",
      "[EPOCH #12, step #1044] loss: 2.1479117994673516\n",
      "[EPOCH #12, step #1046] loss: 2.147681360030698\n",
      "[EPOCH #12, step #1048] loss: 2.1480302189053297\n",
      "[EPOCH #12, step #1050] loss: 2.1478365774272623\n",
      "[EPOCH #12, step #1052] loss: 2.1472154735726394\n",
      "[EPOCH #12, step #1054] loss: 2.147424705446614\n",
      "[EPOCH #12, step #1056] loss: 2.147520715827184\n",
      "[EPOCH #12, step #1058] loss: 2.1479903708323764\n",
      "[EPOCH #12, step #1060] loss: 2.1481997447683496\n",
      "[EPOCH #12, step #1062] loss: 2.1484180710165433\n",
      "[EPOCH #12, step #1064] loss: 2.147550302268194\n",
      "[EPOCH #12, step #1066] loss: 2.1473785702491766\n",
      "[EPOCH #12, step #1068] loss: 2.1472454213783827\n",
      "[EPOCH #12, step #1070] loss: 2.1465216177184376\n",
      "[EPOCH #12, step #1072] loss: 2.1464767507160256\n",
      "[EPOCH #12, step #1074] loss: 2.1458802198809246\n",
      "[EPOCH #12, step #1076] loss: 2.146242892177656\n",
      "[EPOCH #12, step #1078] loss: 2.146537606864201\n",
      "[EPOCH #12, step #1080] loss: 2.1464068163996157\n",
      "[EPOCH #12, step #1082] loss: 2.146015228106815\n",
      "[EPOCH #12, step #1084] loss: 2.145550437786612\n",
      "[EPOCH #12, step #1086] loss: 2.145150213583742\n",
      "[EPOCH #12, step #1088] loss: 2.145380735616272\n",
      "[EPOCH #12, step #1090] loss: 2.1452496601396693\n",
      "[EPOCH #12, step #1092] loss: 2.1454005653664048\n",
      "[EPOCH #12, step #1094] loss: 2.1448695683588177\n",
      "[EPOCH #12, step #1096] loss: 2.1446672369375377\n",
      "[EPOCH #12, step #1098] loss: 2.144664836754248\n",
      "[EPOCH #12, step #1100] loss: 2.1448449411790658\n",
      "[EPOCH #12, step #1102] loss: 2.1445439291994677\n",
      "[EPOCH #12, step #1104] loss: 2.1446796503541696\n",
      "[EPOCH #12, step #1106] loss: 2.1440440402336773\n",
      "[EPOCH #12, step #1108] loss: 2.1435490059788105\n",
      "[EPOCH #12, step #1110] loss: 2.1441718460095025\n",
      "[EPOCH #12, step #1112] loss: 2.14468495254568\n",
      "[EPOCH #12, step #1114] loss: 2.144745813784578\n",
      "[EPOCH #12, step #1116] loss: 2.1451525215389693\n",
      "[EPOCH #12, step #1118] loss: 2.1449650118029258\n",
      "[EPOCH #12, step #1120] loss: 2.14435626799033\n",
      "[EPOCH #12, step #1122] loss: 2.1445928150696725\n",
      "[EPOCH #12, step #1124] loss: 2.1444203601413303\n",
      "[EPOCH #12, step #1126] loss: 2.1444076479486163\n",
      "[EPOCH #12, step #1128] loss: 2.1440604753046566\n",
      "[EPOCH #12, step #1130] loss: 2.143957951762421\n",
      "[EPOCH #12, step #1132] loss: 2.1444230357420095\n",
      "[EPOCH #12, step #1134] loss: 2.144206882783495\n",
      "[EPOCH #12, step #1136] loss: 2.144169079492044\n",
      "[EPOCH #12, step #1138] loss: 2.144001291235672\n",
      "[EPOCH #12, step #1140] loss: 2.1444508581178217\n",
      "[EPOCH #12, step #1142] loss: 2.144394564816332\n",
      "[EPOCH #12, step #1144] loss: 2.1437385719415922\n",
      "[EPOCH #12, step #1146] loss: 2.143560009514028\n",
      "[EPOCH #12, step #1148] loss: 2.142813698844976\n",
      "[EPOCH #12, step #1150] loss: 2.1431530214826715\n",
      "[EPOCH #12, step #1152] loss: 2.1423892218034783\n",
      "[EPOCH #12, step #1154] loss: 2.1423443738516275\n",
      "[EPOCH #12, step #1156] loss: 2.142104931504127\n",
      "[EPOCH #12, step #1158] loss: 2.142005352237494\n",
      "[EPOCH #12, step #1160] loss: 2.141191480285027\n",
      "[EPOCH #12, step #1162] loss: 2.1406759197919\n",
      "[EPOCH #12, step #1164] loss: 2.141249129393582\n",
      "[EPOCH #12, step #1166] loss: 2.140951138229174\n",
      "[EPOCH #12, step #1168] loss: 2.1409034759596537\n",
      "[EPOCH #12, step #1170] loss: 2.141309598691437\n",
      "[EPOCH #12, step #1172] loss: 2.142037403248155\n",
      "[EPOCH #12, step #1174] loss: 2.1418992052686976\n",
      "[EPOCH #12, step #1176] loss: 2.1418384835187316\n",
      "[EPOCH #12, step #1178] loss: 2.141358186775997\n",
      "[EPOCH #12, step #1180] loss: 2.141367165644627\n",
      "[EPOCH #12, step #1182] loss: 2.141581131962529\n",
      "[EPOCH #12, step #1184] loss: 2.1414143294724735\n",
      "[EPOCH #12, step #1186] loss: 2.1407954246935565\n",
      "[EPOCH #12, step #1188] loss: 2.141104069149123\n",
      "[EPOCH #12, step #1190] loss: 2.1410951837584515\n",
      "[EPOCH #12, step #1192] loss: 2.141145789613268\n",
      "[EPOCH #12, step #1194] loss: 2.1411531240870265\n",
      "[EPOCH #12, step #1196] loss: 2.141146237190903\n",
      "[EPOCH #12, step #1198] loss: 2.1415364947092344\n",
      "[EPOCH #12, step #1200] loss: 2.1414334355147058\n",
      "[EPOCH #12, step #1202] loss: 2.14161970094156\n",
      "[EPOCH #12, step #1204] loss: 2.14165045809449\n",
      "[EPOCH #12, step #1206] loss: 2.1412956261299025\n",
      "[EPOCH #12, step #1208] loss: 2.141560745692825\n",
      "[EPOCH #12, step #1210] loss: 2.141247956640557\n",
      "[EPOCH #12, step #1212] loss: 2.1409333966924255\n",
      "[EPOCH #12, step #1214] loss: 2.140964890115055\n",
      "[EPOCH #12, step #1216] loss: 2.1409488519685818\n",
      "[EPOCH #12, step #1218] loss: 2.140501563719201\n",
      "[EPOCH #12, step #1220] loss: 2.1401335972435254\n",
      "[EPOCH #12, step #1222] loss: 2.139779512158984\n",
      "[EPOCH #12, step #1224] loss: 2.1403066317889157\n",
      "[EPOCH #12, step #1226] loss: 2.140392039010655\n",
      "[EPOCH #12, step #1228] loss: 2.139836094067095\n",
      "[EPOCH #12, step #1230] loss: 2.1394382476031923\n",
      "[EPOCH #12, step #1232] loss: 2.1395929283179216\n",
      "[EPOCH #12, step #1234] loss: 2.139605775053202\n",
      "[EPOCH #12, step #1236] loss: 2.1393983414217455\n",
      "[EPOCH #12, step #1238] loss: 2.139752999922265\n",
      "[EPOCH #12, step #1240] loss: 2.139458032311402\n",
      "[EPOCH #12, step #1242] loss: 2.1397059261079576\n",
      "[EPOCH #12, step #1244] loss: 2.1391889879502446\n",
      "[EPOCH #12, step #1246] loss: 2.139402431684584\n",
      "[EPOCH #12, step #1248] loss: 2.1389670012186204\n",
      "[EPOCH #12, step #1250] loss: 2.1389920409444234\n",
      "[EPOCH #12, step #1252] loss: 2.1389160397903306\n",
      "[EPOCH #12, step #1254] loss: 2.138694694602632\n",
      "[EPOCH #12, step #1256] loss: 2.1384862833015483\n",
      "[EPOCH #12, step #1258] loss: 2.138291064569929\n",
      "[EPOCH #12, step #1260] loss: 2.1383856370466083\n",
      "[EPOCH #12, step #1262] loss: 2.1381649332016304\n",
      "[EPOCH #12, step #1264] loss: 2.138057029765585\n",
      "[EPOCH #12, step #1266] loss: 2.1375506643996807\n",
      "[EPOCH #12, step #1268] loss: 2.137661140203664\n",
      "[EPOCH #12, step #1270] loss: 2.137715419852574\n",
      "[EPOCH #12, step #1272] loss: 2.1373699667504336\n",
      "[EPOCH #12, step #1274] loss: 2.1371356074015297\n",
      "[EPOCH #12, step #1276] loss: 2.1370668513941036\n",
      "[EPOCH #12, step #1278] loss: 2.136494261292017\n",
      "[EPOCH #12, step #1280] loss: 2.13646971313959\n",
      "[EPOCH #12, step #1282] loss: 2.136082050489989\n",
      "[EPOCH #12, step #1284] loss: 2.1364414348676513\n",
      "[EPOCH #12, step #1286] loss: 2.1367039841649693\n",
      "[EPOCH #12, step #1288] loss: 2.136853321935892\n",
      "[EPOCH #12, step #1290] loss: 2.136772761226716\n",
      "[EPOCH #12, step #1292] loss: 2.1368581654946195\n",
      "[EPOCH #12, step #1294] loss: 2.137080682290567\n",
      "[EPOCH #12, step #1296] loss: 2.1375912443527185\n",
      "[EPOCH #12, step #1298] loss: 2.1373965461222917\n",
      "[EPOCH #12, step #1300] loss: 2.1379322862735077\n",
      "[EPOCH #12, step #1302] loss: 2.1383349858881964\n",
      "[EPOCH #12, step #1304] loss: 2.1386762865658464\n",
      "[EPOCH #12, step #1306] loss: 2.1383147698462968\n",
      "[EPOCH #12, step #1308] loss: 2.138345577317945\n",
      "[EPOCH #12, step #1310] loss: 2.1382062770682015\n",
      "[EPOCH #12, step #1312] loss: 2.1384558155621995\n",
      "[EPOCH #12, step #1314] loss: 2.138765606046176\n",
      "[EPOCH #12, step #1316] loss: 2.138871098524165\n",
      "[EPOCH #12, step #1318] loss: 2.1391474777681525\n",
      "[EPOCH #12, step #1320] loss: 2.1391100689464224\n",
      "[EPOCH #12, step #1322] loss: 2.1389178949508896\n",
      "[EPOCH #12, step #1324] loss: 2.1388890214236276\n",
      "[EPOCH #12, step #1326] loss: 2.1387360799375474\n",
      "[EPOCH #12, step #1328] loss: 2.137917179376044\n",
      "[EPOCH #12, step #1330] loss: 2.138387456144452\n",
      "[EPOCH #12, step #1332] loss: 2.138325207857646\n",
      "[EPOCH #12, step #1334] loss: 2.138205393423302\n",
      "[EPOCH #12, step #1336] loss: 2.1381824505177556\n",
      "[EPOCH #12, step #1338] loss: 2.1382101499117336\n",
      "[EPOCH #12, step #1340] loss: 2.1382968848894817\n",
      "[EPOCH #12, step #1342] loss: 2.1382663496731826\n",
      "[EPOCH #12, step #1344] loss: 2.1378572467534513\n",
      "[EPOCH #12, step #1346] loss: 2.1377111954784604\n",
      "[EPOCH #12, step #1348] loss: 2.1372685167328176\n",
      "[EPOCH #12, step #1350] loss: 2.137704448643479\n",
      "[EPOCH #12, step #1352] loss: 2.1376940708907552\n",
      "[EPOCH #12, step #1354] loss: 2.1377742932731376\n",
      "[EPOCH #12, step #1356] loss: 2.1377318783902735\n",
      "[EPOCH #12, step #1358] loss: 2.138061486595777\n",
      "[EPOCH #12, step #1360] loss: 2.13798409047852\n",
      "[EPOCH #12, step #1362] loss: 2.138140833386584\n",
      "[EPOCH #12, step #1364] loss: 2.138235005790934\n",
      "[EPOCH #12, step #1366] loss: 2.1383022778035956\n",
      "[EPOCH #12, step #1368] loss: 2.137859886714888\n",
      "[EPOCH #12, step #1370] loss: 2.1378122222067057\n",
      "[EPOCH #12, step #1372] loss: 2.137868380859136\n",
      "[EPOCH #12, step #1374] loss: 2.1377406513907693\n",
      "[EPOCH #12, step #1376] loss: 2.1384114888412156\n",
      "[EPOCH #12, step #1378] loss: 2.1381908314568654\n",
      "[EPOCH #12, step #1380] loss: 2.1380037212613523\n",
      "[EPOCH #12, step #1382] loss: 2.138042267129116\n",
      "[EPOCH #12, step #1384] loss: 2.1379594495580516\n",
      "[EPOCH #12, step #1386] loss: 2.1378889889191104\n",
      "[EPOCH #12, step #1388] loss: 2.1372572184467247\n",
      "[EPOCH #12, step #1390] loss: 2.1372482123604617\n",
      "[EPOCH #12, step #1392] loss: 2.137074886083774\n",
      "[EPOCH #12, step #1394] loss: 2.136796682453497\n",
      "[EPOCH #12, step #1396] loss: 2.1369126218510424\n",
      "[EPOCH #12, step #1398] loss: 2.136628568385481\n",
      "[EPOCH #12, step #1400] loss: 2.1359999869909565\n",
      "[EPOCH #12, step #1402] loss: 2.135982745473757\n",
      "[EPOCH #12, step #1404] loss: 2.1359903494234187\n",
      "[EPOCH #12, step #1406] loss: 2.1360435697654503\n",
      "[EPOCH #12, step #1408] loss: 2.1358941932194955\n",
      "[EPOCH #12, step #1410] loss: 2.13635504364038\n",
      "[EPOCH #12, step #1412] loss: 2.1366371559236206\n",
      "[EPOCH #12, step #1414] loss: 2.136715507760065\n",
      "[EPOCH #12, step #1416] loss: 2.1368028772659677\n",
      "[EPOCH #12, step #1418] loss: 2.1367383918096854\n",
      "[EPOCH #12, step #1420] loss: 2.1369205693138222\n",
      "[EPOCH #12, step #1422] loss: 2.136826111662162\n",
      "[EPOCH #12, step #1424] loss: 2.1367093135599506\n",
      "[EPOCH #12, step #1426] loss: 2.136953620452854\n",
      "[EPOCH #12, step #1428] loss: 2.1370100351878194\n",
      "[EPOCH #12, step #1430] loss: 2.1368425583023027\n",
      "[EPOCH #12, step #1432] loss: 2.1374899771191904\n",
      "[EPOCH #12, step #1434] loss: 2.1371591421785254\n",
      "[EPOCH #12, step #1436] loss: 2.137222684582821\n",
      "[EPOCH #12, step #1438] loss: 2.1374845489849226\n",
      "[EPOCH #12, step #1440] loss: 2.137919881954365\n",
      "[EPOCH #12, step #1442] loss: 2.137670707636547\n",
      "[EPOCH #12, step #1444] loss: 2.137683686995589\n",
      "[EPOCH #12, step #1446] loss: 2.1375990328330703\n",
      "[EPOCH #12, step #1448] loss: 2.1370721388225147\n",
      "[EPOCH #12, step #1450] loss: 2.137195485119652\n",
      "[EPOCH #12, step #1452] loss: 2.1373202190346663\n",
      "[EPOCH #12, step #1454] loss: 2.137566979890017\n",
      "[EPOCH #12, step #1456] loss: 2.1377118288366126\n",
      "[EPOCH #12, step #1458] loss: 2.138164788423294\n",
      "[EPOCH #12, step #1460] loss: 2.138105291279108\n",
      "[EPOCH #12, step #1462] loss: 2.1377626811488395\n",
      "[EPOCH #12, step #1464] loss: 2.1383542383083305\n",
      "[EPOCH #12, step #1466] loss: 2.1384163894211263\n",
      "[EPOCH #12, step #1468] loss: 2.1383667492071248\n",
      "[EPOCH #12, step #1470] loss: 2.138540948353034\n",
      "[EPOCH #12, step #1472] loss: 2.1387556962066983\n",
      "[EPOCH #12, step #1474] loss: 2.1387107469267765\n",
      "[EPOCH #12, step #1476] loss: 2.1384797204404404\n",
      "[EPOCH #12, step #1478] loss: 2.138725949913525\n",
      "[EPOCH #12, step #1480] loss: 2.138565342543819\n",
      "[EPOCH #12, step #1482] loss: 2.1384921849617986\n",
      "[EPOCH #12, step #1484] loss: 2.138203245461589\n",
      "[EPOCH #12, step #1486] loss: 2.138355235646215\n",
      "[EPOCH #12, step #1488] loss: 2.1387529234665204\n",
      "[EPOCH #12, step #1490] loss: 2.1388996428567078\n",
      "[EPOCH #12, step #1492] loss: 2.139196261174712\n",
      "[EPOCH #12, step #1494] loss: 2.1389182869008554\n",
      "[EPOCH #12, step #1496] loss: 2.1387274885623553\n",
      "[EPOCH #12, step #1498] loss: 2.1387348214016506\n",
      "[EPOCH #12, step #1500] loss: 2.138667416445499\n",
      "[EPOCH #12, step #1502] loss: 2.1385855539116316\n",
      "[EPOCH #12, step #1504] loss: 2.138219518122879\n",
      "[EPOCH #12, step #1506] loss: 2.1381781199315406\n",
      "[EPOCH #12, step #1508] loss: 2.1382034529590546\n",
      "[EPOCH #12, step #1510] loss: 2.1378092611175274\n",
      "[EPOCH #12, step #1512] loss: 2.1374706074014376\n",
      "[EPOCH #12, step #1514] loss: 2.13752281783831\n",
      "[EPOCH #12, step #1516] loss: 2.137047629491546\n",
      "[EPOCH #12, step #1518] loss: 2.1371439848391924\n",
      "[EPOCH #12, step #1520] loss: 2.137017629085443\n",
      "[EPOCH #12, step #1522] loss: 2.136642250197543\n",
      "[EPOCH #12, step #1524] loss: 2.1369728541765056\n",
      "[EPOCH #12, step #1526] loss: 2.1367632095222\n",
      "[EPOCH #12, step #1528] loss: 2.1363186151705356\n",
      "[EPOCH #12, step #1530] loss: 2.1365654794006548\n",
      "[EPOCH #12, step #1532] loss: 2.137317947367788\n",
      "[EPOCH #12, step #1534] loss: 2.137455185150867\n",
      "[EPOCH #12, step #1536] loss: 2.137283949783737\n",
      "[EPOCH #12, step #1538] loss: 2.1367203344223635\n",
      "[EPOCH #12, step #1540] loss: 2.1371740969181987\n",
      "[EPOCH #12, step #1542] loss: 2.137017796044217\n",
      "[EPOCH #12, step #1544] loss: 2.1365479987030276\n",
      "[EPOCH #12, step #1546] loss: 2.136765929831176\n",
      "[EPOCH #12, step #1548] loss: 2.1369081917233896\n",
      "[EPOCH #12, step #1550] loss: 2.1369349048800195\n",
      "[EPOCH #12, step #1552] loss: 2.136942353159554\n",
      "[EPOCH #12, step #1554] loss: 2.136673252222239\n",
      "[EPOCH #12, step #1556] loss: 2.1365226992599156\n",
      "[EPOCH #12, step #1558] loss: 2.1361557506765596\n",
      "[EPOCH #12, step #1560] loss: 2.1360317998631957\n",
      "[EPOCH #12, step #1562] loss: 2.1357636269436995\n",
      "[EPOCH #12, step #1564] loss: 2.135427676374539\n",
      "[EPOCH #12, step #1566] loss: 2.1356634308596516\n",
      "[EPOCH #12, step #1568] loss: 2.1353853737343034\n",
      "[EPOCH #12, step #1570] loss: 2.1352219375207273\n",
      "[EPOCH #12, step #1572] loss: 2.135139963540467\n",
      "[EPOCH #12, step #1574] loss: 2.1351965150379\n",
      "[EPOCH #12, step #1576] loss: 2.134680382345172\n",
      "[EPOCH #12, step #1578] loss: 2.1346488575002223\n",
      "[EPOCH #12, step #1580] loss: 2.1345953542472893\n",
      "[EPOCH #12, step #1582] loss: 2.1346505420989654\n",
      "[EPOCH #12, step #1584] loss: 2.134631884210869\n",
      "[EPOCH #12, step #1586] loss: 2.1346019504200986\n",
      "[EPOCH #12, step #1588] loss: 2.134400484020264\n",
      "[EPOCH #12, step #1590] loss: 2.1341324304350513\n",
      "[EPOCH #12, step #1592] loss: 2.134429920939477\n",
      "[EPOCH #12, step #1594] loss: 2.1342252518316047\n",
      "[EPOCH #12, step #1596] loss: 2.134004233998661\n",
      "[EPOCH #12, step #1598] loss: 2.133940517715993\n",
      "[EPOCH #12, step #1600] loss: 2.1341225097955276\n",
      "[EPOCH #12, step #1602] loss: 2.1343929832307382\n",
      "[EPOCH #12, step #1604] loss: 2.1346619366114012\n",
      "[EPOCH #12, step #1606] loss: 2.1347064414822543\n",
      "[EPOCH #12, step #1608] loss: 2.1343010699548954\n",
      "[EPOCH #12, step #1610] loss: 2.134160137339307\n",
      "[EPOCH #12, step #1612] loss: 2.1341167152556144\n",
      "[EPOCH #12, step #1614] loss: 2.1339667174100136\n",
      "[EPOCH #12, step #1616] loss: 2.1339698439405224\n",
      "[EPOCH #12, step #1618] loss: 2.1339703070079197\n",
      "[EPOCH #12, step #1620] loss: 2.1340078416244253\n",
      "[EPOCH #12, step #1622] loss: 2.1335745293346364\n",
      "[EPOCH #12, step #1624] loss: 2.133956637089069\n",
      "[EPOCH #12, step #1626] loss: 2.1343598691832457\n",
      "[EPOCH #12, step #1628] loss: 2.1344543515428436\n",
      "[EPOCH #12, step #1630] loss: 2.1341520202152573\n",
      "[EPOCH #12, step #1632] loss: 2.134037771111095\n",
      "[EPOCH #12, step #1634] loss: 2.134139865983152\n",
      "[EPOCH #12, step #1636] loss: 2.1339731832503106\n",
      "[EPOCH #12, step #1638] loss: 2.1337936152184134\n",
      "[EPOCH #12, step #1640] loss: 2.1337176375386195\n",
      "[EPOCH #12, step #1642] loss: 2.133705987265686\n",
      "[EPOCH #12, step #1644] loss: 2.1337054900485333\n",
      "[EPOCH #12, step #1646] loss: 2.133611155555114\n",
      "[EPOCH #12, step #1648] loss: 2.1339022276833823\n",
      "[EPOCH #12, step #1650] loss: 2.1335921649280136\n",
      "[EPOCH #12, step #1652] loss: 2.133985668907581\n",
      "[EPOCH #12, step #1654] loss: 2.1338438134179016\n",
      "[EPOCH #12, step #1656] loss: 2.133854568688065\n",
      "[EPOCH #12, step #1658] loss: 2.1337274379799207\n",
      "[EPOCH #12, step #1660] loss: 2.133912165576905\n",
      "[EPOCH #12, step #1662] loss: 2.134061758731835\n",
      "[EPOCH #12, step #1664] loss: 2.1340746288185004\n",
      "[EPOCH #12, step #1666] loss: 2.1342389554983137\n",
      "[EPOCH #12, step #1668] loss: 2.1340220329502944\n",
      "[EPOCH #12, step #1670] loss: 2.1337000835733737\n",
      "[EPOCH #12, step #1672] loss: 2.1340711577096814\n",
      "[EPOCH #12, step #1674] loss: 2.133950517924864\n",
      "[EPOCH #12, step #1676] loss: 2.133970802428826\n",
      "[EPOCH #12, step #1678] loss: 2.1339691899375164\n",
      "[EPOCH #12, step #1680] loss: 2.134217234610944\n",
      "[EPOCH #12, step #1682] loss: 2.134436539504334\n",
      "[EPOCH #12, step #1684] loss: 2.1344625481512143\n",
      "[EPOCH #12, step #1686] loss: 2.134085129900097\n",
      "[EPOCH #12, step #1688] loss: 2.13402204149358\n",
      "[EPOCH #12, step #1690] loss: 2.134154958177924\n",
      "[EPOCH #12, step #1692] loss: 2.1342766959499624\n",
      "[EPOCH #12, step #1694] loss: 2.134348355493011\n",
      "[EPOCH #12, step #1696] loss: 2.1344182048745908\n",
      "[EPOCH #12, step #1698] loss: 2.134697382698486\n",
      "[EPOCH #12, step #1700] loss: 2.1347337432078652\n",
      "[EPOCH #12, step #1702] loss: 2.134898662217141\n",
      "[EPOCH #12, step #1704] loss: 2.1348553245018653\n",
      "[EPOCH #12, step #1706] loss: 2.1346632974777715\n",
      "[EPOCH #12, step #1708] loss: 2.1345352201590138\n",
      "[EPOCH #12, step #1710] loss: 2.1346244580699714\n",
      "[EPOCH #12, step #1712] loss: 2.134455911889107\n",
      "[EPOCH #12, step #1714] loss: 2.1344615738871493\n",
      "[EPOCH #12, step #1716] loss: 2.1345853655575735\n",
      "[EPOCH #12, step #1718] loss: 2.13464663207635\n",
      "[EPOCH #12, step #1720] loss: 2.134640657645474\n",
      "[EPOCH #12, step #1722] loss: 2.1346512759624354\n",
      "[EPOCH #12, step #1724] loss: 2.1339847839742467\n",
      "[EPOCH #12, step #1726] loss: 2.1343780457110646\n",
      "[EPOCH #12, step #1728] loss: 2.134194460612904\n",
      "[EPOCH #12, step #1730] loss: 2.1345147197471057\n",
      "[EPOCH #12, step #1732] loss: 2.134724409884273\n",
      "[EPOCH #12, step #1734] loss: 2.134586809897629\n",
      "[EPOCH #12, step #1736] loss: 2.1345674628558076\n",
      "[EPOCH #12, step #1738] loss: 2.134615876127619\n",
      "[EPOCH #12, step #1740] loss: 2.134159348190413\n",
      "[EPOCH #12, step #1742] loss: 2.133987253381135\n",
      "[EPOCH #12, step #1744] loss: 2.1340592287331392\n",
      "[EPOCH #12, step #1746] loss: 2.1338228883917973\n",
      "[EPOCH #12, step #1748] loss: 2.1333502210024906\n",
      "[EPOCH #12, step #1750] loss: 2.1330906339266313\n",
      "[EPOCH #12, step #1752] loss: 2.132979704799206\n",
      "[EPOCH #12, step #1754] loss: 2.1324723038578304\n",
      "[EPOCH #12, step #1756] loss: 2.132376251603367\n",
      "[EPOCH #12, step #1758] loss: 2.132408258452749\n",
      "[EPOCH #12, step #1760] loss: 2.132124266253487\n",
      "[EPOCH #12, step #1762] loss: 2.132160756172812\n",
      "[EPOCH #12, step #1764] loss: 2.13209511416492\n",
      "[EPOCH #12, step #1766] loss: 2.1320421174885396\n",
      "[EPOCH #12, step #1768] loss: 2.1321189601654518\n",
      "[EPOCH #12, step #1770] loss: 2.1322122197713913\n",
      "[EPOCH #12, step #1772] loss: 2.131794862739124\n",
      "[EPOCH #12, step #1774] loss: 2.131559119560349\n",
      "[EPOCH #12, step #1776] loss: 2.1317121741069993\n",
      "[EPOCH #12, step #1778] loss: 2.1321531711769213\n",
      "[EPOCH #12, step #1780] loss: 2.1317074778105423\n",
      "[EPOCH #12, step #1782] loss: 2.1316197205980507\n",
      "[EPOCH #12, step #1784] loss: 2.1317663714999244\n",
      "[EPOCH #12, step #1786] loss: 2.131959753191264\n",
      "[EPOCH #12, step #1788] loss: 2.1317504898271724\n",
      "[EPOCH #12, step #1790] loss: 2.131677559605529\n",
      "[EPOCH #12, step #1792] loss: 2.1318395271423602\n",
      "[EPOCH #12, step #1794] loss: 2.131851035107477\n",
      "[EPOCH #12, step #1796] loss: 2.131757966863094\n",
      "[EPOCH #12, step #1798] loss: 2.1315615771544385\n",
      "[EPOCH #12, step #1800] loss: 2.131626958320169\n",
      "[EPOCH #12, step #1802] loss: 2.1314940223810215\n",
      "[EPOCH #12, step #1804] loss: 2.1315290268768563\n",
      "[EPOCH #12, step #1806] loss: 2.13173492982629\n",
      "[EPOCH #12, step #1808] loss: 2.1317356237724647\n",
      "[EPOCH #12, step #1810] loss: 2.1316975343958044\n",
      "[EPOCH #12, step #1812] loss: 2.132025525508108\n",
      "[EPOCH #12, step #1814] loss: 2.1318354175110494\n",
      "[EPOCH #12, step #1816] loss: 2.131650473694914\n",
      "[EPOCH #12, step #1818] loss: 2.1317165807553082\n",
      "[EPOCH #12, step #1820] loss: 2.1313949674122417\n",
      "[EPOCH #12, step #1822] loss: 2.131353673932321\n",
      "[EPOCH #12, step #1824] loss: 2.131585494982053\n",
      "[EPOCH #12, step #1826] loss: 2.1315745044811605\n",
      "[EPOCH #12, step #1828] loss: 2.131421359462644\n",
      "[EPOCH #12, step #1830] loss: 2.1313574909187287\n",
      "[EPOCH #12, step #1832] loss: 2.1311598319013587\n",
      "[EPOCH #12, step #1834] loss: 2.1316981403314452\n",
      "[EPOCH #12, step #1836] loss: 2.1316551587214336\n",
      "[EPOCH #12, step #1838] loss: 2.1316005301384773\n",
      "[EPOCH #12, step #1840] loss: 2.1315882866438285\n",
      "[EPOCH #12, step #1842] loss: 2.1315308074490633\n",
      "[EPOCH #12, step #1844] loss: 2.1318615694356158\n",
      "[EPOCH #12, step #1846] loss: 2.132043374120447\n",
      "[EPOCH #12, step #1848] loss: 2.1319594398068378\n",
      "[EPOCH #12, step #1850] loss: 2.131596475276092\n",
      "[EPOCH #12, step #1852] loss: 2.1317384278394695\n",
      "[EPOCH #12, step #1854] loss: 2.132049808155173\n",
      "[EPOCH #12, step #1856] loss: 2.1322385035475286\n",
      "[EPOCH #12, step #1858] loss: 2.132108947357354\n",
      "[EPOCH #12, step #1860] loss: 2.1319334451259304\n",
      "[EPOCH #12, step #1862] loss: 2.1315938103154215\n",
      "[EPOCH #12, step #1864] loss: 2.1316184651116585\n",
      "[EPOCH #12, step #1866] loss: 2.131860608395626\n",
      "[EPOCH #12, step #1868] loss: 2.131437424480628\n",
      "[EPOCH #12, step #1870] loss: 2.1312998333186277\n",
      "[EPOCH #12, step #1872] loss: 2.131562531280823\n",
      "[EPOCH #12, step #1874] loss: 2.1316649737675983\n",
      "[EPOCH #12, step #1876] loss: 2.1316711878484402\n",
      "[EPOCH #12, step #1878] loss: 2.1318597310143876\n",
      "[EPOCH #12, step #1880] loss: 2.131821897421537\n",
      "[EPOCH #12, step #1882] loss: 2.1320796121768475\n",
      "[EPOCH #12, step #1884] loss: 2.131962011726845\n",
      "[EPOCH #12, step #1886] loss: 2.132093613148999\n",
      "[EPOCH #12, step #1888] loss: 2.1322725308894355\n",
      "[EPOCH #12, step #1890] loss: 2.132165474717671\n",
      "[EPOCH #12, step #1892] loss: 2.1321987815464984\n",
      "[EPOCH #12, step #1894] loss: 2.1320997513063977\n",
      "[EPOCH #12, step #1896] loss: 2.131946027750207\n",
      "[EPOCH #12, step #1898] loss: 2.1318310632901545\n",
      "[EPOCH #12, step #1900] loss: 2.1316426461273466\n",
      "[EPOCH #12, step #1902] loss: 2.131555611624946\n",
      "[EPOCH #12, step #1904] loss: 2.131430289250972\n",
      "[EPOCH #12, step #1906] loss: 2.1313847617822974\n",
      "[EPOCH #12, step #1908] loss: 2.131939458996916\n",
      "[EPOCH #12, step #1910] loss: 2.131936343535898\n",
      "[EPOCH #12, step #1912] loss: 2.1317182335003597\n",
      "[EPOCH #12, step #1914] loss: 2.1319509780126826\n",
      "[EPOCH #12, step #1916] loss: 2.132015421916621\n",
      "[EPOCH #12, step #1918] loss: 2.1318961185611367\n",
      "[EPOCH #12, step #1920] loss: 2.131836052737715\n",
      "[EPOCH #12, step #1922] loss: 2.1315140042277716\n",
      "[EPOCH #12, step #1924] loss: 2.1311731191114944\n",
      "[EPOCH #12, step #1926] loss: 2.131571199959526\n",
      "[EPOCH #12, step #1928] loss: 2.131556132100542\n",
      "[EPOCH #12, step #1930] loss: 2.131462809213513\n",
      "[EPOCH #12, step #1932] loss: 2.1313949954737916\n",
      "[EPOCH #12, step #1934] loss: 2.1313399054899387\n",
      "[EPOCH #12, step #1936] loss: 2.131021414027118\n",
      "[EPOCH #12, step #1938] loss: 2.130890464770419\n",
      "[EPOCH #12, step #1940] loss: 2.1309619640824966\n",
      "[EPOCH #12, step #1942] loss: 2.130560323005476\n",
      "[EPOCH #12, step #1944] loss: 2.130561122060741\n",
      "[EPOCH #12, step #1946] loss: 2.130275596026953\n",
      "[EPOCH #12, step #1948] loss: 2.130114402386884\n",
      "[EPOCH #12, step #1950] loss: 2.129904751103087\n",
      "[EPOCH #12, step #1952] loss: 2.129602328606648\n",
      "[EPOCH #12, step #1954] loss: 2.129279328063321\n",
      "[EPOCH #12, step #1956] loss: 2.1292267119208343\n",
      "[EPOCH #12, step #1958] loss: 2.129529288558707\n",
      "[EPOCH #12, step #1960] loss: 2.129792057391881\n",
      "[EPOCH #12, step #1962] loss: 2.129539015459516\n",
      "[EPOCH #12, step #1964] loss: 2.1290203329867685\n",
      "[EPOCH #12, step #1966] loss: 2.1293488781526118\n",
      "[EPOCH #12, step #1968] loss: 2.1294877030269452\n",
      "[EPOCH #12, step #1970] loss: 2.1295593013502145\n",
      "[EPOCH #12, step #1972] loss: 2.129397220860504\n",
      "[EPOCH #12, step #1974] loss: 2.1294511505320104\n",
      "[EPOCH #12, step #1976] loss: 2.129028877346095\n",
      "[EPOCH #12, step #1978] loss: 2.1290062278012183\n",
      "[EPOCH #12, step #1980] loss: 2.128945956983571\n",
      "[EPOCH #12, step #1982] loss: 2.1289119928459055\n",
      "[EPOCH #12, step #1984] loss: 2.1293049407545808\n",
      "[EPOCH #12, step #1986] loss: 2.1292356947407867\n",
      "[EPOCH #12, step #1988] loss: 2.1295594316202533\n",
      "[EPOCH #12, step #1990] loss: 2.1296247167242406\n",
      "[EPOCH #12, step #1992] loss: 2.129683648529091\n",
      "[EPOCH #12, step #1994] loss: 2.1297188856846705\n",
      "[EPOCH #12, step #1996] loss: 2.129572074832353\n",
      "[EPOCH #12, step #1998] loss: 2.1295861832913068\n",
      "[EPOCH #12, step #2000] loss: 2.129357820805879\n",
      "[EPOCH #12, step #2002] loss: 2.128920831325586\n",
      "[EPOCH #12, step #2004] loss: 2.1290878135961786\n",
      "[EPOCH #12, step #2006] loss: 2.1288842856735513\n",
      "[EPOCH #12, step #2008] loss: 2.128922451485918\n",
      "[EPOCH #12, step #2010] loss: 2.128233824364289\n",
      "[EPOCH #12, step #2012] loss: 2.127987132046392\n",
      "[EPOCH #12, step #2014] loss: 2.1276841157127553\n",
      "[EPOCH #12, step #2016] loss: 2.1273026399584056\n",
      "[EPOCH #12, step #2018] loss: 2.127277204280681\n",
      "[EPOCH #12, step #2020] loss: 2.1271508349928747\n",
      "[EPOCH #12, step #2022] loss: 2.1270972319422414\n",
      "[EPOCH #12, step #2024] loss: 2.127341286164743\n",
      "[EPOCH #12, step #2026] loss: 2.127118524742879\n",
      "[EPOCH #12, step #2028] loss: 2.12706370703865\n",
      "[EPOCH #12, step #2030] loss: 2.1269706993018507\n",
      "[EPOCH #12, step #2032] loss: 2.127041114238583\n",
      "[EPOCH #12, step #2034] loss: 2.1269322474992833\n",
      "[EPOCH #12, step #2036] loss: 2.1269468696432248\n",
      "[EPOCH #12, step #2038] loss: 2.126938655365911\n",
      "[EPOCH #12, step #2040] loss: 2.1270792641983145\n",
      "[EPOCH #12, step #2042] loss: 2.1270907631237836\n",
      "[EPOCH #12, step #2044] loss: 2.1270159724289166\n",
      "[EPOCH #12, step #2046] loss: 2.127238903443989\n",
      "[EPOCH #12, step #2048] loss: 2.127223698263229\n",
      "[EPOCH #12, step #2050] loss: 2.127143110431502\n",
      "[EPOCH #12, step #2052] loss: 2.1270528571290965\n",
      "[EPOCH #12, step #2054] loss: 2.1269695804646997\n",
      "[EPOCH #12, step #2056] loss: 2.127162661492158\n",
      "[EPOCH #12, step #2058] loss: 2.127166395919192\n",
      "[EPOCH #12, step #2060] loss: 2.12716641245624\n",
      "[EPOCH #12, step #2062] loss: 2.1268931870546033\n",
      "[EPOCH #12, step #2064] loss: 2.126986192098253\n",
      "[EPOCH #12, step #2066] loss: 2.126977311394096\n",
      "[EPOCH #12, step #2068] loss: 2.127092917452923\n",
      "[EPOCH #12, step #2070] loss: 2.1271978140107564\n",
      "[EPOCH #12, step #2072] loss: 2.1273614459145893\n",
      "[EPOCH #12, step #2074] loss: 2.127355427684554\n",
      "[EPOCH #12, step #2076] loss: 2.1274036779160332\n",
      "[EPOCH #12, step #2078] loss: 2.1273637241099306\n",
      "[EPOCH #12, step #2080] loss: 2.1272393124771485\n",
      "[EPOCH #12, step #2082] loss: 2.1269805175549585\n",
      "[EPOCH #12, step #2084] loss: 2.1272051716879976\n",
      "[EPOCH #12, step #2086] loss: 2.1271827974328597\n",
      "[EPOCH #12, step #2088] loss: 2.1273977702288263\n",
      "[EPOCH #12, step #2090] loss: 2.1274094718429586\n",
      "[EPOCH #12, step #2092] loss: 2.127485339173391\n",
      "[EPOCH #12, step #2094] loss: 2.127435379438013\n",
      "[EPOCH #12, step #2096] loss: 2.1275805631136406\n",
      "[EPOCH #12, step #2098] loss: 2.127802778278549\n",
      "[EPOCH #12, step #2100] loss: 2.127750566889705\n",
      "[EPOCH #12, step #2102] loss: 2.127255294076953\n",
      "[EPOCH #12, step #2104] loss: 2.1273000794181915\n",
      "[EPOCH #12, step #2106] loss: 2.127067268092767\n",
      "[EPOCH #12, step #2108] loss: 2.1274483154146746\n",
      "[EPOCH #12, step #2110] loss: 2.1275121116457476\n",
      "[EPOCH #12, step #2112] loss: 2.126972961753\n",
      "[EPOCH #12, step #2114] loss: 2.1268361823778625\n",
      "[EPOCH #12, step #2116] loss: 2.1268027110318277\n",
      "[EPOCH #12, step #2118] loss: 2.1269056718267323\n",
      "[EPOCH #12, step #2120] loss: 2.127061564930201\n",
      "[EPOCH #12, step #2122] loss: 2.126925176120961\n",
      "[EPOCH #12, step #2124] loss: 2.126845810104819\n",
      "[EPOCH #12, step #2126] loss: 2.127120904929211\n",
      "[EPOCH #12, step #2128] loss: 2.1270295155333936\n",
      "[EPOCH #12, step #2130] loss: 2.1270337068436014\n",
      "[EPOCH #12, step #2132] loss: 2.1269840875590735\n",
      "[EPOCH #12, step #2134] loss: 2.127085501137048\n",
      "[EPOCH #12, step #2136] loss: 2.1273797967470744\n",
      "[EPOCH #12, step #2138] loss: 2.127726079036611\n",
      "[EPOCH #12, step #2140] loss: 2.1277683639793628\n",
      "[EPOCH #12, step #2142] loss: 2.1277893176993308\n",
      "[EPOCH #12, step #2144] loss: 2.127521299037622\n",
      "[EPOCH #12, step #2146] loss: 2.1274957491399857\n",
      "[EPOCH #12, step #2148] loss: 2.1274916568763205\n",
      "[EPOCH #12, step #2150] loss: 2.1272328775575247\n",
      "[EPOCH #12, step #2152] loss: 2.127285787796786\n",
      "[EPOCH #12, step #2154] loss: 2.1272750202851616\n",
      "[EPOCH #12, step #2156] loss: 2.1270713092665128\n",
      "[EPOCH #12, step #2158] loss: 2.126992639649406\n",
      "[EPOCH #12, step #2160] loss: 2.1269804642521524\n",
      "[EPOCH #12, step #2162] loss: 2.1268687844551994\n",
      "[EPOCH #12, step #2164] loss: 2.1266389417868563\n",
      "[EPOCH #12, step #2166] loss: 2.126523383542806\n",
      "[EPOCH #12, step #2168] loss: 2.127039374762166\n",
      "[EPOCH #12, step #2170] loss: 2.126823277860015\n",
      "[EPOCH #12, step #2172] loss: 2.126695669525733\n",
      "[EPOCH #12, step #2174] loss: 2.1267292212891853\n",
      "[EPOCH #12, step #2176] loss: 2.126599945329886\n",
      "[EPOCH #12, step #2178] loss: 2.1263380092237454\n",
      "[EPOCH #12, step #2180] loss: 2.1263580836598233\n",
      "[EPOCH #12, step #2182] loss: 2.126191178429744\n",
      "[EPOCH #12, step #2184] loss: 2.1261489837065985\n",
      "[EPOCH #12, step #2186] loss: 2.1259527744416182\n",
      "[EPOCH #12, step #2188] loss: 2.125900526088141\n",
      "[EPOCH #12, step #2190] loss: 2.1260844145883224\n",
      "[EPOCH #12, step #2192] loss: 2.126082272329561\n",
      "[EPOCH #12, step #2194] loss: 2.1257503425341806\n",
      "[EPOCH #12, step #2196] loss: 2.1257352695499816\n",
      "[EPOCH #12, step #2198] loss: 2.1255041085464836\n",
      "[EPOCH #12, step #2200] loss: 2.125466064126423\n",
      "[EPOCH #12, step #2202] loss: 2.125926580420419\n",
      "[EPOCH #12, step #2204] loss: 2.125667520066778\n",
      "[EPOCH #12, step #2206] loss: 2.1251899810954353\n",
      "[EPOCH #12, step #2208] loss: 2.125072106941624\n",
      "[EPOCH #12, step #2210] loss: 2.1250811636259197\n",
      "[EPOCH #12, step #2212] loss: 2.125324006054771\n",
      "[EPOCH #12, step #2214] loss: 2.125414947408586\n",
      "[EPOCH #12, step #2216] loss: 2.1255204863090156\n",
      "[EPOCH #12, step #2218] loss: 2.1253988526328396\n",
      "[EPOCH #12, step #2220] loss: 2.1253723968851945\n",
      "[EPOCH #12, step #2222] loss: 2.1256618748041514\n",
      "[EPOCH #12, step #2224] loss: 2.125914729311225\n",
      "[EPOCH #12, step #2226] loss: 2.125884930810213\n",
      "[EPOCH #12, step #2228] loss: 2.126148119481918\n",
      "[EPOCH #12, step #2230] loss: 2.1260539754417005\n",
      "[EPOCH #12, step #2232] loss: 2.126149198691833\n",
      "[EPOCH #12, step #2234] loss: 2.125999633897871\n",
      "[EPOCH #12, step #2236] loss: 2.125998649684563\n",
      "[EPOCH #12, step #2238] loss: 2.125911231762919\n",
      "[EPOCH #12, step #2240] loss: 2.126043490457088\n",
      "[EPOCH #12, step #2242] loss: 2.12576933168589\n",
      "[EPOCH #12, step #2244] loss: 2.1255316644044124\n",
      "[EPOCH #12, step #2246] loss: 2.1252849064883415\n",
      "[EPOCH #12, step #2248] loss: 2.125226597088398\n",
      "[EPOCH #12, step #2250] loss: 2.1249328173303117\n",
      "[EPOCH #12, step #2252] loss: 2.1247246735264236\n",
      "[EPOCH #12, step #2254] loss: 2.1246641680300895\n",
      "[EPOCH #12, step #2256] loss: 2.1244331369581717\n",
      "[EPOCH #12, step #2258] loss: 2.124466299219119\n",
      "[EPOCH #12, step #2260] loss: 2.1247550833810487\n",
      "[EPOCH #12, step #2262] loss: 2.1244497153804307\n",
      "[EPOCH #12, step #2264] loss: 2.124608829216189\n",
      "[EPOCH #12, step #2266] loss: 2.1246416762267435\n",
      "[EPOCH #12, step #2268] loss: 2.1246616220411196\n",
      "[EPOCH #12, step #2270] loss: 2.125030526606746\n",
      "[EPOCH #12, step #2272] loss: 2.125118668573416\n",
      "[EPOCH #12, step #2274] loss: 2.1251923703623343\n",
      "[EPOCH #12, step #2276] loss: 2.125331020062044\n",
      "[EPOCH #12, step #2278] loss: 2.125569288748406\n",
      "[EPOCH #12, step #2280] loss: 2.1255804248568992\n",
      "[EPOCH #12, step #2282] loss: 2.1256148184384895\n",
      "[EPOCH #12, step #2284] loss: 2.125754810162133\n",
      "[EPOCH #12, step #2286] loss: 2.125783081288206\n",
      "[EPOCH #12, step #2288] loss: 2.1256073536233333\n",
      "[EPOCH #12, step #2290] loss: 2.1257425027349433\n",
      "[EPOCH #12, step #2292] loss: 2.125776037138412\n",
      "[EPOCH #12, step #2294] loss: 2.125777533007603\n",
      "[EPOCH #12, step #2296] loss: 2.125576713887515\n",
      "[EPOCH #12, step #2298] loss: 2.1255873331768504\n",
      "[EPOCH #12, step #2300] loss: 2.1255238381534594\n",
      "[EPOCH #12, step #2302] loss: 2.1250307041305696\n",
      "[EPOCH #12, step #2304] loss: 2.1252909090410346\n",
      "[EPOCH #12, step #2306] loss: 2.1251085897932644\n",
      "[EPOCH #12, step #2308] loss: 2.1250567288561886\n",
      "[EPOCH #12, step #2310] loss: 2.1248781210619976\n",
      "[EPOCH #12, step #2312] loss: 2.124819121987491\n",
      "[EPOCH #12, step #2314] loss: 2.124867951020309\n",
      "[EPOCH #12, step #2316] loss: 2.124700997582684\n",
      "[EPOCH #12, step #2318] loss: 2.1248400876521036\n",
      "[EPOCH #12, step #2320] loss: 2.1249988420622867\n",
      "[EPOCH #12, step #2322] loss: 2.1246790424585855\n",
      "[EPOCH #12, step #2324] loss: 2.1246634838657994\n",
      "[EPOCH #12, step #2326] loss: 2.124339319576662\n",
      "[EPOCH #12, step #2328] loss: 2.124325656952291\n",
      "[EPOCH #12, step #2330] loss: 2.1239110827701686\n",
      "[EPOCH #12, step #2332] loss: 2.123956582447106\n",
      "[EPOCH #12, step #2334] loss: 2.123712868966178\n",
      "[EPOCH #12, step #2336] loss: 2.1239544805625488\n",
      "[EPOCH #12, step #2338] loss: 2.12422245728149\n",
      "[EPOCH #12, step #2340] loss: 2.123943301613949\n",
      "[EPOCH #12, step #2342] loss: 2.1239212030434373\n",
      "[EPOCH #12, step #2344] loss: 2.123671283752425\n",
      "[EPOCH #12, step #2346] loss: 2.1236875850086676\n",
      "[EPOCH #12, step #2348] loss: 2.1235979405703977\n",
      "[EPOCH #12, step #2350] loss: 2.1234636835623983\n",
      "[EPOCH #12, step #2352] loss: 2.1233151620162887\n",
      "[EPOCH #12, step #2354] loss: 2.1232696808067857\n",
      "[EPOCH #12, step #2356] loss: 2.1230998204125657\n",
      "[EPOCH #12, step #2358] loss: 2.1228746842307125\n",
      "[EPOCH #12, step #2360] loss: 2.1229728571897035\n",
      "[EPOCH #12, step #2362] loss: 2.1230994245534824\n",
      "[EPOCH #12, step #2364] loss: 2.1231642880349026\n",
      "[EPOCH #12, step #2366] loss: 2.1231636332216572\n",
      "[EPOCH #12, step #2368] loss: 2.1231931507360993\n",
      "[EPOCH #12, step #2370] loss: 2.1235298935947715\n",
      "[EPOCH #12, step #2372] loss: 2.123443332293141\n",
      "[EPOCH #12, step #2374] loss: 2.12335044996362\n",
      "[EPOCH #12, step #2376] loss: 2.123316456050897\n",
      "[EPOCH #12, step #2378] loss: 2.123394796005464\n",
      "[EPOCH #12, step #2380] loss: 2.123472480952164\n",
      "[EPOCH #12, step #2382] loss: 2.1233776244004634\n",
      "[EPOCH #12, step #2384] loss: 2.123364824169087\n",
      "[EPOCH #12, step #2386] loss: 2.1236799464946916\n",
      "[EPOCH #12, step #2388] loss: 2.123923811217939\n",
      "[EPOCH #12, step #2390] loss: 2.1238452323756425\n",
      "[EPOCH #12, step #2392] loss: 2.1238920882412744\n",
      "[EPOCH #12, step #2394] loss: 2.1239323094891605\n",
      "[EPOCH #12, step #2396] loss: 2.1237911577765822\n",
      "[EPOCH #12, step #2398] loss: 2.1236178506757377\n",
      "[EPOCH #12, step #2400] loss: 2.1234376248296525\n",
      "[EPOCH #12, step #2402] loss: 2.1233223412764155\n",
      "[EPOCH #12, step #2404] loss: 2.123370434935524\n",
      "[EPOCH #12, step #2406] loss: 2.123399513164991\n",
      "[EPOCH #12, step #2408] loss: 2.1231240442354387\n",
      "[EPOCH #12, step #2410] loss: 2.1231872959287275\n",
      "[EPOCH #12, step #2412] loss: 2.1230685580483226\n",
      "[EPOCH #12, step #2414] loss: 2.122625834502542\n",
      "[EPOCH #12, step #2416] loss: 2.1226984168262977\n",
      "[EPOCH #12, step #2418] loss: 2.122443882824715\n",
      "[EPOCH #12, step #2420] loss: 2.122400234229109\n",
      "[EPOCH #12, step #2422] loss: 2.122344320291731\n",
      "[EPOCH #12, step #2424] loss: 2.1220846158450413\n",
      "[EPOCH #12, step #2426] loss: 2.122016303766201\n",
      "[EPOCH #12, step #2428] loss: 2.1218448165710595\n",
      "[EPOCH #12, step #2430] loss: 2.1220054863314233\n",
      "[EPOCH #12, step #2432] loss: 2.122090647605727\n",
      "[EPOCH #12, step #2434] loss: 2.122367829953376\n",
      "[EPOCH #12, step #2436] loss: 2.1223392027736345\n",
      "[EPOCH #12, step #2438] loss: 2.1224973021886933\n",
      "[EPOCH #12, step #2440] loss: 2.1221265121836588\n",
      "[EPOCH #12, step #2442] loss: 2.122006858024644\n",
      "[EPOCH #12, step #2444] loss: 2.122131892849819\n",
      "[EPOCH #12, step #2446] loss: 2.1221873300339573\n",
      "[EPOCH #12, step #2448] loss: 2.1221779629667226\n",
      "[EPOCH #12, step #2450] loss: 2.1221760025514675\n",
      "[EPOCH #12, step #2452] loss: 2.1220600781419354\n",
      "[EPOCH #12, step #2454] loss: 2.1222971425279824\n",
      "[EPOCH #12, step #2456] loss: 2.122405697234918\n",
      "[EPOCH #12, step #2458] loss: 2.122498450845468\n",
      "[EPOCH #12, step #2460] loss: 2.1224782229051122\n",
      "[EPOCH #12, step #2462] loss: 2.1223508887691707\n",
      "[EPOCH #12, step #2464] loss: 2.1222792950411598\n",
      "[EPOCH #12, step #2466] loss: 2.122022142765925\n",
      "[EPOCH #12, step #2468] loss: 2.121743761464718\n",
      "[EPOCH #12, step #2470] loss: 2.1215506947412033\n",
      "[EPOCH #12, step #2472] loss: 2.1216141932221784\n",
      "[EPOCH #12, step #2474] loss: 2.121574278214965\n",
      "[EPOCH #12, step #2476] loss: 2.1217689107491404\n",
      "[EPOCH #12, step #2478] loss: 2.12153553255819\n",
      "[EPOCH #12, step #2480] loss: 2.1212308244424594\n",
      "[EPOCH #12, step #2482] loss: 2.120927816622208\n",
      "[EPOCH #12, step #2484] loss: 2.1210138953187814\n",
      "[EPOCH #12, step #2486] loss: 2.1210130781929895\n",
      "[EPOCH #12, step #2488] loss: 2.120965149279051\n",
      "[EPOCH #12, step #2490] loss: 2.1207583800993115\n",
      "[EPOCH #12, step #2492] loss: 2.1208450239057575\n",
      "[EPOCH #12, step #2494] loss: 2.1209892220392015\n",
      "[EPOCH #12, step #2496] loss: 2.120743333028229\n",
      "[EPOCH #12, step #2498] loss: 2.120563777316423\n",
      "[EPOCH #12, elapsed time: 6120.160[sec]] loss: 2.120539892435074\n",
      "[EPOCH #13, step #0] loss: 1.864298701286316\n",
      "[EPOCH #13, step #2] loss: 1.9433444738388062\n",
      "[EPOCH #13, step #4] loss: 1.951875352859497\n",
      "[EPOCH #13, step #6] loss: 2.064830643790109\n",
      "[EPOCH #13, step #8] loss: 1.997047675980462\n",
      "[EPOCH #13, step #10] loss: 2.0389268073168667\n",
      "[EPOCH #13, step #12] loss: 1.9726886382469764\n",
      "[EPOCH #13, step #14] loss: 1.9590601603190103\n",
      "[EPOCH #13, step #16] loss: 1.9630922219332527\n",
      "[EPOCH #13, step #18] loss: 1.9741328954696655\n",
      "[EPOCH #13, step #20] loss: 2.011641087986174\n",
      "[EPOCH #13, step #22] loss: 2.0259664162345556\n",
      "[EPOCH #13, step #24] loss: 2.019050831794739\n",
      "[EPOCH #13, step #26] loss: 2.020411411921183\n",
      "[EPOCH #13, step #28] loss: 2.0104953626106523\n",
      "[EPOCH #13, step #30] loss: 2.0218800152501752\n",
      "[EPOCH #13, step #32] loss: 2.040095470168374\n",
      "[EPOCH #13, step #34] loss: 2.0356525012425015\n",
      "[EPOCH #13, step #36] loss: 2.0516877883189433\n",
      "[EPOCH #13, step #38] loss: 2.03490136219905\n",
      "[EPOCH #13, step #40] loss: 2.042761817211058\n",
      "[EPOCH #13, step #42] loss: 2.0321977831596554\n",
      "[EPOCH #13, step #44] loss: 2.02234677473704\n",
      "[EPOCH #13, step #46] loss: 2.022988461433573\n",
      "[EPOCH #13, step #48] loss: 2.0235168641927292\n",
      "[EPOCH #13, step #50] loss: 2.023738430995567\n",
      "[EPOCH #13, step #52] loss: 2.010741942333725\n",
      "[EPOCH #13, step #54] loss: 2.0086991851980036\n",
      "[EPOCH #13, step #56] loss: 2.0111923656965556\n",
      "[EPOCH #13, step #58] loss: 2.0167311227927773\n",
      "[EPOCH #13, step #60] loss: 2.019476376596044\n",
      "[EPOCH #13, step #62] loss: 2.0108706326711747\n",
      "[EPOCH #13, step #64] loss: 2.0145254868727465\n",
      "[EPOCH #13, step #66] loss: 2.012598397126838\n",
      "[EPOCH #13, step #68] loss: 2.016173784283624\n",
      "[EPOCH #13, step #70] loss: 2.011922277195353\n",
      "[EPOCH #13, step #72] loss: 2.0221736055530912\n",
      "[EPOCH #13, step #74] loss: 2.0193002049128213\n",
      "[EPOCH #13, step #76] loss: 2.0100047944428083\n",
      "[EPOCH #13, step #78] loss: 2.008373693574833\n",
      "[EPOCH #13, step #80] loss: 2.005284302028609\n",
      "[EPOCH #13, step #82] loss: 2.0144445508359428\n",
      "[EPOCH #13, step #84] loss: 2.0151786299312815\n",
      "[EPOCH #13, step #86] loss: 2.0226947384319085\n",
      "[EPOCH #13, step #88] loss: 2.0203763407267883\n",
      "[EPOCH #13, step #90] loss: 2.016417914694482\n",
      "[EPOCH #13, step #92] loss: 2.0241710524405203\n",
      "[EPOCH #13, step #94] loss: 2.0241868483392818\n",
      "[EPOCH #13, step #96] loss: 2.020508503176502\n",
      "[EPOCH #13, step #98] loss: 2.013878836776271\n",
      "[EPOCH #13, step #100] loss: 2.011176915452032\n",
      "[EPOCH #13, step #102] loss: 2.0103107158420155\n",
      "[EPOCH #13, step #104] loss: 2.011045409384228\n",
      "[EPOCH #13, step #106] loss: 2.012561395903614\n",
      "[EPOCH #13, step #108] loss: 2.016939381940649\n",
      "[EPOCH #13, step #110] loss: 2.0085977380340165\n",
      "[EPOCH #13, step #112] loss: 2.0074423382767534\n",
      "[EPOCH #13, step #114] loss: 2.009926322232122\n",
      "[EPOCH #13, step #116] loss: 2.0068143595997086\n",
      "[EPOCH #13, step #118] loss: 2.0012900007873022\n",
      "[EPOCH #13, step #120] loss: 2.00195066199815\n",
      "[EPOCH #13, step #122] loss: 2.002093931523765\n",
      "[EPOCH #13, step #124] loss: 2.0060787830352784\n",
      "[EPOCH #13, step #126] loss: 2.0058693397702196\n",
      "[EPOCH #13, step #128] loss: 2.0089403178340706\n",
      "[EPOCH #13, step #130] loss: 2.00651740026838\n",
      "[EPOCH #13, step #132] loss: 2.0098370367423035\n",
      "[EPOCH #13, step #134] loss: 2.0101808927677296\n",
      "[EPOCH #13, step #136] loss: 2.0138202870849273\n",
      "[EPOCH #13, step #138] loss: 2.01536411261387\n",
      "[EPOCH #13, step #140] loss: 2.0185207432888923\n",
      "[EPOCH #13, step #142] loss: 2.0178526556575216\n",
      "[EPOCH #13, step #144] loss: 2.0183854505933563\n",
      "[EPOCH #13, step #146] loss: 2.022743024793612\n",
      "[EPOCH #13, step #148] loss: 2.0223509393282386\n",
      "[EPOCH #13, step #150] loss: 2.0254692186582957\n",
      "[EPOCH #13, step #152] loss: 2.025634704072491\n",
      "[EPOCH #13, step #154] loss: 2.0260001436356574\n",
      "[EPOCH #13, step #156] loss: 2.024089700097491\n",
      "[EPOCH #13, step #158] loss: 2.0252669749769776\n",
      "[EPOCH #13, step #160] loss: 2.027267344249702\n",
      "[EPOCH #13, step #162] loss: 2.02761875705485\n",
      "[EPOCH #13, step #164] loss: 2.0266869653354993\n",
      "[EPOCH #13, step #166] loss: 2.0304497665987755\n",
      "[EPOCH #13, step #168] loss: 2.029115322073536\n",
      "[EPOCH #13, step #170] loss: 2.02699821804002\n",
      "[EPOCH #13, step #172] loss: 2.0268533491674874\n",
      "[EPOCH #13, step #174] loss: 2.0310107272011892\n",
      "[EPOCH #13, step #176] loss: 2.0279408531673884\n",
      "[EPOCH #13, step #178] loss: 2.0326776138231075\n",
      "[EPOCH #13, step #180] loss: 2.035550768862772\n",
      "[EPOCH #13, step #182] loss: 2.0372082216492116\n",
      "[EPOCH #13, step #184] loss: 2.0374121814160735\n",
      "[EPOCH #13, step #186] loss: 2.03941205032369\n",
      "[EPOCH #13, step #188] loss: 2.0410733342801453\n",
      "[EPOCH #13, step #190] loss: 2.03996909600902\n",
      "[EPOCH #13, step #192] loss: 2.042527284029234\n",
      "[EPOCH #13, step #194] loss: 2.041000652924562\n",
      "[EPOCH #13, step #196] loss: 2.0388988353274193\n",
      "[EPOCH #13, step #198] loss: 2.038910835232567\n",
      "[EPOCH #13, step #200] loss: 2.040602153213463\n",
      "[EPOCH #13, step #202] loss: 2.0393311149381064\n",
      "[EPOCH #13, step #204] loss: 2.0414221327479294\n",
      "[EPOCH #13, step #206] loss: 2.0387964381111994\n",
      "[EPOCH #13, step #208] loss: 2.0380227845251273\n",
      "[EPOCH #13, step #210] loss: 2.036361129363001\n",
      "[EPOCH #13, step #212] loss: 2.0353521254141005\n",
      "[EPOCH #13, step #214] loss: 2.0325579371563225\n",
      "[EPOCH #13, step #216] loss: 2.0324282574763495\n",
      "[EPOCH #13, step #218] loss: 2.0301422621017178\n",
      "[EPOCH #13, step #220] loss: 2.02828869560725\n",
      "[EPOCH #13, step #222] loss: 2.0251390634630826\n",
      "[EPOCH #13, step #224] loss: 2.0259825446870594\n",
      "[EPOCH #13, step #226] loss: 2.02391110590376\n",
      "[EPOCH #13, step #228] loss: 2.0241389852423857\n",
      "[EPOCH #13, step #230] loss: 2.0238029657504257\n",
      "[EPOCH #13, step #232] loss: 2.024814876875652\n",
      "[EPOCH #13, step #234] loss: 2.023908144869703\n",
      "[EPOCH #13, step #236] loss: 2.0230993238682484\n",
      "[EPOCH #13, step #238] loss: 2.0240817708450383\n",
      "[EPOCH #13, step #240] loss: 2.022205477928225\n",
      "[EPOCH #13, step #242] loss: 2.020044537728706\n",
      "[EPOCH #13, step #244] loss: 2.02048683799043\n",
      "[EPOCH #13, step #246] loss: 2.0223313541064862\n",
      "[EPOCH #13, step #248] loss: 2.0209790142664468\n",
      "[EPOCH #13, step #250] loss: 2.0183993041277883\n",
      "[EPOCH #13, step #252] loss: 2.017519515022459\n",
      "[EPOCH #13, step #254] loss: 2.01685075526144\n",
      "[EPOCH #13, step #256] loss: 2.0176892558888238\n",
      "[EPOCH #13, step #258] loss: 2.020081667366175\n",
      "[EPOCH #13, step #260] loss: 2.0211050318575454\n",
      "[EPOCH #13, step #262] loss: 2.02119429301853\n",
      "[EPOCH #13, step #264] loss: 2.0205960845047573\n",
      "[EPOCH #13, step #266] loss: 2.022187257527412\n",
      "[EPOCH #13, step #268] loss: 2.0234177586757562\n",
      "[EPOCH #13, step #270] loss: 2.024816558369851\n",
      "[EPOCH #13, step #272] loss: 2.0251006053917573\n",
      "[EPOCH #13, step #274] loss: 2.025907083858143\n",
      "[EPOCH #13, step #276] loss: 2.026625053977278\n",
      "[EPOCH #13, step #278] loss: 2.024575540241802\n",
      "[EPOCH #13, step #280] loss: 2.024754682893855\n",
      "[EPOCH #13, step #282] loss: 2.0243183403891303\n",
      "[EPOCH #13, step #284] loss: 2.022997469232793\n",
      "[EPOCH #13, step #286] loss: 2.0223708040622883\n",
      "[EPOCH #13, step #288] loss: 2.0232316643309014\n",
      "[EPOCH #13, step #290] loss: 2.0233944822422827\n",
      "[EPOCH #13, step #292] loss: 2.022763047608906\n",
      "[EPOCH #13, step #294] loss: 2.0211687043561772\n",
      "[EPOCH #13, step #296] loss: 2.023942798476428\n",
      "[EPOCH #13, step #298] loss: 2.024215661163713\n",
      "[EPOCH #13, step #300] loss: 2.021729659400509\n",
      "[EPOCH #13, step #302] loss: 2.0211501444133595\n",
      "[EPOCH #13, step #304] loss: 2.0199119806289674\n",
      "[EPOCH #13, step #306] loss: 2.0204405936045444\n",
      "[EPOCH #13, step #308] loss: 2.0225707678347344\n",
      "[EPOCH #13, step #310] loss: 2.0211318570317944\n",
      "[EPOCH #13, step #312] loss: 2.02152784716207\n",
      "[EPOCH #13, step #314] loss: 2.02072858848269\n",
      "[EPOCH #13, step #316] loss: 2.0206827083220618\n",
      "[EPOCH #13, step #318] loss: 2.019833473202577\n",
      "[EPOCH #13, step #320] loss: 2.020808651811237\n",
      "[EPOCH #13, step #322] loss: 2.018685966453316\n",
      "[EPOCH #13, step #324] loss: 2.0178813853630655\n",
      "[EPOCH #13, step #326] loss: 2.0151046715016028\n",
      "[EPOCH #13, step #328] loss: 2.01454892383158\n",
      "[EPOCH #13, step #330] loss: 2.016292893634462\n",
      "[EPOCH #13, step #332] loss: 2.0181553109630093\n",
      "[EPOCH #13, step #334] loss: 2.01824135637995\n",
      "[EPOCH #13, step #336] loss: 2.0175064678361934\n",
      "[EPOCH #13, step #338] loss: 2.0150008641161397\n",
      "[EPOCH #13, step #340] loss: 2.0150002671127094\n",
      "[EPOCH #13, step #342] loss: 2.0152679879880857\n",
      "[EPOCH #13, step #344] loss: 2.0167836997819983\n",
      "[EPOCH #13, step #346] loss: 2.0177848971199235\n",
      "[EPOCH #13, step #348] loss: 2.017929680709511\n",
      "[EPOCH #13, step #350] loss: 2.0192732277758783\n",
      "[EPOCH #13, step #352] loss: 2.0206628774448427\n",
      "[EPOCH #13, step #354] loss: 2.020975670680194\n",
      "[EPOCH #13, step #356] loss: 2.01946972364805\n",
      "[EPOCH #13, step #358] loss: 2.023050303910768\n",
      "[EPOCH #13, step #360] loss: 2.022531226401184\n",
      "[EPOCH #13, step #362] loss: 2.022818099368702\n",
      "[EPOCH #13, step #364] loss: 2.0216558178810224\n",
      "[EPOCH #13, step #366] loss: 2.020771176678608\n",
      "[EPOCH #13, step #368] loss: 2.0229339218398095\n",
      "[EPOCH #13, step #370] loss: 2.021964912465962\n",
      "[EPOCH #13, step #372] loss: 2.0200028055155244\n",
      "[EPOCH #13, step #374] loss: 2.021333744366964\n",
      "[EPOCH #13, step #376] loss: 2.0209540568232853\n",
      "[EPOCH #13, step #378] loss: 2.02007707568146\n",
      "[EPOCH #13, step #380] loss: 2.0193380270730166\n",
      "[EPOCH #13, step #382] loss: 2.0174603465331753\n",
      "[EPOCH #13, step #384] loss: 2.0180385574117885\n",
      "[EPOCH #13, step #386] loss: 2.0185800310253175\n",
      "[EPOCH #13, step #388] loss: 2.0170361450214926\n",
      "[EPOCH #13, step #390] loss: 2.020080284694272\n",
      "[EPOCH #13, step #392] loss: 2.0197731735748796\n",
      "[EPOCH #13, step #394] loss: 2.0174580181701276\n",
      "[EPOCH #13, step #396] loss: 2.0155435206007297\n",
      "[EPOCH #13, step #398] loss: 2.01919358505641\n",
      "[EPOCH #13, step #400] loss: 2.0181256375110657\n",
      "[EPOCH #13, step #402] loss: 2.016276878991139\n",
      "[EPOCH #13, step #404] loss: 2.0160713534296293\n",
      "[EPOCH #13, step #406] loss: 2.0165108055681795\n",
      "[EPOCH #13, step #408] loss: 2.0161794327873475\n",
      "[EPOCH #13, step #410] loss: 2.016376803391171\n",
      "[EPOCH #13, step #412] loss: 2.016692242379916\n",
      "[EPOCH #13, step #414] loss: 2.0164808764515154\n",
      "[EPOCH #13, step #416] loss: 2.0163555022338024\n",
      "[EPOCH #13, step #418] loss: 2.015355708490977\n",
      "[EPOCH #13, step #420] loss: 2.0155609206179257\n",
      "[EPOCH #13, step #422] loss: 2.0151150838139493\n",
      "[EPOCH #13, step #424] loss: 2.0150012582891126\n",
      "[EPOCH #13, step #426] loss: 2.016339237293538\n",
      "[EPOCH #13, step #428] loss: 2.0176020841220597\n",
      "[EPOCH #13, step #430] loss: 2.0171097951256205\n",
      "[EPOCH #13, step #432] loss: 2.016633289515559\n",
      "[EPOCH #13, step #434] loss: 2.015746883140213\n",
      "[EPOCH #13, step #436] loss: 2.0166724110086123\n",
      "[EPOCH #13, step #438] loss: 2.0151527726297225\n",
      "[EPOCH #13, step #440] loss: 2.0144978886018263\n",
      "[EPOCH #13, step #442] loss: 2.01409891415934\n",
      "[EPOCH #13, step #444] loss: 2.0135589401373704\n",
      "[EPOCH #13, step #446] loss: 2.012778474713865\n",
      "[EPOCH #13, step #448] loss: 2.0128441488822477\n",
      "[EPOCH #13, step #450] loss: 2.0135243155739526\n",
      "[EPOCH #13, step #452] loss: 2.0143092689135216\n",
      "[EPOCH #13, step #454] loss: 2.0139764547348022\n",
      "[EPOCH #13, step #456] loss: 2.013385630801679\n",
      "[EPOCH #13, step #458] loss: 2.012828053991779\n",
      "[EPOCH #13, step #460] loss: 2.011618642382922\n",
      "[EPOCH #13, step #462] loss: 2.010940041191892\n",
      "[EPOCH #13, step #464] loss: 2.012331472673724\n",
      "[EPOCH #13, step #466] loss: 2.012349091454287\n",
      "[EPOCH #13, step #468] loss: 2.0128525777666297\n",
      "[EPOCH #13, step #470] loss: 2.011910480298814\n",
      "[EPOCH #13, step #472] loss: 2.011874266457104\n",
      "[EPOCH #13, step #474] loss: 2.010796174250151\n",
      "[EPOCH #13, step #476] loss: 2.010970228872959\n",
      "[EPOCH #13, step #478] loss: 2.009959692497094\n",
      "[EPOCH #13, step #480] loss: 2.0104816116067328\n",
      "[EPOCH #13, step #482] loss: 2.011798690564884\n",
      "[EPOCH #13, step #484] loss: 2.011816514398634\n",
      "[EPOCH #13, step #486] loss: 2.011156329139302\n",
      "[EPOCH #13, step #488] loss: 2.009673550816401\n",
      "[EPOCH #13, step #490] loss: 2.0096960028902817\n",
      "[EPOCH #13, step #492] loss: 2.0105989085733285\n",
      "[EPOCH #13, step #494] loss: 2.010377134217156\n",
      "[EPOCH #13, step #496] loss: 2.008651151983311\n",
      "[EPOCH #13, step #498] loss: 2.0081845954329314\n",
      "[EPOCH #13, step #500] loss: 2.009093102818716\n",
      "[EPOCH #13, step #502] loss: 2.0075436970348624\n",
      "[EPOCH #13, step #504] loss: 2.0084547760462996\n",
      "[EPOCH #13, step #506] loss: 2.0089152856221095\n",
      "[EPOCH #13, step #508] loss: 2.008491169961356\n",
      "[EPOCH #13, step #510] loss: 2.0084970172370715\n",
      "[EPOCH #13, step #512] loss: 2.0100224866272183\n",
      "[EPOCH #13, step #514] loss: 2.0101475102230184\n",
      "[EPOCH #13, step #516] loss: 2.0098280772941486\n",
      "[EPOCH #13, step #518] loss: 2.010684689575078\n",
      "[EPOCH #13, step #520] loss: 2.0104081623842527\n",
      "[EPOCH #13, step #522] loss: 2.0112575379202062\n",
      "[EPOCH #13, step #524] loss: 2.0126775943665276\n",
      "[EPOCH #13, step #526] loss: 2.012724756063501\n",
      "[EPOCH #13, step #528] loss: 2.0131480328752773\n",
      "[EPOCH #13, step #530] loss: 2.013168017518498\n",
      "[EPOCH #13, step #532] loss: 2.0133593344106906\n",
      "[EPOCH #13, step #534] loss: 2.013261444546352\n",
      "[EPOCH #13, step #536] loss: 2.0145418965838697\n",
      "[EPOCH #13, step #538] loss: 2.0156932047435214\n",
      "[EPOCH #13, step #540] loss: 2.016020132962084\n",
      "[EPOCH #13, step #542] loss: 2.015406855342577\n",
      "[EPOCH #13, step #544] loss: 2.0146174866125124\n",
      "[EPOCH #13, step #546] loss: 2.0136557900273604\n",
      "[EPOCH #13, step #548] loss: 2.0142053732672243\n",
      "[EPOCH #13, step #550] loss: 2.013771725003819\n",
      "[EPOCH #13, step #552] loss: 2.012778885756867\n",
      "[EPOCH #13, step #554] loss: 2.0134288401217075\n",
      "[EPOCH #13, step #556] loss: 2.012701158677654\n",
      "[EPOCH #13, step #558] loss: 2.01307845414218\n",
      "[EPOCH #13, step #560] loss: 2.012242700326889\n",
      "[EPOCH #13, step #562] loss: 2.0119553590540775\n",
      "[EPOCH #13, step #564] loss: 2.0130120302723573\n",
      "[EPOCH #13, step #566] loss: 2.012399043565915\n",
      "[EPOCH #13, step #568] loss: 2.013033114124895\n",
      "[EPOCH #13, step #570] loss: 2.013463399247405\n",
      "[EPOCH #13, step #572] loss: 2.013084313632306\n",
      "[EPOCH #13, step #574] loss: 2.0135068551353785\n",
      "[EPOCH #13, step #576] loss: 2.014400067940948\n",
      "[EPOCH #13, step #578] loss: 2.014405091397709\n",
      "[EPOCH #13, step #580] loss: 2.014542093991002\n",
      "[EPOCH #13, step #582] loss: 2.0140123997094497\n",
      "[EPOCH #13, step #584] loss: 2.013131287159064\n",
      "[EPOCH #13, step #586] loss: 2.0138777065926963\n",
      "[EPOCH #13, step #588] loss: 2.01366056954719\n",
      "[EPOCH #13, step #590] loss: 2.014738040325404\n",
      "[EPOCH #13, step #592] loss: 2.0145517625856963\n",
      "[EPOCH #13, step #594] loss: 2.0145929516864425\n",
      "[EPOCH #13, step #596] loss: 2.015599466448453\n",
      "[EPOCH #13, step #598] loss: 2.016576879211579\n",
      "[EPOCH #13, step #600] loss: 2.017613298286019\n",
      "[EPOCH #13, step #602] loss: 2.016416669287294\n",
      "[EPOCH #13, step #604] loss: 2.017147746953097\n",
      "[EPOCH #13, step #606] loss: 2.017867457336413\n",
      "[EPOCH #13, step #608] loss: 2.0171805461639254\n",
      "[EPOCH #13, step #610] loss: 2.0163369623611875\n",
      "[EPOCH #13, step #612] loss: 2.016646233507315\n",
      "[EPOCH #13, step #614] loss: 2.0171245388868377\n",
      "[EPOCH #13, step #616] loss: 2.0170747306397128\n",
      "[EPOCH #13, step #618] loss: 2.018875367807071\n",
      "[EPOCH #13, step #620] loss: 2.018443797329582\n",
      "[EPOCH #13, step #622] loss: 2.018057588589517\n",
      "[EPOCH #13, step #624] loss: 2.0178621337890625\n",
      "[EPOCH #13, step #626] loss: 2.0178995375808157\n",
      "[EPOCH #13, step #628] loss: 2.017054519327343\n",
      "[EPOCH #13, step #630] loss: 2.0180136777708535\n",
      "[EPOCH #13, step #632] loss: 2.0174245807985183\n",
      "[EPOCH #13, step #634] loss: 2.0173595518577754\n",
      "[EPOCH #13, step #636] loss: 2.0171099276145923\n",
      "[EPOCH #13, step #638] loss: 2.016579232865096\n",
      "[EPOCH #13, step #640] loss: 2.0164605857057616\n",
      "[EPOCH #13, step #642] loss: 2.0162475196236214\n",
      "[EPOCH #13, step #644] loss: 2.015209078049475\n",
      "[EPOCH #13, step #646] loss: 2.0142581227021017\n",
      "[EPOCH #13, step #648] loss: 2.0133050031764848\n",
      "[EPOCH #13, step #650] loss: 2.0137556104616086\n",
      "[EPOCH #13, step #652] loss: 2.0145737405575437\n",
      "[EPOCH #13, step #654] loss: 2.0145860668357094\n",
      "[EPOCH #13, step #656] loss: 2.0144911481909555\n",
      "[EPOCH #13, step #658] loss: 2.0146884775306457\n",
      "[EPOCH #13, step #660] loss: 2.0146821805821244\n",
      "[EPOCH #13, step #662] loss: 2.0148130648096583\n",
      "[EPOCH #13, step #664] loss: 2.015085078182077\n",
      "[EPOCH #13, step #666] loss: 2.0143782559899557\n",
      "[EPOCH #13, step #668] loss: 2.0134783543100627\n",
      "[EPOCH #13, step #670] loss: 2.0137360005371616\n",
      "[EPOCH #13, step #672] loss: 2.013171640051775\n",
      "[EPOCH #13, step #674] loss: 2.0131434622517337\n",
      "[EPOCH #13, step #676] loss: 2.01331734710113\n",
      "[EPOCH #13, step #678] loss: 2.0125058915723932\n",
      "[EPOCH #13, step #680] loss: 2.0118042522940165\n",
      "[EPOCH #13, step #682] loss: 2.0111129779592267\n",
      "[EPOCH #13, step #684] loss: 2.0109592615252865\n",
      "[EPOCH #13, step #686] loss: 2.010957378313878\n",
      "[EPOCH #13, step #688] loss: 2.010741764471389\n",
      "[EPOCH #13, step #690] loss: 2.0107285010314366\n",
      "[EPOCH #13, step #692] loss: 2.011529447540404\n",
      "[EPOCH #13, step #694] loss: 2.0125207638569016\n",
      "[EPOCH #13, step #696] loss: 2.0127140362259306\n",
      "[EPOCH #13, step #698] loss: 2.0130913017133785\n",
      "[EPOCH #13, step #700] loss: 2.013138330271853\n",
      "[EPOCH #13, step #702] loss: 2.012407646070673\n",
      "[EPOCH #13, step #704] loss: 2.0120342951294377\n",
      "[EPOCH #13, step #706] loss: 2.0127455193386052\n",
      "[EPOCH #13, step #708] loss: 2.012432891828217\n",
      "[EPOCH #13, step #710] loss: 2.011382427564318\n",
      "[EPOCH #13, step #712] loss: 2.010839187413412\n",
      "[EPOCH #13, step #714] loss: 2.010891598421377\n",
      "[EPOCH #13, step #716] loss: 2.0117394623231024\n",
      "[EPOCH #13, step #718] loss: 2.0113245474280834\n",
      "[EPOCH #13, step #720] loss: 2.0121304011708654\n",
      "[EPOCH #13, step #722] loss: 2.011129634179185\n",
      "[EPOCH #13, step #724] loss: 2.0114682112068967\n",
      "[EPOCH #13, step #726] loss: 2.010741382222392\n",
      "[EPOCH #13, step #728] loss: 2.0096974098142772\n",
      "[EPOCH #13, step #730] loss: 2.0102517353689295\n",
      "[EPOCH #13, step #732] loss: 2.010612644895525\n",
      "[EPOCH #13, step #734] loss: 2.0101835756885764\n",
      "[EPOCH #13, step #736] loss: 2.009405095024057\n",
      "[EPOCH #13, step #738] loss: 2.010531721321591\n",
      "[EPOCH #13, step #740] loss: 2.0102187092648505\n",
      "[EPOCH #13, step #742] loss: 2.0113309682779326\n",
      "[EPOCH #13, step #744] loss: 2.011497566203943\n",
      "[EPOCH #13, step #746] loss: 2.012399459140527\n",
      "[EPOCH #13, step #748] loss: 2.0120252654135466\n",
      "[EPOCH #13, step #750] loss: 2.0122696383497845\n",
      "[EPOCH #13, step #752] loss: 2.01253289419658\n",
      "[EPOCH #13, step #754] loss: 2.0129785935610336\n",
      "[EPOCH #13, step #756] loss: 2.0130767182913294\n",
      "[EPOCH #13, step #758] loss: 2.0138479953383897\n",
      "[EPOCH #13, step #760] loss: 2.0139248242672734\n",
      "[EPOCH #13, step #762] loss: 2.0140535762706873\n",
      "[EPOCH #13, step #764] loss: 2.013545737858691\n",
      "[EPOCH #13, step #766] loss: 2.0140444100913353\n",
      "[EPOCH #13, step #768] loss: 2.0146685294584117\n",
      "[EPOCH #13, step #770] loss: 2.014902960465576\n",
      "[EPOCH #13, step #772] loss: 2.0138900998647276\n",
      "[EPOCH #13, step #774] loss: 2.013968648449067\n",
      "[EPOCH #13, step #776] loss: 2.0138541974002635\n",
      "[EPOCH #13, step #778] loss: 2.014534186031454\n",
      "[EPOCH #13, step #780] loss: 2.013995633235204\n",
      "[EPOCH #13, step #782] loss: 2.01472405714398\n",
      "[EPOCH #13, step #784] loss: 2.0153019760824313\n",
      "[EPOCH #13, step #786] loss: 2.014819690202667\n",
      "[EPOCH #13, step #788] loss: 2.015179841086287\n",
      "[EPOCH #13, step #790] loss: 2.015700016552217\n",
      "[EPOCH #13, step #792] loss: 2.0147648400346387\n",
      "[EPOCH #13, step #794] loss: 2.014675714834681\n",
      "[EPOCH #13, step #796] loss: 2.014828631390293\n",
      "[EPOCH #13, step #798] loss: 2.0147965190109236\n",
      "[EPOCH #13, step #800] loss: 2.015159948041823\n",
      "[EPOCH #13, step #802] loss: 2.015266017331875\n",
      "[EPOCH #13, step #804] loss: 2.0149940351521747\n",
      "[EPOCH #13, step #806] loss: 2.0144319002513105\n",
      "[EPOCH #13, step #808] loss: 2.0150418246190243\n",
      "[EPOCH #13, step #810] loss: 2.0159748335507883\n",
      "[EPOCH #13, step #812] loss: 2.015683172667012\n",
      "[EPOCH #13, step #814] loss: 2.0164097104335856\n",
      "[EPOCH #13, step #816] loss: 2.0162173662804332\n",
      "[EPOCH #13, step #818] loss: 2.0152358893800857\n",
      "[EPOCH #13, step #820] loss: 2.0155694221898495\n",
      "[EPOCH #13, step #822] loss: 2.016089606400973\n",
      "[EPOCH #13, step #824] loss: 2.016059583461646\n",
      "[EPOCH #13, step #826] loss: 2.0163769629731\n",
      "[EPOCH #13, step #828] loss: 2.016150883800014\n",
      "[EPOCH #13, step #830] loss: 2.017003639510392\n",
      "[EPOCH #13, step #832] loss: 2.0178788710041204\n",
      "[EPOCH #13, step #834] loss: 2.018100945963831\n",
      "[EPOCH #13, step #836] loss: 2.018518074581415\n",
      "[EPOCH #13, step #838] loss: 2.0196032008340445\n",
      "[EPOCH #13, step #840] loss: 2.0196289216720817\n",
      "[EPOCH #13, step #842] loss: 2.019090440632468\n",
      "[EPOCH #13, step #844] loss: 2.019220255676811\n",
      "[EPOCH #13, step #846] loss: 2.019430922364119\n",
      "[EPOCH #13, step #848] loss: 2.0190431403327467\n",
      "[EPOCH #13, step #850] loss: 2.0193578123906244\n",
      "[EPOCH #13, step #852] loss: 2.0190794474913676\n",
      "[EPOCH #13, step #854] loss: 2.0196570883020324\n",
      "[EPOCH #13, step #856] loss: 2.0196418461749546\n",
      "[EPOCH #13, step #858] loss: 2.0190554370147384\n",
      "[EPOCH #13, step #860] loss: 2.0189983774145306\n",
      "[EPOCH #13, step #862] loss: 2.018851062513862\n",
      "[EPOCH #13, step #864] loss: 2.0185648750018523\n",
      "[EPOCH #13, step #866] loss: 2.018600795783249\n",
      "[EPOCH #13, step #868] loss: 2.0187617158999513\n",
      "[EPOCH #13, step #870] loss: 2.0190625008704606\n",
      "[EPOCH #13, step #872] loss: 2.0192906157394184\n",
      "[EPOCH #13, step #874] loss: 2.0195934279305594\n",
      "[EPOCH #13, step #876] loss: 2.018825270566864\n",
      "[EPOCH #13, step #878] loss: 2.0201979394116365\n",
      "[EPOCH #13, step #880] loss: 2.02066587346366\n",
      "[EPOCH #13, step #882] loss: 2.0208522115126337\n",
      "[EPOCH #13, step #884] loss: 2.0208129517776143\n",
      "[EPOCH #13, step #886] loss: 2.0204886069023624\n",
      "[EPOCH #13, step #888] loss: 2.020653093357322\n",
      "[EPOCH #13, step #890] loss: 2.0211709879597963\n",
      "[EPOCH #13, step #892] loss: 2.0210891255873182\n",
      "[EPOCH #13, step #894] loss: 2.021425161947751\n",
      "[EPOCH #13, step #896] loss: 2.021571787703396\n",
      "[EPOCH #13, step #898] loss: 2.0222010782218485\n",
      "[EPOCH #13, step #900] loss: 2.021988293042326\n",
      "[EPOCH #13, step #902] loss: 2.021588311110884\n",
      "[EPOCH #13, step #904] loss: 2.0220378600431412\n",
      "[EPOCH #13, step #906] loss: 2.0215593579059923\n",
      "[EPOCH #13, step #908] loss: 2.0211017954074117\n",
      "[EPOCH #13, step #910] loss: 2.0207609559780417\n",
      "[EPOCH #13, step #912] loss: 2.020533991538943\n",
      "[EPOCH #13, step #914] loss: 2.020061241082155\n",
      "[EPOCH #13, step #916] loss: 2.0196824754987444\n",
      "[EPOCH #13, step #918] loss: 2.020268860267996\n",
      "[EPOCH #13, step #920] loss: 2.0198569292613144\n",
      "[EPOCH #13, step #922] loss: 2.0199913875253332\n",
      "[EPOCH #13, step #924] loss: 2.0195590034691064\n",
      "[EPOCH #13, step #926] loss: 2.018869289688308\n",
      "[EPOCH #13, step #928] loss: 2.0188705537496263\n",
      "[EPOCH #13, step #930] loss: 2.019428413101221\n",
      "[EPOCH #13, step #932] loss: 2.0190544074754624\n",
      "[EPOCH #13, step #934] loss: 2.019091737716593\n",
      "[EPOCH #13, step #936] loss: 2.0194063916913727\n",
      "[EPOCH #13, step #938] loss: 2.0204430108887954\n",
      "[EPOCH #13, step #940] loss: 2.020116939934863\n",
      "[EPOCH #13, step #942] loss: 2.0195964846605965\n",
      "[EPOCH #13, step #944] loss: 2.019844684651289\n",
      "[EPOCH #13, step #946] loss: 2.019970793910364\n",
      "[EPOCH #13, step #948] loss: 2.0197381061296693\n",
      "[EPOCH #13, step #950] loss: 2.019204286997501\n",
      "[EPOCH #13, step #952] loss: 2.018631485551752\n",
      "[EPOCH #13, step #954] loss: 2.0182300445297003\n",
      "[EPOCH #13, step #956] loss: 2.01792460947824\n",
      "[EPOCH #13, step #958] loss: 2.0181813078453694\n",
      "[EPOCH #13, step #960] loss: 2.0179424486845017\n",
      "[EPOCH #13, step #962] loss: 2.0182361969200127\n",
      "[EPOCH #13, step #964] loss: 2.018436011378629\n",
      "[EPOCH #13, step #966] loss: 2.0189329219332897\n",
      "[EPOCH #13, step #968] loss: 2.0190876321280826\n",
      "[EPOCH #13, step #970] loss: 2.0193487484349526\n",
      "[EPOCH #13, step #972] loss: 2.0192811882385615\n",
      "[EPOCH #13, step #974] loss: 2.019275105916537\n",
      "[EPOCH #13, step #976] loss: 2.0195848725835277\n",
      "[EPOCH #13, step #978] loss: 2.0199059985874865\n",
      "[EPOCH #13, step #980] loss: 2.0193534046867208\n",
      "[EPOCH #13, step #982] loss: 2.019792106483863\n",
      "[EPOCH #13, step #984] loss: 2.0199217504656253\n",
      "[EPOCH #13, step #986] loss: 2.0193067049907696\n",
      "[EPOCH #13, step #988] loss: 2.0196758347165114\n",
      "[EPOCH #13, step #990] loss: 2.019861448184032\n",
      "[EPOCH #13, step #992] loss: 2.0193975926165852\n",
      "[EPOCH #13, step #994] loss: 2.019596170660239\n",
      "[EPOCH #13, step #996] loss: 2.0198227363221024\n",
      "[EPOCH #13, step #998] loss: 2.0199329767141254\n",
      "[EPOCH #13, step #1000] loss: 2.0196915429074327\n",
      "[EPOCH #13, step #1002] loss: 2.0201582569900087\n",
      "[EPOCH #13, step #1004] loss: 2.0197783171240964\n",
      "[EPOCH #13, step #1006] loss: 2.019645615746272\n",
      "[EPOCH #13, step #1008] loss: 2.02024891650594\n",
      "[EPOCH #13, step #1010] loss: 2.0200519495736717\n",
      "[EPOCH #13, step #1012] loss: 2.0204555159848394\n",
      "[EPOCH #13, step #1014] loss: 2.0201999039485536\n",
      "[EPOCH #13, step #1016] loss: 2.020228033806605\n",
      "[EPOCH #13, step #1018] loss: 2.020376907831553\n",
      "[EPOCH #13, step #1020] loss: 2.0206847357819995\n",
      "[EPOCH #13, step #1022] loss: 2.0206138773048377\n",
      "[EPOCH #13, step #1024] loss: 2.0199270144904533\n",
      "[EPOCH #13, step #1026] loss: 2.019685798982102\n",
      "[EPOCH #13, step #1028] loss: 2.0197196918511646\n",
      "[EPOCH #13, step #1030] loss: 2.019705019566067\n",
      "[EPOCH #13, step #1032] loss: 2.020004625703566\n",
      "[EPOCH #13, step #1034] loss: 2.019831208675956\n",
      "[EPOCH #13, step #1036] loss: 2.0200725548982392\n",
      "[EPOCH #13, step #1038] loss: 2.020634295277233\n",
      "[EPOCH #13, step #1040] loss: 2.0201088216417005\n",
      "[EPOCH #13, step #1042] loss: 2.0210099432863875\n",
      "[EPOCH #13, step #1044] loss: 2.0213667262684214\n",
      "[EPOCH #13, step #1046] loss: 2.0219733220913803\n",
      "[EPOCH #13, step #1048] loss: 2.0212016634081977\n",
      "[EPOCH #13, step #1050] loss: 2.022114432618008\n",
      "[EPOCH #13, step #1052] loss: 2.022279534584437\n",
      "[EPOCH #13, step #1054] loss: 2.0221826096846596\n",
      "[EPOCH #13, step #1056] loss: 2.0223784841449057\n",
      "[EPOCH #13, step #1058] loss: 2.0219792476569403\n",
      "[EPOCH #13, step #1060] loss: 2.0219561861552346\n",
      "[EPOCH #13, step #1062] loss: 2.021770597289221\n",
      "[EPOCH #13, step #1064] loss: 2.021734340985616\n",
      "[EPOCH #13, step #1066] loss: 2.0227960542528676\n",
      "[EPOCH #13, step #1068] loss: 2.0229682154026514\n",
      "[EPOCH #13, step #1070] loss: 2.022890870867212\n",
      "[EPOCH #13, step #1072] loss: 2.022961617960401\n",
      "[EPOCH #13, step #1074] loss: 2.022643938951714\n",
      "[EPOCH #13, step #1076] loss: 2.022727181320403\n",
      "[EPOCH #13, step #1078] loss: 2.022799619377709\n",
      "[EPOCH #13, step #1080] loss: 2.02287589963336\n",
      "[EPOCH #13, step #1082] loss: 2.0226463581386365\n",
      "[EPOCH #13, step #1084] loss: 2.022475568709835\n",
      "[EPOCH #13, step #1086] loss: 2.022212181161496\n",
      "[EPOCH #13, step #1088] loss: 2.0219371665826733\n",
      "[EPOCH #13, step #1090] loss: 2.0218443195280082\n",
      "[EPOCH #13, step #1092] loss: 2.0216579031529824\n",
      "[EPOCH #13, step #1094] loss: 2.0219584752435553\n",
      "[EPOCH #13, step #1096] loss: 2.0219464386824377\n",
      "[EPOCH #13, step #1098] loss: 2.0211901428267782\n",
      "[EPOCH #13, step #1100] loss: 2.0209432746149214\n",
      "[EPOCH #13, step #1102] loss: 2.0208390496151076\n",
      "[EPOCH #13, step #1104] loss: 2.0206174680010767\n",
      "[EPOCH #13, step #1106] loss: 2.0208591144151695\n",
      "[EPOCH #13, step #1108] loss: 2.0211047427518825\n",
      "[EPOCH #13, step #1110] loss: 2.0216631852861573\n",
      "[EPOCH #13, step #1112] loss: 2.021680960115397\n",
      "[EPOCH #13, step #1114] loss: 2.0214400566212265\n",
      "[EPOCH #13, step #1116] loss: 2.021671272860965\n",
      "[EPOCH #13, step #1118] loss: 2.0216441322800516\n",
      "[EPOCH #13, step #1120] loss: 2.021740507164988\n",
      "[EPOCH #13, step #1122] loss: 2.0217240418266846\n",
      "[EPOCH #13, step #1124] loss: 2.0216730413436887\n",
      "[EPOCH #13, step #1126] loss: 2.0213029435385406\n",
      "[EPOCH #13, step #1128] loss: 2.021449269395259\n",
      "[EPOCH #13, step #1130] loss: 2.021935660263588\n",
      "[EPOCH #13, step #1132] loss: 2.0216379978966104\n",
      "[EPOCH #13, step #1134] loss: 2.0217693630294127\n",
      "[EPOCH #13, step #1136] loss: 2.0216572950467167\n",
      "[EPOCH #13, step #1138] loss: 2.021600331728452\n",
      "[EPOCH #13, step #1140] loss: 2.0218047701821424\n",
      "[EPOCH #13, step #1142] loss: 2.0220100943289196\n",
      "[EPOCH #13, step #1144] loss: 2.0215486681617505\n",
      "[EPOCH #13, step #1146] loss: 2.0214282182786603\n",
      "[EPOCH #13, step #1148] loss: 2.0209625690682644\n",
      "[EPOCH #13, step #1150] loss: 2.0210752540003414\n",
      "[EPOCH #13, step #1152] loss: 2.0210166439633728\n",
      "[EPOCH #13, step #1154] loss: 2.0209869239237404\n",
      "[EPOCH #13, step #1156] loss: 2.021222151345803\n",
      "[EPOCH #13, step #1158] loss: 2.0210391689313703\n",
      "[EPOCH #13, step #1160] loss: 2.020795980062493\n",
      "[EPOCH #13, step #1162] loss: 2.0213263824082404\n",
      "[EPOCH #13, step #1164] loss: 2.021640671987902\n",
      "[EPOCH #13, step #1166] loss: 2.022111562142131\n",
      "[EPOCH #13, step #1168] loss: 2.022075699984874\n",
      "[EPOCH #13, step #1170] loss: 2.022813646127585\n",
      "[EPOCH #13, step #1172] loss: 2.0231647367469288\n",
      "[EPOCH #13, step #1174] loss: 2.0242412242483585\n",
      "[EPOCH #13, step #1176] loss: 2.024749236483643\n",
      "[EPOCH #13, step #1178] loss: 2.024510220312486\n",
      "[EPOCH #13, step #1180] loss: 2.024437078169904\n",
      "[EPOCH #13, step #1182] loss: 2.0247733823747223\n",
      "[EPOCH #13, step #1184] loss: 2.024532120841465\n",
      "[EPOCH #13, step #1186] loss: 2.0241405537074217\n",
      "[EPOCH #13, step #1188] loss: 2.0235733330199657\n",
      "[EPOCH #13, step #1190] loss: 2.023366988455919\n",
      "[EPOCH #13, step #1192] loss: 2.0235969607608215\n",
      "[EPOCH #13, step #1194] loss: 2.0233052736545707\n",
      "[EPOCH #13, step #1196] loss: 2.0241295367155656\n",
      "[EPOCH #13, step #1198] loss: 2.023495539910998\n",
      "[EPOCH #13, step #1200] loss: 2.0231809537674765\n",
      "[EPOCH #13, step #1202] loss: 2.023530981982636\n",
      "[EPOCH #13, step #1204] loss: 2.0231002686923967\n",
      "[EPOCH #13, step #1206] loss: 2.0233286272521442\n",
      "[EPOCH #13, step #1208] loss: 2.0232641603258448\n",
      "[EPOCH #13, step #1210] loss: 2.0237516931617288\n",
      "[EPOCH #13, step #1212] loss: 2.023697223726227\n",
      "[EPOCH #13, step #1214] loss: 2.0239569419696006\n",
      "[EPOCH #13, step #1216] loss: 2.0236689794621903\n",
      "[EPOCH #13, step #1218] loss: 2.0240765450135716\n",
      "[EPOCH #13, step #1220] loss: 2.0242823901281897\n",
      "[EPOCH #13, step #1222] loss: 2.023884820138833\n",
      "[EPOCH #13, step #1224] loss: 2.02385906024855\n",
      "[EPOCH #13, step #1226] loss: 2.0237428438595475\n",
      "[EPOCH #13, step #1228] loss: 2.0233739212919195\n",
      "[EPOCH #13, step #1230] loss: 2.0236446291910353\n",
      "[EPOCH #13, step #1232] loss: 2.0233289197703637\n",
      "[EPOCH #13, step #1234] loss: 2.023192901746464\n",
      "[EPOCH #13, step #1236] loss: 2.023023029730603\n",
      "[EPOCH #13, step #1238] loss: 2.0227286753104137\n",
      "[EPOCH #13, step #1240] loss: 2.0221771986421126\n",
      "[EPOCH #13, step #1242] loss: 2.0222646763318983\n",
      "[EPOCH #13, step #1244] loss: 2.0224806212995903\n",
      "[EPOCH #13, step #1246] loss: 2.0225801693504106\n",
      "[EPOCH #13, step #1248] loss: 2.022300906234784\n",
      "[EPOCH #13, step #1250] loss: 2.0223525676795906\n",
      "[EPOCH #13, step #1252] loss: 2.022322125179903\n",
      "[EPOCH #13, step #1254] loss: 2.0220939473801876\n",
      "[EPOCH #13, step #1256] loss: 2.021919140098772\n",
      "[EPOCH #13, step #1258] loss: 2.0224624774681375\n",
      "[EPOCH #13, step #1260] loss: 2.0224991396813996\n",
      "[EPOCH #13, step #1262] loss: 2.0226836264935733\n",
      "[EPOCH #13, step #1264] loss: 2.0225844940178006\n",
      "[EPOCH #13, step #1266] loss: 2.022240841492199\n",
      "[EPOCH #13, step #1268] loss: 2.0218556526610945\n",
      "[EPOCH #13, step #1270] loss: 2.0214723826017464\n",
      "[EPOCH #13, step #1272] loss: 2.021352262920221\n",
      "[EPOCH #13, step #1274] loss: 2.0217240059609507\n",
      "[EPOCH #13, step #1276] loss: 2.021497387482771\n",
      "[EPOCH #13, step #1278] loss: 2.0213283978000667\n",
      "[EPOCH #13, step #1280] loss: 2.021258354373131\n",
      "[EPOCH #13, step #1282] loss: 2.0216192100908454\n",
      "[EPOCH #13, step #1284] loss: 2.021769923458767\n",
      "[EPOCH #13, step #1286] loss: 2.0219958354635765\n",
      "[EPOCH #13, step #1288] loss: 2.0217673054399925\n",
      "[EPOCH #13, step #1290] loss: 2.0216190151056517\n",
      "[EPOCH #13, step #1292] loss: 2.0217315156793556\n",
      "[EPOCH #13, step #1294] loss: 2.021706364789985\n",
      "[EPOCH #13, step #1296] loss: 2.0220447033299056\n",
      "[EPOCH #13, step #1298] loss: 2.021812084732467\n",
      "[EPOCH #13, step #1300] loss: 2.0222484944509964\n",
      "[EPOCH #13, step #1302] loss: 2.0220502074278968\n",
      "[EPOCH #13, step #1304] loss: 2.0222441964679296\n",
      "[EPOCH #13, step #1306] loss: 2.0221513320037037\n",
      "[EPOCH #13, step #1308] loss: 2.022009022186693\n",
      "[EPOCH #13, step #1310] loss: 2.021944214332022\n",
      "[EPOCH #13, step #1312] loss: 2.021535032047902\n",
      "[EPOCH #13, step #1314] loss: 2.0214064466635993\n",
      "[EPOCH #13, step #1316] loss: 2.0209230323949363\n",
      "[EPOCH #13, step #1318] loss: 2.020470107207251\n",
      "[EPOCH #13, step #1320] loss: 2.020805744489515\n",
      "[EPOCH #13, step #1322] loss: 2.021121619239686\n",
      "[EPOCH #13, step #1324] loss: 2.0209405680422514\n",
      "[EPOCH #13, step #1326] loss: 2.020640172272045\n",
      "[EPOCH #13, step #1328] loss: 2.020540041435563\n",
      "[EPOCH #13, step #1330] loss: 2.0208212909261416\n",
      "[EPOCH #13, step #1332] loss: 2.021241126253653\n",
      "[EPOCH #13, step #1334] loss: 2.021666872635316\n",
      "[EPOCH #13, step #1336] loss: 2.022151031240921\n",
      "[EPOCH #13, step #1338] loss: 2.0217278589500784\n",
      "[EPOCH #13, step #1340] loss: 2.0220510986293987\n",
      "[EPOCH #13, step #1342] loss: 2.0218540626236154\n",
      "[EPOCH #13, step #1344] loss: 2.021424868647494\n",
      "[EPOCH #13, step #1346] loss: 2.021025959969275\n",
      "[EPOCH #13, step #1348] loss: 2.0210576677781904\n",
      "[EPOCH #13, step #1350] loss: 2.0211790982746884\n",
      "[EPOCH #13, step #1352] loss: 2.021008081992996\n",
      "[EPOCH #13, step #1354] loss: 2.020581347300118\n",
      "[EPOCH #13, step #1356] loss: 2.0202324733017294\n",
      "[EPOCH #13, step #1358] loss: 2.020181603077319\n",
      "[EPOCH #13, step #1360] loss: 2.0198558726615543\n",
      "[EPOCH #13, step #1362] loss: 2.0194484566557698\n",
      "[EPOCH #13, step #1364] loss: 2.0197949018233863\n",
      "[EPOCH #13, step #1366] loss: 2.0201854151186494\n",
      "[EPOCH #13, step #1368] loss: 2.0202457789002413\n",
      "[EPOCH #13, step #1370] loss: 2.0197796366842535\n",
      "[EPOCH #13, step #1372] loss: 2.0197180400169077\n",
      "[EPOCH #13, step #1374] loss: 2.019366095196117\n",
      "[EPOCH #13, step #1376] loss: 2.0200359204063054\n",
      "[EPOCH #13, step #1378] loss: 2.0199351043611267\n",
      "[EPOCH #13, step #1380] loss: 2.0199641348398916\n",
      "[EPOCH #13, step #1382] loss: 2.019953857792174\n",
      "[EPOCH #13, step #1384] loss: 2.0200238272601516\n",
      "[EPOCH #13, step #1386] loss: 2.0199925159496974\n",
      "[EPOCH #13, step #1388] loss: 2.019690339560128\n",
      "[EPOCH #13, step #1390] loss: 2.0198879274509522\n",
      "[EPOCH #13, step #1392] loss: 2.0195892392861614\n",
      "[EPOCH #13, step #1394] loss: 2.0193623535949268\n",
      "[EPOCH #13, step #1396] loss: 2.0194634921054115\n",
      "[EPOCH #13, step #1398] loss: 2.019673252122755\n",
      "[EPOCH #13, step #1400] loss: 2.0193074244758558\n",
      "[EPOCH #13, step #1402] loss: 2.018829912690715\n",
      "[EPOCH #13, step #1404] loss: 2.018532189864705\n",
      "[EPOCH #13, step #1406] loss: 2.018771027959486\n",
      "[EPOCH #13, step #1408] loss: 2.0189548432192455\n",
      "[EPOCH #13, step #1410] loss: 2.0184901615645683\n",
      "[EPOCH #13, step #1412] loss: 2.01812139893793\n",
      "[EPOCH #13, step #1414] loss: 2.0182616964245854\n",
      "[EPOCH #13, step #1416] loss: 2.0187172379052885\n",
      "[EPOCH #13, step #1418] loss: 2.019040996546137\n",
      "[EPOCH #13, step #1420] loss: 2.018501654718226\n",
      "[EPOCH #13, step #1422] loss: 2.0187798389983027\n",
      "[EPOCH #13, step #1424] loss: 2.0191551962233425\n",
      "[EPOCH #13, step #1426] loss: 2.0191789121166677\n",
      "[EPOCH #13, step #1428] loss: 2.019105025652491\n",
      "[EPOCH #13, step #1430] loss: 2.0192482516450703\n",
      "[EPOCH #13, step #1432] loss: 2.0189311114209394\n",
      "[EPOCH #13, step #1434] loss: 2.0191603074921134\n",
      "[EPOCH #13, step #1436] loss: 2.0189384232815057\n",
      "[EPOCH #13, step #1438] loss: 2.0191978699138713\n",
      "[EPOCH #13, step #1440] loss: 2.0184025357449578\n",
      "[EPOCH #13, step #1442] loss: 2.0181937804258454\n",
      "[EPOCH #13, step #1444] loss: 2.018122231506559\n",
      "[EPOCH #13, step #1446] loss: 2.018009441757334\n",
      "[EPOCH #13, step #1448] loss: 2.0179560695375716\n",
      "[EPOCH #13, step #1450] loss: 2.0178916044353534\n",
      "[EPOCH #13, step #1452] loss: 2.0176927123657196\n",
      "[EPOCH #13, step #1454] loss: 2.0180296954420425\n",
      "[EPOCH #13, step #1456] loss: 2.017821347459834\n",
      "[EPOCH #13, step #1458] loss: 2.0178143288518893\n",
      "[EPOCH #13, step #1460] loss: 2.0179298858296617\n",
      "[EPOCH #13, step #1462] loss: 2.017979347534727\n",
      "[EPOCH #13, step #1464] loss: 2.0180679771273615\n",
      "[EPOCH #13, step #1466] loss: 2.0178429076845497\n",
      "[EPOCH #13, step #1468] loss: 2.0170050422864514\n",
      "[EPOCH #13, step #1470] loss: 2.0168475345395036\n",
      "[EPOCH #13, step #1472] loss: 2.016427947482687\n",
      "[EPOCH #13, step #1474] loss: 2.0167249462968213\n",
      "[EPOCH #13, step #1476] loss: 2.016992534102825\n",
      "[EPOCH #13, step #1478] loss: 2.0173359413740197\n",
      "[EPOCH #13, step #1480] loss: 2.017275441264398\n",
      "[EPOCH #13, step #1482] loss: 2.0173420361064207\n",
      "[EPOCH #13, step #1484] loss: 2.01712242152153\n",
      "[EPOCH #13, step #1486] loss: 2.017155507305122\n",
      "[EPOCH #13, step #1488] loss: 2.0174657030342567\n",
      "[EPOCH #13, step #1490] loss: 2.017697190694726\n",
      "[EPOCH #13, step #1492] loss: 2.018281160228139\n",
      "[EPOCH #13, step #1494] loss: 2.0188741926365474\n",
      "[EPOCH #13, step #1496] loss: 2.0186960738582775\n",
      "[EPOCH #13, step #1498] loss: 2.0188086540242525\n",
      "[EPOCH #13, step #1500] loss: 2.0184594878826356\n",
      "[EPOCH #13, step #1502] loss: 2.018175148995654\n",
      "[EPOCH #13, step #1504] loss: 2.017969580742212\n",
      "[EPOCH #13, step #1506] loss: 2.0177535608895347\n",
      "[EPOCH #13, step #1508] loss: 2.017915239548983\n",
      "[EPOCH #13, step #1510] loss: 2.018065205163154\n",
      "[EPOCH #13, step #1512] loss: 2.017885393680363\n",
      "[EPOCH #13, step #1514] loss: 2.017805295651502\n",
      "[EPOCH #13, step #1516] loss: 2.0172848494805704\n",
      "[EPOCH #13, step #1518] loss: 2.017163578894203\n",
      "[EPOCH #13, step #1520] loss: 2.017305148815654\n",
      "[EPOCH #13, step #1522] loss: 2.0168045869565527\n",
      "[EPOCH #13, step #1524] loss: 2.0172255004820276\n",
      "[EPOCH #13, step #1526] loss: 2.0170733995037917\n",
      "[EPOCH #13, step #1528] loss: 2.0168639147804015\n",
      "[EPOCH #13, step #1530] loss: 2.0169352782777055\n",
      "[EPOCH #13, step #1532] loss: 2.0172051616688607\n",
      "[EPOCH #13, step #1534] loss: 2.0169820722617233\n",
      "[EPOCH #13, step #1536] loss: 2.017105885659555\n",
      "[EPOCH #13, step #1538] loss: 2.01678426928765\n",
      "[EPOCH #13, step #1540] loss: 2.017060752428638\n",
      "[EPOCH #13, step #1542] loss: 2.0171389464658342\n",
      "[EPOCH #13, step #1544] loss: 2.017272591976672\n",
      "[EPOCH #13, step #1546] loss: 2.01739849671288\n",
      "[EPOCH #13, step #1548] loss: 2.017054915735997\n",
      "[EPOCH #13, step #1550] loss: 2.017105855532879\n",
      "[EPOCH #13, step #1552] loss: 2.0169588884690155\n",
      "[EPOCH #13, step #1554] loss: 2.016529401935565\n",
      "[EPOCH #13, step #1556] loss: 2.0165058196012073\n",
      "[EPOCH #13, step #1558] loss: 2.016489327450912\n",
      "[EPOCH #13, step #1560] loss: 2.0159049153251574\n",
      "[EPOCH #13, step #1562] loss: 2.0158609973263144\n",
      "[EPOCH #13, step #1564] loss: 2.0156854243324207\n",
      "[EPOCH #13, step #1566] loss: 2.015584968957615\n",
      "[EPOCH #13, step #1568] loss: 2.0154590586175427\n",
      "[EPOCH #13, step #1570] loss: 2.015159611410582\n",
      "[EPOCH #13, step #1572] loss: 2.0145324190482925\n",
      "[EPOCH #13, step #1574] loss: 2.015112852369036\n",
      "[EPOCH #13, step #1576] loss: 2.0152532262142957\n",
      "[EPOCH #13, step #1578] loss: 2.015197496311509\n",
      "[EPOCH #13, step #1580] loss: 2.0151790449847007\n",
      "[EPOCH #13, step #1582] loss: 2.015436495171268\n",
      "[EPOCH #13, step #1584] loss: 2.0152781607600794\n",
      "[EPOCH #13, step #1586] loss: 2.0152642684082003\n",
      "[EPOCH #13, step #1588] loss: 2.014943461811265\n",
      "[EPOCH #13, step #1590] loss: 2.0149625471595844\n",
      "[EPOCH #13, step #1592] loss: 2.0157491270282026\n",
      "[EPOCH #13, step #1594] loss: 2.015875352662185\n",
      "[EPOCH #13, step #1596] loss: 2.0158881334939\n",
      "[EPOCH #13, step #1598] loss: 2.016455122498589\n",
      "[EPOCH #13, step #1600] loss: 2.0162619041100953\n",
      "[EPOCH #13, step #1602] loss: 2.016153893542156\n",
      "[EPOCH #13, step #1604] loss: 2.015653678932665\n",
      "[EPOCH #13, step #1606] loss: 2.0156153189742794\n",
      "[EPOCH #13, step #1608] loss: 2.015585567952684\n",
      "[EPOCH #13, step #1610] loss: 2.015670727307126\n",
      "[EPOCH #13, step #1612] loss: 2.0154008954042837\n",
      "[EPOCH #13, step #1614] loss: 2.0156741152606883\n",
      "[EPOCH #13, step #1616] loss: 2.015588214092219\n",
      "[EPOCH #13, step #1618] loss: 2.0160734168978074\n",
      "[EPOCH #13, step #1620] loss: 2.0158165839628848\n",
      "[EPOCH #13, step #1622] loss: 2.01575330136664\n",
      "[EPOCH #13, step #1624] loss: 2.0159628024468055\n",
      "[EPOCH #13, step #1626] loss: 2.0157374095975364\n",
      "[EPOCH #13, step #1628] loss: 2.0157155695687488\n",
      "[EPOCH #13, step #1630] loss: 2.016293625024694\n",
      "[EPOCH #13, step #1632] loss: 2.0162174270989626\n",
      "[EPOCH #13, step #1634] loss: 2.016422364908621\n",
      "[EPOCH #13, step #1636] loss: 2.0163000873770742\n",
      "[EPOCH #13, step #1638] loss: 2.0161616129435878\n",
      "[EPOCH #13, step #1640] loss: 2.01643579962194\n",
      "[EPOCH #13, step #1642] loss: 2.0165106201781344\n",
      "[EPOCH #13, step #1644] loss: 2.0168832488335373\n",
      "[EPOCH #13, step #1646] loss: 2.0168182592212465\n",
      "[EPOCH #13, step #1648] loss: 2.0168752774388374\n",
      "[EPOCH #13, step #1650] loss: 2.016991836673776\n",
      "[EPOCH #13, step #1652] loss: 2.0171239311162874\n",
      "[EPOCH #13, step #1654] loss: 2.01739076646073\n",
      "[EPOCH #13, step #1656] loss: 2.0174052687963235\n",
      "[EPOCH #13, step #1658] loss: 2.017543117277158\n",
      "[EPOCH #13, step #1660] loss: 2.017123472611636\n",
      "[EPOCH #13, step #1662] loss: 2.017225438474677\n",
      "[EPOCH #13, step #1664] loss: 2.0174067417780557\n",
      "[EPOCH #13, step #1666] loss: 2.017192668090985\n",
      "[EPOCH #13, step #1668] loss: 2.0173844278323\n",
      "[EPOCH #13, step #1670] loss: 2.017322549771435\n",
      "[EPOCH #13, step #1672] loss: 2.017374347443361\n",
      "[EPOCH #13, step #1674] loss: 2.017289199402083\n",
      "[EPOCH #13, step #1676] loss: 2.016920911391434\n",
      "[EPOCH #13, step #1678] loss: 2.0165714548058706\n",
      "[EPOCH #13, step #1680] loss: 2.0165526557720397\n",
      "[EPOCH #13, step #1682] loss: 2.0165026389057976\n",
      "[EPOCH #13, step #1684] loss: 2.016639243176854\n",
      "[EPOCH #13, step #1686] loss: 2.016455380112445\n",
      "[EPOCH #13, step #1688] loss: 2.0162067017377376\n",
      "[EPOCH #13, step #1690] loss: 2.016242282549916\n",
      "[EPOCH #13, step #1692] loss: 2.016301002505258\n",
      "[EPOCH #13, step #1694] loss: 2.015655062191606\n",
      "[EPOCH #13, step #1696] loss: 2.0162190481291566\n",
      "[EPOCH #13, step #1698] loss: 2.0157887842319795\n",
      "[EPOCH #13, step #1700] loss: 2.0161733471036727\n",
      "[EPOCH #13, step #1702] loss: 2.015900354698974\n",
      "[EPOCH #13, step #1704] loss: 2.0160865928420573\n",
      "[EPOCH #13, step #1706] loss: 2.0159625324786723\n",
      "[EPOCH #13, step #1708] loss: 2.015963634529471\n",
      "[EPOCH #13, step #1710] loss: 2.01574581725635\n",
      "[EPOCH #13, step #1712] loss: 2.0156356255630965\n",
      "[EPOCH #13, step #1714] loss: 2.0155013522323295\n",
      "[EPOCH #13, step #1716] loss: 2.0157901207652285\n",
      "[EPOCH #13, step #1718] loss: 2.0158317571743205\n",
      "[EPOCH #13, step #1720] loss: 2.01577080903117\n",
      "[EPOCH #13, step #1722] loss: 2.0156908621984515\n",
      "[EPOCH #13, step #1724] loss: 2.0156677923340727\n",
      "[EPOCH #13, step #1726] loss: 2.0156010055928544\n",
      "[EPOCH #13, step #1728] loss: 2.0155851698942167\n",
      "[EPOCH #13, step #1730] loss: 2.0156469944926925\n",
      "[EPOCH #13, step #1732] loss: 2.0154248289613452\n",
      "[EPOCH #13, step #1734] loss: 2.0150464188468558\n",
      "[EPOCH #13, step #1736] loss: 2.0152054660678527\n",
      "[EPOCH #13, step #1738] loss: 2.0150702526132016\n",
      "[EPOCH #13, step #1740] loss: 2.0150796835070572\n",
      "[EPOCH #13, step #1742] loss: 2.01500522084983\n",
      "[EPOCH #13, step #1744] loss: 2.0148637823525677\n",
      "[EPOCH #13, step #1746] loss: 2.015081258726311\n",
      "[EPOCH #13, step #1748] loss: 2.015028927992793\n",
      "[EPOCH #13, step #1750] loss: 2.014873530168931\n",
      "[EPOCH #13, step #1752] loss: 2.014393904653877\n",
      "[EPOCH #13, step #1754] loss: 2.014188543072453\n",
      "[EPOCH #13, step #1756] loss: 2.014443503161622\n",
      "[EPOCH #13, step #1758] loss: 2.014544569205804\n",
      "[EPOCH #13, step #1760] loss: 2.014817567998073\n",
      "[EPOCH #13, step #1762] loss: 2.0145616559771335\n",
      "[EPOCH #13, step #1764] loss: 2.0147131754386187\n",
      "[EPOCH #13, step #1766] loss: 2.0148193776168997\n",
      "[EPOCH #13, step #1768] loss: 2.0147707890898174\n",
      "[EPOCH #13, step #1770] loss: 2.0145479422514887\n",
      "[EPOCH #13, step #1772] loss: 2.014497762605825\n",
      "[EPOCH #13, step #1774] loss: 2.014445030387019\n",
      "[EPOCH #13, step #1776] loss: 2.0143792366941256\n",
      "[EPOCH #13, step #1778] loss: 2.0146968689709985\n",
      "[EPOCH #13, step #1780] loss: 2.0144396738548216\n",
      "[EPOCH #13, step #1782] loss: 2.014030055991733\n",
      "[EPOCH #13, step #1784] loss: 2.014184769128217\n",
      "[EPOCH #13, step #1786] loss: 2.014079726869725\n",
      "[EPOCH #13, step #1788] loss: 2.0142607089858804\n",
      "[EPOCH #13, step #1790] loss: 2.013820988848381\n",
      "[EPOCH #13, step #1792] loss: 2.013942754009351\n",
      "[EPOCH #13, step #1794] loss: 2.01375086320808\n",
      "[EPOCH #13, step #1796] loss: 2.014051132024363\n",
      "[EPOCH #13, step #1798] loss: 2.014114694041368\n",
      "[EPOCH #13, step #1800] loss: 2.0138118945513086\n",
      "[EPOCH #13, step #1802] loss: 2.0138512289133987\n",
      "[EPOCH #13, step #1804] loss: 2.013786104445312\n",
      "[EPOCH #13, step #1806] loss: 2.013337041306509\n",
      "[EPOCH #13, step #1808] loss: 2.013069633227676\n",
      "[EPOCH #13, step #1810] loss: 2.0132053195936517\n",
      "[EPOCH #13, step #1812] loss: 2.01312509506234\n",
      "[EPOCH #13, step #1814] loss: 2.0126085642612344\n",
      "[EPOCH #13, step #1816] loss: 2.0125426625444396\n",
      "[EPOCH #13, step #1818] loss: 2.012452636661603\n",
      "[EPOCH #13, step #1820] loss: 2.012571756359249\n",
      "[EPOCH #13, step #1822] loss: 2.012429896319102\n",
      "[EPOCH #13, step #1824] loss: 2.012354752396884\n",
      "[EPOCH #13, step #1826] loss: 2.0119617372898047\n",
      "[EPOCH #13, step #1828] loss: 2.0118771982427632\n",
      "[EPOCH #13, step #1830] loss: 2.011905403947127\n",
      "[EPOCH #13, step #1832] loss: 2.0120229391341513\n",
      "[EPOCH #13, step #1834] loss: 2.0119585347110633\n",
      "[EPOCH #13, step #1836] loss: 2.0122837006039895\n",
      "[EPOCH #13, step #1838] loss: 2.0123343132578078\n",
      "[EPOCH #13, step #1840] loss: 2.0127318765986297\n",
      "[EPOCH #13, step #1842] loss: 2.0127140145811513\n",
      "[EPOCH #13, step #1844] loss: 2.0121874059118876\n",
      "[EPOCH #13, step #1846] loss: 2.0121190464683782\n",
      "[EPOCH #13, step #1848] loss: 2.012097454187095\n",
      "[EPOCH #13, step #1850] loss: 2.01193400739271\n",
      "[EPOCH #13, step #1852] loss: 2.01235288648559\n",
      "[EPOCH #13, step #1854] loss: 2.0123782155327397\n",
      "[EPOCH #13, step #1856] loss: 2.012239603567457\n",
      "[EPOCH #13, step #1858] loss: 2.012033162224735\n",
      "[EPOCH #13, step #1860] loss: 2.0120792616316865\n",
      "[EPOCH #13, step #1862] loss: 2.011797476825827\n",
      "[EPOCH #13, step #1864] loss: 2.0117991522873373\n",
      "[EPOCH #13, step #1866] loss: 2.011805909932713\n",
      "[EPOCH #13, step #1868] loss: 2.0116158966204263\n",
      "[EPOCH #13, step #1870] loss: 2.011303808139901\n",
      "[EPOCH #13, step #1872] loss: 2.011440238402734\n",
      "[EPOCH #13, step #1874] loss: 2.011189737256368\n",
      "[EPOCH #13, step #1876] loss: 2.011034944048573\n",
      "[EPOCH #13, step #1878] loss: 2.0105651712214585\n",
      "[EPOCH #13, step #1880] loss: 2.01077536874981\n",
      "[EPOCH #13, step #1882] loss: 2.0107725547212145\n",
      "[EPOCH #13, step #1884] loss: 2.011000750425324\n",
      "[EPOCH #13, step #1886] loss: 2.010705046383363\n",
      "[EPOCH #13, step #1888] loss: 2.0107470408768298\n",
      "[EPOCH #13, step #1890] loss: 2.0107095554226735\n",
      "[EPOCH #13, step #1892] loss: 2.010589542240298\n",
      "[EPOCH #13, step #1894] loss: 2.0105004527638015\n",
      "[EPOCH #13, step #1896] loss: 2.010884754709275\n",
      "[EPOCH #13, step #1898] loss: 2.010780261716697\n",
      "[EPOCH #13, step #1900] loss: 2.0111136734328854\n",
      "[EPOCH #13, step #1902] loss: 2.0112914116960168\n",
      "[EPOCH #13, step #1904] loss: 2.010594830863432\n",
      "[EPOCH #13, step #1906] loss: 2.010324316182309\n",
      "[EPOCH #13, step #1908] loss: 2.010243944936925\n",
      "[EPOCH #13, step #1910] loss: 2.010317805298706\n",
      "[EPOCH #13, step #1912] loss: 2.009954762907472\n",
      "[EPOCH #13, step #1914] loss: 2.0100419320263376\n",
      "[EPOCH #13, step #1916] loss: 2.009849088603653\n",
      "[EPOCH #13, step #1918] loss: 2.009816703167727\n",
      "[EPOCH #13, step #1920] loss: 2.009777161555015\n",
      "[EPOCH #13, step #1922] loss: 2.0097964699542343\n",
      "[EPOCH #13, step #1924] loss: 2.0098244438542947\n",
      "[EPOCH #13, step #1926] loss: 2.0098343654562294\n",
      "[EPOCH #13, step #1928] loss: 2.009588925315655\n",
      "[EPOCH #13, step #1930] loss: 2.009252810527598\n",
      "[EPOCH #13, step #1932] loss: 2.009457843327115\n",
      "[EPOCH #13, step #1934] loss: 2.0092293497203855\n",
      "[EPOCH #13, step #1936] loss: 2.0091354393995973\n",
      "[EPOCH #13, step #1938] loss: 2.0089189648443795\n",
      "[EPOCH #13, step #1940] loss: 2.008503881758602\n",
      "[EPOCH #13, step #1942] loss: 2.0087669623984055\n",
      "[EPOCH #13, step #1944] loss: 2.0089053764441327\n",
      "[EPOCH #13, step #1946] loss: 2.008953231018999\n",
      "[EPOCH #13, step #1948] loss: 2.0091910348175857\n",
      "[EPOCH #13, step #1950] loss: 2.0086772207233734\n",
      "[EPOCH #13, step #1952] loss: 2.008271030444581\n",
      "[EPOCH #13, step #1954] loss: 2.0082438698205194\n",
      "[EPOCH #13, step #1956] loss: 2.008047144755333\n",
      "[EPOCH #13, step #1958] loss: 2.0075865267733644\n",
      "[EPOCH #13, step #1960] loss: 2.007706312060903\n",
      "[EPOCH #13, step #1962] loss: 2.0078620073811106\n",
      "[EPOCH #13, step #1964] loss: 2.0078631084383898\n",
      "[EPOCH #13, step #1966] loss: 2.007634909854786\n",
      "[EPOCH #13, step #1968] loss: 2.0076356018903354\n",
      "[EPOCH #13, step #1970] loss: 2.0077844887200738\n",
      "[EPOCH #13, step #1972] loss: 2.0077716986418856\n",
      "[EPOCH #13, step #1974] loss: 2.0076731074007252\n",
      "[EPOCH #13, step #1976] loss: 2.007476819182624\n",
      "[EPOCH #13, step #1978] loss: 2.0078661320123965\n",
      "[EPOCH #13, step #1980] loss: 2.008109110644946\n",
      "[EPOCH #13, step #1982] loss: 2.008166706327591\n",
      "[EPOCH #13, step #1984] loss: 2.008466413879875\n",
      "[EPOCH #13, step #1986] loss: 2.0085126117179306\n",
      "[EPOCH #13, step #1988] loss: 2.0082473254431545\n",
      "[EPOCH #13, step #1990] loss: 2.0080580394032133\n",
      "[EPOCH #13, step #1992] loss: 2.008080648227487\n",
      "[EPOCH #13, step #1994] loss: 2.007808018029483\n",
      "[EPOCH #13, step #1996] loss: 2.007482247526907\n",
      "[EPOCH #13, step #1998] loss: 2.0075440280374255\n",
      "[EPOCH #13, step #2000] loss: 2.0077856876205527\n",
      "[EPOCH #13, step #2002] loss: 2.0080627765407932\n",
      "[EPOCH #13, step #2004] loss: 2.007792645559049\n",
      "[EPOCH #13, step #2006] loss: 2.007764828401118\n",
      "[EPOCH #13, step #2008] loss: 2.0079447137235467\n",
      "[EPOCH #13, step #2010] loss: 2.0079446431714345\n",
      "[EPOCH #13, step #2012] loss: 2.0076424976041882\n",
      "[EPOCH #13, step #2014] loss: 2.007723134918781\n",
      "[EPOCH #13, step #2016] loss: 2.0074771185824347\n",
      "[EPOCH #13, step #2018] loss: 2.0075473044992025\n",
      "[EPOCH #13, step #2020] loss: 2.007823801937226\n",
      "[EPOCH #13, step #2022] loss: 2.007870309198486\n",
      "[EPOCH #13, step #2024] loss: 2.007812792872205\n",
      "[EPOCH #13, step #2026] loss: 2.00749545239673\n",
      "[EPOCH #13, step #2028] loss: 2.0073148007461037\n",
      "[EPOCH #13, step #2030] loss: 2.007237501710228\n",
      "[EPOCH #13, step #2032] loss: 2.007523044540679\n",
      "[EPOCH #13, step #2034] loss: 2.007863099862082\n",
      "[EPOCH #13, step #2036] loss: 2.0080223164841655\n",
      "[EPOCH #13, step #2038] loss: 2.0077391743601507\n",
      "[EPOCH #13, step #2040] loss: 2.007923489105228\n",
      "[EPOCH #13, step #2042] loss: 2.0080110195274745\n",
      "[EPOCH #13, step #2044] loss: 2.0079131600326314\n",
      "[EPOCH #13, step #2046] loss: 2.0080412194154644\n",
      "[EPOCH #13, step #2048] loss: 2.0081092614904157\n",
      "[EPOCH #13, step #2050] loss: 2.00847543111259\n",
      "[EPOCH #13, step #2052] loss: 2.0085009812031265\n",
      "[EPOCH #13, step #2054] loss: 2.0085818797712487\n",
      "[EPOCH #13, step #2056] loss: 2.0086946691421264\n",
      "[EPOCH #13, step #2058] loss: 2.0084290596511307\n",
      "[EPOCH #13, step #2060] loss: 2.0087476334833276\n",
      "[EPOCH #13, step #2062] loss: 2.0087937550006187\n",
      "[EPOCH #13, step #2064] loss: 2.0091793430342224\n",
      "[EPOCH #13, step #2066] loss: 2.0090190070114913\n",
      "[EPOCH #13, step #2068] loss: 2.0090198454619492\n",
      "[EPOCH #13, step #2070] loss: 2.0091659411435425\n",
      "[EPOCH #13, step #2072] loss: 2.0087895656747627\n",
      "[EPOCH #13, step #2074] loss: 2.008660900449178\n",
      "[EPOCH #13, step #2076] loss: 2.008595995393348\n",
      "[EPOCH #13, step #2078] loss: 2.008525403203042\n",
      "[EPOCH #13, step #2080] loss: 2.008754318119069\n",
      "[EPOCH #13, step #2082] loss: 2.0089220058671913\n",
      "[EPOCH #13, step #2084] loss: 2.0089359895216763\n",
      "[EPOCH #13, step #2086] loss: 2.008887720439328\n",
      "[EPOCH #13, step #2088] loss: 2.0087375963287757\n",
      "[EPOCH #13, step #2090] loss: 2.008546359569818\n",
      "[EPOCH #13, step #2092] loss: 2.0085566779727637\n",
      "[EPOCH #13, step #2094] loss: 2.0085200995420216\n",
      "[EPOCH #13, step #2096] loss: 2.008375592838882\n",
      "[EPOCH #13, step #2098] loss: 2.0086493286534455\n",
      "[EPOCH #13, step #2100] loss: 2.0085982079735145\n",
      "[EPOCH #13, step #2102] loss: 2.0083102589837156\n",
      "[EPOCH #13, step #2104] loss: 2.008580986111294\n",
      "[EPOCH #13, step #2106] loss: 2.0083061926275505\n",
      "[EPOCH #13, step #2108] loss: 2.008088283767176\n",
      "[EPOCH #13, step #2110] loss: 2.007924885334194\n",
      "[EPOCH #13, step #2112] loss: 2.0078795777639957\n",
      "[EPOCH #13, step #2114] loss: 2.0078969792553156\n",
      "[EPOCH #13, step #2116] loss: 2.0081795095890604\n",
      "[EPOCH #13, step #2118] loss: 2.008058542404157\n",
      "[EPOCH #13, step #2120] loss: 2.008105625189008\n",
      "[EPOCH #13, step #2122] loss: 2.0081057893292162\n",
      "[EPOCH #13, step #2124] loss: 2.0080028177149156\n",
      "[EPOCH #13, step #2126] loss: 2.0078801723730413\n",
      "[EPOCH #13, step #2128] loss: 2.0077461477958747\n",
      "[EPOCH #13, step #2130] loss: 2.0078599064185663\n",
      "[EPOCH #13, step #2132] loss: 2.0077360198355816\n",
      "[EPOCH #13, step #2134] loss: 2.0078104375955372\n",
      "[EPOCH #13, step #2136] loss: 2.007676869895785\n",
      "[EPOCH #13, step #2138] loss: 2.0073472914599884\n",
      "[EPOCH #13, step #2140] loss: 2.007224821420765\n",
      "[EPOCH #13, step #2142] loss: 2.007083613907017\n",
      "[EPOCH #13, step #2144] loss: 2.007088474238113\n",
      "[EPOCH #13, step #2146] loss: 2.007406297371895\n",
      "[EPOCH #13, step #2148] loss: 2.007231506262895\n",
      "[EPOCH #13, step #2150] loss: 2.0069626584711435\n",
      "[EPOCH #13, step #2152] loss: 2.006830905018659\n",
      "[EPOCH #13, step #2154] loss: 2.006894453329719\n",
      "[EPOCH #13, step #2156] loss: 2.006962142390789\n",
      "[EPOCH #13, step #2158] loss: 2.006757863421526\n",
      "[EPOCH #13, step #2160] loss: 2.0064724019587676\n",
      "[EPOCH #13, step #2162] loss: 2.00660960248814\n",
      "[EPOCH #13, step #2164] loss: 2.006563297320183\n",
      "[EPOCH #13, step #2166] loss: 2.0064910519876733\n",
      "[EPOCH #13, step #2168] loss: 2.006191243054736\n",
      "[EPOCH #13, step #2170] loss: 2.0058907762972895\n",
      "[EPOCH #13, step #2172] loss: 2.005960316521969\n",
      "[EPOCH #13, step #2174] loss: 2.0064083540576627\n",
      "[EPOCH #13, step #2176] loss: 2.00660975180912\n",
      "[EPOCH #13, step #2178] loss: 2.0064354329111382\n",
      "[EPOCH #13, step #2180] loss: 2.006340131416391\n",
      "[EPOCH #13, step #2182] loss: 2.0064138677542873\n",
      "[EPOCH #13, step #2184] loss: 2.0066628323539715\n",
      "[EPOCH #13, step #2186] loss: 2.0065048255493068\n",
      "[EPOCH #13, step #2188] loss: 2.0063146188848364\n",
      "[EPOCH #13, step #2190] loss: 2.0065256856120053\n",
      "[EPOCH #13, step #2192] loss: 2.006610481966265\n",
      "[EPOCH #13, step #2194] loss: 2.0063727703615855\n",
      "[EPOCH #13, step #2196] loss: 2.0064745786030507\n",
      "[EPOCH #13, step #2198] loss: 2.006497810677324\n",
      "[EPOCH #13, step #2200] loss: 2.006504264651294\n",
      "[EPOCH #13, step #2202] loss: 2.0065297668108983\n",
      "[EPOCH #13, step #2204] loss: 2.0063619143297884\n",
      "[EPOCH #13, step #2206] loss: 2.0064345256851226\n",
      "[EPOCH #13, step #2208] loss: 2.0066061785664693\n",
      "[EPOCH #13, step #2210] loss: 2.0066017378298526\n",
      "[EPOCH #13, step #2212] loss: 2.0064394275257613\n",
      "[EPOCH #13, step #2214] loss: 2.005988802382424\n",
      "[EPOCH #13, step #2216] loss: 2.0056427310165867\n",
      "[EPOCH #13, step #2218] loss: 2.0056415984307177\n",
      "[EPOCH #13, step #2220] loss: 2.0054652580856365\n",
      "[EPOCH #13, step #2222] loss: 2.005227247605815\n",
      "[EPOCH #13, step #2224] loss: 2.0051525954450113\n",
      "[EPOCH #13, step #2226] loss: 2.0052997789203078\n",
      "[EPOCH #13, step #2228] loss: 2.0052599988747413\n",
      "[EPOCH #13, step #2230] loss: 2.0051886277153907\n",
      "[EPOCH #13, step #2232] loss: 2.00534609465977\n",
      "[EPOCH #13, step #2234] loss: 2.0051728777704088\n",
      "[EPOCH #13, step #2236] loss: 2.0050479423589453\n",
      "[EPOCH #13, step #2238] loss: 2.0049801148064916\n",
      "[EPOCH #13, step #2240] loss: 2.0052167681485935\n",
      "[EPOCH #13, step #2242] loss: 2.005163703440982\n",
      "[EPOCH #13, step #2244] loss: 2.005283815398779\n",
      "[EPOCH #13, step #2246] loss: 2.0050704628825984\n",
      "[EPOCH #13, step #2248] loss: 2.005397982043974\n",
      "[EPOCH #13, step #2250] loss: 2.005238045114562\n",
      "[EPOCH #13, step #2252] loss: 2.005188738670129\n",
      "[EPOCH #13, step #2254] loss: 2.0050884120480186\n",
      "[EPOCH #13, step #2256] loss: 2.0046856107572353\n",
      "[EPOCH #13, step #2258] loss: 2.00485403957806\n",
      "[EPOCH #13, step #2260] loss: 2.004783880863502\n",
      "[EPOCH #13, step #2262] loss: 2.004727132226638\n",
      "[EPOCH #13, step #2264] loss: 2.0048619312429534\n",
      "[EPOCH #13, step #2266] loss: 2.004884860565024\n",
      "[EPOCH #13, step #2268] loss: 2.004571030086334\n",
      "[EPOCH #13, step #2270] loss: 2.0045345704075737\n",
      "[EPOCH #13, step #2272] loss: 2.004588353964289\n",
      "[EPOCH #13, step #2274] loss: 2.0042566773655652\n",
      "[EPOCH #13, step #2276] loss: 2.004369247101041\n",
      "[EPOCH #13, step #2278] loss: 2.0042139751548147\n",
      "[EPOCH #13, step #2280] loss: 2.003908249747591\n",
      "[EPOCH #13, step #2282] loss: 2.004083820356385\n",
      "[EPOCH #13, step #2284] loss: 2.004031497540046\n",
      "[EPOCH #13, step #2286] loss: 2.0039567436565204\n",
      "[EPOCH #13, step #2288] loss: 2.0040736776504415\n",
      "[EPOCH #13, step #2290] loss: 2.0042625118790105\n",
      "[EPOCH #13, step #2292] loss: 2.0040378406793335\n",
      "[EPOCH #13, step #2294] loss: 2.003933986391637\n",
      "[EPOCH #13, step #2296] loss: 2.003674920040159\n",
      "[EPOCH #13, step #2298] loss: 2.0036222637607097\n",
      "[EPOCH #13, step #2300] loss: 2.003615704737037\n",
      "[EPOCH #13, step #2302] loss: 2.003469074026067\n",
      "[EPOCH #13, step #2304] loss: 2.0035594896742683\n",
      "[EPOCH #13, step #2306] loss: 2.0033605481620262\n",
      "[EPOCH #13, step #2308] loss: 2.003224538125327\n",
      "[EPOCH #13, step #2310] loss: 2.0032081126341414\n",
      "[EPOCH #13, step #2312] loss: 2.0031520618384295\n",
      "[EPOCH #13, step #2314] loss: 2.0030514241809723\n",
      "[EPOCH #13, step #2316] loss: 2.003141730933751\n",
      "[EPOCH #13, step #2318] loss: 2.003158571135129\n",
      "[EPOCH #13, step #2320] loss: 2.002972474133131\n",
      "[EPOCH #13, step #2322] loss: 2.0029369734814595\n",
      "[EPOCH #13, step #2324] loss: 2.0028220363842544\n",
      "[EPOCH #13, step #2326] loss: 2.002745593572616\n",
      "[EPOCH #13, step #2328] loss: 2.0024677847218952\n",
      "[EPOCH #13, step #2330] loss: 2.002339042956509\n",
      "[EPOCH #13, step #2332] loss: 2.0023333812240263\n",
      "[EPOCH #13, step #2334] loss: 2.002381517187686\n",
      "[EPOCH #13, step #2336] loss: 2.0024615485391712\n",
      "[EPOCH #13, step #2338] loss: 2.0024289516059186\n",
      "[EPOCH #13, step #2340] loss: 2.0024534268849736\n",
      "[EPOCH #13, step #2342] loss: 2.002306597333559\n",
      "[EPOCH #13, step #2344] loss: 2.0023071181799557\n",
      "[EPOCH #13, step #2346] loss: 2.0023855389967644\n",
      "[EPOCH #13, step #2348] loss: 2.0022216217727955\n",
      "[EPOCH #13, step #2350] loss: 2.0019555418403137\n",
      "[EPOCH #13, step #2352] loss: 2.0020659066138244\n",
      "[EPOCH #13, step #2354] loss: 2.0020076094159656\n",
      "[EPOCH #13, step #2356] loss: 2.001960985024298\n",
      "[EPOCH #13, step #2358] loss: 2.001807100290765\n",
      "[EPOCH #13, step #2360] loss: 2.001942250396376\n",
      "[EPOCH #13, step #2362] loss: 2.002039086349526\n",
      "[EPOCH #13, step #2364] loss: 2.001993249989967\n",
      "[EPOCH #13, step #2366] loss: 2.001864490349886\n",
      "[EPOCH #13, step #2368] loss: 2.002091614140293\n",
      "[EPOCH #13, step #2370] loss: 2.0019694809569732\n",
      "[EPOCH #13, step #2372] loss: 2.001944456731424\n",
      "[EPOCH #13, step #2374] loss: 2.0018940542120682\n",
      "[EPOCH #13, step #2376] loss: 2.0018587151043143\n",
      "[EPOCH #13, step #2378] loss: 2.0020655556454683\n",
      "[EPOCH #13, step #2380] loss: 2.0022088806451945\n",
      "[EPOCH #13, step #2382] loss: 2.0020570028143374\n",
      "[EPOCH #13, step #2384] loss: 2.00223133898881\n",
      "[EPOCH #13, step #2386] loss: 2.002191269552553\n",
      "[EPOCH #13, step #2388] loss: 2.002016474283505\n",
      "[EPOCH #13, step #2390] loss: 2.0019885285635564\n",
      "[EPOCH #13, step #2392] loss: 2.0022717857779293\n",
      "[EPOCH #13, step #2394] loss: 2.0021969017753523\n",
      "[EPOCH #13, step #2396] loss: 2.0021233233900233\n",
      "[EPOCH #13, step #2398] loss: 2.0020909895743864\n",
      "[EPOCH #13, step #2400] loss: 2.0024917809876834\n",
      "[EPOCH #13, step #2402] loss: 2.002510645664388\n",
      "[EPOCH #13, step #2404] loss: 2.002320080140524\n",
      "[EPOCH #13, step #2406] loss: 2.00202804370495\n",
      "[EPOCH #13, step #2408] loss: 2.002061958132863\n",
      "[EPOCH #13, step #2410] loss: 2.002283222148251\n",
      "[EPOCH #13, step #2412] loss: 2.002068928253389\n",
      "[EPOCH #13, step #2414] loss: 2.002190742927062\n",
      "[EPOCH #13, step #2416] loss: 2.0021110135856914\n",
      "[EPOCH #13, step #2418] loss: 2.0019203213040817\n",
      "[EPOCH #13, step #2420] loss: 2.001946608028546\n",
      "[EPOCH #13, step #2422] loss: 2.002085579361642\n",
      "[EPOCH #13, step #2424] loss: 2.002031930304065\n",
      "[EPOCH #13, step #2426] loss: 2.002118132317759\n",
      "[EPOCH #13, step #2428] loss: 2.002138920603784\n",
      "[EPOCH #13, step #2430] loss: 2.0021552329983354\n",
      "[EPOCH #13, step #2432] loss: 2.001946280142725\n",
      "[EPOCH #13, step #2434] loss: 2.001964907332857\n",
      "[EPOCH #13, step #2436] loss: 2.0021139134820682\n",
      "[EPOCH #13, step #2438] loss: 2.0020919881819115\n",
      "[EPOCH #13, step #2440] loss: 2.0020694502647274\n",
      "[EPOCH #13, step #2442] loss: 2.0019773966554633\n",
      "[EPOCH #13, step #2444] loss: 2.0019034756229455\n",
      "[EPOCH #13, step #2446] loss: 2.0018122025202576\n",
      "[EPOCH #13, step #2448] loss: 2.0018880844797686\n",
      "[EPOCH #13, step #2450] loss: 2.0014867025801037\n",
      "[EPOCH #13, step #2452] loss: 2.0012399724100347\n",
      "[EPOCH #13, step #2454] loss: 2.001074405163223\n",
      "[EPOCH #13, step #2456] loss: 2.000938860730616\n",
      "[EPOCH #13, step #2458] loss: 2.000961305650088\n",
      "[EPOCH #13, step #2460] loss: 2.001107102339464\n",
      "[EPOCH #13, step #2462] loss: 2.0010628194475966\n",
      "[EPOCH #13, step #2464] loss: 2.0010515066479573\n",
      "[EPOCH #13, step #2466] loss: 2.000897264886492\n",
      "[EPOCH #13, step #2468] loss: 2.000936519042255\n",
      "[EPOCH #13, step #2470] loss: 2.0010633969393785\n",
      "[EPOCH #13, step #2472] loss: 2.001098272870824\n",
      "[EPOCH #13, step #2474] loss: 2.0012716313082763\n",
      "[EPOCH #13, step #2476] loss: 2.0011306431296374\n",
      "[EPOCH #13, step #2478] loss: 2.001117653979463\n",
      "[EPOCH #13, step #2480] loss: 2.0008718011745374\n",
      "[EPOCH #13, step #2482] loss: 2.0011026768544196\n",
      "[EPOCH #13, step #2484] loss: 2.0010466010997474\n",
      "[EPOCH #13, step #2486] loss: 2.0014607243428615\n",
      "[EPOCH #13, step #2488] loss: 2.0014113749112887\n",
      "[EPOCH #13, step #2490] loss: 2.0013695456617\n",
      "[EPOCH #13, step #2492] loss: 2.0010908543704935\n",
      "[EPOCH #13, step #2494] loss: 2.000964999628927\n",
      "[EPOCH #13, step #2496] loss: 2.000729079097569\n",
      "[EPOCH #13, step #2498] loss: 2.000667535242628\n",
      "[EPOCH #13, elapsed time: 6615.599[sec]] loss: 2.0005969812870026\n",
      "[EPOCH #14, step #0] loss: 1.741181492805481\n",
      "[EPOCH #14, step #2] loss: 1.86746346950531\n",
      "[EPOCH #14, step #4] loss: 1.954421305656433\n",
      "[EPOCH #14, step #6] loss: 1.9129016058785575\n",
      "[EPOCH #14, step #8] loss: 1.9011386103100247\n",
      "[EPOCH #14, step #10] loss: 1.8792839050292969\n",
      "[EPOCH #14, step #12] loss: 1.9228896911327655\n",
      "[EPOCH #14, step #14] loss: 1.927183977762858\n",
      "[EPOCH #14, step #16] loss: 1.9258331130532658\n",
      "[EPOCH #14, step #18] loss: 1.9472689252150686\n",
      "[EPOCH #14, step #20] loss: 1.9483447926385062\n",
      "[EPOCH #14, step #22] loss: 1.990179875622625\n",
      "[EPOCH #14, step #24] loss: 1.9898150205612182\n",
      "[EPOCH #14, step #26] loss: 1.996887697113885\n",
      "[EPOCH #14, step #28] loss: 2.001227276078586\n",
      "[EPOCH #14, step #30] loss: 1.9955281749848397\n",
      "[EPOCH #14, step #32] loss: 1.989030086632931\n",
      "[EPOCH #14, step #34] loss: 1.9842973470687866\n",
      "[EPOCH #14, step #36] loss: 1.976052094150234\n",
      "[EPOCH #14, step #38] loss: 1.965970250276419\n",
      "[EPOCH #14, step #40] loss: 1.9592207960966157\n",
      "[EPOCH #14, step #42] loss: 1.9480281236559847\n",
      "[EPOCH #14, step #44] loss: 1.9513394408755833\n",
      "[EPOCH #14, step #46] loss: 1.9429273630710358\n",
      "[EPOCH #14, step #48] loss: 1.9393849421520621\n",
      "[EPOCH #14, step #50] loss: 1.942686637242635\n",
      "[EPOCH #14, step #52] loss: 1.9364111873338807\n",
      "[EPOCH #14, step #54] loss: 1.9448832468553023\n",
      "[EPOCH #14, step #56] loss: 1.9564442969205087\n",
      "[EPOCH #14, step #58] loss: 1.9430435411000655\n",
      "[EPOCH #14, step #60] loss: 1.9537959900058683\n",
      "[EPOCH #14, step #62] loss: 1.9477127866139488\n",
      "[EPOCH #14, step #64] loss: 1.9532816831882183\n",
      "[EPOCH #14, step #66] loss: 1.9457128314829584\n",
      "[EPOCH #14, step #68] loss: 1.9439648458923118\n",
      "[EPOCH #14, step #70] loss: 1.9459197286149146\n",
      "[EPOCH #14, step #72] loss: 1.9461809200783298\n",
      "[EPOCH #14, step #74] loss: 1.9466504685084025\n",
      "[EPOCH #14, step #76] loss: 1.9458893104033037\n",
      "[EPOCH #14, step #78] loss: 1.9466475821748566\n",
      "[EPOCH #14, step #80] loss: 1.9500241426774014\n",
      "[EPOCH #14, step #82] loss: 1.9518558935946728\n",
      "[EPOCH #14, step #84] loss: 1.9450432833503275\n",
      "[EPOCH #14, step #86] loss: 1.9486032491442802\n",
      "[EPOCH #14, step #88] loss: 1.9474927776315238\n",
      "[EPOCH #14, step #90] loss: 1.9413893249008682\n",
      "[EPOCH #14, step #92] loss: 1.9420215442616453\n",
      "[EPOCH #14, step #94] loss: 1.947254769425643\n",
      "[EPOCH #14, step #96] loss: 1.9558542180307132\n",
      "[EPOCH #14, step #98] loss: 1.9614574271019058\n",
      "[EPOCH #14, step #100] loss: 1.9704700944447282\n",
      "[EPOCH #14, step #102] loss: 1.9691551310344808\n",
      "[EPOCH #14, step #104] loss: 1.9629047212146578\n",
      "[EPOCH #14, step #106] loss: 1.9594598540635866\n",
      "[EPOCH #14, step #108] loss: 1.9553965133264524\n",
      "[EPOCH #14, step #110] loss: 1.9549083344571225\n",
      "[EPOCH #14, step #112] loss: 1.9545892160550682\n",
      "[EPOCH #14, step #114] loss: 1.957342264963233\n",
      "[EPOCH #14, step #116] loss: 1.9560335283605461\n",
      "[EPOCH #14, step #118] loss: 1.9515692276113175\n",
      "[EPOCH #14, step #120] loss: 1.9535150370321983\n",
      "[EPOCH #14, step #122] loss: 1.9548897336168987\n",
      "[EPOCH #14, step #124] loss: 1.9530904178619384\n",
      "[EPOCH #14, step #126] loss: 1.9511663481945127\n",
      "[EPOCH #14, step #128] loss: 1.9462823110033376\n",
      "[EPOCH #14, step #130] loss: 1.9473903561366424\n",
      "[EPOCH #14, step #132] loss: 1.9453497399064832\n",
      "[EPOCH #14, step #134] loss: 1.9421023925145466\n",
      "[EPOCH #14, step #136] loss: 1.9439664844178806\n",
      "[EPOCH #14, step #138] loss: 1.9428448033847396\n",
      "[EPOCH #14, step #140] loss: 1.9432578154489504\n",
      "[EPOCH #14, step #142] loss: 1.9418564076190228\n",
      "[EPOCH #14, step #144] loss: 1.9452145740903657\n",
      "[EPOCH #14, step #146] loss: 1.9437354438158931\n",
      "[EPOCH #14, step #148] loss: 1.9431027806045225\n",
      "[EPOCH #14, step #150] loss: 1.9433571400231873\n",
      "[EPOCH #14, step #152] loss: 1.9404013951619465\n",
      "[EPOCH #14, step #154] loss: 1.9357303119474842\n",
      "[EPOCH #14, step #156] loss: 1.9347324902844276\n",
      "[EPOCH #14, step #158] loss: 1.9359930918651558\n",
      "[EPOCH #14, step #160] loss: 1.9354519955119731\n",
      "[EPOCH #14, step #162] loss: 1.936296931805055\n",
      "[EPOCH #14, step #164] loss: 1.9358971530740912\n",
      "[EPOCH #14, step #166] loss: 1.9356535873013343\n",
      "[EPOCH #14, step #168] loss: 1.9349196965877826\n",
      "[EPOCH #14, step #170] loss: 1.929445975705197\n",
      "[EPOCH #14, step #172] loss: 1.9280541914735916\n",
      "[EPOCH #14, step #174] loss: 1.9303986079352242\n",
      "[EPOCH #14, step #176] loss: 1.927190832499057\n",
      "[EPOCH #14, step #178] loss: 1.925557237097671\n",
      "[EPOCH #14, step #180] loss: 1.9235933590989087\n",
      "[EPOCH #14, step #182] loss: 1.9238258202870686\n",
      "[EPOCH #14, step #184] loss: 1.9224135759714487\n",
      "[EPOCH #14, step #186] loss: 1.9223110886181103\n",
      "[EPOCH #14, step #188] loss: 1.9164358036858695\n",
      "[EPOCH #14, step #190] loss: 1.916121012253287\n",
      "[EPOCH #14, step #192] loss: 1.9177938582365994\n",
      "[EPOCH #14, step #194] loss: 1.919545519657624\n",
      "[EPOCH #14, step #196] loss: 1.9177645711124245\n",
      "[EPOCH #14, step #198] loss: 1.918721194842353\n",
      "[EPOCH #14, step #200] loss: 1.920525379441864\n",
      "[EPOCH #14, step #202] loss: 1.9204545232462766\n",
      "[EPOCH #14, step #204] loss: 1.9217740425249425\n",
      "[EPOCH #14, step #206] loss: 1.9215065189029858\n",
      "[EPOCH #14, step #208] loss: 1.923543622048848\n",
      "[EPOCH #14, step #210] loss: 1.9219384453307962\n",
      "[EPOCH #14, step #212] loss: 1.923547456521943\n",
      "[EPOCH #14, step #214] loss: 1.924155562977458\n",
      "[EPOCH #14, step #216] loss: 1.9242435424558577\n",
      "[EPOCH #14, step #218] loss: 1.9230417677256615\n",
      "[EPOCH #14, step #220] loss: 1.924467706572416\n",
      "[EPOCH #14, step #222] loss: 1.9237390494667361\n",
      "[EPOCH #14, step #224] loss: 1.9230679925282796\n",
      "[EPOCH #14, step #226] loss: 1.9220722661669558\n",
      "[EPOCH #14, step #228] loss: 1.9179820358492923\n",
      "[EPOCH #14, step #230] loss: 1.9170687384419627\n",
      "[EPOCH #14, step #232] loss: 1.914881096889021\n",
      "[EPOCH #14, step #234] loss: 1.916103538046492\n",
      "[EPOCH #14, step #236] loss: 1.9146010890791687\n",
      "[EPOCH #14, step #238] loss: 1.913176564990726\n",
      "[EPOCH #14, step #240] loss: 1.9168782377638758\n",
      "[EPOCH #14, step #242] loss: 1.9155838710290414\n",
      "[EPOCH #14, step #244] loss: 1.914003864599734\n",
      "[EPOCH #14, step #246] loss: 1.9149102083584557\n",
      "[EPOCH #14, step #248] loss: 1.9149095255687054\n",
      "[EPOCH #14, step #250] loss: 1.9162996679663182\n",
      "[EPOCH #14, step #252] loss: 1.91905890434627\n",
      "[EPOCH #14, step #254] loss: 1.9180329313465194\n",
      "[EPOCH #14, step #256] loss: 1.918062470766357\n",
      "[EPOCH #14, step #258] loss: 1.9169106257928383\n",
      "[EPOCH #14, step #260] loss: 1.9159675745214997\n",
      "[EPOCH #14, step #262] loss: 1.9157613860337\n",
      "[EPOCH #14, step #264] loss: 1.9133424619458756\n",
      "[EPOCH #14, step #266] loss: 1.9124142842346363\n",
      "[EPOCH #14, step #268] loss: 1.913404406668085\n",
      "[EPOCH #14, step #270] loss: 1.913079779966291\n",
      "[EPOCH #14, step #272] loss: 1.911019844886584\n",
      "[EPOCH #14, step #274] loss: 1.910446158322421\n",
      "[EPOCH #14, step #276] loss: 1.9104254482455203\n",
      "[EPOCH #14, step #278] loss: 1.910140672464952\n",
      "[EPOCH #14, step #280] loss: 1.9118824166335244\n",
      "[EPOCH #14, step #282] loss: 1.9101490881754737\n",
      "[EPOCH #14, step #284] loss: 1.9119281927744547\n",
      "[EPOCH #14, step #286] loss: 1.9132695044374632\n",
      "[EPOCH #14, step #288] loss: 1.912891289767097\n",
      "[EPOCH #14, step #290] loss: 1.9127787982475306\n",
      "[EPOCH #14, step #292] loss: 1.9125218403624187\n",
      "[EPOCH #14, step #294] loss: 1.9104931273702848\n",
      "[EPOCH #14, step #296] loss: 1.9102119139147928\n",
      "[EPOCH #14, step #298] loss: 1.9106024687106793\n",
      "[EPOCH #14, step #300] loss: 1.9096278320515274\n",
      "[EPOCH #14, step #302] loss: 1.9116312009666618\n",
      "[EPOCH #14, step #304] loss: 1.9102931304056137\n",
      "[EPOCH #14, step #306] loss: 1.910798442868534\n",
      "[EPOCH #14, step #308] loss: 1.9128233294656747\n",
      "[EPOCH #14, step #310] loss: 1.9129527726740698\n",
      "[EPOCH #14, step #312] loss: 1.9134529821408062\n",
      "[EPOCH #14, step #314] loss: 1.9134567658106485\n",
      "[EPOCH #14, step #316] loss: 1.9148642426409557\n",
      "[EPOCH #14, step #318] loss: 1.9165632448226306\n",
      "[EPOCH #14, step #320] loss: 1.9186012477518242\n",
      "[EPOCH #14, step #322] loss: 1.9196894087658578\n",
      "[EPOCH #14, step #324] loss: 1.916638706280635\n",
      "[EPOCH #14, step #326] loss: 1.9159030181552292\n",
      "[EPOCH #14, step #328] loss: 1.9174354797438649\n",
      "[EPOCH #14, step #330] loss: 1.9159081140673773\n",
      "[EPOCH #14, step #332] loss: 1.9154077295784477\n",
      "[EPOCH #14, step #334] loss: 1.9173030038378132\n",
      "[EPOCH #14, step #336] loss: 1.9166407475485645\n",
      "[EPOCH #14, step #338] loss: 1.9181021684038955\n",
      "[EPOCH #14, step #340] loss: 1.9190909670245262\n",
      "[EPOCH #14, step #342] loss: 1.9190809379166138\n",
      "[EPOCH #14, step #344] loss: 1.9180337397948555\n",
      "[EPOCH #14, step #346] loss: 1.9165538322685087\n",
      "[EPOCH #14, step #348] loss: 1.9178042586006887\n",
      "[EPOCH #14, step #350] loss: 1.918262149533655\n",
      "[EPOCH #14, step #352] loss: 1.9191176803524028\n",
      "[EPOCH #14, step #354] loss: 1.9192367600723053\n",
      "[EPOCH #14, step #356] loss: 1.9177668017833507\n",
      "[EPOCH #14, step #358] loss: 1.9182850281840247\n",
      "[EPOCH #14, step #360] loss: 1.9182343644778814\n",
      "[EPOCH #14, step #362] loss: 1.9177745419757097\n",
      "[EPOCH #14, step #364] loss: 1.9168833347216045\n",
      "[EPOCH #14, step #366] loss: 1.9155409378316812\n",
      "[EPOCH #14, step #368] loss: 1.9165296632099926\n",
      "[EPOCH #14, step #370] loss: 1.9170273356039247\n",
      "[EPOCH #14, step #372] loss: 1.9179039432919378\n",
      "[EPOCH #14, step #374] loss: 1.918656111717224\n",
      "[EPOCH #14, step #376] loss: 1.918137708772715\n",
      "[EPOCH #14, step #378] loss: 1.9175843377855648\n",
      "[EPOCH #14, step #380] loss: 1.9171437362986288\n",
      "[EPOCH #14, step #382] loss: 1.9188618438984644\n",
      "[EPOCH #14, step #384] loss: 1.91911026812219\n",
      "[EPOCH #14, step #386] loss: 1.919953531689114\n",
      "[EPOCH #14, step #388] loss: 1.9181879761899345\n",
      "[EPOCH #14, step #390] loss: 1.9193843953749712\n",
      "[EPOCH #14, step #392] loss: 1.9207517679107704\n",
      "[EPOCH #14, step #394] loss: 1.9218712480762337\n",
      "[EPOCH #14, step #396] loss: 1.9229390636199066\n",
      "[EPOCH #14, step #398] loss: 1.922493246563694\n",
      "[EPOCH #14, step #400] loss: 1.920949760815152\n",
      "[EPOCH #14, step #402] loss: 1.9208380729329793\n",
      "[EPOCH #14, step #404] loss: 1.9201411579862053\n",
      "[EPOCH #14, step #406] loss: 1.9200300599198963\n",
      "[EPOCH #14, step #408] loss: 1.9209277682316042\n",
      "[EPOCH #14, step #410] loss: 1.9217533653379937\n",
      "[EPOCH #14, step #412] loss: 1.9204295305016543\n",
      "[EPOCH #14, step #414] loss: 1.9199626290654561\n",
      "[EPOCH #14, step #416] loss: 1.9188316300046815\n",
      "[EPOCH #14, step #418] loss: 1.919040586612674\n",
      "[EPOCH #14, step #420] loss: 1.9198784697933604\n",
      "[EPOCH #14, step #422] loss: 1.9193418722062527\n",
      "[EPOCH #14, step #424] loss: 1.921524380796096\n",
      "[EPOCH #14, step #426] loss: 1.9222150948901924\n",
      "[EPOCH #14, step #428] loss: 1.9234675432974364\n",
      "[EPOCH #14, step #430] loss: 1.9228498670175291\n",
      "[EPOCH #14, step #432] loss: 1.9236229839831522\n",
      "[EPOCH #14, step #434] loss: 1.9252571281345412\n",
      "[EPOCH #14, step #436] loss: 1.9261158494709285\n",
      "[EPOCH #14, step #438] loss: 1.927874882834919\n",
      "[EPOCH #14, step #440] loss: 1.9295515111244184\n",
      "[EPOCH #14, step #442] loss: 1.9294318940246618\n",
      "[EPOCH #14, step #444] loss: 1.92884663008572\n",
      "[EPOCH #14, step #446] loss: 1.9299113683785902\n",
      "[EPOCH #14, step #448] loss: 1.9307452957985927\n",
      "[EPOCH #14, step #450] loss: 1.930203605649741\n",
      "[EPOCH #14, step #452] loss: 1.930018741563456\n",
      "[EPOCH #14, step #454] loss: 1.9297191808511922\n",
      "[EPOCH #14, step #456] loss: 1.9289013768181498\n",
      "[EPOCH #14, step #458] loss: 1.9299677174075756\n",
      "[EPOCH #14, step #460] loss: 1.9286014164864629\n",
      "[EPOCH #14, step #462] loss: 1.9274154945274666\n",
      "[EPOCH #14, step #464] loss: 1.9266589715916624\n",
      "[EPOCH #14, step #466] loss: 1.926815307880622\n",
      "[EPOCH #14, step #468] loss: 1.928080550388995\n",
      "[EPOCH #14, step #470] loss: 1.9272095564824\n",
      "[EPOCH #14, step #472] loss: 1.9257005798388234\n",
      "[EPOCH #14, step #474] loss: 1.924726360722592\n",
      "[EPOCH #14, step #476] loss: 1.924493045926844\n",
      "[EPOCH #14, step #478] loss: 1.9235422529109087\n",
      "[EPOCH #14, step #480] loss: 1.923686606968267\n",
      "[EPOCH #14, step #482] loss: 1.9218440857980068\n",
      "[EPOCH #14, step #484] loss: 1.9216431917603483\n",
      "[EPOCH #14, step #486] loss: 1.9212463565430846\n",
      "[EPOCH #14, step #488] loss: 1.9219920671790656\n",
      "[EPOCH #14, step #490] loss: 1.9217591526066455\n",
      "[EPOCH #14, step #492] loss: 1.9217946227133638\n",
      "[EPOCH #14, step #494] loss: 1.921148496926433\n",
      "[EPOCH #14, step #496] loss: 1.9204296060730994\n",
      "[EPOCH #14, step #498] loss: 1.9208982936843841\n",
      "[EPOCH #14, step #500] loss: 1.9200537685386674\n",
      "[EPOCH #14, step #502] loss: 1.919941060348723\n",
      "[EPOCH #14, step #504] loss: 1.9198103472737982\n",
      "[EPOCH #14, step #506] loss: 1.919888465127061\n",
      "[EPOCH #14, step #508] loss: 1.9210414973129692\n",
      "[EPOCH #14, step #510] loss: 1.920765873737298\n",
      "[EPOCH #14, step #512] loss: 1.921344659714206\n",
      "[EPOCH #14, step #514] loss: 1.9216172257673394\n",
      "[EPOCH #14, step #516] loss: 1.9206735474459207\n",
      "[EPOCH #14, step #518] loss: 1.9209561816529732\n",
      "[EPOCH #14, step #520] loss: 1.9209716580879665\n",
      "[EPOCH #14, step #522] loss: 1.9192171133271139\n",
      "[EPOCH #14, step #524] loss: 1.9187244842165991\n",
      "[EPOCH #14, step #526] loss: 1.9189560594323465\n",
      "[EPOCH #14, step #528] loss: 1.917818208948651\n",
      "[EPOCH #14, step #530] loss: 1.9190088263563743\n",
      "[EPOCH #14, step #532] loss: 1.9191763300385754\n",
      "[EPOCH #14, step #534] loss: 1.919707583266998\n",
      "[EPOCH #14, step #536] loss: 1.920007497016722\n",
      "[EPOCH #14, step #538] loss: 1.919299973627632\n",
      "[EPOCH #14, step #540] loss: 1.9189045098704904\n",
      "[EPOCH #14, step #542] loss: 1.9176643441395207\n",
      "[EPOCH #14, step #544] loss: 1.9184250391951394\n",
      "[EPOCH #14, step #546] loss: 1.9183248416597272\n",
      "[EPOCH #14, step #548] loss: 1.9178606200087918\n",
      "[EPOCH #14, step #550] loss: 1.9177526609867324\n",
      "[EPOCH #14, step #552] loss: 1.9180224737250136\n",
      "[EPOCH #14, step #554] loss: 1.9177658220669171\n",
      "[EPOCH #14, step #556] loss: 1.9177579869059729\n",
      "[EPOCH #14, step #558] loss: 1.9178705607842461\n",
      "[EPOCH #14, step #560] loss: 1.9187277897581485\n",
      "[EPOCH #14, step #562] loss: 1.9198611798972474\n",
      "[EPOCH #14, step #564] loss: 1.9182747927387205\n",
      "[EPOCH #14, step #566] loss: 1.9183146718107624\n",
      "[EPOCH #14, step #568] loss: 1.9175448828296628\n",
      "[EPOCH #14, step #570] loss: 1.9184054752156112\n",
      "[EPOCH #14, step #572] loss: 1.9183488591179174\n",
      "[EPOCH #14, step #574] loss: 1.9181602150460948\n",
      "[EPOCH #14, step #576] loss: 1.9183392973045337\n",
      "[EPOCH #14, step #578] loss: 1.9176158657963411\n",
      "[EPOCH #14, step #580] loss: 1.918208163699677\n",
      "[EPOCH #14, step #582] loss: 1.9188412916598967\n",
      "[EPOCH #14, step #584] loss: 1.9188922890231142\n",
      "[EPOCH #14, step #586] loss: 1.9192611736577048\n",
      "[EPOCH #14, step #588] loss: 1.9194481085435644\n",
      "[EPOCH #14, step #590] loss: 1.9191632791219024\n",
      "[EPOCH #14, step #592] loss: 1.9195558443841403\n",
      "[EPOCH #14, step #594] loss: 1.9191310197365383\n",
      "[EPOCH #14, step #596] loss: 1.9180849534982014\n",
      "[EPOCH #14, step #598] loss: 1.9167215318632047\n",
      "[EPOCH #14, step #600] loss: 1.9162168096186913\n",
      "[EPOCH #14, step #602] loss: 1.9155454592127508\n",
      "[EPOCH #14, step #604] loss: 1.9160737023865881\n",
      "[EPOCH #14, step #606] loss: 1.9173920557172923\n",
      "[EPOCH #14, step #608] loss: 1.9178976550673812\n",
      "[EPOCH #14, step #610] loss: 1.919458982402096\n",
      "[EPOCH #14, step #612] loss: 1.9197451856358017\n",
      "[EPOCH #14, step #614] loss: 1.9193694048780736\n",
      "[EPOCH #14, step #616] loss: 1.9203060422956073\n",
      "[EPOCH #14, step #618] loss: 1.921662090668193\n",
      "[EPOCH #14, step #620] loss: 1.9210166332226444\n",
      "[EPOCH #14, step #622] loss: 1.9207083706297041\n",
      "[EPOCH #14, step #624] loss: 1.9208230995178224\n",
      "[EPOCH #14, step #626] loss: 1.9204980760480037\n",
      "[EPOCH #14, step #628] loss: 1.919992338871918\n",
      "[EPOCH #14, step #630] loss: 1.9193256862945678\n",
      "[EPOCH #14, step #632] loss: 1.9190269808445308\n",
      "[EPOCH #14, step #634] loss: 1.9197135992876189\n",
      "[EPOCH #14, step #636] loss: 1.920371339309908\n",
      "[EPOCH #14, step #638] loss: 1.9203318846244395\n",
      "[EPOCH #14, step #640] loss: 1.919356547540138\n",
      "[EPOCH #14, step #642] loss: 1.9201576826546463\n",
      "[EPOCH #14, step #644] loss: 1.9212160282356794\n",
      "[EPOCH #14, step #646] loss: 1.9216939682569902\n",
      "[EPOCH #14, step #648] loss: 1.9232156517325638\n",
      "[EPOCH #14, step #650] loss: 1.9228028754851052\n",
      "[EPOCH #14, step #652] loss: 1.9233210632665965\n",
      "[EPOCH #14, step #654] loss: 1.9227122097524978\n",
      "[EPOCH #14, step #656] loss: 1.921642001542508\n",
      "[EPOCH #14, step #658] loss: 1.9211586127693627\n",
      "[EPOCH #14, step #660] loss: 1.921650935229303\n",
      "[EPOCH #14, step #662] loss: 1.920727169172077\n",
      "[EPOCH #14, step #664] loss: 1.9206428787762062\n",
      "[EPOCH #14, step #666] loss: 1.9203966818470648\n",
      "[EPOCH #14, step #668] loss: 1.920315275277792\n",
      "[EPOCH #14, step #670] loss: 1.9194355481783074\n",
      "[EPOCH #14, step #672] loss: 1.9188347348132424\n",
      "[EPOCH #14, step #674] loss: 1.9175039830031217\n",
      "[EPOCH #14, step #676] loss: 1.9172878980284427\n",
      "[EPOCH #14, step #678] loss: 1.9176493477575558\n",
      "[EPOCH #14, step #680] loss: 1.9181742776683073\n",
      "[EPOCH #14, step #682] loss: 1.9186031076604415\n",
      "[EPOCH #14, step #684] loss: 1.918487266032365\n",
      "[EPOCH #14, step #686] loss: 1.9190679403371687\n",
      "[EPOCH #14, step #688] loss: 1.9189189352387095\n",
      "[EPOCH #14, step #690] loss: 1.9197747079404839\n",
      "[EPOCH #14, step #692] loss: 1.9192368906813781\n",
      "[EPOCH #14, step #694] loss: 1.9181342443973899\n",
      "[EPOCH #14, step #696] loss: 1.9167541814500324\n",
      "[EPOCH #14, step #698] loss: 1.9165588180735729\n",
      "[EPOCH #14, step #700] loss: 1.916843699660689\n",
      "[EPOCH #14, step #702] loss: 1.917004352104274\n",
      "[EPOCH #14, step #704] loss: 1.9179737914538553\n",
      "[EPOCH #14, step #706] loss: 1.9186486633022908\n",
      "[EPOCH #14, step #708] loss: 1.918268781118568\n",
      "[EPOCH #14, step #710] loss: 1.9177203409782442\n",
      "[EPOCH #14, step #712] loss: 1.917926597561776\n",
      "[EPOCH #14, step #714] loss: 1.9177046939209625\n",
      "[EPOCH #14, step #716] loss: 1.9181277100178653\n",
      "[EPOCH #14, step #718] loss: 1.9169009051833596\n",
      "[EPOCH #14, step #720] loss: 1.916574195420031\n",
      "[EPOCH #14, step #722] loss: 1.9170578155939675\n",
      "[EPOCH #14, step #724] loss: 1.9172425487123688\n",
      "[EPOCH #14, step #726] loss: 1.9168237301801554\n",
      "[EPOCH #14, step #728] loss: 1.9170099678353518\n",
      "[EPOCH #14, step #730] loss: 1.9171055088943398\n",
      "[EPOCH #14, step #732] loss: 1.9167976228146728\n",
      "[EPOCH #14, step #734] loss: 1.9167556730257411\n",
      "[EPOCH #14, step #736] loss: 1.9171948026931431\n",
      "[EPOCH #14, step #738] loss: 1.9166497780925043\n",
      "[EPOCH #14, step #740] loss: 1.9168308836567578\n",
      "[EPOCH #14, step #742] loss: 1.9169415240332706\n",
      "[EPOCH #14, step #744] loss: 1.9162706781553742\n",
      "[EPOCH #14, step #746] loss: 1.916109908696319\n",
      "[EPOCH #14, step #748] loss: 1.9165482441478163\n",
      "[EPOCH #14, step #750] loss: 1.9163137853701169\n",
      "[EPOCH #14, step #752] loss: 1.9168086897329506\n",
      "[EPOCH #14, step #754] loss: 1.9160783502439789\n",
      "[EPOCH #14, step #756] loss: 1.9158081679237093\n",
      "[EPOCH #14, step #758] loss: 1.9152114152594204\n",
      "[EPOCH #14, step #760] loss: 1.9151403313397422\n",
      "[EPOCH #14, step #762] loss: 1.9148333335141523\n",
      "[EPOCH #14, step #764] loss: 1.9155454875596987\n",
      "[EPOCH #14, step #766] loss: 1.9156062573466495\n",
      "[EPOCH #14, step #768] loss: 1.9165902430741468\n",
      "[EPOCH #14, step #770] loss: 1.9160048995655026\n",
      "[EPOCH #14, step #772] loss: 1.9153425648789202\n",
      "[EPOCH #14, step #774] loss: 1.9154267435689127\n",
      "[EPOCH #14, step #776] loss: 1.915342384477073\n",
      "[EPOCH #14, step #778] loss: 1.9145587212926156\n",
      "[EPOCH #14, step #780] loss: 1.9141432919972379\n",
      "[EPOCH #14, step #782] loss: 1.9139255734391292\n",
      "[EPOCH #14, step #784] loss: 1.9137073222239307\n",
      "[EPOCH #14, step #786] loss: 1.9138214256439305\n",
      "[EPOCH #14, step #788] loss: 1.91311616302292\n",
      "[EPOCH #14, step #790] loss: 1.91264144433886\n",
      "[EPOCH #14, step #792] loss: 1.9124418427935164\n",
      "[EPOCH #14, step #794] loss: 1.9129394268839615\n",
      "[EPOCH #14, step #796] loss: 1.912928554763459\n",
      "[EPOCH #14, step #798] loss: 1.9139620100004653\n",
      "[EPOCH #14, step #800] loss: 1.9144130531470576\n",
      "[EPOCH #14, step #802] loss: 1.9141587926026151\n",
      "[EPOCH #14, step #804] loss: 1.914581645053366\n",
      "[EPOCH #14, step #806] loss: 1.914441801506052\n",
      "[EPOCH #14, step #808] loss: 1.9149989672143322\n",
      "[EPOCH #14, step #810] loss: 1.9159045848540694\n",
      "[EPOCH #14, step #812] loss: 1.9160132620753985\n",
      "[EPOCH #14, step #814] loss: 1.9155159578732919\n",
      "[EPOCH #14, step #816] loss: 1.9162412988366229\n",
      "[EPOCH #14, step #818] loss: 1.9169953672877162\n",
      "[EPOCH #14, step #820] loss: 1.9169731299856838\n",
      "[EPOCH #14, step #822] loss: 1.916469005014598\n",
      "[EPOCH #14, step #824] loss: 1.9168494137850676\n",
      "[EPOCH #14, step #826] loss: 1.9168660028093238\n",
      "[EPOCH #14, step #828] loss: 1.9165128524110746\n",
      "[EPOCH #14, step #830] loss: 1.9163007261377236\n",
      "[EPOCH #14, step #832] loss: 1.915771404234301\n",
      "[EPOCH #14, step #834] loss: 1.9160942163296089\n",
      "[EPOCH #14, step #836] loss: 1.9170025702445739\n",
      "[EPOCH #14, step #838] loss: 1.9172275562252277\n",
      "[EPOCH #14, step #840] loss: 1.9177139172514326\n",
      "[EPOCH #14, step #842] loss: 1.9170037066809222\n",
      "[EPOCH #14, step #844] loss: 1.9162945222572463\n",
      "[EPOCH #14, step #846] loss: 1.9158314182175655\n",
      "[EPOCH #14, step #848] loss: 1.9154444103106172\n",
      "[EPOCH #14, step #850] loss: 1.9158237563176945\n",
      "[EPOCH #14, step #852] loss: 1.9154039287343534\n",
      "[EPOCH #14, step #854] loss: 1.9149240435215464\n",
      "[EPOCH #14, step #856] loss: 1.915683569680017\n",
      "[EPOCH #14, step #858] loss: 1.915766060282937\n",
      "[EPOCH #14, step #860] loss: 1.9161905525176506\n",
      "[EPOCH #14, step #862] loss: 1.9167237314951378\n",
      "[EPOCH #14, step #864] loss: 1.9171036305455114\n",
      "[EPOCH #14, step #866] loss: 1.916518151141368\n",
      "[EPOCH #14, step #868] loss: 1.916056040378654\n",
      "[EPOCH #14, step #870] loss: 1.9155972944198327\n",
      "[EPOCH #14, step #872] loss: 1.9155943976781349\n",
      "[EPOCH #14, step #874] loss: 1.9155678433009555\n",
      "[EPOCH #14, step #876] loss: 1.9150188719533052\n",
      "[EPOCH #14, step #878] loss: 1.9150234477104995\n",
      "[EPOCH #14, step #880] loss: 1.9157906083324576\n",
      "[EPOCH #14, step #882] loss: 1.9152190250556573\n",
      "[EPOCH #14, step #884] loss: 1.9158544227901826\n",
      "[EPOCH #14, step #886] loss: 1.9163482124668367\n",
      "[EPOCH #14, step #888] loss: 1.916394357606182\n",
      "[EPOCH #14, step #890] loss: 1.916498963011368\n",
      "[EPOCH #14, step #892] loss: 1.9171137589489893\n",
      "[EPOCH #14, step #894] loss: 1.9177658364759478\n",
      "[EPOCH #14, step #896] loss: 1.9179318627651984\n",
      "[EPOCH #14, step #898] loss: 1.9187556555592047\n",
      "[EPOCH #14, step #900] loss: 1.9187321725087478\n",
      "[EPOCH #14, step #902] loss: 1.9185661643842526\n",
      "[EPOCH #14, step #904] loss: 1.918137638608395\n",
      "[EPOCH #14, step #906] loss: 1.918600552794426\n",
      "[EPOCH #14, step #908] loss: 1.9185706694396285\n",
      "[EPOCH #14, step #910] loss: 1.9183659473706025\n",
      "[EPOCH #14, step #912] loss: 1.9176357244217905\n",
      "[EPOCH #14, step #914] loss: 1.9175022714125003\n",
      "[EPOCH #14, step #916] loss: 1.918454184786964\n",
      "[EPOCH #14, step #918] loss: 1.9178669014226106\n",
      "[EPOCH #14, step #920] loss: 1.9177345990099166\n",
      "[EPOCH #14, step #922] loss: 1.917998328756537\n",
      "[EPOCH #14, step #924] loss: 1.9171998350040333\n",
      "[EPOCH #14, step #926] loss: 1.9174708782533483\n",
      "[EPOCH #14, step #928] loss: 1.9171979739155272\n",
      "[EPOCH #14, step #930] loss: 1.9171311218935745\n",
      "[EPOCH #14, step #932] loss: 1.9180832472644818\n",
      "[EPOCH #14, step #934] loss: 1.9183100175092564\n",
      "[EPOCH #14, step #936] loss: 1.918667065677419\n",
      "[EPOCH #14, step #938] loss: 1.9183777085762308\n",
      "[EPOCH #14, step #940] loss: 1.9177336690276385\n",
      "[EPOCH #14, step #942] loss: 1.9171044941545166\n",
      "[EPOCH #14, step #944] loss: 1.9171122548441408\n",
      "[EPOCH #14, step #946] loss: 1.91667420786059\n",
      "[EPOCH #14, step #948] loss: 1.916043030826259\n",
      "[EPOCH #14, step #950] loss: 1.916341704274327\n",
      "[EPOCH #14, step #952] loss: 1.9162131475376558\n",
      "[EPOCH #14, step #954] loss: 1.9164241044309127\n",
      "[EPOCH #14, step #956] loss: 1.9160988684607398\n",
      "[EPOCH #14, step #958] loss: 1.9159796392084785\n",
      "[EPOCH #14, step #960] loss: 1.9163925214811122\n",
      "[EPOCH #14, step #962] loss: 1.9160103778106277\n",
      "[EPOCH #14, step #964] loss: 1.915364571803592\n",
      "[EPOCH #14, step #966] loss: 1.9148493540447278\n",
      "[EPOCH #14, step #968] loss: 1.915503412331344\n",
      "[EPOCH #14, step #970] loss: 1.915272748310706\n",
      "[EPOCH #14, step #972] loss: 1.9155887081101153\n",
      "[EPOCH #14, step #974] loss: 1.9150228061431493\n",
      "[EPOCH #14, step #976] loss: 1.9149421613316453\n",
      "[EPOCH #14, step #978] loss: 1.9145860029070565\n",
      "[EPOCH #14, step #980] loss: 1.9152422767895807\n",
      "[EPOCH #14, step #982] loss: 1.9147889836030962\n",
      "[EPOCH #14, step #984] loss: 1.9147022269098892\n",
      "[EPOCH #14, step #986] loss: 1.914722448303586\n",
      "[EPOCH #14, step #988] loss: 1.9152216317077497\n",
      "[EPOCH #14, step #990] loss: 1.915334705748303\n",
      "[EPOCH #14, step #992] loss: 1.9155118997243477\n",
      "[EPOCH #14, step #994] loss: 1.915342996108472\n",
      "[EPOCH #14, step #996] loss: 1.9150203155538623\n",
      "[EPOCH #14, step #998] loss: 1.915066816546657\n",
      "[EPOCH #14, step #1000] loss: 1.9153288481356976\n",
      "[EPOCH #14, step #1002] loss: 1.9157274968602722\n",
      "[EPOCH #14, step #1004] loss: 1.9155783463473344\n",
      "[EPOCH #14, step #1006] loss: 1.915073647636406\n",
      "[EPOCH #14, step #1008] loss: 1.915405790680582\n",
      "[EPOCH #14, step #1010] loss: 1.9146665667214096\n",
      "[EPOCH #14, step #1012] loss: 1.9152910418712845\n",
      "[EPOCH #14, step #1014] loss: 1.915330799107481\n",
      "[EPOCH #14, step #1016] loss: 1.9153986892634554\n",
      "[EPOCH #14, step #1018] loss: 1.9152891811374593\n",
      "[EPOCH #14, step #1020] loss: 1.9152104903621843\n",
      "[EPOCH #14, step #1022] loss: 1.915054424067746\n",
      "[EPOCH #14, step #1024] loss: 1.9149239559871394\n",
      "[EPOCH #14, step #1026] loss: 1.9150322406410358\n",
      "[EPOCH #14, step #1028] loss: 1.9149019998526318\n",
      "[EPOCH #14, step #1030] loss: 1.914668133372132\n",
      "[EPOCH #14, step #1032] loss: 1.9143435103387823\n",
      "[EPOCH #14, step #1034] loss: 1.9141057381883335\n",
      "[EPOCH #14, step #1036] loss: 1.9142579595516136\n",
      "[EPOCH #14, step #1038] loss: 1.9148237159093833\n",
      "[EPOCH #14, step #1040] loss: 1.9148200746915527\n",
      "[EPOCH #14, step #1042] loss: 1.9150090301025404\n",
      "[EPOCH #14, step #1044] loss: 1.9147714822486257\n",
      "[EPOCH #14, step #1046] loss: 1.9146429191004581\n",
      "[EPOCH #14, step #1048] loss: 1.9153266854236193\n",
      "[EPOCH #14, step #1050] loss: 1.9151109674791287\n",
      "[EPOCH #14, step #1052] loss: 1.9152440318354853\n",
      "[EPOCH #14, step #1054] loss: 1.9148692068895456\n",
      "[EPOCH #14, step #1056] loss: 1.914083986544\n",
      "[EPOCH #14, step #1058] loss: 1.913460403934079\n",
      "[EPOCH #14, step #1060] loss: 1.9131748353839482\n",
      "[EPOCH #14, step #1062] loss: 1.9132028925788929\n",
      "[EPOCH #14, step #1064] loss: 1.9136283040606359\n",
      "[EPOCH #14, step #1066] loss: 1.9132334844129826\n",
      "[EPOCH #14, step #1068] loss: 1.9138143022446235\n",
      "[EPOCH #14, step #1070] loss: 1.91366074143115\n",
      "[EPOCH #14, step #1072] loss: 1.914224698514663\n",
      "[EPOCH #14, step #1074] loss: 1.9144822160587753\n",
      "[EPOCH #14, step #1076] loss: 1.914428762738751\n",
      "[EPOCH #14, step #1078] loss: 1.9147966928897466\n",
      "[EPOCH #14, step #1080] loss: 1.9143920639507424\n",
      "[EPOCH #14, step #1082] loss: 1.9138903833602383\n",
      "[EPOCH #14, step #1084] loss: 1.9146024888561617\n",
      "[EPOCH #14, step #1086] loss: 1.9143443700909724\n",
      "[EPOCH #14, step #1088] loss: 1.913797838957185\n",
      "[EPOCH #14, step #1090] loss: 1.9133569293891914\n",
      "[EPOCH #14, step #1092] loss: 1.9132211081826784\n",
      "[EPOCH #14, step #1094] loss: 1.913462740645561\n",
      "[EPOCH #14, step #1096] loss: 1.9133595685689364\n",
      "[EPOCH #14, step #1098] loss: 1.9127055426095159\n",
      "[EPOCH #14, step #1100] loss: 1.9134947704684182\n",
      "[EPOCH #14, step #1102] loss: 1.9129889266445543\n",
      "[EPOCH #14, step #1104] loss: 1.912593172038842\n",
      "[EPOCH #14, step #1106] loss: 1.9124734189559882\n",
      "[EPOCH #14, step #1108] loss: 1.9118817035306994\n",
      "[EPOCH #14, step #1110] loss: 1.9121768618359638\n",
      "[EPOCH #14, step #1112] loss: 1.91166175065122\n",
      "[EPOCH #14, step #1114] loss: 1.9117495752770806\n",
      "[EPOCH #14, step #1116] loss: 1.9118969243023154\n",
      "[EPOCH #14, step #1118] loss: 1.9118781165420422\n",
      "[EPOCH #14, step #1120] loss: 1.9116915130487624\n",
      "[EPOCH #14, step #1122] loss: 1.9117279910446805\n",
      "[EPOCH #14, step #1124] loss: 1.911805833498637\n",
      "[EPOCH #14, step #1126] loss: 1.9113075883386403\n",
      "[EPOCH #14, step #1128] loss: 1.911044158589217\n",
      "[EPOCH #14, step #1130] loss: 1.910085429668848\n",
      "[EPOCH #14, step #1132] loss: 1.9099829236911865\n",
      "[EPOCH #14, step #1134] loss: 1.9098177073810594\n",
      "[EPOCH #14, step #1136] loss: 1.9100481401752147\n",
      "[EPOCH #14, step #1138] loss: 1.9098439114045636\n",
      "[EPOCH #14, step #1140] loss: 1.9098513592344748\n",
      "[EPOCH #14, step #1142] loss: 1.909420759763409\n",
      "[EPOCH #14, step #1144] loss: 1.9095621238108806\n",
      "[EPOCH #14, step #1146] loss: 1.9093751588279304\n",
      "[EPOCH #14, step #1148] loss: 1.9094337282023086\n",
      "[EPOCH #14, step #1150] loss: 1.9092739879515355\n",
      "[EPOCH #14, step #1152] loss: 1.909462816283068\n",
      "[EPOCH #14, step #1154] loss: 1.9101775231299463\n",
      "[EPOCH #14, step #1156] loss: 1.909624075209569\n",
      "[EPOCH #14, step #1158] loss: 1.9097539680183089\n",
      "[EPOCH #14, step #1160] loss: 1.909870310655244\n",
      "[EPOCH #14, step #1162] loss: 1.9092931320005107\n",
      "[EPOCH #14, step #1164] loss: 1.9092185477842076\n",
      "[EPOCH #14, step #1166] loss: 1.9091658936470313\n",
      "[EPOCH #14, step #1168] loss: 1.909354462798994\n",
      "[EPOCH #14, step #1170] loss: 1.9093920054545674\n",
      "[EPOCH #14, step #1172] loss: 1.9102472742703462\n",
      "[EPOCH #14, step #1174] loss: 1.909890805508228\n",
      "[EPOCH #14, step #1176] loss: 1.9097561846370907\n",
      "[EPOCH #14, step #1178] loss: 1.909768932547177\n",
      "[EPOCH #14, step #1180] loss: 1.9096476188864777\n",
      "[EPOCH #14, step #1182] loss: 1.9088593045232263\n",
      "[EPOCH #14, step #1184] loss: 1.9081582171001514\n",
      "[EPOCH #14, step #1186] loss: 1.908325617917968\n",
      "[EPOCH #14, step #1188] loss: 1.908705829270654\n",
      "[EPOCH #14, step #1190] loss: 1.908671759938513\n",
      "[EPOCH #14, step #1192] loss: 1.9084187937901986\n",
      "[EPOCH #14, step #1194] loss: 1.9084126600161755\n",
      "[EPOCH #14, step #1196] loss: 1.9080366316494985\n",
      "[EPOCH #14, step #1198] loss: 1.908078328682245\n",
      "[EPOCH #14, step #1200] loss: 1.9079979376233092\n",
      "[EPOCH #14, step #1202] loss: 1.9081086356344563\n",
      "[EPOCH #14, step #1204] loss: 1.9083595698305185\n",
      "[EPOCH #14, step #1206] loss: 1.9078860256231414\n",
      "[EPOCH #14, step #1208] loss: 1.9074177597060098\n",
      "[EPOCH #14, step #1210] loss: 1.907639891819753\n",
      "[EPOCH #14, step #1212] loss: 1.9067565476904207\n",
      "[EPOCH #14, step #1214] loss: 1.907085128478062\n",
      "[EPOCH #14, step #1216] loss: 1.9072144315589523\n",
      "[EPOCH #14, step #1218] loss: 1.9065609850582281\n",
      "[EPOCH #14, step #1220] loss: 1.906676485146\n",
      "[EPOCH #14, step #1222] loss: 1.9067692889215901\n",
      "[EPOCH #14, step #1224] loss: 1.9069927417015542\n",
      "[EPOCH #14, step #1226] loss: 1.9065527490415317\n",
      "[EPOCH #14, step #1228] loss: 1.906384291059123\n",
      "[EPOCH #14, step #1230] loss: 1.9063899498659842\n",
      "[EPOCH #14, step #1232] loss: 1.9061519198560752\n",
      "[EPOCH #14, step #1234] loss: 1.9058150934304303\n",
      "[EPOCH #14, step #1236] loss: 1.9057197783777766\n",
      "[EPOCH #14, step #1238] loss: 1.9060818208043282\n",
      "[EPOCH #14, step #1240] loss: 1.906362114367612\n",
      "[EPOCH #14, step #1242] loss: 1.9065460992837662\n",
      "[EPOCH #14, step #1244] loss: 1.9066248330725244\n",
      "[EPOCH #14, step #1246] loss: 1.906758087868679\n",
      "[EPOCH #14, step #1248] loss: 1.9063061639917098\n",
      "[EPOCH #14, step #1250] loss: 1.9062596298426653\n",
      "[EPOCH #14, step #1252] loss: 1.9065426553808396\n",
      "[EPOCH #14, step #1254] loss: 1.9064939557793605\n",
      "[EPOCH #14, step #1256] loss: 1.9062714550167015\n",
      "[EPOCH #14, step #1258] loss: 1.9059524194317454\n",
      "[EPOCH #14, step #1260] loss: 1.9061530974060652\n",
      "[EPOCH #14, step #1262] loss: 1.9056040704580686\n",
      "[EPOCH #14, step #1264] loss: 1.9057204313428977\n",
      "[EPOCH #14, step #1266] loss: 1.9054600199847684\n",
      "[EPOCH #14, step #1268] loss: 1.9058108324136576\n",
      "[EPOCH #14, step #1270] loss: 1.906093859653788\n",
      "[EPOCH #14, step #1272] loss: 1.9064711344494936\n",
      "[EPOCH #14, step #1274] loss: 1.9064392044029983\n",
      "[EPOCH #14, step #1276] loss: 1.9066594527303566\n",
      "[EPOCH #14, step #1278] loss: 1.9062688726293937\n",
      "[EPOCH #14, step #1280] loss: 1.9063768544111468\n",
      "[EPOCH #14, step #1282] loss: 1.9058558162264032\n",
      "[EPOCH #14, step #1284] loss: 1.9052994462766537\n",
      "[EPOCH #14, step #1286] loss: 1.9055416281128819\n",
      "[EPOCH #14, step #1288] loss: 1.9054789110336126\n",
      "[EPOCH #14, step #1290] loss: 1.9053857092890603\n",
      "[EPOCH #14, step #1292] loss: 1.905299666309578\n",
      "[EPOCH #14, step #1294] loss: 1.9054719387334287\n",
      "[EPOCH #14, step #1296] loss: 1.905726628663821\n",
      "[EPOCH #14, step #1298] loss: 1.9051657165354081\n",
      "[EPOCH #14, step #1300] loss: 1.9054060100501176\n",
      "[EPOCH #14, step #1302] loss: 1.904817631678314\n",
      "[EPOCH #14, step #1304] loss: 1.9044840508493883\n",
      "[EPOCH #14, step #1306] loss: 1.9041396751600819\n",
      "[EPOCH #14, step #1308] loss: 1.9041743847684518\n",
      "[EPOCH #14, step #1310] loss: 1.9041954910909737\n",
      "[EPOCH #14, step #1312] loss: 1.9041339458623916\n",
      "[EPOCH #14, step #1314] loss: 1.9038399091691571\n",
      "[EPOCH #14, step #1316] loss: 1.9035627478076005\n",
      "[EPOCH #14, step #1318] loss: 1.903249912952455\n",
      "[EPOCH #14, step #1320] loss: 1.9031398729516376\n",
      "[EPOCH #14, step #1322] loss: 1.9030123137202302\n",
      "[EPOCH #14, step #1324] loss: 1.902912086810706\n",
      "[EPOCH #14, step #1326] loss: 1.9030861155647214\n",
      "[EPOCH #14, step #1328] loss: 1.9034652605013707\n",
      "[EPOCH #14, step #1330] loss: 1.903329390139619\n",
      "[EPOCH #14, step #1332] loss: 1.9028432256551229\n",
      "[EPOCH #14, step #1334] loss: 1.9025866499554351\n",
      "[EPOCH #14, step #1336] loss: 1.9024804429323172\n",
      "[EPOCH #14, step #1338] loss: 1.9026244944650081\n",
      "[EPOCH #14, step #1340] loss: 1.9027810433655865\n",
      "[EPOCH #14, step #1342] loss: 1.9028959799771512\n",
      "[EPOCH #14, step #1344] loss: 1.9033440403778756\n",
      "[EPOCH #14, step #1346] loss: 1.9035152747353183\n",
      "[EPOCH #14, step #1348] loss: 1.9037373650065168\n",
      "[EPOCH #14, step #1350] loss: 1.9038541291397117\n",
      "[EPOCH #14, step #1352] loss: 1.9042922811691443\n",
      "[EPOCH #14, step #1354] loss: 1.9043651187551858\n",
      "[EPOCH #14, step #1356] loss: 1.904768815353326\n",
      "[EPOCH #14, step #1358] loss: 1.9047687013329961\n",
      "[EPOCH #14, step #1360] loss: 1.9048094908863547\n",
      "[EPOCH #14, step #1362] loss: 1.9051652528394782\n",
      "[EPOCH #14, step #1364] loss: 1.9051291093721494\n",
      "[EPOCH #14, step #1366] loss: 1.9057436502145517\n",
      "[EPOCH #14, step #1368] loss: 1.9056469774141722\n",
      "[EPOCH #14, step #1370] loss: 1.905904081944216\n",
      "[EPOCH #14, step #1372] loss: 1.906337694625132\n",
      "[EPOCH #14, step #1374] loss: 1.9062552588202737\n",
      "[EPOCH #14, step #1376] loss: 1.9064728650132556\n",
      "[EPOCH #14, step #1378] loss: 1.9065693041999934\n",
      "[EPOCH #14, step #1380] loss: 1.906303027934738\n",
      "[EPOCH #14, step #1382] loss: 1.9062731135865527\n",
      "[EPOCH #14, step #1384] loss: 1.9065385475055405\n",
      "[EPOCH #14, step #1386] loss: 1.9062211919191852\n",
      "[EPOCH #14, step #1388] loss: 1.9059703193009543\n",
      "[EPOCH #14, step #1390] loss: 1.9062770629083399\n",
      "[EPOCH #14, step #1392] loss: 1.9061380294442434\n",
      "[EPOCH #14, step #1394] loss: 1.9058396202689003\n",
      "[EPOCH #14, step #1396] loss: 1.905548749007578\n",
      "[EPOCH #14, step #1398] loss: 1.9052355101996443\n",
      "[EPOCH #14, step #1400] loss: 1.905458817645365\n",
      "[EPOCH #14, step #1402] loss: 1.9050864224253767\n",
      "[EPOCH #14, step #1404] loss: 1.9052660345606958\n",
      "[EPOCH #14, step #1406] loss: 1.9051617883839502\n",
      "[EPOCH #14, step #1408] loss: 1.9049184120149796\n",
      "[EPOCH #14, step #1410] loss: 1.9052097069127267\n",
      "[EPOCH #14, step #1412] loss: 1.9046481115465372\n",
      "[EPOCH #14, step #1414] loss: 1.9050097984475718\n",
      "[EPOCH #14, step #1416] loss: 1.904875401804459\n",
      "[EPOCH #14, step #1418] loss: 1.905029252518055\n",
      "[EPOCH #14, step #1420] loss: 1.9049823170057238\n",
      "[EPOCH #14, step #1422] loss: 1.904924390270772\n",
      "[EPOCH #14, step #1424] loss: 1.905023970603943\n",
      "[EPOCH #14, step #1426] loss: 1.904656326010583\n",
      "[EPOCH #14, step #1428] loss: 1.904467342615628\n",
      "[EPOCH #14, step #1430] loss: 1.9043587497028749\n",
      "[EPOCH #14, step #1432] loss: 1.9041286172021625\n",
      "[EPOCH #14, step #1434] loss: 1.9042179789692684\n",
      "[EPOCH #14, step #1436] loss: 1.9038544427046116\n",
      "[EPOCH #14, step #1438] loss: 1.9041472244295832\n",
      "[EPOCH #14, step #1440] loss: 1.9045364106388079\n",
      "[EPOCH #14, step #1442] loss: 1.9051049349626896\n",
      "[EPOCH #14, step #1444] loss: 1.9049492561280934\n",
      "[EPOCH #14, step #1446] loss: 1.9051934465014202\n",
      "[EPOCH #14, step #1448] loss: 1.9051501546093643\n",
      "[EPOCH #14, step #1450] loss: 1.905126199732149\n",
      "[EPOCH #14, step #1452] loss: 1.9052011544181\n",
      "[EPOCH #14, step #1454] loss: 1.9051820950819454\n",
      "[EPOCH #14, step #1456] loss: 1.9051222716935627\n",
      "[EPOCH #14, step #1458] loss: 1.9052214802251113\n",
      "[EPOCH #14, step #1460] loss: 1.905370167067082\n",
      "[EPOCH #14, step #1462] loss: 1.9054742102254685\n",
      "[EPOCH #14, step #1464] loss: 1.9057648103798617\n",
      "[EPOCH #14, step #1466] loss: 1.9059462563554366\n",
      "[EPOCH #14, step #1468] loss: 1.9056014203960348\n",
      "[EPOCH #14, step #1470] loss: 1.905109405760697\n",
      "[EPOCH #14, step #1472] loss: 1.9053567539488305\n",
      "[EPOCH #14, step #1474] loss: 1.9060392619795719\n",
      "[EPOCH #14, step #1476] loss: 1.9064626450787223\n",
      "[EPOCH #14, step #1478] loss: 1.906558942923762\n",
      "[EPOCH #14, step #1480] loss: 1.9066516078057762\n",
      "[EPOCH #14, step #1482] loss: 1.9061333039123627\n",
      "[EPOCH #14, step #1484] loss: 1.9062647524104777\n",
      "[EPOCH #14, step #1486] loss: 1.9058642007395494\n",
      "[EPOCH #14, step #1488] loss: 1.9055755915779489\n",
      "[EPOCH #14, step #1490] loss: 1.9056667837818384\n",
      "[EPOCH #14, step #1492] loss: 1.905643840165084\n",
      "[EPOCH #14, step #1494] loss: 1.906029497500646\n",
      "[EPOCH #14, step #1496] loss: 1.905915760484312\n",
      "[EPOCH #14, step #1498] loss: 1.9059464485347868\n",
      "[EPOCH #14, step #1500] loss: 1.906384875741027\n",
      "[EPOCH #14, step #1502] loss: 1.906251716042707\n",
      "[EPOCH #14, step #1504] loss: 1.9060878683166251\n",
      "[EPOCH #14, step #1506] loss: 1.9060103508836004\n",
      "[EPOCH #14, step #1508] loss: 1.9056922283450684\n",
      "[EPOCH #14, step #1510] loss: 1.9053755754039114\n",
      "[EPOCH #14, step #1512] loss: 1.905714224681741\n",
      "[EPOCH #14, step #1514] loss: 1.9056438808787382\n",
      "[EPOCH #14, step #1516] loss: 1.9058662755126299\n",
      "[EPOCH #14, step #1518] loss: 1.9052405572392739\n",
      "[EPOCH #14, step #1520] loss: 1.905827298593866\n",
      "[EPOCH #14, step #1522] loss: 1.9056133922588177\n",
      "[EPOCH #14, step #1524] loss: 1.9054038798222777\n",
      "[EPOCH #14, step #1526] loss: 1.9053854142909121\n",
      "[EPOCH #14, step #1528] loss: 1.9052117330876732\n",
      "[EPOCH #14, step #1530] loss: 1.9047882951684125\n",
      "[EPOCH #14, step #1532] loss: 1.9049503324238677\n",
      "[EPOCH #14, step #1534] loss: 1.9049590589169183\n",
      "[EPOCH #14, step #1536] loss: 1.9054297204908024\n",
      "[EPOCH #14, step #1538] loss: 1.9051515045221785\n",
      "[EPOCH #14, step #1540] loss: 1.9050922023252108\n",
      "[EPOCH #14, step #1542] loss: 1.9050366458997894\n",
      "[EPOCH #14, step #1544] loss: 1.9046181701919407\n",
      "[EPOCH #14, step #1546] loss: 1.9044120609182347\n",
      "[EPOCH #14, step #1548] loss: 1.9044113561674578\n",
      "[EPOCH #14, step #1550] loss: 1.9041087521344595\n",
      "[EPOCH #14, step #1552] loss: 1.9041834526958576\n",
      "[EPOCH #14, step #1554] loss: 1.9040114891107442\n",
      "[EPOCH #14, step #1556] loss: 1.9037507051217992\n",
      "[EPOCH #14, step #1558] loss: 1.903704861251875\n",
      "[EPOCH #14, step #1560] loss: 1.9038254098201852\n",
      "[EPOCH #14, step #1562] loss: 1.9036127184723253\n",
      "[EPOCH #14, step #1564] loss: 1.9032102636635875\n",
      "[EPOCH #14, step #1566] loss: 1.9031769021270986\n",
      "[EPOCH #14, step #1568] loss: 1.903391629590435\n",
      "[EPOCH #14, step #1570] loss: 1.9032663909740921\n",
      "[EPOCH #14, step #1572] loss: 1.9037632366994044\n",
      "[EPOCH #14, step #1574] loss: 1.9037850550242832\n",
      "[EPOCH #14, step #1576] loss: 1.903694213608359\n",
      "[EPOCH #14, step #1578] loss: 1.9035843874247034\n",
      "[EPOCH #14, step #1580] loss: 1.903987493792491\n",
      "[EPOCH #14, step #1582] loss: 1.904149398424169\n",
      "[EPOCH #14, step #1584] loss: 1.9042611083021674\n",
      "[EPOCH #14, step #1586] loss: 1.9039578691697676\n",
      "[EPOCH #14, step #1588] loss: 1.9039554663466687\n",
      "[EPOCH #14, step #1590] loss: 1.903742323874828\n",
      "[EPOCH #14, step #1592] loss: 1.903684265644986\n",
      "[EPOCH #14, step #1594] loss: 1.9038870901897036\n",
      "[EPOCH #14, step #1596] loss: 1.9042158420188917\n",
      "[EPOCH #14, step #1598] loss: 1.9041017992486053\n",
      "[EPOCH #14, step #1600] loss: 1.9046932298790136\n",
      "[EPOCH #14, step #1602] loss: 1.9050002792665384\n",
      "[EPOCH #14, step #1604] loss: 1.9051303636247867\n",
      "[EPOCH #14, step #1606] loss: 1.9051715655584993\n",
      "[EPOCH #14, step #1608] loss: 1.9053115111985808\n",
      "[EPOCH #14, step #1610] loss: 1.9047780277416766\n",
      "[EPOCH #14, step #1612] loss: 1.9042109359663166\n",
      "[EPOCH #14, step #1614] loss: 1.904643141891196\n",
      "[EPOCH #14, step #1616] loss: 1.9048860491833424\n",
      "[EPOCH #14, step #1618] loss: 1.9046194269894228\n",
      "[EPOCH #14, step #1620] loss: 1.904720568348051\n",
      "[EPOCH #14, step #1622] loss: 1.9049315000123912\n",
      "[EPOCH #14, step #1624] loss: 1.9046588722375724\n",
      "[EPOCH #14, step #1626] loss: 1.9046000749257421\n",
      "[EPOCH #14, step #1628] loss: 1.9049325522796883\n",
      "[EPOCH #14, step #1630] loss: 1.9047223838979228\n",
      "[EPOCH #14, step #1632] loss: 1.9042838840344458\n",
      "[EPOCH #14, step #1634] loss: 1.9041126410166422\n",
      "[EPOCH #14, step #1636] loss: 1.9040703637321765\n",
      "[EPOCH #14, step #1638] loss: 1.9042575207332637\n",
      "[EPOCH #14, step #1640] loss: 1.9043378859013773\n",
      "[EPOCH #14, step #1642] loss: 1.9039513252163107\n",
      "[EPOCH #14, step #1644] loss: 1.9037733804128816\n",
      "[EPOCH #14, step #1646] loss: 1.9036249586069447\n",
      "[EPOCH #14, step #1648] loss: 1.9035264765442754\n",
      "[EPOCH #14, step #1650] loss: 1.9034563214182492\n",
      "[EPOCH #14, step #1652] loss: 1.904006171356312\n",
      "[EPOCH #14, step #1654] loss: 1.9044436315035171\n",
      "[EPOCH #14, step #1656] loss: 1.904786184888758\n",
      "[EPOCH #14, step #1658] loss: 1.9044379125954949\n",
      "[EPOCH #14, step #1660] loss: 1.9043995722599019\n",
      "[EPOCH #14, step #1662] loss: 1.9045490920364463\n",
      "[EPOCH #14, step #1664] loss: 1.9044109285772741\n",
      "[EPOCH #14, step #1666] loss: 1.9041165810683993\n",
      "[EPOCH #14, step #1668] loss: 1.9040560550929688\n",
      "[EPOCH #14, step #1670] loss: 1.9041492854814055\n",
      "[EPOCH #14, step #1672] loss: 1.9039083380080666\n",
      "[EPOCH #14, step #1674] loss: 1.9040795501310435\n",
      "[EPOCH #14, step #1676] loss: 1.9039321664407556\n",
      "[EPOCH #14, step #1678] loss: 1.9041675370388473\n",
      "[EPOCH #14, step #1680] loss: 1.9046972337611583\n",
      "[EPOCH #14, step #1682] loss: 1.9046143862157086\n",
      "[EPOCH #14, step #1684] loss: 1.9048987390025787\n",
      "[EPOCH #14, step #1686] loss: 1.9050895650498458\n",
      "[EPOCH #14, step #1688] loss: 1.9050611853246648\n",
      "[EPOCH #14, step #1690] loss: 1.90507128871735\n",
      "[EPOCH #14, step #1692] loss: 1.9045211973798677\n",
      "[EPOCH #14, step #1694] loss: 1.9046331507618097\n",
      "[EPOCH #14, step #1696] loss: 1.9048957371613384\n",
      "[EPOCH #14, step #1698] loss: 1.9049090415046381\n",
      "[EPOCH #14, step #1700] loss: 1.9051297603110438\n",
      "[EPOCH #14, step #1702] loss: 1.9049449898674429\n",
      "[EPOCH #14, step #1704] loss: 1.904707627841804\n",
      "[EPOCH #14, step #1706] loss: 1.904746085841822\n",
      "[EPOCH #14, step #1708] loss: 1.9046236419621931\n",
      "[EPOCH #14, step #1710] loss: 1.9046206576025744\n",
      "[EPOCH #14, step #1712] loss: 1.904357521142865\n",
      "[EPOCH #14, step #1714] loss: 1.9044802834619239\n",
      "[EPOCH #14, step #1716] loss: 1.9040994724702474\n",
      "[EPOCH #14, step #1718] loss: 1.9043213194924222\n",
      "[EPOCH #14, step #1720] loss: 1.9039546445938544\n",
      "[EPOCH #14, step #1722] loss: 1.904267523223691\n",
      "[EPOCH #14, step #1724] loss: 1.90422854444255\n",
      "[EPOCH #14, step #1726] loss: 1.9040190300364404\n",
      "[EPOCH #14, step #1728] loss: 1.9041792894802458\n",
      "[EPOCH #14, step #1730] loss: 1.9040315238676067\n",
      "[EPOCH #14, step #1732] loss: 1.9039850070582465\n",
      "[EPOCH #14, step #1734] loss: 1.904056184504836\n",
      "[EPOCH #14, step #1736] loss: 1.9039862512100958\n",
      "[EPOCH #14, step #1738] loss: 1.904161102611351\n",
      "[EPOCH #14, step #1740] loss: 1.9039516903626925\n",
      "[EPOCH #14, step #1742] loss: 1.9042028082696036\n",
      "[EPOCH #14, step #1744] loss: 1.9040881987629101\n",
      "[EPOCH #14, step #1746] loss: 1.903677069874716\n",
      "[EPOCH #14, step #1748] loss: 1.9037230363091173\n",
      "[EPOCH #14, step #1750] loss: 1.9038113758674287\n",
      "[EPOCH #14, step #1752] loss: 1.903769510851815\n",
      "[EPOCH #14, step #1754] loss: 1.903948654612245\n",
      "[EPOCH #14, step #1756] loss: 1.9038480304491132\n",
      "[EPOCH #14, step #1758] loss: 1.9038293057371771\n",
      "[EPOCH #14, step #1760] loss: 1.9039710821041256\n",
      "[EPOCH #14, step #1762] loss: 1.9038128644582972\n",
      "[EPOCH #14, step #1764] loss: 1.903550079861714\n",
      "[EPOCH #14, step #1766] loss: 1.903207397150602\n",
      "[EPOCH #14, step #1768] loss: 1.903037625561332\n",
      "[EPOCH #14, step #1770] loss: 1.902987932162659\n",
      "[EPOCH #14, step #1772] loss: 1.9028581466906096\n",
      "[EPOCH #14, step #1774] loss: 1.9029014492706513\n",
      "[EPOCH #14, step #1776] loss: 1.9027664952554526\n",
      "[EPOCH #14, step #1778] loss: 1.902720618944881\n",
      "[EPOCH #14, step #1780] loss: 1.9024989393438803\n",
      "[EPOCH #14, step #1782] loss: 1.902404576556708\n",
      "[EPOCH #14, step #1784] loss: 1.9023157706781595\n",
      "[EPOCH #14, step #1786] loss: 1.9019197138181665\n",
      "[EPOCH #14, step #1788] loss: 1.9021025135771665\n",
      "[EPOCH #14, step #1790] loss: 1.9021394562281955\n",
      "[EPOCH #14, step #1792] loss: 1.9023180386239567\n",
      "[EPOCH #14, step #1794] loss: 1.9021371788301176\n",
      "[EPOCH #14, step #1796] loss: 1.9021765275603875\n",
      "[EPOCH #14, step #1798] loss: 1.9022355049169348\n",
      "[EPOCH #14, step #1800] loss: 1.90233922468034\n",
      "[EPOCH #14, step #1802] loss: 1.902313865163362\n",
      "[EPOCH #14, step #1804] loss: 1.9021669130246064\n",
      "[EPOCH #14, step #1806] loss: 1.9023396448331704\n",
      "[EPOCH #14, step #1808] loss: 1.9019311756768762\n",
      "[EPOCH #14, step #1810] loss: 1.9021516516352148\n",
      "[EPOCH #14, step #1812] loss: 1.9019264041950081\n",
      "[EPOCH #14, step #1814] loss: 1.902014914688657\n",
      "[EPOCH #14, step #1816] loss: 1.901967939270284\n",
      "[EPOCH #14, step #1818] loss: 1.9019068664348406\n",
      "[EPOCH #14, step #1820] loss: 1.901741314235459\n",
      "[EPOCH #14, step #1822] loss: 1.9013030704272298\n",
      "[EPOCH #14, step #1824] loss: 1.901281368961073\n",
      "[EPOCH #14, step #1826] loss: 1.9014945186809171\n",
      "[EPOCH #14, step #1828] loss: 1.9017582526293004\n",
      "[EPOCH #14, step #1830] loss: 1.9020871799673167\n",
      "[EPOCH #14, step #1832] loss: 1.9020811327805756\n",
      "[EPOCH #14, step #1834] loss: 1.9017683528099787\n",
      "[EPOCH #14, step #1836] loss: 1.9019847777983905\n",
      "[EPOCH #14, step #1838] loss: 1.901657550603297\n",
      "[EPOCH #14, step #1840] loss: 1.9014757154818012\n",
      "[EPOCH #14, step #1842] loss: 1.9014527464585658\n",
      "[EPOCH #14, step #1844] loss: 1.9014575953082986\n",
      "[EPOCH #14, step #1846] loss: 1.9014602527143378\n",
      "[EPOCH #14, step #1848] loss: 1.9014219091414373\n",
      "[EPOCH #14, step #1850] loss: 1.9011487973695957\n",
      "[EPOCH #14, step #1852] loss: 1.9008649590204552\n",
      "[EPOCH #14, step #1854] loss: 1.9005483617037133\n",
      "[EPOCH #14, step #1856] loss: 1.9002915875656219\n",
      "[EPOCH #14, step #1858] loss: 1.9003367102742517\n",
      "[EPOCH #14, step #1860] loss: 1.9001405526719255\n",
      "[EPOCH #14, step #1862] loss: 1.9004040928342556\n",
      "[EPOCH #14, step #1864] loss: 1.9003976869199615\n",
      "[EPOCH #14, step #1866] loss: 1.9005971423559287\n",
      "[EPOCH #14, step #1868] loss: 1.9005498362454964\n",
      "[EPOCH #14, step #1870] loss: 1.9005766840047342\n",
      "[EPOCH #14, step #1872] loss: 1.9004366209464982\n",
      "[EPOCH #14, step #1874] loss: 1.9003477940241496\n",
      "[EPOCH #14, step #1876] loss: 1.9002512312341893\n",
      "[EPOCH #14, step #1878] loss: 1.9003805786831192\n",
      "[EPOCH #14, step #1880] loss: 1.9002784188284259\n",
      "[EPOCH #14, step #1882] loss: 1.9001934552407935\n",
      "[EPOCH #14, step #1884] loss: 1.9003244444925527\n",
      "[EPOCH #14, step #1886] loss: 1.9005680040638473\n",
      "[EPOCH #14, step #1888] loss: 1.9004136666600322\n",
      "[EPOCH #14, step #1890] loss: 1.9004567466294053\n",
      "[EPOCH #14, step #1892] loss: 1.9008756231770463\n",
      "[EPOCH #14, step #1894] loss: 1.9008487182430982\n",
      "[EPOCH #14, step #1896] loss: 1.9006398942009297\n",
      "[EPOCH #14, step #1898] loss: 1.9007113394202402\n",
      "[EPOCH #14, step #1900] loss: 1.9002803390368481\n",
      "[EPOCH #14, step #1902] loss: 1.8999942411451796\n",
      "[EPOCH #14, step #1904] loss: 1.8999160904896855\n",
      "[EPOCH #14, step #1906] loss: 1.9001236748307804\n",
      "[EPOCH #14, step #1908] loss: 1.9001963733690082\n",
      "[EPOCH #14, step #1910] loss: 1.8998861775730118\n",
      "[EPOCH #14, step #1912] loss: 1.9000311960304088\n",
      "[EPOCH #14, step #1914] loss: 1.899984759637021\n",
      "[EPOCH #14, step #1916] loss: 1.900216464767496\n",
      "[EPOCH #14, step #1918] loss: 1.900446898742167\n",
      "[EPOCH #14, step #1920] loss: 1.90029573750831\n",
      "[EPOCH #14, step #1922] loss: 1.899995485135682\n",
      "[EPOCH #14, step #1924] loss: 1.8999733269059813\n",
      "[EPOCH #14, step #1926] loss: 1.8998212653488216\n",
      "[EPOCH #14, step #1928] loss: 1.8994943971396605\n",
      "[EPOCH #14, step #1930] loss: 1.8996861652041395\n",
      "[EPOCH #14, step #1932] loss: 1.8992888282385134\n",
      "[EPOCH #14, step #1934] loss: 1.8993416688854996\n",
      "[EPOCH #14, step #1936] loss: 1.899477099719956\n",
      "[EPOCH #14, step #1938] loss: 1.8996719395517996\n",
      "[EPOCH #14, step #1940] loss: 1.899545621650849\n",
      "[EPOCH #14, step #1942] loss: 1.8995569533315197\n",
      "[EPOCH #14, step #1944] loss: 1.8993469973762729\n",
      "[EPOCH #14, step #1946] loss: 1.899284001797606\n",
      "[EPOCH #14, step #1948] loss: 1.8993966665067326\n",
      "[EPOCH #14, step #1950] loss: 1.8998453596321392\n",
      "[EPOCH #14, step #1952] loss: 1.8998888258560462\n",
      "[EPOCH #14, step #1954] loss: 1.9001058296779232\n",
      "[EPOCH #14, step #1956] loss: 1.9001981534090466\n",
      "[EPOCH #14, step #1958] loss: 1.9001693524773964\n",
      "[EPOCH #14, step #1960] loss: 1.9000030229554865\n",
      "[EPOCH #14, step #1962] loss: 1.900030402826279\n",
      "[EPOCH #14, step #1964] loss: 1.8999543069276494\n",
      "[EPOCH #14, step #1966] loss: 1.9000064493983182\n",
      "[EPOCH #14, step #1968] loss: 1.8998930456070442\n",
      "[EPOCH #14, step #1970] loss: 1.8998473187136444\n",
      "[EPOCH #14, step #1972] loss: 1.8997349841185047\n",
      "[EPOCH #14, step #1974] loss: 1.899490166555477\n",
      "[EPOCH #14, step #1976] loss: 1.8994344161747077\n",
      "[EPOCH #14, step #1978] loss: 1.8997364032744397\n",
      "[EPOCH #14, step #1980] loss: 1.8998117879567153\n",
      "[EPOCH #14, step #1982] loss: 1.8997515602900534\n",
      "[EPOCH #14, step #1984] loss: 1.8997305716915756\n",
      "[EPOCH #14, step #1986] loss: 1.8997784113248029\n",
      "[EPOCH #14, step #1988] loss: 1.8996139073743479\n",
      "[EPOCH #14, step #1990] loss: 1.8995025145354911\n",
      "[EPOCH #14, step #1992] loss: 1.8997175484761124\n",
      "[EPOCH #14, step #1994] loss: 1.8996581498841594\n",
      "[EPOCH #14, step #1996] loss: 1.899257221159842\n",
      "[EPOCH #14, step #1998] loss: 1.8991391339142243\n",
      "[EPOCH #14, step #2000] loss: 1.8988993240558523\n",
      "[EPOCH #14, step #2002] loss: 1.8991128287193957\n",
      "[EPOCH #14, step #2004] loss: 1.8989087977611514\n",
      "[EPOCH #14, step #2006] loss: 1.8990178065449668\n",
      "[EPOCH #14, step #2008] loss: 1.899229728089689\n",
      "[EPOCH #14, step #2010] loss: 1.8990540766467032\n",
      "[EPOCH #14, step #2012] loss: 1.8988500474047674\n",
      "[EPOCH #14, step #2014] loss: 1.8983261806497502\n",
      "[EPOCH #14, step #2016] loss: 1.898191833708862\n",
      "[EPOCH #14, step #2018] loss: 1.8977293223068818\n",
      "[EPOCH #14, step #2020] loss: 1.8978198978465597\n",
      "[EPOCH #14, step #2022] loss: 1.898119531347206\n",
      "[EPOCH #14, step #2024] loss: 1.8986184982605923\n",
      "[EPOCH #14, step #2026] loss: 1.8984745082798766\n",
      "[EPOCH #14, step #2028] loss: 1.8988444365674841\n",
      "[EPOCH #14, step #2030] loss: 1.898821615456713\n",
      "[EPOCH #14, step #2032] loss: 1.8984209897186273\n",
      "[EPOCH #14, step #2034] loss: 1.8984897148989928\n",
      "[EPOCH #14, step #2036] loss: 1.8981524154024494\n",
      "[EPOCH #14, step #2038] loss: 1.8983105999281034\n",
      "[EPOCH #14, step #2040] loss: 1.8981193740948459\n",
      "[EPOCH #14, step #2042] loss: 1.8982113536759095\n",
      "[EPOCH #14, step #2044] loss: 1.8983442139800428\n",
      "[EPOCH #14, step #2046] loss: 1.898390122431339\n",
      "[EPOCH #14, step #2048] loss: 1.8985263355887185\n",
      "[EPOCH #14, step #2050] loss: 1.898678614592215\n",
      "[EPOCH #14, step #2052] loss: 1.8983638067682138\n",
      "[EPOCH #14, step #2054] loss: 1.8983060774141856\n",
      "[EPOCH #14, step #2056] loss: 1.897878157379677\n",
      "[EPOCH #14, step #2058] loss: 1.8977119794107282\n",
      "[EPOCH #14, step #2060] loss: 1.8973288694554773\n",
      "[EPOCH #14, step #2062] loss: 1.8970596440717888\n",
      "[EPOCH #14, step #2064] loss: 1.8970558276187999\n",
      "[EPOCH #14, step #2066] loss: 1.897038889208103\n",
      "[EPOCH #14, step #2068] loss: 1.8971863576558088\n",
      "[EPOCH #14, step #2070] loss: 1.897216450874498\n",
      "[EPOCH #14, step #2072] loss: 1.8972842517936512\n",
      "[EPOCH #14, step #2074] loss: 1.8972435429584549\n",
      "[EPOCH #14, step #2076] loss: 1.897313746283361\n",
      "[EPOCH #14, step #2078] loss: 1.897328025392181\n",
      "[EPOCH #14, step #2080] loss: 1.897659904277422\n",
      "[EPOCH #14, step #2082] loss: 1.8978986205587693\n",
      "[EPOCH #14, step #2084] loss: 1.897637986107696\n",
      "[EPOCH #14, step #2086] loss: 1.8976921378909313\n",
      "[EPOCH #14, step #2088] loss: 1.8975102472898777\n",
      "[EPOCH #14, step #2090] loss: 1.8972008790427106\n",
      "[EPOCH #14, step #2092] loss: 1.8969729050915605\n",
      "[EPOCH #14, step #2094] loss: 1.8968246797957682\n",
      "[EPOCH #14, step #2096] loss: 1.8965572355244917\n",
      "[EPOCH #14, step #2098] loss: 1.8967367619091469\n",
      "[EPOCH #14, step #2100] loss: 1.8968707997704732\n",
      "[EPOCH #14, step #2102] loss: 1.8967395401318414\n",
      "[EPOCH #14, step #2104] loss: 1.8962907942910092\n",
      "[EPOCH #14, step #2106] loss: 1.8958387415048121\n",
      "[EPOCH #14, step #2108] loss: 1.8957222008264252\n",
      "[EPOCH #14, step #2110] loss: 1.8956480956879458\n",
      "[EPOCH #14, step #2112] loss: 1.8955527034575377\n",
      "[EPOCH #14, step #2114] loss: 1.8957831108823735\n",
      "[EPOCH #14, step #2116] loss: 1.89562985944365\n",
      "[EPOCH #14, step #2118] loss: 1.8955583202777015\n",
      "[EPOCH #14, step #2120] loss: 1.8954027895093357\n",
      "[EPOCH #14, step #2122] loss: 1.8953725998546511\n",
      "[EPOCH #14, step #2124] loss: 1.895409239544588\n",
      "[EPOCH #14, step #2126] loss: 1.895220226282013\n",
      "[EPOCH #14, step #2128] loss: 1.8956819358371468\n",
      "[EPOCH #14, step #2130] loss: 1.895476117821044\n",
      "[EPOCH #14, step #2132] loss: 1.89538308744748\n",
      "[EPOCH #14, step #2134] loss: 1.8953782148606884\n",
      "[EPOCH #14, step #2136] loss: 1.8952228427212205\n",
      "[EPOCH #14, step #2138] loss: 1.8955123579463093\n",
      "[EPOCH #14, step #2140] loss: 1.8957325370442026\n",
      "[EPOCH #14, step #2142] loss: 1.8959267964387574\n",
      "[EPOCH #14, step #2144] loss: 1.8955789530471767\n",
      "[EPOCH #14, step #2146] loss: 1.8953367894229969\n",
      "[EPOCH #14, step #2148] loss: 1.895160123546382\n",
      "[EPOCH #14, step #2150] loss: 1.8948027921908959\n",
      "[EPOCH #14, step #2152] loss: 1.8946484369396666\n",
      "[EPOCH #14, step #2154] loss: 1.8943974146986782\n",
      "[EPOCH #14, step #2156] loss: 1.8945749087857604\n",
      "[EPOCH #14, step #2158] loss: 1.8946891366579621\n",
      "[EPOCH #14, step #2160] loss: 1.8944737328693084\n",
      "[EPOCH #14, step #2162] loss: 1.8942440490837291\n",
      "[EPOCH #14, step #2164] loss: 1.8939432897413575\n",
      "[EPOCH #14, step #2166] loss: 1.8935905356092502\n",
      "[EPOCH #14, step #2168] loss: 1.893707843517147\n",
      "[EPOCH #14, step #2170] loss: 1.8937603032627395\n",
      "[EPOCH #14, step #2172] loss: 1.8939654726725375\n",
      "[EPOCH #14, step #2174] loss: 1.8940493108486307\n",
      "[EPOCH #14, step #2176] loss: 1.8940100135965308\n",
      "[EPOCH #14, step #2178] loss: 1.8937990304361303\n",
      "[EPOCH #14, step #2180] loss: 1.8935796092924095\n",
      "[EPOCH #14, step #2182] loss: 1.8936910576848769\n",
      "[EPOCH #14, step #2184] loss: 1.8934847849730223\n",
      "[EPOCH #14, step #2186] loss: 1.8933984911163813\n",
      "[EPOCH #14, step #2188] loss: 1.89333590659555\n",
      "[EPOCH #14, step #2190] loss: 1.8930036311604452\n",
      "[EPOCH #14, step #2192] loss: 1.8929174997683698\n",
      "[EPOCH #14, step #2194] loss: 1.8925113844165498\n",
      "[EPOCH #14, step #2196] loss: 1.8927246965383149\n",
      "[EPOCH #14, step #2198] loss: 1.8927126653414523\n",
      "[EPOCH #14, step #2200] loss: 1.8927755342294605\n",
      "[EPOCH #14, step #2202] loss: 1.8930087412588714\n",
      "[EPOCH #14, step #2204] loss: 1.8924936778961665\n",
      "[EPOCH #14, step #2206] loss: 1.8926263153688045\n",
      "[EPOCH #14, step #2208] loss: 1.8921621104288338\n",
      "[EPOCH #14, step #2210] loss: 1.8921013176036818\n",
      "[EPOCH #14, step #2212] loss: 1.892528672860426\n",
      "[EPOCH #14, step #2214] loss: 1.8926771856592148\n",
      "[EPOCH #14, step #2216] loss: 1.8923293714540521\n",
      "[EPOCH #14, step #2218] loss: 1.8922239429191083\n",
      "[EPOCH #14, step #2220] loss: 1.8919182290691665\n",
      "[EPOCH #14, step #2222] loss: 1.8914770797947427\n",
      "[EPOCH #14, step #2224] loss: 1.8911904910976967\n",
      "[EPOCH #14, step #2226] loss: 1.8911993437729773\n",
      "[EPOCH #14, step #2228] loss: 1.8911574166577299\n",
      "[EPOCH #14, step #2230] loss: 1.8909369276970933\n",
      "[EPOCH #14, step #2232] loss: 1.8908377380793906\n",
      "[EPOCH #14, step #2234] loss: 1.8904487785876998\n",
      "[EPOCH #14, step #2236] loss: 1.8903277073260338\n",
      "[EPOCH #14, step #2238] loss: 1.8905872296094361\n",
      "[EPOCH #14, step #2240] loss: 1.8906225385223314\n",
      "[EPOCH #14, step #2242] loss: 1.8907036591043869\n",
      "[EPOCH #14, step #2244] loss: 1.8907015921012862\n",
      "[EPOCH #14, step #2246] loss: 1.8905847328845586\n",
      "[EPOCH #14, step #2248] loss: 1.8904431049640362\n",
      "[EPOCH #14, step #2250] loss: 1.8904321638545372\n",
      "[EPOCH #14, step #2252] loss: 1.8906226921652987\n",
      "[EPOCH #14, step #2254] loss: 1.8901327505344299\n",
      "[EPOCH #14, step #2256] loss: 1.8902186279968716\n",
      "[EPOCH #14, step #2258] loss: 1.8900450226900694\n",
      "[EPOCH #14, step #2260] loss: 1.8900115078184152\n",
      "[EPOCH #14, step #2262] loss: 1.8899042403018427\n",
      "[EPOCH #14, step #2264] loss: 1.889874410050331\n",
      "[EPOCH #14, step #2266] loss: 1.889989565425262\n",
      "[EPOCH #14, step #2268] loss: 1.8897138535582374\n",
      "[EPOCH #14, step #2270] loss: 1.8895384434927198\n",
      "[EPOCH #14, step #2272] loss: 1.8895549342541038\n",
      "[EPOCH #14, step #2274] loss: 1.8897728553709092\n",
      "[EPOCH #14, step #2276] loss: 1.8898311342960603\n",
      "[EPOCH #14, step #2278] loss: 1.8897803505035071\n",
      "[EPOCH #14, step #2280] loss: 1.8896827740086009\n",
      "[EPOCH #14, step #2282] loss: 1.8895754508161775\n",
      "[EPOCH #14, step #2284] loss: 1.8895127784240688\n",
      "[EPOCH #14, step #2286] loss: 1.8897319179358938\n",
      "[EPOCH #14, step #2288] loss: 1.8899965574773652\n",
      "[EPOCH #14, step #2290] loss: 1.8900743826462785\n",
      "[EPOCH #14, step #2292] loss: 1.8897829124410757\n",
      "[EPOCH #14, step #2294] loss: 1.8896778085912236\n",
      "[EPOCH #14, step #2296] loss: 1.8896660525538271\n",
      "[EPOCH #14, step #2298] loss: 1.8895459828453511\n",
      "[EPOCH #14, step #2300] loss: 1.8893116713606342\n",
      "[EPOCH #14, step #2302] loss: 1.8892554680368354\n",
      "[EPOCH #14, step #2304] loss: 1.8893718201788283\n",
      "[EPOCH #14, step #2306] loss: 1.8893195845939197\n",
      "[EPOCH #14, step #2308] loss: 1.8891386235106193\n",
      "[EPOCH #14, step #2310] loss: 1.8892853716037739\n",
      "[EPOCH #14, step #2312] loss: 1.8891460102871287\n",
      "[EPOCH #14, step #2314] loss: 1.8891463888901614\n",
      "[EPOCH #14, step #2316] loss: 1.8891804274887065\n",
      "[EPOCH #14, step #2318] loss: 1.8891157227479574\n",
      "[EPOCH #14, step #2320] loss: 1.8890264654714246\n",
      "[EPOCH #14, step #2322] loss: 1.8888180392392997\n",
      "[EPOCH #14, step #2324] loss: 1.8887395345011064\n",
      "[EPOCH #14, step #2326] loss: 1.8885379939515754\n",
      "[EPOCH #14, step #2328] loss: 1.8882061826051586\n",
      "[EPOCH #14, step #2330] loss: 1.8883906040310297\n",
      "[EPOCH #14, step #2332] loss: 1.8882022709791313\n",
      "[EPOCH #14, step #2334] loss: 1.88809565379737\n",
      "[EPOCH #14, step #2336] loss: 1.8882249588633788\n",
      "[EPOCH #14, step #2338] loss: 1.8883928403022607\n",
      "[EPOCH #14, step #2340] loss: 1.8883211423270165\n",
      "[EPOCH #14, step #2342] loss: 1.8882599633522539\n",
      "[EPOCH #14, step #2344] loss: 1.8883782408639058\n",
      "[EPOCH #14, step #2346] loss: 1.888425254953837\n",
      "[EPOCH #14, step #2348] loss: 1.8884537569661504\n",
      "[EPOCH #14, step #2350] loss: 1.8885442686811096\n",
      "[EPOCH #14, step #2352] loss: 1.8885430967964825\n",
      "[EPOCH #14, step #2354] loss: 1.8883783053440653\n",
      "[EPOCH #14, step #2356] loss: 1.88830540141768\n",
      "[EPOCH #14, step #2358] loss: 1.8883741664502418\n",
      "[EPOCH #14, step #2360] loss: 1.8884300062182797\n",
      "[EPOCH #14, step #2362] loss: 1.8884196893370762\n",
      "[EPOCH #14, step #2364] loss: 1.8883184752555024\n",
      "[EPOCH #14, step #2366] loss: 1.8885501078729343\n",
      "[EPOCH #14, step #2368] loss: 1.888586422117917\n",
      "[EPOCH #14, step #2370] loss: 1.8885289112358141\n",
      "[EPOCH #14, step #2372] loss: 1.8881944920310378\n",
      "[EPOCH #14, step #2374] loss: 1.8881796393143504\n",
      "[EPOCH #14, step #2376] loss: 1.8882022599588184\n",
      "[EPOCH #14, step #2378] loss: 1.88794332123845\n",
      "[EPOCH #14, step #2380] loss: 1.8879334822466072\n",
      "[EPOCH #14, step #2382] loss: 1.8881502870847036\n",
      "[EPOCH #14, step #2384] loss: 1.8882861286839099\n",
      "[EPOCH #14, step #2386] loss: 1.8882145788762477\n",
      "[EPOCH #14, step #2388] loss: 1.888109372519409\n",
      "[EPOCH #14, step #2390] loss: 1.8881213109595962\n",
      "[EPOCH #14, step #2392] loss: 1.8882142929068382\n",
      "[EPOCH #14, step #2394] loss: 1.8880443266388767\n",
      "[EPOCH #14, step #2396] loss: 1.8881025537133564\n",
      "[EPOCH #14, step #2398] loss: 1.887925078840045\n",
      "[EPOCH #14, step #2400] loss: 1.8878271858278088\n",
      "[EPOCH #14, step #2402] loss: 1.887684695233517\n",
      "[EPOCH #14, step #2404] loss: 1.887601601953566\n",
      "[EPOCH #14, step #2406] loss: 1.887676834119124\n",
      "[EPOCH #14, step #2408] loss: 1.887564988243179\n",
      "[EPOCH #14, step #2410] loss: 1.8874358633947985\n",
      "[EPOCH #14, step #2412] loss: 1.8873100849883566\n",
      "[EPOCH #14, step #2414] loss: 1.8873031014487858\n",
      "[EPOCH #14, step #2416] loss: 1.887496703707782\n",
      "[EPOCH #14, step #2418] loss: 1.8875441092900769\n",
      "[EPOCH #14, step #2420] loss: 1.8875433947123166\n",
      "[EPOCH #14, step #2422] loss: 1.8872130021938744\n",
      "[EPOCH #14, step #2424] loss: 1.8871771343958748\n",
      "[EPOCH #14, step #2426] loss: 1.8870751242800705\n",
      "[EPOCH #14, step #2428] loss: 1.8873903900078168\n",
      "[EPOCH #14, step #2430] loss: 1.887274471098187\n",
      "[EPOCH #14, step #2432] loss: 1.8870490976581347\n",
      "[EPOCH #14, step #2434] loss: 1.8869801437585505\n",
      "[EPOCH #14, step #2436] loss: 1.8871673183163318\n",
      "[EPOCH #14, step #2438] loss: 1.8875428265653316\n",
      "[EPOCH #14, step #2440] loss: 1.8878972494226165\n",
      "[EPOCH #14, step #2442] loss: 1.8878381657785828\n",
      "[EPOCH #14, step #2444] loss: 1.8876921495289403\n",
      "[EPOCH #14, step #2446] loss: 1.8880138681234024\n",
      "[EPOCH #14, step #2448] loss: 1.8880055769943325\n",
      "[EPOCH #14, step #2450] loss: 1.8878191211475541\n",
      "[EPOCH #14, step #2452] loss: 1.8878151537980346\n",
      "[EPOCH #14, step #2454] loss: 1.8876396453550537\n",
      "[EPOCH #14, step #2456] loss: 1.8877257713710676\n",
      "[EPOCH #14, step #2458] loss: 1.8876204022841514\n",
      "[EPOCH #14, step #2460] loss: 1.8875555156547332\n",
      "[EPOCH #14, step #2462] loss: 1.8876403318978983\n",
      "[EPOCH #14, step #2464] loss: 1.8875069120109202\n",
      "[EPOCH #14, step #2466] loss: 1.8875038470630467\n",
      "[EPOCH #14, step #2468] loss: 1.8876828618646393\n",
      "[EPOCH #14, step #2470] loss: 1.887628318519546\n",
      "[EPOCH #14, step #2472] loss: 1.887491937210046\n",
      "[EPOCH #14, step #2474] loss: 1.8874654346523863\n",
      "[EPOCH #14, step #2476] loss: 1.8877957525106992\n",
      "[EPOCH #14, step #2478] loss: 1.8878783824319751\n",
      "[EPOCH #14, step #2480] loss: 1.8877214570527883\n",
      "[EPOCH #14, step #2482] loss: 1.8876627318282018\n",
      "[EPOCH #14, step #2484] loss: 1.8878694411974317\n",
      "[EPOCH #14, step #2486] loss: 1.888105270658385\n",
      "[EPOCH #14, step #2488] loss: 1.887956516624886\n",
      "[EPOCH #14, step #2490] loss: 1.8877318415092397\n",
      "[EPOCH #14, step #2492] loss: 1.8877151327060495\n",
      "[EPOCH #14, step #2494] loss: 1.8877475004157944\n",
      "[EPOCH #14, step #2496] loss: 1.887966153475586\n",
      "[EPOCH #14, step #2498] loss: 1.8878887312657455\n",
      "[EPOCH #14, elapsed time: 7118.157[sec]] loss: 1.887878363752365\n",
      "[EPOCH #15, step #0] loss: 1.7036705017089844\n",
      "[EPOCH #15, step #2] loss: 1.794034441312154\n",
      "[EPOCH #15, step #4] loss: 1.870996117591858\n",
      "[EPOCH #15, step #6] loss: 1.8608752489089966\n",
      "[EPOCH #15, step #8] loss: 1.8921234475241766\n",
      "[EPOCH #15, step #10] loss: 1.862987680868669\n",
      "[EPOCH #15, step #12] loss: 1.8311277536245494\n",
      "[EPOCH #15, step #14] loss: 1.8101685285568236\n",
      "[EPOCH #15, step #16] loss: 1.8027740857180428\n",
      "[EPOCH #15, step #18] loss: 1.7834423905924748\n",
      "[EPOCH #15, step #20] loss: 1.791701322510129\n",
      "[EPOCH #15, step #22] loss: 1.787132968073306\n",
      "[EPOCH #15, step #24] loss: 1.7754466009140015\n",
      "[EPOCH #15, step #26] loss: 1.7487092592098095\n",
      "[EPOCH #15, step #28] loss: 1.7431713507093232\n",
      "[EPOCH #15, step #30] loss: 1.7514352452370427\n",
      "[EPOCH #15, step #32] loss: 1.7365773771748398\n",
      "[EPOCH #15, step #34] loss: 1.7464040858404977\n",
      "[EPOCH #15, step #36] loss: 1.7549979139018703\n",
      "[EPOCH #15, step #38] loss: 1.7709836990405352\n",
      "[EPOCH #15, step #40] loss: 1.755250913340871\n",
      "[EPOCH #15, step #42] loss: 1.7663395765215852\n",
      "[EPOCH #15, step #44] loss: 1.7576068745719062\n",
      "[EPOCH #15, step #46] loss: 1.7719149741720646\n",
      "[EPOCH #15, step #48] loss: 1.7778117997305733\n",
      "[EPOCH #15, step #50] loss: 1.7802389135547714\n",
      "[EPOCH #15, step #52] loss: 1.783466303123618\n",
      "[EPOCH #15, step #54] loss: 1.7835074988278476\n",
      "[EPOCH #15, step #56] loss: 1.7800207158975434\n",
      "[EPOCH #15, step #58] loss: 1.7911251136812114\n",
      "[EPOCH #15, step #60] loss: 1.7805347755307057\n",
      "[EPOCH #15, step #62] loss: 1.7793875100120666\n",
      "[EPOCH #15, step #64] loss: 1.7833287752591647\n",
      "[EPOCH #15, step #66] loss: 1.779353921093158\n",
      "[EPOCH #15, step #68] loss: 1.779887254687323\n",
      "[EPOCH #15, step #70] loss: 1.775216520672113\n",
      "[EPOCH #15, step #72] loss: 1.7791490718109968\n",
      "[EPOCH #15, step #74] loss: 1.781721920967102\n",
      "[EPOCH #15, step #76] loss: 1.7784865041831872\n",
      "[EPOCH #15, step #78] loss: 1.7790150068983246\n",
      "[EPOCH #15, step #80] loss: 1.7722220656312542\n",
      "[EPOCH #15, step #82] loss: 1.7794202896485847\n",
      "[EPOCH #15, step #84] loss: 1.7744990418939028\n",
      "[EPOCH #15, step #86] loss: 1.7695773908461647\n",
      "[EPOCH #15, step #88] loss: 1.7728786749786205\n",
      "[EPOCH #15, step #90] loss: 1.7689127843458574\n",
      "[EPOCH #15, step #92] loss: 1.7732108087949856\n",
      "[EPOCH #15, step #94] loss: 1.7662130456221732\n",
      "[EPOCH #15, step #96] loss: 1.762031171739716\n",
      "[EPOCH #15, step #98] loss: 1.7695349924492114\n",
      "[EPOCH #15, step #100] loss: 1.768999953081112\n",
      "[EPOCH #15, step #102] loss: 1.77338336972357\n",
      "[EPOCH #15, step #104] loss: 1.7755298058191935\n",
      "[EPOCH #15, step #106] loss: 1.7752304233123208\n",
      "[EPOCH #15, step #108] loss: 1.7742323755124294\n",
      "[EPOCH #15, step #110] loss: 1.7829183361551784\n",
      "[EPOCH #15, step #112] loss: 1.7842553031128066\n",
      "[EPOCH #15, step #114] loss: 1.7817226555036463\n",
      "[EPOCH #15, step #116] loss: 1.7831966235087469\n",
      "[EPOCH #15, step #118] loss: 1.7808021387132276\n",
      "[EPOCH #15, step #120] loss: 1.7792706164446743\n",
      "[EPOCH #15, step #122] loss: 1.781064038354207\n",
      "[EPOCH #15, step #124] loss: 1.7790579004287719\n",
      "[EPOCH #15, step #126] loss: 1.7807534491921972\n",
      "[EPOCH #15, step #128] loss: 1.7804874736209249\n",
      "[EPOCH #15, step #130] loss: 1.7792298284195762\n",
      "[EPOCH #15, step #132] loss: 1.774597409972571\n",
      "[EPOCH #15, step #134] loss: 1.7740608347786797\n",
      "[EPOCH #15, step #136] loss: 1.7783132826324797\n",
      "[EPOCH #15, step #138] loss: 1.784413166183362\n",
      "[EPOCH #15, step #140] loss: 1.7825912634531658\n",
      "[EPOCH #15, step #142] loss: 1.7864988058597058\n",
      "[EPOCH #15, step #144] loss: 1.7856844663619995\n",
      "[EPOCH #15, step #146] loss: 1.7833521658060503\n",
      "[EPOCH #15, step #148] loss: 1.7829600332567357\n",
      "[EPOCH #15, step #150] loss: 1.7785780564049223\n",
      "[EPOCH #15, step #152] loss: 1.777342549336502\n",
      "[EPOCH #15, step #154] loss: 1.7799917321051322\n",
      "[EPOCH #15, step #156] loss: 1.779499527755057\n",
      "[EPOCH #15, step #158] loss: 1.7821809893134255\n",
      "[EPOCH #15, step #160] loss: 1.783709886651602\n",
      "[EPOCH #15, step #162] loss: 1.7875358056437018\n",
      "[EPOCH #15, step #164] loss: 1.7854430754979451\n",
      "[EPOCH #15, step #166] loss: 1.7835207121100969\n",
      "[EPOCH #15, step #168] loss: 1.780384169527765\n",
      "[EPOCH #15, step #170] loss: 1.7803200518178661\n",
      "[EPOCH #15, step #172] loss: 1.7778959088242812\n",
      "[EPOCH #15, step #174] loss: 1.7783402000154769\n",
      "[EPOCH #15, step #176] loss: 1.779398278327985\n",
      "[EPOCH #15, step #178] loss: 1.7787492421752247\n",
      "[EPOCH #15, step #180] loss: 1.7788273043395406\n",
      "[EPOCH #15, step #182] loss: 1.7799990704802215\n",
      "[EPOCH #15, step #184] loss: 1.7765013333913442\n",
      "[EPOCH #15, step #186] loss: 1.7742210186739018\n",
      "[EPOCH #15, step #188] loss: 1.7782269798258625\n",
      "[EPOCH #15, step #190] loss: 1.7753586151212921\n",
      "[EPOCH #15, step #192] loss: 1.7741380052863007\n",
      "[EPOCH #15, step #194] loss: 1.7718958848561996\n",
      "[EPOCH #15, step #196] loss: 1.771038285971898\n",
      "[EPOCH #15, step #198] loss: 1.7703746844775712\n",
      "[EPOCH #15, step #200] loss: 1.7686585466660076\n",
      "[EPOCH #15, step #202] loss: 1.768723390372516\n",
      "[EPOCH #15, step #204] loss: 1.7674398910708544\n",
      "[EPOCH #15, step #206] loss: 1.7675420771474424\n",
      "[EPOCH #15, step #208] loss: 1.7707530191640535\n",
      "[EPOCH #15, step #210] loss: 1.7727430109729134\n",
      "[EPOCH #15, step #212] loss: 1.7731781822974693\n",
      "[EPOCH #15, step #214] loss: 1.7774464701497277\n",
      "[EPOCH #15, step #216] loss: 1.7787550231828118\n",
      "[EPOCH #15, step #218] loss: 1.782605114592809\n",
      "[EPOCH #15, step #220] loss: 1.7850699689053842\n",
      "[EPOCH #15, step #222] loss: 1.7849425537169248\n",
      "[EPOCH #15, step #224] loss: 1.784496897061666\n",
      "[EPOCH #15, step #226] loss: 1.783270219874277\n",
      "[EPOCH #15, step #228] loss: 1.7844800027697367\n",
      "[EPOCH #15, step #230] loss: 1.7823565739057796\n",
      "[EPOCH #15, step #232] loss: 1.7806312162988687\n",
      "[EPOCH #15, step #234] loss: 1.7812384722080636\n",
      "[EPOCH #15, step #236] loss: 1.7830709193829242\n",
      "[EPOCH #15, step #238] loss: 1.782512562544276\n",
      "[EPOCH #15, step #240] loss: 1.7854233005729454\n",
      "[EPOCH #15, step #242] loss: 1.7846170766853993\n",
      "[EPOCH #15, step #244] loss: 1.7849474060292148\n",
      "[EPOCH #15, step #246] loss: 1.7859326832690219\n",
      "[EPOCH #15, step #248] loss: 1.783834856198016\n",
      "[EPOCH #15, step #250] loss: 1.7822422943267215\n",
      "[EPOCH #15, step #252] loss: 1.785222583137482\n",
      "[EPOCH #15, step #254] loss: 1.785097057211633\n",
      "[EPOCH #15, step #256] loss: 1.7878810306467434\n",
      "[EPOCH #15, step #258] loss: 1.7886109453370673\n",
      "[EPOCH #15, step #260] loss: 1.790504375636806\n",
      "[EPOCH #15, step #262] loss: 1.7923409698580608\n",
      "[EPOCH #15, step #264] loss: 1.7941726446151733\n",
      "[EPOCH #15, step #266] loss: 1.7926588683539115\n",
      "[EPOCH #15, step #268] loss: 1.791360726143791\n",
      "[EPOCH #15, step #270] loss: 1.7903772324213683\n",
      "[EPOCH #15, step #272] loss: 1.7884399371269422\n",
      "[EPOCH #15, step #274] loss: 1.7877664158561013\n",
      "[EPOCH #15, step #276] loss: 1.7896686017728454\n",
      "[EPOCH #15, step #278] loss: 1.7880792912616525\n",
      "[EPOCH #15, step #280] loss: 1.7903469240962397\n",
      "[EPOCH #15, step #282] loss: 1.7907141152203294\n",
      "[EPOCH #15, step #284] loss: 1.7915294906549286\n",
      "[EPOCH #15, step #286] loss: 1.7908652127827502\n",
      "[EPOCH #15, step #288] loss: 1.7925950932255252\n",
      "[EPOCH #15, step #290] loss: 1.7936855964234604\n",
      "[EPOCH #15, step #292] loss: 1.795165246257196\n",
      "[EPOCH #15, step #294] loss: 1.7938387135327873\n",
      "[EPOCH #15, step #296] loss: 1.7916727720286307\n",
      "[EPOCH #15, step #298] loss: 1.790408100970214\n",
      "[EPOCH #15, step #300] loss: 1.7893791745271397\n",
      "[EPOCH #15, step #302] loss: 1.7885003361371483\n",
      "[EPOCH #15, step #304] loss: 1.7891379172684716\n",
      "[EPOCH #15, step #306] loss: 1.7882264844757727\n",
      "[EPOCH #15, step #308] loss: 1.7875949696043933\n",
      "[EPOCH #15, step #310] loss: 1.788685453666368\n",
      "[EPOCH #15, step #312] loss: 1.7875325908295263\n",
      "[EPOCH #15, step #314] loss: 1.7871052518723503\n",
      "[EPOCH #15, step #316] loss: 1.7856682948885656\n",
      "[EPOCH #15, step #318] loss: 1.7870323553354388\n",
      "[EPOCH #15, step #320] loss: 1.7866013116925676\n",
      "[EPOCH #15, step #322] loss: 1.7858877082358204\n",
      "[EPOCH #15, step #324] loss: 1.7849814778107864\n",
      "[EPOCH #15, step #326] loss: 1.7838991293484283\n",
      "[EPOCH #15, step #328] loss: 1.7844484464738144\n",
      "[EPOCH #15, step #330] loss: 1.7841824055438316\n",
      "[EPOCH #15, step #332] loss: 1.784025682701363\n",
      "[EPOCH #15, step #334] loss: 1.783999433802135\n",
      "[EPOCH #15, step #336] loss: 1.7855571080386108\n",
      "[EPOCH #15, step #338] loss: 1.7850408504846174\n",
      "[EPOCH #15, step #340] loss: 1.783800117081561\n",
      "[EPOCH #15, step #342] loss: 1.7867510426496278\n",
      "[EPOCH #15, step #344] loss: 1.7882289077924645\n",
      "[EPOCH #15, step #346] loss: 1.7857137526833702\n",
      "[EPOCH #15, step #348] loss: 1.7856537452058328\n",
      "[EPOCH #15, step #350] loss: 1.785412848844827\n",
      "[EPOCH #15, step #352] loss: 1.7854769547330083\n",
      "[EPOCH #15, step #354] loss: 1.785182891765111\n",
      "[EPOCH #15, step #356] loss: 1.7846802887128514\n",
      "[EPOCH #15, step #358] loss: 1.7833418178691174\n",
      "[EPOCH #15, step #360] loss: 1.78410595011513\n",
      "[EPOCH #15, step #362] loss: 1.7840204830012045\n",
      "[EPOCH #15, step #364] loss: 1.7842666936247316\n",
      "[EPOCH #15, step #366] loss: 1.7856649361774122\n",
      "[EPOCH #15, step #368] loss: 1.7857469068310126\n",
      "[EPOCH #15, step #370] loss: 1.7859325791304965\n",
      "[EPOCH #15, step #372] loss: 1.7865413478488257\n",
      "[EPOCH #15, step #374] loss: 1.787107109705607\n",
      "[EPOCH #15, step #376] loss: 1.78920513533787\n",
      "[EPOCH #15, step #378] loss: 1.789290641731826\n",
      "[EPOCH #15, step #380] loss: 1.7877996352713879\n",
      "[EPOCH #15, step #382] loss: 1.7872797148034716\n",
      "[EPOCH #15, step #384] loss: 1.7891964946474348\n",
      "[EPOCH #15, step #386] loss: 1.7904571898531851\n",
      "[EPOCH #15, step #388] loss: 1.7898678338313163\n",
      "[EPOCH #15, step #390] loss: 1.7885285792753214\n",
      "[EPOCH #15, step #392] loss: 1.7899350385932826\n",
      "[EPOCH #15, step #394] loss: 1.7885462582865848\n",
      "[EPOCH #15, step #396] loss: 1.7895245864349287\n",
      "[EPOCH #15, step #398] loss: 1.7897475064547737\n",
      "[EPOCH #15, step #400] loss: 1.7925321276942987\n",
      "[EPOCH #15, step #402] loss: 1.7915007500139715\n",
      "[EPOCH #15, step #404] loss: 1.791398506105682\n",
      "[EPOCH #15, step #406] loss: 1.7913159498125681\n",
      "[EPOCH #15, step #408] loss: 1.7902870930203016\n",
      "[EPOCH #15, step #410] loss: 1.7907515627914392\n",
      "[EPOCH #15, step #412] loss: 1.7904486347341653\n",
      "[EPOCH #15, step #414] loss: 1.7906775086759084\n",
      "[EPOCH #15, step #416] loss: 1.791810052286235\n",
      "[EPOCH #15, step #418] loss: 1.7923022534227029\n",
      "[EPOCH #15, step #420] loss: 1.7929691959729954\n",
      "[EPOCH #15, step #422] loss: 1.794521327278011\n",
      "[EPOCH #15, step #424] loss: 1.7960956130308263\n",
      "[EPOCH #15, step #426] loss: 1.7965833426080209\n",
      "[EPOCH #15, step #428] loss: 1.7964093412830557\n",
      "[EPOCH #15, step #430] loss: 1.7974407692243217\n",
      "[EPOCH #15, step #432] loss: 1.7972888161899312\n",
      "[EPOCH #15, step #434] loss: 1.796547977677707\n",
      "[EPOCH #15, step #436] loss: 1.798113553147567\n",
      "[EPOCH #15, step #438] loss: 1.7978272106761541\n",
      "[EPOCH #15, step #440] loss: 1.7994347553945182\n",
      "[EPOCH #15, step #442] loss: 1.7991193976951239\n",
      "[EPOCH #15, step #444] loss: 1.7992313237672442\n",
      "[EPOCH #15, step #446] loss: 1.799226473908563\n",
      "[EPOCH #15, step #448] loss: 1.7992436962828604\n",
      "[EPOCH #15, step #450] loss: 1.7977997696320391\n",
      "[EPOCH #15, step #452] loss: 1.796926858146196\n",
      "[EPOCH #15, step #454] loss: 1.7962928282035575\n",
      "[EPOCH #15, step #456] loss: 1.7967826167133758\n",
      "[EPOCH #15, step #458] loss: 1.7960524764196026\n",
      "[EPOCH #15, step #460] loss: 1.795379425594967\n",
      "[EPOCH #15, step #462] loss: 1.7958582099004132\n",
      "[EPOCH #15, step #464] loss: 1.7962599469769385\n",
      "[EPOCH #15, step #466] loss: 1.7966371251377866\n",
      "[EPOCH #15, step #468] loss: 1.7971349817349205\n",
      "[EPOCH #15, step #470] loss: 1.7986051932515106\n",
      "[EPOCH #15, step #472] loss: 1.7975152577204634\n",
      "[EPOCH #15, step #474] loss: 1.7986984157562256\n",
      "[EPOCH #15, step #476] loss: 1.7990068767055776\n",
      "[EPOCH #15, step #478] loss: 1.800202374916236\n",
      "[EPOCH #15, step #480] loss: 1.8002462657226594\n",
      "[EPOCH #15, step #482] loss: 1.7986141425975855\n",
      "[EPOCH #15, step #484] loss: 1.8007048479060537\n",
      "[EPOCH #15, step #486] loss: 1.7993502002477155\n",
      "[EPOCH #15, step #488] loss: 1.7990446502689448\n",
      "[EPOCH #15, step #490] loss: 1.799387117510172\n",
      "[EPOCH #15, step #492] loss: 1.7997229674766804\n",
      "[EPOCH #15, step #494] loss: 1.8004891101760094\n",
      "[EPOCH #15, step #496] loss: 1.8000090019084078\n",
      "[EPOCH #15, step #498] loss: 1.8012641983662914\n",
      "[EPOCH #15, step #500] loss: 1.8006706111683342\n",
      "[EPOCH #15, step #502] loss: 1.8013772457304815\n",
      "[EPOCH #15, step #504] loss: 1.8001221602505977\n",
      "[EPOCH #15, step #506] loss: 1.8008656703979071\n",
      "[EPOCH #15, step #508] loss: 1.8004043842345652\n",
      "[EPOCH #15, step #510] loss: 1.8002254626988898\n",
      "[EPOCH #15, step #512] loss: 1.7996613874770047\n",
      "[EPOCH #15, step #514] loss: 1.8001398547181806\n",
      "[EPOCH #15, step #516] loss: 1.7993117536290242\n",
      "[EPOCH #15, step #518] loss: 1.7991805065114603\n",
      "[EPOCH #15, step #520] loss: 1.7986066329959716\n",
      "[EPOCH #15, step #522] loss: 1.7985876714294318\n",
      "[EPOCH #15, step #524] loss: 1.798568355696542\n",
      "[EPOCH #15, step #526] loss: 1.79786680409759\n",
      "[EPOCH #15, step #528] loss: 1.7977405975806915\n",
      "[EPOCH #15, step #530] loss: 1.7974340929149908\n",
      "[EPOCH #15, step #532] loss: 1.798142457545139\n",
      "[EPOCH #15, step #534] loss: 1.7977868106877692\n",
      "[EPOCH #15, step #536] loss: 1.7978282734002482\n",
      "[EPOCH #15, step #538] loss: 1.7975157853181376\n",
      "[EPOCH #15, step #540] loss: 1.797461973100405\n",
      "[EPOCH #15, step #542] loss: 1.7974157862461293\n",
      "[EPOCH #15, step #544] loss: 1.7975228219950965\n",
      "[EPOCH #15, step #546] loss: 1.797495539924998\n",
      "[EPOCH #15, step #548] loss: 1.7973168968937219\n",
      "[EPOCH #15, step #550] loss: 1.7973401626528067\n",
      "[EPOCH #15, step #552] loss: 1.797546826693723\n",
      "[EPOCH #15, step #554] loss: 1.7975003070659465\n",
      "[EPOCH #15, step #556] loss: 1.7967577479258046\n",
      "[EPOCH #15, step #558] loss: 1.796809030773388\n",
      "[EPOCH #15, step #560] loss: 1.7962880551071303\n",
      "[EPOCH #15, step #562] loss: 1.796846273949049\n",
      "[EPOCH #15, step #564] loss: 1.7965760532733615\n",
      "[EPOCH #15, step #566] loss: 1.7974234289593167\n",
      "[EPOCH #15, step #568] loss: 1.7965614697216685\n",
      "[EPOCH #15, step #570] loss: 1.796653705177708\n",
      "[EPOCH #15, step #572] loss: 1.7967487970987956\n",
      "[EPOCH #15, step #574] loss: 1.796850150771763\n",
      "[EPOCH #15, step #576] loss: 1.7973806521301665\n",
      "[EPOCH #15, step #578] loss: 1.7976778387405712\n",
      "[EPOCH #15, step #580] loss: 1.797785896032074\n",
      "[EPOCH #15, step #582] loss: 1.7973097601640287\n",
      "[EPOCH #15, step #584] loss: 1.7970334900750053\n",
      "[EPOCH #15, step #586] loss: 1.7977629745636117\n",
      "[EPOCH #15, step #588] loss: 1.797587632323364\n",
      "[EPOCH #15, step #590] loss: 1.7977457224011624\n",
      "[EPOCH #15, step #592] loss: 1.7972020911929176\n",
      "[EPOCH #15, step #594] loss: 1.7977901723204541\n",
      "[EPOCH #15, step #596] loss: 1.7972639373798467\n",
      "[EPOCH #15, step #598] loss: 1.7987324240211653\n",
      "[EPOCH #15, step #600] loss: 1.7986309996460519\n",
      "[EPOCH #15, step #602] loss: 1.7990271349253741\n",
      "[EPOCH #15, step #604] loss: 1.7990121203020584\n",
      "[EPOCH #15, step #606] loss: 1.7993605973496665\n",
      "[EPOCH #15, step #608] loss: 1.7999476251148043\n",
      "[EPOCH #15, step #610] loss: 1.7992195372885846\n",
      "[EPOCH #15, step #612] loss: 1.7997007476952882\n",
      "[EPOCH #15, step #614] loss: 1.7988639228712253\n",
      "[EPOCH #15, step #616] loss: 1.799169336184497\n",
      "[EPOCH #15, step #618] loss: 1.7991836069088567\n",
      "[EPOCH #15, step #620] loss: 1.7996217741866427\n",
      "[EPOCH #15, step #622] loss: 1.7993317165114524\n",
      "[EPOCH #15, step #624] loss: 1.7989939960479737\n",
      "[EPOCH #15, step #626] loss: 1.7982230116115612\n",
      "[EPOCH #15, step #628] loss: 1.7974631858364767\n",
      "[EPOCH #15, step #630] loss: 1.7972083554592828\n",
      "[EPOCH #15, step #632] loss: 1.797321025605827\n",
      "[EPOCH #15, step #634] loss: 1.797348260128592\n",
      "[EPOCH #15, step #636] loss: 1.79782105727323\n",
      "[EPOCH #15, step #638] loss: 1.797928530845284\n",
      "[EPOCH #15, step #640] loss: 1.7980485464592992\n",
      "[EPOCH #15, step #642] loss: 1.7973931080445902\n",
      "[EPOCH #15, step #644] loss: 1.7964018847591192\n",
      "[EPOCH #15, step #646] loss: 1.7962031745836944\n",
      "[EPOCH #15, step #648] loss: 1.7960552866176023\n",
      "[EPOCH #15, step #650] loss: 1.7960676068351382\n",
      "[EPOCH #15, step #652] loss: 1.7966639079142128\n",
      "[EPOCH #15, step #654] loss: 1.795845655812562\n",
      "[EPOCH #15, step #656] loss: 1.7951288067224\n",
      "[EPOCH #15, step #658] loss: 1.7947705747144176\n",
      "[EPOCH #15, step #660] loss: 1.7937452234046\n",
      "[EPOCH #15, step #662] loss: 1.7945501095928578\n",
      "[EPOCH #15, step #664] loss: 1.794026604093107\n",
      "[EPOCH #15, step #666] loss: 1.7944334341489572\n",
      "[EPOCH #15, step #668] loss: 1.7946584675522306\n",
      "[EPOCH #15, step #670] loss: 1.7946239077387554\n",
      "[EPOCH #15, step #672] loss: 1.7949113271920145\n",
      "[EPOCH #15, step #674] loss: 1.7948014370600383\n",
      "[EPOCH #15, step #676] loss: 1.7947992308277148\n",
      "[EPOCH #15, step #678] loss: 1.7942039754148436\n",
      "[EPOCH #15, step #680] loss: 1.7939350090362953\n",
      "[EPOCH #15, step #682] loss: 1.7937505639664075\n",
      "[EPOCH #15, step #684] loss: 1.7925816857901802\n",
      "[EPOCH #15, step #686] loss: 1.792182202248941\n",
      "[EPOCH #15, step #688] loss: 1.7921835594149562\n",
      "[EPOCH #15, step #690] loss: 1.7928545110995104\n",
      "[EPOCH #15, step #692] loss: 1.7928177520826265\n",
      "[EPOCH #15, step #694] loss: 1.7941000377531533\n",
      "[EPOCH #15, step #696] loss: 1.7945022138324667\n",
      "[EPOCH #15, step #698] loss: 1.794649894657053\n",
      "[EPOCH #15, step #700] loss: 1.7943722041969463\n",
      "[EPOCH #15, step #702] loss: 1.7945501680564067\n",
      "[EPOCH #15, step #704] loss: 1.7954622566277254\n",
      "[EPOCH #15, step #706] loss: 1.796137753436724\n",
      "[EPOCH #15, step #708] loss: 1.7965646558487196\n",
      "[EPOCH #15, step #710] loss: 1.7963958269433131\n",
      "[EPOCH #15, step #712] loss: 1.797089824335438\n",
      "[EPOCH #15, step #714] loss: 1.7973928169770674\n",
      "[EPOCH #15, step #716] loss: 1.7969855048500178\n",
      "[EPOCH #15, step #718] loss: 1.7968923141959645\n",
      "[EPOCH #15, step #720] loss: 1.797025569434305\n",
      "[EPOCH #15, step #722] loss: 1.796969809802571\n",
      "[EPOCH #15, step #724] loss: 1.7969704014679482\n",
      "[EPOCH #15, step #726] loss: 1.7967699716966778\n",
      "[EPOCH #15, step #728] loss: 1.7963341863721158\n",
      "[EPOCH #15, step #730] loss: 1.797088107560467\n",
      "[EPOCH #15, step #732] loss: 1.7972397488754086\n",
      "[EPOCH #15, step #734] loss: 1.7977293818986335\n",
      "[EPOCH #15, step #736] loss: 1.7969641027165884\n",
      "[EPOCH #15, step #738] loss: 1.797695184915411\n",
      "[EPOCH #15, step #740] loss: 1.7977005341435894\n",
      "[EPOCH #15, step #742] loss: 1.7972984721490544\n",
      "[EPOCH #15, step #744] loss: 1.7977342263164136\n",
      "[EPOCH #15, step #746] loss: 1.7978748379940968\n",
      "[EPOCH #15, step #748] loss: 1.7968828894585889\n",
      "[EPOCH #15, step #750] loss: 1.7972159750769523\n",
      "[EPOCH #15, step #752] loss: 1.7979737670614742\n",
      "[EPOCH #15, step #754] loss: 1.7978376202235948\n",
      "[EPOCH #15, step #756] loss: 1.7975905925783486\n",
      "[EPOCH #15, step #758] loss: 1.7977363141314942\n",
      "[EPOCH #15, step #760] loss: 1.7973357208768266\n",
      "[EPOCH #15, step #762] loss: 1.7973557088821932\n",
      "[EPOCH #15, step #764] loss: 1.7966247915442473\n",
      "[EPOCH #15, step #766] loss: 1.7960528149287736\n",
      "[EPOCH #15, step #768] loss: 1.7959982142801867\n",
      "[EPOCH #15, step #770] loss: 1.7962898784419752\n",
      "[EPOCH #15, step #772] loss: 1.7963084414273616\n",
      "[EPOCH #15, step #774] loss: 1.7958207335010652\n",
      "[EPOCH #15, step #776] loss: 1.7960896289486683\n",
      "[EPOCH #15, step #778] loss: 1.7961118542643046\n",
      "[EPOCH #15, step #780] loss: 1.7957206990441044\n",
      "[EPOCH #15, step #782] loss: 1.7952833585203227\n",
      "[EPOCH #15, step #784] loss: 1.7951469284713648\n",
      "[EPOCH #15, step #786] loss: 1.794879687483762\n",
      "[EPOCH #15, step #788] loss: 1.7943347095687732\n",
      "[EPOCH #15, step #790] loss: 1.7945552214358458\n",
      "[EPOCH #15, step #792] loss: 1.7941297558788092\n",
      "[EPOCH #15, step #794] loss: 1.7945056927279106\n",
      "[EPOCH #15, step #796] loss: 1.7953404089438272\n",
      "[EPOCH #15, step #798] loss: 1.795704352094772\n",
      "[EPOCH #15, step #800] loss: 1.7954794589648682\n",
      "[EPOCH #15, step #802] loss: 1.795296697064325\n",
      "[EPOCH #15, step #804] loss: 1.794739045859864\n",
      "[EPOCH #15, step #806] loss: 1.7946794443709553\n",
      "[EPOCH #15, step #808] loss: 1.795658066776686\n",
      "[EPOCH #15, step #810] loss: 1.7957351716320258\n",
      "[EPOCH #15, step #812] loss: 1.7958984221039662\n",
      "[EPOCH #15, step #814] loss: 1.795796944027298\n",
      "[EPOCH #15, step #816] loss: 1.7958695977524999\n",
      "[EPOCH #15, step #818] loss: 1.7964286444679138\n",
      "[EPOCH #15, step #820] loss: 1.797094293837135\n",
      "[EPOCH #15, step #822] loss: 1.7971785233637831\n",
      "[EPOCH #15, step #824] loss: 1.7967114659511683\n",
      "[EPOCH #15, step #826] loss: 1.7966624668460371\n",
      "[EPOCH #15, step #828] loss: 1.7968338315248202\n",
      "[EPOCH #15, step #830] loss: 1.7970405425405676\n",
      "[EPOCH #15, step #832] loss: 1.7970578943838735\n",
      "[EPOCH #15, step #834] loss: 1.796810343022832\n",
      "[EPOCH #15, step #836] loss: 1.79710048102421\n",
      "[EPOCH #15, step #838] loss: 1.7976328819386298\n",
      "[EPOCH #15, step #840] loss: 1.797155348781173\n",
      "[EPOCH #15, step #842] loss: 1.7975929173710508\n",
      "[EPOCH #15, step #844] loss: 1.7981060578272894\n",
      "[EPOCH #15, step #846] loss: 1.7985574250519627\n",
      "[EPOCH #15, step #848] loss: 1.7980556469783626\n",
      "[EPOCH #15, step #850] loss: 1.7983866358475735\n",
      "[EPOCH #15, step #852] loss: 1.798613920301234\n",
      "[EPOCH #15, step #854] loss: 1.7983482982680115\n",
      "[EPOCH #15, step #856] loss: 1.798445835413983\n",
      "[EPOCH #15, step #858] loss: 1.798186351589607\n",
      "[EPOCH #15, step #860] loss: 1.7983074423605003\n",
      "[EPOCH #15, step #862] loss: 1.7980483137718635\n",
      "[EPOCH #15, step #864] loss: 1.7978212459928038\n",
      "[EPOCH #15, step #866] loss: 1.7972807016614674\n",
      "[EPOCH #15, step #868] loss: 1.7970038301239628\n",
      "[EPOCH #15, step #870] loss: 1.7977824464320589\n",
      "[EPOCH #15, step #872] loss: 1.7981524717357151\n",
      "[EPOCH #15, step #874] loss: 1.7991662645339965\n",
      "[EPOCH #15, step #876] loss: 1.7994482506368152\n",
      "[EPOCH #15, step #878] loss: 1.7988616864157754\n",
      "[EPOCH #15, step #880] loss: 1.798451282109359\n",
      "[EPOCH #15, step #882] loss: 1.7979379954451478\n",
      "[EPOCH #15, step #884] loss: 1.7979984160870481\n",
      "[EPOCH #15, step #886] loss: 1.7974111696509927\n",
      "[EPOCH #15, step #888] loss: 1.7972256917384934\n",
      "[EPOCH #15, step #890] loss: 1.796483903487791\n",
      "[EPOCH #15, step #892] loss: 1.7963333933510945\n",
      "[EPOCH #15, step #894] loss: 1.7968971087279932\n",
      "[EPOCH #15, step #896] loss: 1.7959517696363605\n",
      "[EPOCH #15, step #898] loss: 1.796328861933529\n",
      "[EPOCH #15, step #900] loss: 1.7966440840645979\n",
      "[EPOCH #15, step #902] loss: 1.7967624030635998\n",
      "[EPOCH #15, step #904] loss: 1.7967503992892102\n",
      "[EPOCH #15, step #906] loss: 1.7968727469838572\n",
      "[EPOCH #15, step #908] loss: 1.7965258336303258\n",
      "[EPOCH #15, step #910] loss: 1.7967092094515602\n",
      "[EPOCH #15, step #912] loss: 1.7962317901529854\n",
      "[EPOCH #15, step #914] loss: 1.7964175043210306\n",
      "[EPOCH #15, step #916] loss: 1.7964614546545978\n",
      "[EPOCH #15, step #918] loss: 1.7962414014585908\n",
      "[EPOCH #15, step #920] loss: 1.7956256674891833\n",
      "[EPOCH #15, step #922] loss: 1.795151823778452\n",
      "[EPOCH #15, step #924] loss: 1.794714761553584\n",
      "[EPOCH #15, step #926] loss: 1.794294948202378\n",
      "[EPOCH #15, step #928] loss: 1.7936536015940687\n",
      "[EPOCH #15, step #930] loss: 1.7937719453162204\n",
      "[EPOCH #15, step #932] loss: 1.793549234205248\n",
      "[EPOCH #15, step #934] loss: 1.7930971756338436\n",
      "[EPOCH #15, step #936] loss: 1.7928381578136026\n",
      "[EPOCH #15, step #938] loss: 1.7929902733070529\n",
      "[EPOCH #15, step #940] loss: 1.792424251371945\n",
      "[EPOCH #15, step #942] loss: 1.7928161461810923\n",
      "[EPOCH #15, step #944] loss: 1.791865202106496\n",
      "[EPOCH #15, step #946] loss: 1.7921382957929795\n",
      "[EPOCH #15, step #948] loss: 1.791633846511077\n",
      "[EPOCH #15, step #950] loss: 1.7926420284245168\n",
      "[EPOCH #15, step #952] loss: 1.7929093742670819\n",
      "[EPOCH #15, step #954] loss: 1.7930985885140784\n",
      "[EPOCH #15, step #956] loss: 1.7932013894821535\n",
      "[EPOCH #15, step #958] loss: 1.7936671698801958\n",
      "[EPOCH #15, step #960] loss: 1.7936849450221544\n",
      "[EPOCH #15, step #962] loss: 1.7937891995795419\n",
      "[EPOCH #15, step #964] loss: 1.7935845004462208\n",
      "[EPOCH #15, step #966] loss: 1.7929107891366796\n",
      "[EPOCH #15, step #968] loss: 1.7928292892788709\n",
      "[EPOCH #15, step #970] loss: 1.7931388114434192\n",
      "[EPOCH #15, step #972] loss: 1.7934769491252527\n",
      "[EPOCH #15, step #974] loss: 1.7932120929620206\n",
      "[EPOCH #15, step #976] loss: 1.7933403055889945\n",
      "[EPOCH #15, step #978] loss: 1.7924299091557316\n",
      "[EPOCH #15, step #980] loss: 1.7928543292540415\n",
      "[EPOCH #15, step #982] loss: 1.792502209953471\n",
      "[EPOCH #15, step #984] loss: 1.7927709981269644\n",
      "[EPOCH #15, step #986] loss: 1.7932281461530182\n",
      "[EPOCH #15, step #988] loss: 1.7931315216666164\n",
      "[EPOCH #15, step #990] loss: 1.792974722974837\n",
      "[EPOCH #15, step #992] loss: 1.7927422441864782\n",
      "[EPOCH #15, step #994] loss: 1.7932280293661147\n",
      "[EPOCH #15, step #996] loss: 1.7931658256735463\n",
      "[EPOCH #15, step #998] loss: 1.7930864570615765\n",
      "[EPOCH #15, step #1000] loss: 1.79310244554049\n",
      "[EPOCH #15, step #1002] loss: 1.7934497566308718\n",
      "[EPOCH #15, step #1004] loss: 1.793046872651399\n",
      "[EPOCH #15, step #1006] loss: 1.7929570285423984\n",
      "[EPOCH #15, step #1008] loss: 1.793201344691372\n",
      "[EPOCH #15, step #1010] loss: 1.792667987556533\n",
      "[EPOCH #15, step #1012] loss: 1.7926827693856362\n",
      "[EPOCH #15, step #1014] loss: 1.7926316297700253\n",
      "[EPOCH #15, step #1016] loss: 1.7933299359787647\n",
      "[EPOCH #15, step #1018] loss: 1.7936171417264406\n",
      "[EPOCH #15, step #1020] loss: 1.7931919602292292\n",
      "[EPOCH #15, step #1022] loss: 1.7927868462960626\n",
      "[EPOCH #15, step #1024] loss: 1.7925998441184439\n",
      "[EPOCH #15, step #1026] loss: 1.792398488277818\n",
      "[EPOCH #15, step #1028] loss: 1.7923868047716087\n",
      "[EPOCH #15, step #1030] loss: 1.7929217977274055\n",
      "[EPOCH #15, step #1032] loss: 1.7929029119672526\n",
      "[EPOCH #15, step #1034] loss: 1.7927143570305644\n",
      "[EPOCH #15, step #1036] loss: 1.7925111592218295\n",
      "[EPOCH #15, step #1038] loss: 1.7924852149777968\n",
      "[EPOCH #15, step #1040] loss: 1.7921897807336564\n",
      "[EPOCH #15, step #1042] loss: 1.7921639237399298\n",
      "[EPOCH #15, step #1044] loss: 1.7926618784808657\n",
      "[EPOCH #15, step #1046] loss: 1.7923538994538637\n",
      "[EPOCH #15, step #1048] loss: 1.7919067669414814\n",
      "[EPOCH #15, step #1050] loss: 1.79238861600747\n",
      "[EPOCH #15, step #1052] loss: 1.7919254941478413\n",
      "[EPOCH #15, step #1054] loss: 1.7918037248448737\n",
      "[EPOCH #15, step #1056] loss: 1.791569449818123\n",
      "[EPOCH #15, step #1058] loss: 1.791002259263461\n",
      "[EPOCH #15, step #1060] loss: 1.7914201490840858\n",
      "[EPOCH #15, step #1062] loss: 1.7911662412833629\n",
      "[EPOCH #15, step #1064] loss: 1.790965607804312\n",
      "[EPOCH #15, step #1066] loss: 1.7908131340003617\n",
      "[EPOCH #15, step #1068] loss: 1.7910427779544726\n",
      "[EPOCH #15, step #1070] loss: 1.791010064682484\n",
      "[EPOCH #15, step #1072] loss: 1.79037830636308\n",
      "[EPOCH #15, step #1074] loss: 1.7903597897152568\n",
      "[EPOCH #15, step #1076] loss: 1.7900476260880354\n",
      "[EPOCH #15, step #1078] loss: 1.7902324607352398\n",
      "[EPOCH #15, step #1080] loss: 1.7897643568778236\n",
      "[EPOCH #15, step #1082] loss: 1.7893998164989722\n",
      "[EPOCH #15, step #1084] loss: 1.788978427676012\n",
      "[EPOCH #15, step #1086] loss: 1.7885744466404359\n",
      "[EPOCH #15, step #1088] loss: 1.788504421108901\n",
      "[EPOCH #15, step #1090] loss: 1.788373047337414\n",
      "[EPOCH #15, step #1092] loss: 1.7878534553908254\n",
      "[EPOCH #15, step #1094] loss: 1.7873234440746917\n",
      "[EPOCH #15, step #1096] loss: 1.786867514239079\n",
      "[EPOCH #15, step #1098] loss: 1.7866039219718288\n",
      "[EPOCH #15, step #1100] loss: 1.7865525431030993\n",
      "[EPOCH #15, step #1102] loss: 1.7866302065058177\n",
      "[EPOCH #15, step #1104] loss: 1.7859288990227884\n",
      "[EPOCH #15, step #1106] loss: 1.7861556075345102\n",
      "[EPOCH #15, step #1108] loss: 1.7852685252646265\n",
      "[EPOCH #15, step #1110] loss: 1.7849943854592063\n",
      "[EPOCH #15, step #1112] loss: 1.785333025273394\n",
      "[EPOCH #15, step #1114] loss: 1.7854612986603124\n",
      "[EPOCH #15, step #1116] loss: 1.7858481920501859\n",
      "[EPOCH #15, step #1118] loss: 1.7859085134569292\n",
      "[EPOCH #15, step #1120] loss: 1.785272832431504\n",
      "[EPOCH #15, step #1122] loss: 1.7851837559247379\n",
      "[EPOCH #15, step #1124] loss: 1.7858403031031291\n",
      "[EPOCH #15, step #1126] loss: 1.786084419557661\n",
      "[EPOCH #15, step #1128] loss: 1.7861935992067741\n",
      "[EPOCH #15, step #1130] loss: 1.7863866472328584\n",
      "[EPOCH #15, step #1132] loss: 1.7859086237012656\n",
      "[EPOCH #15, step #1134] loss: 1.7855758435925724\n",
      "[EPOCH #15, step #1136] loss: 1.7860295632059573\n",
      "[EPOCH #15, step #1138] loss: 1.7860191213760175\n",
      "[EPOCH #15, step #1140] loss: 1.7862507885323606\n",
      "[EPOCH #15, step #1142] loss: 1.7859833901739912\n",
      "[EPOCH #15, step #1144] loss: 1.7860294702271706\n",
      "[EPOCH #15, step #1146] loss: 1.785936660005824\n",
      "[EPOCH #15, step #1148] loss: 1.7865451388612221\n",
      "[EPOCH #15, step #1150] loss: 1.7867612815959675\n",
      "[EPOCH #15, step #1152] loss: 1.7863528675755933\n",
      "[EPOCH #15, step #1154] loss: 1.7865131092277957\n",
      "[EPOCH #15, step #1156] loss: 1.7868884132149514\n",
      "[EPOCH #15, step #1158] loss: 1.7871840175006592\n",
      "[EPOCH #15, step #1160] loss: 1.7873145430176347\n",
      "[EPOCH #15, step #1162] loss: 1.7869484017659956\n",
      "[EPOCH #15, step #1164] loss: 1.787104549940052\n",
      "[EPOCH #15, step #1166] loss: 1.786951507680316\n",
      "[EPOCH #15, step #1168] loss: 1.7863889852071848\n",
      "[EPOCH #15, step #1170] loss: 1.7859821820442336\n",
      "[EPOCH #15, step #1172] loss: 1.7855722185697498\n",
      "[EPOCH #15, step #1174] loss: 1.7862171399339717\n",
      "[EPOCH #15, step #1176] loss: 1.7861089102778276\n",
      "[EPOCH #15, step #1178] loss: 1.7853559990673373\n",
      "[EPOCH #15, step #1180] loss: 1.7854132361577588\n",
      "[EPOCH #15, step #1182] loss: 1.7849760098872502\n",
      "[EPOCH #15, step #1184] loss: 1.7850031897991518\n",
      "[EPOCH #15, step #1186] loss: 1.7849389265441251\n",
      "[EPOCH #15, step #1188] loss: 1.784104704455832\n",
      "[EPOCH #15, step #1190] loss: 1.784245318769908\n",
      "[EPOCH #15, step #1192] loss: 1.7843379385813083\n",
      "[EPOCH #15, step #1194] loss: 1.7842871799628606\n",
      "[EPOCH #15, step #1196] loss: 1.784091531782222\n",
      "[EPOCH #15, step #1198] loss: 1.784576359343986\n",
      "[EPOCH #15, step #1200] loss: 1.784987146908\n",
      "[EPOCH #15, step #1202] loss: 1.7846105540680668\n",
      "[EPOCH #15, step #1204] loss: 1.7843788646563454\n",
      "[EPOCH #15, step #1206] loss: 1.7845469067288313\n",
      "[EPOCH #15, step #1208] loss: 1.7844144669912194\n",
      "[EPOCH #15, step #1210] loss: 1.784589859004064\n",
      "[EPOCH #15, step #1212] loss: 1.7845024071934787\n",
      "[EPOCH #15, step #1214] loss: 1.7844977504431956\n",
      "[EPOCH #15, step #1216] loss: 1.7846514038502828\n",
      "[EPOCH #15, step #1218] loss: 1.7848969613850556\n",
      "[EPOCH #15, step #1220] loss: 1.7851802302031707\n",
      "[EPOCH #15, step #1222] loss: 1.7856520738936992\n",
      "[EPOCH #15, step #1224] loss: 1.7854237293710513\n",
      "[EPOCH #15, step #1226] loss: 1.7847205986797858\n",
      "[EPOCH #15, step #1228] loss: 1.7851831089975\n",
      "[EPOCH #15, step #1230] loss: 1.785047548220082\n",
      "[EPOCH #15, step #1232] loss: 1.7853269728334185\n",
      "[EPOCH #15, step #1234] loss: 1.7854370595472544\n",
      "[EPOCH #15, step #1236] loss: 1.7852569458555962\n",
      "[EPOCH #15, step #1238] loss: 1.7852485756704748\n",
      "[EPOCH #15, step #1240] loss: 1.7853462311358916\n",
      "[EPOCH #15, step #1242] loss: 1.7852668110535976\n",
      "[EPOCH #15, step #1244] loss: 1.785170334170621\n",
      "[EPOCH #15, step #1246] loss: 1.7851361542486055\n",
      "[EPOCH #15, step #1248] loss: 1.7857217855984158\n",
      "[EPOCH #15, step #1250] loss: 1.7860079528711779\n",
      "[EPOCH #15, step #1252] loss: 1.7862899609308478\n",
      "[EPOCH #15, step #1254] loss: 1.7865862512493513\n",
      "[EPOCH #15, step #1256] loss: 1.7870390364454205\n",
      "[EPOCH #15, step #1258] loss: 1.7871481907850604\n",
      "[EPOCH #15, step #1260] loss: 1.786605174393998\n",
      "[EPOCH #15, step #1262] loss: 1.7867013082462744\n",
      "[EPOCH #15, step #1264] loss: 1.7865621050827116\n",
      "[EPOCH #15, step #1266] loss: 1.7864207777811396\n",
      "[EPOCH #15, step #1268] loss: 1.7862910580409617\n",
      "[EPOCH #15, step #1270] loss: 1.7863113849675158\n",
      "[EPOCH #15, step #1272] loss: 1.7865340229758857\n",
      "[EPOCH #15, step #1274] loss: 1.7864684585029003\n",
      "[EPOCH #15, step #1276] loss: 1.7861058531371334\n",
      "[EPOCH #15, step #1278] loss: 1.7872608344101923\n",
      "[EPOCH #15, step #1280] loss: 1.7875736835038263\n",
      "[EPOCH #15, step #1282] loss: 1.7878894490463513\n",
      "[EPOCH #15, step #1284] loss: 1.7877088838514188\n",
      "[EPOCH #15, step #1286] loss: 1.7873230074483846\n",
      "[EPOCH #15, step #1288] loss: 1.7872521540191952\n",
      "[EPOCH #15, step #1290] loss: 1.787417759597994\n",
      "[EPOCH #15, step #1292] loss: 1.7875396376972685\n",
      "[EPOCH #15, step #1294] loss: 1.7872975342522257\n",
      "[EPOCH #15, step #1296] loss: 1.7873242393584092\n",
      "[EPOCH #15, step #1298] loss: 1.786635200687332\n",
      "[EPOCH #15, step #1300] loss: 1.7867345376073351\n",
      "[EPOCH #15, step #1302] loss: 1.7868146429314398\n",
      "[EPOCH #15, step #1304] loss: 1.7871684733478503\n",
      "[EPOCH #15, step #1306] loss: 1.787067394860391\n",
      "[EPOCH #15, step #1308] loss: 1.787100984769709\n",
      "[EPOCH #15, step #1310] loss: 1.7872956358777212\n",
      "[EPOCH #15, step #1312] loss: 1.7868866488757427\n",
      "[EPOCH #15, step #1314] loss: 1.7869248169456597\n",
      "[EPOCH #15, step #1316] loss: 1.7872741867306563\n",
      "[EPOCH #15, step #1318] loss: 1.7872053755784776\n",
      "[EPOCH #15, step #1320] loss: 1.7871979331988264\n",
      "[EPOCH #15, step #1322] loss: 1.7871090299418184\n",
      "[EPOCH #15, step #1324] loss: 1.7872929553715688\n",
      "[EPOCH #15, step #1326] loss: 1.7870800616872338\n",
      "[EPOCH #15, step #1328] loss: 1.7869688814703553\n",
      "[EPOCH #15, step #1330] loss: 1.7876186650736183\n",
      "[EPOCH #15, step #1332] loss: 1.7876297414794686\n",
      "[EPOCH #15, step #1334] loss: 1.7873229704992601\n",
      "[EPOCH #15, step #1336] loss: 1.7874680435202777\n",
      "[EPOCH #15, step #1338] loss: 1.7871804715004138\n",
      "[EPOCH #15, step #1340] loss: 1.7867510337868704\n",
      "[EPOCH #15, step #1342] loss: 1.7876082636133026\n",
      "[EPOCH #15, step #1344] loss: 1.7875570935830751\n",
      "[EPOCH #15, step #1346] loss: 1.7873720056761082\n",
      "[EPOCH #15, step #1348] loss: 1.7875080479349006\n",
      "[EPOCH #15, step #1350] loss: 1.787656197320259\n",
      "[EPOCH #15, step #1352] loss: 1.7878746928678824\n",
      "[EPOCH #15, step #1354] loss: 1.7879789669575286\n",
      "[EPOCH #15, step #1356] loss: 1.7876499256581706\n",
      "[EPOCH #15, step #1358] loss: 1.7876958865028167\n",
      "[EPOCH #15, step #1360] loss: 1.7875634890369945\n",
      "[EPOCH #15, step #1362] loss: 1.7874857717721846\n",
      "[EPOCH #15, step #1364] loss: 1.787475980463482\n",
      "[EPOCH #15, step #1366] loss: 1.7880870472277353\n",
      "[EPOCH #15, step #1368] loss: 1.788542788293433\n",
      "[EPOCH #15, step #1370] loss: 1.7883220241941038\n",
      "[EPOCH #15, step #1372] loss: 1.7883165424007268\n",
      "[EPOCH #15, step #1374] loss: 1.7879852362979543\n",
      "[EPOCH #15, step #1376] loss: 1.7877774851947221\n",
      "[EPOCH #15, step #1378] loss: 1.7877541399676355\n",
      "[EPOCH #15, step #1380] loss: 1.7881691836085032\n",
      "[EPOCH #15, step #1382] loss: 1.7880472758069732\n",
      "[EPOCH #15, step #1384] loss: 1.7881199259620282\n",
      "[EPOCH #15, step #1386] loss: 1.7880893133919102\n",
      "[EPOCH #15, step #1388] loss: 1.788028670910711\n",
      "[EPOCH #15, step #1390] loss: 1.7880067385245706\n",
      "[EPOCH #15, step #1392] loss: 1.788427520936458\n",
      "[EPOCH #15, step #1394] loss: 1.7882511209416132\n",
      "[EPOCH #15, step #1396] loss: 1.7879279557943515\n",
      "[EPOCH #15, step #1398] loss: 1.7876966443123181\n",
      "[EPOCH #15, step #1400] loss: 1.78808867697372\n",
      "[EPOCH #15, step #1402] loss: 1.7881400517625463\n",
      "[EPOCH #15, step #1404] loss: 1.7884065376481977\n",
      "[EPOCH #15, step #1406] loss: 1.7880214986940097\n",
      "[EPOCH #15, step #1408] loss: 1.7878908195167336\n",
      "[EPOCH #15, step #1410] loss: 1.7880235839025254\n",
      "[EPOCH #15, step #1412] loss: 1.7875670721492105\n",
      "[EPOCH #15, step #1414] loss: 1.7875766942442095\n",
      "[EPOCH #15, step #1416] loss: 1.787577847611677\n",
      "[EPOCH #15, step #1418] loss: 1.7874072976226618\n",
      "[EPOCH #15, step #1420] loss: 1.7875026205658158\n",
      "[EPOCH #15, step #1422] loss: 1.7881108451626793\n",
      "[EPOCH #15, step #1424] loss: 1.788031408703118\n",
      "[EPOCH #15, step #1426] loss: 1.7881841350036145\n",
      "[EPOCH #15, step #1428] loss: 1.7881864718493254\n",
      "[EPOCH #15, step #1430] loss: 1.7883631327950313\n",
      "[EPOCH #15, step #1432] loss: 1.788493056481981\n",
      "[EPOCH #15, step #1434] loss: 1.788719731050086\n",
      "[EPOCH #15, step #1436] loss: 1.7888976393180667\n",
      "[EPOCH #15, step #1438] loss: 1.7890572409981071\n",
      "[EPOCH #15, step #1440] loss: 1.7887144459774724\n",
      "[EPOCH #15, step #1442] loss: 1.7886366692584006\n",
      "[EPOCH #15, step #1444] loss: 1.7883080093505885\n",
      "[EPOCH #15, step #1446] loss: 1.7889420907499054\n",
      "[EPOCH #15, step #1448] loss: 1.7888278809393414\n",
      "[EPOCH #15, step #1450] loss: 1.7887832717103518\n",
      "[EPOCH #15, step #1452] loss: 1.7886666718714006\n",
      "[EPOCH #15, step #1454] loss: 1.7887111060398142\n",
      "[EPOCH #15, step #1456] loss: 1.788853344437842\n",
      "[EPOCH #15, step #1458] loss: 1.7882561885060473\n",
      "[EPOCH #15, step #1460] loss: 1.7884756429076276\n",
      "[EPOCH #15, step #1462] loss: 1.788703860074628\n",
      "[EPOCH #15, step #1464] loss: 1.788258282926709\n",
      "[EPOCH #15, step #1466] loss: 1.7882214078061338\n",
      "[EPOCH #15, step #1468] loss: 1.7883244975640549\n",
      "[EPOCH #15, step #1470] loss: 1.7881186639346855\n",
      "[EPOCH #15, step #1472] loss: 1.787830506670823\n",
      "[EPOCH #15, step #1474] loss: 1.7875937661073975\n",
      "[EPOCH #15, step #1476] loss: 1.7874818161765547\n",
      "[EPOCH #15, step #1478] loss: 1.787513045985768\n",
      "[EPOCH #15, step #1480] loss: 1.787309829042539\n",
      "[EPOCH #15, step #1482] loss: 1.7870788939563471\n",
      "[EPOCH #15, step #1484] loss: 1.7871957410866965\n",
      "[EPOCH #15, step #1486] loss: 1.786978804311579\n",
      "[EPOCH #15, step #1488] loss: 1.7870646576260143\n",
      "[EPOCH #15, step #1490] loss: 1.787044334259711\n",
      "[EPOCH #15, step #1492] loss: 1.787237160611456\n",
      "[EPOCH #15, step #1494] loss: 1.7871133201098361\n",
      "[EPOCH #15, step #1496] loss: 1.7873914708036858\n",
      "[EPOCH #15, step #1498] loss: 1.787219720852224\n",
      "[EPOCH #15, step #1500] loss: 1.7872929733884406\n",
      "[EPOCH #15, step #1502] loss: 1.7872425379232812\n",
      "[EPOCH #15, step #1504] loss: 1.7872647326253974\n",
      "[EPOCH #15, step #1506] loss: 1.7871165893769216\n",
      "[EPOCH #15, step #1508] loss: 1.7868263841939336\n",
      "[EPOCH #15, step #1510] loss: 1.7870722453299144\n",
      "[EPOCH #15, step #1512] loss: 1.787159306082754\n",
      "[EPOCH #15, step #1514] loss: 1.7869765557471675\n",
      "[EPOCH #15, step #1516] loss: 1.7876117987387574\n",
      "[EPOCH #15, step #1518] loss: 1.78756090255063\n",
      "[EPOCH #15, step #1520] loss: 1.7879486208993458\n",
      "[EPOCH #15, step #1522] loss: 1.7877261581893666\n",
      "[EPOCH #15, step #1524] loss: 1.7878154301643372\n",
      "[EPOCH #15, step #1526] loss: 1.787546169195756\n",
      "[EPOCH #15, step #1528] loss: 1.7875938937506541\n",
      "[EPOCH #15, step #1530] loss: 1.7875450923114256\n",
      "[EPOCH #15, step #1532] loss: 1.7874454720612842\n",
      "[EPOCH #15, step #1534] loss: 1.7877757342319924\n",
      "[EPOCH #15, step #1536] loss: 1.7878221105505447\n",
      "[EPOCH #15, step #1538] loss: 1.7878786455198417\n",
      "[EPOCH #15, step #1540] loss: 1.7877170163497453\n",
      "[EPOCH #15, step #1542] loss: 1.7873897324965051\n",
      "[EPOCH #15, step #1544] loss: 1.7868091572835607\n",
      "[EPOCH #15, step #1546] loss: 1.7863383520859322\n",
      "[EPOCH #15, step #1548] loss: 1.7863494969322422\n",
      "[EPOCH #15, step #1550] loss: 1.786447683624265\n",
      "[EPOCH #15, step #1552] loss: 1.7867573014168454\n",
      "[EPOCH #15, step #1554] loss: 1.7866647939206703\n",
      "[EPOCH #15, step #1556] loss: 1.7869282214780917\n",
      "[EPOCH #15, step #1558] loss: 1.78708674943623\n",
      "[EPOCH #15, step #1560] loss: 1.7873346270619868\n",
      "[EPOCH #15, step #1562] loss: 1.78725556765164\n",
      "[EPOCH #15, step #1564] loss: 1.7873098648775119\n",
      "[EPOCH #15, step #1566] loss: 1.7873849910995956\n",
      "[EPOCH #15, step #1568] loss: 1.7874653210603484\n",
      "[EPOCH #15, step #1570] loss: 1.7875218299222857\n",
      "[EPOCH #15, step #1572] loss: 1.7871803301046096\n",
      "[EPOCH #15, step #1574] loss: 1.7868700818031553\n",
      "[EPOCH #15, step #1576] loss: 1.7867246518122977\n",
      "[EPOCH #15, step #1578] loss: 1.7867538826687568\n",
      "[EPOCH #15, step #1580] loss: 1.7867262583982333\n",
      "[EPOCH #15, step #1582] loss: 1.7864049280360013\n",
      "[EPOCH #15, step #1584] loss: 1.7865650583516912\n",
      "[EPOCH #15, step #1586] loss: 1.7866649528907843\n",
      "[EPOCH #15, step #1588] loss: 1.7865698465466724\n",
      "[EPOCH #15, step #1590] loss: 1.7867757652556648\n",
      "[EPOCH #15, step #1592] loss: 1.786516376022116\n",
      "[EPOCH #15, step #1594] loss: 1.7863530704967654\n",
      "[EPOCH #15, step #1596] loss: 1.7864994724691101\n",
      "[EPOCH #15, step #1598] loss: 1.786522588966935\n",
      "[EPOCH #15, step #1600] loss: 1.786189223400583\n",
      "[EPOCH #15, step #1602] loss: 1.7859755345827628\n",
      "[EPOCH #15, step #1604] loss: 1.7858789487419842\n",
      "[EPOCH #15, step #1606] loss: 1.7861271655626303\n",
      "[EPOCH #15, step #1608] loss: 1.7856848455868277\n",
      "[EPOCH #15, step #1610] loss: 1.7856641405121574\n",
      "[EPOCH #15, step #1612] loss: 1.785078372965669\n",
      "[EPOCH #15, step #1614] loss: 1.785143746126547\n",
      "[EPOCH #15, step #1616] loss: 1.7851672058645118\n",
      "[EPOCH #15, step #1618] loss: 1.7849893635110108\n",
      "[EPOCH #15, step #1620] loss: 1.784489749280999\n",
      "[EPOCH #15, step #1622] loss: 1.7843345287253074\n",
      "[EPOCH #15, step #1624] loss: 1.7839427577165456\n",
      "[EPOCH #15, step #1626] loss: 1.7842511884918517\n",
      "[EPOCH #15, step #1628] loss: 1.7839636819870506\n",
      "[EPOCH #15, step #1630] loss: 1.7840349829540452\n",
      "[EPOCH #15, step #1632] loss: 1.784106533766815\n",
      "[EPOCH #15, step #1634] loss: 1.7840382265752974\n",
      "[EPOCH #15, step #1636] loss: 1.7839866152389354\n",
      "[EPOCH #15, step #1638] loss: 1.783749836512351\n",
      "[EPOCH #15, step #1640] loss: 1.7837907181579409\n",
      "[EPOCH #15, step #1642] loss: 1.7836915013344639\n",
      "[EPOCH #15, step #1644] loss: 1.7837901998435834\n",
      "[EPOCH #15, step #1646] loss: 1.7837194058485442\n",
      "[EPOCH #15, step #1648] loss: 1.7839001923564566\n",
      "[EPOCH #15, step #1650] loss: 1.7836560622841426\n",
      "[EPOCH #15, step #1652] loss: 1.7836074934752868\n",
      "[EPOCH #15, step #1654] loss: 1.7836101976046028\n",
      "[EPOCH #15, step #1656] loss: 1.7834647741746528\n",
      "[EPOCH #15, step #1658] loss: 1.7833369152958383\n",
      "[EPOCH #15, step #1660] loss: 1.7830696122822884\n",
      "[EPOCH #15, step #1662] loss: 1.783423622437292\n",
      "[EPOCH #15, step #1664] loss: 1.7834121889896222\n",
      "[EPOCH #15, step #1666] loss: 1.7834501745962568\n",
      "[EPOCH #15, step #1668] loss: 1.7830632652544989\n",
      "[EPOCH #15, step #1670] loss: 1.7833808759313226\n",
      "[EPOCH #15, step #1672] loss: 1.7828769061427165\n",
      "[EPOCH #15, step #1674] loss: 1.7827986082034324\n",
      "[EPOCH #15, step #1676] loss: 1.7827294563422547\n",
      "[EPOCH #15, step #1678] loss: 1.7825718095360803\n",
      "[EPOCH #15, step #1680] loss: 1.7823524415883047\n",
      "[EPOCH #15, step #1682] loss: 1.7824708674184921\n",
      "[EPOCH #15, step #1684] loss: 1.7825372879512231\n",
      "[EPOCH #15, step #1686] loss: 1.7827714937073844\n",
      "[EPOCH #15, step #1688] loss: 1.7824110140314886\n",
      "[EPOCH #15, step #1690] loss: 1.7823091786616938\n",
      "[EPOCH #15, step #1692] loss: 1.7823540909855027\n",
      "[EPOCH #15, step #1694] loss: 1.7820483805858984\n",
      "[EPOCH #15, step #1696] loss: 1.7819739441416442\n",
      "[EPOCH #15, step #1698] loss: 1.7818926832057085\n",
      "[EPOCH #15, step #1700] loss: 1.7818955667645422\n",
      "[EPOCH #15, step #1702] loss: 1.7817439653911242\n",
      "[EPOCH #15, step #1704] loss: 1.7818330133765323\n",
      "[EPOCH #15, step #1706] loss: 1.781727870060955\n",
      "[EPOCH #15, step #1708] loss: 1.7817803231019456\n",
      "[EPOCH #15, step #1710] loss: 1.7819667293410912\n",
      "[EPOCH #15, step #1712] loss: 1.7822222394060825\n",
      "[EPOCH #15, step #1714] loss: 1.782453767029954\n",
      "[EPOCH #15, step #1716] loss: 1.7823832123586447\n",
      "[EPOCH #15, step #1718] loss: 1.7819838834890729\n",
      "[EPOCH #15, step #1720] loss: 1.782148521733381\n",
      "[EPOCH #15, step #1722] loss: 1.7822558912716144\n",
      "[EPOCH #15, step #1724] loss: 1.78203080125477\n",
      "[EPOCH #15, step #1726] loss: 1.7823945892361044\n",
      "[EPOCH #15, step #1728] loss: 1.7822681367224942\n",
      "[EPOCH #15, step #1730] loss: 1.7821565432262034\n",
      "[EPOCH #15, step #1732] loss: 1.7819173059158082\n",
      "[EPOCH #15, step #1734] loss: 1.7821556541005885\n",
      "[EPOCH #15, step #1736] loss: 1.7817463026900502\n",
      "[EPOCH #15, step #1738] loss: 1.7817449181363663\n",
      "[EPOCH #15, step #1740] loss: 1.7814087618157344\n",
      "[EPOCH #15, step #1742] loss: 1.781894319404902\n",
      "[EPOCH #15, step #1744] loss: 1.7822410490929568\n",
      "[EPOCH #15, step #1746] loss: 1.7820382446101821\n",
      "[EPOCH #15, step #1748] loss: 1.7816824535767373\n",
      "[EPOCH #15, step #1750] loss: 1.7820518526399156\n",
      "[EPOCH #15, step #1752] loss: 1.7819718071820052\n",
      "[EPOCH #15, step #1754] loss: 1.7818967307395066\n",
      "[EPOCH #15, step #1756] loss: 1.7817054166329742\n",
      "[EPOCH #15, step #1758] loss: 1.7823036181581096\n",
      "[EPOCH #15, step #1760] loss: 1.7820458571589988\n",
      "[EPOCH #15, step #1762] loss: 1.7816524117830053\n",
      "[EPOCH #15, step #1764] loss: 1.7813493792463633\n",
      "[EPOCH #15, step #1766] loss: 1.7813443954407866\n",
      "[EPOCH #15, step #1768] loss: 1.7817379622691225\n",
      "[EPOCH #15, step #1770] loss: 1.7817404177618323\n",
      "[EPOCH #15, step #1772] loss: 1.7817496076453156\n",
      "[EPOCH #15, step #1774] loss: 1.781845989260875\n",
      "[EPOCH #15, step #1776] loss: 1.7820035445602944\n",
      "[EPOCH #15, step #1778] loss: 1.7818139840070286\n",
      "[EPOCH #15, step #1780] loss: 1.781575654243767\n",
      "[EPOCH #15, step #1782] loss: 1.781995617166638\n",
      "[EPOCH #15, step #1784] loss: 1.7819245219898492\n",
      "[EPOCH #15, step #1786] loss: 1.7820543521399197\n",
      "[EPOCH #15, step #1788] loss: 1.7821626376346078\n",
      "[EPOCH #15, step #1790] loss: 1.7818485379618416\n",
      "[EPOCH #15, step #1792] loss: 1.7815428430051425\n",
      "[EPOCH #15, step #1794] loss: 1.781562028455867\n",
      "[EPOCH #15, step #1796] loss: 1.7817456784285501\n",
      "[EPOCH #15, step #1798] loss: 1.7821233683059188\n",
      "[EPOCH #15, step #1800] loss: 1.782049841347302\n",
      "[EPOCH #15, step #1802] loss: 1.7822924055989688\n",
      "[EPOCH #15, step #1804] loss: 1.7820940274941295\n",
      "[EPOCH #15, step #1806] loss: 1.7823176415308313\n",
      "[EPOCH #15, step #1808] loss: 1.782190304721107\n",
      "[EPOCH #15, step #1810] loss: 1.7824927436456306\n",
      "[EPOCH #15, step #1812] loss: 1.7826194262478277\n",
      "[EPOCH #15, step #1814] loss: 1.7823140638590516\n",
      "[EPOCH #15, step #1816] loss: 1.7824769691575932\n",
      "[EPOCH #15, step #1818] loss: 1.7826718340017036\n",
      "[EPOCH #15, step #1820] loss: 1.782510225586941\n",
      "[EPOCH #15, step #1822] loss: 1.7823766128937097\n",
      "[EPOCH #15, step #1824] loss: 1.7822510588332399\n",
      "[EPOCH #15, step #1826] loss: 1.781995395493103\n",
      "[EPOCH #15, step #1828] loss: 1.7820214015203073\n",
      "[EPOCH #15, step #1830] loss: 1.7822341576161638\n",
      "[EPOCH #15, step #1832] loss: 1.7821403831910125\n",
      "[EPOCH #15, step #1834] loss: 1.78174962617396\n",
      "[EPOCH #15, step #1836] loss: 1.7818229309099163\n",
      "[EPOCH #15, step #1838] loss: 1.781801413070125\n",
      "[EPOCH #15, step #1840] loss: 1.781681749919133\n",
      "[EPOCH #15, step #1842] loss: 1.7816903482813324\n",
      "[EPOCH #15, step #1844] loss: 1.781515781504675\n",
      "[EPOCH #15, step #1846] loss: 1.7815366602292497\n",
      "[EPOCH #15, step #1848] loss: 1.7817774313794656\n",
      "[EPOCH #15, step #1850] loss: 1.7812668024881797\n",
      "[EPOCH #15, step #1852] loss: 1.7812348400587914\n",
      "[EPOCH #15, step #1854] loss: 1.7810730902975138\n",
      "[EPOCH #15, step #1856] loss: 1.7813834940225255\n",
      "[EPOCH #15, step #1858] loss: 1.7816143560114568\n",
      "[EPOCH #15, step #1860] loss: 1.7812755669335536\n",
      "[EPOCH #15, step #1862] loss: 1.7812481122636308\n",
      "[EPOCH #15, step #1864] loss: 1.7811447310064177\n",
      "[EPOCH #15, step #1866] loss: 1.7811233161858333\n",
      "[EPOCH #15, step #1868] loss: 1.7814375651016663\n",
      "[EPOCH #15, step #1870] loss: 1.7813223040021084\n",
      "[EPOCH #15, step #1872] loss: 1.781270396276648\n",
      "[EPOCH #15, step #1874] loss: 1.7812949946403502\n",
      "[EPOCH #15, step #1876] loss: 1.7815479188442993\n",
      "[EPOCH #15, step #1878] loss: 1.78139277647124\n",
      "[EPOCH #15, step #1880] loss: 1.7812704926852785\n",
      "[EPOCH #15, step #1882] loss: 1.781691640188133\n",
      "[EPOCH #15, step #1884] loss: 1.78162670005854\n",
      "[EPOCH #15, step #1886] loss: 1.7821412086170947\n",
      "[EPOCH #15, step #1888] loss: 1.7822076743907433\n",
      "[EPOCH #15, step #1890] loss: 1.7822119579751425\n",
      "[EPOCH #15, step #1892] loss: 1.7823949800681262\n",
      "[EPOCH #15, step #1894] loss: 1.7821001148160969\n",
      "[EPOCH #15, step #1896] loss: 1.7822706655068465\n",
      "[EPOCH #15, step #1898] loss: 1.782111062100839\n",
      "[EPOCH #15, step #1900] loss: 1.782049941395785\n",
      "[EPOCH #15, step #1902] loss: 1.7824273258839165\n",
      "[EPOCH #15, step #1904] loss: 1.7824641504625636\n",
      "[EPOCH #15, step #1906] loss: 1.7821141854905307\n",
      "[EPOCH #15, step #1908] loss: 1.78232817124671\n",
      "[EPOCH #15, step #1910] loss: 1.7826427419980366\n",
      "[EPOCH #15, step #1912] loss: 1.7827003242392472\n",
      "[EPOCH #15, step #1914] loss: 1.7823969497693115\n",
      "[EPOCH #15, step #1916] loss: 1.7821159740879813\n",
      "[EPOCH #15, step #1918] loss: 1.7818360173994205\n",
      "[EPOCH #15, step #1920] loss: 1.7818391092241834\n",
      "[EPOCH #15, step #1922] loss: 1.782039301133813\n",
      "[EPOCH #15, step #1924] loss: 1.7822619251771408\n",
      "[EPOCH #15, step #1926] loss: 1.7821930230560856\n",
      "[EPOCH #15, step #1928] loss: 1.782138071819066\n",
      "[EPOCH #15, step #1930] loss: 1.781901214482067\n",
      "[EPOCH #15, step #1932] loss: 1.7821193864415854\n",
      "[EPOCH #15, step #1934] loss: 1.7819794442302497\n",
      "[EPOCH #15, step #1936] loss: 1.7817689386544058\n",
      "[EPOCH #15, step #1938] loss: 1.7815617396697487\n",
      "[EPOCH #15, step #1940] loss: 1.7813964313234882\n",
      "[EPOCH #15, step #1942] loss: 1.781604185830792\n",
      "[EPOCH #15, step #1944] loss: 1.7817441637534408\n",
      "[EPOCH #15, step #1946] loss: 1.7819625266588952\n",
      "[EPOCH #15, step #1948] loss: 1.7820926452673906\n",
      "[EPOCH #15, step #1950] loss: 1.782174971090226\n",
      "[EPOCH #15, step #1952] loss: 1.782173748939268\n",
      "[EPOCH #15, step #1954] loss: 1.7823065137619252\n",
      "[EPOCH #15, step #1956] loss: 1.7823588606284233\n",
      "[EPOCH #15, step #1958] loss: 1.7821651978904096\n",
      "[EPOCH #15, step #1960] loss: 1.782093035998483\n",
      "[EPOCH #15, step #1962] loss: 1.7821235280223968\n",
      "[EPOCH #15, step #1964] loss: 1.7820097019350862\n",
      "[EPOCH #15, step #1966] loss: 1.7818414519508297\n",
      "[EPOCH #15, step #1968] loss: 1.7823016869349793\n",
      "[EPOCH #15, step #1970] loss: 1.782030905218429\n",
      "[EPOCH #15, step #1972] loss: 1.7820636282943556\n",
      "[EPOCH #15, step #1974] loss: 1.7820136778867697\n",
      "[EPOCH #15, step #1976] loss: 1.78204902917614\n",
      "[EPOCH #15, step #1978] loss: 1.7822321609995353\n",
      "[EPOCH #15, step #1980] loss: 1.782083619188504\n",
      "[EPOCH #15, step #1982] loss: 1.782011424419078\n",
      "[EPOCH #15, step #1984] loss: 1.781895933223311\n",
      "[EPOCH #15, step #1986] loss: 1.7819227264583801\n",
      "[EPOCH #15, step #1988] loss: 1.781864906687902\n",
      "[EPOCH #15, step #1990] loss: 1.7822247478364401\n",
      "[EPOCH #15, step #1992] loss: 1.7818156777466594\n",
      "[EPOCH #15, step #1994] loss: 1.7817072889261079\n",
      "[EPOCH #15, step #1996] loss: 1.7819411973088874\n",
      "[EPOCH #15, step #1998] loss: 1.7820390004286353\n",
      "[EPOCH #15, step #2000] loss: 1.7822055153582228\n",
      "[EPOCH #15, step #2002] loss: 1.7819984734088137\n",
      "[EPOCH #15, step #2004] loss: 1.781739005483594\n",
      "[EPOCH #15, step #2006] loss: 1.7819792073225582\n",
      "[EPOCH #15, step #2008] loss: 1.7816470667994277\n",
      "[EPOCH #15, step #2010] loss: 1.7816912261838642\n",
      "[EPOCH #15, step #2012] loss: 1.7817961651474696\n",
      "[EPOCH #15, step #2014] loss: 1.782156551209632\n",
      "[EPOCH #15, step #2016] loss: 1.7820440862931766\n",
      "[EPOCH #15, step #2018] loss: 1.782073635166975\n",
      "[EPOCH #15, step #2020] loss: 1.7818625556661727\n",
      "[EPOCH #15, step #2022] loss: 1.7817010782287077\n",
      "[EPOCH #15, step #2024] loss: 1.7814563778300345\n",
      "[EPOCH #15, step #2026] loss: 1.781687168870351\n",
      "[EPOCH #15, step #2028] loss: 1.781587488314035\n",
      "[EPOCH #15, step #2030] loss: 1.7816229536285664\n",
      "[EPOCH #15, step #2032] loss: 1.7816520913504523\n",
      "[EPOCH #15, step #2034] loss: 1.7818257248079454\n",
      "[EPOCH #15, step #2036] loss: 1.7821381272904475\n",
      "[EPOCH #15, step #2038] loss: 1.7820804421372014\n",
      "[EPOCH #15, step #2040] loss: 1.7817831433677953\n",
      "[EPOCH #15, step #2042] loss: 1.7818685689511629\n",
      "[EPOCH #15, step #2044] loss: 1.7813552618026733\n",
      "[EPOCH #15, step #2046] loss: 1.7812902831309123\n",
      "[EPOCH #15, step #2048] loss: 1.7814336219259796\n",
      "[EPOCH #15, step #2050] loss: 1.7813316179681906\n",
      "[EPOCH #15, step #2052] loss: 1.781460099666222\n",
      "[EPOCH #15, step #2054] loss: 1.7812162867427743\n",
      "[EPOCH #15, step #2056] loss: 1.7813439389485204\n",
      "[EPOCH #15, step #2058] loss: 1.781241126463447\n",
      "[EPOCH #15, step #2060] loss: 1.7814302091630903\n",
      "[EPOCH #15, step #2062] loss: 1.7814537244575785\n",
      "[EPOCH #15, step #2064] loss: 1.7814940570919047\n",
      "[EPOCH #15, step #2066] loss: 1.7815418836282657\n",
      "[EPOCH #15, step #2068] loss: 1.781761331221745\n",
      "[EPOCH #15, step #2070] loss: 1.7816968702682834\n",
      "[EPOCH #15, step #2072] loss: 1.781714187689697\n",
      "[EPOCH #15, step #2074] loss: 1.7816729674281844\n",
      "[EPOCH #15, step #2076] loss: 1.7818600488041936\n",
      "[EPOCH #15, step #2078] loss: 1.7818269339130726\n",
      "[EPOCH #15, step #2080] loss: 1.781638528852724\n",
      "[EPOCH #15, step #2082] loss: 1.781720357163274\n",
      "[EPOCH #15, step #2084] loss: 1.781717229346863\n",
      "[EPOCH #15, step #2086] loss: 1.7819488206775667\n",
      "[EPOCH #15, step #2088] loss: 1.78171675487133\n",
      "[EPOCH #15, step #2090] loss: 1.781427113078303\n",
      "[EPOCH #15, step #2092] loss: 1.7810338881957832\n",
      "[EPOCH #15, step #2094] loss: 1.7808327022201975\n",
      "[EPOCH #15, step #2096] loss: 1.7811985476902683\n",
      "[EPOCH #15, step #2098] loss: 1.7813068714069151\n",
      "[EPOCH #15, step #2100] loss: 1.7810844375881791\n",
      "[EPOCH #15, step #2102] loss: 1.780966361873897\n",
      "[EPOCH #15, step #2104] loss: 1.7808988710480462\n",
      "[EPOCH #15, step #2106] loss: 1.7810664140165389\n",
      "[EPOCH #15, step #2108] loss: 1.7810063273944015\n",
      "[EPOCH #15, step #2110] loss: 1.7809558943062245\n",
      "[EPOCH #15, step #2112] loss: 1.7808788142608232\n",
      "[EPOCH #15, step #2114] loss: 1.7807349446253855\n",
      "[EPOCH #15, step #2116] loss: 1.7807689976117833\n",
      "[EPOCH #15, step #2118] loss: 1.7809253053993703\n",
      "[EPOCH #15, step #2120] loss: 1.780784948149811\n",
      "[EPOCH #15, step #2122] loss: 1.7807827040770678\n",
      "[EPOCH #15, step #2124] loss: 1.7807681356317857\n",
      "[EPOCH #15, step #2126] loss: 1.7806306337604065\n",
      "[EPOCH #15, step #2128] loss: 1.780547537284034\n",
      "[EPOCH #15, step #2130] loss: 1.7804154899969509\n",
      "[EPOCH #15, step #2132] loss: 1.7800505396574247\n",
      "[EPOCH #15, step #2134] loss: 1.7798776829270624\n",
      "[EPOCH #15, step #2136] loss: 1.7797455136665519\n",
      "[EPOCH #15, step #2138] loss: 1.779753340689475\n",
      "[EPOCH #15, step #2140] loss: 1.7797087327947354\n",
      "[EPOCH #15, step #2142] loss: 1.7796541438501015\n",
      "[EPOCH #15, step #2144] loss: 1.7798182752582576\n",
      "[EPOCH #15, step #2146] loss: 1.7798338804791347\n",
      "[EPOCH #15, step #2148] loss: 1.7796952450979915\n",
      "[EPOCH #15, step #2150] loss: 1.7794824055547993\n",
      "[EPOCH #15, step #2152] loss: 1.7793466156159121\n",
      "[EPOCH #15, step #2154] loss: 1.7792156341734175\n",
      "[EPOCH #15, step #2156] loss: 1.778970935524864\n",
      "[EPOCH #15, step #2158] loss: 1.7792086500213786\n",
      "[EPOCH #15, step #2160] loss: 1.7792924580227607\n",
      "[EPOCH #15, step #2162] loss: 1.7792936689149326\n",
      "[EPOCH #15, step #2164] loss: 1.7792167100289678\n",
      "[EPOCH #15, step #2166] loss: 1.7789083513511619\n",
      "[EPOCH #15, step #2168] loss: 1.778595744876501\n",
      "[EPOCH #15, step #2170] loss: 1.7783416767155504\n",
      "[EPOCH #15, step #2172] loss: 1.7782083864975677\n",
      "[EPOCH #15, step #2174] loss: 1.778353182913243\n",
      "[EPOCH #15, step #2176] loss: 1.778167126317828\n",
      "[EPOCH #15, step #2178] loss: 1.7779866582267378\n",
      "[EPOCH #15, step #2180] loss: 1.7779050960501417\n",
      "[EPOCH #15, step #2182] loss: 1.7775635070010056\n",
      "[EPOCH #15, step #2184] loss: 1.7777187215927264\n",
      "[EPOCH #15, step #2186] loss: 1.7775342191906351\n",
      "[EPOCH #15, step #2188] loss: 1.7775013751774522\n",
      "[EPOCH #15, step #2190] loss: 1.777239801621448\n",
      "[EPOCH #15, step #2192] loss: 1.7770219124238675\n",
      "[EPOCH #15, step #2194] loss: 1.7772917338004144\n",
      "[EPOCH #15, step #2196] loss: 1.7774076227931255\n",
      "[EPOCH #15, step #2198] loss: 1.7772518581778096\n",
      "[EPOCH #15, step #2200] loss: 1.7769578547978173\n",
      "[EPOCH #15, step #2202] loss: 1.7768888575782897\n",
      "[EPOCH #15, step #2204] loss: 1.776918492511827\n",
      "[EPOCH #15, step #2206] loss: 1.7770383434701842\n",
      "[EPOCH #15, step #2208] loss: 1.7768356786588027\n",
      "[EPOCH #15, step #2210] loss: 1.7767326609681817\n",
      "[EPOCH #15, step #2212] loss: 1.776664081871698\n",
      "[EPOCH #15, step #2214] loss: 1.7766287491499166\n",
      "[EPOCH #15, step #2216] loss: 1.776553659811179\n",
      "[EPOCH #15, step #2218] loss: 1.776139729191667\n",
      "[EPOCH #15, step #2220] loss: 1.7760017394804837\n",
      "[EPOCH #15, step #2222] loss: 1.7756860563468675\n",
      "[EPOCH #15, step #2224] loss: 1.7757656019725157\n",
      "[EPOCH #15, step #2226] loss: 1.7755565734845296\n",
      "[EPOCH #15, step #2228] loss: 1.7754633221298977\n",
      "[EPOCH #15, step #2230] loss: 1.775292455054676\n",
      "[EPOCH #15, step #2232] loss: 1.775160730926114\n",
      "[EPOCH #15, step #2234] loss: 1.7752557660109245\n",
      "[EPOCH #15, step #2236] loss: 1.7750107511431712\n",
      "[EPOCH #15, step #2238] loss: 1.7751177864023595\n",
      "[EPOCH #15, step #2240] loss: 1.7751224367068528\n",
      "[EPOCH #15, step #2242] loss: 1.7751514444487253\n",
      "[EPOCH #15, step #2244] loss: 1.7750711243508388\n",
      "[EPOCH #15, step #2246] loss: 1.7748045746251961\n",
      "[EPOCH #15, step #2248] loss: 1.774617376302072\n",
      "[EPOCH #15, step #2250] loss: 1.774869080015629\n",
      "[EPOCH #15, step #2252] loss: 1.7749865705364818\n",
      "[EPOCH #15, step #2254] loss: 1.7747165114810883\n",
      "[EPOCH #15, step #2256] loss: 1.774598177840977\n",
      "[EPOCH #15, step #2258] loss: 1.7744291082532493\n",
      "[EPOCH #15, step #2260] loss: 1.774426265028608\n",
      "[EPOCH #15, step #2262] loss: 1.7746137733539542\n",
      "[EPOCH #15, step #2264] loss: 1.7745115425413018\n",
      "[EPOCH #15, step #2266] loss: 1.7744081568286763\n",
      "[EPOCH #15, step #2268] loss: 1.7741904210392838\n",
      "[EPOCH #15, step #2270] loss: 1.7739365489301258\n",
      "[EPOCH #15, step #2272] loss: 1.7740296811402971\n",
      "[EPOCH #15, step #2274] loss: 1.7742470102519778\n",
      "[EPOCH #15, step #2276] loss: 1.7743543229398362\n",
      "[EPOCH #15, step #2278] loss: 1.7744261312505665\n",
      "[EPOCH #15, step #2280] loss: 1.7740568021367067\n",
      "[EPOCH #15, step #2282] loss: 1.7741584794541174\n",
      "[EPOCH #15, step #2284] loss: 1.7740699808759293\n",
      "[EPOCH #15, step #2286] loss: 1.7740728380276638\n",
      "[EPOCH #15, step #2288] loss: 1.7742853317264908\n",
      "[EPOCH #15, step #2290] loss: 1.7744837919732255\n",
      "[EPOCH #15, step #2292] loss: 1.7743791395329618\n",
      "[EPOCH #15, step #2294] loss: 1.7741837520225376\n",
      "[EPOCH #15, step #2296] loss: 1.7743079207698107\n",
      "[EPOCH #15, step #2298] loss: 1.773876383673787\n",
      "[EPOCH #15, step #2300] loss: 1.7738704265122411\n",
      "[EPOCH #15, step #2302] loss: 1.773907221274639\n",
      "[EPOCH #15, step #2304] loss: 1.7739735537392456\n",
      "[EPOCH #15, step #2306] loss: 1.7740943286395146\n",
      "[EPOCH #15, step #2308] loss: 1.7741980493559162\n",
      "[EPOCH #15, step #2310] loss: 1.7741697105635095\n",
      "[EPOCH #15, step #2312] loss: 1.7742315382602871\n",
      "[EPOCH #15, step #2314] loss: 1.7740920573794816\n",
      "[EPOCH #15, step #2316] loss: 1.7737937952919567\n",
      "[EPOCH #15, step #2318] loss: 1.7736875830204542\n",
      "[EPOCH #15, step #2320] loss: 1.7737939198794728\n",
      "[EPOCH #15, step #2322] loss: 1.773704289491968\n",
      "[EPOCH #15, step #2324] loss: 1.7735164049363905\n",
      "[EPOCH #15, step #2326] loss: 1.7737312680874764\n",
      "[EPOCH #15, step #2328] loss: 1.7736127029267847\n",
      "[EPOCH #15, step #2330] loss: 1.7734750192444604\n",
      "[EPOCH #15, step #2332] loss: 1.7733415815128157\n",
      "[EPOCH #15, step #2334] loss: 1.7731112080672058\n",
      "[EPOCH #15, step #2336] loss: 1.7727872727261071\n",
      "[EPOCH #15, step #2338] loss: 1.7724397290257523\n",
      "[EPOCH #15, step #2340] loss: 1.772448332505265\n",
      "[EPOCH #15, step #2342] loss: 1.772112051162565\n",
      "[EPOCH #15, step #2344] loss: 1.7720330374327296\n",
      "[EPOCH #15, step #2346] loss: 1.7720491603480333\n",
      "[EPOCH #15, step #2348] loss: 1.7719466609364116\n",
      "[EPOCH #15, step #2350] loss: 1.7717767850686417\n",
      "[EPOCH #15, step #2352] loss: 1.7716361032715768\n",
      "[EPOCH #15, step #2354] loss: 1.7713420227328176\n",
      "[EPOCH #15, step #2356] loss: 1.7715100089675246\n",
      "[EPOCH #15, step #2358] loss: 1.7712849800290573\n",
      "[EPOCH #15, step #2360] loss: 1.7714841279727027\n",
      "[EPOCH #15, step #2362] loss: 1.7714722762660762\n",
      "[EPOCH #15, step #2364] loss: 1.7713299189511111\n",
      "[EPOCH #15, step #2366] loss: 1.7712557793519745\n",
      "[EPOCH #15, step #2368] loss: 1.7709317323325202\n",
      "[EPOCH #15, step #2370] loss: 1.7709281402567376\n",
      "[EPOCH #15, step #2372] loss: 1.7709515980161095\n",
      "[EPOCH #15, step #2374] loss: 1.7708140054752952\n",
      "[EPOCH #15, step #2376] loss: 1.7706416367130415\n",
      "[EPOCH #15, step #2378] loss: 1.7706697692436149\n",
      "[EPOCH #15, step #2380] loss: 1.7707108102741986\n",
      "[EPOCH #15, step #2382] loss: 1.7705062213336227\n",
      "[EPOCH #15, step #2384] loss: 1.7704558242791855\n",
      "[EPOCH #15, step #2386] loss: 1.770564243116287\n",
      "[EPOCH #15, step #2388] loss: 1.7706324382774399\n",
      "[EPOCH #15, step #2390] loss: 1.7707805423395546\n",
      "[EPOCH #15, step #2392] loss: 1.7706841845867078\n",
      "[EPOCH #15, step #2394] loss: 1.770831132258652\n",
      "[EPOCH #15, step #2396] loss: 1.7702615667145403\n",
      "[EPOCH #15, step #2398] loss: 1.7702013516783863\n",
      "[EPOCH #15, step #2400] loss: 1.7703060400034178\n",
      "[EPOCH #15, step #2402] loss: 1.770185161842389\n",
      "[EPOCH #15, step #2404] loss: 1.7702251544613352\n",
      "[EPOCH #15, step #2406] loss: 1.7697717466689167\n",
      "[EPOCH #15, step #2408] loss: 1.7696791724725203\n",
      "[EPOCH #15, step #2410] loss: 1.7697478370367863\n",
      "[EPOCH #15, step #2412] loss: 1.769804268593715\n",
      "[EPOCH #15, step #2414] loss: 1.7699533580746463\n",
      "[EPOCH #15, step #2416] loss: 1.7699463527509385\n",
      "[EPOCH #15, step #2418] loss: 1.7700282378401724\n",
      "[EPOCH #15, step #2420] loss: 1.7703133606063783\n",
      "[EPOCH #15, step #2422] loss: 1.7703831662484255\n",
      "[EPOCH #15, step #2424] loss: 1.7704091545724376\n",
      "[EPOCH #15, step #2426] loss: 1.7704413755715114\n",
      "[EPOCH #15, step #2428] loss: 1.770566267528471\n",
      "[EPOCH #15, step #2430] loss: 1.770181069963511\n",
      "[EPOCH #15, step #2432] loss: 1.7702121855396329\n",
      "[EPOCH #15, step #2434] loss: 1.7702779094051777\n",
      "[EPOCH #15, step #2436] loss: 1.770326836680505\n",
      "[EPOCH #15, step #2438] loss: 1.7705273574226554\n",
      "[EPOCH #15, step #2440] loss: 1.7705632284350787\n",
      "[EPOCH #15, step #2442] loss: 1.770370929274362\n",
      "[EPOCH #15, step #2444] loss: 1.7705806157584083\n",
      "[EPOCH #15, step #2446] loss: 1.7704089075923697\n",
      "[EPOCH #15, step #2448] loss: 1.7702741410450917\n",
      "[EPOCH #15, step #2450] loss: 1.770471389976534\n",
      "[EPOCH #15, step #2452] loss: 1.7705430552223678\n",
      "[EPOCH #15, step #2454] loss: 1.7704405102613259\n",
      "[EPOCH #15, step #2456] loss: 1.7703897361838823\n",
      "[EPOCH #15, step #2458] loss: 1.7706230762723307\n",
      "[EPOCH #15, step #2460] loss: 1.7705840991067479\n",
      "[EPOCH #15, step #2462] loss: 1.7704056949330886\n",
      "[EPOCH #15, step #2464] loss: 1.770064741675317\n",
      "[EPOCH #15, step #2466] loss: 1.7698179919032564\n",
      "[EPOCH #15, step #2468] loss: 1.7701790265440216\n",
      "[EPOCH #15, step #2470] loss: 1.7702996790384966\n",
      "[EPOCH #15, step #2472] loss: 1.7702582257265413\n",
      "[EPOCH #15, step #2474] loss: 1.7702612882431108\n",
      "[EPOCH #15, step #2476] loss: 1.7701522041387407\n",
      "[EPOCH #15, step #2478] loss: 1.7701238118481761\n",
      "[EPOCH #15, step #2480] loss: 1.770171215461176\n",
      "[EPOCH #15, step #2482] loss: 1.77006178422172\n",
      "[EPOCH #15, step #2484] loss: 1.7700786433949076\n",
      "[EPOCH #15, step #2486] loss: 1.770198011115511\n",
      "[EPOCH #15, step #2488] loss: 1.7703809553526069\n",
      "[EPOCH #15, step #2490] loss: 1.7704936220242957\n",
      "[EPOCH #15, step #2492] loss: 1.7703438789979358\n",
      "[EPOCH #15, step #2494] loss: 1.7707777645162686\n",
      "[EPOCH #15, step #2496] loss: 1.7709906055156737\n",
      "[EPOCH #15, step #2498] loss: 1.7707781286275879\n",
      "[EPOCH #15, elapsed time: 7630.203[sec]] loss: 1.7708536918401718\n",
      "[EPOCH #16, step #0] loss: 1.783724069595337\n",
      "[EPOCH #16, step #2] loss: 1.7024226586023967\n",
      "[EPOCH #16, step #4] loss: 1.6417879581451416\n",
      "[EPOCH #16, step #6] loss: 1.6575303758893694\n",
      "[EPOCH #16, step #8] loss: 1.6504778464635212\n",
      "[EPOCH #16, step #10] loss: 1.7377070405266501\n",
      "[EPOCH #16, step #12] loss: 1.724646623318012\n",
      "[EPOCH #16, step #14] loss: 1.6952913761138917\n",
      "[EPOCH #16, step #16] loss: 1.7385127965141745\n",
      "[EPOCH #16, step #18] loss: 1.7710914235366018\n",
      "[EPOCH #16, step #20] loss: 1.7486109620048886\n",
      "[EPOCH #16, step #22] loss: 1.752008759457132\n",
      "[EPOCH #16, step #24] loss: 1.7664117765426637\n",
      "[EPOCH #16, step #26] loss: 1.7619814033861514\n",
      "[EPOCH #16, step #28] loss: 1.7565064389130165\n",
      "[EPOCH #16, step #30] loss: 1.750099274419969\n",
      "[EPOCH #16, step #32] loss: 1.7416713454506614\n",
      "[EPOCH #16, step #34] loss: 1.7482709578105382\n",
      "[EPOCH #16, step #36] loss: 1.7344361640311576\n",
      "[EPOCH #16, step #38] loss: 1.728153760616596\n",
      "[EPOCH #16, step #40] loss: 1.7170133765150861\n",
      "[EPOCH #16, step #42] loss: 1.7126010323679723\n",
      "[EPOCH #16, step #44] loss: 1.706180903646681\n",
      "[EPOCH #16, step #46] loss: 1.7206886499486072\n",
      "[EPOCH #16, step #48] loss: 1.7231734942416757\n",
      "[EPOCH #16, step #50] loss: 1.7144914585001327\n",
      "[EPOCH #16, step #52] loss: 1.7109460853180796\n",
      "[EPOCH #16, step #54] loss: 1.701555731079795\n",
      "[EPOCH #16, step #56] loss: 1.7054656221155535\n",
      "[EPOCH #16, step #58] loss: 1.7189981896998519\n",
      "[EPOCH #16, step #60] loss: 1.7360628569712404\n",
      "[EPOCH #16, step #62] loss: 1.721902330716451\n",
      "[EPOCH #16, step #64] loss: 1.7265885958304772\n",
      "[EPOCH #16, step #66] loss: 1.734813343233137\n",
      "[EPOCH #16, step #68] loss: 1.7323090477266174\n",
      "[EPOCH #16, step #70] loss: 1.7306967335687558\n",
      "[EPOCH #16, step #72] loss: 1.7289192529573834\n",
      "[EPOCH #16, step #74] loss: 1.7324903837839762\n",
      "[EPOCH #16, step #76] loss: 1.7386026119256948\n",
      "[EPOCH #16, step #78] loss: 1.7358503613290908\n",
      "[EPOCH #16, step #80] loss: 1.7293580049349937\n",
      "[EPOCH #16, step #82] loss: 1.7273284843169063\n",
      "[EPOCH #16, step #84] loss: 1.729852227603688\n",
      "[EPOCH #16, step #86] loss: 1.7279131933190357\n",
      "[EPOCH #16, step #88] loss: 1.72559904650356\n",
      "[EPOCH #16, step #90] loss: 1.7243411318286435\n",
      "[EPOCH #16, step #92] loss: 1.7225618439335977\n",
      "[EPOCH #16, step #94] loss: 1.7172749180542795\n",
      "[EPOCH #16, step #96] loss: 1.7092552492299031\n",
      "[EPOCH #16, step #98] loss: 1.708927212339459\n",
      "[EPOCH #16, step #100] loss: 1.6973829287113529\n",
      "[EPOCH #16, step #102] loss: 1.6948479442920499\n",
      "[EPOCH #16, step #104] loss: 1.6870679690724328\n",
      "[EPOCH #16, step #106] loss: 1.6860665523003195\n",
      "[EPOCH #16, step #108] loss: 1.6864489377091785\n",
      "[EPOCH #16, step #110] loss: 1.6879316068984367\n",
      "[EPOCH #16, step #112] loss: 1.688228706870459\n",
      "[EPOCH #16, step #114] loss: 1.6920592997385109\n",
      "[EPOCH #16, step #116] loss: 1.6959689799537006\n",
      "[EPOCH #16, step #118] loss: 1.690985689143173\n",
      "[EPOCH #16, step #120] loss: 1.6927008269246944\n",
      "[EPOCH #16, step #122] loss: 1.6952930267264203\n",
      "[EPOCH #16, step #124] loss: 1.6914858689308168\n",
      "[EPOCH #16, step #126] loss: 1.6970292991540563\n",
      "[EPOCH #16, step #128] loss: 1.6996206511822782\n",
      "[EPOCH #16, step #130] loss: 1.6942800151482793\n",
      "[EPOCH #16, step #132] loss: 1.694228436265673\n",
      "[EPOCH #16, step #134] loss: 1.69535744410974\n",
      "[EPOCH #16, step #136] loss: 1.6956118253895835\n",
      "[EPOCH #16, step #138] loss: 1.6945465078456796\n",
      "[EPOCH #16, step #140] loss: 1.6984130647165556\n",
      "[EPOCH #16, step #142] loss: 1.6976695631767487\n",
      "[EPOCH #16, step #144] loss: 1.6973037337434702\n",
      "[EPOCH #16, step #146] loss: 1.696899957802831\n",
      "[EPOCH #16, step #148] loss: 1.694260583227913\n",
      "[EPOCH #16, step #150] loss: 1.6969990331605571\n",
      "[EPOCH #16, step #152] loss: 1.6938134373403062\n",
      "[EPOCH #16, step #154] loss: 1.6956914767142266\n",
      "[EPOCH #16, step #156] loss: 1.6947349283345945\n",
      "[EPOCH #16, step #158] loss: 1.697697360185707\n",
      "[EPOCH #16, step #160] loss: 1.699423637079156\n",
      "[EPOCH #16, step #162] loss: 1.7038564605215576\n",
      "[EPOCH #16, step #164] loss: 1.7075773748484524\n",
      "[EPOCH #16, step #166] loss: 1.7066230399166038\n",
      "[EPOCH #16, step #168] loss: 1.7032102752014024\n",
      "[EPOCH #16, step #170] loss: 1.7024211329326295\n",
      "[EPOCH #16, step #172] loss: 1.7000983198943165\n",
      "[EPOCH #16, step #174] loss: 1.7009501024654934\n",
      "[EPOCH #16, step #176] loss: 1.702152110425766\n",
      "[EPOCH #16, step #178] loss: 1.7023061250841152\n",
      "[EPOCH #16, step #180] loss: 1.7032269940850484\n",
      "[EPOCH #16, step #182] loss: 1.7056746036628556\n",
      "[EPOCH #16, step #184] loss: 1.7065419780241478\n",
      "[EPOCH #16, step #186] loss: 1.7033790072655295\n",
      "[EPOCH #16, step #188] loss: 1.7072648431258226\n",
      "[EPOCH #16, step #190] loss: 1.7089871839078934\n",
      "[EPOCH #16, step #192] loss: 1.7108397900749364\n",
      "[EPOCH #16, step #194] loss: 1.7143318203779367\n",
      "[EPOCH #16, step #196] loss: 1.7146244336505831\n",
      "[EPOCH #16, step #198] loss: 1.7143523971639087\n",
      "[EPOCH #16, step #200] loss: 1.714023321125638\n",
      "[EPOCH #16, step #202] loss: 1.7125667917904595\n",
      "[EPOCH #16, step #204] loss: 1.7126803017244105\n",
      "[EPOCH #16, step #206] loss: 1.7127661454504814\n",
      "[EPOCH #16, step #208] loss: 1.7099250689077605\n",
      "[EPOCH #16, step #210] loss: 1.7097996690826958\n",
      "[EPOCH #16, step #212] loss: 1.7103038581324295\n",
      "[EPOCH #16, step #214] loss: 1.7087800782780314\n",
      "[EPOCH #16, step #216] loss: 1.7060319643965514\n",
      "[EPOCH #16, step #218] loss: 1.7056802639133855\n",
      "[EPOCH #16, step #220] loss: 1.7046582135140087\n",
      "[EPOCH #16, step #222] loss: 1.7044024448758284\n",
      "[EPOCH #16, step #224] loss: 1.7056454719437493\n",
      "[EPOCH #16, step #226] loss: 1.70470460632299\n",
      "[EPOCH #16, step #228] loss: 1.7046468978886\n",
      "[EPOCH #16, step #230] loss: 1.7073513370055657\n",
      "[EPOCH #16, step #232] loss: 1.7106269385681643\n",
      "[EPOCH #16, step #234] loss: 1.7126381359201797\n",
      "[EPOCH #16, step #236] loss: 1.7129881022348685\n",
      "[EPOCH #16, step #238] loss: 1.7122347352394998\n",
      "[EPOCH #16, step #240] loss: 1.7096646808984368\n",
      "[EPOCH #16, step #242] loss: 1.7106426225768194\n",
      "[EPOCH #16, step #244] loss: 1.709060425417764\n",
      "[EPOCH #16, step #246] loss: 1.7060455829508392\n",
      "[EPOCH #16, step #248] loss: 1.7086475663874523\n",
      "[EPOCH #16, step #250] loss: 1.7093808753082003\n",
      "[EPOCH #16, step #252] loss: 1.711685105039197\n",
      "[EPOCH #16, step #254] loss: 1.7098588412883235\n",
      "[EPOCH #16, step #256] loss: 1.7099447294431902\n",
      "[EPOCH #16, step #258] loss: 1.7100547209209458\n",
      "[EPOCH #16, step #260] loss: 1.7082824426135799\n",
      "[EPOCH #16, step #262] loss: 1.710704731623936\n",
      "[EPOCH #16, step #264] loss: 1.7113487110947663\n",
      "[EPOCH #16, step #266] loss: 1.710799147796988\n",
      "[EPOCH #16, step #268] loss: 1.7099432619530914\n",
      "[EPOCH #16, step #270] loss: 1.7096465683071376\n",
      "[EPOCH #16, step #272] loss: 1.7122007938095065\n",
      "[EPOCH #16, step #274] loss: 1.711380446390672\n",
      "[EPOCH #16, step #276] loss: 1.7120019337330483\n",
      "[EPOCH #16, step #278] loss: 1.7133355437641076\n",
      "[EPOCH #16, step #280] loss: 1.7114786548122392\n",
      "[EPOCH #16, step #282] loss: 1.7128927195872519\n",
      "[EPOCH #16, step #284] loss: 1.7133401977388483\n",
      "[EPOCH #16, step #286] loss: 1.712278229226634\n",
      "[EPOCH #16, step #288] loss: 1.7116307612108936\n",
      "[EPOCH #16, step #290] loss: 1.7126031927636398\n",
      "[EPOCH #16, step #292] loss: 1.7113199626626414\n",
      "[EPOCH #16, step #294] loss: 1.7118396554963062\n",
      "[EPOCH #16, step #296] loss: 1.7115820503796793\n",
      "[EPOCH #16, step #298] loss: 1.7114835828044344\n",
      "[EPOCH #16, step #300] loss: 1.711217209152209\n",
      "[EPOCH #16, step #302] loss: 1.7097674574789041\n",
      "[EPOCH #16, step #304] loss: 1.7080313516444847\n",
      "[EPOCH #16, step #306] loss: 1.709249409674045\n",
      "[EPOCH #16, step #308] loss: 1.7093079300374274\n",
      "[EPOCH #16, step #310] loss: 1.7097244046125382\n",
      "[EPOCH #16, step #312] loss: 1.7115851086549485\n",
      "[EPOCH #16, step #314] loss: 1.7127149553526015\n",
      "[EPOCH #16, step #316] loss: 1.7124154573359325\n",
      "[EPOCH #16, step #318] loss: 1.711957144699874\n",
      "[EPOCH #16, step #320] loss: 1.7116643467053445\n",
      "[EPOCH #16, step #322] loss: 1.711482587059954\n",
      "[EPOCH #16, step #324] loss: 1.7114866948127747\n",
      "[EPOCH #16, step #326] loss: 1.7092711023234446\n",
      "[EPOCH #16, step #328] loss: 1.70910898222387\n",
      "[EPOCH #16, step #330] loss: 1.7106347028222328\n",
      "[EPOCH #16, step #332] loss: 1.7096596625116136\n",
      "[EPOCH #16, step #334] loss: 1.70700029490599\n",
      "[EPOCH #16, step #336] loss: 1.7084269631510318\n",
      "[EPOCH #16, step #338] loss: 1.7070774168743146\n",
      "[EPOCH #16, step #340] loss: 1.7098032185409076\n",
      "[EPOCH #16, step #342] loss: 1.709435898604268\n",
      "[EPOCH #16, step #344] loss: 1.707964325123939\n",
      "[EPOCH #16, step #346] loss: 1.7079655686098147\n",
      "[EPOCH #16, step #348] loss: 1.707148336578577\n",
      "[EPOCH #16, step #350] loss: 1.7082369903213956\n",
      "[EPOCH #16, step #352] loss: 1.7069446620117166\n",
      "[EPOCH #16, step #354] loss: 1.705560081609538\n",
      "[EPOCH #16, step #356] loss: 1.705243441404081\n",
      "[EPOCH #16, step #358] loss: 1.7052156438734538\n",
      "[EPOCH #16, step #360] loss: 1.7047601437964928\n",
      "[EPOCH #16, step #362] loss: 1.7052436608913517\n",
      "[EPOCH #16, step #364] loss: 1.7075556799157026\n",
      "[EPOCH #16, step #366] loss: 1.7077641277612068\n",
      "[EPOCH #16, step #368] loss: 1.7080756857143184\n",
      "[EPOCH #16, step #370] loss: 1.7076088866454893\n",
      "[EPOCH #16, step #372] loss: 1.7080381825845938\n",
      "[EPOCH #16, step #374] loss: 1.7088052713076274\n",
      "[EPOCH #16, step #376] loss: 1.708314601717324\n",
      "[EPOCH #16, step #378] loss: 1.7091086079074085\n",
      "[EPOCH #16, step #380] loss: 1.7080005183620404\n",
      "[EPOCH #16, step #382] loss: 1.7076632193734689\n",
      "[EPOCH #16, step #384] loss: 1.7084514415109313\n",
      "[EPOCH #16, step #386] loss: 1.7090185346221431\n",
      "[EPOCH #16, step #388] loss: 1.708588510828337\n",
      "[EPOCH #16, step #390] loss: 1.7095469844615674\n",
      "[EPOCH #16, step #392] loss: 1.710039996463834\n",
      "[EPOCH #16, step #394] loss: 1.7088708242283592\n",
      "[EPOCH #16, step #396] loss: 1.7074742192585461\n",
      "[EPOCH #16, step #398] loss: 1.7075771417534142\n",
      "[EPOCH #16, step #400] loss: 1.7081939411579523\n",
      "[EPOCH #16, step #402] loss: 1.7091757874039208\n",
      "[EPOCH #16, step #404] loss: 1.7083931927327756\n",
      "[EPOCH #16, step #406] loss: 1.7064568669848712\n",
      "[EPOCH #16, step #408] loss: 1.7071643722377954\n",
      "[EPOCH #16, step #410] loss: 1.7063109362792506\n",
      "[EPOCH #16, step #412] loss: 1.7062463504927499\n",
      "[EPOCH #16, step #414] loss: 1.7055255874093758\n",
      "[EPOCH #16, step #416] loss: 1.7062696022667188\n",
      "[EPOCH #16, step #418] loss: 1.7070286215631945\n",
      "[EPOCH #16, step #420] loss: 1.7077715285033908\n",
      "[EPOCH #16, step #422] loss: 1.7083181085034183\n",
      "[EPOCH #16, step #424] loss: 1.708200744600857\n",
      "[EPOCH #16, step #426] loss: 1.7081334223791922\n",
      "[EPOCH #16, step #428] loss: 1.7077956820701385\n",
      "[EPOCH #16, step #430] loss: 1.707805432880561\n",
      "[EPOCH #16, step #432] loss: 1.7063420461727346\n",
      "[EPOCH #16, step #434] loss: 1.7062595985401636\n",
      "[EPOCH #16, step #436] loss: 1.7060867969449651\n",
      "[EPOCH #16, step #438] loss: 1.7060803360982473\n",
      "[EPOCH #16, step #440] loss: 1.7051150491989118\n",
      "[EPOCH #16, step #442] loss: 1.7054248567897634\n",
      "[EPOCH #16, step #444] loss: 1.7056644848223483\n",
      "[EPOCH #16, step #446] loss: 1.704008681528787\n",
      "[EPOCH #16, step #448] loss: 1.7038276881842411\n",
      "[EPOCH #16, step #450] loss: 1.703931816269183\n",
      "[EPOCH #16, step #452] loss: 1.7037234960276033\n",
      "[EPOCH #16, step #454] loss: 1.7038398031350022\n",
      "[EPOCH #16, step #456] loss: 1.7042806207220715\n",
      "[EPOCH #16, step #458] loss: 1.7034186593587621\n",
      "[EPOCH #16, step #460] loss: 1.7037209079736226\n",
      "[EPOCH #16, step #462] loss: 1.703952347099395\n",
      "[EPOCH #16, step #464] loss: 1.7045908739489894\n",
      "[EPOCH #16, step #466] loss: 1.7075207015176401\n",
      "[EPOCH #16, step #468] loss: 1.7070774601212442\n",
      "[EPOCH #16, step #470] loss: 1.706662222711397\n",
      "[EPOCH #16, step #472] loss: 1.7074530461121815\n",
      "[EPOCH #16, step #474] loss: 1.7065534457407499\n",
      "[EPOCH #16, step #476] loss: 1.706295988969583\n",
      "[EPOCH #16, step #478] loss: 1.706937310964429\n",
      "[EPOCH #16, step #480] loss: 1.7068701381494995\n",
      "[EPOCH #16, step #482] loss: 1.706571180257738\n",
      "[EPOCH #16, step #484] loss: 1.7060132834100232\n",
      "[EPOCH #16, step #486] loss: 1.706552795928117\n",
      "[EPOCH #16, step #488] loss: 1.7050175158524075\n",
      "[EPOCH #16, step #490] loss: 1.7059947870170997\n",
      "[EPOCH #16, step #492] loss: 1.7066703501627847\n",
      "[EPOCH #16, step #494] loss: 1.7061271189439176\n",
      "[EPOCH #16, step #496] loss: 1.706195108967288\n",
      "[EPOCH #16, step #498] loss: 1.7057964189019137\n",
      "[EPOCH #16, step #500] loss: 1.7046462258179031\n",
      "[EPOCH #16, step #502] loss: 1.703907305037762\n",
      "[EPOCH #16, step #504] loss: 1.7036727502794549\n",
      "[EPOCH #16, step #506] loss: 1.7041547722835277\n",
      "[EPOCH #16, step #508] loss: 1.7039191920771346\n",
      "[EPOCH #16, step #510] loss: 1.704645898827368\n",
      "[EPOCH #16, step #512] loss: 1.70533632848695\n",
      "[EPOCH #16, step #514] loss: 1.7046603553503463\n",
      "[EPOCH #16, step #516] loss: 1.704721592726975\n",
      "[EPOCH #16, step #518] loss: 1.7051175507736573\n",
      "[EPOCH #16, step #520] loss: 1.7058896797632301\n",
      "[EPOCH #16, step #522] loss: 1.7065588790873496\n",
      "[EPOCH #16, step #524] loss: 1.705324564547766\n",
      "[EPOCH #16, step #526] loss: 1.7049692644113834\n",
      "[EPOCH #16, step #528] loss: 1.704335386113093\n",
      "[EPOCH #16, step #530] loss: 1.7044835183804543\n",
      "[EPOCH #16, step #532] loss: 1.7048118636711007\n",
      "[EPOCH #16, step #534] loss: 1.7048185042131727\n",
      "[EPOCH #16, step #536] loss: 1.706363184825002\n",
      "[EPOCH #16, step #538] loss: 1.707212036637959\n",
      "[EPOCH #16, step #540] loss: 1.7062022971357744\n",
      "[EPOCH #16, step #542] loss: 1.7067929531548782\n",
      "[EPOCH #16, step #544] loss: 1.7069435691614763\n",
      "[EPOCH #16, step #546] loss: 1.706278251664512\n",
      "[EPOCH #16, step #548] loss: 1.705663214724355\n",
      "[EPOCH #16, step #550] loss: 1.7052863108268017\n",
      "[EPOCH #16, step #552] loss: 1.7044724106357498\n",
      "[EPOCH #16, step #554] loss: 1.7027330099999367\n",
      "[EPOCH #16, step #556] loss: 1.7030441296592862\n",
      "[EPOCH #16, step #558] loss: 1.701993544754274\n",
      "[EPOCH #16, step #560] loss: 1.7015364316695514\n",
      "[EPOCH #16, step #562] loss: 1.700712283381772\n",
      "[EPOCH #16, step #564] loss: 1.6998207778002308\n",
      "[EPOCH #16, step #566] loss: 1.699694201008563\n",
      "[EPOCH #16, step #568] loss: 1.6996523208903094\n",
      "[EPOCH #16, step #570] loss: 1.6988575059770494\n",
      "[EPOCH #16, step #572] loss: 1.69890934072864\n",
      "[EPOCH #16, step #574] loss: 1.6991982491120048\n",
      "[EPOCH #16, step #576] loss: 1.698515711871962\n",
      "[EPOCH #16, step #578] loss: 1.6977775691910317\n",
      "[EPOCH #16, step #580] loss: 1.6987204962055777\n",
      "[EPOCH #16, step #582] loss: 1.6988324125267016\n",
      "[EPOCH #16, step #584] loss: 1.6990579729406243\n",
      "[EPOCH #16, step #586] loss: 1.698691412374961\n",
      "[EPOCH #16, step #588] loss: 1.698481709119217\n",
      "[EPOCH #16, step #590] loss: 1.6985702669963416\n",
      "[EPOCH #16, step #592] loss: 1.6990258106694858\n",
      "[EPOCH #16, step #594] loss: 1.6992611556493935\n",
      "[EPOCH #16, step #596] loss: 1.6988611187367784\n",
      "[EPOCH #16, step #598] loss: 1.69969170519426\n",
      "[EPOCH #16, step #600] loss: 1.6992609481049854\n",
      "[EPOCH #16, step #602] loss: 1.6985043174591823\n",
      "[EPOCH #16, step #604] loss: 1.6991594564816184\n",
      "[EPOCH #16, step #606] loss: 1.6998174805224826\n",
      "[EPOCH #16, step #608] loss: 1.7004215255355208\n",
      "[EPOCH #16, step #610] loss: 1.6995811573612318\n",
      "[EPOCH #16, step #612] loss: 1.6998446557494595\n",
      "[EPOCH #16, step #614] loss: 1.6994869805933015\n",
      "[EPOCH #16, step #616] loss: 1.7003201124540603\n",
      "[EPOCH #16, step #618] loss: 1.7011107241009664\n",
      "[EPOCH #16, step #620] loss: 1.7011497066792658\n",
      "[EPOCH #16, step #622] loss: 1.7018506616880194\n",
      "[EPOCH #16, step #624] loss: 1.701072067642212\n",
      "[EPOCH #16, step #626] loss: 1.7014628492854238\n",
      "[EPOCH #16, step #628] loss: 1.7017824079349804\n",
      "[EPOCH #16, step #630] loss: 1.7020379922658253\n",
      "[EPOCH #16, step #632] loss: 1.70202247979705\n",
      "[EPOCH #16, step #634] loss: 1.7014925772749532\n",
      "[EPOCH #16, step #636] loss: 1.7004726664799161\n",
      "[EPOCH #16, step #638] loss: 1.7005731992318596\n",
      "[EPOCH #16, step #640] loss: 1.7005241447231514\n",
      "[EPOCH #16, step #642] loss: 1.7011413893098966\n",
      "[EPOCH #16, step #644] loss: 1.7013587269672128\n",
      "[EPOCH #16, step #646] loss: 1.700422678885541\n",
      "[EPOCH #16, step #648] loss: 1.7011877667554904\n",
      "[EPOCH #16, step #650] loss: 1.700967439491811\n",
      "[EPOCH #16, step #652] loss: 1.700550304255113\n",
      "[EPOCH #16, step #654] loss: 1.7003679876109117\n",
      "[EPOCH #16, step #656] loss: 1.7005863695928496\n",
      "[EPOCH #16, step #658] loss: 1.7009626285078312\n",
      "[EPOCH #16, step #660] loss: 1.6998620581518684\n",
      "[EPOCH #16, step #662] loss: 1.6995960283423261\n",
      "[EPOCH #16, step #664] loss: 1.6991338188486889\n",
      "[EPOCH #16, step #666] loss: 1.7001286251791592\n",
      "[EPOCH #16, step #668] loss: 1.7008657262998845\n",
      "[EPOCH #16, step #670] loss: 1.7011866183998687\n",
      "[EPOCH #16, step #672] loss: 1.7006407235742147\n",
      "[EPOCH #16, step #674] loss: 1.7011044295628865\n",
      "[EPOCH #16, step #676] loss: 1.7008816095363442\n",
      "[EPOCH #16, step #678] loss: 1.700565741234219\n",
      "[EPOCH #16, step #680] loss: 1.6999202185965494\n",
      "[EPOCH #16, step #682] loss: 1.6998505999019171\n",
      "[EPOCH #16, step #684] loss: 1.699752920213407\n",
      "[EPOCH #16, step #686] loss: 1.6993467172680985\n",
      "[EPOCH #16, step #688] loss: 1.6990166319472004\n",
      "[EPOCH #16, step #690] loss: 1.6985200407191055\n",
      "[EPOCH #16, step #692] loss: 1.6976895776145902\n",
      "[EPOCH #16, step #694] loss: 1.6979402898884506\n",
      "[EPOCH #16, step #696] loss: 1.6979209525000245\n",
      "[EPOCH #16, step #698] loss: 1.6988957221586476\n",
      "[EPOCH #16, step #700] loss: 1.6982411081542643\n",
      "[EPOCH #16, step #702] loss: 1.6990670126837653\n",
      "[EPOCH #16, step #704] loss: 1.6983441325789648\n",
      "[EPOCH #16, step #706] loss: 1.6985352808211784\n",
      "[EPOCH #16, step #708] loss: 1.6987246979443076\n",
      "[EPOCH #16, step #710] loss: 1.6995425710530556\n",
      "[EPOCH #16, step #712] loss: 1.6992247238399938\n",
      "[EPOCH #16, step #714] loss: 1.6995737084141977\n",
      "[EPOCH #16, step #716] loss: 1.7004054304279876\n",
      "[EPOCH #16, step #718] loss: 1.7002576264618832\n",
      "[EPOCH #16, step #720] loss: 1.6998693104755862\n",
      "[EPOCH #16, step #722] loss: 1.7001555442480296\n",
      "[EPOCH #16, step #724] loss: 1.69964075959962\n",
      "[EPOCH #16, step #726] loss: 1.6999757891672023\n",
      "[EPOCH #16, step #728] loss: 1.7001170130914132\n",
      "[EPOCH #16, step #730] loss: 1.7006437106595647\n",
      "[EPOCH #16, step #732] loss: 1.7002487418433654\n",
      "[EPOCH #16, step #734] loss: 1.7000240144275485\n",
      "[EPOCH #16, step #736] loss: 1.6995542267769617\n",
      "[EPOCH #16, step #738] loss: 1.698872645588463\n",
      "[EPOCH #16, step #740] loss: 1.6974375601883038\n",
      "[EPOCH #16, step #742] loss: 1.6967999371994553\n",
      "[EPOCH #16, step #744] loss: 1.696917603159911\n",
      "[EPOCH #16, step #746] loss: 1.6978550908396361\n",
      "[EPOCH #16, step #748] loss: 1.69785134353052\n",
      "[EPOCH #16, step #750] loss: 1.6984009155420743\n",
      "[EPOCH #16, step #752] loss: 1.6990289848005946\n",
      "[EPOCH #16, step #754] loss: 1.698471343280464\n",
      "[EPOCH #16, step #756] loss: 1.6987545827263413\n",
      "[EPOCH #16, step #758] loss: 1.6990233741415977\n",
      "[EPOCH #16, step #760] loss: 1.6983508053339733\n",
      "[EPOCH #16, step #762] loss: 1.6977348669797065\n",
      "[EPOCH #16, step #764] loss: 1.6982277725257127\n",
      "[EPOCH #16, step #766] loss: 1.6979050168468868\n",
      "[EPOCH #16, step #768] loss: 1.697780312580312\n",
      "[EPOCH #16, step #770] loss: 1.697613398079433\n",
      "[EPOCH #16, step #772] loss: 1.6977478839447397\n",
      "[EPOCH #16, step #774] loss: 1.6981333069647513\n",
      "[EPOCH #16, step #776] loss: 1.6982855152439427\n",
      "[EPOCH #16, step #778] loss: 1.6973147216290043\n",
      "[EPOCH #16, step #780] loss: 1.6974904549411867\n",
      "[EPOCH #16, step #782] loss: 1.697666540151964\n",
      "[EPOCH #16, step #784] loss: 1.6972633619976651\n",
      "[EPOCH #16, step #786] loss: 1.696645217293251\n",
      "[EPOCH #16, step #788] loss: 1.6955993403651113\n",
      "[EPOCH #16, step #790] loss: 1.6949620494046795\n",
      "[EPOCH #16, step #792] loss: 1.6950998214574962\n",
      "[EPOCH #16, step #794] loss: 1.695169333541918\n",
      "[EPOCH #16, step #796] loss: 1.6954851018888888\n",
      "[EPOCH #16, step #798] loss: 1.694490398871287\n",
      "[EPOCH #16, step #800] loss: 1.6937181245670485\n",
      "[EPOCH #16, step #802] loss: 1.6937410622129998\n",
      "[EPOCH #16, step #804] loss: 1.6934930705135653\n",
      "[EPOCH #16, step #806] loss: 1.6937394202715699\n",
      "[EPOCH #16, step #808] loss: 1.6930587362447391\n",
      "[EPOCH #16, step #810] loss: 1.6929948606267664\n",
      "[EPOCH #16, step #812] loss: 1.6921837258016346\n",
      "[EPOCH #16, step #814] loss: 1.6923574876200203\n",
      "[EPOCH #16, step #816] loss: 1.692209191100542\n",
      "[EPOCH #16, step #818] loss: 1.692587547395401\n",
      "[EPOCH #16, step #820] loss: 1.6922439402116782\n",
      "[EPOCH #16, step #822] loss: 1.6916327990709215\n",
      "[EPOCH #16, step #824] loss: 1.6912992093057344\n",
      "[EPOCH #16, step #826] loss: 1.6918862207624903\n",
      "[EPOCH #16, step #828] loss: 1.6916065428886828\n",
      "[EPOCH #16, step #830] loss: 1.6915634150396042\n",
      "[EPOCH #16, step #832] loss: 1.6914961441081253\n",
      "[EPOCH #16, step #834] loss: 1.6904697903615986\n",
      "[EPOCH #16, step #836] loss: 1.6904451730288343\n",
      "[EPOCH #16, step #838] loss: 1.6898783314640105\n",
      "[EPOCH #16, step #840] loss: 1.6911253128267214\n",
      "[EPOCH #16, step #842] loss: 1.6912871146682884\n",
      "[EPOCH #16, step #844] loss: 1.6912004964591483\n",
      "[EPOCH #16, step #846] loss: 1.6912632160231806\n",
      "[EPOCH #16, step #848] loss: 1.690572092193316\n",
      "[EPOCH #16, step #850] loss: 1.690315378818893\n",
      "[EPOCH #16, step #852] loss: 1.6903162748844376\n",
      "[EPOCH #16, step #854] loss: 1.6908947183374774\n",
      "[EPOCH #16, step #856] loss: 1.6904999571336192\n",
      "[EPOCH #16, step #858] loss: 1.691620013627795\n",
      "[EPOCH #16, step #860] loss: 1.6917789731429982\n",
      "[EPOCH #16, step #862] loss: 1.6916610180710034\n",
      "[EPOCH #16, step #864] loss: 1.6917214038055066\n",
      "[EPOCH #16, step #866] loss: 1.6925640334445025\n",
      "[EPOCH #16, step #868] loss: 1.6922686183685811\n",
      "[EPOCH #16, step #870] loss: 1.6921547793630343\n",
      "[EPOCH #16, step #872] loss: 1.6926077059454114\n",
      "[EPOCH #16, step #874] loss: 1.6922078416006905\n",
      "[EPOCH #16, step #876] loss: 1.692323881924628\n",
      "[EPOCH #16, step #878] loss: 1.6924638303337922\n",
      "[EPOCH #16, step #880] loss: 1.6923377707380713\n",
      "[EPOCH #16, step #882] loss: 1.6930583418428156\n",
      "[EPOCH #16, step #884] loss: 1.6935830345261569\n",
      "[EPOCH #16, step #886] loss: 1.6929975155375587\n",
      "[EPOCH #16, step #888] loss: 1.6936118452567754\n",
      "[EPOCH #16, step #890] loss: 1.6925324802313055\n",
      "[EPOCH #16, step #892] loss: 1.692206759335346\n",
      "[EPOCH #16, step #894] loss: 1.6925750627198033\n",
      "[EPOCH #16, step #896] loss: 1.6925422926012887\n",
      "[EPOCH #16, step #898] loss: 1.6922088289950394\n",
      "[EPOCH #16, step #900] loss: 1.692571421442233\n",
      "[EPOCH #16, step #902] loss: 1.6922706908165814\n",
      "[EPOCH #16, step #904] loss: 1.691448786772417\n",
      "[EPOCH #16, step #906] loss: 1.6915545863116852\n",
      "[EPOCH #16, step #908] loss: 1.690785193469527\n",
      "[EPOCH #16, step #910] loss: 1.690907377442989\n",
      "[EPOCH #16, step #912] loss: 1.690333084887769\n",
      "[EPOCH #16, step #914] loss: 1.6899721114361872\n",
      "[EPOCH #16, step #916] loss: 1.6903146626255114\n",
      "[EPOCH #16, step #918] loss: 1.6901565233693419\n",
      "[EPOCH #16, step #920] loss: 1.6901851491223976\n",
      "[EPOCH #16, step #922] loss: 1.6899127328641237\n",
      "[EPOCH #16, step #924] loss: 1.6902136101593843\n",
      "[EPOCH #16, step #926] loss: 1.6902477379884278\n",
      "[EPOCH #16, step #928] loss: 1.6909927495457513\n",
      "[EPOCH #16, step #930] loss: 1.6910002002398514\n",
      "[EPOCH #16, step #932] loss: 1.6915536753489913\n",
      "[EPOCH #16, step #934] loss: 1.6913067794738605\n",
      "[EPOCH #16, step #936] loss: 1.691100819515444\n",
      "[EPOCH #16, step #938] loss: 1.6907946563249452\n",
      "[EPOCH #16, step #940] loss: 1.691130382094956\n",
      "[EPOCH #16, step #942] loss: 1.6906602530565393\n",
      "[EPOCH #16, step #944] loss: 1.6909169636075458\n",
      "[EPOCH #16, step #946] loss: 1.6905352987482782\n",
      "[EPOCH #16, step #948] loss: 1.6898817282456617\n",
      "[EPOCH #16, step #950] loss: 1.689591524728841\n",
      "[EPOCH #16, step #952] loss: 1.6891980172454497\n",
      "[EPOCH #16, step #954] loss: 1.688897303511335\n",
      "[EPOCH #16, step #956] loss: 1.6883528420668534\n",
      "[EPOCH #16, step #958] loss: 1.688602741617356\n",
      "[EPOCH #16, step #960] loss: 1.688910780166364\n",
      "[EPOCH #16, step #962] loss: 1.688765014195863\n",
      "[EPOCH #16, step #964] loss: 1.6890088181421548\n",
      "[EPOCH #16, step #966] loss: 1.6886263565538835\n",
      "[EPOCH #16, step #968] loss: 1.6885367036480898\n",
      "[EPOCH #16, step #970] loss: 1.6886368341720928\n",
      "[EPOCH #16, step #972] loss: 1.6879554060110697\n",
      "[EPOCH #16, step #974] loss: 1.6881773526240618\n",
      "[EPOCH #16, step #976] loss: 1.6881565726157222\n",
      "[EPOCH #16, step #978] loss: 1.6884339253310652\n",
      "[EPOCH #16, step #980] loss: 1.688202784270443\n",
      "[EPOCH #16, step #982] loss: 1.688195977242529\n",
      "[EPOCH #16, step #984] loss: 1.6886631054926644\n",
      "[EPOCH #16, step #986] loss: 1.6886919609439892\n",
      "[EPOCH #16, step #988] loss: 1.6893260313237521\n",
      "[EPOCH #16, step #990] loss: 1.6891700111773131\n",
      "[EPOCH #16, step #992] loss: 1.6889866987263928\n",
      "[EPOCH #16, step #994] loss: 1.6887167828166905\n",
      "[EPOCH #16, step #996] loss: 1.689112881779551\n",
      "[EPOCH #16, step #998] loss: 1.6892748706572287\n",
      "[EPOCH #16, step #1000] loss: 1.6897530283603992\n",
      "[EPOCH #16, step #1002] loss: 1.6900007075231787\n",
      "[EPOCH #16, step #1004] loss: 1.689832093051417\n",
      "[EPOCH #16, step #1006] loss: 1.6903564028493698\n",
      "[EPOCH #16, step #1008] loss: 1.6902860893957443\n",
      "[EPOCH #16, step #1010] loss: 1.6896750519584596\n",
      "[EPOCH #16, step #1012] loss: 1.6899938110891004\n",
      "[EPOCH #16, step #1014] loss: 1.6902038951812706\n",
      "[EPOCH #16, step #1016] loss: 1.6899459232505678\n",
      "[EPOCH #16, step #1018] loss: 1.689956365845973\n",
      "[EPOCH #16, step #1020] loss: 1.690476457764423\n",
      "[EPOCH #16, step #1022] loss: 1.6900714623613442\n",
      "[EPOCH #16, step #1024] loss: 1.6899783901470464\n",
      "[EPOCH #16, step #1026] loss: 1.689776340327221\n",
      "[EPOCH #16, step #1028] loss: 1.6901934033927695\n",
      "[EPOCH #16, step #1030] loss: 1.6910437659426412\n",
      "[EPOCH #16, step #1032] loss: 1.6905914738355972\n",
      "[EPOCH #16, step #1034] loss: 1.6903473894953152\n",
      "[EPOCH #16, step #1036] loss: 1.6900068738191545\n",
      "[EPOCH #16, step #1038] loss: 1.690512904820245\n",
      "[EPOCH #16, step #1040] loss: 1.690847110965868\n",
      "[EPOCH #16, step #1042] loss: 1.6911434019171951\n",
      "[EPOCH #16, step #1044] loss: 1.691236020446394\n",
      "[EPOCH #16, step #1046] loss: 1.6916081897964224\n",
      "[EPOCH #16, step #1048] loss: 1.6916214180515423\n",
      "[EPOCH #16, step #1050] loss: 1.6919638193527025\n",
      "[EPOCH #16, step #1052] loss: 1.6909728175328103\n",
      "[EPOCH #16, step #1054] loss: 1.6910834535603274\n",
      "[EPOCH #16, step #1056] loss: 1.6916423718548093\n",
      "[EPOCH #16, step #1058] loss: 1.691442849446964\n",
      "[EPOCH #16, step #1060] loss: 1.691096829143366\n",
      "[EPOCH #16, step #1062] loss: 1.6913067465218754\n",
      "[EPOCH #16, step #1064] loss: 1.6913810533536993\n",
      "[EPOCH #16, step #1066] loss: 1.6906558577435644\n",
      "[EPOCH #16, step #1068] loss: 1.6909824001443396\n",
      "[EPOCH #16, step #1070] loss: 1.6911734812845147\n",
      "[EPOCH #16, step #1072] loss: 1.6912531498871668\n",
      "[EPOCH #16, step #1074] loss: 1.6912617038571558\n",
      "[EPOCH #16, step #1076] loss: 1.690960039833462\n",
      "[EPOCH #16, step #1078] loss: 1.690548863037523\n",
      "[EPOCH #16, step #1080] loss: 1.689808711257938\n",
      "[EPOCH #16, step #1082] loss: 1.6901747622868581\n",
      "[EPOCH #16, step #1084] loss: 1.6899306417610238\n",
      "[EPOCH #16, step #1086] loss: 1.6893275019326337\n",
      "[EPOCH #16, step #1088] loss: 1.689763636464258\n",
      "[EPOCH #16, step #1090] loss: 1.689290259815377\n",
      "[EPOCH #16, step #1092] loss: 1.689576691536323\n",
      "[EPOCH #16, step #1094] loss: 1.6891060729549356\n",
      "[EPOCH #16, step #1096] loss: 1.688969643255093\n",
      "[EPOCH #16, step #1098] loss: 1.6890826700924741\n",
      "[EPOCH #16, step #1100] loss: 1.6887148798973748\n",
      "[EPOCH #16, step #1102] loss: 1.6887949714310475\n",
      "[EPOCH #16, step #1104] loss: 1.6884662449629597\n",
      "[EPOCH #16, step #1106] loss: 1.6880652714443294\n",
      "[EPOCH #16, step #1108] loss: 1.6881247823898378\n",
      "[EPOCH #16, step #1110] loss: 1.6883333224524901\n",
      "[EPOCH #16, step #1112] loss: 1.6882120007239048\n",
      "[EPOCH #16, step #1114] loss: 1.6878026029454218\n",
      "[EPOCH #16, step #1116] loss: 1.6878011178095211\n",
      "[EPOCH #16, step #1118] loss: 1.6875142331523911\n",
      "[EPOCH #16, step #1120] loss: 1.6875008907730722\n",
      "[EPOCH #16, step #1122] loss: 1.6871921802246455\n",
      "[EPOCH #16, step #1124] loss: 1.6867596179644266\n",
      "[EPOCH #16, step #1126] loss: 1.6868449284000109\n",
      "[EPOCH #16, step #1128] loss: 1.6868440740081037\n",
      "[EPOCH #16, step #1130] loss: 1.687066760292947\n",
      "[EPOCH #16, step #1132] loss: 1.6865296802053595\n",
      "[EPOCH #16, step #1134] loss: 1.6864742540052808\n",
      "[EPOCH #16, step #1136] loss: 1.6868468421849643\n",
      "[EPOCH #16, step #1138] loss: 1.6870543609804183\n",
      "[EPOCH #16, step #1140] loss: 1.6869223715964374\n",
      "[EPOCH #16, step #1142] loss: 1.686812298556534\n",
      "[EPOCH #16, step #1144] loss: 1.6872383521113332\n",
      "[EPOCH #16, step #1146] loss: 1.6879346397199522\n",
      "[EPOCH #16, step #1148] loss: 1.687873799609972\n",
      "[EPOCH #16, step #1150] loss: 1.687889866006571\n",
      "[EPOCH #16, step #1152] loss: 1.6877962165259321\n",
      "[EPOCH #16, step #1154] loss: 1.6878504071400795\n",
      "[EPOCH #16, step #1156] loss: 1.6872977420700555\n",
      "[EPOCH #16, step #1158] loss: 1.687972638759251\n",
      "[EPOCH #16, step #1160] loss: 1.6881625639478468\n",
      "[EPOCH #16, step #1162] loss: 1.6887326680783659\n",
      "[EPOCH #16, step #1164] loss: 1.688802476144144\n",
      "[EPOCH #16, step #1166] loss: 1.6884049359507916\n",
      "[EPOCH #16, step #1168] loss: 1.6879113328773003\n",
      "[EPOCH #16, step #1170] loss: 1.6882496727622542\n",
      "[EPOCH #16, step #1172] loss: 1.688271964348389\n",
      "[EPOCH #16, step #1174] loss: 1.6881967436506393\n",
      "[EPOCH #16, step #1176] loss: 1.6884379109894714\n",
      "[EPOCH #16, step #1178] loss: 1.6891878273549779\n",
      "[EPOCH #16, step #1180] loss: 1.6889756004957706\n",
      "[EPOCH #16, step #1182] loss: 1.68978846451033\n",
      "[EPOCH #16, step #1184] loss: 1.6899793047945209\n",
      "[EPOCH #16, step #1186] loss: 1.6901699364335976\n",
      "[EPOCH #16, step #1188] loss: 1.690570631129487\n",
      "[EPOCH #16, step #1190] loss: 1.690238898937488\n",
      "[EPOCH #16, step #1192] loss: 1.689931395317663\n",
      "[EPOCH #16, step #1194] loss: 1.6895341118509302\n",
      "[EPOCH #16, step #1196] loss: 1.6895556565912544\n",
      "[EPOCH #16, step #1198] loss: 1.6893998665348304\n",
      "[EPOCH #16, step #1200] loss: 1.6902816352697336\n",
      "[EPOCH #16, step #1202] loss: 1.6906702742909552\n",
      "[EPOCH #16, step #1204] loss: 1.6906516227979382\n",
      "[EPOCH #16, step #1206] loss: 1.6905741580478792\n",
      "[EPOCH #16, step #1208] loss: 1.6902324009079692\n",
      "[EPOCH #16, step #1210] loss: 1.6898288466436227\n",
      "[EPOCH #16, step #1212] loss: 1.6895537384757304\n",
      "[EPOCH #16, step #1214] loss: 1.6898342136002371\n",
      "[EPOCH #16, step #1216] loss: 1.6901914332377292\n",
      "[EPOCH #16, step #1218] loss: 1.690126253651047\n",
      "[EPOCH #16, step #1220] loss: 1.6896555184048772\n",
      "[EPOCH #16, step #1222] loss: 1.6895057857280273\n",
      "[EPOCH #16, step #1224] loss: 1.6892040353405233\n",
      "[EPOCH #16, step #1226] loss: 1.6891661812934626\n",
      "[EPOCH #16, step #1228] loss: 1.6893444948316687\n",
      "[EPOCH #16, step #1230] loss: 1.6895943744990227\n",
      "[EPOCH #16, step #1232] loss: 1.689722304651627\n",
      "[EPOCH #16, step #1234] loss: 1.689925970577518\n",
      "[EPOCH #16, step #1236] loss: 1.6898811181032956\n",
      "[EPOCH #16, step #1238] loss: 1.6898574665056494\n",
      "[EPOCH #16, step #1240] loss: 1.6898727948679066\n",
      "[EPOCH #16, step #1242] loss: 1.690031603901787\n",
      "[EPOCH #16, step #1244] loss: 1.6892821660961013\n",
      "[EPOCH #16, step #1246] loss: 1.688995447413101\n",
      "[EPOCH #16, step #1248] loss: 1.6889496086787186\n",
      "[EPOCH #16, step #1250] loss: 1.689522962823665\n",
      "[EPOCH #16, step #1252] loss: 1.689577384415571\n",
      "[EPOCH #16, step #1254] loss: 1.6900058058153586\n",
      "[EPOCH #16, step #1256] loss: 1.6901075488627668\n",
      "[EPOCH #16, step #1258] loss: 1.6900600335539286\n",
      "[EPOCH #16, step #1260] loss: 1.6900524648288997\n",
      "[EPOCH #16, step #1262] loss: 1.6901188590936216\n",
      "[EPOCH #16, step #1264] loss: 1.6903878444268299\n",
      "[EPOCH #16, step #1266] loss: 1.6902283251803036\n",
      "[EPOCH #16, step #1268] loss: 1.6897399471067274\n",
      "[EPOCH #16, step #1270] loss: 1.6894608684921715\n",
      "[EPOCH #16, step #1272] loss: 1.688651189641136\n",
      "[EPOCH #16, step #1274] loss: 1.688290790903802\n",
      "[EPOCH #16, step #1276] loss: 1.6878656720685699\n",
      "[EPOCH #16, step #1278] loss: 1.687230481357664\n",
      "[EPOCH #16, step #1280] loss: 1.6869006997714464\n",
      "[EPOCH #16, step #1282] loss: 1.6867027305478894\n",
      "[EPOCH #16, step #1284] loss: 1.6864520196784796\n",
      "[EPOCH #16, step #1286] loss: 1.6863930164702474\n",
      "[EPOCH #16, step #1288] loss: 1.6864873285992743\n",
      "[EPOCH #16, step #1290] loss: 1.6869059069317316\n",
      "[EPOCH #16, step #1292] loss: 1.6864958251527549\n",
      "[EPOCH #16, step #1294] loss: 1.6864015122177978\n",
      "[EPOCH #16, step #1296] loss: 1.6866216448608875\n",
      "[EPOCH #16, step #1298] loss: 1.6869454273267193\n",
      "[EPOCH #16, step #1300] loss: 1.686209436153834\n",
      "[EPOCH #16, step #1302] loss: 1.6858751046959475\n",
      "[EPOCH #16, step #1304] loss: 1.6858913450405515\n",
      "[EPOCH #16, step #1306] loss: 1.6852682235593\n",
      "[EPOCH #16, step #1308] loss: 1.685286524507087\n",
      "[EPOCH #16, step #1310] loss: 1.6850975496818055\n",
      "[EPOCH #16, step #1312] loss: 1.6853741162711213\n",
      "[EPOCH #16, step #1314] loss: 1.6854611011965646\n",
      "[EPOCH #16, step #1316] loss: 1.6854029838207913\n",
      "[EPOCH #16, step #1318] loss: 1.6854153182399914\n",
      "[EPOCH #16, step #1320] loss: 1.6856399572861185\n",
      "[EPOCH #16, step #1322] loss: 1.6856511811910933\n",
      "[EPOCH #16, step #1324] loss: 1.6857573013035756\n",
      "[EPOCH #16, step #1326] loss: 1.6854228161741398\n",
      "[EPOCH #16, step #1328] loss: 1.6848657152274213\n",
      "[EPOCH #16, step #1330] loss: 1.6849517278166126\n",
      "[EPOCH #16, step #1332] loss: 1.6846023963880288\n",
      "[EPOCH #16, step #1334] loss: 1.6847712858339374\n",
      "[EPOCH #16, step #1336] loss: 1.6845477748559141\n",
      "[EPOCH #16, step #1338] loss: 1.684635506493552\n",
      "[EPOCH #16, step #1340] loss: 1.68431267255638\n",
      "[EPOCH #16, step #1342] loss: 1.6846665559823355\n",
      "[EPOCH #16, step #1344] loss: 1.6844245768391066\n",
      "[EPOCH #16, step #1346] loss: 1.6844043279012753\n",
      "[EPOCH #16, step #1348] loss: 1.6844565876772706\n",
      "[EPOCH #16, step #1350] loss: 1.6847576606635426\n",
      "[EPOCH #16, step #1352] loss: 1.6848625481701391\n",
      "[EPOCH #16, step #1354] loss: 1.6845561767856134\n",
      "[EPOCH #16, step #1356] loss: 1.684417879440895\n",
      "[EPOCH #16, step #1358] loss: 1.684603796582436\n",
      "[EPOCH #16, step #1360] loss: 1.6840191063943986\n",
      "[EPOCH #16, step #1362] loss: 1.684098271657156\n",
      "[EPOCH #16, step #1364] loss: 1.683766888131152\n",
      "[EPOCH #16, step #1366] loss: 1.68400387935771\n",
      "[EPOCH #16, step #1368] loss: 1.6840677618806252\n",
      "[EPOCH #16, step #1370] loss: 1.6843016168916425\n",
      "[EPOCH #16, step #1372] loss: 1.6842402173321522\n",
      "[EPOCH #16, step #1374] loss: 1.6838780777237632\n",
      "[EPOCH #16, step #1376] loss: 1.6833127001618335\n",
      "[EPOCH #16, step #1378] loss: 1.6842076414905656\n",
      "[EPOCH #16, step #1380] loss: 1.6846796302239504\n",
      "[EPOCH #16, step #1382] loss: 1.684769413691884\n",
      "[EPOCH #16, step #1384] loss: 1.6843640454409354\n",
      "[EPOCH #16, step #1386] loss: 1.683775393113698\n",
      "[EPOCH #16, step #1388] loss: 1.6831641976914018\n",
      "[EPOCH #16, step #1390] loss: 1.6830488414664992\n",
      "[EPOCH #16, step #1392] loss: 1.682841340201584\n",
      "[EPOCH #16, step #1394] loss: 1.682916179395491\n",
      "[EPOCH #16, step #1396] loss: 1.6826718266128042\n",
      "[EPOCH #16, step #1398] loss: 1.6826968855564726\n",
      "[EPOCH #16, step #1400] loss: 1.6823219879876707\n",
      "[EPOCH #16, step #1402] loss: 1.682233406702111\n",
      "[EPOCH #16, step #1404] loss: 1.6819634585618124\n",
      "[EPOCH #16, step #1406] loss: 1.6821805057834036\n",
      "[EPOCH #16, step #1408] loss: 1.6823369551838672\n",
      "[EPOCH #16, step #1410] loss: 1.6824602907976303\n",
      "[EPOCH #16, step #1412] loss: 1.6826917300474027\n",
      "[EPOCH #16, step #1414] loss: 1.6828753802043388\n",
      "[EPOCH #16, step #1416] loss: 1.6825350668956969\n",
      "[EPOCH #16, step #1418] loss: 1.6821304025828123\n",
      "[EPOCH #16, step #1420] loss: 1.6817584436683064\n",
      "[EPOCH #16, step #1422] loss: 1.6821091260946894\n",
      "[EPOCH #16, step #1424] loss: 1.682154537543916\n",
      "[EPOCH #16, step #1426] loss: 1.6820554723669452\n",
      "[EPOCH #16, step #1428] loss: 1.6821250476313272\n",
      "[EPOCH #16, step #1430] loss: 1.682027706101922\n",
      "[EPOCH #16, step #1432] loss: 1.682077279268905\n",
      "[EPOCH #16, step #1434] loss: 1.682034010795766\n",
      "[EPOCH #16, step #1436] loss: 1.6820045341695442\n",
      "[EPOCH #16, step #1438] loss: 1.682207972204793\n",
      "[EPOCH #16, step #1440] loss: 1.682375511595311\n",
      "[EPOCH #16, step #1442] loss: 1.6821856412388596\n",
      "[EPOCH #16, step #1444] loss: 1.6824153074756214\n",
      "[EPOCH #16, step #1446] loss: 1.6824880641908915\n",
      "[EPOCH #16, step #1448] loss: 1.6826495814520874\n",
      "[EPOCH #16, step #1450] loss: 1.6822800101862538\n",
      "[EPOCH #16, step #1452] loss: 1.6820409442749995\n",
      "[EPOCH #16, step #1454] loss: 1.6827162639791613\n",
      "[EPOCH #16, step #1456] loss: 1.6823863794563074\n",
      "[EPOCH #16, step #1458] loss: 1.6824592081057528\n",
      "[EPOCH #16, step #1460] loss: 1.682244848544103\n",
      "[EPOCH #16, step #1462] loss: 1.6823745479098102\n",
      "[EPOCH #16, step #1464] loss: 1.68233936642624\n",
      "[EPOCH #16, step #1466] loss: 1.6820838698011398\n",
      "[EPOCH #16, step #1468] loss: 1.6819704289416864\n",
      "[EPOCH #16, step #1470] loss: 1.6819488577174946\n",
      "[EPOCH #16, step #1472] loss: 1.6820225559038446\n",
      "[EPOCH #16, step #1474] loss: 1.681687036005117\n",
      "[EPOCH #16, step #1476] loss: 1.6812650221541836\n",
      "[EPOCH #16, step #1478] loss: 1.6807713974078335\n",
      "[EPOCH #16, step #1480] loss: 1.681002653305149\n",
      "[EPOCH #16, step #1482] loss: 1.6810325872472067\n",
      "[EPOCH #16, step #1484] loss: 1.6814753439691332\n",
      "[EPOCH #16, step #1486] loss: 1.6815113935922728\n",
      "[EPOCH #16, step #1488] loss: 1.681170819548651\n",
      "[EPOCH #16, step #1490] loss: 1.681236032069249\n",
      "[EPOCH #16, step #1492] loss: 1.6813103816929234\n",
      "[EPOCH #16, step #1494] loss: 1.6810128482687832\n",
      "[EPOCH #16, step #1496] loss: 1.6812679157228412\n",
      "[EPOCH #16, step #1498] loss: 1.6809183043030758\n",
      "[EPOCH #16, step #1500] loss: 1.6804351899959022\n",
      "[EPOCH #16, step #1502] loss: 1.680433171594928\n",
      "[EPOCH #16, step #1504] loss: 1.680247506073543\n",
      "[EPOCH #16, step #1506] loss: 1.6803181260408908\n",
      "[EPOCH #16, step #1508] loss: 1.6800413828878864\n",
      "[EPOCH #16, step #1510] loss: 1.6802727311040928\n",
      "[EPOCH #16, step #1512] loss: 1.6798001726731038\n",
      "[EPOCH #16, step #1514] loss: 1.6791138623413866\n",
      "[EPOCH #16, step #1516] loss: 1.6792981031700114\n",
      "[EPOCH #16, step #1518] loss: 1.6791025588118458\n",
      "[EPOCH #16, step #1520] loss: 1.6789725209677557\n",
      "[EPOCH #16, step #1522] loss: 1.6785783491789004\n",
      "[EPOCH #16, step #1524] loss: 1.6784885080134282\n",
      "[EPOCH #16, step #1526] loss: 1.6786152326209762\n",
      "[EPOCH #16, step #1528] loss: 1.6785146163677842\n",
      "[EPOCH #16, step #1530] loss: 1.6786882574070832\n",
      "[EPOCH #16, step #1532] loss: 1.6783393363663361\n",
      "[EPOCH #16, step #1534] loss: 1.678504295729659\n",
      "[EPOCH #16, step #1536] loss: 1.6787040362748995\n",
      "[EPOCH #16, step #1538] loss: 1.678590966440626\n",
      "[EPOCH #16, step #1540] loss: 1.6784217307739333\n",
      "[EPOCH #16, step #1542] loss: 1.6783554914394756\n",
      "[EPOCH #16, step #1544] loss: 1.67833317487371\n",
      "[EPOCH #16, step #1546] loss: 1.6788554946376033\n",
      "[EPOCH #16, step #1548] loss: 1.6783256341827693\n",
      "[EPOCH #16, step #1550] loss: 1.6782978641302797\n",
      "[EPOCH #16, step #1552] loss: 1.6779224523711957\n",
      "[EPOCH #16, step #1554] loss: 1.677970439636439\n",
      "[EPOCH #16, step #1556] loss: 1.6782930661794384\n",
      "[EPOCH #16, step #1558] loss: 1.6783651843370728\n",
      "[EPOCH #16, step #1560] loss: 1.6783145299177762\n",
      "[EPOCH #16, step #1562] loss: 1.6785584632128534\n",
      "[EPOCH #16, step #1564] loss: 1.6785937864178666\n",
      "[EPOCH #16, step #1566] loss: 1.6783680284030893\n",
      "[EPOCH #16, step #1568] loss: 1.6780876642659335\n",
      "[EPOCH #16, step #1570] loss: 1.678136578758077\n",
      "[EPOCH #16, step #1572] loss: 1.6779813072670817\n",
      "[EPOCH #16, step #1574] loss: 1.6779090509338985\n",
      "[EPOCH #16, step #1576] loss: 1.6775016057846588\n",
      "[EPOCH #16, step #1578] loss: 1.6773662834774474\n",
      "[EPOCH #16, step #1580] loss: 1.6775472322119556\n",
      "[EPOCH #16, step #1582] loss: 1.6775068350781086\n",
      "[EPOCH #16, step #1584] loss: 1.677702409649497\n",
      "[EPOCH #16, step #1586] loss: 1.6774091080216094\n",
      "[EPOCH #16, step #1588] loss: 1.677795327219894\n",
      "[EPOCH #16, step #1590] loss: 1.6774803318743583\n",
      "[EPOCH #16, step #1592] loss: 1.6778199623683228\n",
      "[EPOCH #16, step #1594] loss: 1.6774061764669268\n",
      "[EPOCH #16, step #1596] loss: 1.6771438112464934\n",
      "[EPOCH #16, step #1598] loss: 1.6774028003253065\n",
      "[EPOCH #16, step #1600] loss: 1.6773827351829844\n",
      "[EPOCH #16, step #1602] loss: 1.6775438518205883\n",
      "[EPOCH #16, step #1604] loss: 1.6776766074037996\n",
      "[EPOCH #16, step #1606] loss: 1.677228780844676\n",
      "[EPOCH #16, step #1608] loss: 1.6774462661882452\n",
      "[EPOCH #16, step #1610] loss: 1.6770392382907098\n",
      "[EPOCH #16, step #1612] loss: 1.6774101237000254\n",
      "[EPOCH #16, step #1614] loss: 1.6773239527324404\n",
      "[EPOCH #16, step #1616] loss: 1.6774381840383852\n",
      "[EPOCH #16, step #1618] loss: 1.6773075392910402\n",
      "[EPOCH #16, step #1620] loss: 1.6774424355313926\n",
      "[EPOCH #16, step #1622] loss: 1.6770175709742055\n",
      "[EPOCH #16, step #1624] loss: 1.6769328268858104\n",
      "[EPOCH #16, step #1626] loss: 1.6768656374489375\n",
      "[EPOCH #16, step #1628] loss: 1.6769108913148232\n",
      "[EPOCH #16, step #1630] loss: 1.6771527667267785\n",
      "[EPOCH #16, step #1632] loss: 1.6770670136935275\n",
      "[EPOCH #16, step #1634] loss: 1.676544090330783\n",
      "[EPOCH #16, step #1636] loss: 1.6765714443596529\n",
      "[EPOCH #16, step #1638] loss: 1.6768689052661503\n",
      "[EPOCH #16, step #1640] loss: 1.6766421222091084\n",
      "[EPOCH #16, step #1642] loss: 1.6761595051751512\n",
      "[EPOCH #16, step #1644] loss: 1.6761344380291763\n",
      "[EPOCH #16, step #1646] loss: 1.6762139598528545\n",
      "[EPOCH #16, step #1648] loss: 1.676163180551072\n",
      "[EPOCH #16, step #1650] loss: 1.6757786520533964\n",
      "[EPOCH #16, step #1652] loss: 1.6753778447905816\n",
      "[EPOCH #16, step #1654] loss: 1.6759295905464726\n",
      "[EPOCH #16, step #1656] loss: 1.6757378695812581\n",
      "[EPOCH #16, step #1658] loss: 1.6760009279662116\n",
      "[EPOCH #16, step #1660] loss: 1.6761506631889664\n",
      "[EPOCH #16, step #1662] loss: 1.6761902880037827\n",
      "[EPOCH #16, step #1664] loss: 1.6762861265076532\n",
      "[EPOCH #16, step #1666] loss: 1.676422753838915\n",
      "[EPOCH #16, step #1668] loss: 1.6764033528914204\n",
      "[EPOCH #16, step #1670] loss: 1.6763450190879712\n",
      "[EPOCH #16, step #1672] loss: 1.6763954162241381\n",
      "[EPOCH #16, step #1674] loss: 1.6766113497961812\n",
      "[EPOCH #16, step #1676] loss: 1.6763042211177168\n",
      "[EPOCH #16, step #1678] loss: 1.6760286568814335\n",
      "[EPOCH #16, step #1680] loss: 1.6758292187614714\n",
      "[EPOCH #16, step #1682] loss: 1.675905476810673\n",
      "[EPOCH #16, step #1684] loss: 1.6758675156785756\n",
      "[EPOCH #16, step #1686] loss: 1.6757949718230563\n",
      "[EPOCH #16, step #1688] loss: 1.6754839063537692\n",
      "[EPOCH #16, step #1690] loss: 1.6754018309058556\n",
      "[EPOCH #16, step #1692] loss: 1.6755522668044804\n",
      "[EPOCH #16, step #1694] loss: 1.6755662606177428\n",
      "[EPOCH #16, step #1696] loss: 1.6754367064572673\n",
      "[EPOCH #16, step #1698] loss: 1.6757465559219598\n",
      "[EPOCH #16, step #1700] loss: 1.6756271089195574\n",
      "[EPOCH #16, step #1702] loss: 1.6758220285019731\n",
      "[EPOCH #16, step #1704] loss: 1.6760884029424785\n",
      "[EPOCH #16, step #1706] loss: 1.6765064942117456\n",
      "[EPOCH #16, step #1708] loss: 1.676171394138046\n",
      "[EPOCH #16, step #1710] loss: 1.6761558400407164\n",
      "[EPOCH #16, step #1712] loss: 1.6766023752429091\n",
      "[EPOCH #16, step #1714] loss: 1.6765018829798908\n",
      "[EPOCH #16, step #1716] loss: 1.6766921602922882\n",
      "[EPOCH #16, step #1718] loss: 1.6765549239410502\n",
      "[EPOCH #16, step #1720] loss: 1.6766250190660055\n",
      "[EPOCH #16, step #1722] loss: 1.6766574568549215\n",
      "[EPOCH #16, step #1724] loss: 1.676297322874484\n",
      "[EPOCH #16, step #1726] loss: 1.6761677028060167\n",
      "[EPOCH #16, step #1728] loss: 1.6761008528286905\n",
      "[EPOCH #16, step #1730] loss: 1.6760703192702062\n",
      "[EPOCH #16, step #1732] loss: 1.6762650534725574\n",
      "[EPOCH #16, step #1734] loss: 1.67642118425809\n",
      "[EPOCH #16, step #1736] loss: 1.6760838454182834\n",
      "[EPOCH #16, step #1738] loss: 1.6761594200147987\n",
      "[EPOCH #16, step #1740] loss: 1.6761766918975003\n",
      "[EPOCH #16, step #1742] loss: 1.6760460359572817\n",
      "[EPOCH #16, step #1744] loss: 1.6758736582745113\n",
      "[EPOCH #16, step #1746] loss: 1.6756695064395648\n",
      "[EPOCH #16, step #1748] loss: 1.6757843382294482\n",
      "[EPOCH #16, step #1750] loss: 1.6756283692602836\n",
      "[EPOCH #16, step #1752] loss: 1.6753283916237827\n",
      "[EPOCH #16, step #1754] loss: 1.6754251383308671\n",
      "[EPOCH #16, step #1756] loss: 1.675722841485088\n",
      "[EPOCH #16, step #1758] loss: 1.6757064845292253\n",
      "[EPOCH #16, step #1760] loss: 1.6763312070292549\n",
      "[EPOCH #16, step #1762] loss: 1.676154408107342\n",
      "[EPOCH #16, step #1764] loss: 1.6763093402297908\n",
      "[EPOCH #16, step #1766] loss: 1.6761986661847865\n",
      "[EPOCH #16, step #1768] loss: 1.6761800877922601\n",
      "[EPOCH #16, step #1770] loss: 1.6761546411937\n",
      "[EPOCH #16, step #1772] loss: 1.676062586310215\n",
      "[EPOCH #16, step #1774] loss: 1.675924939739872\n",
      "[EPOCH #16, step #1776] loss: 1.6760316296581748\n",
      "[EPOCH #16, step #1778] loss: 1.6758379515735804\n",
      "[EPOCH #16, step #1780] loss: 1.6759377934502993\n",
      "[EPOCH #16, step #1782] loss: 1.675740345535289\n",
      "[EPOCH #16, step #1784] loss: 1.6756207827760392\n",
      "[EPOCH #16, step #1786] loss: 1.676222135217482\n",
      "[EPOCH #16, step #1788] loss: 1.676372864680826\n",
      "[EPOCH #16, step #1790] loss: 1.6761946834910855\n",
      "[EPOCH #16, step #1792] loss: 1.67623188627943\n",
      "[EPOCH #16, step #1794] loss: 1.6760869567772805\n",
      "[EPOCH #16, step #1796] loss: 1.6762106078627643\n",
      "[EPOCH #16, step #1798] loss: 1.675918554616942\n",
      "[EPOCH #16, step #1800] loss: 1.675690805594303\n",
      "[EPOCH #16, step #1802] loss: 1.6755198954676365\n",
      "[EPOCH #16, step #1804] loss: 1.6752453618102456\n",
      "[EPOCH #16, step #1806] loss: 1.675344306886955\n",
      "[EPOCH #16, step #1808] loss: 1.6750089624364315\n",
      "[EPOCH #16, step #1810] loss: 1.6749249835951694\n",
      "[EPOCH #16, step #1812] loss: 1.6752340683474176\n",
      "[EPOCH #16, step #1814] loss: 1.6751834973487645\n",
      "[EPOCH #16, step #1816] loss: 1.675306710786195\n",
      "[EPOCH #16, step #1818] loss: 1.6754907405985915\n",
      "[EPOCH #16, step #1820] loss: 1.6755584512746706\n",
      "[EPOCH #16, step #1822] loss: 1.6756477623736539\n",
      "[EPOCH #16, step #1824] loss: 1.6754679652109539\n",
      "[EPOCH #16, step #1826] loss: 1.6754936480626554\n",
      "[EPOCH #16, step #1828] loss: 1.6759803620696132\n",
      "[EPOCH #16, step #1830] loss: 1.6761309206322983\n",
      "[EPOCH #16, step #1832] loss: 1.6763591896102394\n",
      "[EPOCH #16, step #1834] loss: 1.676542911899837\n",
      "[EPOCH #16, step #1836] loss: 1.6764749853456546\n",
      "[EPOCH #16, step #1838] loss: 1.6760588554081028\n",
      "[EPOCH #16, step #1840] loss: 1.6762787950938969\n",
      "[EPOCH #16, step #1842] loss: 1.676200101088391\n",
      "[EPOCH #16, step #1844] loss: 1.6762705847176755\n",
      "[EPOCH #16, step #1846] loss: 1.6761476258103372\n",
      "[EPOCH #16, step #1848] loss: 1.6763638287959968\n",
      "[EPOCH #16, step #1850] loss: 1.6763875004988886\n",
      "[EPOCH #16, step #1852] loss: 1.6764446023793331\n",
      "[EPOCH #16, step #1854] loss: 1.6764821646027166\n",
      "[EPOCH #16, step #1856] loss: 1.6768065112280346\n",
      "[EPOCH #16, step #1858] loss: 1.6763256460893148\n",
      "[EPOCH #16, step #1860] loss: 1.6760137683598346\n",
      "[EPOCH #16, step #1862] loss: 1.6759349818966816\n",
      "[EPOCH #16, step #1864] loss: 1.6759300179200263\n",
      "[EPOCH #16, step #1866] loss: 1.6759971442488215\n",
      "[EPOCH #16, step #1868] loss: 1.675915104332552\n",
      "[EPOCH #16, step #1870] loss: 1.675721540577204\n",
      "[EPOCH #16, step #1872] loss: 1.675828804164027\n",
      "[EPOCH #16, step #1874] loss: 1.675567020702362\n",
      "[EPOCH #16, step #1876] loss: 1.675522370832552\n",
      "[EPOCH #16, step #1878] loss: 1.6753276896451368\n",
      "[EPOCH #16, step #1880] loss: 1.6753327436170826\n",
      "[EPOCH #16, step #1882] loss: 1.675412957014964\n",
      "[EPOCH #16, step #1884] loss: 1.6753151911006998\n",
      "[EPOCH #16, step #1886] loss: 1.6753356841170226\n",
      "[EPOCH #16, step #1888] loss: 1.675397232230092\n",
      "[EPOCH #16, step #1890] loss: 1.6753898497487678\n",
      "[EPOCH #16, step #1892] loss: 1.6751605492386312\n",
      "[EPOCH #16, step #1894] loss: 1.6752281181730506\n",
      "[EPOCH #16, step #1896] loss: 1.6751292694790085\n",
      "[EPOCH #16, step #1898] loss: 1.6748376609840916\n",
      "[EPOCH #16, step #1900] loss: 1.6748810513341885\n",
      "[EPOCH #16, step #1902] loss: 1.6747044491817997\n",
      "[EPOCH #16, step #1904] loss: 1.674480168744335\n",
      "[EPOCH #16, step #1906] loss: 1.6741558223665856\n",
      "[EPOCH #16, step #1908] loss: 1.6748560292674586\n",
      "[EPOCH #16, step #1910] loss: 1.6750229755226447\n",
      "[EPOCH #16, step #1912] loss: 1.6749382235588854\n",
      "[EPOCH #16, step #1914] loss: 1.675320331079219\n",
      "[EPOCH #16, step #1916] loss: 1.6753425700439408\n",
      "[EPOCH #16, step #1918] loss: 1.675308292423952\n",
      "[EPOCH #16, step #1920] loss: 1.6746282481328079\n",
      "[EPOCH #16, step #1922] loss: 1.6749067199893501\n",
      "[EPOCH #16, step #1924] loss: 1.6746932587066254\n",
      "[EPOCH #16, step #1926] loss: 1.6746654574216557\n",
      "[EPOCH #16, step #1928] loss: 1.674818128301048\n",
      "[EPOCH #16, step #1930] loss: 1.6746608534975413\n",
      "[EPOCH #16, step #1932] loss: 1.6744635324063724\n",
      "[EPOCH #16, step #1934] loss: 1.6748522099906469\n",
      "[EPOCH #16, step #1936] loss: 1.6749755453681847\n",
      "[EPOCH #16, step #1938] loss: 1.6749710292776816\n",
      "[EPOCH #16, step #1940] loss: 1.6749721508797513\n",
      "[EPOCH #16, step #1942] loss: 1.6747058933074488\n",
      "[EPOCH #16, step #1944] loss: 1.674606432032156\n",
      "[EPOCH #16, step #1946] loss: 1.6745577932444975\n",
      "[EPOCH #16, step #1948] loss: 1.6745394769236024\n",
      "[EPOCH #16, step #1950] loss: 1.6743785581608297\n",
      "[EPOCH #16, step #1952] loss: 1.6744695765753617\n",
      "[EPOCH #16, step #1954] loss: 1.6740960077861387\n",
      "[EPOCH #16, step #1956] loss: 1.6739340185449023\n",
      "[EPOCH #16, step #1958] loss: 1.6742010729966448\n",
      "[EPOCH #16, step #1960] loss: 1.674090632548568\n",
      "[EPOCH #16, step #1962] loss: 1.673898410930721\n",
      "[EPOCH #16, step #1964] loss: 1.6741719952066436\n",
      "[EPOCH #16, step #1966] loss: 1.6736600421441044\n",
      "[EPOCH #16, step #1968] loss: 1.6737697778346274\n",
      "[EPOCH #16, step #1970] loss: 1.6736861246603507\n",
      "[EPOCH #16, step #1972] loss: 1.673687026818513\n",
      "[EPOCH #16, step #1974] loss: 1.6734718560568893\n",
      "[EPOCH #16, step #1976] loss: 1.6735016097911513\n",
      "[EPOCH #16, step #1978] loss: 1.67320293883834\n",
      "[EPOCH #16, step #1980] loss: 1.6731055232986305\n",
      "[EPOCH #16, step #1982] loss: 1.673389014786563\n",
      "[EPOCH #16, step #1984] loss: 1.6735470374225068\n",
      "[EPOCH #16, step #1986] loss: 1.6736424257242926\n",
      "[EPOCH #16, step #1988] loss: 1.6735646312952401\n",
      "[EPOCH #16, step #1990] loss: 1.6738138656290495\n",
      "[EPOCH #16, step #1992] loss: 1.6737574063768592\n",
      "[EPOCH #16, step #1994] loss: 1.6736937782220673\n",
      "[EPOCH #16, step #1996] loss: 1.6737954944267712\n",
      "[EPOCH #16, step #1998] loss: 1.673827089268664\n",
      "[EPOCH #16, step #2000] loss: 1.6735924546686427\n",
      "[EPOCH #16, step #2002] loss: 1.6733508245741435\n",
      "[EPOCH #16, step #2004] loss: 1.6734374290095304\n",
      "[EPOCH #16, step #2006] loss: 1.6737506081942723\n",
      "[EPOCH #16, step #2008] loss: 1.673769376775173\n",
      "[EPOCH #16, step #2010] loss: 1.6740351709662713\n",
      "[EPOCH #16, step #2012] loss: 1.6738001741228326\n",
      "[EPOCH #16, step #2014] loss: 1.6734266495290524\n",
      "[EPOCH #16, step #2016] loss: 1.6734270384598913\n",
      "[EPOCH #16, step #2018] loss: 1.673489411317694\n",
      "[EPOCH #16, step #2020] loss: 1.672959845352739\n",
      "[EPOCH #16, step #2022] loss: 1.673150162088712\n",
      "[EPOCH #16, step #2024] loss: 1.673234955293161\n",
      "[EPOCH #16, step #2026] loss: 1.673159905296273\n",
      "[EPOCH #16, step #2028] loss: 1.6734970119447177\n",
      "[EPOCH #16, step #2030] loss: 1.6731781124305631\n",
      "[EPOCH #16, step #2032] loss: 1.6730049333722499\n",
      "[EPOCH #16, step #2034] loss: 1.672915875413787\n",
      "[EPOCH #16, step #2036] loss: 1.6733072077344315\n",
      "[EPOCH #16, step #2038] loss: 1.673432214579318\n",
      "[EPOCH #16, step #2040] loss: 1.6735907848531975\n",
      "[EPOCH #16, step #2042] loss: 1.6732721584892367\n",
      "[EPOCH #16, step #2044] loss: 1.6733809137111189\n",
      "[EPOCH #16, step #2046] loss: 1.6735899697062908\n",
      "[EPOCH #16, step #2048] loss: 1.6736712052567289\n",
      "[EPOCH #16, step #2050] loss: 1.6733997051219485\n",
      "[EPOCH #16, step #2052] loss: 1.673178852039956\n",
      "[EPOCH #16, step #2054] loss: 1.6731540594077747\n",
      "[EPOCH #16, step #2056] loss: 1.67295856144339\n",
      "[EPOCH #16, step #2058] loss: 1.6731170987897617\n",
      "[EPOCH #16, step #2060] loss: 1.6731464240459606\n",
      "[EPOCH #16, step #2062] loss: 1.6729214010571485\n",
      "[EPOCH #16, step #2064] loss: 1.6728971801138963\n",
      "[EPOCH #16, step #2066] loss: 1.6728313808920998\n",
      "[EPOCH #16, step #2068] loss: 1.6727392782964472\n",
      "[EPOCH #16, step #2070] loss: 1.6727671174252454\n",
      "[EPOCH #16, step #2072] loss: 1.6727482139115395\n",
      "[EPOCH #16, step #2074] loss: 1.6728854589002677\n",
      "[EPOCH #16, step #2076] loss: 1.6731082752569397\n",
      "[EPOCH #16, step #2078] loss: 1.67297982051431\n",
      "[EPOCH #16, step #2080] loss: 1.6731775898248287\n",
      "[EPOCH #16, step #2082] loss: 1.6733623827184787\n",
      "[EPOCH #16, step #2084] loss: 1.6731128299836633\n",
      "[EPOCH #16, step #2086] loss: 1.6726370300467528\n",
      "[EPOCH #16, step #2088] loss: 1.6725941467307983\n",
      "[EPOCH #16, step #2090] loss: 1.6728150568072275\n",
      "[EPOCH #16, step #2092] loss: 1.672811561945347\n",
      "[EPOCH #16, step #2094] loss: 1.6727761138879598\n",
      "[EPOCH #16, step #2096] loss: 1.6726926068891272\n",
      "[EPOCH #16, step #2098] loss: 1.6722978469926781\n",
      "[EPOCH #16, step #2100] loss: 1.672522056562341\n",
      "[EPOCH #16, step #2102] loss: 1.6725318607011976\n",
      "[EPOCH #16, step #2104] loss: 1.6725808489067822\n",
      "[EPOCH #16, step #2106] loss: 1.6726044863957503\n",
      "[EPOCH #16, step #2108] loss: 1.6724636991083932\n",
      "[EPOCH #16, step #2110] loss: 1.6724453972505202\n",
      "[EPOCH #16, step #2112] loss: 1.672206482275707\n",
      "[EPOCH #16, step #2114] loss: 1.6722303720230751\n",
      "[EPOCH #16, step #2116] loss: 1.672326691600023\n",
      "[EPOCH #16, step #2118] loss: 1.6722086809783006\n",
      "[EPOCH #16, step #2120] loss: 1.6723490720759693\n",
      "[EPOCH #16, step #2122] loss: 1.672345528050071\n",
      "[EPOCH #16, step #2124] loss: 1.6719850902557374\n",
      "[EPOCH #16, step #2126] loss: 1.6718613237745055\n",
      "[EPOCH #16, step #2128] loss: 1.6717897783483682\n",
      "[EPOCH #16, step #2130] loss: 1.6717821392079912\n",
      "[EPOCH #16, step #2132] loss: 1.6717908491397542\n",
      "[EPOCH #16, step #2134] loss: 1.6718855447456484\n",
      "[EPOCH #16, step #2136] loss: 1.6717737105386972\n",
      "[EPOCH #16, step #2138] loss: 1.6714372114914497\n",
      "[EPOCH #16, step #2140] loss: 1.6712224649414176\n",
      "[EPOCH #16, step #2142] loss: 1.6712704566500758\n",
      "[EPOCH #16, step #2144] loss: 1.6714169428898737\n",
      "[EPOCH #16, step #2146] loss: 1.671465108657805\n",
      "[EPOCH #16, step #2148] loss: 1.671294754080686\n",
      "[EPOCH #16, step #2150] loss: 1.6711737106479305\n",
      "[EPOCH #16, step #2152] loss: 1.6714182949819179\n",
      "[EPOCH #16, step #2154] loss: 1.6714792684170043\n",
      "[EPOCH #16, step #2156] loss: 1.6714701555810927\n",
      "[EPOCH #16, step #2158] loss: 1.6715522111152377\n",
      "[EPOCH #16, step #2160] loss: 1.6713191211251184\n",
      "[EPOCH #16, step #2162] loss: 1.6714002507955346\n",
      "[EPOCH #16, step #2164] loss: 1.6713604183174997\n",
      "[EPOCH #16, step #2166] loss: 1.6712845156805605\n",
      "[EPOCH #16, step #2168] loss: 1.6711290456447363\n",
      "[EPOCH #16, step #2170] loss: 1.6709154023930863\n",
      "[EPOCH #16, step #2172] loss: 1.670785468676866\n",
      "[EPOCH #16, step #2174] loss: 1.6703456484586343\n",
      "[EPOCH #16, step #2176] loss: 1.6702792225598084\n",
      "[EPOCH #16, step #2178] loss: 1.669926723355052\n",
      "[EPOCH #16, step #2180] loss: 1.6697130522450303\n",
      "[EPOCH #16, step #2182] loss: 1.6699532541287256\n",
      "[EPOCH #16, step #2184] loss: 1.6700387395492136\n",
      "[EPOCH #16, step #2186] loss: 1.6700931971728339\n",
      "[EPOCH #16, step #2188] loss: 1.6699479300445375\n",
      "[EPOCH #16, step #2190] loss: 1.6697776061331828\n",
      "[EPOCH #16, step #2192] loss: 1.6697160518718428\n",
      "[EPOCH #16, step #2194] loss: 1.6696216375789772\n",
      "[EPOCH #16, step #2196] loss: 1.669609872330087\n",
      "[EPOCH #16, step #2198] loss: 1.6695692006866192\n",
      "[EPOCH #16, step #2200] loss: 1.669601012608616\n",
      "[EPOCH #16, step #2202] loss: 1.669707418570343\n",
      "[EPOCH #16, step #2204] loss: 1.6695060957586414\n",
      "[EPOCH #16, step #2206] loss: 1.6693311269649511\n",
      "[EPOCH #16, step #2208] loss: 1.6693644716816285\n",
      "[EPOCH #16, step #2210] loss: 1.6695622141034503\n",
      "[EPOCH #16, step #2212] loss: 1.6694672971734945\n",
      "[EPOCH #16, step #2214] loss: 1.6694275576158786\n",
      "[EPOCH #16, step #2216] loss: 1.6692003323034923\n",
      "[EPOCH #16, step #2218] loss: 1.6689732079572537\n",
      "[EPOCH #16, step #2220] loss: 1.6694354952481993\n",
      "[EPOCH #16, step #2222] loss: 1.6692652799393537\n",
      "[EPOCH #16, step #2224] loss: 1.6691781382614308\n",
      "[EPOCH #16, step #2226] loss: 1.6691339748773972\n",
      "[EPOCH #16, step #2228] loss: 1.6690500586382633\n",
      "[EPOCH #16, step #2230] loss: 1.669088620821065\n",
      "[EPOCH #16, step #2232] loss: 1.668870160678978\n",
      "[EPOCH #16, step #2234] loss: 1.668959051597305\n",
      "[EPOCH #16, step #2236] loss: 1.6689942955277997\n",
      "[EPOCH #16, step #2238] loss: 1.6689984648288387\n",
      "[EPOCH #16, step #2240] loss: 1.6688507372436114\n",
      "[EPOCH #16, step #2242] loss: 1.6688757200513202\n",
      "[EPOCH #16, step #2244] loss: 1.6688332487055348\n",
      "[EPOCH #16, step #2246] loss: 1.6685896744237882\n",
      "[EPOCH #16, step #2248] loss: 1.6687107048017706\n",
      "[EPOCH #16, step #2250] loss: 1.668985797055082\n",
      "[EPOCH #16, step #2252] loss: 1.6691045838888094\n",
      "[EPOCH #16, step #2254] loss: 1.669007501210976\n",
      "[EPOCH #16, step #2256] loss: 1.6688986149941285\n",
      "[EPOCH #16, step #2258] loss: 1.6691874330578889\n",
      "[EPOCH #16, step #2260] loss: 1.6693272357596491\n",
      "[EPOCH #16, step #2262] loss: 1.6694301255656405\n",
      "[EPOCH #16, step #2264] loss: 1.6695208664235164\n",
      "[EPOCH #16, step #2266] loss: 1.669727150227564\n",
      "[EPOCH #16, step #2268] loss: 1.669553744524993\n",
      "[EPOCH #16, step #2270] loss: 1.6698006718550311\n",
      "[EPOCH #16, step #2272] loss: 1.6697387307213625\n",
      "[EPOCH #16, step #2274] loss: 1.6696571346953675\n",
      "[EPOCH #16, step #2276] loss: 1.6694119219514012\n",
      "[EPOCH #16, step #2278] loss: 1.6695519667437537\n",
      "[EPOCH #16, step #2280] loss: 1.669523107592655\n",
      "[EPOCH #16, step #2282] loss: 1.6699290883890956\n",
      "[EPOCH #16, step #2284] loss: 1.6698879806426734\n",
      "[EPOCH #16, step #2286] loss: 1.6697464390097094\n",
      "[EPOCH #16, step #2288] loss: 1.669812462380902\n",
      "[EPOCH #16, step #2290] loss: 1.6697079936576587\n",
      "[EPOCH #16, step #2292] loss: 1.6697025772166263\n",
      "[EPOCH #16, step #2294] loss: 1.6695781757628996\n",
      "[EPOCH #16, step #2296] loss: 1.6694316771116577\n",
      "[EPOCH #16, step #2298] loss: 1.6694231628075327\n",
      "[EPOCH #16, step #2300] loss: 1.6693016560582272\n",
      "[EPOCH #16, step #2302] loss: 1.6697451949274855\n",
      "[EPOCH #16, step #2304] loss: 1.6697859822540118\n",
      "[EPOCH #16, step #2306] loss: 1.6698221488075438\n",
      "[EPOCH #16, step #2308] loss: 1.6694995938260198\n",
      "[EPOCH #16, step #2310] loss: 1.66955078313589\n",
      "[EPOCH #16, step #2312] loss: 1.6692808403682255\n",
      "[EPOCH #16, step #2314] loss: 1.6690671037649234\n",
      "[EPOCH #16, step #2316] loss: 1.669094315931413\n",
      "[EPOCH #16, step #2318] loss: 1.66905787701543\n",
      "[EPOCH #16, step #2320] loss: 1.669233346180585\n",
      "[EPOCH #16, step #2322] loss: 1.6691910608852418\n",
      "[EPOCH #16, step #2324] loss: 1.669208800920876\n",
      "[EPOCH #16, step #2326] loss: 1.6694660856327275\n",
      "[EPOCH #16, step #2328] loss: 1.6694475151326535\n",
      "[EPOCH #16, step #2330] loss: 1.6696276189124108\n",
      "[EPOCH #16, step #2332] loss: 1.669608660639482\n",
      "[EPOCH #16, step #2334] loss: 1.6694787162784845\n",
      "[EPOCH #16, step #2336] loss: 1.669378933204664\n",
      "[EPOCH #16, step #2338] loss: 1.6693978927847972\n",
      "[EPOCH #16, step #2340] loss: 1.6692325720569101\n",
      "[EPOCH #16, step #2342] loss: 1.669171923711877\n",
      "[EPOCH #16, step #2344] loss: 1.6693640618944474\n",
      "[EPOCH #16, step #2346] loss: 1.6691738050645293\n",
      "[EPOCH #16, step #2348] loss: 1.6691284807452043\n",
      "[EPOCH #16, step #2350] loss: 1.6691022382194263\n",
      "[EPOCH #16, step #2352] loss: 1.6690638823758477\n",
      "[EPOCH #16, step #2354] loss: 1.6690831033034437\n",
      "[EPOCH #16, step #2356] loss: 1.6689472066481132\n",
      "[EPOCH #16, step #2358] loss: 1.6688363192798021\n",
      "[EPOCH #16, step #2360] loss: 1.668946057343473\n",
      "[EPOCH #16, step #2362] loss: 1.6689692953608575\n",
      "[EPOCH #16, step #2364] loss: 1.6689375700960705\n",
      "[EPOCH #16, step #2366] loss: 1.6687331194609694\n",
      "[EPOCH #16, step #2368] loss: 1.6687050930001455\n",
      "[EPOCH #16, step #2370] loss: 1.6684726171984243\n",
      "[EPOCH #16, step #2372] loss: 1.668201260912333\n",
      "[EPOCH #16, step #2374] loss: 1.6683878829855667\n",
      "[EPOCH #16, step #2376] loss: 1.6681346215266966\n",
      "[EPOCH #16, step #2378] loss: 1.6678815207695852\n",
      "[EPOCH #16, step #2380] loss: 1.667851420021618\n",
      "[EPOCH #16, step #2382] loss: 1.66775007163883\n",
      "[EPOCH #16, step #2384] loss: 1.6675914907355478\n",
      "[EPOCH #16, step #2386] loss: 1.6676820305835067\n",
      "[EPOCH #16, step #2388] loss: 1.6674929141199903\n",
      "[EPOCH #16, step #2390] loss: 1.6674519309634597\n",
      "[EPOCH #16, step #2392] loss: 1.6673715685482957\n",
      "[EPOCH #16, step #2394] loss: 1.667285971999915\n",
      "[EPOCH #16, step #2396] loss: 1.6670639101644331\n",
      "[EPOCH #16, step #2398] loss: 1.6671237884933325\n",
      "[EPOCH #16, step #2400] loss: 1.6669117962504765\n",
      "[EPOCH #16, step #2402] loss: 1.666712284385786\n",
      "[EPOCH #16, step #2404] loss: 1.6666566525576267\n",
      "[EPOCH #16, step #2406] loss: 1.6666654144821198\n",
      "[EPOCH #16, step #2408] loss: 1.6665055892337848\n",
      "[EPOCH #16, step #2410] loss: 1.6667649452244282\n",
      "[EPOCH #16, step #2412] loss: 1.6667723622106685\n",
      "[EPOCH #16, step #2414] loss: 1.6667311786371235\n",
      "[EPOCH #16, step #2416] loss: 1.6669476770595129\n",
      "[EPOCH #16, step #2418] loss: 1.666973916298597\n",
      "[EPOCH #16, step #2420] loss: 1.6668605899475961\n",
      "[EPOCH #16, step #2422] loss: 1.6669233255134452\n",
      "[EPOCH #16, step #2424] loss: 1.6670073836120134\n",
      "[EPOCH #16, step #2426] loss: 1.6669671902894285\n",
      "[EPOCH #16, step #2428] loss: 1.6669899770976977\n",
      "[EPOCH #16, step #2430] loss: 1.6671124416729493\n",
      "[EPOCH #16, step #2432] loss: 1.6669570632888318\n",
      "[EPOCH #16, step #2434] loss: 1.6669601104097935\n",
      "[EPOCH #16, step #2436] loss: 1.666949823199113\n",
      "[EPOCH #16, step #2438] loss: 1.6670386403151447\n",
      "[EPOCH #16, step #2440] loss: 1.667040637065914\n",
      "[EPOCH #16, step #2442] loss: 1.6670862139125266\n",
      "[EPOCH #16, step #2444] loss: 1.667135692569132\n",
      "[EPOCH #16, step #2446] loss: 1.667351526584633\n",
      "[EPOCH #16, step #2448] loss: 1.6670503407509876\n",
      "[EPOCH #16, step #2450] loss: 1.6668786560453137\n",
      "[EPOCH #16, step #2452] loss: 1.6671208522779524\n",
      "[EPOCH #16, step #2454] loss: 1.6670437956536133\n",
      "[EPOCH #16, step #2456] loss: 1.6669728948083116\n",
      "[EPOCH #16, step #2458] loss: 1.6668194577479662\n",
      "[EPOCH #16, step #2460] loss: 1.666735978157527\n",
      "[EPOCH #16, step #2462] loss: 1.6666009769757202\n",
      "[EPOCH #16, step #2464] loss: 1.6664482917553514\n",
      "[EPOCH #16, step #2466] loss: 1.6665219175801085\n",
      "[EPOCH #16, step #2468] loss: 1.6666753487144708\n",
      "[EPOCH #16, step #2470] loss: 1.6666597341632419\n",
      "[EPOCH #16, step #2472] loss: 1.6666666252912898\n",
      "[EPOCH #16, step #2474] loss: 1.6664710244747123\n",
      "[EPOCH #16, step #2476] loss: 1.666328409673901\n",
      "[EPOCH #16, step #2478] loss: 1.6663959480764983\n",
      "[EPOCH #16, step #2480] loss: 1.6666522430633643\n",
      "[EPOCH #16, step #2482] loss: 1.666530255967938\n",
      "[EPOCH #16, step #2484] loss: 1.6664817334180866\n",
      "[EPOCH #16, step #2486] loss: 1.6664946977517956\n",
      "[EPOCH #16, step #2488] loss: 1.6666003768345399\n",
      "[EPOCH #16, step #2490] loss: 1.6670335036403727\n",
      "[EPOCH #16, step #2492] loss: 1.6669909691552394\n",
      "[EPOCH #16, step #2494] loss: 1.6668534802530477\n",
      "[EPOCH #16, step #2496] loss: 1.6671782206381422\n",
      "[EPOCH #16, step #2498] loss: 1.6672565603599685\n",
      "[EPOCH #16, elapsed time: 8148.295[sec]] loss: 1.6672781621456145\n",
      "[EPOCH #17, step #0] loss: 1.1768500804901123\n",
      "[EPOCH #17, step #2] loss: 1.3764240741729736\n",
      "[EPOCH #17, step #4] loss: 1.4960321187973022\n",
      "[EPOCH #17, step #6] loss: 1.4958384037017822\n",
      "[EPOCH #17, step #8] loss: 1.524163219663832\n",
      "[EPOCH #17, step #10] loss: 1.5969962748614224\n",
      "[EPOCH #17, step #12] loss: 1.6524691581726074\n",
      "[EPOCH #17, step #14] loss: 1.6603965044021607\n",
      "[EPOCH #17, step #16] loss: 1.6765346807592056\n",
      "[EPOCH #17, step #18] loss: 1.6789236633401168\n",
      "[EPOCH #17, step #20] loss: 1.6879009235472906\n",
      "[EPOCH #17, step #22] loss: 1.6895441697991413\n",
      "[EPOCH #17, step #24] loss: 1.6766003847122193\n",
      "[EPOCH #17, step #26] loss: 1.67861329626154\n",
      "[EPOCH #17, step #28] loss: 1.6932429034134437\n",
      "[EPOCH #17, step #30] loss: 1.695940867547066\n",
      "[EPOCH #17, step #32] loss: 1.681687719894178\n",
      "[EPOCH #17, step #34] loss: 1.680127647944859\n",
      "[EPOCH #17, step #36] loss: 1.695346348994487\n",
      "[EPOCH #17, step #38] loss: 1.6976938431079571\n",
      "[EPOCH #17, step #40] loss: 1.6999295455653494\n",
      "[EPOCH #17, step #42] loss: 1.6986482947371726\n",
      "[EPOCH #17, step #44] loss: 1.7020876275168524\n",
      "[EPOCH #17, step #46] loss: 1.7066226588918807\n",
      "[EPOCH #17, step #48] loss: 1.7106580490968666\n",
      "[EPOCH #17, step #50] loss: 1.7183791983361338\n",
      "[EPOCH #17, step #52] loss: 1.7162643333650984\n",
      "[EPOCH #17, step #54] loss: 1.7090858719565651\n",
      "[EPOCH #17, step #56] loss: 1.701922847513567\n",
      "[EPOCH #17, step #58] loss: 1.6927748494229073\n",
      "[EPOCH #17, step #60] loss: 1.695084499531105\n",
      "[EPOCH #17, step #62] loss: 1.6959077668568445\n",
      "[EPOCH #17, step #64] loss: 1.6849298550532414\n",
      "[EPOCH #17, step #66] loss: 1.6899151784270556\n",
      "[EPOCH #17, step #68] loss: 1.686539473740951\n",
      "[EPOCH #17, step #70] loss: 1.6777332416722472\n",
      "[EPOCH #17, step #72] loss: 1.668062247642099\n",
      "[EPOCH #17, step #74] loss: 1.6609365336100261\n",
      "[EPOCH #17, step #76] loss: 1.661154801195318\n",
      "[EPOCH #17, step #78] loss: 1.6604474571686756\n",
      "[EPOCH #17, step #80] loss: 1.6544124785764718\n",
      "[EPOCH #17, step #82] loss: 1.6473265512880073\n",
      "[EPOCH #17, step #84] loss: 1.6413740087957944\n",
      "[EPOCH #17, step #86] loss: 1.6433763832881534\n",
      "[EPOCH #17, step #88] loss: 1.6442345943343772\n",
      "[EPOCH #17, step #90] loss: 1.6495082666585734\n",
      "[EPOCH #17, step #92] loss: 1.6465864066154725\n",
      "[EPOCH #17, step #94] loss: 1.6448382703881514\n",
      "[EPOCH #17, step #96] loss: 1.6361900887538476\n",
      "[EPOCH #17, step #98] loss: 1.6377788854367805\n",
      "[EPOCH #17, step #100] loss: 1.641494645930753\n",
      "[EPOCH #17, step #102] loss: 1.6437861988845381\n",
      "[EPOCH #17, step #104] loss: 1.6392785038266864\n",
      "[EPOCH #17, step #106] loss: 1.630465985458588\n",
      "[EPOCH #17, step #108] loss: 1.6306107394192197\n",
      "[EPOCH #17, step #110] loss: 1.6334737496333078\n",
      "[EPOCH #17, step #112] loss: 1.6290076253688441\n",
      "[EPOCH #17, step #114] loss: 1.6332695753678033\n",
      "[EPOCH #17, step #116] loss: 1.638658863866431\n",
      "[EPOCH #17, step #118] loss: 1.6403938541893197\n",
      "[EPOCH #17, step #120] loss: 1.6419594829732722\n",
      "[EPOCH #17, step #122] loss: 1.6424493566761171\n",
      "[EPOCH #17, step #124] loss: 1.637669695854187\n",
      "[EPOCH #17, step #126] loss: 1.6373589376764974\n",
      "[EPOCH #17, step #128] loss: 1.6362086137135823\n",
      "[EPOCH #17, step #130] loss: 1.6323160861284678\n",
      "[EPOCH #17, step #132] loss: 1.6326487082287782\n",
      "[EPOCH #17, step #134] loss: 1.633385052504363\n",
      "[EPOCH #17, step #136] loss: 1.6332051371135852\n",
      "[EPOCH #17, step #138] loss: 1.6296321479536646\n",
      "[EPOCH #17, step #140] loss: 1.6282249536920101\n",
      "[EPOCH #17, step #142] loss: 1.6294875003241158\n",
      "[EPOCH #17, step #144] loss: 1.6293416335664948\n",
      "[EPOCH #17, step #146] loss: 1.6288315082082943\n",
      "[EPOCH #17, step #148] loss: 1.6253880734411663\n",
      "[EPOCH #17, step #150] loss: 1.6246273596555192\n",
      "[EPOCH #17, step #152] loss: 1.6263435697243884\n",
      "[EPOCH #17, step #154] loss: 1.6274008581715245\n",
      "[EPOCH #17, step #156] loss: 1.625917039859067\n",
      "[EPOCH #17, step #158] loss: 1.6246278945754908\n",
      "[EPOCH #17, step #160] loss: 1.621377574731104\n",
      "[EPOCH #17, step #162] loss: 1.6196624867023866\n",
      "[EPOCH #17, step #164] loss: 1.6193223331913804\n",
      "[EPOCH #17, step #166] loss: 1.6169499822719369\n",
      "[EPOCH #17, step #168] loss: 1.6148593806656155\n",
      "[EPOCH #17, step #170] loss: 1.611737588692827\n",
      "[EPOCH #17, step #172] loss: 1.6114124025223573\n",
      "[EPOCH #17, step #174] loss: 1.6095480932508197\n",
      "[EPOCH #17, step #176] loss: 1.6095226417153567\n",
      "[EPOCH #17, step #178] loss: 1.6087702732512406\n",
      "[EPOCH #17, step #180] loss: 1.611608062001223\n",
      "[EPOCH #17, step #182] loss: 1.6157866501417317\n",
      "[EPOCH #17, step #184] loss: 1.6207030856931532\n",
      "[EPOCH #17, step #186] loss: 1.6196236623162255\n",
      "[EPOCH #17, step #188] loss: 1.6170577794786483\n",
      "[EPOCH #17, step #190] loss: 1.6168459235685657\n",
      "[EPOCH #17, step #192] loss: 1.6125294136877504\n",
      "[EPOCH #17, step #194] loss: 1.6110270060025729\n",
      "[EPOCH #17, step #196] loss: 1.6138280896365944\n",
      "[EPOCH #17, step #198] loss: 1.6154515120252293\n",
      "[EPOCH #17, step #200] loss: 1.6113982034559866\n",
      "[EPOCH #17, step #202] loss: 1.6126162547783311\n",
      "[EPOCH #17, step #204] loss: 1.6153045619406352\n",
      "[EPOCH #17, step #206] loss: 1.613236165277048\n",
      "[EPOCH #17, step #208] loss: 1.6147378352270172\n",
      "[EPOCH #17, step #210] loss: 1.6146938569172864\n",
      "[EPOCH #17, step #212] loss: 1.6132206379527776\n",
      "[EPOCH #17, step #214] loss: 1.6125082526096077\n",
      "[EPOCH #17, step #216] loss: 1.61084844165134\n",
      "[EPOCH #17, step #218] loss: 1.6114919441475717\n",
      "[EPOCH #17, step #220] loss: 1.6098839281910684\n",
      "[EPOCH #17, step #222] loss: 1.6098727367384016\n",
      "[EPOCH #17, step #224] loss: 1.6109280204772949\n",
      "[EPOCH #17, step #226] loss: 1.6095957425197316\n",
      "[EPOCH #17, step #228] loss: 1.6099842318280815\n",
      "[EPOCH #17, step #230] loss: 1.6094958807998923\n",
      "[EPOCH #17, step #232] loss: 1.6080710928839164\n",
      "[EPOCH #17, step #234] loss: 1.6072249077736063\n",
      "[EPOCH #17, step #236] loss: 1.6081745493764112\n",
      "[EPOCH #17, step #238] loss: 1.6089527477280365\n",
      "[EPOCH #17, step #240] loss: 1.605886116562048\n",
      "[EPOCH #17, step #242] loss: 1.605710980332928\n",
      "[EPOCH #17, step #244] loss: 1.6060818968986978\n",
      "[EPOCH #17, step #246] loss: 1.6060769244244224\n",
      "[EPOCH #17, step #248] loss: 1.6037204265594482\n",
      "[EPOCH #17, step #250] loss: 1.6058227450724143\n",
      "[EPOCH #17, step #252] loss: 1.605895556480046\n",
      "[EPOCH #17, step #254] loss: 1.6059484654781866\n",
      "[EPOCH #17, step #256] loss: 1.6079525632153224\n",
      "[EPOCH #17, step #258] loss: 1.6084714805757678\n",
      "[EPOCH #17, step #260] loss: 1.6100827510329498\n",
      "[EPOCH #17, step #262] loss: 1.610653441215196\n",
      "[EPOCH #17, step #264] loss: 1.609379459327122\n",
      "[EPOCH #17, step #266] loss: 1.6078261547767267\n",
      "[EPOCH #17, step #268] loss: 1.6080507975085516\n",
      "[EPOCH #17, step #270] loss: 1.6063500062126075\n",
      "[EPOCH #17, step #272] loss: 1.6069385712836688\n",
      "[EPOCH #17, step #274] loss: 1.6068928029320457\n",
      "[EPOCH #17, step #276] loss: 1.6072136495087552\n",
      "[EPOCH #17, step #278] loss: 1.605932498918212\n",
      "[EPOCH #17, step #280] loss: 1.604864343629613\n",
      "[EPOCH #17, step #282] loss: 1.6042974492265143\n",
      "[EPOCH #17, step #284] loss: 1.6043497943041618\n",
      "[EPOCH #17, step #286] loss: 1.6049828483667938\n",
      "[EPOCH #17, step #288] loss: 1.6052298533462737\n",
      "[EPOCH #17, step #290] loss: 1.6040584545364904\n",
      "[EPOCH #17, step #292] loss: 1.6030552517431995\n",
      "[EPOCH #17, step #294] loss: 1.6005319158909685\n",
      "[EPOCH #17, step #296] loss: 1.5998470590572165\n",
      "[EPOCH #17, step #298] loss: 1.601114346430852\n",
      "[EPOCH #17, step #300] loss: 1.598542217796427\n",
      "[EPOCH #17, step #302] loss: 1.5978713511633795\n",
      "[EPOCH #17, step #304] loss: 1.5995764107000632\n",
      "[EPOCH #17, step #306] loss: 1.5982998326081017\n",
      "[EPOCH #17, step #308] loss: 1.5990335906593545\n",
      "[EPOCH #17, step #310] loss: 1.5974533607722095\n",
      "[EPOCH #17, step #312] loss: 1.5982073602584985\n",
      "[EPOCH #17, step #314] loss: 1.5970350655298384\n",
      "[EPOCH #17, step #316] loss: 1.5977823899747445\n",
      "[EPOCH #17, step #318] loss: 1.5962342180802156\n",
      "[EPOCH #17, step #320] loss: 1.5956817453152665\n",
      "[EPOCH #17, step #322] loss: 1.597355418160973\n",
      "[EPOCH #17, step #324] loss: 1.595894227027893\n",
      "[EPOCH #17, step #326] loss: 1.5961734205940084\n",
      "[EPOCH #17, step #328] loss: 1.595272700837318\n",
      "[EPOCH #17, step #330] loss: 1.5942797988563147\n",
      "[EPOCH #17, step #332] loss: 1.5927925374772813\n",
      "[EPOCH #17, step #334] loss: 1.593774915809062\n",
      "[EPOCH #17, step #336] loss: 1.5947336223783408\n",
      "[EPOCH #17, step #338] loss: 1.5953438127287018\n",
      "[EPOCH #17, step #340] loss: 1.5944649938963724\n",
      "[EPOCH #17, step #342] loss: 1.5953770604842605\n",
      "[EPOCH #17, step #344] loss: 1.5930796485016312\n",
      "[EPOCH #17, step #346] loss: 1.5927506778013465\n",
      "[EPOCH #17, step #348] loss: 1.5924850924308798\n",
      "[EPOCH #17, step #350] loss: 1.592848532559865\n",
      "[EPOCH #17, step #352] loss: 1.5932861880607714\n",
      "[EPOCH #17, step #354] loss: 1.5951871331308929\n",
      "[EPOCH #17, step #356] loss: 1.5957700628526403\n",
      "[EPOCH #17, step #358] loss: 1.5952421134560886\n",
      "[EPOCH #17, step #360] loss: 1.5935835481680662\n",
      "[EPOCH #17, step #362] loss: 1.594164158030318\n",
      "[EPOCH #17, step #364] loss: 1.5965567448367812\n",
      "[EPOCH #17, step #366] loss: 1.5959567325316593\n",
      "[EPOCH #17, step #368] loss: 1.595467044732112\n",
      "[EPOCH #17, step #370] loss: 1.594825514564617\n",
      "[EPOCH #17, step #372] loss: 1.5951624843454233\n",
      "[EPOCH #17, step #374] loss: 1.595323481877645\n",
      "[EPOCH #17, step #376] loss: 1.5941423218825768\n",
      "[EPOCH #17, step #378] loss: 1.594698236611399\n",
      "[EPOCH #17, step #380] loss: 1.5939392198727826\n",
      "[EPOCH #17, step #382] loss: 1.5939534270732272\n",
      "[EPOCH #17, step #384] loss: 1.5936002901622228\n",
      "[EPOCH #17, step #386] loss: 1.5957201254152205\n",
      "[EPOCH #17, step #388] loss: 1.5943097164207989\n",
      "[EPOCH #17, step #390] loss: 1.5938107098459893\n",
      "[EPOCH #17, step #392] loss: 1.593458892128243\n",
      "[EPOCH #17, step #394] loss: 1.5923760761188555\n",
      "[EPOCH #17, step #396] loss: 1.5941307808950507\n",
      "[EPOCH #17, step #398] loss: 1.5949003765158785\n",
      "[EPOCH #17, step #400] loss: 1.596325633829074\n",
      "[EPOCH #17, step #402] loss: 1.5959699218977177\n",
      "[EPOCH #17, step #404] loss: 1.5953149927986994\n",
      "[EPOCH #17, step #406] loss: 1.5948574194451222\n",
      "[EPOCH #17, step #408] loss: 1.5958269065050157\n",
      "[EPOCH #17, step #410] loss: 1.595491400310303\n",
      "[EPOCH #17, step #412] loss: 1.594338942093653\n",
      "[EPOCH #17, step #414] loss: 1.5948158042976655\n",
      "[EPOCH #17, step #416] loss: 1.593595610248099\n",
      "[EPOCH #17, step #418] loss: 1.593962171197222\n",
      "[EPOCH #17, step #420] loss: 1.5924489339570251\n",
      "[EPOCH #17, step #422] loss: 1.591696091013879\n",
      "[EPOCH #17, step #424] loss: 1.5921910207411822\n",
      "[EPOCH #17, step #426] loss: 1.5920132420939639\n",
      "[EPOCH #17, step #428] loss: 1.59214398549709\n",
      "[EPOCH #17, step #430] loss: 1.5915708411873908\n",
      "[EPOCH #17, step #432] loss: 1.5913376678770739\n",
      "[EPOCH #17, step #434] loss: 1.5922295373061608\n",
      "[EPOCH #17, step #436] loss: 1.5912196617104641\n",
      "[EPOCH #17, step #438] loss: 1.5916298950994747\n",
      "[EPOCH #17, step #440] loss: 1.590542238585803\n",
      "[EPOCH #17, step #442] loss: 1.5907452539719524\n",
      "[EPOCH #17, step #444] loss: 1.5906870568736216\n",
      "[EPOCH #17, step #446] loss: 1.5907441825674684\n",
      "[EPOCH #17, step #448] loss: 1.5898376517412658\n",
      "[EPOCH #17, step #450] loss: 1.5895694898660326\n",
      "[EPOCH #17, step #452] loss: 1.5896283693397808\n",
      "[EPOCH #17, step #454] loss: 1.5899098674019614\n",
      "[EPOCH #17, step #456] loss: 1.5906958999988547\n",
      "[EPOCH #17, step #458] loss: 1.5905380716510849\n",
      "[EPOCH #17, step #460] loss: 1.589390036340908\n",
      "[EPOCH #17, step #462] loss: 1.5896856272452335\n",
      "[EPOCH #17, step #464] loss: 1.5898875500566216\n",
      "[EPOCH #17, step #466] loss: 1.590559331201639\n",
      "[EPOCH #17, step #468] loss: 1.5917109525534137\n",
      "[EPOCH #17, step #470] loss: 1.5909780165192429\n",
      "[EPOCH #17, step #472] loss: 1.5906578476282809\n",
      "[EPOCH #17, step #474] loss: 1.5926774516858553\n",
      "[EPOCH #17, step #476] loss: 1.5935966943544912\n",
      "[EPOCH #17, step #478] loss: 1.5934024994457938\n",
      "[EPOCH #17, step #480] loss: 1.5923467247500984\n",
      "[EPOCH #17, step #482] loss: 1.592433246026128\n",
      "[EPOCH #17, step #484] loss: 1.591620504487421\n",
      "[EPOCH #17, step #486] loss: 1.5925887610143705\n",
      "[EPOCH #17, step #488] loss: 1.5945319127451423\n",
      "[EPOCH #17, step #490] loss: 1.5955766640952551\n",
      "[EPOCH #17, step #492] loss: 1.5957722015845124\n",
      "[EPOCH #17, step #494] loss: 1.597253473599752\n",
      "[EPOCH #17, step #496] loss: 1.5969447744204486\n",
      "[EPOCH #17, step #498] loss: 1.5967346257819441\n",
      "[EPOCH #17, step #500] loss: 1.5968393779800323\n",
      "[EPOCH #17, step #502] loss: 1.595508886141995\n",
      "[EPOCH #17, step #504] loss: 1.5950112352276793\n",
      "[EPOCH #17, step #506] loss: 1.596880446054056\n",
      "[EPOCH #17, step #508] loss: 1.5956633037106227\n",
      "[EPOCH #17, step #510] loss: 1.5961750839087827\n",
      "[EPOCH #17, step #512] loss: 1.5972100856476128\n",
      "[EPOCH #17, step #514] loss: 1.597308921351016\n",
      "[EPOCH #17, step #516] loss: 1.5985809025035835\n",
      "[EPOCH #17, step #518] loss: 1.5976171757674171\n",
      "[EPOCH #17, step #520] loss: 1.5972181281750581\n",
      "[EPOCH #17, step #522] loss: 1.5971442096319983\n",
      "[EPOCH #17, step #524] loss: 1.5978233078547885\n",
      "[EPOCH #17, step #526] loss: 1.5985453232868347\n",
      "[EPOCH #17, step #528] loss: 1.5988137972152074\n",
      "[EPOCH #17, step #530] loss: 1.5982254132937128\n",
      "[EPOCH #17, step #532] loss: 1.5981661911082312\n",
      "[EPOCH #17, step #534] loss: 1.59741070404231\n",
      "[EPOCH #17, step #536] loss: 1.5973722630594918\n",
      "[EPOCH #17, step #538] loss: 1.5972602548758483\n",
      "[EPOCH #17, step #540] loss: 1.5956785987353368\n",
      "[EPOCH #17, step #542] loss: 1.5971528473919048\n",
      "[EPOCH #17, step #544] loss: 1.5974710460102886\n",
      "[EPOCH #17, step #546] loss: 1.5981339026630688\n",
      "[EPOCH #17, step #548] loss: 1.5978914023748512\n",
      "[EPOCH #17, step #550] loss: 1.5977440765245856\n",
      "[EPOCH #17, step #552] loss: 1.5978258253221702\n",
      "[EPOCH #17, step #554] loss: 1.5973133856111819\n",
      "[EPOCH #17, step #556] loss: 1.5967576841905686\n",
      "[EPOCH #17, step #558] loss: 1.5968873067917253\n",
      "[EPOCH #17, step #560] loss: 1.5966893627894327\n",
      "[EPOCH #17, step #562] loss: 1.5961355102210444\n",
      "[EPOCH #17, step #564] loss: 1.5963986523383487\n",
      "[EPOCH #17, step #566] loss: 1.594789338280074\n",
      "[EPOCH #17, step #568] loss: 1.5953473866719143\n",
      "[EPOCH #17, step #570] loss: 1.595167812866839\n",
      "[EPOCH #17, step #572] loss: 1.5943030189677267\n",
      "[EPOCH #17, step #574] loss: 1.5952014558211618\n",
      "[EPOCH #17, step #576] loss: 1.5960069973299367\n",
      "[EPOCH #17, step #578] loss: 1.5957695735756803\n",
      "[EPOCH #17, step #580] loss: 1.596458668142506\n",
      "[EPOCH #17, step #582] loss: 1.5970654986530388\n",
      "[EPOCH #17, step #584] loss: 1.59625973823743\n",
      "[EPOCH #17, step #586] loss: 1.5964914808078357\n",
      "[EPOCH #17, step #588] loss: 1.595295902626219\n",
      "[EPOCH #17, step #590] loss: 1.5960265101515096\n",
      "[EPOCH #17, step #592] loss: 1.5961683083947553\n",
      "[EPOCH #17, step #594] loss: 1.5958050677756301\n",
      "[EPOCH #17, step #596] loss: 1.5956076627200972\n",
      "[EPOCH #17, step #598] loss: 1.5947399386181458\n",
      "[EPOCH #17, step #600] loss: 1.5943698605364451\n",
      "[EPOCH #17, step #602] loss: 1.5940851771811744\n",
      "[EPOCH #17, step #604] loss: 1.5937813835695755\n",
      "[EPOCH #17, step #606] loss: 1.5930934244954016\n",
      "[EPOCH #17, step #608] loss: 1.5931817295124573\n",
      "[EPOCH #17, step #610] loss: 1.5937114407700135\n",
      "[EPOCH #17, step #612] loss: 1.5934058206116395\n",
      "[EPOCH #17, step #614] loss: 1.5926583867732103\n",
      "[EPOCH #17, step #616] loss: 1.591919119972464\n",
      "[EPOCH #17, step #618] loss: 1.5929091221296345\n",
      "[EPOCH #17, step #620] loss: 1.5923778348498874\n",
      "[EPOCH #17, step #622] loss: 1.5922667438681588\n",
      "[EPOCH #17, step #624] loss: 1.5925124691009522\n",
      "[EPOCH #17, step #626] loss: 1.5921891093063962\n",
      "[EPOCH #17, step #628] loss: 1.5916761476398462\n",
      "[EPOCH #17, step #630] loss: 1.5916930777146208\n",
      "[EPOCH #17, step #632] loss: 1.5914473156981748\n",
      "[EPOCH #17, step #634] loss: 1.5912566598006121\n",
      "[EPOCH #17, step #636] loss: 1.590568725692234\n",
      "[EPOCH #17, step #638] loss: 1.5904441064512227\n",
      "[EPOCH #17, step #640] loss: 1.590461243519359\n",
      "[EPOCH #17, step #642] loss: 1.5902745779343008\n",
      "[EPOCH #17, step #644] loss: 1.5904422946678576\n",
      "[EPOCH #17, step #646] loss: 1.5906446858941128\n",
      "[EPOCH #17, step #648] loss: 1.5896335414084153\n",
      "[EPOCH #17, step #650] loss: 1.5887121782507947\n",
      "[EPOCH #17, step #652] loss: 1.5882373281496407\n",
      "[EPOCH #17, step #654] loss: 1.5880955075489656\n",
      "[EPOCH #17, step #656] loss: 1.5879210230059457\n",
      "[EPOCH #17, step #658] loss: 1.5881170133900389\n",
      "[EPOCH #17, step #660] loss: 1.588212956639173\n",
      "[EPOCH #17, step #662] loss: 1.5877609161230235\n",
      "[EPOCH #17, step #664] loss: 1.5869242451244727\n",
      "[EPOCH #17, step #666] loss: 1.5873531639307872\n",
      "[EPOCH #17, step #668] loss: 1.586902331521871\n",
      "[EPOCH #17, step #670] loss: 1.5869418126815478\n",
      "[EPOCH #17, step #672] loss: 1.5873470334737474\n",
      "[EPOCH #17, step #674] loss: 1.588578504456414\n",
      "[EPOCH #17, step #676] loss: 1.5884449237206486\n",
      "[EPOCH #17, step #678] loss: 1.5893587130334486\n",
      "[EPOCH #17, step #680] loss: 1.5896599462553969\n",
      "[EPOCH #17, step #682] loss: 1.5893776212569386\n",
      "[EPOCH #17, step #684] loss: 1.589629381416488\n",
      "[EPOCH #17, step #686] loss: 1.589028231615236\n",
      "[EPOCH #17, step #688] loss: 1.5891213692151582\n",
      "[EPOCH #17, step #690] loss: 1.5900662523275173\n",
      "[EPOCH #17, step #692] loss: 1.5894122065231742\n",
      "[EPOCH #17, step #694] loss: 1.5891209893947025\n",
      "[EPOCH #17, step #696] loss: 1.5885084034551678\n",
      "[EPOCH #17, step #698] loss: 1.588017999017358\n",
      "[EPOCH #17, step #700] loss: 1.587448601715915\n",
      "[EPOCH #17, step #702] loss: 1.5869216893509475\n",
      "[EPOCH #17, step #704] loss: 1.5862799433106227\n",
      "[EPOCH #17, step #706] loss: 1.586031670786198\n",
      "[EPOCH #17, step #708] loss: 1.5860492673680207\n",
      "[EPOCH #17, step #710] loss: 1.5857991332243264\n",
      "[EPOCH #17, step #712] loss: 1.58677474763584\n",
      "[EPOCH #17, step #714] loss: 1.587396948654335\n",
      "[EPOCH #17, step #716] loss: 1.586831837684706\n",
      "[EPOCH #17, step #718] loss: 1.587789234100363\n",
      "[EPOCH #17, step #720] loss: 1.587036004013559\n",
      "[EPOCH #17, step #722] loss: 1.5867686957574318\n",
      "[EPOCH #17, step #724] loss: 1.5874035683993635\n",
      "[EPOCH #17, step #726] loss: 1.5869681154681368\n",
      "[EPOCH #17, step #728] loss: 1.5870083626078644\n",
      "[EPOCH #17, step #730] loss: 1.58696233508688\n",
      "[EPOCH #17, step #732] loss: 1.5869818394050754\n",
      "[EPOCH #17, step #734] loss: 1.5869437958918462\n",
      "[EPOCH #17, step #736] loss: 1.5873918610964894\n",
      "[EPOCH #17, step #738] loss: 1.5870034367209036\n",
      "[EPOCH #17, step #740] loss: 1.5872528226430278\n",
      "[EPOCH #17, step #742] loss: 1.5871057200720622\n",
      "[EPOCH #17, step #744] loss: 1.5863148673268772\n",
      "[EPOCH #17, step #746] loss: 1.5874538704094638\n",
      "[EPOCH #17, step #748] loss: 1.587284525819073\n",
      "[EPOCH #17, step #750] loss: 1.58686907504116\n",
      "[EPOCH #17, step #752] loss: 1.5866312500965072\n",
      "[EPOCH #17, step #754] loss: 1.5864593142705248\n",
      "[EPOCH #17, step #756] loss: 1.5856839514471581\n",
      "[EPOCH #17, step #758] loss: 1.5859672000756848\n",
      "[EPOCH #17, step #760] loss: 1.5863476040798794\n",
      "[EPOCH #17, step #762] loss: 1.5867314151198961\n",
      "[EPOCH #17, step #764] loss: 1.587156611330369\n",
      "[EPOCH #17, step #766] loss: 1.5879292741437312\n",
      "[EPOCH #17, step #768] loss: 1.5873321446702757\n",
      "[EPOCH #17, step #770] loss: 1.5881430045176108\n",
      "[EPOCH #17, step #772] loss: 1.587698126672002\n",
      "[EPOCH #17, step #774] loss: 1.5872553570039811\n",
      "[EPOCH #17, step #776] loss: 1.586116233080664\n",
      "[EPOCH #17, step #778] loss: 1.586250340066305\n",
      "[EPOCH #17, step #780] loss: 1.5862856242476597\n",
      "[EPOCH #17, step #782] loss: 1.5863502981714515\n",
      "[EPOCH #17, step #784] loss: 1.585900190833268\n",
      "[EPOCH #17, step #786] loss: 1.5861419596847768\n",
      "[EPOCH #17, step #788] loss: 1.5859185436077141\n",
      "[EPOCH #17, step #790] loss: 1.5866539469259577\n",
      "[EPOCH #17, step #792] loss: 1.5870165658027198\n",
      "[EPOCH #17, step #794] loss: 1.5877094106854133\n",
      "[EPOCH #17, step #796] loss: 1.5872261253474198\n",
      "[EPOCH #17, step #798] loss: 1.5870120644718595\n",
      "[EPOCH #17, step #800] loss: 1.5864515801642867\n",
      "[EPOCH #17, step #802] loss: 1.5869504088631008\n",
      "[EPOCH #17, step #804] loss: 1.58650636998763\n",
      "[EPOCH #17, step #806] loss: 1.5866003516586\n",
      "[EPOCH #17, step #808] loss: 1.5866070243130508\n",
      "[EPOCH #17, step #810] loss: 1.5864254246510647\n",
      "[EPOCH #17, step #812] loss: 1.5869467123554788\n",
      "[EPOCH #17, step #814] loss: 1.586689189606649\n",
      "[EPOCH #17, step #816] loss: 1.5867652278781084\n",
      "[EPOCH #17, step #818] loss: 1.5870586399339204\n",
      "[EPOCH #17, step #820] loss: 1.5871978206843609\n",
      "[EPOCH #17, step #822] loss: 1.587576581380202\n",
      "[EPOCH #17, step #824] loss: 1.5875481741356128\n",
      "[EPOCH #17, step #826] loss: 1.587975540501319\n",
      "[EPOCH #17, step #828] loss: 1.5882910825087453\n",
      "[EPOCH #17, step #830] loss: 1.588419951112979\n",
      "[EPOCH #17, step #832] loss: 1.5880059938327749\n",
      "[EPOCH #17, step #834] loss: 1.5878172506115393\n",
      "[EPOCH #17, step #836] loss: 1.5877640137678122\n",
      "[EPOCH #17, step #838] loss: 1.587334601472757\n",
      "[EPOCH #17, step #840] loss: 1.5871123546085517\n",
      "[EPOCH #17, step #842] loss: 1.5867729489630793\n",
      "[EPOCH #17, step #844] loss: 1.588089619021444\n",
      "[EPOCH #17, step #846] loss: 1.587862165506221\n",
      "[EPOCH #17, step #848] loss: 1.5878033497589075\n",
      "[EPOCH #17, step #850] loss: 1.5876255777831925\n",
      "[EPOCH #17, step #852] loss: 1.587999542461051\n",
      "[EPOCH #17, step #854] loss: 1.5876085995233546\n",
      "[EPOCH #17, step #856] loss: 1.5881131324078126\n",
      "[EPOCH #17, step #858] loss: 1.5884924284654114\n",
      "[EPOCH #17, step #860] loss: 1.5875224070266565\n",
      "[EPOCH #17, step #862] loss: 1.5871323916202071\n",
      "[EPOCH #17, step #864] loss: 1.58627588555992\n",
      "[EPOCH #17, step #866] loss: 1.5862003084972518\n",
      "[EPOCH #17, step #868] loss: 1.5859690989668815\n",
      "[EPOCH #17, step #870] loss: 1.586006335905581\n",
      "[EPOCH #17, step #872] loss: 1.5864098730229295\n",
      "[EPOCH #17, step #874] loss: 1.5864819746017456\n",
      "[EPOCH #17, step #876] loss: 1.5864794882292623\n",
      "[EPOCH #17, step #878] loss: 1.586037312351396\n",
      "[EPOCH #17, step #880] loss: 1.5854826171065297\n",
      "[EPOCH #17, step #882] loss: 1.5849323864026357\n",
      "[EPOCH #17, step #884] loss: 1.5846961526547447\n",
      "[EPOCH #17, step #886] loss: 1.585182014823363\n",
      "[EPOCH #17, step #888] loss: 1.585353883366751\n",
      "[EPOCH #17, step #890] loss: 1.584846871201572\n",
      "[EPOCH #17, step #892] loss: 1.5848514870860408\n",
      "[EPOCH #17, step #894] loss: 1.5849446902727948\n",
      "[EPOCH #17, step #896] loss: 1.5851667207751918\n",
      "[EPOCH #17, step #898] loss: 1.5851661452196861\n",
      "[EPOCH #17, step #900] loss: 1.5855777615579993\n",
      "[EPOCH #17, step #902] loss: 1.585333951023858\n",
      "[EPOCH #17, step #904] loss: 1.5854269001365366\n",
      "[EPOCH #17, step #906] loss: 1.5853381921858614\n",
      "[EPOCH #17, step #908] loss: 1.5845726691063482\n",
      "[EPOCH #17, step #910] loss: 1.583800503503609\n",
      "[EPOCH #17, step #912] loss: 1.5835188648134046\n",
      "[EPOCH #17, step #914] loss: 1.5833844785481854\n",
      "[EPOCH #17, step #916] loss: 1.5836677219771507\n",
      "[EPOCH #17, step #918] loss: 1.5833891362957129\n",
      "[EPOCH #17, step #920] loss: 1.5831024808552314\n",
      "[EPOCH #17, step #922] loss: 1.5836377209728485\n",
      "[EPOCH #17, step #924] loss: 1.5838344805949442\n",
      "[EPOCH #17, step #926] loss: 1.583655162022209\n",
      "[EPOCH #17, step #928] loss: 1.5835061967693693\n",
      "[EPOCH #17, step #930] loss: 1.5832308900855665\n",
      "[EPOCH #17, step #932] loss: 1.5835083654072506\n",
      "[EPOCH #17, step #934] loss: 1.5840658374011198\n",
      "[EPOCH #17, step #936] loss: 1.5837206472836538\n",
      "[EPOCH #17, step #938] loss: 1.5842236700657204\n",
      "[EPOCH #17, step #940] loss: 1.5845705666020116\n",
      "[EPOCH #17, step #942] loss: 1.5849321062971906\n",
      "[EPOCH #17, step #944] loss: 1.5844175592301384\n",
      "[EPOCH #17, step #946] loss: 1.5837701662289176\n",
      "[EPOCH #17, step #948] loss: 1.5843278692193228\n",
      "[EPOCH #17, step #950] loss: 1.5842308462856947\n",
      "[EPOCH #17, step #952] loss: 1.5844286535118959\n",
      "[EPOCH #17, step #954] loss: 1.5844334073091677\n",
      "[EPOCH #17, step #956] loss: 1.5835164903722463\n",
      "[EPOCH #17, step #958] loss: 1.583861323914513\n",
      "[EPOCH #17, step #960] loss: 1.5842861693806007\n",
      "[EPOCH #17, step #962] loss: 1.5837727551148317\n",
      "[EPOCH #17, step #964] loss: 1.5834393297452383\n",
      "[EPOCH #17, step #966] loss: 1.5834885888656884\n",
      "[EPOCH #17, step #968] loss: 1.583420806009826\n",
      "[EPOCH #17, step #970] loss: 1.5828600104142414\n",
      "[EPOCH #17, step #972] loss: 1.5823329181122265\n",
      "[EPOCH #17, step #974] loss: 1.5826410381610576\n",
      "[EPOCH #17, step #976] loss: 1.5821216052727909\n",
      "[EPOCH #17, step #978] loss: 1.5817227821428028\n",
      "[EPOCH #17, step #980] loss: 1.5817171432434844\n",
      "[EPOCH #17, step #982] loss: 1.581870050541867\n",
      "[EPOCH #17, step #984] loss: 1.5821511718827457\n",
      "[EPOCH #17, step #986] loss: 1.5817956820568173\n",
      "[EPOCH #17, step #988] loss: 1.5821283246918805\n",
      "[EPOCH #17, step #990] loss: 1.5825442561708714\n",
      "[EPOCH #17, step #992] loss: 1.5820299510629277\n",
      "[EPOCH #17, step #994] loss: 1.5813990445592296\n",
      "[EPOCH #17, step #996] loss: 1.5813766954655393\n",
      "[EPOCH #17, step #998] loss: 1.581122456131516\n",
      "[EPOCH #17, step #1000] loss: 1.5812577292635723\n",
      "[EPOCH #17, step #1002] loss: 1.5819727497348044\n",
      "[EPOCH #17, step #1004] loss: 1.5826082408724733\n",
      "[EPOCH #17, step #1006] loss: 1.5824114942503307\n",
      "[EPOCH #17, step #1008] loss: 1.5824570560124513\n",
      "[EPOCH #17, step #1010] loss: 1.5824720584792034\n",
      "[EPOCH #17, step #1012] loss: 1.582226046216688\n",
      "[EPOCH #17, step #1014] loss: 1.5827632552884483\n",
      "[EPOCH #17, step #1016] loss: 1.5835423392180497\n",
      "[EPOCH #17, step #1018] loss: 1.5832378934480258\n",
      "[EPOCH #17, step #1020] loss: 1.5839204405243787\n",
      "[EPOCH #17, step #1022] loss: 1.5840280840240732\n",
      "[EPOCH #17, step #1024] loss: 1.5838819941078743\n",
      "[EPOCH #17, step #1026] loss: 1.5837491111142494\n",
      "[EPOCH #17, step #1028] loss: 1.5836210713094594\n",
      "[EPOCH #17, step #1030] loss: 1.5838948940328899\n",
      "[EPOCH #17, step #1032] loss: 1.584129199169266\n",
      "[EPOCH #17, step #1034] loss: 1.5840477797720167\n",
      "[EPOCH #17, step #1036] loss: 1.5846536777403453\n",
      "[EPOCH #17, step #1038] loss: 1.5852749963238104\n",
      "[EPOCH #17, step #1040] loss: 1.585384611952889\n",
      "[EPOCH #17, step #1042] loss: 1.5854690718970843\n",
      "[EPOCH #17, step #1044] loss: 1.5855675484575154\n",
      "[EPOCH #17, step #1046] loss: 1.5855773150522365\n",
      "[EPOCH #17, step #1048] loss: 1.5855081833124842\n",
      "[EPOCH #17, step #1050] loss: 1.585197184054087\n",
      "[EPOCH #17, step #1052] loss: 1.5850336579402515\n",
      "[EPOCH #17, step #1054] loss: 1.5852021299267267\n",
      "[EPOCH #17, step #1056] loss: 1.5851587804286347\n",
      "[EPOCH #17, step #1058] loss: 1.5856703192811736\n",
      "[EPOCH #17, step #1060] loss: 1.5860047991493758\n",
      "[EPOCH #17, step #1062] loss: 1.5863509198908299\n",
      "[EPOCH #17, step #1064] loss: 1.5863541296949968\n",
      "[EPOCH #17, step #1066] loss: 1.5862963545400626\n",
      "[EPOCH #17, step #1068] loss: 1.5859840634941944\n",
      "[EPOCH #17, step #1070] loss: 1.5859452282903799\n",
      "[EPOCH #17, step #1072] loss: 1.5853487383174985\n",
      "[EPOCH #17, step #1074] loss: 1.5852308356484701\n",
      "[EPOCH #17, step #1076] loss: 1.5845010153319732\n",
      "[EPOCH #17, step #1078] loss: 1.584814358243686\n",
      "[EPOCH #17, step #1080] loss: 1.5855845985977215\n",
      "[EPOCH #17, step #1082] loss: 1.5855809621863748\n",
      "[EPOCH #17, step #1084] loss: 1.5847746511208847\n",
      "[EPOCH #17, step #1086] loss: 1.5844437154258406\n",
      "[EPOCH #17, step #1088] loss: 1.5851536907659307\n",
      "[EPOCH #17, step #1090] loss: 1.5847312043720598\n",
      "[EPOCH #17, step #1092] loss: 1.5846901448189612\n",
      "[EPOCH #17, step #1094] loss: 1.5848171103490543\n",
      "[EPOCH #17, step #1096] loss: 1.584685659778042\n",
      "[EPOCH #17, step #1098] loss: 1.5846518315001983\n",
      "[EPOCH #17, step #1100] loss: 1.584493803609836\n",
      "[EPOCH #17, step #1102] loss: 1.5841793031554166\n",
      "[EPOCH #17, step #1104] loss: 1.5837962442933164\n",
      "[EPOCH #17, step #1106] loss: 1.5832905355830826\n",
      "[EPOCH #17, step #1108] loss: 1.5835180839404424\n",
      "[EPOCH #17, step #1110] loss: 1.5834746975602598\n",
      "[EPOCH #17, step #1112] loss: 1.5831606343107403\n",
      "[EPOCH #17, step #1114] loss: 1.5827630183087336\n",
      "[EPOCH #17, step #1116] loss: 1.582425450787762\n",
      "[EPOCH #17, step #1118] loss: 1.5825884163219872\n",
      "[EPOCH #17, step #1120] loss: 1.5826449472919093\n",
      "[EPOCH #17, step #1122] loss: 1.5825950585617514\n",
      "[EPOCH #17, step #1124] loss: 1.5830310660468208\n",
      "[EPOCH #17, step #1126] loss: 1.5835223238131804\n",
      "[EPOCH #17, step #1128] loss: 1.583370241367046\n",
      "[EPOCH #17, step #1130] loss: 1.5837252814615859\n",
      "[EPOCH #17, step #1132] loss: 1.583525434596709\n",
      "[EPOCH #17, step #1134] loss: 1.5833121836448032\n",
      "[EPOCH #17, step #1136] loss: 1.5830476278784826\n",
      "[EPOCH #17, step #1138] loss: 1.5823648479342776\n",
      "[EPOCH #17, step #1140] loss: 1.582439385099854\n",
      "[EPOCH #17, step #1142] loss: 1.5820789413293619\n",
      "[EPOCH #17, step #1144] loss: 1.5821497705826073\n",
      "[EPOCH #17, step #1146] loss: 1.5826162707836813\n",
      "[EPOCH #17, step #1148] loss: 1.5824739709950406\n",
      "[EPOCH #17, step #1150] loss: 1.5827359955379179\n",
      "[EPOCH #17, step #1152] loss: 1.5829185944273487\n",
      "[EPOCH #17, step #1154] loss: 1.5828691097565029\n",
      "[EPOCH #17, step #1156] loss: 1.582219480643936\n",
      "[EPOCH #17, step #1158] loss: 1.5822139512474316\n",
      "[EPOCH #17, step #1160] loss: 1.581990574989516\n",
      "[EPOCH #17, step #1162] loss: 1.5822013464859612\n",
      "[EPOCH #17, step #1164] loss: 1.5823553662443366\n",
      "[EPOCH #17, step #1166] loss: 1.5819714979524784\n",
      "[EPOCH #17, step #1168] loss: 1.581680015073667\n",
      "[EPOCH #17, step #1170] loss: 1.581916787296559\n",
      "[EPOCH #17, step #1172] loss: 1.58134289643547\n",
      "[EPOCH #17, step #1174] loss: 1.5811707700567044\n",
      "[EPOCH #17, step #1176] loss: 1.5809707563614177\n",
      "[EPOCH #17, step #1178] loss: 1.5808774833460801\n",
      "[EPOCH #17, step #1180] loss: 1.5804152354459253\n",
      "[EPOCH #17, step #1182] loss: 1.5800920154518328\n",
      "[EPOCH #17, step #1184] loss: 1.5801091170009178\n",
      "[EPOCH #17, step #1186] loss: 1.5800375209300581\n",
      "[EPOCH #17, step #1188] loss: 1.5799358761340656\n",
      "[EPOCH #17, step #1190] loss: 1.5799316424066334\n",
      "[EPOCH #17, step #1192] loss: 1.5797775500178437\n",
      "[EPOCH #17, step #1194] loss: 1.5793454346796458\n",
      "[EPOCH #17, step #1196] loss: 1.5796665663308866\n",
      "[EPOCH #17, step #1198] loss: 1.5797331426618892\n",
      "[EPOCH #17, step #1200] loss: 1.579091336258643\n",
      "[EPOCH #17, step #1202] loss: 1.5789387655674372\n",
      "[EPOCH #17, step #1204] loss: 1.5789383197226465\n",
      "[EPOCH #17, step #1206] loss: 1.5786849754648753\n",
      "[EPOCH #17, step #1208] loss: 1.5783799447433529\n",
      "[EPOCH #17, step #1210] loss: 1.5781395053883214\n",
      "[EPOCH #17, step #1212] loss: 1.5782704263409602\n",
      "[EPOCH #17, step #1214] loss: 1.5779451354050342\n",
      "[EPOCH #17, step #1216] loss: 1.5776274508399462\n",
      "[EPOCH #17, step #1218] loss: 1.5775841078961648\n",
      "[EPOCH #17, step #1220] loss: 1.5774402896172681\n",
      "[EPOCH #17, step #1222] loss: 1.5775811181434918\n",
      "[EPOCH #17, step #1224] loss: 1.5774651220380043\n",
      "[EPOCH #17, step #1226] loss: 1.5776318811554197\n",
      "[EPOCH #17, step #1228] loss: 1.5776024721714421\n",
      "[EPOCH #17, step #1230] loss: 1.5771645836768162\n",
      "[EPOCH #17, step #1232] loss: 1.5769494750203878\n",
      "[EPOCH #17, step #1234] loss: 1.5763106445069255\n",
      "[EPOCH #17, step #1236] loss: 1.5768848033614378\n",
      "[EPOCH #17, step #1238] loss: 1.576731708042077\n",
      "[EPOCH #17, step #1240] loss: 1.5769047227528286\n",
      "[EPOCH #17, step #1242] loss: 1.5766874307696126\n",
      "[EPOCH #17, step #1244] loss: 1.5766508747296162\n",
      "[EPOCH #17, step #1246] loss: 1.5767781021791931\n",
      "[EPOCH #17, step #1248] loss: 1.5766144470275165\n",
      "[EPOCH #17, step #1250] loss: 1.5764638333678913\n",
      "[EPOCH #17, step #1252] loss: 1.5758180063149496\n",
      "[EPOCH #17, step #1254] loss: 1.5758915838967282\n",
      "[EPOCH #17, step #1256] loss: 1.5760074994729072\n",
      "[EPOCH #17, step #1258] loss: 1.5765360771331454\n",
      "[EPOCH #17, step #1260] loss: 1.5768986707353856\n",
      "[EPOCH #17, step #1262] loss: 1.5767423933399922\n",
      "[EPOCH #17, step #1264] loss: 1.5763060501441655\n",
      "[EPOCH #17, step #1266] loss: 1.5763763109811573\n",
      "[EPOCH #17, step #1268] loss: 1.5761401717638388\n",
      "[EPOCH #17, step #1270] loss: 1.5756772203674287\n",
      "[EPOCH #17, step #1272] loss: 1.5757276682711359\n",
      "[EPOCH #17, step #1274] loss: 1.575955957665163\n",
      "[EPOCH #17, step #1276] loss: 1.57632039507199\n",
      "[EPOCH #17, step #1278] loss: 1.5761570365192183\n",
      "[EPOCH #17, step #1280] loss: 1.5761155629418586\n",
      "[EPOCH #17, step #1282] loss: 1.5765245162873927\n",
      "[EPOCH #17, step #1284] loss: 1.5767832539424822\n",
      "[EPOCH #17, step #1286] loss: 1.5770778583294676\n",
      "[EPOCH #17, step #1288] loss: 1.5769801268843924\n",
      "[EPOCH #17, step #1290] loss: 1.5773987761308388\n",
      "[EPOCH #17, step #1292] loss: 1.5774155819683415\n",
      "[EPOCH #17, step #1294] loss: 1.5769827711536157\n",
      "[EPOCH #17, step #1296] loss: 1.5771581206123186\n",
      "[EPOCH #17, step #1298] loss: 1.577313993002838\n",
      "[EPOCH #17, step #1300] loss: 1.5770819938063714\n",
      "[EPOCH #17, step #1302] loss: 1.5769294196152266\n",
      "[EPOCH #17, step #1304] loss: 1.5766768674284106\n",
      "[EPOCH #17, step #1306] loss: 1.576817702544766\n",
      "[EPOCH #17, step #1308] loss: 1.5768597197496226\n",
      "[EPOCH #17, step #1310] loss: 1.5772064347288974\n",
      "[EPOCH #17, step #1312] loss: 1.5771162941631978\n",
      "[EPOCH #17, step #1314] loss: 1.577323436510427\n",
      "[EPOCH #17, step #1316] loss: 1.5773462700228305\n",
      "[EPOCH #17, step #1318] loss: 1.5771115300237817\n",
      "[EPOCH #17, step #1320] loss: 1.5771036119645152\n",
      "[EPOCH #17, step #1322] loss: 1.5764359268651977\n",
      "[EPOCH #17, step #1324] loss: 1.5763150217398159\n",
      "[EPOCH #17, step #1326] loss: 1.5762218491601692\n",
      "[EPOCH #17, step #1328] loss: 1.5763630071827306\n",
      "[EPOCH #17, step #1330] loss: 1.5760819787911058\n",
      "[EPOCH #17, step #1332] loss: 1.5760368840728411\n",
      "[EPOCH #17, step #1334] loss: 1.5756304216295591\n",
      "[EPOCH #17, step #1336] loss: 1.5753863945146416\n",
      "[EPOCH #17, step #1338] loss: 1.5749061933375723\n",
      "[EPOCH #17, step #1340] loss: 1.574659345356232\n",
      "[EPOCH #17, step #1342] loss: 1.5742830876441296\n",
      "[EPOCH #17, step #1344] loss: 1.5743955026771943\n",
      "[EPOCH #17, step #1346] loss: 1.5744914331963615\n",
      "[EPOCH #17, step #1348] loss: 1.5741688465082353\n",
      "[EPOCH #17, step #1350] loss: 1.5737697526227978\n",
      "[EPOCH #17, step #1352] loss: 1.5739214791691225\n",
      "[EPOCH #17, step #1354] loss: 1.5740379966493023\n",
      "[EPOCH #17, step #1356] loss: 1.574115738020105\n",
      "[EPOCH #17, step #1358] loss: 1.5738371879498338\n",
      "[EPOCH #17, step #1360] loss: 1.5743631447263713\n",
      "[EPOCH #17, step #1362] loss: 1.5745944602036424\n",
      "[EPOCH #17, step #1364] loss: 1.574712666006752\n",
      "[EPOCH #17, step #1366] loss: 1.5745530581509186\n",
      "[EPOCH #17, step #1368] loss: 1.5745002510688704\n",
      "[EPOCH #17, step #1370] loss: 1.5746907283145088\n",
      "[EPOCH #17, step #1372] loss: 1.5747975274670845\n",
      "[EPOCH #17, step #1374] loss: 1.5746082803119312\n",
      "[EPOCH #17, step #1376] loss: 1.5748267614850118\n",
      "[EPOCH #17, step #1378] loss: 1.5744686231741098\n",
      "[EPOCH #17, step #1380] loss: 1.5745039434643606\n",
      "[EPOCH #17, step #1382] loss: 1.5743724518467013\n",
      "[EPOCH #17, step #1384] loss: 1.5742629868459186\n",
      "[EPOCH #17, step #1386] loss: 1.574172883258935\n",
      "[EPOCH #17, step #1388] loss: 1.5739882795221949\n",
      "[EPOCH #17, step #1390] loss: 1.5742064191230676\n",
      "[EPOCH #17, step #1392] loss: 1.5740425030019587\n",
      "[EPOCH #17, step #1394] loss: 1.5743634008164902\n",
      "[EPOCH #17, step #1396] loss: 1.5741812671263387\n",
      "[EPOCH #17, step #1398] loss: 1.574386713290061\n",
      "[EPOCH #17, step #1400] loss: 1.5743751998546718\n",
      "[EPOCH #17, step #1402] loss: 1.574162158257436\n",
      "[EPOCH #17, step #1404] loss: 1.5741626228301975\n",
      "[EPOCH #17, step #1406] loss: 1.5737367074965753\n",
      "[EPOCH #17, step #1408] loss: 1.573610821922592\n",
      "[EPOCH #17, step #1410] loss: 1.5738417490165677\n",
      "[EPOCH #17, step #1412] loss: 1.574141757883084\n",
      "[EPOCH #17, step #1414] loss: 1.5740316501775815\n",
      "[EPOCH #17, step #1416] loss: 1.5739524920977752\n",
      "[EPOCH #17, step #1418] loss: 1.5735931234766347\n",
      "[EPOCH #17, step #1420] loss: 1.5735824755343815\n",
      "[EPOCH #17, step #1422] loss: 1.5740717975756524\n",
      "[EPOCH #17, step #1424] loss: 1.5737662290690237\n",
      "[EPOCH #17, step #1426] loss: 1.573441859342539\n",
      "[EPOCH #17, step #1428] loss: 1.5736522430552728\n",
      "[EPOCH #17, step #1430] loss: 1.573410746894626\n",
      "[EPOCH #17, step #1432] loss: 1.5730098465565443\n",
      "[EPOCH #17, step #1434] loss: 1.5733120119530148\n",
      "[EPOCH #17, step #1436] loss: 1.572987460268813\n",
      "[EPOCH #17, step #1438] loss: 1.572421869732921\n",
      "[EPOCH #17, step #1440] loss: 1.5722022717152926\n",
      "[EPOCH #17, step #1442] loss: 1.5724970566177237\n",
      "[EPOCH #17, step #1444] loss: 1.5719890358951265\n",
      "[EPOCH #17, step #1446] loss: 1.5720574143596906\n",
      "[EPOCH #17, step #1448] loss: 1.5715079071852485\n",
      "[EPOCH #17, step #1450] loss: 1.5710052913587558\n",
      "[EPOCH #17, step #1452] loss: 1.571049461057903\n",
      "[EPOCH #17, step #1454] loss: 1.5710341428563357\n",
      "[EPOCH #17, step #1456] loss: 1.5711363169045667\n",
      "[EPOCH #17, step #1458] loss: 1.5713966876942462\n",
      "[EPOCH #17, step #1460] loss: 1.571776751824065\n",
      "[EPOCH #17, step #1462] loss: 1.5717901682821105\n",
      "[EPOCH #17, step #1464] loss: 1.5719944574320275\n",
      "[EPOCH #17, step #1466] loss: 1.571727016098904\n",
      "[EPOCH #17, step #1468] loss: 1.5716333406729468\n",
      "[EPOCH #17, step #1470] loss: 1.5717203715559092\n",
      "[EPOCH #17, step #1472] loss: 1.5722654278150483\n",
      "[EPOCH #17, step #1474] loss: 1.5717231727454621\n",
      "[EPOCH #17, step #1476] loss: 1.5716770027405358\n",
      "[EPOCH #17, step #1478] loss: 1.5720872176588185\n",
      "[EPOCH #17, step #1480] loss: 1.57220829656042\n",
      "[EPOCH #17, step #1482] loss: 1.5726060886199782\n",
      "[EPOCH #17, step #1484] loss: 1.5724147063313108\n",
      "[EPOCH #17, step #1486] loss: 1.5722415990370908\n",
      "[EPOCH #17, step #1488] loss: 1.572575982542467\n",
      "[EPOCH #17, step #1490] loss: 1.5724674293372873\n",
      "[EPOCH #17, step #1492] loss: 1.5725538639996728\n",
      "[EPOCH #17, step #1494] loss: 1.5725575051180096\n",
      "[EPOCH #17, step #1496] loss: 1.5723967564528039\n",
      "[EPOCH #17, step #1498] loss: 1.5722821141736678\n",
      "[EPOCH #17, step #1500] loss: 1.5725066443827056\n",
      "[EPOCH #17, step #1502] loss: 1.5725832583106365\n",
      "[EPOCH #17, step #1504] loss: 1.572657987168461\n",
      "[EPOCH #17, step #1506] loss: 1.572900146107525\n",
      "[EPOCH #17, step #1508] loss: 1.5726437273603784\n",
      "[EPOCH #17, step #1510] loss: 1.572395323089698\n",
      "[EPOCH #17, step #1512] loss: 1.5718045338682993\n",
      "[EPOCH #17, step #1514] loss: 1.5717138407647413\n",
      "[EPOCH #17, step #1516] loss: 1.571826522493331\n",
      "[EPOCH #17, step #1518] loss: 1.5718595889777711\n",
      "[EPOCH #17, step #1520] loss: 1.5716763465989192\n",
      "[EPOCH #17, step #1522] loss: 1.5718226938441797\n",
      "[EPOCH #17, step #1524] loss: 1.5717881760050039\n",
      "[EPOCH #17, step #1526] loss: 1.572243792290928\n",
      "[EPOCH #17, step #1528] loss: 1.572177081734936\n",
      "[EPOCH #17, step #1530] loss: 1.5720898048461924\n",
      "[EPOCH #17, step #1532] loss: 1.5719123195373226\n",
      "[EPOCH #17, step #1534] loss: 1.5721386438860567\n",
      "[EPOCH #17, step #1536] loss: 1.5720542455231437\n",
      "[EPOCH #17, step #1538] loss: 1.5721404278255113\n",
      "[EPOCH #17, step #1540] loss: 1.5721038009809412\n",
      "[EPOCH #17, step #1542] loss: 1.5722312164708383\n",
      "[EPOCH #17, step #1544] loss: 1.5720701608071435\n",
      "[EPOCH #17, step #1546] loss: 1.5723841060880084\n",
      "[EPOCH #17, step #1548] loss: 1.5725565558483403\n",
      "[EPOCH #17, step #1550] loss: 1.5727391665708934\n",
      "[EPOCH #17, step #1552] loss: 1.5728975416995292\n",
      "[EPOCH #17, step #1554] loss: 1.5729706630062827\n",
      "[EPOCH #17, step #1556] loss: 1.5727075986090424\n",
      "[EPOCH #17, step #1558] loss: 1.5726258545980154\n",
      "[EPOCH #17, step #1560] loss: 1.5728527516756663\n",
      "[EPOCH #17, step #1562] loss: 1.5726527119018447\n",
      "[EPOCH #17, step #1564] loss: 1.572133067012214\n",
      "[EPOCH #17, step #1566] loss: 1.5720093219844717\n",
      "[EPOCH #17, step #1568] loss: 1.5720571777940633\n",
      "[EPOCH #17, step #1570] loss: 1.5718754531470627\n",
      "[EPOCH #17, step #1572] loss: 1.5713131715746647\n",
      "[EPOCH #17, step #1574] loss: 1.5712721376570444\n",
      "[EPOCH #17, step #1576] loss: 1.5710874228214415\n",
      "[EPOCH #17, step #1578] loss: 1.5710027244288836\n",
      "[EPOCH #17, step #1580] loss: 1.5708936388020573\n",
      "[EPOCH #17, step #1582] loss: 1.570974366467585\n",
      "[EPOCH #17, step #1584] loss: 1.5704606811706951\n",
      "[EPOCH #17, step #1586] loss: 1.5706425891331177\n",
      "[EPOCH #17, step #1588] loss: 1.5706161837895911\n",
      "[EPOCH #17, step #1590] loss: 1.5706242608769294\n",
      "[EPOCH #17, step #1592] loss: 1.5707275115762651\n",
      "[EPOCH #17, step #1594] loss: 1.5705647295545262\n",
      "[EPOCH #17, step #1596] loss: 1.5703614452666017\n",
      "[EPOCH #17, step #1598] loss: 1.5705090655693044\n",
      "[EPOCH #17, step #1600] loss: 1.5703863648233527\n",
      "[EPOCH #17, step #1602] loss: 1.5701423257645115\n",
      "[EPOCH #17, step #1604] loss: 1.5701460206620046\n",
      "[EPOCH #17, step #1606] loss: 1.5699996847726576\n",
      "[EPOCH #17, step #1608] loss: 1.5703507156161658\n",
      "[EPOCH #17, step #1610] loss: 1.570316210546381\n",
      "[EPOCH #17, step #1612] loss: 1.570591306472076\n",
      "[EPOCH #17, step #1614] loss: 1.570665735393855\n",
      "[EPOCH #17, step #1616] loss: 1.5706513032326377\n",
      "[EPOCH #17, step #1618] loss: 1.5704549343001335\n",
      "[EPOCH #17, step #1620] loss: 1.5706539236050487\n",
      "[EPOCH #17, step #1622] loss: 1.5705395242496545\n",
      "[EPOCH #17, step #1624] loss: 1.5700704651245705\n",
      "[EPOCH #17, step #1626] loss: 1.5706523295260677\n",
      "[EPOCH #17, step #1628] loss: 1.5706355447707694\n",
      "[EPOCH #17, step #1630] loss: 1.571063368215216\n",
      "[EPOCH #17, step #1632] loss: 1.5713435524238522\n",
      "[EPOCH #17, step #1634] loss: 1.571469799276521\n",
      "[EPOCH #17, step #1636] loss: 1.5712944781481673\n",
      "[EPOCH #17, step #1638] loss: 1.5714245507672038\n",
      "[EPOCH #17, step #1640] loss: 1.571476108231681\n",
      "[EPOCH #17, step #1642] loss: 1.5713885377183312\n",
      "[EPOCH #17, step #1644] loss: 1.5708080022168376\n",
      "[EPOCH #17, step #1646] loss: 1.5709800856288592\n",
      "[EPOCH #17, step #1648] loss: 1.5712027760835905\n",
      "[EPOCH #17, step #1650] loss: 1.5716056461264913\n",
      "[EPOCH #17, step #1652] loss: 1.5714711832120356\n",
      "[EPOCH #17, step #1654] loss: 1.5713155021840353\n",
      "[EPOCH #17, step #1656] loss: 1.5715438790830705\n",
      "[EPOCH #17, step #1658] loss: 1.571602311530984\n",
      "[EPOCH #17, step #1660] loss: 1.5708429125473486\n",
      "[EPOCH #17, step #1662] loss: 1.5708707489669145\n",
      "[EPOCH #17, step #1664] loss: 1.570816909765696\n",
      "[EPOCH #17, step #1666] loss: 1.5706317703310573\n",
      "[EPOCH #17, step #1668] loss: 1.5707749140841152\n",
      "[EPOCH #17, step #1670] loss: 1.5710276013930211\n",
      "[EPOCH #17, step #1672] loss: 1.5707262292352895\n",
      "[EPOCH #17, step #1674] loss: 1.570557694043686\n",
      "[EPOCH #17, step #1676] loss: 1.570201447447923\n",
      "[EPOCH #17, step #1678] loss: 1.570583967490875\n",
      "[EPOCH #17, step #1680] loss: 1.5709437409516673\n",
      "[EPOCH #17, step #1682] loss: 1.5709376494868907\n",
      "[EPOCH #17, step #1684] loss: 1.5707633042194016\n",
      "[EPOCH #17, step #1686] loss: 1.5709286662835515\n",
      "[EPOCH #17, step #1688] loss: 1.5713376058425474\n",
      "[EPOCH #17, step #1690] loss: 1.5711897020506338\n",
      "[EPOCH #17, step #1692] loss: 1.5711704770348442\n",
      "[EPOCH #17, step #1694] loss: 1.5709952091748736\n",
      "[EPOCH #17, step #1696] loss: 1.5707011790084502\n",
      "[EPOCH #17, step #1698] loss: 1.571104473370254\n",
      "[EPOCH #17, step #1700] loss: 1.5709825198766696\n",
      "[EPOCH #17, step #1702] loss: 1.571009237732666\n",
      "[EPOCH #17, step #1704] loss: 1.5708473318483123\n",
      "[EPOCH #17, step #1706] loss: 1.5713957262863245\n",
      "[EPOCH #17, step #1708] loss: 1.5717211195500431\n",
      "[EPOCH #17, step #1710] loss: 1.5715681408874338\n",
      "[EPOCH #17, step #1712] loss: 1.57179472259242\n",
      "[EPOCH #17, step #1714] loss: 1.5716902995943676\n",
      "[EPOCH #17, step #1716] loss: 1.5717323117639412\n",
      "[EPOCH #17, step #1718] loss: 1.5716195535424007\n",
      "[EPOCH #17, step #1720] loss: 1.5711493664948764\n",
      "[EPOCH #17, step #1722] loss: 1.5713011999498323\n",
      "[EPOCH #17, step #1724] loss: 1.5709421228671419\n",
      "[EPOCH #17, step #1726] loss: 1.5707574100872652\n",
      "[EPOCH #17, step #1728] loss: 1.5706969826051858\n",
      "[EPOCH #17, step #1730] loss: 1.5704234454550543\n",
      "[EPOCH #17, step #1732] loss: 1.57022188095708\n",
      "[EPOCH #17, step #1734] loss: 1.5701056792687957\n",
      "[EPOCH #17, step #1736] loss: 1.569946608429471\n",
      "[EPOCH #17, step #1738] loss: 1.57018952876278\n",
      "[EPOCH #17, step #1740] loss: 1.5703337407194287\n",
      "[EPOCH #17, step #1742] loss: 1.5702209525660955\n",
      "[EPOCH #17, step #1744] loss: 1.5700403250049384\n",
      "[EPOCH #17, step #1746] loss: 1.5700816957692658\n",
      "[EPOCH #17, step #1748] loss: 1.5698122502804621\n",
      "[EPOCH #17, step #1750] loss: 1.5694788928238887\n",
      "[EPOCH #17, step #1752] loss: 1.5696876197628342\n",
      "[EPOCH #17, step #1754] loss: 1.5697479782281099\n",
      "[EPOCH #17, step #1756] loss: 1.5694245358183767\n",
      "[EPOCH #17, step #1758] loss: 1.569578313400557\n",
      "[EPOCH #17, step #1760] loss: 1.5697080658823843\n",
      "[EPOCH #17, step #1762] loss: 1.5695979168857286\n",
      "[EPOCH #17, step #1764] loss: 1.569416130602191\n",
      "[EPOCH #17, step #1766] loss: 1.5696154346085567\n",
      "[EPOCH #17, step #1768] loss: 1.5699159800837847\n",
      "[EPOCH #17, step #1770] loss: 1.5699620206836655\n",
      "[EPOCH #17, step #1772] loss: 1.5702964497432828\n",
      "[EPOCH #17, step #1774] loss: 1.5703880894687814\n",
      "[EPOCH #17, step #1776] loss: 1.5699119564852289\n",
      "[EPOCH #17, step #1778] loss: 1.5701303937382882\n",
      "[EPOCH #17, step #1780] loss: 1.5701529445238558\n",
      "[EPOCH #17, step #1782] loss: 1.5697570778450403\n",
      "[EPOCH #17, step #1784] loss: 1.5694270682268117\n",
      "[EPOCH #17, step #1786] loss: 1.569625999784763\n",
      "[EPOCH #17, step #1788] loss: 1.569446465168138\n",
      "[EPOCH #17, step #1790] loss: 1.569667679979973\n",
      "[EPOCH #17, step #1792] loss: 1.569657386246834\n",
      "[EPOCH #17, step #1794] loss: 1.5693652744080695\n",
      "[EPOCH #17, step #1796] loss: 1.5695617882888317\n",
      "[EPOCH #17, step #1798] loss: 1.5693491695986117\n",
      "[EPOCH #17, step #1800] loss: 1.569222150412882\n",
      "[EPOCH #17, step #1802] loss: 1.5693465541351919\n",
      "[EPOCH #17, step #1804] loss: 1.5693413342135105\n",
      "[EPOCH #17, step #1806] loss: 1.5693998389568655\n",
      "[EPOCH #17, step #1808] loss: 1.5690183113002196\n",
      "[EPOCH #17, step #1810] loss: 1.5691866289509522\n",
      "[EPOCH #17, step #1812] loss: 1.5693081999377394\n",
      "[EPOCH #17, step #1814] loss: 1.569496228806572\n",
      "[EPOCH #17, step #1816] loss: 1.5694770777560094\n",
      "[EPOCH #17, step #1818] loss: 1.5694057828060148\n",
      "[EPOCH #17, step #1820] loss: 1.5695547991437875\n",
      "[EPOCH #17, step #1822] loss: 1.5696206326937192\n",
      "[EPOCH #17, step #1824] loss: 1.5691985038208636\n",
      "[EPOCH #17, step #1826] loss: 1.5694499934509143\n",
      "[EPOCH #17, step #1828] loss: 1.5693138127381714\n",
      "[EPOCH #17, step #1830] loss: 1.569196122061158\n",
      "[EPOCH #17, step #1832] loss: 1.5693483418346557\n",
      "[EPOCH #17, step #1834] loss: 1.5691822476218118\n",
      "[EPOCH #17, step #1836] loss: 1.5689124001324923\n",
      "[EPOCH #17, step #1838] loss: 1.5689954012875456\n",
      "[EPOCH #17, step #1840] loss: 1.5689182077523873\n",
      "[EPOCH #17, step #1842] loss: 1.5688182040523462\n",
      "[EPOCH #17, step #1844] loss: 1.5690115916373606\n",
      "[EPOCH #17, step #1846] loss: 1.5691748186260155\n",
      "[EPOCH #17, step #1848] loss: 1.5691912087187243\n",
      "[EPOCH #17, step #1850] loss: 1.5694650582916863\n",
      "[EPOCH #17, step #1852] loss: 1.5694432431018746\n",
      "[EPOCH #17, step #1854] loss: 1.5691982974260643\n",
      "[EPOCH #17, step #1856] loss: 1.5692301673406417\n",
      "[EPOCH #17, step #1858] loss: 1.569025136053466\n",
      "[EPOCH #17, step #1860] loss: 1.568759744811737\n",
      "[EPOCH #17, step #1862] loss: 1.568610045644972\n",
      "[EPOCH #17, step #1864] loss: 1.5684834420840799\n",
      "[EPOCH #17, step #1866] loss: 1.5684174808768838\n",
      "[EPOCH #17, step #1868] loss: 1.568357073412406\n",
      "[EPOCH #17, step #1870] loss: 1.5684533223055825\n",
      "[EPOCH #17, step #1872] loss: 1.5685268099525684\n",
      "[EPOCH #17, step #1874] loss: 1.5686997228622437\n",
      "[EPOCH #17, step #1876] loss: 1.5685136527791579\n",
      "[EPOCH #17, step #1878] loss: 1.5685284673818698\n",
      "[EPOCH #17, step #1880] loss: 1.5687841061009555\n",
      "[EPOCH #17, step #1882] loss: 1.5689246773529864\n",
      "[EPOCH #17, step #1884] loss: 1.568904893531091\n",
      "[EPOCH #17, step #1886] loss: 1.5687376459755464\n",
      "[EPOCH #17, step #1888] loss: 1.5688376433638558\n",
      "[EPOCH #17, step #1890] loss: 1.568570296894237\n",
      "[EPOCH #17, step #1892] loss: 1.5687642004272009\n",
      "[EPOCH #17, step #1894] loss: 1.568658064349031\n",
      "[EPOCH #17, step #1896] loss: 1.5686930745415897\n",
      "[EPOCH #17, step #1898] loss: 1.5691872009671066\n",
      "[EPOCH #17, step #1900] loss: 1.569150513940457\n",
      "[EPOCH #17, step #1902] loss: 1.569465928809366\n",
      "[EPOCH #17, step #1904] loss: 1.569512679508039\n",
      "[EPOCH #17, step #1906] loss: 1.5695159162097285\n",
      "[EPOCH #17, step #1908] loss: 1.5697216639786007\n",
      "[EPOCH #17, step #1910] loss: 1.5696364986154185\n",
      "[EPOCH #17, step #1912] loss: 1.5697539472729514\n",
      "[EPOCH #17, step #1914] loss: 1.5696231424341625\n",
      "[EPOCH #17, step #1916] loss: 1.5693478718609877\n",
      "[EPOCH #17, step #1918] loss: 1.5691189106210188\n",
      "[EPOCH #17, step #1920] loss: 1.5691168160565132\n",
      "[EPOCH #17, step #1922] loss: 1.5689672583164924\n",
      "[EPOCH #17, step #1924] loss: 1.5689517182808417\n",
      "[EPOCH #17, step #1926] loss: 1.568902573686965\n",
      "[EPOCH #17, step #1928] loss: 1.5687343091653256\n",
      "[EPOCH #17, step #1930] loss: 1.5687930192557227\n",
      "[EPOCH #17, step #1932] loss: 1.5688085302564065\n",
      "[EPOCH #17, step #1934] loss: 1.5687645112513264\n",
      "[EPOCH #17, step #1936] loss: 1.5687860702200531\n",
      "[EPOCH #17, step #1938] loss: 1.5689149490024947\n",
      "[EPOCH #17, step #1940] loss: 1.5688059780783163\n",
      "[EPOCH #17, step #1942] loss: 1.5687477029112278\n",
      "[EPOCH #17, step #1944] loss: 1.5685407788097705\n",
      "[EPOCH #17, step #1946] loss: 1.5685112655744469\n",
      "[EPOCH #17, step #1948] loss: 1.5684712005921546\n",
      "[EPOCH #17, step #1950] loss: 1.5687083343797192\n",
      "[EPOCH #17, step #1952] loss: 1.568290270967967\n",
      "[EPOCH #17, step #1954] loss: 1.5685042686169715\n",
      "[EPOCH #17, step #1956] loss: 1.5685304609804538\n",
      "[EPOCH #17, step #1958] loss: 1.5683894615017557\n",
      "[EPOCH #17, step #1960] loss: 1.568368388401617\n",
      "[EPOCH #17, step #1962] loss: 1.5685264210402206\n",
      "[EPOCH #17, step #1964] loss: 1.5684682910982282\n",
      "[EPOCH #17, step #1966] loss: 1.5683266882006748\n",
      "[EPOCH #17, step #1968] loss: 1.5683647823430609\n",
      "[EPOCH #17, step #1970] loss: 1.5688231199420326\n",
      "[EPOCH #17, step #1972] loss: 1.568528066295328\n",
      "[EPOCH #17, step #1974] loss: 1.5685039447229119\n",
      "[EPOCH #17, step #1976] loss: 1.56849057673202\n",
      "[EPOCH #17, step #1978] loss: 1.5687924880701944\n",
      "[EPOCH #17, step #1980] loss: 1.568879304661527\n",
      "[EPOCH #17, step #1982] loss: 1.568839250822832\n",
      "[EPOCH #17, step #1984] loss: 1.5688306195910091\n",
      "[EPOCH #17, step #1986] loss: 1.5689516845035025\n",
      "[EPOCH #17, step #1988] loss: 1.5688936128995117\n",
      "[EPOCH #17, step #1990] loss: 1.5687912930081922\n",
      "[EPOCH #17, step #1992] loss: 1.5687696190258396\n",
      "[EPOCH #17, step #1994] loss: 1.5685497897609433\n",
      "[EPOCH #17, step #1996] loss: 1.5684493802819899\n",
      "[EPOCH #17, step #1998] loss: 1.5683825454335025\n",
      "[EPOCH #17, step #2000] loss: 1.568441050640051\n",
      "[EPOCH #17, step #2002] loss: 1.5683992952331567\n",
      "[EPOCH #17, step #2004] loss: 1.5687684371881652\n",
      "[EPOCH #17, step #2006] loss: 1.5687626482065957\n",
      "[EPOCH #17, step #2008] loss: 1.568504659675021\n",
      "[EPOCH #17, step #2010] loss: 1.5685820200738476\n",
      "[EPOCH #17, step #2012] loss: 1.5684538226902218\n",
      "[EPOCH #17, step #2014] loss: 1.568380289160584\n",
      "[EPOCH #17, step #2016] loss: 1.5681579094684885\n",
      "[EPOCH #17, step #2018] loss: 1.5679153502725505\n",
      "[EPOCH #17, step #2020] loss: 1.5680815078786314\n",
      "[EPOCH #17, step #2022] loss: 1.5679723677868544\n",
      "[EPOCH #17, step #2024] loss: 1.5677654256938416\n",
      "[EPOCH #17, step #2026] loss: 1.5674346003205422\n",
      "[EPOCH #17, step #2028] loss: 1.5674928853287375\n",
      "[EPOCH #17, step #2030] loss: 1.567222558237073\n",
      "[EPOCH #17, step #2032] loss: 1.567249030769018\n",
      "[EPOCH #17, step #2034] loss: 1.567427743037737\n",
      "[EPOCH #17, step #2036] loss: 1.5675002676514826\n",
      "[EPOCH #17, step #2038] loss: 1.5671638929709435\n",
      "[EPOCH #17, step #2040] loss: 1.567084400283537\n",
      "[EPOCH #17, step #2042] loss: 1.5670069289219128\n",
      "[EPOCH #17, step #2044] loss: 1.566937751874947\n",
      "[EPOCH #17, step #2046] loss: 1.5670012211182318\n",
      "[EPOCH #17, step #2048] loss: 1.5671044936582714\n",
      "[EPOCH #17, step #2050] loss: 1.5671502140776115\n",
      "[EPOCH #17, step #2052] loss: 1.5671748326455333\n",
      "[EPOCH #17, step #2054] loss: 1.567098402106849\n",
      "[EPOCH #17, step #2056] loss: 1.5670971722642253\n",
      "[EPOCH #17, step #2058] loss: 1.567008620387666\n",
      "[EPOCH #17, step #2060] loss: 1.5673395670599755\n",
      "[EPOCH #17, step #2062] loss: 1.5676203644281443\n",
      "[EPOCH #17, step #2064] loss: 1.567600331699011\n",
      "[EPOCH #17, step #2066] loss: 1.5675161440244434\n",
      "[EPOCH #17, step #2068] loss: 1.5676977649986485\n",
      "[EPOCH #17, step #2070] loss: 1.567935062916828\n",
      "[EPOCH #17, step #2072] loss: 1.5680333598477796\n",
      "[EPOCH #17, step #2074] loss: 1.5678218149277101\n",
      "[EPOCH #17, step #2076] loss: 1.567831137172293\n",
      "[EPOCH #17, step #2078] loss: 1.5678769949252012\n",
      "[EPOCH #17, step #2080] loss: 1.5678591439495975\n",
      "[EPOCH #17, step #2082] loss: 1.568040559970583\n",
      "[EPOCH #17, step #2084] loss: 1.5681483680395771\n",
      "[EPOCH #17, step #2086] loss: 1.5682878278920567\n",
      "[EPOCH #17, step #2088] loss: 1.5682722055609573\n",
      "[EPOCH #17, step #2090] loss: 1.5679183508835586\n",
      "[EPOCH #17, step #2092] loss: 1.5674895985070678\n",
      "[EPOCH #17, step #2094] loss: 1.5674288656944875\n",
      "[EPOCH #17, step #2096] loss: 1.5675736956216633\n",
      "[EPOCH #17, step #2098] loss: 1.5673751706109267\n",
      "[EPOCH #17, step #2100] loss: 1.56702830756295\n",
      "[EPOCH #17, step #2102] loss: 1.5670320556325907\n",
      "[EPOCH #17, step #2104] loss: 1.5670442680848182\n",
      "[EPOCH #17, step #2106] loss: 1.5669214702297514\n",
      "[EPOCH #17, step #2108] loss: 1.566546953476227\n",
      "[EPOCH #17, step #2110] loss: 1.5665064232996548\n",
      "[EPOCH #17, step #2112] loss: 1.5666234656865146\n",
      "[EPOCH #17, step #2114] loss: 1.566656336378544\n",
      "[EPOCH #17, step #2116] loss: 1.566672826804358\n",
      "[EPOCH #17, step #2118] loss: 1.5664065462511179\n",
      "[EPOCH #17, step #2120] loss: 1.5664823660587488\n",
      "[EPOCH #17, step #2122] loss: 1.566501977642471\n",
      "[EPOCH #17, step #2124] loss: 1.5667394056881174\n",
      "[EPOCH #17, step #2126] loss: 1.5668518330830052\n",
      "[EPOCH #17, step #2128] loss: 1.5667810394149142\n",
      "[EPOCH #17, step #2130] loss: 1.5665622690036116\n",
      "[EPOCH #17, step #2132] loss: 1.5665067017944665\n",
      "[EPOCH #17, step #2134] loss: 1.5663658137622984\n",
      "[EPOCH #17, step #2136] loss: 1.5667216522871026\n",
      "[EPOCH #17, step #2138] loss: 1.5667679638102434\n",
      "[EPOCH #17, step #2140] loss: 1.5668280423105125\n",
      "[EPOCH #17, step #2142] loss: 1.5669465206295767\n",
      "[EPOCH #17, step #2144] loss: 1.5669816847447748\n",
      "[EPOCH #17, step #2146] loss: 1.56681986703504\n",
      "[EPOCH #17, step #2148] loss: 1.5669398377140271\n",
      "[EPOCH #17, step #2150] loss: 1.5671588066620696\n",
      "[EPOCH #17, step #2152] loss: 1.5673082584123306\n",
      "[EPOCH #17, step #2154] loss: 1.5671037277323463\n",
      "[EPOCH #17, step #2156] loss: 1.5670105717388856\n",
      "[EPOCH #17, step #2158] loss: 1.5669587970387333\n",
      "[EPOCH #17, step #2160] loss: 1.5669548951713423\n",
      "[EPOCH #17, step #2162] loss: 1.5672939724796522\n",
      "[EPOCH #17, step #2164] loss: 1.5670721163099963\n",
      "[EPOCH #17, step #2166] loss: 1.5668619117485965\n",
      "[EPOCH #17, step #2168] loss: 1.566652208388044\n",
      "[EPOCH #17, step #2170] loss: 1.566666700553367\n",
      "[EPOCH #17, step #2172] loss: 1.5668786305521032\n",
      "[EPOCH #17, step #2174] loss: 1.5667390156888414\n",
      "[EPOCH #17, step #2176] loss: 1.566910374914773\n",
      "[EPOCH #17, step #2178] loss: 1.566932439749369\n",
      "[EPOCH #17, step #2180] loss: 1.5669246864996609\n",
      "[EPOCH #17, step #2182] loss: 1.5667791098997892\n",
      "[EPOCH #17, step #2184] loss: 1.566562945782729\n",
      "[EPOCH #17, step #2186] loss: 1.5664795952187753\n",
      "[EPOCH #17, step #2188] loss: 1.5667075224258193\n",
      "[EPOCH #17, step #2190] loss: 1.566512458675912\n",
      "[EPOCH #17, step #2192] loss: 1.5664014435771172\n",
      "[EPOCH #17, step #2194] loss: 1.5665604482750686\n",
      "[EPOCH #17, step #2196] loss: 1.5664015942179836\n",
      "[EPOCH #17, step #2198] loss: 1.566343542552634\n",
      "[EPOCH #17, step #2200] loss: 1.566401342216918\n",
      "[EPOCH #17, step #2202] loss: 1.5662258688666526\n",
      "[EPOCH #17, step #2204] loss: 1.5662240790672042\n",
      "[EPOCH #17, step #2206] loss: 1.5660114681013149\n",
      "[EPOCH #17, step #2208] loss: 1.565853642359639\n",
      "[EPOCH #17, step #2210] loss: 1.5655605994646822\n",
      "[EPOCH #17, step #2212] loss: 1.5654908858754761\n",
      "[EPOCH #17, step #2214] loss: 1.5655233836873659\n",
      "[EPOCH #17, step #2216] loss: 1.5654638641096743\n",
      "[EPOCH #17, step #2218] loss: 1.5657031428658141\n",
      "[EPOCH #17, step #2220] loss: 1.5656819297944249\n",
      "[EPOCH #17, step #2222] loss: 1.5656116914491744\n",
      "[EPOCH #17, step #2224] loss: 1.5654660036858548\n",
      "[EPOCH #17, step #2226] loss: 1.5654641871073345\n",
      "[EPOCH #17, step #2228] loss: 1.565333795579574\n",
      "[EPOCH #17, step #2230] loss: 1.5650272379002728\n",
      "[EPOCH #17, step #2232] loss: 1.565009858060513\n",
      "[EPOCH #17, step #2234] loss: 1.5648993889490763\n",
      "[EPOCH #17, step #2236] loss: 1.5645976205942191\n",
      "[EPOCH #17, step #2238] loss: 1.564694508930145\n",
      "[EPOCH #17, step #2240] loss: 1.564553685163824\n",
      "[EPOCH #17, step #2242] loss: 1.564303718583689\n",
      "[EPOCH #17, step #2244] loss: 1.5645549245029355\n",
      "[EPOCH #17, step #2246] loss: 1.564637669336016\n",
      "[EPOCH #17, step #2248] loss: 1.5650163336349308\n",
      "[EPOCH #17, step #2250] loss: 1.564976463234197\n",
      "[EPOCH #17, step #2252] loss: 1.5649487798974824\n",
      "[EPOCH #17, step #2254] loss: 1.564933820177869\n",
      "[EPOCH #17, step #2256] loss: 1.564679251897108\n",
      "[EPOCH #17, step #2258] loss: 1.5644864480597829\n",
      "[EPOCH #17, step #2260] loss: 1.5643765010279083\n",
      "[EPOCH #17, step #2262] loss: 1.5642488115770439\n",
      "[EPOCH #17, step #2264] loss: 1.564443979121202\n",
      "[EPOCH #17, step #2266] loss: 1.5645659509134229\n",
      "[EPOCH #17, step #2268] loss: 1.5645118385172458\n",
      "[EPOCH #17, step #2270] loss: 1.564383220929818\n",
      "[EPOCH #17, step #2272] loss: 1.5643854844271219\n",
      "[EPOCH #17, step #2274] loss: 1.564369212952289\n",
      "[EPOCH #17, step #2276] loss: 1.5642894615611853\n",
      "[EPOCH #17, step #2278] loss: 1.5640994799194654\n",
      "[EPOCH #17, step #2280] loss: 1.5639738513680206\n",
      "[EPOCH #17, step #2282] loss: 1.563799612547189\n",
      "[EPOCH #17, step #2284] loss: 1.5637662613417962\n",
      "[EPOCH #17, step #2286] loss: 1.5638033932194628\n",
      "[EPOCH #17, step #2288] loss: 1.5633907287388507\n",
      "[EPOCH #17, step #2290] loss: 1.5631304534956234\n",
      "[EPOCH #17, step #2292] loss: 1.563156257328694\n",
      "[EPOCH #17, step #2294] loss: 1.5629458556247953\n",
      "[EPOCH #17, step #2296] loss: 1.5630248095815888\n",
      "[EPOCH #17, step #2298] loss: 1.5628205368237789\n",
      "[EPOCH #17, step #2300] loss: 1.5627454112064108\n",
      "[EPOCH #17, step #2302] loss: 1.5624631098235011\n",
      "[EPOCH #17, step #2304] loss: 1.5624692281259631\n",
      "[EPOCH #17, step #2306] loss: 1.5626345075050059\n",
      "[EPOCH #17, step #2308] loss: 1.5625384773408866\n",
      "[EPOCH #17, step #2310] loss: 1.5626317495806605\n",
      "[EPOCH #17, step #2312] loss: 1.5625299336948386\n",
      "[EPOCH #17, step #2314] loss: 1.5626444798566352\n",
      "[EPOCH #17, step #2316] loss: 1.562804508373868\n",
      "[EPOCH #17, step #2318] loss: 1.5628763037850602\n",
      "[EPOCH #17, step #2320] loss: 1.5628103624896108\n",
      "[EPOCH #17, step #2322] loss: 1.5628037124269234\n",
      "[EPOCH #17, step #2324] loss: 1.5628489378447175\n",
      "[EPOCH #17, step #2326] loss: 1.5627819327873687\n",
      "[EPOCH #17, step #2328] loss: 1.5627990758383208\n",
      "[EPOCH #17, step #2330] loss: 1.5627489750194017\n",
      "[EPOCH #17, step #2332] loss: 1.5630429765465839\n",
      "[EPOCH #17, step #2334] loss: 1.5628676846400062\n",
      "[EPOCH #17, step #2336] loss: 1.562801407451654\n",
      "[EPOCH #17, step #2338] loss: 1.562906244566625\n",
      "[EPOCH #17, step #2340] loss: 1.562833505122899\n",
      "[EPOCH #17, step #2342] loss: 1.562596076429272\n",
      "[EPOCH #17, step #2344] loss: 1.5628144590076862\n",
      "[EPOCH #17, step #2346] loss: 1.563104058866253\n",
      "[EPOCH #17, step #2348] loss: 1.5631973095374596\n",
      "[EPOCH #17, step #2350] loss: 1.5632451529809133\n",
      "[EPOCH #17, step #2352] loss: 1.5631876964544773\n",
      "[EPOCH #17, step #2354] loss: 1.563164265646803\n",
      "[EPOCH #17, step #2356] loss: 1.5634624386015816\n",
      "[EPOCH #17, step #2358] loss: 1.5635430270607769\n",
      "[EPOCH #17, step #2360] loss: 1.5634451958649445\n",
      "[EPOCH #17, step #2362] loss: 1.5634930850689663\n",
      "[EPOCH #17, step #2364] loss: 1.5634147175774766\n",
      "[EPOCH #17, step #2366] loss: 1.5632406485750547\n",
      "[EPOCH #17, step #2368] loss: 1.5632544007166471\n",
      "[EPOCH #17, step #2370] loss: 1.5629289894856164\n",
      "[EPOCH #17, step #2372] loss: 1.562966810968723\n",
      "[EPOCH #17, step #2374] loss: 1.5628771172071758\n",
      "[EPOCH #17, step #2376] loss: 1.5629792274122836\n",
      "[EPOCH #17, step #2378] loss: 1.5626788399910014\n",
      "[EPOCH #17, step #2380] loss: 1.5626006448834646\n",
      "[EPOCH #17, step #2382] loss: 1.5628136099760541\n",
      "[EPOCH #17, step #2384] loss: 1.562925132815443\n",
      "[EPOCH #17, step #2386] loss: 1.5626674176361155\n",
      "[EPOCH #17, step #2388] loss: 1.562930310655708\n",
      "[EPOCH #17, step #2390] loss: 1.5627522851472517\n",
      "[EPOCH #17, step #2392] loss: 1.5632002805497822\n",
      "[EPOCH #17, step #2394] loss: 1.5630229715514532\n",
      "[EPOCH #17, step #2396] loss: 1.5628413659212337\n",
      "[EPOCH #17, step #2398] loss: 1.5627890122637444\n",
      "[EPOCH #17, step #2400] loss: 1.5627216247159805\n",
      "[EPOCH #17, step #2402] loss: 1.5628603230502969\n",
      "[EPOCH #17, step #2404] loss: 1.562793720388115\n",
      "[EPOCH #17, step #2406] loss: 1.5629491142380718\n",
      "[EPOCH #17, step #2408] loss: 1.5630647095470025\n",
      "[EPOCH #17, step #2410] loss: 1.5628253351549348\n",
      "[EPOCH #17, step #2412] loss: 1.5625712779662049\n",
      "[EPOCH #17, step #2414] loss: 1.5624185871140064\n",
      "[EPOCH #17, step #2416] loss: 1.5625564068568163\n",
      "[EPOCH #17, step #2418] loss: 1.5625172210853422\n",
      "[EPOCH #17, step #2420] loss: 1.5624961654591394\n",
      "[EPOCH #17, step #2422] loss: 1.5625494653116905\n",
      "[EPOCH #17, step #2424] loss: 1.56253844949388\n",
      "[EPOCH #17, step #2426] loss: 1.562791772766962\n",
      "[EPOCH #17, step #2428] loss: 1.5629693160777527\n",
      "[EPOCH #17, step #2430] loss: 1.5627054043730215\n",
      "[EPOCH #17, step #2432] loss: 1.562634180124238\n",
      "[EPOCH #17, step #2434] loss: 1.5627592132321617\n",
      "[EPOCH #17, step #2436] loss: 1.562717242518751\n",
      "[EPOCH #17, step #2438] loss: 1.562564053512001\n",
      "[EPOCH #17, step #2440] loss: 1.562705158210592\n",
      "[EPOCH #17, step #2442] loss: 1.5627162715620648\n",
      "[EPOCH #17, step #2444] loss: 1.5626109301678242\n",
      "[EPOCH #17, step #2446] loss: 1.5625455492508378\n",
      "[EPOCH #17, step #2448] loss: 1.5625505358796064\n",
      "[EPOCH #17, step #2450] loss: 1.5627890239682114\n",
      "[EPOCH #17, step #2452] loss: 1.5627982169814951\n",
      "[EPOCH #17, step #2454] loss: 1.5629241193142054\n",
      "[EPOCH #17, step #2456] loss: 1.5628249893161306\n",
      "[EPOCH #17, step #2458] loss: 1.5628288355044302\n",
      "[EPOCH #17, step #2460] loss: 1.5627127189260341\n",
      "[EPOCH #17, step #2462] loss: 1.562622721196189\n",
      "[EPOCH #17, step #2464] loss: 1.5625999583675703\n",
      "[EPOCH #17, step #2466] loss: 1.5624777912175458\n",
      "[EPOCH #17, step #2468] loss: 1.5624131932341652\n",
      "[EPOCH #17, step #2470] loss: 1.562530665781661\n",
      "[EPOCH #17, step #2472] loss: 1.562417039493294\n",
      "[EPOCH #17, step #2474] loss: 1.5623124019064085\n",
      "[EPOCH #17, step #2476] loss: 1.5620781272758049\n",
      "[EPOCH #17, step #2478] loss: 1.5622026375485505\n",
      "[EPOCH #17, step #2480] loss: 1.5619939321570222\n",
      "[EPOCH #17, step #2482] loss: 1.5622543351476441\n",
      "[EPOCH #17, step #2484] loss: 1.562357076552792\n",
      "[EPOCH #17, step #2486] loss: 1.5623327069940172\n",
      "[EPOCH #17, step #2488] loss: 1.5622452151205417\n",
      "[EPOCH #17, step #2490] loss: 1.5622606888108348\n",
      "[EPOCH #17, step #2492] loss: 1.5624143863078155\n",
      "[EPOCH #17, step #2494] loss: 1.562657420525331\n",
      "[EPOCH #17, step #2496] loss: 1.562451892439537\n",
      "[EPOCH #17, step #2498] loss: 1.5625576155812515\n",
      "[EPOCH #17, elapsed time: 8662.021[sec]] loss: 1.5624875242710115\n",
      "[EPOCH #18, step #0] loss: 1.5266653299331665\n",
      "[EPOCH #18, step #2] loss: 1.5200337966283162\n",
      "[EPOCH #18, step #4] loss: 1.4907796144485475\n",
      "[EPOCH #18, step #6] loss: 1.5483455317361015\n",
      "[EPOCH #18, step #8] loss: 1.4772643380694919\n",
      "[EPOCH #18, step #10] loss: 1.5437207872217351\n",
      "[EPOCH #18, step #12] loss: 1.55101988865779\n",
      "[EPOCH #18, step #14] loss: 1.5692652146021524\n",
      "[EPOCH #18, step #16] loss: 1.5499291980967802\n",
      "[EPOCH #18, step #18] loss: 1.5484523898676823\n",
      "[EPOCH #18, step #20] loss: 1.5526750144504367\n",
      "[EPOCH #18, step #22] loss: 1.5302544780399487\n",
      "[EPOCH #18, step #24] loss: 1.5145793390274047\n",
      "[EPOCH #18, step #26] loss: 1.4961738763032135\n",
      "[EPOCH #18, step #28] loss: 1.488828679610943\n",
      "[EPOCH #18, step #30] loss: 1.5021944507475822\n",
      "[EPOCH #18, step #32] loss: 1.512276468854962\n",
      "[EPOCH #18, step #34] loss: 1.5025142329079764\n",
      "[EPOCH #18, step #36] loss: 1.5339640088983484\n",
      "[EPOCH #18, step #38] loss: 1.528142776244726\n",
      "[EPOCH #18, step #40] loss: 1.5335824809423306\n",
      "[EPOCH #18, step #42] loss: 1.5467812238737595\n",
      "[EPOCH #18, step #44] loss: 1.5413122256596883\n",
      "[EPOCH #18, step #46] loss: 1.530054769617446\n",
      "[EPOCH #18, step #48] loss: 1.5254491786567532\n",
      "[EPOCH #18, step #50] loss: 1.5229944177702361\n",
      "[EPOCH #18, step #52] loss: 1.5322393786232427\n",
      "[EPOCH #18, step #54] loss: 1.516656255722046\n",
      "[EPOCH #18, step #56] loss: 1.5171202630327458\n",
      "[EPOCH #18, step #58] loss: 1.5133360947592784\n",
      "[EPOCH #18, step #60] loss: 1.5262529537326\n",
      "[EPOCH #18, step #62] loss: 1.5245487368296062\n",
      "[EPOCH #18, step #64] loss: 1.520729395059439\n",
      "[EPOCH #18, step #66] loss: 1.5236831013836079\n",
      "[EPOCH #18, step #68] loss: 1.5183498842128809\n",
      "[EPOCH #18, step #70] loss: 1.5196071090832564\n",
      "[EPOCH #18, step #72] loss: 1.5165489683412525\n",
      "[EPOCH #18, step #74] loss: 1.51541081905365\n",
      "[EPOCH #18, step #76] loss: 1.5166307083972088\n",
      "[EPOCH #18, step #78] loss: 1.5176314658756498\n",
      "[EPOCH #18, step #80] loss: 1.5191958377390733\n",
      "[EPOCH #18, step #82] loss: 1.5167363537363259\n",
      "[EPOCH #18, step #84] loss: 1.5173137552597944\n",
      "[EPOCH #18, step #86] loss: 1.5198497251532543\n",
      "[EPOCH #18, step #88] loss: 1.5241733695683854\n",
      "[EPOCH #18, step #90] loss: 1.5168601759187468\n",
      "[EPOCH #18, step #92] loss: 1.509365968165859\n",
      "[EPOCH #18, step #94] loss: 1.5066958283123217\n",
      "[EPOCH #18, step #96] loss: 1.508565414197666\n",
      "[EPOCH #18, step #98] loss: 1.5126318094706295\n",
      "[EPOCH #18, step #100] loss: 1.512555200864773\n",
      "[EPOCH #18, step #102] loss: 1.5126337756230994\n",
      "[EPOCH #18, step #104] loss: 1.5028470521881467\n",
      "[EPOCH #18, step #106] loss: 1.5013003377156837\n",
      "[EPOCH #18, step #108] loss: 1.5016672004253493\n",
      "[EPOCH #18, step #110] loss: 1.5042234986752003\n",
      "[EPOCH #18, step #112] loss: 1.500955138058789\n",
      "[EPOCH #18, step #114] loss: 1.4944236573965652\n",
      "[EPOCH #18, step #116] loss: 1.4936939218105414\n",
      "[EPOCH #18, step #118] loss: 1.4926316402539486\n",
      "[EPOCH #18, step #120] loss: 1.492556965548145\n",
      "[EPOCH #18, step #122] loss: 1.4912086914225322\n",
      "[EPOCH #18, step #124] loss: 1.4891445927619935\n",
      "[EPOCH #18, step #126] loss: 1.490050738721382\n",
      "[EPOCH #18, step #128] loss: 1.4932649657707806\n",
      "[EPOCH #18, step #130] loss: 1.488132253402972\n",
      "[EPOCH #18, step #132] loss: 1.4869377330729836\n",
      "[EPOCH #18, step #134] loss: 1.4894303644144977\n",
      "[EPOCH #18, step #136] loss: 1.49114031556749\n",
      "[EPOCH #18, step #138] loss: 1.490740137563335\n",
      "[EPOCH #18, step #140] loss: 1.4852779888092202\n",
      "[EPOCH #18, step #142] loss: 1.4811926213177768\n",
      "[EPOCH #18, step #144] loss: 1.482291002109133\n",
      "[EPOCH #18, step #146] loss: 1.4808292315930736\n",
      "[EPOCH #18, step #148] loss: 1.4782794009919134\n",
      "[EPOCH #18, step #150] loss: 1.4797242035139475\n",
      "[EPOCH #18, step #152] loss: 1.4749876615268733\n",
      "[EPOCH #18, step #154] loss: 1.4750571731598145\n",
      "[EPOCH #18, step #156] loss: 1.4732164672225903\n",
      "[EPOCH #18, step #158] loss: 1.4730719466629267\n",
      "[EPOCH #18, step #160] loss: 1.4727454840766718\n",
      "[EPOCH #18, step #162] loss: 1.4699933708079753\n",
      "[EPOCH #18, step #164] loss: 1.4684310028047272\n",
      "[EPOCH #18, step #166] loss: 1.4695660015066228\n",
      "[EPOCH #18, step #168] loss: 1.4693824331435932\n",
      "[EPOCH #18, step #170] loss: 1.4664872682582566\n",
      "[EPOCH #18, step #172] loss: 1.4667400693617805\n",
      "[EPOCH #18, step #174] loss: 1.466194658960615\n",
      "[EPOCH #18, step #176] loss: 1.4670614643959001\n",
      "[EPOCH #18, step #178] loss: 1.4637936307065313\n",
      "[EPOCH #18, step #180] loss: 1.4625399968900734\n",
      "[EPOCH #18, step #182] loss: 1.465503209927043\n",
      "[EPOCH #18, step #184] loss: 1.4648332666706394\n",
      "[EPOCH #18, step #186] loss: 1.464460273477483\n",
      "[EPOCH #18, step #188] loss: 1.4675549867922666\n",
      "[EPOCH #18, step #190] loss: 1.4681705960428528\n",
      "[EPOCH #18, step #192] loss: 1.4663330625375934\n",
      "[EPOCH #18, step #194] loss: 1.469607322032635\n",
      "[EPOCH #18, step #196] loss: 1.4750608623330363\n",
      "[EPOCH #18, step #198] loss: 1.4726593248808204\n",
      "[EPOCH #18, step #200] loss: 1.472551593733071\n",
      "[EPOCH #18, step #202] loss: 1.4748478763796427\n",
      "[EPOCH #18, step #204] loss: 1.4754484938412178\n",
      "[EPOCH #18, step #206] loss: 1.4727108662831034\n",
      "[EPOCH #18, step #208] loss: 1.4693760940332732\n",
      "[EPOCH #18, step #210] loss: 1.4669963889777378\n",
      "[EPOCH #18, step #212] loss: 1.4672057057770205\n",
      "[EPOCH #18, step #214] loss: 1.466407829661702\n",
      "[EPOCH #18, step #216] loss: 1.4648624889312252\n",
      "[EPOCH #18, step #218] loss: 1.4642050669073514\n",
      "[EPOCH #18, step #220] loss: 1.4618397827062133\n",
      "[EPOCH #18, step #222] loss: 1.4578840072379518\n",
      "[EPOCH #18, step #224] loss: 1.4624974772665236\n",
      "[EPOCH #18, step #226] loss: 1.4627600002393848\n",
      "[EPOCH #18, step #228] loss: 1.464066808140434\n",
      "[EPOCH #18, step #230] loss: 1.461361075634564\n",
      "[EPOCH #18, step #232] loss: 1.4592679649463538\n",
      "[EPOCH #18, step #234] loss: 1.459087546074644\n",
      "[EPOCH #18, step #236] loss: 1.4606260420903878\n",
      "[EPOCH #18, step #238] loss: 1.4586876363933834\n",
      "[EPOCH #18, step #240] loss: 1.4596225461029908\n",
      "[EPOCH #18, step #242] loss: 1.4582428522561313\n",
      "[EPOCH #18, step #244] loss: 1.4585996912450208\n",
      "[EPOCH #18, step #246] loss: 1.4584843352256034\n",
      "[EPOCH #18, step #248] loss: 1.459089437881148\n",
      "[EPOCH #18, step #250] loss: 1.457085322811309\n",
      "[EPOCH #18, step #252] loss: 1.4574915733733196\n",
      "[EPOCH #18, step #254] loss: 1.4557816105730392\n",
      "[EPOCH #18, step #256] loss: 1.453261437814987\n",
      "[EPOCH #18, step #258] loss: 1.4505906461748836\n",
      "[EPOCH #18, step #260] loss: 1.4491431751927197\n",
      "[EPOCH #18, step #262] loss: 1.4503854053102065\n",
      "[EPOCH #18, step #264] loss: 1.450168133456752\n",
      "[EPOCH #18, step #266] loss: 1.4502455601084991\n",
      "[EPOCH #18, step #268] loss: 1.4531210073751144\n",
      "[EPOCH #18, step #270] loss: 1.451691336957291\n",
      "[EPOCH #18, step #272] loss: 1.4509271887632518\n",
      "[EPOCH #18, step #274] loss: 1.4519871705228633\n",
      "[EPOCH #18, step #276] loss: 1.4515543937252746\n",
      "[EPOCH #18, step #278] loss: 1.4530325775505395\n",
      "[EPOCH #18, step #280] loss: 1.4527736382552314\n",
      "[EPOCH #18, step #282] loss: 1.450033652066342\n",
      "[EPOCH #18, step #284] loss: 1.4501017629054556\n",
      "[EPOCH #18, step #286] loss: 1.4495984731235572\n",
      "[EPOCH #18, step #288] loss: 1.449926772744598\n",
      "[EPOCH #18, step #290] loss: 1.4518090023617565\n",
      "[EPOCH #18, step #292] loss: 1.449323460917424\n",
      "[EPOCH #18, step #294] loss: 1.4473356036816614\n",
      "[EPOCH #18, step #296] loss: 1.4481413577140783\n",
      "[EPOCH #18, step #298] loss: 1.4477754217326442\n",
      "[EPOCH #18, step #300] loss: 1.4479040204488558\n",
      "[EPOCH #18, step #302] loss: 1.448413334270515\n",
      "[EPOCH #18, step #304] loss: 1.4482861401604825\n",
      "[EPOCH #18, step #306] loss: 1.4492442037072943\n",
      "[EPOCH #18, step #308] loss: 1.4495381278899109\n",
      "[EPOCH #18, step #310] loss: 1.4497304717827457\n",
      "[EPOCH #18, step #312] loss: 1.451790613107407\n",
      "[EPOCH #18, step #314] loss: 1.4527496924476018\n",
      "[EPOCH #18, step #316] loss: 1.4526501672125014\n",
      "[EPOCH #18, step #318] loss: 1.4533155155032407\n",
      "[EPOCH #18, step #320] loss: 1.4526509822714737\n",
      "[EPOCH #18, step #322] loss: 1.4531829759432435\n",
      "[EPOCH #18, step #324] loss: 1.4559880916888897\n",
      "[EPOCH #18, step #326] loss: 1.4551559059627195\n",
      "[EPOCH #18, step #328] loss: 1.4555463801763702\n",
      "[EPOCH #18, step #330] loss: 1.455326945039801\n",
      "[EPOCH #18, step #332] loss: 1.4561037727304407\n",
      "[EPOCH #18, step #334] loss: 1.4558871660659563\n",
      "[EPOCH #18, step #336] loss: 1.4543996943210635\n",
      "[EPOCH #18, step #338] loss: 1.4549955516438218\n",
      "[EPOCH #18, step #340] loss: 1.4562277356900077\n",
      "[EPOCH #18, step #342] loss: 1.4558296290500519\n",
      "[EPOCH #18, step #344] loss: 1.4555638513703277\n",
      "[EPOCH #18, step #346] loss: 1.454988692610683\n",
      "[EPOCH #18, step #348] loss: 1.4558563126533968\n",
      "[EPOCH #18, step #350] loss: 1.4566768074986602\n",
      "[EPOCH #18, step #352] loss: 1.4569520170222598\n",
      "[EPOCH #18, step #354] loss: 1.4559993270417335\n",
      "[EPOCH #18, step #356] loss: 1.4563364371532153\n",
      "[EPOCH #18, step #358] loss: 1.4558524650451532\n",
      "[EPOCH #18, step #360] loss: 1.4561292887394448\n",
      "[EPOCH #18, step #362] loss: 1.4554871892140917\n",
      "[EPOCH #18, step #364] loss: 1.456348229760993\n",
      "[EPOCH #18, step #366] loss: 1.4578619094245766\n",
      "[EPOCH #18, step #368] loss: 1.457933926970009\n",
      "[EPOCH #18, step #370] loss: 1.4583230725517171\n",
      "[EPOCH #18, step #372] loss: 1.457951739070882\n",
      "[EPOCH #18, step #374] loss: 1.4576597318649291\n",
      "[EPOCH #18, step #376] loss: 1.4563548745147745\n",
      "[EPOCH #18, step #378] loss: 1.4569296361903088\n",
      "[EPOCH #18, step #380] loss: 1.458299112132215\n",
      "[EPOCH #18, step #382] loss: 1.4567681333103628\n",
      "[EPOCH #18, step #384] loss: 1.457824283451229\n",
      "[EPOCH #18, step #386] loss: 1.4573187057978114\n",
      "[EPOCH #18, step #388] loss: 1.4590186230014712\n",
      "[EPOCH #18, step #390] loss: 1.4595079781759122\n",
      "[EPOCH #18, step #392] loss: 1.4593837707097295\n",
      "[EPOCH #18, step #394] loss: 1.4605047787292094\n",
      "[EPOCH #18, step #396] loss: 1.45981507757749\n",
      "[EPOCH #18, step #398] loss: 1.4595942189520164\n",
      "[EPOCH #18, step #400] loss: 1.4604059963154972\n",
      "[EPOCH #18, step #402] loss: 1.4611657213040676\n",
      "[EPOCH #18, step #404] loss: 1.4602693822648791\n",
      "[EPOCH #18, step #406] loss: 1.4604930327038215\n",
      "[EPOCH #18, step #408] loss: 1.4609563857827035\n",
      "[EPOCH #18, step #410] loss: 1.4600698715868947\n",
      "[EPOCH #18, step #412] loss: 1.4598373318988531\n",
      "[EPOCH #18, step #414] loss: 1.4595301085207835\n",
      "[EPOCH #18, step #416] loss: 1.4590626054530522\n",
      "[EPOCH #18, step #418] loss: 1.4598155886574975\n",
      "[EPOCH #18, step #420] loss: 1.459310304099194\n",
      "[EPOCH #18, step #422] loss: 1.4593879278951785\n",
      "[EPOCH #18, step #424] loss: 1.4600272833599763\n",
      "[EPOCH #18, step #426] loss: 1.4603820080221117\n",
      "[EPOCH #18, step #428] loss: 1.458932170223245\n",
      "[EPOCH #18, step #430] loss: 1.4578169011737796\n",
      "[EPOCH #18, step #432] loss: 1.45635484864475\n",
      "[EPOCH #18, step #434] loss: 1.4566494707403512\n",
      "[EPOCH #18, step #436] loss: 1.4579338090370666\n",
      "[EPOCH #18, step #438] loss: 1.4579809680071942\n",
      "[EPOCH #18, step #440] loss: 1.458336473727713\n",
      "[EPOCH #18, step #442] loss: 1.4590789231705072\n",
      "[EPOCH #18, step #444] loss: 1.4583659031417933\n",
      "[EPOCH #18, step #446] loss: 1.4578991377647024\n",
      "[EPOCH #18, step #448] loss: 1.45759012239813\n",
      "[EPOCH #18, step #450] loss: 1.4575717778269308\n",
      "[EPOCH #18, step #452] loss: 1.4575734976637968\n",
      "[EPOCH #18, step #454] loss: 1.457895373381101\n",
      "[EPOCH #18, step #456] loss: 1.4590102271125927\n",
      "[EPOCH #18, step #458] loss: 1.4592571275426411\n",
      "[EPOCH #18, step #460] loss: 1.4600039033982863\n",
      "[EPOCH #18, step #462] loss: 1.4607469102218908\n",
      "[EPOCH #18, step #464] loss: 1.4615221165841625\n",
      "[EPOCH #18, step #466] loss: 1.461824293693077\n",
      "[EPOCH #18, step #468] loss: 1.4615704178301765\n",
      "[EPOCH #18, step #470] loss: 1.4622389203423907\n",
      "[EPOCH #18, step #472] loss: 1.4625253192214078\n",
      "[EPOCH #18, step #474] loss: 1.462384276766526\n",
      "[EPOCH #18, step #476] loss: 1.4619815988110796\n",
      "[EPOCH #18, step #478] loss: 1.4619356723568384\n",
      "[EPOCH #18, step #480] loss: 1.4616116234517642\n",
      "[EPOCH #18, step #482] loss: 1.4619330902030503\n",
      "[EPOCH #18, step #484] loss: 1.4618587527078453\n",
      "[EPOCH #18, step #486] loss: 1.4615429046217665\n",
      "[EPOCH #18, step #488] loss: 1.460044833170612\n",
      "[EPOCH #18, step #490] loss: 1.4584747920696701\n",
      "[EPOCH #18, step #492] loss: 1.4598464795348611\n",
      "[EPOCH #18, step #494] loss: 1.4610469643515769\n",
      "[EPOCH #18, step #496] loss: 1.4615697300649984\n",
      "[EPOCH #18, step #498] loss: 1.4619774994009243\n",
      "[EPOCH #18, step #500] loss: 1.460581152025097\n",
      "[EPOCH #18, step #502] loss: 1.4603944267951707\n",
      "[EPOCH #18, step #504] loss: 1.4609581288724842\n",
      "[EPOCH #18, step #506] loss: 1.4614322150247336\n",
      "[EPOCH #18, step #508] loss: 1.4616333353964426\n",
      "[EPOCH #18, step #510] loss: 1.4597484476412346\n",
      "[EPOCH #18, step #512] loss: 1.4594792031172887\n",
      "[EPOCH #18, step #514] loss: 1.4595779896939842\n",
      "[EPOCH #18, step #516] loss: 1.459802966860323\n",
      "[EPOCH #18, step #518] loss: 1.4602112794198052\n",
      "[EPOCH #18, step #520] loss: 1.4598113176003527\n",
      "[EPOCH #18, step #522] loss: 1.4588987579993036\n",
      "[EPOCH #18, step #524] loss: 1.4585657484190804\n",
      "[EPOCH #18, step #526] loss: 1.4586935557948117\n",
      "[EPOCH #18, step #528] loss: 1.4592003879790496\n",
      "[EPOCH #18, step #530] loss: 1.4596689181812739\n",
      "[EPOCH #18, step #532] loss: 1.4596714681577057\n",
      "[EPOCH #18, step #534] loss: 1.4601273323887975\n",
      "[EPOCH #18, step #536] loss: 1.4597416992960028\n",
      "[EPOCH #18, step #538] loss: 1.4596416130800194\n",
      "[EPOCH #18, step #540] loss: 1.4607473112739169\n",
      "[EPOCH #18, step #542] loss: 1.4601441978530112\n",
      "[EPOCH #18, step #544] loss: 1.460649934274341\n",
      "[EPOCH #18, step #546] loss: 1.4600306730819577\n",
      "[EPOCH #18, step #548] loss: 1.4608199022072477\n",
      "[EPOCH #18, step #550] loss: 1.4605020264099384\n",
      "[EPOCH #18, step #552] loss: 1.4601598612654274\n",
      "[EPOCH #18, step #554] loss: 1.4602493332312987\n",
      "[EPOCH #18, step #556] loss: 1.4601846701152876\n",
      "[EPOCH #18, step #558] loss: 1.4611008739855293\n",
      "[EPOCH #18, step #560] loss: 1.4623093306487045\n",
      "[EPOCH #18, step #562] loss: 1.462604939725852\n",
      "[EPOCH #18, step #564] loss: 1.4634584999717442\n",
      "[EPOCH #18, step #566] loss: 1.463547420354537\n",
      "[EPOCH #18, step #568] loss: 1.46206502074307\n",
      "[EPOCH #18, step #570] loss: 1.4624208889366657\n",
      "[EPOCH #18, step #572] loss: 1.4622337871197006\n",
      "[EPOCH #18, step #574] loss: 1.4643062702469203\n",
      "[EPOCH #18, step #576] loss: 1.464977282895166\n",
      "[EPOCH #18, step #578] loss: 1.4656487974066397\n",
      "[EPOCH #18, step #580] loss: 1.466586178325745\n",
      "[EPOCH #18, step #582] loss: 1.466579822794651\n",
      "[EPOCH #18, step #584] loss: 1.4665180806420808\n",
      "[EPOCH #18, step #586] loss: 1.4665640232104054\n",
      "[EPOCH #18, step #588] loss: 1.4661701018012845\n",
      "[EPOCH #18, step #590] loss: 1.4660684115390488\n",
      "[EPOCH #18, step #592] loss: 1.4655938153524222\n",
      "[EPOCH #18, step #594] loss: 1.4649965912354093\n",
      "[EPOCH #18, step #596] loss: 1.4655553365073213\n",
      "[EPOCH #18, step #598] loss: 1.466760526017872\n",
      "[EPOCH #18, step #600] loss: 1.4665076820901943\n",
      "[EPOCH #18, step #602] loss: 1.4661677297865772\n",
      "[EPOCH #18, step #604] loss: 1.4666734432385973\n",
      "[EPOCH #18, step #606] loss: 1.4684274138689435\n",
      "[EPOCH #18, step #608] loss: 1.4680503122325015\n",
      "[EPOCH #18, step #610] loss: 1.4677221549708401\n",
      "[EPOCH #18, step #612] loss: 1.4674363094480742\n",
      "[EPOCH #18, step #614] loss: 1.467993484570728\n",
      "[EPOCH #18, step #616] loss: 1.4675441136043308\n",
      "[EPOCH #18, step #618] loss: 1.4690794384344714\n",
      "[EPOCH #18, step #620] loss: 1.4692939923005404\n",
      "[EPOCH #18, step #622] loss: 1.4694101630588978\n",
      "[EPOCH #18, step #624] loss: 1.4694446102142333\n",
      "[EPOCH #18, step #626] loss: 1.469904173314096\n",
      "[EPOCH #18, step #628] loss: 1.4697191501080706\n",
      "[EPOCH #18, step #630] loss: 1.4701847678696864\n",
      "[EPOCH #18, step #632] loss: 1.4707739155439403\n",
      "[EPOCH #18, step #634] loss: 1.470363413442777\n",
      "[EPOCH #18, step #636] loss: 1.4703777128336382\n",
      "[EPOCH #18, step #638] loss: 1.4708215248230292\n",
      "[EPOCH #18, step #640] loss: 1.4703368350235795\n",
      "[EPOCH #18, step #642] loss: 1.4706826625307834\n",
      "[EPOCH #18, step #644] loss: 1.4696073016455007\n",
      "[EPOCH #18, step #646] loss: 1.4691759954095809\n",
      "[EPOCH #18, step #648] loss: 1.469623312009685\n",
      "[EPOCH #18, step #650] loss: 1.4698865679185695\n",
      "[EPOCH #18, step #652] loss: 1.4706600420690423\n",
      "[EPOCH #18, step #654] loss: 1.4711626587933258\n",
      "[EPOCH #18, step #656] loss: 1.4712238870617824\n",
      "[EPOCH #18, step #658] loss: 1.4708490315626894\n",
      "[EPOCH #18, step #660] loss: 1.470827151715485\n",
      "[EPOCH #18, step #662] loss: 1.4703981590486759\n",
      "[EPOCH #18, step #664] loss: 1.4704495772383266\n",
      "[EPOCH #18, step #666] loss: 1.46997741423268\n",
      "[EPOCH #18, step #668] loss: 1.46999257295121\n",
      "[EPOCH #18, step #670] loss: 1.470424495048921\n",
      "[EPOCH #18, step #672] loss: 1.4700081601716788\n",
      "[EPOCH #18, step #674] loss: 1.4702183910652442\n",
      "[EPOCH #18, step #676] loss: 1.4701611824894938\n",
      "[EPOCH #18, step #678] loss: 1.470232372255845\n",
      "[EPOCH #18, step #680] loss: 1.46976392507203\n",
      "[EPOCH #18, step #682] loss: 1.4701405983543676\n",
      "[EPOCH #18, step #684] loss: 1.4708046309269258\n",
      "[EPOCH #18, step #686] loss: 1.4709651248076772\n",
      "[EPOCH #18, step #688] loss: 1.470641998836368\n",
      "[EPOCH #18, step #690] loss: 1.4705468605982757\n",
      "[EPOCH #18, step #692] loss: 1.4696135256025527\n",
      "[EPOCH #18, step #694] loss: 1.4687665632302813\n",
      "[EPOCH #18, step #696] loss: 1.4691951746920089\n",
      "[EPOCH #18, step #698] loss: 1.468885860729627\n",
      "[EPOCH #18, step #700] loss: 1.4693303594575629\n",
      "[EPOCH #18, step #702] loss: 1.4691636696309487\n",
      "[EPOCH #18, step #704] loss: 1.4689367936858049\n",
      "[EPOCH #18, step #706] loss: 1.4684413615008223\n",
      "[EPOCH #18, step #708] loss: 1.468436765990237\n",
      "[EPOCH #18, step #710] loss: 1.4691291226784053\n",
      "[EPOCH #18, step #712] loss: 1.467931701040201\n",
      "[EPOCH #18, step #714] loss: 1.4680288127252272\n",
      "[EPOCH #18, step #716] loss: 1.4677176438116128\n",
      "[EPOCH #18, step #718] loss: 1.4675819169165196\n",
      "[EPOCH #18, step #720] loss: 1.4674192159417268\n",
      "[EPOCH #18, step #722] loss: 1.46742276334169\n",
      "[EPOCH #18, step #724] loss: 1.467129563956425\n",
      "[EPOCH #18, step #726] loss: 1.466809625474754\n",
      "[EPOCH #18, step #728] loss: 1.4663341611174072\n",
      "[EPOCH #18, step #730] loss: 1.4669385189559978\n",
      "[EPOCH #18, step #732] loss: 1.4661370240975207\n",
      "[EPOCH #18, step #734] loss: 1.4658146001854722\n",
      "[EPOCH #18, step #736] loss: 1.4670055407520226\n",
      "[EPOCH #18, step #738] loss: 1.4664083138531696\n",
      "[EPOCH #18, step #740] loss: 1.466111433168172\n",
      "[EPOCH #18, step #742] loss: 1.466308913513276\n",
      "[EPOCH #18, step #744] loss: 1.465645912989674\n",
      "[EPOCH #18, step #746] loss: 1.465878688028379\n",
      "[EPOCH #18, step #748] loss: 1.4662289979142722\n",
      "[EPOCH #18, step #750] loss: 1.4667860306055345\n",
      "[EPOCH #18, step #752] loss: 1.4658221101380915\n",
      "[EPOCH #18, step #754] loss: 1.4654811344399357\n",
      "[EPOCH #18, step #756] loss: 1.4662485048666971\n",
      "[EPOCH #18, step #758] loss: 1.4656410311521748\n",
      "[EPOCH #18, step #760] loss: 1.4659196335758706\n",
      "[EPOCH #18, step #762] loss: 1.465463151625537\n",
      "[EPOCH #18, step #764] loss: 1.465863408761866\n",
      "[EPOCH #18, step #766] loss: 1.4657547352677684\n",
      "[EPOCH #18, step #768] loss: 1.465917756250528\n",
      "[EPOCH #18, step #770] loss: 1.466387960233577\n",
      "[EPOCH #18, step #772] loss: 1.4666120807072787\n",
      "[EPOCH #18, step #774] loss: 1.465885989281439\n",
      "[EPOCH #18, step #776] loss: 1.4657624065492452\n",
      "[EPOCH #18, step #778] loss: 1.465495192346585\n",
      "[EPOCH #18, step #780] loss: 1.4661869456307073\n",
      "[EPOCH #18, step #782] loss: 1.466865194254908\n",
      "[EPOCH #18, step #784] loss: 1.4665260468318964\n",
      "[EPOCH #18, step #786] loss: 1.4661940210504787\n",
      "[EPOCH #18, step #788] loss: 1.4657835578132794\n",
      "[EPOCH #18, step #790] loss: 1.4663599642127865\n",
      "[EPOCH #18, step #792] loss: 1.4664574000152935\n",
      "[EPOCH #18, step #794] loss: 1.4667209281861406\n",
      "[EPOCH #18, step #796] loss: 1.4661556079965015\n",
      "[EPOCH #18, step #798] loss: 1.4654590353947856\n",
      "[EPOCH #18, step #800] loss: 1.4656676749016313\n",
      "[EPOCH #18, step #802] loss: 1.465488733419891\n",
      "[EPOCH #18, step #804] loss: 1.4666919659383548\n",
      "[EPOCH #18, step #806] loss: 1.466932613462616\n",
      "[EPOCH #18, step #808] loss: 1.4675698987633101\n",
      "[EPOCH #18, step #810] loss: 1.4672578634962936\n",
      "[EPOCH #18, step #812] loss: 1.4684834361516241\n",
      "[EPOCH #18, step #814] loss: 1.4691791288691796\n",
      "[EPOCH #18, step #816] loss: 1.4686558369177791\n",
      "[EPOCH #18, step #818] loss: 1.469115161342644\n",
      "[EPOCH #18, step #820] loss: 1.468603685915688\n",
      "[EPOCH #18, step #822] loss: 1.4682564361706685\n",
      "[EPOCH #18, step #824] loss: 1.4685450446966923\n",
      "[EPOCH #18, step #826] loss: 1.468569381061171\n",
      "[EPOCH #18, step #828] loss: 1.468484347059298\n",
      "[EPOCH #18, step #830] loss: 1.46801979461445\n",
      "[EPOCH #18, step #832] loss: 1.467518191806981\n",
      "[EPOCH #18, step #834] loss: 1.467514219826567\n",
      "[EPOCH #18, step #836] loss: 1.46742464051879\n",
      "[EPOCH #18, step #838] loss: 1.4681440286329448\n",
      "[EPOCH #18, step #840] loss: 1.4679824692173888\n",
      "[EPOCH #18, step #842] loss: 1.4686743886445341\n",
      "[EPOCH #18, step #844] loss: 1.469025953704789\n",
      "[EPOCH #18, step #846] loss: 1.469690965086116\n",
      "[EPOCH #18, step #848] loss: 1.4695375326525055\n",
      "[EPOCH #18, step #850] loss: 1.469224944658201\n",
      "[EPOCH #18, step #852] loss: 1.4682747388361208\n",
      "[EPOCH #18, step #854] loss: 1.4678625697978058\n",
      "[EPOCH #18, step #856] loss: 1.4682675682121287\n",
      "[EPOCH #18, step #858] loss: 1.4680372482128832\n",
      "[EPOCH #18, step #860] loss: 1.4679101514483994\n",
      "[EPOCH #18, step #862] loss: 1.4688923832715455\n",
      "[EPOCH #18, step #864] loss: 1.4691213879282075\n",
      "[EPOCH #18, step #866] loss: 1.4696529416201987\n",
      "[EPOCH #18, step #868] loss: 1.4700282293578697\n",
      "[EPOCH #18, step #870] loss: 1.4699894701709155\n",
      "[EPOCH #18, step #872] loss: 1.4700243736596998\n",
      "[EPOCH #18, step #874] loss: 1.4696432640893118\n",
      "[EPOCH #18, step #876] loss: 1.4691145221618862\n",
      "[EPOCH #18, step #878] loss: 1.4695042504656708\n",
      "[EPOCH #18, step #880] loss: 1.4694750759577238\n",
      "[EPOCH #18, step #882] loss: 1.4695408419871518\n",
      "[EPOCH #18, step #884] loss: 1.4696789306435882\n",
      "[EPOCH #18, step #886] loss: 1.469910652016572\n",
      "[EPOCH #18, step #888] loss: 1.4705015872809428\n",
      "[EPOCH #18, step #890] loss: 1.471467188311747\n",
      "[EPOCH #18, step #892] loss: 1.471395433950264\n",
      "[EPOCH #18, step #894] loss: 1.4712777333552611\n",
      "[EPOCH #18, step #896] loss: 1.4716298747620853\n",
      "[EPOCH #18, step #898] loss: 1.471331583512108\n",
      "[EPOCH #18, step #900] loss: 1.4712839246986973\n",
      "[EPOCH #18, step #902] loss: 1.4709056137936192\n",
      "[EPOCH #18, step #904] loss: 1.4704284216158956\n",
      "[EPOCH #18, step #906] loss: 1.4709104039308911\n",
      "[EPOCH #18, step #908] loss: 1.4710164441265026\n",
      "[EPOCH #18, step #910] loss: 1.4704134579416688\n",
      "[EPOCH #18, step #912] loss: 1.4699481515477024\n",
      "[EPOCH #18, step #914] loss: 1.4697341314430445\n",
      "[EPOCH #18, step #916] loss: 1.4695971590612031\n",
      "[EPOCH #18, step #918] loss: 1.4697141909365814\n",
      "[EPOCH #18, step #920] loss: 1.4694925417211493\n",
      "[EPOCH #18, step #922] loss: 1.4689047206778438\n",
      "[EPOCH #18, step #924] loss: 1.4681907620945491\n",
      "[EPOCH #18, step #926] loss: 1.4679416351848178\n",
      "[EPOCH #18, step #928] loss: 1.4677228929537105\n",
      "[EPOCH #18, step #930] loss: 1.46746267533584\n",
      "[EPOCH #18, step #932] loss: 1.4674766201042797\n",
      "[EPOCH #18, step #934] loss: 1.4667075314623788\n",
      "[EPOCH #18, step #936] loss: 1.4668665658066342\n",
      "[EPOCH #18, step #938] loss: 1.466976405903935\n",
      "[EPOCH #18, step #940] loss: 1.4670626891026715\n",
      "[EPOCH #18, step #942] loss: 1.4671601085495973\n",
      "[EPOCH #18, step #944] loss: 1.4665819466429413\n",
      "[EPOCH #18, step #946] loss: 1.4662759081866699\n",
      "[EPOCH #18, step #948] loss: 1.4664526624473555\n",
      "[EPOCH #18, step #950] loss: 1.466976698703445\n",
      "[EPOCH #18, step #952] loss: 1.4669030791564854\n",
      "[EPOCH #18, step #954] loss: 1.4671902335126987\n",
      "[EPOCH #18, step #956] loss: 1.467111208284412\n",
      "[EPOCH #18, step #958] loss: 1.4675935864199936\n",
      "[EPOCH #18, step #960] loss: 1.4674576435947517\n",
      "[EPOCH #18, step #962] loss: 1.466740005298567\n",
      "[EPOCH #18, step #964] loss: 1.4676456768278012\n",
      "[EPOCH #18, step #966] loss: 1.4670046339237208\n",
      "[EPOCH #18, step #968] loss: 1.4668435700414597\n",
      "[EPOCH #18, step #970] loss: 1.4660241309818107\n",
      "[EPOCH #18, step #972] loss: 1.4660711826915487\n",
      "[EPOCH #18, step #974] loss: 1.465757747124403\n",
      "[EPOCH #18, step #976] loss: 1.466121464510169\n",
      "[EPOCH #18, step #978] loss: 1.4669940535576522\n",
      "[EPOCH #18, step #980] loss: 1.4671579599988085\n",
      "[EPOCH #18, step #982] loss: 1.467014938562593\n",
      "[EPOCH #18, step #984] loss: 1.4671889904791933\n",
      "[EPOCH #18, step #986] loss: 1.4677904260315553\n",
      "[EPOCH #18, step #988] loss: 1.4678376558094584\n",
      "[EPOCH #18, step #990] loss: 1.4681011001108633\n",
      "[EPOCH #18, step #992] loss: 1.468210796154998\n",
      "[EPOCH #18, step #994] loss: 1.4683638273771085\n",
      "[EPOCH #18, step #996] loss: 1.4689705789746828\n",
      "[EPOCH #18, step #998] loss: 1.4688298954620018\n",
      "[EPOCH #18, step #1000] loss: 1.4684435263142124\n",
      "[EPOCH #18, step #1002] loss: 1.4687983896416181\n",
      "[EPOCH #18, step #1004] loss: 1.469133063513248\n",
      "[EPOCH #18, step #1006] loss: 1.4691358720060612\n",
      "[EPOCH #18, step #1008] loss: 1.4695289838538534\n",
      "[EPOCH #18, step #1010] loss: 1.4696831706133842\n",
      "[EPOCH #18, step #1012] loss: 1.4704993354250389\n",
      "[EPOCH #18, step #1014] loss: 1.4702505023021417\n",
      "[EPOCH #18, step #1016] loss: 1.4706142182547082\n",
      "[EPOCH #18, step #1018] loss: 1.4698048126943213\n",
      "[EPOCH #18, step #1020] loss: 1.469508039262456\n",
      "[EPOCH #18, step #1022] loss: 1.469310938671071\n",
      "[EPOCH #18, step #1024] loss: 1.4698974954791186\n",
      "[EPOCH #18, step #1026] loss: 1.4703020758150616\n",
      "[EPOCH #18, step #1028] loss: 1.4698452093395014\n",
      "[EPOCH #18, step #1030] loss: 1.469791341822316\n",
      "[EPOCH #18, step #1032] loss: 1.4696543089764162\n",
      "[EPOCH #18, step #1034] loss: 1.4696530778626888\n",
      "[EPOCH #18, step #1036] loss: 1.4697965933018964\n",
      "[EPOCH #18, step #1038] loss: 1.4699070350382624\n",
      "[EPOCH #18, step #1040] loss: 1.4698436379318165\n",
      "[EPOCH #18, step #1042] loss: 1.4698797691817023\n",
      "[EPOCH #18, step #1044] loss: 1.469436449525459\n",
      "[EPOCH #18, step #1046] loss: 1.4703172700339082\n",
      "[EPOCH #18, step #1048] loss: 1.4701811684893926\n",
      "[EPOCH #18, step #1050] loss: 1.4700461488241927\n",
      "[EPOCH #18, step #1052] loss: 1.4704404534437718\n",
      "[EPOCH #18, step #1054] loss: 1.4701795204555819\n",
      "[EPOCH #18, step #1056] loss: 1.4700290923876478\n",
      "[EPOCH #18, step #1058] loss: 1.4704478089262338\n",
      "[EPOCH #18, step #1060] loss: 1.4705961099443965\n",
      "[EPOCH #18, step #1062] loss: 1.4704510457428244\n",
      "[EPOCH #18, step #1064] loss: 1.4700717727343242\n",
      "[EPOCH #18, step #1066] loss: 1.4696669495876638\n",
      "[EPOCH #18, step #1068] loss: 1.4692566686974606\n",
      "[EPOCH #18, step #1070] loss: 1.4693295129763535\n",
      "[EPOCH #18, step #1072] loss: 1.4692542670713\n",
      "[EPOCH #18, step #1074] loss: 1.4693455132772757\n",
      "[EPOCH #18, step #1076] loss: 1.4693439518176745\n",
      "[EPOCH #18, step #1078] loss: 1.4695266972436631\n",
      "[EPOCH #18, step #1080] loss: 1.4699630697605017\n",
      "[EPOCH #18, step #1082] loss: 1.4697790957113603\n",
      "[EPOCH #18, step #1084] loss: 1.4699856967969973\n",
      "[EPOCH #18, step #1086] loss: 1.469879673836751\n",
      "[EPOCH #18, step #1088] loss: 1.4697184269312218\n",
      "[EPOCH #18, step #1090] loss: 1.4705106305158215\n",
      "[EPOCH #18, step #1092] loss: 1.4700460593196523\n",
      "[EPOCH #18, step #1094] loss: 1.470319815531169\n",
      "[EPOCH #18, step #1096] loss: 1.4699152523317225\n",
      "[EPOCH #18, step #1098] loss: 1.4693605563551648\n",
      "[EPOCH #18, step #1100] loss: 1.469042982868884\n",
      "[EPOCH #18, step #1102] loss: 1.4691107795115286\n",
      "[EPOCH #18, step #1104] loss: 1.4694258164496443\n",
      "[EPOCH #18, step #1106] loss: 1.4700940535105125\n",
      "[EPOCH #18, step #1108] loss: 1.4704390253646618\n",
      "[EPOCH #18, step #1110] loss: 1.4702708760861551\n",
      "[EPOCH #18, step #1112] loss: 1.4704594425756654\n",
      "[EPOCH #18, step #1114] loss: 1.4705069045849446\n",
      "[EPOCH #18, step #1116] loss: 1.4707984488887667\n",
      "[EPOCH #18, step #1118] loss: 1.4708545617060111\n",
      "[EPOCH #18, step #1120] loss: 1.4713950600611323\n",
      "[EPOCH #18, step #1122] loss: 1.4711512880248887\n",
      "[EPOCH #18, step #1124] loss: 1.4714431121614244\n",
      "[EPOCH #18, step #1126] loss: 1.4713398095455017\n",
      "[EPOCH #18, step #1128] loss: 1.4710782940563003\n",
      "[EPOCH #18, step #1130] loss: 1.470956731011233\n",
      "[EPOCH #18, step #1132] loss: 1.4704895575069687\n",
      "[EPOCH #18, step #1134] loss: 1.4709443604893622\n",
      "[EPOCH #18, step #1136] loss: 1.4707039457302715\n",
      "[EPOCH #18, step #1138] loss: 1.4707363430505473\n",
      "[EPOCH #18, step #1140] loss: 1.4701480957419073\n",
      "[EPOCH #18, step #1142] loss: 1.4703977559599455\n",
      "[EPOCH #18, step #1144] loss: 1.4698741715027255\n",
      "[EPOCH #18, step #1146] loss: 1.4696742302454755\n",
      "[EPOCH #18, step #1148] loss: 1.469839006636431\n",
      "[EPOCH #18, step #1150] loss: 1.4698942120856144\n",
      "[EPOCH #18, step #1152] loss: 1.4702887378975504\n",
      "[EPOCH #18, step #1154] loss: 1.4703282437799297\n",
      "[EPOCH #18, step #1156] loss: 1.4703469359885029\n",
      "[EPOCH #18, step #1158] loss: 1.4699778246200732\n",
      "[EPOCH #18, step #1160] loss: 1.4697833028361265\n",
      "[EPOCH #18, step #1162] loss: 1.4697311928020094\n",
      "[EPOCH #18, step #1164] loss: 1.4694574069567505\n",
      "[EPOCH #18, step #1166] loss: 1.4692370146896048\n",
      "[EPOCH #18, step #1168] loss: 1.469438050729378\n",
      "[EPOCH #18, step #1170] loss: 1.4687253095266861\n",
      "[EPOCH #18, step #1172] loss: 1.4690261927813622\n",
      "[EPOCH #18, step #1174] loss: 1.469588599306472\n",
      "[EPOCH #18, step #1176] loss: 1.4698091458747624\n",
      "[EPOCH #18, step #1178] loss: 1.469722403925895\n",
      "[EPOCH #18, step #1180] loss: 1.470040756701212\n",
      "[EPOCH #18, step #1182] loss: 1.4697794648216422\n",
      "[EPOCH #18, step #1184] loss: 1.4699007467881537\n",
      "[EPOCH #18, step #1186] loss: 1.470067247986894\n",
      "[EPOCH #18, step #1188] loss: 1.4705453370176913\n",
      "[EPOCH #18, step #1190] loss: 1.4706822655763474\n",
      "[EPOCH #18, step #1192] loss: 1.4710236868734432\n",
      "[EPOCH #18, step #1194] loss: 1.4710193515322698\n",
      "[EPOCH #18, step #1196] loss: 1.4712071414778605\n",
      "[EPOCH #18, step #1198] loss: 1.4713929445172866\n",
      "[EPOCH #18, step #1200] loss: 1.4709918984366297\n",
      "[EPOCH #18, step #1202] loss: 1.4712217227677356\n",
      "[EPOCH #18, step #1204] loss: 1.4712601166048485\n",
      "[EPOCH #18, step #1206] loss: 1.4712271117531968\n",
      "[EPOCH #18, step #1208] loss: 1.4713754223041835\n",
      "[EPOCH #18, step #1210] loss: 1.4713440212604922\n",
      "[EPOCH #18, step #1212] loss: 1.4717157304237818\n",
      "[EPOCH #18, step #1214] loss: 1.471619434072157\n",
      "[EPOCH #18, step #1216] loss: 1.4713776772298477\n",
      "[EPOCH #18, step #1218] loss: 1.4712882697631142\n",
      "[EPOCH #18, step #1220] loss: 1.4716702218821165\n",
      "[EPOCH #18, step #1222] loss: 1.4714513634524184\n",
      "[EPOCH #18, step #1224] loss: 1.4712108732242974\n",
      "[EPOCH #18, step #1226] loss: 1.4713624595818524\n",
      "[EPOCH #18, step #1228] loss: 1.47109836582443\n",
      "[EPOCH #18, step #1230] loss: 1.4711680607423852\n",
      "[EPOCH #18, step #1232] loss: 1.4709764966999528\n",
      "[EPOCH #18, step #1234] loss: 1.4711693892594773\n",
      "[EPOCH #18, step #1236] loss: 1.4716754640507526\n",
      "[EPOCH #18, step #1238] loss: 1.471929903613453\n",
      "[EPOCH #18, step #1240] loss: 1.472200538485786\n",
      "[EPOCH #18, step #1242] loss: 1.471837306876194\n",
      "[EPOCH #18, step #1244] loss: 1.4718912205542904\n",
      "[EPOCH #18, step #1246] loss: 1.4719515639777745\n",
      "[EPOCH #18, step #1248] loss: 1.4724654571546183\n",
      "[EPOCH #18, step #1250] loss: 1.4723246030384403\n",
      "[EPOCH #18, step #1252] loss: 1.4720258938723911\n",
      "[EPOCH #18, step #1254] loss: 1.4719126427316096\n",
      "[EPOCH #18, step #1256] loss: 1.4720441003877585\n",
      "[EPOCH #18, step #1258] loss: 1.471949406755264\n",
      "[EPOCH #18, step #1260] loss: 1.4718543606367875\n",
      "[EPOCH #18, step #1262] loss: 1.4714152584544082\n",
      "[EPOCH #18, step #1264] loss: 1.4719480281761983\n",
      "[EPOCH #18, step #1266] loss: 1.4722582896864123\n",
      "[EPOCH #18, step #1268] loss: 1.4720456849129018\n",
      "[EPOCH #18, step #1270] loss: 1.4720265581136984\n",
      "[EPOCH #18, step #1272] loss: 1.4718858745279784\n",
      "[EPOCH #18, step #1274] loss: 1.4718588531718535\n",
      "[EPOCH #18, step #1276] loss: 1.472315546396475\n",
      "[EPOCH #18, step #1278] loss: 1.4723562734773887\n",
      "[EPOCH #18, step #1280] loss: 1.4725199505093505\n",
      "[EPOCH #18, step #1282] loss: 1.4724163249053717\n",
      "[EPOCH #18, step #1284] loss: 1.472499945655407\n",
      "[EPOCH #18, step #1286] loss: 1.4725800614627462\n",
      "[EPOCH #18, step #1288] loss: 1.4728181927217079\n",
      "[EPOCH #18, step #1290] loss: 1.4724538728860255\n",
      "[EPOCH #18, step #1292] loss: 1.4724003770788419\n",
      "[EPOCH #18, step #1294] loss: 1.4722282807339113\n",
      "[EPOCH #18, step #1296] loss: 1.4722784411107566\n",
      "[EPOCH #18, step #1298] loss: 1.4725496972680918\n",
      "[EPOCH #18, step #1300] loss: 1.4727862575803694\n",
      "[EPOCH #18, step #1302] loss: 1.4731666801164265\n",
      "[EPOCH #18, step #1304] loss: 1.4732391749305287\n",
      "[EPOCH #18, step #1306] loss: 1.4733487707837083\n",
      "[EPOCH #18, step #1308] loss: 1.4732935348478686\n",
      "[EPOCH #18, step #1310] loss: 1.4735314822397008\n",
      "[EPOCH #18, step #1312] loss: 1.4735299502268877\n",
      "[EPOCH #18, step #1314] loss: 1.473296817355283\n",
      "[EPOCH #18, step #1316] loss: 1.4738631137139704\n",
      "[EPOCH #18, step #1318] loss: 1.4739725931383065\n",
      "[EPOCH #18, step #1320] loss: 1.4737504023119503\n",
      "[EPOCH #18, step #1322] loss: 1.474371666360424\n",
      "[EPOCH #18, step #1324] loss: 1.4743060225360798\n",
      "[EPOCH #18, step #1326] loss: 1.473980084881355\n",
      "[EPOCH #18, step #1328] loss: 1.4739035204714452\n",
      "[EPOCH #18, step #1330] loss: 1.473948407853841\n",
      "[EPOCH #18, step #1332] loss: 1.4739300040311591\n",
      "[EPOCH #18, step #1334] loss: 1.4746371721060536\n",
      "[EPOCH #18, step #1336] loss: 1.4748297937788353\n",
      "[EPOCH #18, step #1338] loss: 1.4744012111866092\n",
      "[EPOCH #18, step #1340] loss: 1.4741916518705624\n",
      "[EPOCH #18, step #1342] loss: 1.4740968294669157\n",
      "[EPOCH #18, step #1344] loss: 1.4744121169512157\n",
      "[EPOCH #18, step #1346] loss: 1.4738188320031056\n",
      "[EPOCH #18, step #1348] loss: 1.4737394164455122\n",
      "[EPOCH #18, step #1350] loss: 1.47353439212816\n",
      "[EPOCH #18, step #1352] loss: 1.472977808115664\n",
      "[EPOCH #18, step #1354] loss: 1.4728833019953371\n",
      "[EPOCH #18, step #1356] loss: 1.4732085949547078\n",
      "[EPOCH #18, step #1358] loss: 1.4729246894957126\n",
      "[EPOCH #18, step #1360] loss: 1.4734390330262082\n",
      "[EPOCH #18, step #1362] loss: 1.4728580735137335\n",
      "[EPOCH #18, step #1364] loss: 1.4728633726909484\n",
      "[EPOCH #18, step #1366] loss: 1.4729908145773385\n",
      "[EPOCH #18, step #1368] loss: 1.4731774530417734\n",
      "[EPOCH #18, step #1370] loss: 1.4736069619959937\n",
      "[EPOCH #18, step #1372] loss: 1.47356518801337\n",
      "[EPOCH #18, step #1374] loss: 1.4735268265984276\n",
      "[EPOCH #18, step #1376] loss: 1.4737191773361284\n",
      "[EPOCH #18, step #1378] loss: 1.4739443205507705\n",
      "[EPOCH #18, step #1380] loss: 1.47410689187516\n",
      "[EPOCH #18, step #1382] loss: 1.4746587143716654\n",
      "[EPOCH #18, step #1384] loss: 1.4747711247055109\n",
      "[EPOCH #18, step #1386] loss: 1.4746659670962476\n",
      "[EPOCH #18, step #1388] loss: 1.474285275151697\n",
      "[EPOCH #18, step #1390] loss: 1.474229114335017\n",
      "[EPOCH #18, step #1392] loss: 1.4745086372454903\n",
      "[EPOCH #18, step #1394] loss: 1.474075745938072\n",
      "[EPOCH #18, step #1396] loss: 1.4742963471067916\n",
      "[EPOCH #18, step #1398] loss: 1.4740393000726106\n",
      "[EPOCH #18, step #1400] loss: 1.4737470622236264\n",
      "[EPOCH #18, step #1402] loss: 1.4741440981690237\n",
      "[EPOCH #18, step #1404] loss: 1.4743716201748287\n",
      "[EPOCH #18, step #1406] loss: 1.4743848326533249\n",
      "[EPOCH #18, step #1408] loss: 1.4742126727967164\n",
      "[EPOCH #18, step #1410] loss: 1.474822125478808\n",
      "[EPOCH #18, step #1412] loss: 1.4749026064828872\n",
      "[EPOCH #18, step #1414] loss: 1.474776112569937\n",
      "[EPOCH #18, step #1416] loss: 1.4745927899339792\n",
      "[EPOCH #18, step #1418] loss: 1.4747256728609823\n",
      "[EPOCH #18, step #1420] loss: 1.4746851314548703\n",
      "[EPOCH #18, step #1422] loss: 1.4747376987319216\n",
      "[EPOCH #18, step #1424] loss: 1.4745191643530862\n",
      "[EPOCH #18, step #1426] loss: 1.4741626341357963\n",
      "[EPOCH #18, step #1428] loss: 1.4740152327308629\n",
      "[EPOCH #18, step #1430] loss: 1.4738949719714918\n",
      "[EPOCH #18, step #1432] loss: 1.4738832774564925\n",
      "[EPOCH #18, step #1434] loss: 1.4741394832989896\n",
      "[EPOCH #18, step #1436] loss: 1.4738725558203296\n",
      "[EPOCH #18, step #1438] loss: 1.4738299037285196\n",
      "[EPOCH #18, step #1440] loss: 1.4744672352534711\n",
      "[EPOCH #18, step #1442] loss: 1.4748115967481563\n",
      "[EPOCH #18, step #1444] loss: 1.4750450228324812\n",
      "[EPOCH #18, step #1446] loss: 1.4749126444212222\n",
      "[EPOCH #18, step #1448] loss: 1.4744342583635908\n",
      "[EPOCH #18, step #1450] loss: 1.4745727672320577\n",
      "[EPOCH #18, step #1452] loss: 1.4742879178387824\n",
      "[EPOCH #18, step #1454] loss: 1.474338233184159\n",
      "[EPOCH #18, step #1456] loss: 1.4740401467151159\n",
      "[EPOCH #18, step #1458] loss: 1.473684216869294\n",
      "[EPOCH #18, step #1460] loss: 1.4735526522898168\n",
      "[EPOCH #18, step #1462] loss: 1.4734407197263903\n",
      "[EPOCH #18, step #1464] loss: 1.4733092696186625\n",
      "[EPOCH #18, step #1466] loss: 1.474122869375212\n",
      "[EPOCH #18, step #1468] loss: 1.474162027493393\n",
      "[EPOCH #18, step #1470] loss: 1.474367682014818\n",
      "[EPOCH #18, step #1472] loss: 1.4741349025235562\n",
      "[EPOCH #18, step #1474] loss: 1.47415982771728\n",
      "[EPOCH #18, step #1476] loss: 1.4741240327392144\n",
      "[EPOCH #18, step #1478] loss: 1.4741049462512508\n",
      "[EPOCH #18, step #1480] loss: 1.4744252473578752\n",
      "[EPOCH #18, step #1482] loss: 1.4743033804285792\n",
      "[EPOCH #18, step #1484] loss: 1.4745854402632024\n",
      "[EPOCH #18, step #1486] loss: 1.474554591156447\n",
      "[EPOCH #18, step #1488] loss: 1.4749233563367434\n",
      "[EPOCH #18, step #1490] loss: 1.4748118253141183\n",
      "[EPOCH #18, step #1492] loss: 1.4743693430233704\n",
      "[EPOCH #18, step #1494] loss: 1.4742362468537678\n",
      "[EPOCH #18, step #1496] loss: 1.4743073301547833\n",
      "[EPOCH #18, step #1498] loss: 1.4743621683741028\n",
      "[EPOCH #18, step #1500] loss: 1.4741553744421572\n",
      "[EPOCH #18, step #1502] loss: 1.4740098322619617\n",
      "[EPOCH #18, step #1504] loss: 1.4738359107923666\n",
      "[EPOCH #18, step #1506] loss: 1.4741069655506993\n",
      "[EPOCH #18, step #1508] loss: 1.4741281920746512\n",
      "[EPOCH #18, step #1510] loss: 1.4740993567526064\n",
      "[EPOCH #18, step #1512] loss: 1.4740524592576087\n",
      "[EPOCH #18, step #1514] loss: 1.4740249611363552\n",
      "[EPOCH #18, step #1516] loss: 1.4743597444218086\n",
      "[EPOCH #18, step #1518] loss: 1.4745760090732511\n",
      "[EPOCH #18, step #1520] loss: 1.4743870460305224\n",
      "[EPOCH #18, step #1522] loss: 1.474394866493448\n",
      "[EPOCH #18, step #1524] loss: 1.4742106287987506\n",
      "[EPOCH #18, step #1526] loss: 1.474287363112012\n",
      "[EPOCH #18, step #1528] loss: 1.474295965708339\n",
      "[EPOCH #18, step #1530] loss: 1.4740872129671407\n",
      "[EPOCH #18, step #1532] loss: 1.4738003811413216\n",
      "[EPOCH #18, step #1534] loss: 1.4737011820563275\n",
      "[EPOCH #18, step #1536] loss: 1.4739583959886604\n",
      "[EPOCH #18, step #1538] loss: 1.473897278851081\n",
      "[EPOCH #18, step #1540] loss: 1.4737965073158492\n",
      "[EPOCH #18, step #1542] loss: 1.473604571216692\n",
      "[EPOCH #18, step #1544] loss: 1.473618665520813\n",
      "[EPOCH #18, step #1546] loss: 1.473398716086022\n",
      "[EPOCH #18, step #1548] loss: 1.4731013666744615\n",
      "[EPOCH #18, step #1550] loss: 1.4727153090566762\n",
      "[EPOCH #18, step #1552] loss: 1.473208710791139\n",
      "[EPOCH #18, step #1554] loss: 1.4727401990215878\n",
      "[EPOCH #18, step #1556] loss: 1.4723288128601104\n",
      "[EPOCH #18, step #1558] loss: 1.4722663359889776\n",
      "[EPOCH #18, step #1560] loss: 1.4716384811786258\n",
      "[EPOCH #18, step #1562] loss: 1.471695158699729\n",
      "[EPOCH #18, step #1564] loss: 1.4716379701139066\n",
      "[EPOCH #18, step #1566] loss: 1.4714408162755424\n",
      "[EPOCH #18, step #1568] loss: 1.4711849539047446\n",
      "[EPOCH #18, step #1570] loss: 1.470547917274667\n",
      "[EPOCH #18, step #1572] loss: 1.4705205072435086\n",
      "[EPOCH #18, step #1574] loss: 1.4703449934626383\n",
      "[EPOCH #18, step #1576] loss: 1.470243627123993\n",
      "[EPOCH #18, step #1578] loss: 1.4702971639551643\n",
      "[EPOCH #18, step #1580] loss: 1.4700634034278648\n",
      "[EPOCH #18, step #1582] loss: 1.4695181874105316\n",
      "[EPOCH #18, step #1584] loss: 1.469533069088632\n",
      "[EPOCH #18, step #1586] loss: 1.4691929030358304\n",
      "[EPOCH #18, step #1588] loss: 1.4693003283348227\n",
      "[EPOCH #18, step #1590] loss: 1.469113876465954\n",
      "[EPOCH #18, step #1592] loss: 1.469084577184762\n",
      "[EPOCH #18, step #1594] loss: 1.469564044400816\n",
      "[EPOCH #18, step #1596] loss: 1.469261128117162\n",
      "[EPOCH #18, step #1598] loss: 1.4697766055383856\n",
      "[EPOCH #18, step #1600] loss: 1.4703142737910422\n",
      "[EPOCH #18, step #1602] loss: 1.4701044608188731\n",
      "[EPOCH #18, step #1604] loss: 1.4698420116463182\n",
      "[EPOCH #18, step #1606] loss: 1.4697073404656928\n",
      "[EPOCH #18, step #1608] loss: 1.4694983243868172\n",
      "[EPOCH #18, step #1610] loss: 1.4693060841048304\n",
      "[EPOCH #18, step #1612] loss: 1.4692111348632841\n",
      "[EPOCH #18, step #1614] loss: 1.4692081209306747\n",
      "[EPOCH #18, step #1616] loss: 1.4690247928941405\n",
      "[EPOCH #18, step #1618] loss: 1.4691412180864643\n",
      "[EPOCH #18, step #1620] loss: 1.4689097087520055\n",
      "[EPOCH #18, step #1622] loss: 1.4686215731073733\n",
      "[EPOCH #18, step #1624] loss: 1.4681333186809833\n",
      "[EPOCH #18, step #1626] loss: 1.4680107580640964\n",
      "[EPOCH #18, step #1628] loss: 1.4682025048833744\n",
      "[EPOCH #18, step #1630] loss: 1.468253046438637\n",
      "[EPOCH #18, step #1632] loss: 1.4683775357943112\n",
      "[EPOCH #18, step #1634] loss: 1.468149865366268\n",
      "[EPOCH #18, step #1636] loss: 1.4683007464295272\n",
      "[EPOCH #18, step #1638] loss: 1.468390792444612\n",
      "[EPOCH #18, step #1640] loss: 1.4684419212800421\n",
      "[EPOCH #18, step #1642] loss: 1.468306818751395\n",
      "[EPOCH #18, step #1644] loss: 1.468638259299258\n",
      "[EPOCH #18, step #1646] loss: 1.4688521250132438\n",
      "[EPOCH #18, step #1648] loss: 1.4691068496466984\n",
      "[EPOCH #18, step #1650] loss: 1.4688072619764534\n",
      "[EPOCH #18, step #1652] loss: 1.469005610246191\n",
      "[EPOCH #18, step #1654] loss: 1.4693165063137734\n",
      "[EPOCH #18, step #1656] loss: 1.4691943359000896\n",
      "[EPOCH #18, step #1658] loss: 1.469232811993903\n",
      "[EPOCH #18, step #1660] loss: 1.4692972884129358\n",
      "[EPOCH #18, step #1662] loss: 1.4696317753444863\n",
      "[EPOCH #18, step #1664] loss: 1.4698652785819573\n",
      "[EPOCH #18, step #1666] loss: 1.4697865698962564\n",
      "[EPOCH #18, step #1668] loss: 1.4699184292444145\n",
      "[EPOCH #18, step #1670] loss: 1.4700974074756934\n",
      "[EPOCH #18, step #1672] loss: 1.4701441405992344\n",
      "[EPOCH #18, step #1674] loss: 1.470164931638917\n",
      "[EPOCH #18, step #1676] loss: 1.4700606314995208\n",
      "[EPOCH #18, step #1678] loss: 1.4703195439413093\n",
      "[EPOCH #18, step #1680] loss: 1.4702049035674258\n",
      "[EPOCH #18, step #1682] loss: 1.4702299414684004\n",
      "[EPOCH #18, step #1684] loss: 1.4697969485461182\n",
      "[EPOCH #18, step #1686] loss: 1.470556080094017\n",
      "[EPOCH #18, step #1688] loss: 1.4707884000136768\n",
      "[EPOCH #18, step #1690] loss: 1.4709363080988545\n",
      "[EPOCH #18, step #1692] loss: 1.4714528727094873\n",
      "[EPOCH #18, step #1694] loss: 1.4715495378218568\n",
      "[EPOCH #18, step #1696] loss: 1.4720164210780902\n",
      "[EPOCH #18, step #1698] loss: 1.4722373711494505\n",
      "[EPOCH #18, step #1700] loss: 1.472090369950036\n",
      "[EPOCH #18, step #1702] loss: 1.4721338522833232\n",
      "[EPOCH #18, step #1704] loss: 1.4721890554400134\n",
      "[EPOCH #18, step #1706] loss: 1.4723242778979202\n",
      "[EPOCH #18, step #1708] loss: 1.4726153181058192\n",
      "[EPOCH #18, step #1710] loss: 1.4727103341608143\n",
      "[EPOCH #18, step #1712] loss: 1.4725910653444458\n",
      "[EPOCH #18, step #1714] loss: 1.4726492350025011\n",
      "[EPOCH #18, step #1716] loss: 1.4724815942273282\n",
      "[EPOCH #18, step #1718] loss: 1.4722908524457212\n",
      "[EPOCH #18, step #1720] loss: 1.472097011585003\n",
      "[EPOCH #18, step #1722] loss: 1.472015321704446\n",
      "[EPOCH #18, step #1724] loss: 1.4718576137570367\n",
      "[EPOCH #18, step #1726] loss: 1.4718740412315054\n",
      "[EPOCH #18, step #1728] loss: 1.4719094184177193\n",
      "[EPOCH #18, step #1730] loss: 1.4721969727626913\n",
      "[EPOCH #18, step #1732] loss: 1.4721106688410852\n",
      "[EPOCH #18, step #1734] loss: 1.4715091135041514\n",
      "[EPOCH #18, step #1736] loss: 1.471628929735534\n",
      "[EPOCH #18, step #1738] loss: 1.4715359691506902\n",
      "[EPOCH #18, step #1740] loss: 1.471818136730665\n",
      "[EPOCH #18, step #1742] loss: 1.4714663077960122\n",
      "[EPOCH #18, step #1744] loss: 1.471559324647089\n",
      "[EPOCH #18, step #1746] loss: 1.471496391310034\n",
      "[EPOCH #18, step #1748] loss: 1.4711454915209727\n",
      "[EPOCH #18, step #1750] loss: 1.4708239792552014\n",
      "[EPOCH #18, step #1752] loss: 1.4706216870344373\n",
      "[EPOCH #18, step #1754] loss: 1.4708421879684144\n",
      "[EPOCH #18, step #1756] loss: 1.4707201202280764\n",
      "[EPOCH #18, step #1758] loss: 1.4706109412493118\n",
      "[EPOCH #18, step #1760] loss: 1.470606491215049\n",
      "[EPOCH #18, step #1762] loss: 1.4706689177489862\n",
      "[EPOCH #18, step #1764] loss: 1.470351358277264\n",
      "[EPOCH #18, step #1766] loss: 1.4703352042828566\n",
      "[EPOCH #18, step #1768] loss: 1.469835127255821\n",
      "[EPOCH #18, step #1770] loss: 1.469295039916025\n",
      "[EPOCH #18, step #1772] loss: 1.4692689212983567\n",
      "[EPOCH #18, step #1774] loss: 1.4693696159376226\n",
      "[EPOCH #18, step #1776] loss: 1.469030237258252\n",
      "[EPOCH #18, step #1778] loss: 1.4688933795258328\n",
      "[EPOCH #18, step #1780] loss: 1.4686742335942808\n",
      "[EPOCH #18, step #1782] loss: 1.4688642966031895\n",
      "[EPOCH #18, step #1784] loss: 1.468849602366696\n",
      "[EPOCH #18, step #1786] loss: 1.468720884882143\n",
      "[EPOCH #18, step #1788] loss: 1.468334941806708\n",
      "[EPOCH #18, step #1790] loss: 1.4684092200780834\n",
      "[EPOCH #18, step #1792] loss: 1.4684637324542755\n",
      "[EPOCH #18, step #1794] loss: 1.4685994555691158\n",
      "[EPOCH #18, step #1796] loss: 1.4684970101914807\n",
      "[EPOCH #18, step #1798] loss: 1.4685877585755645\n",
      "[EPOCH #18, step #1800] loss: 1.4684676856944323\n",
      "[EPOCH #18, step #1802] loss: 1.4683461748952014\n",
      "[EPOCH #18, step #1804] loss: 1.4682696175707344\n",
      "[EPOCH #18, step #1806] loss: 1.4683646442287195\n",
      "[EPOCH #18, step #1808] loss: 1.468429022463993\n",
      "[EPOCH #18, step #1810] loss: 1.4685411210023258\n",
      "[EPOCH #18, step #1812] loss: 1.4685038390306893\n",
      "[EPOCH #18, step #1814] loss: 1.4684821705844449\n",
      "[EPOCH #18, step #1816] loss: 1.4687830984231596\n",
      "[EPOCH #18, step #1818] loss: 1.4688194451782977\n",
      "[EPOCH #18, step #1820] loss: 1.4687621645518936\n",
      "[EPOCH #18, step #1822] loss: 1.468916838959031\n",
      "[EPOCH #18, step #1824] loss: 1.468902861288149\n",
      "[EPOCH #18, step #1826] loss: 1.4689203587854633\n",
      "[EPOCH #18, step #1828] loss: 1.4685828154891354\n",
      "[EPOCH #18, step #1830] loss: 1.4686666472175616\n",
      "[EPOCH #18, step #1832] loss: 1.4686486141251138\n",
      "[EPOCH #18, step #1834] loss: 1.468664181102524\n",
      "[EPOCH #18, step #1836] loss: 1.4685993019043264\n",
      "[EPOCH #18, step #1838] loss: 1.4688238286985011\n",
      "[EPOCH #18, step #1840] loss: 1.4687541678895903\n",
      "[EPOCH #18, step #1842] loss: 1.4686397283994435\n",
      "[EPOCH #18, step #1844] loss: 1.4687671676560792\n",
      "[EPOCH #18, step #1846] loss: 1.469119932855473\n",
      "[EPOCH #18, step #1848] loss: 1.4689852470253015\n",
      "[EPOCH #18, step #1850] loss: 1.4689819417664451\n",
      "[EPOCH #18, step #1852] loss: 1.4689581838415817\n",
      "[EPOCH #18, step #1854] loss: 1.4691301148214109\n",
      "[EPOCH #18, step #1856] loss: 1.4689030295812642\n",
      "[EPOCH #18, step #1858] loss: 1.468969513261876\n",
      "[EPOCH #18, step #1860] loss: 1.4686245815142838\n",
      "[EPOCH #18, step #1862] loss: 1.4683573289513907\n",
      "[EPOCH #18, step #1864] loss: 1.4685674212892956\n",
      "[EPOCH #18, step #1866] loss: 1.4688557522400343\n",
      "[EPOCH #18, step #1868] loss: 1.4686820828512814\n",
      "[EPOCH #18, step #1870] loss: 1.4687399314343133\n",
      "[EPOCH #18, step #1872] loss: 1.4685082948914328\n",
      "[EPOCH #18, step #1874] loss: 1.468566970094045\n",
      "[EPOCH #18, step #1876] loss: 1.4684895448819335\n",
      "[EPOCH #18, step #1878] loss: 1.4686727380739875\n",
      "[EPOCH #18, step #1880] loss: 1.468796952901401\n",
      "[EPOCH #18, step #1882] loss: 1.4687117270124257\n",
      "[EPOCH #18, step #1884] loss: 1.4689186141408723\n",
      "[EPOCH #18, step #1886] loss: 1.4691041732946273\n",
      "[EPOCH #18, step #1888] loss: 1.4692817173223762\n",
      "[EPOCH #18, step #1890] loss: 1.469496067745354\n",
      "[EPOCH #18, step #1892] loss: 1.4695419883891758\n",
      "[EPOCH #18, step #1894] loss: 1.4692988482817497\n",
      "[EPOCH #18, step #1896] loss: 1.4691092715680631\n",
      "[EPOCH #18, step #1898] loss: 1.468973598491524\n",
      "[EPOCH #18, step #1900] loss: 1.4689529459141606\n",
      "[EPOCH #18, step #1902] loss: 1.4688283724028126\n",
      "[EPOCH #18, step #1904] loss: 1.4686998873245058\n",
      "[EPOCH #18, step #1906] loss: 1.4685476279783825\n",
      "[EPOCH #18, step #1908] loss: 1.468467929682974\n",
      "[EPOCH #18, step #1910] loss: 1.4685156746162662\n",
      "[EPOCH #18, step #1912] loss: 1.4686751836454188\n",
      "[EPOCH #18, step #1914] loss: 1.4687034418626492\n",
      "[EPOCH #18, step #1916] loss: 1.468496904779861\n",
      "[EPOCH #18, step #1918] loss: 1.468748533179078\n",
      "[EPOCH #18, step #1920] loss: 1.4687534790061403\n",
      "[EPOCH #18, step #1922] loss: 1.4687471036729995\n",
      "[EPOCH #18, step #1924] loss: 1.4686189527325817\n",
      "[EPOCH #18, step #1926] loss: 1.4689151365706261\n",
      "[EPOCH #18, step #1928] loss: 1.468968773364032\n",
      "[EPOCH #18, step #1930] loss: 1.4688777794867585\n",
      "[EPOCH #18, step #1932] loss: 1.4689986911451514\n",
      "[EPOCH #18, step #1934] loss: 1.4688246775967206\n",
      "[EPOCH #18, step #1936] loss: 1.46858786665784\n",
      "[EPOCH #18, step #1938] loss: 1.468494955106394\n",
      "[EPOCH #18, step #1940] loss: 1.4684603648785155\n",
      "[EPOCH #18, step #1942] loss: 1.4682085690459086\n",
      "[EPOCH #18, step #1944] loss: 1.4678972596374453\n",
      "[EPOCH #18, step #1946] loss: 1.4680992024154251\n",
      "[EPOCH #18, step #1948] loss: 1.4683047250150227\n",
      "[EPOCH #18, step #1950] loss: 1.468051989679762\n",
      "[EPOCH #18, step #1952] loss: 1.4678494563727762\n",
      "[EPOCH #18, step #1954] loss: 1.4678997465716603\n",
      "[EPOCH #18, step #1956] loss: 1.4680490103009165\n",
      "[EPOCH #18, step #1958] loss: 1.467975774579294\n",
      "[EPOCH #18, step #1960] loss: 1.4679001694671479\n",
      "[EPOCH #18, step #1962] loss: 1.4676586548345647\n",
      "[EPOCH #18, step #1964] loss: 1.4672812840714102\n",
      "[EPOCH #18, step #1966] loss: 1.4674333773655641\n",
      "[EPOCH #18, step #1968] loss: 1.467642723908577\n",
      "[EPOCH #18, step #1970] loss: 1.4674994761964382\n",
      "[EPOCH #18, step #1972] loss: 1.4676470460773299\n",
      "[EPOCH #18, step #1974] loss: 1.4675496428224104\n",
      "[EPOCH #18, step #1976] loss: 1.4681206329277687\n",
      "[EPOCH #18, step #1978] loss: 1.467926852476603\n",
      "[EPOCH #18, step #1980] loss: 1.4679542129115586\n",
      "[EPOCH #18, step #1982] loss: 1.4678099018662973\n",
      "[EPOCH #18, step #1984] loss: 1.4677163851651496\n",
      "[EPOCH #18, step #1986] loss: 1.4677085793372309\n",
      "[EPOCH #18, step #1988] loss: 1.4679184053758092\n",
      "[EPOCH #18, step #1990] loss: 1.4677905031390552\n",
      "[EPOCH #18, step #1992] loss: 1.4678807353411136\n",
      "[EPOCH #18, step #1994] loss: 1.468156441261894\n",
      "[EPOCH #18, step #1996] loss: 1.4682212073801755\n",
      "[EPOCH #18, step #1998] loss: 1.4680507108233702\n",
      "[EPOCH #18, step #2000] loss: 1.4680358472613917\n",
      "[EPOCH #18, step #2002] loss: 1.467934825541791\n",
      "[EPOCH #18, step #2004] loss: 1.4680263222898926\n",
      "[EPOCH #18, step #2006] loss: 1.46785706739017\n",
      "[EPOCH #18, step #2008] loss: 1.4675033362781664\n",
      "[EPOCH #18, step #2010] loss: 1.4675089353533421\n",
      "[EPOCH #18, step #2012] loss: 1.4674633691338124\n",
      "[EPOCH #18, step #2014] loss: 1.4673676624783216\n",
      "[EPOCH #18, step #2016] loss: 1.4673833171802402\n",
      "[EPOCH #18, step #2018] loss: 1.4670478419362465\n",
      "[EPOCH #18, step #2020] loss: 1.4670685866809847\n",
      "[EPOCH #18, step #2022] loss: 1.4671546509816278\n",
      "[EPOCH #18, step #2024] loss: 1.4672345872867254\n",
      "[EPOCH #18, step #2026] loss: 1.4673499695526653\n",
      "[EPOCH #18, step #2028] loss: 1.4671828005629963\n",
      "[EPOCH #18, step #2030] loss: 1.4672240519218407\n",
      "[EPOCH #18, step #2032] loss: 1.4672378944576636\n",
      "[EPOCH #18, step #2034] loss: 1.4673825893413817\n",
      "[EPOCH #18, step #2036] loss: 1.4670755918492977\n",
      "[EPOCH #18, step #2038] loss: 1.4671775813252392\n",
      "[EPOCH #18, step #2040] loss: 1.4669568453683157\n",
      "[EPOCH #18, step #2042] loss: 1.4667249613688147\n",
      "[EPOCH #18, step #2044] loss: 1.4666939448902252\n",
      "[EPOCH #18, step #2046] loss: 1.466722802674415\n",
      "[EPOCH #18, step #2048] loss: 1.4664819251915022\n",
      "[EPOCH #18, step #2050] loss: 1.4665204836123749\n",
      "[EPOCH #18, step #2052] loss: 1.4661648962419902\n",
      "[EPOCH #18, step #2054] loss: 1.466114577150693\n",
      "[EPOCH #18, step #2056] loss: 1.465812989386993\n",
      "[EPOCH #18, step #2058] loss: 1.4655452827159035\n",
      "[EPOCH #18, step #2060] loss: 1.4659676301947848\n",
      "[EPOCH #18, step #2062] loss: 1.4657276408856088\n",
      "[EPOCH #18, step #2064] loss: 1.4659631628101155\n",
      "[EPOCH #18, step #2066] loss: 1.4657260963290455\n",
      "[EPOCH #18, step #2068] loss: 1.4657030813702066\n",
      "[EPOCH #18, step #2070] loss: 1.4656220343537747\n",
      "[EPOCH #18, step #2072] loss: 1.4653403140816548\n",
      "[EPOCH #18, step #2074] loss: 1.4653188017190222\n",
      "[EPOCH #18, step #2076] loss: 1.4654074234060215\n",
      "[EPOCH #18, step #2078] loss: 1.4655349620435603\n",
      "[EPOCH #18, step #2080] loss: 1.4656716134902206\n",
      "[EPOCH #18, step #2082] loss: 1.4654798822453317\n",
      "[EPOCH #18, step #2084] loss: 1.4654040693379136\n",
      "[EPOCH #18, step #2086] loss: 1.4653861059431945\n",
      "[EPOCH #18, step #2088] loss: 1.4653042040697521\n",
      "[EPOCH #18, step #2090] loss: 1.4652776125228788\n",
      "[EPOCH #18, step #2092] loss: 1.4653450836135165\n",
      "[EPOCH #18, step #2094] loss: 1.465506371279605\n",
      "[EPOCH #18, step #2096] loss: 1.4655033853091566\n",
      "[EPOCH #18, step #2098] loss: 1.4653121041592785\n",
      "[EPOCH #18, step #2100] loss: 1.4652623255896262\n",
      "[EPOCH #18, step #2102] loss: 1.465277325693222\n",
      "[EPOCH #18, step #2104] loss: 1.4656671520649962\n",
      "[EPOCH #18, step #2106] loss: 1.4656452853701156\n",
      "[EPOCH #18, step #2108] loss: 1.4654887900526572\n",
      "[EPOCH #18, step #2110] loss: 1.4655382537774033\n",
      "[EPOCH #18, step #2112] loss: 1.4653409754445752\n",
      "[EPOCH #18, step #2114] loss: 1.465240645070448\n",
      "[EPOCH #18, step #2116] loss: 1.465084813651354\n",
      "[EPOCH #18, step #2118] loss: 1.4648679345494569\n",
      "[EPOCH #18, step #2120] loss: 1.46496754322677\n",
      "[EPOCH #18, step #2122] loss: 1.4650402132823566\n",
      "[EPOCH #18, step #2124] loss: 1.4648396685824674\n",
      "[EPOCH #18, step #2126] loss: 1.4649949135722047\n",
      "[EPOCH #18, step #2128] loss: 1.4650688335166508\n",
      "[EPOCH #18, step #2130] loss: 1.4652163531230906\n",
      "[EPOCH #18, step #2132] loss: 1.4650737420248414\n",
      "[EPOCH #18, step #2134] loss: 1.4649029878877644\n",
      "[EPOCH #18, step #2136] loss: 1.4648381614160695\n",
      "[EPOCH #18, step #2138] loss: 1.4649226234972392\n",
      "[EPOCH #18, step #2140] loss: 1.4651175958706029\n",
      "[EPOCH #18, step #2142] loss: 1.4652444939996059\n",
      "[EPOCH #18, step #2144] loss: 1.4651697418628595\n",
      "[EPOCH #18, step #2146] loss: 1.4655612138298206\n",
      "[EPOCH #18, step #2148] loss: 1.4652706851455544\n",
      "[EPOCH #18, step #2150] loss: 1.4652281825845046\n",
      "[EPOCH #18, step #2152] loss: 1.4652497395492408\n",
      "[EPOCH #18, step #2154] loss: 1.4655330303650167\n",
      "[EPOCH #18, step #2156] loss: 1.4654301355489714\n",
      "[EPOCH #18, step #2158] loss: 1.4653591006759583\n",
      "[EPOCH #18, step #2160] loss: 1.4653734670695968\n",
      "[EPOCH #18, step #2162] loss: 1.4651319005397863\n",
      "[EPOCH #18, step #2164] loss: 1.4648634693914417\n",
      "[EPOCH #18, step #2166] loss: 1.4647493589898106\n",
      "[EPOCH #18, step #2168] loss: 1.4645234351061411\n",
      "[EPOCH #18, step #2170] loss: 1.4643038465975617\n",
      "[EPOCH #18, step #2172] loss: 1.4644009191705727\n",
      "[EPOCH #18, step #2174] loss: 1.4643670369016712\n",
      "[EPOCH #18, step #2176] loss: 1.4643677034726317\n",
      "[EPOCH #18, step #2178] loss: 1.4641949380138917\n",
      "[EPOCH #18, step #2180] loss: 1.464131812418562\n",
      "[EPOCH #18, step #2182] loss: 1.4641339521969452\n",
      "[EPOCH #18, step #2184] loss: 1.464123154859521\n",
      "[EPOCH #18, step #2186] loss: 1.4644147821305602\n",
      "[EPOCH #18, step #2188] loss: 1.4641751791310125\n",
      "[EPOCH #18, step #2190] loss: 1.46443120176963\n",
      "[EPOCH #18, step #2192] loss: 1.4643976893590238\n",
      "[EPOCH #18, step #2194] loss: 1.4644557674544818\n",
      "[EPOCH #18, step #2196] loss: 1.4644870006826503\n",
      "[EPOCH #18, step #2198] loss: 1.4643013850023878\n",
      "[EPOCH #18, step #2200] loss: 1.4643292184690626\n",
      "[EPOCH #18, step #2202] loss: 1.46434941772867\n",
      "[EPOCH #18, step #2204] loss: 1.4644205199077287\n",
      "[EPOCH #18, step #2206] loss: 1.4642360099959708\n",
      "[EPOCH #18, step #2208] loss: 1.4644305583792825\n",
      "[EPOCH #18, step #2210] loss: 1.46452026362335\n",
      "[EPOCH #18, step #2212] loss: 1.4644233184166748\n",
      "[EPOCH #18, step #2214] loss: 1.464399788153629\n",
      "[EPOCH #18, step #2216] loss: 1.4643501340939646\n",
      "[EPOCH #18, step #2218] loss: 1.4643915049553777\n",
      "[EPOCH #18, step #2220] loss: 1.4643021580175686\n",
      "[EPOCH #18, step #2222] loss: 1.4643192401459986\n",
      "[EPOCH #18, step #2224] loss: 1.4642056052604417\n",
      "[EPOCH #18, step #2226] loss: 1.4642763915059809\n",
      "[EPOCH #18, step #2228] loss: 1.4641870616957338\n",
      "[EPOCH #18, step #2230] loss: 1.4642868513806633\n",
      "[EPOCH #18, step #2232] loss: 1.464019456413686\n",
      "[EPOCH #18, step #2234] loss: 1.4644114697539565\n",
      "[EPOCH #18, step #2236] loss: 1.4643769582894215\n",
      "[EPOCH #18, step #2238] loss: 1.4639885902085332\n",
      "[EPOCH #18, step #2240] loss: 1.4636769867911503\n",
      "[EPOCH #18, step #2242] loss: 1.463586206288408\n",
      "[EPOCH #18, step #2244] loss: 1.4635476321844854\n",
      "[EPOCH #18, step #2246] loss: 1.4637941995036299\n",
      "[EPOCH #18, step #2248] loss: 1.463595638570917\n",
      "[EPOCH #18, step #2250] loss: 1.46357854503041\n",
      "[EPOCH #18, step #2252] loss: 1.463258596166102\n",
      "[EPOCH #18, step #2254] loss: 1.4630274505150027\n",
      "[EPOCH #18, step #2256] loss: 1.4632603362644991\n",
      "[EPOCH #18, step #2258] loss: 1.4631675415832737\n",
      "[EPOCH #18, step #2260] loss: 1.4632175789634405\n",
      "[EPOCH #18, step #2262] loss: 1.4632518513245862\n",
      "[EPOCH #18, step #2264] loss: 1.4632973784116194\n",
      "[EPOCH #18, step #2266] loss: 1.4632113172348553\n",
      "[EPOCH #18, step #2268] loss: 1.4632103573440611\n",
      "[EPOCH #18, step #2270] loss: 1.4629831892548548\n",
      "[EPOCH #18, step #2272] loss: 1.4629140672734064\n",
      "[EPOCH #18, step #2274] loss: 1.4627590623268714\n",
      "[EPOCH #18, step #2276] loss: 1.462572804290996\n",
      "[EPOCH #18, step #2278] loss: 1.4627303569240495\n",
      "[EPOCH #18, step #2280] loss: 1.4628930590436\n",
      "[EPOCH #18, step #2282] loss: 1.4627461220369076\n",
      "[EPOCH #18, step #2284] loss: 1.4628778471205897\n",
      "[EPOCH #18, step #2286] loss: 1.4628541359590765\n",
      "[EPOCH #18, step #2288] loss: 1.4627686054126412\n",
      "[EPOCH #18, step #2290] loss: 1.462836087036216\n",
      "[EPOCH #18, step #2292] loss: 1.4630872154152659\n",
      "[EPOCH #18, step #2294] loss: 1.4629087099062852\n",
      "[EPOCH #18, step #2296] loss: 1.4629969894237294\n",
      "[EPOCH #18, step #2298] loss: 1.4631841057225277\n",
      "[EPOCH #18, step #2300] loss: 1.4631582882962813\n",
      "[EPOCH #18, step #2302] loss: 1.4632137948101207\n",
      "[EPOCH #18, step #2304] loss: 1.4633828341573025\n",
      "[EPOCH #18, step #2306] loss: 1.4630471774908593\n",
      "[EPOCH #18, step #2308] loss: 1.462939602825847\n",
      "[EPOCH #18, step #2310] loss: 1.463034783230876\n",
      "[EPOCH #18, step #2312] loss: 1.4630325966153472\n",
      "[EPOCH #18, step #2314] loss: 1.462978661704012\n",
      "[EPOCH #18, step #2316] loss: 1.4629165649311162\n",
      "[EPOCH #18, step #2318] loss: 1.462670127627869\n",
      "[EPOCH #18, step #2320] loss: 1.462431886364601\n",
      "[EPOCH #18, step #2322] loss: 1.4623961603903226\n",
      "[EPOCH #18, step #2324] loss: 1.4622804228721127\n",
      "[EPOCH #18, step #2326] loss: 1.4625879755899227\n",
      "[EPOCH #18, step #2328] loss: 1.4626236023079842\n",
      "[EPOCH #18, step #2330] loss: 1.4625216122862097\n",
      "[EPOCH #18, step #2332] loss: 1.4623737042163811\n",
      "[EPOCH #18, step #2334] loss: 1.4623048357841035\n",
      "[EPOCH #18, step #2336] loss: 1.4622184491381973\n",
      "[EPOCH #18, step #2338] loss: 1.4619528933079031\n",
      "[EPOCH #18, step #2340] loss: 1.4620540254343173\n",
      "[EPOCH #18, step #2342] loss: 1.4622802772279788\n",
      "[EPOCH #18, step #2344] loss: 1.4622071609059886\n",
      "[EPOCH #18, step #2346] loss: 1.4619328480707516\n",
      "[EPOCH #18, step #2348] loss: 1.4618058028805758\n",
      "[EPOCH #18, step #2350] loss: 1.4617193716477963\n",
      "[EPOCH #18, step #2352] loss: 1.4617967712235764\n",
      "[EPOCH #18, step #2354] loss: 1.4619657748570614\n",
      "[EPOCH #18, step #2356] loss: 1.4616988631795917\n",
      "[EPOCH #18, step #2358] loss: 1.4613747196007503\n",
      "[EPOCH #18, step #2360] loss: 1.461197065176069\n",
      "[EPOCH #18, step #2362] loss: 1.4611077580571024\n",
      "[EPOCH #18, step #2364] loss: 1.4611460155462865\n",
      "[EPOCH #18, step #2366] loss: 1.4612910940418478\n",
      "[EPOCH #18, step #2368] loss: 1.4612947229395037\n",
      "[EPOCH #18, step #2370] loss: 1.4612371839586062\n",
      "[EPOCH #18, step #2372] loss: 1.4610311409314876\n",
      "[EPOCH #18, step #2374] loss: 1.4610499056263975\n",
      "[EPOCH #18, step #2376] loss: 1.4610876324901974\n",
      "[EPOCH #18, step #2378] loss: 1.4612172967799324\n",
      "[EPOCH #18, step #2380] loss: 1.4610142847511358\n",
      "[EPOCH #18, step #2382] loss: 1.4607765136823603\n",
      "[EPOCH #18, step #2384] loss: 1.460601747560801\n",
      "[EPOCH #18, step #2386] loss: 1.4604531417194648\n",
      "[EPOCH #18, step #2388] loss: 1.4603808974062065\n",
      "[EPOCH #18, step #2390] loss: 1.4605235387869133\n",
      "[EPOCH #18, step #2392] loss: 1.4605724682530947\n",
      "[EPOCH #18, step #2394] loss: 1.460614185791175\n",
      "[EPOCH #18, step #2396] loss: 1.4605452065473803\n",
      "[EPOCH #18, step #2398] loss: 1.4608101778201334\n",
      "[EPOCH #18, step #2400] loss: 1.460780400675766\n",
      "[EPOCH #18, step #2402] loss: 1.460840449251833\n",
      "[EPOCH #18, step #2404] loss: 1.4611340521774767\n",
      "[EPOCH #18, step #2406] loss: 1.4610592450251656\n",
      "[EPOCH #18, step #2408] loss: 1.4611915025338933\n",
      "[EPOCH #18, step #2410] loss: 1.4613568539542314\n",
      "[EPOCH #18, step #2412] loss: 1.4616897122967654\n",
      "[EPOCH #18, step #2414] loss: 1.4615907346733361\n",
      "[EPOCH #18, step #2416] loss: 1.4616293135289076\n",
      "[EPOCH #18, step #2418] loss: 1.4615932795172537\n",
      "[EPOCH #18, step #2420] loss: 1.461584189912102\n",
      "[EPOCH #18, step #2422] loss: 1.4614368647127864\n",
      "[EPOCH #18, step #2424] loss: 1.461573150821568\n",
      "[EPOCH #18, step #2426] loss: 1.4617042520874364\n",
      "[EPOCH #18, step #2428] loss: 1.461620502630935\n",
      "[EPOCH #18, step #2430] loss: 1.4615515446476561\n",
      "[EPOCH #18, step #2432] loss: 1.4616613590418435\n",
      "[EPOCH #18, step #2434] loss: 1.4618939876556396\n",
      "[EPOCH #18, step #2436] loss: 1.461735704124194\n",
      "[EPOCH #18, step #2438] loss: 1.4617948571694293\n",
      "[EPOCH #18, step #2440] loss: 1.4617852819400554\n",
      "[EPOCH #18, step #2442] loss: 1.46179510743902\n",
      "[EPOCH #18, step #2444] loss: 1.4617880834392243\n",
      "[EPOCH #18, step #2446] loss: 1.461737297728055\n",
      "[EPOCH #18, step #2448] loss: 1.4620491539813782\n",
      "[EPOCH #18, step #2450] loss: 1.462172923064728\n",
      "[EPOCH #18, step #2452] loss: 1.462004347621204\n",
      "[EPOCH #18, step #2454] loss: 1.462021097291997\n",
      "[EPOCH #18, step #2456] loss: 1.4620662916953553\n",
      "[EPOCH #18, step #2458] loss: 1.4618190209426352\n",
      "[EPOCH #18, step #2460] loss: 1.4619760652326657\n",
      "[EPOCH #18, step #2462] loss: 1.4621418861175426\n",
      "[EPOCH #18, step #2464] loss: 1.4624858436913326\n",
      "[EPOCH #18, step #2466] loss: 1.4623382129213034\n",
      "[EPOCH #18, step #2468] loss: 1.4623772924658063\n",
      "[EPOCH #18, step #2470] loss: 1.4625539641687137\n",
      "[EPOCH #18, step #2472] loss: 1.4624103357856495\n",
      "[EPOCH #18, step #2474] loss: 1.4624312523639564\n",
      "[EPOCH #18, step #2476] loss: 1.4622662088107716\n",
      "[EPOCH #18, step #2478] loss: 1.4623300969576634\n",
      "[EPOCH #18, step #2480] loss: 1.4621020989858158\n",
      "[EPOCH #18, step #2482] loss: 1.4621705706927068\n",
      "[EPOCH #18, step #2484] loss: 1.462145534943287\n",
      "[EPOCH #18, step #2486] loss: 1.462023116806975\n",
      "[EPOCH #18, step #2488] loss: 1.4617444874771919\n",
      "[EPOCH #18, step #2490] loss: 1.4614068856204863\n",
      "[EPOCH #18, step #2492] loss: 1.4614017500582823\n",
      "[EPOCH #18, step #2494] loss: 1.4614191988188183\n",
      "[EPOCH #18, step #2496] loss: 1.4615631178707709\n",
      "[EPOCH #18, step #2498] loss: 1.4612303690559247\n",
      "[EPOCH #18, elapsed time: 9158.744[sec]] loss: 1.4610934242486955\n",
      "[EPOCH #19, step #0] loss: 1.3065963983535767\n",
      "[EPOCH #19, step #2] loss: 1.4407878319422405\n",
      "[EPOCH #19, step #4] loss: 1.422441267967224\n",
      "[EPOCH #19, step #6] loss: 1.476536682673863\n",
      "[EPOCH #19, step #8] loss: 1.5372896989186604\n",
      "[EPOCH #19, step #10] loss: 1.5146037448536267\n",
      "[EPOCH #19, step #12] loss: 1.5162552778537457\n",
      "[EPOCH #19, step #14] loss: 1.471270537376404\n",
      "[EPOCH #19, step #16] loss: 1.455513680682463\n",
      "[EPOCH #19, step #18] loss: 1.4443292366830927\n",
      "[EPOCH #19, step #20] loss: 1.4395059063321067\n",
      "[EPOCH #19, step #22] loss: 1.4116484289583953\n",
      "[EPOCH #19, step #24] loss: 1.388390007019043\n",
      "[EPOCH #19, step #26] loss: 1.432287163204617\n",
      "[EPOCH #19, step #28] loss: 1.4314580128110688\n",
      "[EPOCH #19, step #30] loss: 1.425291645911432\n",
      "[EPOCH #19, step #32] loss: 1.4151146086779507\n",
      "[EPOCH #19, step #34] loss: 1.3981684344155447\n",
      "[EPOCH #19, step #36] loss: 1.4008799436930064\n",
      "[EPOCH #19, step #38] loss: 1.399316430091858\n",
      "[EPOCH #19, step #40] loss: 1.3891946237261703\n",
      "[EPOCH #19, step #42] loss: 1.3776433814403624\n",
      "[EPOCH #19, step #44] loss: 1.3700934794214037\n",
      "[EPOCH #19, step #46] loss: 1.373641423722531\n",
      "[EPOCH #19, step #48] loss: 1.3788057894122845\n",
      "[EPOCH #19, step #50] loss: 1.3734218665197784\n",
      "[EPOCH #19, step #52] loss: 1.3838170935522836\n",
      "[EPOCH #19, step #54] loss: 1.3986443985592236\n",
      "[EPOCH #19, step #56] loss: 1.4015235179348995\n",
      "[EPOCH #19, step #58] loss: 1.4023259059857514\n",
      "[EPOCH #19, step #60] loss: 1.4055429452755412\n",
      "[EPOCH #19, step #62] loss: 1.389911775551145\n",
      "[EPOCH #19, step #64] loss: 1.3901447341992306\n",
      "[EPOCH #19, step #66] loss: 1.3851223587989807\n",
      "[EPOCH #19, step #68] loss: 1.391139024409695\n",
      "[EPOCH #19, step #70] loss: 1.3887018393462813\n",
      "[EPOCH #19, step #72] loss: 1.3897700824149668\n",
      "[EPOCH #19, step #74] loss: 1.3893467211723327\n",
      "[EPOCH #19, step #76] loss: 1.3782562257407547\n",
      "[EPOCH #19, step #78] loss: 1.365893222863161\n",
      "[EPOCH #19, step #80] loss: 1.3667596379915874\n",
      "[EPOCH #19, step #82] loss: 1.369071800306619\n",
      "[EPOCH #19, step #84] loss: 1.3697761374361375\n",
      "[EPOCH #19, step #86] loss: 1.3644773912155765\n",
      "[EPOCH #19, step #88] loss: 1.3635876587267672\n",
      "[EPOCH #19, step #90] loss: 1.364300052543263\n",
      "[EPOCH #19, step #92] loss: 1.3654081827850753\n",
      "[EPOCH #19, step #94] loss: 1.3618833635982714\n",
      "[EPOCH #19, step #96] loss: 1.3651795700653313\n",
      "[EPOCH #19, step #98] loss: 1.3700687578230193\n",
      "[EPOCH #19, step #100] loss: 1.3613793814536368\n",
      "[EPOCH #19, step #102] loss: 1.358471299838094\n",
      "[EPOCH #19, step #104] loss: 1.3548856723876226\n",
      "[EPOCH #19, step #106] loss: 1.3537855293149146\n",
      "[EPOCH #19, step #108] loss: 1.3551482410605895\n",
      "[EPOCH #19, step #110] loss: 1.3504054041596147\n",
      "[EPOCH #19, step #112] loss: 1.3590695425472428\n",
      "[EPOCH #19, step #114] loss: 1.361818972877834\n",
      "[EPOCH #19, step #116] loss: 1.3627562787797716\n",
      "[EPOCH #19, step #118] loss: 1.361334970017441\n",
      "[EPOCH #19, step #120] loss: 1.361443227972866\n",
      "[EPOCH #19, step #122] loss: 1.3611508016663838\n",
      "[EPOCH #19, step #124] loss: 1.3584076738357544\n",
      "[EPOCH #19, step #126] loss: 1.3640297379080706\n",
      "[EPOCH #19, step #128] loss: 1.36304131404374\n",
      "[EPOCH #19, step #130] loss: 1.3602553132836146\n",
      "[EPOCH #19, step #132] loss: 1.3571544249254959\n",
      "[EPOCH #19, step #134] loss: 1.360931467126917\n",
      "[EPOCH #19, step #136] loss: 1.3587856301426018\n",
      "[EPOCH #19, step #138] loss: 1.358785636991048\n",
      "[EPOCH #19, step #140] loss: 1.3590255612177207\n",
      "[EPOCH #19, step #142] loss: 1.3600554999771652\n",
      "[EPOCH #19, step #144] loss: 1.358455308552446\n",
      "[EPOCH #19, step #146] loss: 1.3607537697772591\n",
      "[EPOCH #19, step #148] loss: 1.3579623131143967\n",
      "[EPOCH #19, step #150] loss: 1.358611631867112\n",
      "[EPOCH #19, step #152] loss: 1.3581056275398902\n",
      "[EPOCH #19, step #154] loss: 1.362344611844709\n",
      "[EPOCH #19, step #156] loss: 1.3665692753093257\n",
      "[EPOCH #19, step #158] loss: 1.3666147405996263\n",
      "[EPOCH #19, step #160] loss: 1.3656571118727974\n",
      "[EPOCH #19, step #162] loss: 1.3660448036310864\n",
      "[EPOCH #19, step #164] loss: 1.3648433977907355\n",
      "[EPOCH #19, step #166] loss: 1.365166805104581\n",
      "[EPOCH #19, step #168] loss: 1.3656090727219214\n",
      "[EPOCH #19, step #170] loss: 1.3625275262615137\n",
      "[EPOCH #19, step #172] loss: 1.3645430276159607\n",
      "[EPOCH #19, step #174] loss: 1.367321628502437\n",
      "[EPOCH #19, step #176] loss: 1.3731166141181341\n",
      "[EPOCH #19, step #178] loss: 1.3733333812079616\n",
      "[EPOCH #19, step #180] loss: 1.3740709022263795\n",
      "[EPOCH #19, step #182] loss: 1.3745348039872007\n",
      "[EPOCH #19, step #184] loss: 1.3755046196886012\n",
      "[EPOCH #19, step #186] loss: 1.3733947254757193\n",
      "[EPOCH #19, step #188] loss: 1.372126527248867\n",
      "[EPOCH #19, step #190] loss: 1.3726128910848607\n",
      "[EPOCH #19, step #192] loss: 1.3766678370960017\n",
      "[EPOCH #19, step #194] loss: 1.377089863251417\n",
      "[EPOCH #19, step #196] loss: 1.3830176764333308\n",
      "[EPOCH #19, step #198] loss: 1.382959462589954\n",
      "[EPOCH #19, step #200] loss: 1.3829114404483813\n",
      "[EPOCH #19, step #202] loss: 1.3845780949874464\n",
      "[EPOCH #19, step #204] loss: 1.3842082102124285\n",
      "[EPOCH #19, step #206] loss: 1.3836336622491552\n",
      "[EPOCH #19, step #208] loss: 1.3874677131620892\n",
      "[EPOCH #19, step #210] loss: 1.3905691956456803\n",
      "[EPOCH #19, step #212] loss: 1.3879631049756154\n",
      "[EPOCH #19, step #214] loss: 1.3874599126882332\n",
      "[EPOCH #19, step #216] loss: 1.3845144556964049\n",
      "[EPOCH #19, step #218] loss: 1.3834294742100859\n",
      "[EPOCH #19, step #220] loss: 1.3850409631276024\n",
      "[EPOCH #19, step #222] loss: 1.3832784998042702\n",
      "[EPOCH #19, step #224] loss: 1.3827402851316664\n",
      "[EPOCH #19, step #226] loss: 1.3819601816752933\n",
      "[EPOCH #19, step #228] loss: 1.3799516444122948\n",
      "[EPOCH #19, step #230] loss: 1.3800985356429956\n",
      "[EPOCH #19, step #232] loss: 1.38033426140511\n",
      "[EPOCH #19, step #234] loss: 1.3793901552545262\n",
      "[EPOCH #19, step #236] loss: 1.3807637583354355\n",
      "[EPOCH #19, step #238] loss: 1.3793212541975237\n",
      "[EPOCH #19, step #240] loss: 1.3763803451387715\n",
      "[EPOCH #19, step #242] loss: 1.3776868758378205\n",
      "[EPOCH #19, step #244] loss: 1.3764719065354796\n",
      "[EPOCH #19, step #246] loss: 1.3761417385537615\n",
      "[EPOCH #19, step #248] loss: 1.3735595982237514\n",
      "[EPOCH #19, step #250] loss: 1.3744794541146175\n",
      "[EPOCH #19, step #252] loss: 1.3780489055064356\n",
      "[EPOCH #19, step #254] loss: 1.3760507268064162\n",
      "[EPOCH #19, step #256] loss: 1.3758719841793818\n",
      "[EPOCH #19, step #258] loss: 1.3767872457338577\n",
      "[EPOCH #19, step #260] loss: 1.3771965875936194\n",
      "[EPOCH #19, step #262] loss: 1.377325447566609\n",
      "[EPOCH #19, step #264] loss: 1.3786887103656553\n",
      "[EPOCH #19, step #266] loss: 1.3792044654321134\n",
      "[EPOCH #19, step #268] loss: 1.3811441936900624\n",
      "[EPOCH #19, step #270] loss: 1.3795321183450988\n",
      "[EPOCH #19, step #272] loss: 1.37910592796165\n",
      "[EPOCH #19, step #274] loss: 1.3805045281757007\n",
      "[EPOCH #19, step #276] loss: 1.382147645476923\n",
      "[EPOCH #19, step #278] loss: 1.381826117260909\n",
      "[EPOCH #19, step #280] loss: 1.3820730458374975\n",
      "[EPOCH #19, step #282] loss: 1.3811249166411141\n",
      "[EPOCH #19, step #284] loss: 1.3813654734377276\n",
      "[EPOCH #19, step #286] loss: 1.3799223679698718\n",
      "[EPOCH #19, step #288] loss: 1.381815184771396\n",
      "[EPOCH #19, step #290] loss: 1.382500034836969\n",
      "[EPOCH #19, step #292] loss: 1.3814537602479955\n",
      "[EPOCH #19, step #294] loss: 1.3818830756817835\n",
      "[EPOCH #19, step #296] loss: 1.3827716296770758\n",
      "[EPOCH #19, step #298] loss: 1.3822129478422693\n",
      "[EPOCH #19, step #300] loss: 1.3825663292526802\n",
      "[EPOCH #19, step #302] loss: 1.3813464090769048\n",
      "[EPOCH #19, step #304] loss: 1.3826476280806494\n",
      "[EPOCH #19, step #306] loss: 1.3825906056922888\n",
      "[EPOCH #19, step #308] loss: 1.3838898421877024\n",
      "[EPOCH #19, step #310] loss: 1.3849161579677913\n",
      "[EPOCH #19, step #312] loss: 1.385916921658257\n",
      "[EPOCH #19, step #314] loss: 1.3851169968408252\n",
      "[EPOCH #19, step #316] loss: 1.3851471898683614\n",
      "[EPOCH #19, step #318] loss: 1.3823651473350285\n",
      "[EPOCH #19, step #320] loss: 1.383241076521413\n",
      "[EPOCH #19, step #322] loss: 1.3831171736628647\n",
      "[EPOCH #19, step #324] loss: 1.3823351982923655\n",
      "[EPOCH #19, step #326] loss: 1.3814515558951492\n",
      "[EPOCH #19, step #328] loss: 1.3829436586620598\n",
      "[EPOCH #19, step #330] loss: 1.3837096725345739\n",
      "[EPOCH #19, step #332] loss: 1.3818983695170544\n",
      "[EPOCH #19, step #334] loss: 1.38201841382838\n",
      "[EPOCH #19, step #336] loss: 1.3815135793091635\n",
      "[EPOCH #19, step #338] loss: 1.3823841096377303\n",
      "[EPOCH #19, step #340] loss: 1.3823533526613565\n",
      "[EPOCH #19, step #342] loss: 1.3810551244732938\n",
      "[EPOCH #19, step #344] loss: 1.3812142208002616\n",
      "[EPOCH #19, step #346] loss: 1.3815533841721264\n",
      "[EPOCH #19, step #348] loss: 1.380281402422569\n",
      "[EPOCH #19, step #350] loss: 1.3807247467869708\n",
      "[EPOCH #19, step #352] loss: 1.3796311351800439\n",
      "[EPOCH #19, step #354] loss: 1.3812899846426199\n",
      "[EPOCH #19, step #356] loss: 1.3830756788828127\n",
      "[EPOCH #19, step #358] loss: 1.3822064205464546\n",
      "[EPOCH #19, step #360] loss: 1.381781432602214\n",
      "[EPOCH #19, step #362] loss: 1.3802662314462268\n",
      "[EPOCH #19, step #364] loss: 1.380562313125558\n",
      "[EPOCH #19, step #366] loss: 1.3824067114159586\n",
      "[EPOCH #19, step #368] loss: 1.3818854489300632\n",
      "[EPOCH #19, step #370] loss: 1.3843684345885428\n",
      "[EPOCH #19, step #372] loss: 1.3831689522349482\n",
      "[EPOCH #19, step #374] loss: 1.38148020585378\n",
      "[EPOCH #19, step #376] loss: 1.3830708091391808\n",
      "[EPOCH #19, step #378] loss: 1.3809580265060264\n",
      "[EPOCH #19, step #380] loss: 1.3814093669255574\n",
      "[EPOCH #19, step #382] loss: 1.3822067524683381\n",
      "[EPOCH #19, step #384] loss: 1.3821658598912228\n",
      "[EPOCH #19, step #386] loss: 1.382136953893558\n",
      "[EPOCH #19, step #388] loss: 1.3818317527636157\n",
      "[EPOCH #19, step #390] loss: 1.3823279238417936\n",
      "[EPOCH #19, step #392] loss: 1.3817693679084002\n",
      "[EPOCH #19, step #394] loss: 1.3817182134978379\n",
      "[EPOCH #19, step #396] loss: 1.3811895653642996\n",
      "[EPOCH #19, step #398] loss: 1.3811940476111602\n",
      "[EPOCH #19, step #400] loss: 1.3809938450109334\n",
      "[EPOCH #19, step #402] loss: 1.3807160941601984\n",
      "[EPOCH #19, step #404] loss: 1.3815704847559518\n",
      "[EPOCH #19, step #406] loss: 1.3803652072421455\n",
      "[EPOCH #19, step #408] loss: 1.3807127378097666\n",
      "[EPOCH #19, step #410] loss: 1.3790037273780562\n",
      "[EPOCH #19, step #412] loss: 1.3791772700106548\n",
      "[EPOCH #19, step #414] loss: 1.3786733335759267\n",
      "[EPOCH #19, step #416] loss: 1.3782063295229448\n",
      "[EPOCH #19, step #418] loss: 1.3793760863864053\n",
      "[EPOCH #19, step #420] loss: 1.378390421352024\n",
      "[EPOCH #19, step #422] loss: 1.377157120417196\n",
      "[EPOCH #19, step #424] loss: 1.3759326529502869\n",
      "[EPOCH #19, step #426] loss: 1.3754994471402582\n",
      "[EPOCH #19, step #428] loss: 1.3753288849528298\n",
      "[EPOCH #19, step #430] loss: 1.376455793386269\n",
      "[EPOCH #19, step #432] loss: 1.3770919610116004\n",
      "[EPOCH #19, step #434] loss: 1.3772397440055322\n",
      "[EPOCH #19, step #436] loss: 1.3788093899971288\n",
      "[EPOCH #19, step #438] loss: 1.3787975407678608\n",
      "[EPOCH #19, step #440] loss: 1.378690992758658\n",
      "[EPOCH #19, step #442] loss: 1.3783021033752045\n",
      "[EPOCH #19, step #444] loss: 1.3785672119494234\n",
      "[EPOCH #19, step #446] loss: 1.3791953987989916\n",
      "[EPOCH #19, step #448] loss: 1.378473276417611\n",
      "[EPOCH #19, step #450] loss: 1.3798830061159748\n",
      "[EPOCH #19, step #452] loss: 1.3781045258176774\n",
      "[EPOCH #19, step #454] loss: 1.3788871845046242\n",
      "[EPOCH #19, step #456] loss: 1.3788201079848559\n",
      "[EPOCH #19, step #458] loss: 1.3788898688515807\n",
      "[EPOCH #19, step #460] loss: 1.3802902611889705\n",
      "[EPOCH #19, step #462] loss: 1.3810950580734929\n",
      "[EPOCH #19, step #464] loss: 1.3809416015942892\n",
      "[EPOCH #19, step #466] loss: 1.3825010499045476\n",
      "[EPOCH #19, step #468] loss: 1.3824776295405716\n",
      "[EPOCH #19, step #470] loss: 1.3818464984053513\n",
      "[EPOCH #19, step #472] loss: 1.381493217219258\n",
      "[EPOCH #19, step #474] loss: 1.3812413550678053\n",
      "[EPOCH #19, step #476] loss: 1.3827178304550283\n",
      "[EPOCH #19, step #478] loss: 1.384244941594954\n",
      "[EPOCH #19, step #480] loss: 1.3830556516340022\n",
      "[EPOCH #19, step #482] loss: 1.3833158118631035\n",
      "[EPOCH #19, step #484] loss: 1.3834667605223114\n",
      "[EPOCH #19, step #486] loss: 1.3847266047642217\n",
      "[EPOCH #19, step #488] loss: 1.3847857905068037\n",
      "[EPOCH #19, step #490] loss: 1.384607606652798\n",
      "[EPOCH #19, step #492] loss: 1.3849134880437328\n",
      "[EPOCH #19, step #494] loss: 1.3849940374644116\n",
      "[EPOCH #19, step #496] loss: 1.3849492982119862\n",
      "[EPOCH #19, step #498] loss: 1.3849640649879624\n",
      "[EPOCH #19, step #500] loss: 1.3848179678717059\n",
      "[EPOCH #19, step #502] loss: 1.3843529603590312\n",
      "[EPOCH #19, step #504] loss: 1.384409264526745\n",
      "[EPOCH #19, step #506] loss: 1.3841789377746732\n",
      "[EPOCH #19, step #508] loss: 1.3848910814184103\n",
      "[EPOCH #19, step #510] loss: 1.3838196003740315\n",
      "[EPOCH #19, step #512] loss: 1.3841183826937313\n",
      "[EPOCH #19, step #514] loss: 1.3835134575667891\n",
      "[EPOCH #19, step #516] loss: 1.3842411935905885\n",
      "[EPOCH #19, step #518] loss: 1.384341113599509\n",
      "[EPOCH #19, step #520] loss: 1.385158983164694\n",
      "[EPOCH #19, step #522] loss: 1.3868943528053181\n",
      "[EPOCH #19, step #524] loss: 1.3870627691632225\n",
      "[EPOCH #19, step #526] loss: 1.388782908387157\n",
      "[EPOCH #19, step #528] loss: 1.3890124998831794\n",
      "[EPOCH #19, step #530] loss: 1.3887298333891815\n",
      "[EPOCH #19, step #532] loss: 1.3885333379258806\n",
      "[EPOCH #19, step #534] loss: 1.3889864527176474\n",
      "[EPOCH #19, step #536] loss: 1.390151984642782\n",
      "[EPOCH #19, step #538] loss: 1.3892379685102898\n",
      "[EPOCH #19, step #540] loss: 1.389737067513457\n",
      "[EPOCH #19, step #542] loss: 1.3904181541000282\n",
      "[EPOCH #19, step #544] loss: 1.3897148353244186\n",
      "[EPOCH #19, step #546] loss: 1.3883394685044368\n",
      "[EPOCH #19, step #548] loss: 1.3886715108579626\n",
      "[EPOCH #19, step #550] loss: 1.387436852697452\n",
      "[EPOCH #19, step #552] loss: 1.3884826122528822\n",
      "[EPOCH #19, step #554] loss: 1.3889424667702064\n",
      "[EPOCH #19, step #556] loss: 1.3887384592737715\n",
      "[EPOCH #19, step #558] loss: 1.388396478083138\n",
      "[EPOCH #19, step #560] loss: 1.3887917423843275\n",
      "[EPOCH #19, step #562] loss: 1.3882254895689645\n",
      "[EPOCH #19, step #564] loss: 1.388577681727114\n",
      "[EPOCH #19, step #566] loss: 1.3890368698765991\n",
      "[EPOCH #19, step #568] loss: 1.3885380295751804\n",
      "[EPOCH #19, step #570] loss: 1.3880890726834378\n",
      "[EPOCH #19, step #572] loss: 1.3882265147114299\n",
      "[EPOCH #19, step #574] loss: 1.3877786480862162\n",
      "[EPOCH #19, step #576] loss: 1.3882320470578542\n",
      "[EPOCH #19, step #578] loss: 1.3873758241920273\n",
      "[EPOCH #19, step #580] loss: 1.3880997838744198\n",
      "[EPOCH #19, step #582] loss: 1.3884616769198488\n",
      "[EPOCH #19, step #584] loss: 1.3882373043614575\n",
      "[EPOCH #19, step #586] loss: 1.3889104763531401\n",
      "[EPOCH #19, step #588] loss: 1.3886983688092192\n",
      "[EPOCH #19, step #590] loss: 1.388615740737334\n",
      "[EPOCH #19, step #592] loss: 1.3898289165448579\n",
      "[EPOCH #19, step #594] loss: 1.3904984724621814\n",
      "[EPOCH #19, step #596] loss: 1.3896938845939573\n",
      "[EPOCH #19, step #598] loss: 1.3891248746785974\n",
      "[EPOCH #19, step #600] loss: 1.3892217323109632\n",
      "[EPOCH #19, step #602] loss: 1.3883495945637894\n",
      "[EPOCH #19, step #604] loss: 1.3888475969803236\n",
      "[EPOCH #19, step #606] loss: 1.3893678335617166\n",
      "[EPOCH #19, step #608] loss: 1.3884361361830888\n",
      "[EPOCH #19, step #610] loss: 1.3887452197348038\n",
      "[EPOCH #19, step #612] loss: 1.3891979045619\n",
      "[EPOCH #19, step #614] loss: 1.389650718758746\n",
      "[EPOCH #19, step #616] loss: 1.3903610588472513\n",
      "[EPOCH #19, step #618] loss: 1.3898570982435408\n",
      "[EPOCH #19, step #620] loss: 1.3895598692210591\n",
      "[EPOCH #19, step #622] loss: 1.3888570938982894\n",
      "[EPOCH #19, step #624] loss: 1.3889216608047485\n",
      "[EPOCH #19, step #626] loss: 1.3890715076972804\n",
      "[EPOCH #19, step #628] loss: 1.3882713164358336\n",
      "[EPOCH #19, step #630] loss: 1.3889677229849549\n",
      "[EPOCH #19, step #632] loss: 1.3884770197890945\n",
      "[EPOCH #19, step #634] loss: 1.3887559892624382\n",
      "[EPOCH #19, step #636] loss: 1.3890096383341815\n",
      "[EPOCH #19, step #638] loss: 1.3897625452289373\n",
      "[EPOCH #19, step #640] loss: 1.389425615624593\n",
      "[EPOCH #19, step #642] loss: 1.3907822633790747\n",
      "[EPOCH #19, step #644] loss: 1.3907202585723049\n",
      "[EPOCH #19, step #646] loss: 1.390780527403771\n",
      "[EPOCH #19, step #648] loss: 1.39057387611348\n",
      "[EPOCH #19, step #650] loss: 1.3909696737925212\n",
      "[EPOCH #19, step #652] loss: 1.3914054644965834\n",
      "[EPOCH #19, step #654] loss: 1.3914609093702477\n",
      "[EPOCH #19, step #656] loss: 1.3915769240990439\n",
      "[EPOCH #19, step #658] loss: 1.3913200207292038\n",
      "[EPOCH #19, step #660] loss: 1.3908761321326066\n",
      "[EPOCH #19, step #662] loss: 1.3907274696442156\n",
      "[EPOCH #19, step #664] loss: 1.3906077514017434\n",
      "[EPOCH #19, step #666] loss: 1.390448044801223\n",
      "[EPOCH #19, step #668] loss: 1.3905370153475591\n",
      "[EPOCH #19, step #670] loss: 1.3903257018052342\n",
      "[EPOCH #19, step #672] loss: 1.3894300086182967\n",
      "[EPOCH #19, step #674] loss: 1.3886942763681764\n",
      "[EPOCH #19, step #676] loss: 1.3890997084240089\n",
      "[EPOCH #19, step #678] loss: 1.3892542855026795\n",
      "[EPOCH #19, step #680] loss: 1.388876393240454\n",
      "[EPOCH #19, step #682] loss: 1.3895565509621606\n",
      "[EPOCH #19, step #684] loss: 1.3890585969834433\n",
      "[EPOCH #19, step #686] loss: 1.3891847852883208\n",
      "[EPOCH #19, step #688] loss: 1.3888216718533908\n",
      "[EPOCH #19, step #690] loss: 1.389164763921939\n",
      "[EPOCH #19, step #692] loss: 1.3890646067360606\n",
      "[EPOCH #19, step #694] loss: 1.3886529230385376\n",
      "[EPOCH #19, step #696] loss: 1.3896884077590712\n",
      "[EPOCH #19, step #698] loss: 1.389231143335416\n",
      "[EPOCH #19, step #700] loss: 1.3889950655836523\n",
      "[EPOCH #19, step #702] loss: 1.3891663726837842\n",
      "[EPOCH #19, step #704] loss: 1.3879624223032743\n",
      "[EPOCH #19, step #706] loss: 1.3878033400593586\n",
      "[EPOCH #19, step #708] loss: 1.3875577770940675\n",
      "[EPOCH #19, step #710] loss: 1.3875321956291145\n",
      "[EPOCH #19, step #712] loss: 1.387253967107262\n",
      "[EPOCH #19, step #714] loss: 1.3873508276639286\n",
      "[EPOCH #19, step #716] loss: 1.3866714468560957\n",
      "[EPOCH #19, step #718] loss: 1.3861670900286487\n",
      "[EPOCH #19, step #720] loss: 1.3863428588052398\n",
      "[EPOCH #19, step #722] loss: 1.386102850671296\n",
      "[EPOCH #19, step #724] loss: 1.3871641191942938\n",
      "[EPOCH #19, step #726] loss: 1.387457809061263\n",
      "[EPOCH #19, step #728] loss: 1.3880298693647763\n",
      "[EPOCH #19, step #730] loss: 1.3875004663023838\n",
      "[EPOCH #19, step #732] loss: 1.3874223459954151\n",
      "[EPOCH #19, step #734] loss: 1.3864472417604357\n",
      "[EPOCH #19, step #736] loss: 1.3867410435120158\n",
      "[EPOCH #19, step #738] loss: 1.38602183797524\n",
      "[EPOCH #19, step #740] loss: 1.3857639518022216\n",
      "[EPOCH #19, step #742] loss: 1.3852664028491177\n",
      "[EPOCH #19, step #744] loss: 1.3858008811937883\n",
      "[EPOCH #19, step #746] loss: 1.3861539847400772\n",
      "[EPOCH #19, step #748] loss: 1.3870866141109186\n",
      "[EPOCH #19, step #750] loss: 1.3871317176463283\n",
      "[EPOCH #19, step #752] loss: 1.3869686471830167\n",
      "[EPOCH #19, step #754] loss: 1.386728948631034\n",
      "[EPOCH #19, step #756] loss: 1.386350710924267\n",
      "[EPOCH #19, step #758] loss: 1.3864819634416201\n",
      "[EPOCH #19, step #760] loss: 1.3859628034797198\n",
      "[EPOCH #19, step #762] loss: 1.386936312109271\n",
      "[EPOCH #19, step #764] loss: 1.3864991080527211\n",
      "[EPOCH #19, step #766] loss: 1.3861404980643321\n",
      "[EPOCH #19, step #768] loss: 1.3867560026704568\n",
      "[EPOCH #19, step #770] loss: 1.3857448244837007\n",
      "[EPOCH #19, step #772] loss: 1.3867107142452126\n",
      "[EPOCH #19, step #774] loss: 1.385749670767015\n",
      "[EPOCH #19, step #776] loss: 1.3851969516722238\n",
      "[EPOCH #19, step #778] loss: 1.3851601367431365\n",
      "[EPOCH #19, step #780] loss: 1.3851209492750571\n",
      "[EPOCH #19, step #782] loss: 1.3848753161205034\n",
      "[EPOCH #19, step #784] loss: 1.3844900052258924\n",
      "[EPOCH #19, step #786] loss: 1.3848325859333994\n",
      "[EPOCH #19, step #788] loss: 1.3839523478001545\n",
      "[EPOCH #19, step #790] loss: 1.3840353045843343\n",
      "[EPOCH #19, step #792] loss: 1.3835269665206966\n",
      "[EPOCH #19, step #794] loss: 1.3836909685494765\n",
      "[EPOCH #19, step #796] loss: 1.3832480475175635\n",
      "[EPOCH #19, step #798] loss: 1.382918681758217\n",
      "[EPOCH #19, step #800] loss: 1.3825946934660722\n",
      "[EPOCH #19, step #802] loss: 1.3829495039853184\n",
      "[EPOCH #19, step #804] loss: 1.3828437485309861\n",
      "[EPOCH #19, step #806] loss: 1.3821873242379417\n",
      "[EPOCH #19, step #808] loss: 1.3818290808292195\n",
      "[EPOCH #19, step #810] loss: 1.3816320281728423\n",
      "[EPOCH #19, step #812] loss: 1.381468009098283\n",
      "[EPOCH #19, step #814] loss: 1.3811103146500383\n",
      "[EPOCH #19, step #816] loss: 1.3810126733312993\n",
      "[EPOCH #19, step #818] loss: 1.3803554518609984\n",
      "[EPOCH #19, step #820] loss: 1.3801849274629507\n",
      "[EPOCH #19, step #822] loss: 1.3797300872941787\n",
      "[EPOCH #19, step #824] loss: 1.3796526735479182\n",
      "[EPOCH #19, step #826] loss: 1.3797739487605343\n",
      "[EPOCH #19, step #828] loss: 1.3798318925898958\n",
      "[EPOCH #19, step #830] loss: 1.3800714760480806\n",
      "[EPOCH #19, step #832] loss: 1.37993078171706\n",
      "[EPOCH #19, step #834] loss: 1.3791392063666246\n",
      "[EPOCH #19, step #836] loss: 1.3792922196280002\n",
      "[EPOCH #19, step #838] loss: 1.3792748617472326\n",
      "[EPOCH #19, step #840] loss: 1.378885028762001\n",
      "[EPOCH #19, step #842] loss: 1.3789737660124066\n",
      "[EPOCH #19, step #844] loss: 1.3790717610240688\n",
      "[EPOCH #19, step #846] loss: 1.378637319331749\n",
      "[EPOCH #19, step #848] loss: 1.3791545896283026\n",
      "[EPOCH #19, step #850] loss: 1.379417831132891\n",
      "[EPOCH #19, step #852] loss: 1.3788021083174389\n",
      "[EPOCH #19, step #854] loss: 1.378543740406371\n",
      "[EPOCH #19, step #856] loss: 1.377782468756828\n",
      "[EPOCH #19, step #858] loss: 1.377521475479961\n",
      "[EPOCH #19, step #860] loss: 1.3767787519924592\n",
      "[EPOCH #19, step #862] loss: 1.3771506604562629\n",
      "[EPOCH #19, step #864] loss: 1.3773699403498214\n",
      "[EPOCH #19, step #866] loss: 1.3772847338943746\n",
      "[EPOCH #19, step #868] loss: 1.377382414524794\n",
      "[EPOCH #19, step #870] loss: 1.37765983776986\n",
      "[EPOCH #19, step #872] loss: 1.3775451599800572\n",
      "[EPOCH #19, step #874] loss: 1.3771066062109811\n",
      "[EPOCH #19, step #876] loss: 1.376829283947004\n",
      "[EPOCH #19, step #878] loss: 1.3762480074770758\n",
      "[EPOCH #19, step #880] loss: 1.3759677140856168\n",
      "[EPOCH #19, step #882] loss: 1.3770594368704583\n",
      "[EPOCH #19, step #884] loss: 1.377432255286955\n",
      "[EPOCH #19, step #886] loss: 1.3772080208026838\n",
      "[EPOCH #19, step #888] loss: 1.3770336567081671\n",
      "[EPOCH #19, step #890] loss: 1.3773378852240565\n",
      "[EPOCH #19, step #892] loss: 1.3772004798705473\n",
      "[EPOCH #19, step #894] loss: 1.3779886003313118\n",
      "[EPOCH #19, step #896] loss: 1.3777304332258975\n",
      "[EPOCH #19, step #898] loss: 1.3778176312982306\n",
      "[EPOCH #19, step #900] loss: 1.3780907880717457\n",
      "[EPOCH #19, step #902] loss: 1.378106328736112\n",
      "[EPOCH #19, step #904] loss: 1.3779511396397544\n",
      "[EPOCH #19, step #906] loss: 1.3777931331931033\n",
      "[EPOCH #19, step #908] loss: 1.3776975458342382\n",
      "[EPOCH #19, step #910] loss: 1.3775560399180056\n",
      "[EPOCH #19, step #912] loss: 1.3775422591369229\n",
      "[EPOCH #19, step #914] loss: 1.3781483237209216\n",
      "[EPOCH #19, step #916] loss: 1.3782323016465166\n",
      "[EPOCH #19, step #918] loss: 1.3783242306849384\n",
      "[EPOCH #19, step #920] loss: 1.3785889874840405\n",
      "[EPOCH #19, step #922] loss: 1.3778917874700973\n",
      "[EPOCH #19, step #924] loss: 1.3777744018709337\n",
      "[EPOCH #19, step #926] loss: 1.3773987369115557\n",
      "[EPOCH #19, step #928] loss: 1.3768362009615123\n",
      "[EPOCH #19, step #930] loss: 1.3766570723786646\n",
      "[EPOCH #19, step #932] loss: 1.377158473286726\n",
      "[EPOCH #19, step #934] loss: 1.3767457811590185\n",
      "[EPOCH #19, step #936] loss: 1.3770480111416274\n",
      "[EPOCH #19, step #938] loss: 1.3771128272350095\n",
      "[EPOCH #19, step #940] loss: 1.3769178684408936\n",
      "[EPOCH #19, step #942] loss: 1.3773427047507\n",
      "[EPOCH #19, step #944] loss: 1.377278964986246\n",
      "[EPOCH #19, step #946] loss: 1.3769462200505178\n",
      "[EPOCH #19, step #948] loss: 1.3765766891965876\n",
      "[EPOCH #19, step #950] loss: 1.3765706943287332\n",
      "[EPOCH #19, step #952] loss: 1.3769581197816703\n",
      "[EPOCH #19, step #954] loss: 1.3771644342632194\n",
      "[EPOCH #19, step #956] loss: 1.377164643261749\n",
      "[EPOCH #19, step #958] loss: 1.3769098351844533\n",
      "[EPOCH #19, step #960] loss: 1.3770217789447519\n",
      "[EPOCH #19, step #962] loss: 1.3769113780429678\n",
      "[EPOCH #19, step #964] loss: 1.3765134372241756\n",
      "[EPOCH #19, step #966] loss: 1.3762376485344296\n",
      "[EPOCH #19, step #968] loss: 1.3756835188166892\n",
      "[EPOCH #19, step #970] loss: 1.3751253224180362\n",
      "[EPOCH #19, step #972] loss: 1.3749984252244571\n",
      "[EPOCH #19, step #974] loss: 1.3747679962867345\n",
      "[EPOCH #19, step #976] loss: 1.3751405694101582\n",
      "[EPOCH #19, step #978] loss: 1.3742646821550988\n",
      "[EPOCH #19, step #980] loss: 1.3739666690884744\n",
      "[EPOCH #19, step #982] loss: 1.3743762273875768\n",
      "[EPOCH #19, step #984] loss: 1.3746999165733453\n",
      "[EPOCH #19, step #986] loss: 1.3744145131763355\n",
      "[EPOCH #19, step #988] loss: 1.3745972835378772\n",
      "[EPOCH #19, step #990] loss: 1.3746607605552097\n",
      "[EPOCH #19, step #992] loss: 1.3747066222168767\n",
      "[EPOCH #19, step #994] loss: 1.3746721913467101\n",
      "[EPOCH #19, step #996] loss: 1.3753639861358444\n",
      "[EPOCH #19, step #998] loss: 1.3753683731720612\n",
      "[EPOCH #19, step #1000] loss: 1.3750514104054286\n",
      "[EPOCH #19, step #1002] loss: 1.3749868046132065\n",
      "[EPOCH #19, step #1004] loss: 1.3747506829636607\n",
      "[EPOCH #19, step #1006] loss: 1.374669953041304\n",
      "[EPOCH #19, step #1008] loss: 1.374343201355608\n",
      "[EPOCH #19, step #1010] loss: 1.374141623488048\n",
      "[EPOCH #19, step #1012] loss: 1.3742503024865702\n",
      "[EPOCH #19, step #1014] loss: 1.3739768518602906\n",
      "[EPOCH #19, step #1016] loss: 1.3736729179394516\n",
      "[EPOCH #19, step #1018] loss: 1.3739369065885572\n",
      "[EPOCH #19, step #1020] loss: 1.3740397986539081\n",
      "[EPOCH #19, step #1022] loss: 1.3739710206626563\n",
      "[EPOCH #19, step #1024] loss: 1.373349584660879\n",
      "[EPOCH #19, step #1026] loss: 1.3736275891250158\n",
      "[EPOCH #19, step #1028] loss: 1.373852582378684\n",
      "[EPOCH #19, step #1030] loss: 1.3729425588935238\n",
      "[EPOCH #19, step #1032] loss: 1.3730829867596548\n",
      "[EPOCH #19, step #1034] loss: 1.3732773667948257\n",
      "[EPOCH #19, step #1036] loss: 1.3730701650694919\n",
      "[EPOCH #19, step #1038] loss: 1.3738978895806027\n",
      "[EPOCH #19, step #1040] loss: 1.3740345910692535\n",
      "[EPOCH #19, step #1042] loss: 1.3735738586373663\n",
      "[EPOCH #19, step #1044] loss: 1.3736214426145599\n",
      "[EPOCH #19, step #1046] loss: 1.3738555748232684\n",
      "[EPOCH #19, step #1048] loss: 1.3731088350794223\n",
      "[EPOCH #19, step #1050] loss: 1.3729424546946807\n",
      "[EPOCH #19, step #1052] loss: 1.3733310094925752\n",
      "[EPOCH #19, step #1054] loss: 1.3734860465424885\n",
      "[EPOCH #19, step #1056] loss: 1.3734108394570472\n",
      "[EPOCH #19, step #1058] loss: 1.3739116553206618\n",
      "[EPOCH #19, step #1060] loss: 1.3738515097279238\n",
      "[EPOCH #19, step #1062] loss: 1.373549340192933\n",
      "[EPOCH #19, step #1064] loss: 1.3729682380044963\n",
      "[EPOCH #19, step #1066] loss: 1.373546189254092\n",
      "[EPOCH #19, step #1068] loss: 1.3738509685888372\n",
      "[EPOCH #19, step #1070] loss: 1.3742365078543193\n",
      "[EPOCH #19, step #1072] loss: 1.3740491414892262\n",
      "[EPOCH #19, step #1074] loss: 1.3742903739352559\n",
      "[EPOCH #19, step #1076] loss: 1.3749699394461614\n",
      "[EPOCH #19, step #1078] loss: 1.3751453345743343\n",
      "[EPOCH #19, step #1080] loss: 1.3755496335625097\n",
      "[EPOCH #19, step #1082] loss: 1.3756760639497119\n",
      "[EPOCH #19, step #1084] loss: 1.3754501432867094\n",
      "[EPOCH #19, step #1086] loss: 1.375521979204755\n",
      "[EPOCH #19, step #1088] loss: 1.3753398132499366\n",
      "[EPOCH #19, step #1090] loss: 1.374909024955372\n",
      "[EPOCH #19, step #1092] loss: 1.3746185725910993\n",
      "[EPOCH #19, step #1094] loss: 1.3746750872973437\n",
      "[EPOCH #19, step #1096] loss: 1.374646458717075\n",
      "[EPOCH #19, step #1098] loss: 1.3744429162244995\n",
      "[EPOCH #19, step #1100] loss: 1.3743849953773561\n",
      "[EPOCH #19, step #1102] loss: 1.3745288654337768\n",
      "[EPOCH #19, step #1104] loss: 1.374753855364355\n",
      "[EPOCH #19, step #1106] loss: 1.3746882537085405\n",
      "[EPOCH #19, step #1108] loss: 1.3746863206944238\n",
      "[EPOCH #19, step #1110] loss: 1.3750689068321276\n",
      "[EPOCH #19, step #1112] loss: 1.3747086835571591\n",
      "[EPOCH #19, step #1114] loss: 1.3749412669194654\n",
      "[EPOCH #19, step #1116] loss: 1.3747200587015656\n",
      "[EPOCH #19, step #1118] loss: 1.375377906657842\n",
      "[EPOCH #19, step #1120] loss: 1.375679260167982\n",
      "[EPOCH #19, step #1122] loss: 1.3757084879828476\n",
      "[EPOCH #19, step #1124] loss: 1.37583839586046\n",
      "[EPOCH #19, step #1126] loss: 1.3761099659455172\n",
      "[EPOCH #19, step #1128] loss: 1.3758479419062897\n",
      "[EPOCH #19, step #1130] loss: 1.375644479780256\n",
      "[EPOCH #19, step #1132] loss: 1.3758426967807713\n",
      "[EPOCH #19, step #1134] loss: 1.375667207041501\n",
      "[EPOCH #19, step #1136] loss: 1.3749883199010697\n",
      "[EPOCH #19, step #1138] loss: 1.374297378615814\n",
      "[EPOCH #19, step #1140] loss: 1.3735627593647275\n",
      "[EPOCH #19, step #1142] loss: 1.37344741461471\n",
      "[EPOCH #19, step #1144] loss: 1.3734876924727162\n",
      "[EPOCH #19, step #1146] loss: 1.3735048510556442\n",
      "[EPOCH #19, step #1148] loss: 1.373540296722641\n",
      "[EPOCH #19, step #1150] loss: 1.3735381647051157\n",
      "[EPOCH #19, step #1152] loss: 1.3737534715213262\n",
      "[EPOCH #19, step #1154] loss: 1.3733329178967002\n",
      "[EPOCH #19, step #1156] loss: 1.373245848750079\n",
      "[EPOCH #19, step #1158] loss: 1.3732604681674112\n",
      "[EPOCH #19, step #1160] loss: 1.3725917856822643\n",
      "[EPOCH #19, step #1162] loss: 1.3726185570476594\n",
      "[EPOCH #19, step #1164] loss: 1.3723023516937387\n",
      "[EPOCH #19, step #1166] loss: 1.3719543304418844\n",
      "[EPOCH #19, step #1168] loss: 1.371514822602578\n",
      "[EPOCH #19, step #1170] loss: 1.3712477328734556\n",
      "[EPOCH #19, step #1172] loss: 1.3712016780053258\n",
      "[EPOCH #19, step #1174] loss: 1.3714596721973824\n",
      "[EPOCH #19, step #1176] loss: 1.3715118534400894\n",
      "[EPOCH #19, step #1178] loss: 1.3714381683873766\n",
      "[EPOCH #19, step #1180] loss: 1.3717611943332952\n",
      "[EPOCH #19, step #1182] loss: 1.3715191450747815\n",
      "[EPOCH #19, step #1184] loss: 1.3715957353889692\n",
      "[EPOCH #19, step #1186] loss: 1.371828699172196\n",
      "[EPOCH #19, step #1188] loss: 1.3723368361980801\n",
      "[EPOCH #19, step #1190] loss: 1.37253401491644\n",
      "[EPOCH #19, step #1192] loss: 1.3730071846017893\n",
      "[EPOCH #19, step #1194] loss: 1.3728396993301903\n",
      "[EPOCH #19, step #1196] loss: 1.372745326288362\n",
      "[EPOCH #19, step #1198] loss: 1.3732668768872411\n",
      "[EPOCH #19, step #1200] loss: 1.3731208753824036\n",
      "[EPOCH #19, step #1202] loss: 1.373078470119118\n",
      "[EPOCH #19, step #1204] loss: 1.3733209583274557\n",
      "[EPOCH #19, step #1206] loss: 1.3732485682290747\n",
      "[EPOCH #19, step #1208] loss: 1.3733937238443972\n",
      "[EPOCH #19, step #1210] loss: 1.373167641688535\n",
      "[EPOCH #19, step #1212] loss: 1.3737707427976944\n",
      "[EPOCH #19, step #1214] loss: 1.3742517323160368\n",
      "[EPOCH #19, step #1216] loss: 1.373848480578809\n",
      "[EPOCH #19, step #1218] loss: 1.3741359932682766\n",
      "[EPOCH #19, step #1220] loss: 1.3734612543987115\n",
      "[EPOCH #19, step #1222] loss: 1.373556169738364\n",
      "[EPOCH #19, step #1224] loss: 1.3740842211003206\n",
      "[EPOCH #19, step #1226] loss: 1.374580703621097\n",
      "[EPOCH #19, step #1228] loss: 1.3742260618652145\n",
      "[EPOCH #19, step #1230] loss: 1.3737498600244715\n",
      "[EPOCH #19, step #1232] loss: 1.373993320863419\n",
      "[EPOCH #19, step #1234] loss: 1.3741089626845078\n",
      "[EPOCH #19, step #1236] loss: 1.3736126463357343\n",
      "[EPOCH #19, step #1238] loss: 1.37402869415822\n",
      "[EPOCH #19, step #1240] loss: 1.3740889364245628\n",
      "[EPOCH #19, step #1242] loss: 1.3742806580597993\n",
      "[EPOCH #19, step #1244] loss: 1.3741323134985315\n",
      "[EPOCH #19, step #1246] loss: 1.3739754696702995\n",
      "[EPOCH #19, step #1248] loss: 1.3745972026911997\n",
      "[EPOCH #19, step #1250] loss: 1.3747937182823626\n",
      "[EPOCH #19, step #1252] loss: 1.3744005331114018\n",
      "[EPOCH #19, step #1254] loss: 1.3742819403272226\n",
      "[EPOCH #19, step #1256] loss: 1.3741156605376834\n",
      "[EPOCH #19, step #1258] loss: 1.3742816379091112\n",
      "[EPOCH #19, step #1260] loss: 1.3737508751493328\n",
      "[EPOCH #19, step #1262] loss: 1.3734153952753365\n",
      "[EPOCH #19, step #1264] loss: 1.373430572950793\n",
      "[EPOCH #19, step #1266] loss: 1.3736564555126753\n",
      "[EPOCH #19, step #1268] loss: 1.3738155018353293\n",
      "[EPOCH #19, step #1270] loss: 1.3737689188200128\n",
      "[EPOCH #19, step #1272] loss: 1.3737520063756867\n",
      "[EPOCH #19, step #1274] loss: 1.3742476964464374\n",
      "[EPOCH #19, step #1276] loss: 1.3741335358205211\n",
      "[EPOCH #19, step #1278] loss: 1.3740838993518403\n",
      "[EPOCH #19, step #1280] loss: 1.3739907932318718\n",
      "[EPOCH #19, step #1282] loss: 1.3737578632677336\n",
      "[EPOCH #19, step #1284] loss: 1.3735197950429954\n",
      "[EPOCH #19, step #1286] loss: 1.3733649745687737\n",
      "[EPOCH #19, step #1288] loss: 1.373566493496033\n",
      "[EPOCH #19, step #1290] loss: 1.3732768314739792\n",
      "[EPOCH #19, step #1292] loss: 1.3734135778947847\n",
      "[EPOCH #19, step #1294] loss: 1.3732930110688375\n",
      "[EPOCH #19, step #1296] loss: 1.3735497731287478\n",
      "[EPOCH #19, step #1298] loss: 1.3738965064034818\n",
      "[EPOCH #19, step #1300] loss: 1.3738595393875028\n",
      "[EPOCH #19, step #1302] loss: 1.3734834545498524\n",
      "[EPOCH #19, step #1304] loss: 1.3732058177049133\n",
      "[EPOCH #19, step #1306] loss: 1.3732500779510184\n",
      "[EPOCH #19, step #1308] loss: 1.3726542078419621\n",
      "[EPOCH #19, step #1310] loss: 1.372461597988571\n",
      "[EPOCH #19, step #1312] loss: 1.3726150971374163\n",
      "[EPOCH #19, step #1314] loss: 1.3721007848420523\n",
      "[EPOCH #19, step #1316] loss: 1.3718544671095585\n",
      "[EPOCH #19, step #1318] loss: 1.3719992130610688\n",
      "[EPOCH #19, step #1320] loss: 1.372139419054642\n",
      "[EPOCH #19, step #1322] loss: 1.3719519324493696\n",
      "[EPOCH #19, step #1324] loss: 1.3721233839358924\n",
      "[EPOCH #19, step #1326] loss: 1.3717969200983027\n",
      "[EPOCH #19, step #1328] loss: 1.3718433474758858\n",
      "[EPOCH #19, step #1330] loss: 1.372161006273675\n",
      "[EPOCH #19, step #1332] loss: 1.3722584459089464\n",
      "[EPOCH #19, step #1334] loss: 1.3721862454985858\n",
      "[EPOCH #19, step #1336] loss: 1.3724735690393641\n",
      "[EPOCH #19, step #1338] loss: 1.372711817171255\n",
      "[EPOCH #19, step #1340] loss: 1.372378272453766\n",
      "[EPOCH #19, step #1342] loss: 1.372990098047505\n",
      "[EPOCH #19, step #1344] loss: 1.3729277348872897\n",
      "[EPOCH #19, step #1346] loss: 1.3735435359904566\n",
      "[EPOCH #19, step #1348] loss: 1.37342894824016\n",
      "[EPOCH #19, step #1350] loss: 1.3736399732899613\n",
      "[EPOCH #19, step #1352] loss: 1.3733795135442364\n",
      "[EPOCH #19, step #1354] loss: 1.3733903603800108\n",
      "[EPOCH #19, step #1356] loss: 1.3731838255220243\n",
      "[EPOCH #19, step #1358] loss: 1.373181428209309\n",
      "[EPOCH #19, step #1360] loss: 1.372682988337083\n",
      "[EPOCH #19, step #1362] loss: 1.3735869693476228\n",
      "[EPOCH #19, step #1364] loss: 1.3735189103381538\n",
      "[EPOCH #19, step #1366] loss: 1.3736085413840013\n",
      "[EPOCH #19, step #1368] loss: 1.3733621382034111\n",
      "[EPOCH #19, step #1370] loss: 1.3734063219624135\n",
      "[EPOCH #19, step #1372] loss: 1.3736422271165896\n",
      "[EPOCH #19, step #1374] loss: 1.3734849892529575\n",
      "[EPOCH #19, step #1376] loss: 1.3732815714703146\n",
      "[EPOCH #19, step #1378] loss: 1.3735018204830105\n",
      "[EPOCH #19, step #1380] loss: 1.3736804460028995\n",
      "[EPOCH #19, step #1382] loss: 1.3737633462324577\n",
      "[EPOCH #19, step #1384] loss: 1.3737957506403595\n",
      "[EPOCH #19, step #1386] loss: 1.3737930585861893\n",
      "[EPOCH #19, step #1388] loss: 1.373956487580458\n",
      "[EPOCH #19, step #1390] loss: 1.3735979832735616\n",
      "[EPOCH #19, step #1392] loss: 1.3735401304779682\n",
      "[EPOCH #19, step #1394] loss: 1.3732528605768757\n",
      "[EPOCH #19, step #1396] loss: 1.373219289349588\n",
      "[EPOCH #19, step #1398] loss: 1.3731966419165436\n",
      "[EPOCH #19, step #1400] loss: 1.3734483452544393\n",
      "[EPOCH #19, step #1402] loss: 1.3732936481705582\n",
      "[EPOCH #19, step #1404] loss: 1.373059611048987\n",
      "[EPOCH #19, step #1406] loss: 1.3730527248125002\n",
      "[EPOCH #19, step #1408] loss: 1.3733637214468422\n",
      "[EPOCH #19, step #1410] loss: 1.3729700902351498\n",
      "[EPOCH #19, step #1412] loss: 1.372779844968098\n",
      "[EPOCH #19, step #1414] loss: 1.3727538997208693\n",
      "[EPOCH #19, step #1416] loss: 1.3729381842687254\n",
      "[EPOCH #19, step #1418] loss: 1.3725587546699396\n",
      "[EPOCH #19, step #1420] loss: 1.3726310255576153\n",
      "[EPOCH #19, step #1422] loss: 1.3727867993266334\n",
      "[EPOCH #19, step #1424] loss: 1.3729246978174177\n",
      "[EPOCH #19, step #1426] loss: 1.3725648797636025\n",
      "[EPOCH #19, step #1428] loss: 1.373155688388603\n",
      "[EPOCH #19, step #1430] loss: 1.372792483542367\n",
      "[EPOCH #19, step #1432] loss: 1.3730069781547647\n",
      "[EPOCH #19, step #1434] loss: 1.372845120961658\n",
      "[EPOCH #19, step #1436] loss: 1.3729376190639488\n",
      "[EPOCH #19, step #1438] loss: 1.3729832986728279\n",
      "[EPOCH #19, step #1440] loss: 1.3734252394941595\n",
      "[EPOCH #19, step #1442] loss: 1.3730151634289007\n",
      "[EPOCH #19, step #1444] loss: 1.3734709792483637\n",
      "[EPOCH #19, step #1446] loss: 1.3731499449005602\n",
      "[EPOCH #19, step #1448] loss: 1.3730298789144797\n",
      "[EPOCH #19, step #1450] loss: 1.3726907156813482\n",
      "[EPOCH #19, step #1452] loss: 1.3724463305962307\n",
      "[EPOCH #19, step #1454] loss: 1.3724871276580182\n",
      "[EPOCH #19, step #1456] loss: 1.3720925846734764\n",
      "[EPOCH #19, step #1458] loss: 1.3724735766097729\n",
      "[EPOCH #19, step #1460] loss: 1.3720258258125049\n",
      "[EPOCH #19, step #1462] loss: 1.3720853524263477\n",
      "[EPOCH #19, step #1464] loss: 1.3721050233157421\n",
      "[EPOCH #19, step #1466] loss: 1.3722009571052036\n",
      "[EPOCH #19, step #1468] loss: 1.3719363255594927\n",
      "[EPOCH #19, step #1470] loss: 1.3717243421004792\n",
      "[EPOCH #19, step #1472] loss: 1.3715757987811625\n",
      "[EPOCH #19, step #1474] loss: 1.371642059229188\n",
      "[EPOCH #19, step #1476] loss: 1.3717928873015646\n",
      "[EPOCH #19, step #1478] loss: 1.371500221114452\n",
      "[EPOCH #19, step #1480] loss: 1.3714622405636239\n",
      "[EPOCH #19, step #1482] loss: 1.3717849794787809\n",
      "[EPOCH #19, step #1484] loss: 1.3718480258678347\n",
      "[EPOCH #19, step #1486] loss: 1.3717997775994937\n",
      "[EPOCH #19, step #1488] loss: 1.3713647780440812\n",
      "[EPOCH #19, step #1490] loss: 1.3713318278212263\n",
      "[EPOCH #19, step #1492] loss: 1.371149425289412\n",
      "[EPOCH #19, step #1494] loss: 1.3711049803124622\n",
      "[EPOCH #19, step #1496] loss: 1.371171895949619\n",
      "[EPOCH #19, step #1498] loss: 1.3710601092021095\n",
      "[EPOCH #19, step #1500] loss: 1.3711892240925838\n",
      "[EPOCH #19, step #1502] loss: 1.3709639220418568\n",
      "[EPOCH #19, step #1504] loss: 1.3709151225232603\n",
      "[EPOCH #19, step #1506] loss: 1.3709808421910166\n",
      "[EPOCH #19, step #1508] loss: 1.3711557122869473\n",
      "[EPOCH #19, step #1510] loss: 1.3711072511029196\n",
      "[EPOCH #19, step #1512] loss: 1.3712559724909852\n",
      "[EPOCH #19, step #1514] loss: 1.3714265992539156\n",
      "[EPOCH #19, step #1516] loss: 1.3712654554616015\n",
      "[EPOCH #19, step #1518] loss: 1.3712574311822083\n",
      "[EPOCH #19, step #1520] loss: 1.3712547118533684\n",
      "[EPOCH #19, step #1522] loss: 1.3709356205602734\n",
      "[EPOCH #19, step #1524] loss: 1.3703464067568545\n",
      "[EPOCH #19, step #1526] loss: 1.3702751734948424\n",
      "[EPOCH #19, step #1528] loss: 1.3703814026497017\n",
      "[EPOCH #19, step #1530] loss: 1.3704261455482942\n",
      "[EPOCH #19, step #1532] loss: 1.3703662222767685\n",
      "[EPOCH #19, step #1534] loss: 1.3708176849331064\n",
      "[EPOCH #19, step #1536] loss: 1.3704292296044767\n",
      "[EPOCH #19, step #1538] loss: 1.3707007931532063\n",
      "[EPOCH #19, step #1540] loss: 1.3708582267522966\n",
      "[EPOCH #19, step #1542] loss: 1.3711324467801151\n",
      "[EPOCH #19, step #1544] loss: 1.3710812058263613\n",
      "[EPOCH #19, step #1546] loss: 1.371088154984815\n",
      "[EPOCH #19, step #1548] loss: 1.3710360683649874\n",
      "[EPOCH #19, step #1550] loss: 1.3708747749479258\n",
      "[EPOCH #19, step #1552] loss: 1.3705736452045552\n",
      "[EPOCH #19, step #1554] loss: 1.3708097902908203\n",
      "[EPOCH #19, step #1556] loss: 1.370413907039755\n",
      "[EPOCH #19, step #1558] loss: 1.3703448536535194\n",
      "[EPOCH #19, step #1560] loss: 1.3699984802106189\n",
      "[EPOCH #19, step #1562] loss: 1.3700441456496983\n",
      "[EPOCH #19, step #1564] loss: 1.369746669565146\n",
      "[EPOCH #19, step #1566] loss: 1.3696409492790889\n",
      "[EPOCH #19, step #1568] loss: 1.3696855498849396\n",
      "[EPOCH #19, step #1570] loss: 1.3699624646931678\n",
      "[EPOCH #19, step #1572] loss: 1.3696042353077746\n",
      "[EPOCH #19, step #1574] loss: 1.3696435497677515\n",
      "[EPOCH #19, step #1576] loss: 1.3696077786900986\n",
      "[EPOCH #19, step #1578] loss: 1.36961687675679\n",
      "[EPOCH #19, step #1580] loss: 1.3693650158653525\n",
      "[EPOCH #19, step #1582] loss: 1.3692052680634277\n",
      "[EPOCH #19, step #1584] loss: 1.3687276636764454\n",
      "[EPOCH #19, step #1586] loss: 1.3688824016415404\n",
      "[EPOCH #19, step #1588] loss: 1.3686254671566738\n",
      "[EPOCH #19, step #1590] loss: 1.3691240342662891\n",
      "[EPOCH #19, step #1592] loss: 1.369083021806608\n",
      "[EPOCH #19, step #1594] loss: 1.369012963921299\n",
      "[EPOCH #19, step #1596] loss: 1.3688525694119758\n",
      "[EPOCH #19, step #1598] loss: 1.3691856898763464\n",
      "[EPOCH #19, step #1600] loss: 1.3688519484620032\n",
      "[EPOCH #19, step #1602] loss: 1.368608220956211\n",
      "[EPOCH #19, step #1604] loss: 1.3685566800034306\n",
      "[EPOCH #19, step #1606] loss: 1.3687702252320346\n",
      "[EPOCH #19, step #1608] loss: 1.368591893637973\n",
      "[EPOCH #19, step #1610] loss: 1.3686108869251297\n",
      "[EPOCH #19, step #1612] loss: 1.3686224485655711\n",
      "[EPOCH #19, step #1614] loss: 1.3688913175196102\n",
      "[EPOCH #19, step #1616] loss: 1.3690023408602547\n",
      "[EPOCH #19, step #1618] loss: 1.3687887579441955\n",
      "[EPOCH #19, step #1620] loss: 1.3686309978228008\n",
      "[EPOCH #19, step #1622] loss: 1.3683983888511517\n",
      "[EPOCH #19, step #1624] loss: 1.3685084287570073\n",
      "[EPOCH #19, step #1626] loss: 1.3687642383736631\n",
      "[EPOCH #19, step #1628] loss: 1.3686978059944892\n",
      "[EPOCH #19, step #1630] loss: 1.3685696650179964\n",
      "[EPOCH #19, step #1632] loss: 1.3689202514442285\n",
      "[EPOCH #19, step #1634] loss: 1.3689919108279984\n",
      "[EPOCH #19, step #1636] loss: 1.3688586725646865\n",
      "[EPOCH #19, step #1638] loss: 1.3687855996250597\n",
      "[EPOCH #19, step #1640] loss: 1.368672335205973\n",
      "[EPOCH #19, step #1642] loss: 1.3686758374485821\n",
      "[EPOCH #19, step #1644] loss: 1.3688288999908238\n",
      "[EPOCH #19, step #1646] loss: 1.3686793243877802\n",
      "[EPOCH #19, step #1648] loss: 1.3683604593707837\n",
      "[EPOCH #19, step #1650] loss: 1.3686890590198109\n",
      "[EPOCH #19, step #1652] loss: 1.368441219266371\n",
      "[EPOCH #19, step #1654] loss: 1.3687452759987637\n",
      "[EPOCH #19, step #1656] loss: 1.3688364925338479\n",
      "[EPOCH #19, step #1658] loss: 1.3688617617772099\n",
      "[EPOCH #19, step #1660] loss: 1.3688376381912553\n",
      "[EPOCH #19, step #1662] loss: 1.3686279403252983\n",
      "[EPOCH #19, step #1664] loss: 1.3685143777916022\n",
      "[EPOCH #19, step #1666] loss: 1.3688990717243132\n",
      "[EPOCH #19, step #1668] loss: 1.3689608658910013\n",
      "[EPOCH #19, step #1670] loss: 1.3690422383130916\n",
      "[EPOCH #19, step #1672] loss: 1.3689097904973735\n",
      "[EPOCH #19, step #1674] loss: 1.3687272879614758\n",
      "[EPOCH #19, step #1676] loss: 1.3688839419512218\n",
      "[EPOCH #19, step #1678] loss: 1.3690025640286598\n",
      "[EPOCH #19, step #1680] loss: 1.3688636305500963\n",
      "[EPOCH #19, step #1682] loss: 1.3684919022833812\n",
      "[EPOCH #19, step #1684] loss: 1.368373584464325\n",
      "[EPOCH #19, step #1686] loss: 1.368261011380307\n",
      "[EPOCH #19, step #1688] loss: 1.3685747932018508\n",
      "[EPOCH #19, step #1690] loss: 1.3683494015743858\n",
      "[EPOCH #19, step #1692] loss: 1.3682117187547318\n",
      "[EPOCH #19, step #1694] loss: 1.3680472995679287\n",
      "[EPOCH #19, step #1696] loss: 1.368130578247322\n",
      "[EPOCH #19, step #1698] loss: 1.3677409910818912\n",
      "[EPOCH #19, step #1700] loss: 1.3677296157376617\n",
      "[EPOCH #19, step #1702] loss: 1.3681456265348724\n",
      "[EPOCH #19, step #1704] loss: 1.3677323218664466\n",
      "[EPOCH #19, step #1706] loss: 1.3683143948070056\n",
      "[EPOCH #19, step #1708] loss: 1.3683960025878312\n",
      "[EPOCH #19, step #1710] loss: 1.3682546915888159\n",
      "[EPOCH #19, step #1712] loss: 1.3683019234155676\n",
      "[EPOCH #19, step #1714] loss: 1.3687020763363853\n",
      "[EPOCH #19, step #1716] loss: 1.3687298769998077\n",
      "[EPOCH #19, step #1718] loss: 1.3689896769132497\n",
      "[EPOCH #19, step #1720] loss: 1.369043175527206\n",
      "[EPOCH #19, step #1722] loss: 1.3686797487064635\n",
      "[EPOCH #19, step #1724] loss: 1.3685846803844839\n",
      "[EPOCH #19, step #1726] loss: 1.368460166675201\n",
      "[EPOCH #19, step #1728] loss: 1.3685435565170212\n",
      "[EPOCH #19, step #1730] loss: 1.3684602478967796\n",
      "[EPOCH #19, step #1732] loss: 1.3687363764968692\n",
      "[EPOCH #19, step #1734] loss: 1.3688657760276575\n",
      "[EPOCH #19, step #1736] loss: 1.3686228599367158\n",
      "[EPOCH #19, step #1738] loss: 1.3686831489659508\n",
      "[EPOCH #19, step #1740] loss: 1.368869020156926\n",
      "[EPOCH #19, step #1742] loss: 1.3687237819856566\n",
      "[EPOCH #19, step #1744] loss: 1.3686438764747029\n",
      "[EPOCH #19, step #1746] loss: 1.368429100916054\n",
      "[EPOCH #19, step #1748] loss: 1.3685751431597648\n",
      "[EPOCH #19, step #1750] loss: 1.3683426127578109\n",
      "[EPOCH #19, step #1752] loss: 1.3684716721092438\n",
      "[EPOCH #19, step #1754] loss: 1.3686877444259122\n",
      "[EPOCH #19, step #1756] loss: 1.368681403066736\n",
      "[EPOCH #19, step #1758] loss: 1.3686384154423317\n",
      "[EPOCH #19, step #1760] loss: 1.3685210375268644\n",
      "[EPOCH #19, step #1762] loss: 1.3679226784630385\n",
      "[EPOCH #19, step #1764] loss: 1.3679410183733651\n",
      "[EPOCH #19, step #1766] loss: 1.3679035023301755\n",
      "[EPOCH #19, step #1768] loss: 1.367639821589229\n",
      "[EPOCH #19, step #1770] loss: 1.3675544902404644\n",
      "[EPOCH #19, step #1772] loss: 1.3676478549106876\n",
      "[EPOCH #19, step #1774] loss: 1.3677386879920959\n",
      "[EPOCH #19, step #1776] loss: 1.3672918802107326\n",
      "[EPOCH #19, step #1778] loss: 1.3675297946659215\n",
      "[EPOCH #19, step #1780] loss: 1.3676115125501376\n",
      "[EPOCH #19, step #1782] loss: 1.3676394973320034\n",
      "[EPOCH #19, step #1784] loss: 1.3675259842258207\n",
      "[EPOCH #19, step #1786] loss: 1.3675662007289153\n",
      "[EPOCH #19, step #1788] loss: 1.3674645683430906\n",
      "[EPOCH #19, step #1790] loss: 1.3672350323246818\n",
      "[EPOCH #19, step #1792] loss: 1.367114958354899\n",
      "[EPOCH #19, step #1794] loss: 1.3668853435675745\n",
      "[EPOCH #19, step #1796] loss: 1.3666780554856868\n",
      "[EPOCH #19, step #1798] loss: 1.3663303682113634\n",
      "[EPOCH #19, step #1800] loss: 1.3662230866872755\n",
      "[EPOCH #19, step #1802] loss: 1.366335452330225\n",
      "[EPOCH #19, step #1804] loss: 1.3666643287006177\n",
      "[EPOCH #19, step #1806] loss: 1.3668029362085319\n",
      "[EPOCH #19, step #1808] loss: 1.3667291606441263\n",
      "[EPOCH #19, step #1810] loss: 1.3664674425177783\n",
      "[EPOCH #19, step #1812] loss: 1.3666497374922284\n",
      "[EPOCH #19, step #1814] loss: 1.3667655145498019\n",
      "[EPOCH #19, step #1816] loss: 1.3666608430687124\n",
      "[EPOCH #19, step #1818] loss: 1.3669286243465983\n",
      "[EPOCH #19, step #1820] loss: 1.3668681261370563\n",
      "[EPOCH #19, step #1822] loss: 1.3668265973089555\n",
      "[EPOCH #19, step #1824] loss: 1.3668367046199432\n",
      "[EPOCH #19, step #1826] loss: 1.367021383257857\n",
      "[EPOCH #19, step #1828] loss: 1.3672250906191867\n",
      "[EPOCH #19, step #1830] loss: 1.367192174032827\n",
      "[EPOCH #19, step #1832] loss: 1.3672747232194684\n",
      "[EPOCH #19, step #1834] loss: 1.3672228168076974\n",
      "[EPOCH #19, step #1836] loss: 1.3669511242995265\n",
      "[EPOCH #19, step #1838] loss: 1.3669865162169046\n",
      "[EPOCH #19, step #1840] loss: 1.3668460911347255\n",
      "[EPOCH #19, step #1842] loss: 1.3667888170471025\n",
      "[EPOCH #19, step #1844] loss: 1.3665947446978188\n",
      "[EPOCH #19, step #1846] loss: 1.366410171398293\n",
      "[EPOCH #19, step #1848] loss: 1.3663270986035039\n",
      "[EPOCH #19, step #1850] loss: 1.3664111716885106\n",
      "[EPOCH #19, step #1852] loss: 1.3662673757646255\n",
      "[EPOCH #19, step #1854] loss: 1.366390940667484\n",
      "[EPOCH #19, step #1856] loss: 1.3666584051676058\n",
      "[EPOCH #19, step #1858] loss: 1.366401030306793\n",
      "[EPOCH #19, step #1860] loss: 1.3664223458547864\n",
      "[EPOCH #19, step #1862] loss: 1.3669176655179125\n",
      "[EPOCH #19, step #1864] loss: 1.367107252205345\n",
      "[EPOCH #19, step #1866] loss: 1.3673898731889607\n",
      "[EPOCH #19, step #1868] loss: 1.3672950074531103\n",
      "[EPOCH #19, step #1870] loss: 1.36743143986152\n",
      "[EPOCH #19, step #1872] loss: 1.36731044901162\n",
      "[EPOCH #19, step #1874] loss: 1.3674586484273275\n",
      "[EPOCH #19, step #1876] loss: 1.3671658126737567\n",
      "[EPOCH #19, step #1878] loss: 1.367325083824978\n",
      "[EPOCH #19, step #1880] loss: 1.3675439582740545\n",
      "[EPOCH #19, step #1882] loss: 1.3676629402633682\n",
      "[EPOCH #19, step #1884] loss: 1.3672471488818565\n",
      "[EPOCH #19, step #1886] loss: 1.3669846816927147\n",
      "[EPOCH #19, step #1888] loss: 1.3669061557586513\n",
      "[EPOCH #19, step #1890] loss: 1.3677099923933707\n",
      "[EPOCH #19, step #1892] loss: 1.367687657625034\n",
      "[EPOCH #19, step #1894] loss: 1.3679569832253267\n",
      "[EPOCH #19, step #1896] loss: 1.367898226255609\n",
      "[EPOCH #19, step #1898] loss: 1.368013951482115\n",
      "[EPOCH #19, step #1900] loss: 1.3679522375945101\n",
      "[EPOCH #19, step #1902] loss: 1.368306620053348\n",
      "[EPOCH #19, step #1904] loss: 1.368733334259724\n",
      "[EPOCH #19, step #1906] loss: 1.3689234124532719\n",
      "[EPOCH #19, step #1908] loss: 1.36882273119866\n",
      "[EPOCH #19, step #1910] loss: 1.368571795043616\n",
      "[EPOCH #19, step #1912] loss: 1.3684606001567792\n",
      "[EPOCH #19, step #1914] loss: 1.3685751852416495\n",
      "[EPOCH #19, step #1916] loss: 1.3685541653856985\n",
      "[EPOCH #19, step #1918] loss: 1.3689087030165763\n",
      "[EPOCH #19, step #1920] loss: 1.3690053676019913\n",
      "[EPOCH #19, step #1922] loss: 1.3689149563906406\n",
      "[EPOCH #19, step #1924] loss: 1.3688760917527334\n",
      "[EPOCH #19, step #1926] loss: 1.3692499660554796\n",
      "[EPOCH #19, step #1928] loss: 1.369308212960304\n",
      "[EPOCH #19, step #1930] loss: 1.3693727962036073\n",
      "[EPOCH #19, step #1932] loss: 1.3697199715090365\n",
      "[EPOCH #19, step #1934] loss: 1.3694152122012095\n",
      "[EPOCH #19, step #1936] loss: 1.369522281233404\n",
      "[EPOCH #19, step #1938] loss: 1.3693364410132338\n",
      "[EPOCH #19, step #1940] loss: 1.369301648283668\n",
      "[EPOCH #19, step #1942] loss: 1.3692146978056805\n",
      "[EPOCH #19, step #1944] loss: 1.3688548750313512\n",
      "[EPOCH #19, step #1946] loss: 1.368830603364191\n",
      "[EPOCH #19, step #1948] loss: 1.3688435382326791\n",
      "[EPOCH #19, step #1950] loss: 1.369231217125023\n",
      "[EPOCH #19, step #1952] loss: 1.3692003565755064\n",
      "[EPOCH #19, step #1954] loss: 1.369185069119534\n",
      "[EPOCH #19, step #1956] loss: 1.3691598190052752\n",
      "[EPOCH #19, step #1958] loss: 1.3691526602396495\n",
      "[EPOCH #19, step #1960] loss: 1.3691887520880555\n",
      "[EPOCH #19, step #1962] loss: 1.3691116585697498\n",
      "[EPOCH #19, step #1964] loss: 1.369225138713992\n",
      "[EPOCH #19, step #1966] loss: 1.3694307371693695\n",
      "[EPOCH #19, step #1968] loss: 1.3689728667737264\n",
      "[EPOCH #19, step #1970] loss: 1.3688402852087926\n",
      "[EPOCH #19, step #1972] loss: 1.3689202498616269\n",
      "[EPOCH #19, step #1974] loss: 1.3689933501014226\n",
      "[EPOCH #19, step #1976] loss: 1.3685188183714538\n",
      "[EPOCH #19, step #1978] loss: 1.368521749762467\n",
      "[EPOCH #19, step #1980] loss: 1.3687112427672492\n",
      "[EPOCH #19, step #1982] loss: 1.3686366556752407\n",
      "[EPOCH #19, step #1984] loss: 1.368420550174617\n",
      "[EPOCH #19, step #1986] loss: 1.3684095781714578\n",
      "[EPOCH #19, step #1988] loss: 1.3683509365465847\n",
      "[EPOCH #19, step #1990] loss: 1.368424747500331\n",
      "[EPOCH #19, step #1992] loss: 1.368804645759642\n",
      "[EPOCH #19, step #1994] loss: 1.3688519469777445\n",
      "[EPOCH #19, step #1996] loss: 1.3687859531575939\n",
      "[EPOCH #19, step #1998] loss: 1.368810608453784\n",
      "[EPOCH #19, step #2000] loss: 1.3687982050732694\n",
      "[EPOCH #19, step #2002] loss: 1.3686788047901464\n",
      "[EPOCH #19, step #2004] loss: 1.3684421958174193\n",
      "[EPOCH #19, step #2006] loss: 1.3682204241115892\n",
      "[EPOCH #19, step #2008] loss: 1.3681665071211626\n",
      "[EPOCH #19, step #2010] loss: 1.3677546723987972\n",
      "[EPOCH #19, step #2012] loss: 1.3677269725200256\n",
      "[EPOCH #19, step #2014] loss: 1.3677359829765396\n",
      "[EPOCH #19, step #2016] loss: 1.3675102716811411\n",
      "[EPOCH #19, step #2018] loss: 1.3676764553817797\n",
      "[EPOCH #19, step #2020] loss: 1.3676499663633264\n",
      "[EPOCH #19, step #2022] loss: 1.3678300356252089\n",
      "[EPOCH #19, step #2024] loss: 1.3677374618730427\n",
      "[EPOCH #19, step #2026] loss: 1.367791507622851\n",
      "[EPOCH #19, step #2028] loss: 1.3678366627053946\n",
      "[EPOCH #19, step #2030] loss: 1.3680904997152274\n",
      "[EPOCH #19, step #2032] loss: 1.3683088614151389\n",
      "[EPOCH #19, step #2034] loss: 1.3683713183356152\n",
      "[EPOCH #19, step #2036] loss: 1.3681806761608677\n",
      "[EPOCH #19, step #2038] loss: 1.3679135872664085\n",
      "[EPOCH #19, step #2040] loss: 1.3680302309732937\n",
      "[EPOCH #19, step #2042] loss: 1.368376746080812\n",
      "[EPOCH #19, step #2044] loss: 1.3684811263037777\n",
      "[EPOCH #19, step #2046] loss: 1.3684764490456014\n",
      "[EPOCH #19, step #2048] loss: 1.3684063210552526\n",
      "[EPOCH #19, step #2050] loss: 1.3684287927663368\n",
      "[EPOCH #19, step #2052] loss: 1.3684639652299115\n",
      "[EPOCH #19, step #2054] loss: 1.3687932003153502\n",
      "[EPOCH #19, step #2056] loss: 1.3684314004587907\n",
      "[EPOCH #19, step #2058] loss: 1.3687225752458114\n",
      "[EPOCH #19, step #2060] loss: 1.3688041072109265\n",
      "[EPOCH #19, step #2062] loss: 1.3686825125701672\n",
      "[EPOCH #19, step #2064] loss: 1.3685612957067697\n",
      "[EPOCH #19, step #2066] loss: 1.3685934437203648\n",
      "[EPOCH #19, step #2068] loss: 1.3684551111738021\n",
      "[EPOCH #19, step #2070] loss: 1.368286654691314\n",
      "[EPOCH #19, step #2072] loss: 1.3686101643347937\n",
      "[EPOCH #19, step #2074] loss: 1.3688812256721128\n",
      "[EPOCH #19, step #2076] loss: 1.3688849062373216\n",
      "[EPOCH #19, step #2078] loss: 1.368798722178389\n",
      "[EPOCH #19, step #2080] loss: 1.3687614092799347\n",
      "[EPOCH #19, step #2082] loss: 1.3687341897406375\n",
      "[EPOCH #19, step #2084] loss: 1.368631908504797\n",
      "[EPOCH #19, step #2086] loss: 1.3686485611826937\n",
      "[EPOCH #19, step #2088] loss: 1.3684316084052799\n",
      "[EPOCH #19, step #2090] loss: 1.3686496952912957\n",
      "[EPOCH #19, step #2092] loss: 1.3688628436330967\n",
      "[EPOCH #19, step #2094] loss: 1.3689854481624248\n",
      "[EPOCH #19, step #2096] loss: 1.368819920489148\n",
      "[EPOCH #19, step #2098] loss: 1.368862105500647\n",
      "[EPOCH #19, step #2100] loss: 1.3687845641859708\n",
      "[EPOCH #19, step #2102] loss: 1.3688138557285339\n",
      "[EPOCH #19, step #2104] loss: 1.3686428152184023\n",
      "[EPOCH #19, step #2106] loss: 1.3687504750606172\n",
      "[EPOCH #19, step #2108] loss: 1.3688091720207543\n",
      "[EPOCH #19, step #2110] loss: 1.3687590186712246\n",
      "[EPOCH #19, step #2112] loss: 1.3688418353500944\n",
      "[EPOCH #19, step #2114] loss: 1.3687950422859643\n",
      "[EPOCH #19, step #2116] loss: 1.3690433314120256\n",
      "[EPOCH #19, step #2118] loss: 1.3690464467921308\n",
      "[EPOCH #19, step #2120] loss: 1.369237105388902\n",
      "[EPOCH #19, step #2122] loss: 1.369538318083301\n",
      "[EPOCH #19, step #2124] loss: 1.3692524750933928\n",
      "[EPOCH #19, step #2126] loss: 1.3692707583609465\n",
      "[EPOCH #19, step #2128] loss: 1.3692848473829302\n",
      "[EPOCH #19, step #2130] loss: 1.3691659868183073\n",
      "[EPOCH #19, step #2132] loss: 1.3690486629971639\n",
      "[EPOCH #19, step #2134] loss: 1.3692554865843798\n",
      "[EPOCH #19, step #2136] loss: 1.368986086277522\n",
      "[EPOCH #19, step #2138] loss: 1.368896572737005\n",
      "[EPOCH #19, step #2140] loss: 1.3691750733388022\n",
      "[EPOCH #19, step #2142] loss: 1.369072082912705\n",
      "[EPOCH #19, step #2144] loss: 1.3693004489500762\n",
      "[EPOCH #19, step #2146] loss: 1.369434750935173\n",
      "[EPOCH #19, step #2148] loss: 1.369333004246983\n",
      "[EPOCH #19, step #2150] loss: 1.3697489148957516\n",
      "[EPOCH #19, step #2152] loss: 1.3699837552908682\n",
      "[EPOCH #19, step #2154] loss: 1.3701649917803895\n",
      "[EPOCH #19, step #2156] loss: 1.3699273575938407\n",
      "[EPOCH #19, step #2158] loss: 1.3697668161862644\n",
      "[EPOCH #19, step #2160] loss: 1.3699040947717298\n",
      "[EPOCH #19, step #2162] loss: 1.369868681406567\n",
      "[EPOCH #19, step #2164] loss: 1.3698368535856726\n",
      "[EPOCH #19, step #2166] loss: 1.369938198602524\n",
      "[EPOCH #19, step #2168] loss: 1.3700238670990619\n",
      "[EPOCH #19, step #2170] loss: 1.3699358888124882\n",
      "[EPOCH #19, step #2172] loss: 1.3697113582904692\n",
      "[EPOCH #19, step #2174] loss: 1.3696352716149955\n",
      "[EPOCH #19, step #2176] loss: 1.3695394280693867\n",
      "[EPOCH #19, step #2178] loss: 1.369333414924205\n",
      "[EPOCH #19, step #2180] loss: 1.3690024686482782\n",
      "[EPOCH #19, step #2182] loss: 1.3686831561840842\n",
      "[EPOCH #19, step #2184] loss: 1.368655598654627\n",
      "[EPOCH #19, step #2186] loss: 1.368716338071095\n",
      "[EPOCH #19, step #2188] loss: 1.3688634269419409\n",
      "[EPOCH #19, step #2190] loss: 1.3691696337454398\n",
      "[EPOCH #19, step #2192] loss: 1.369117605240444\n",
      "[EPOCH #19, step #2194] loss: 1.3691861841021475\n",
      "[EPOCH #19, step #2196] loss: 1.369008824561583\n",
      "[EPOCH #19, step #2198] loss: 1.3689044401720472\n",
      "[EPOCH #19, step #2200] loss: 1.368967189132382\n",
      "[EPOCH #19, step #2202] loss: 1.3686907802232005\n",
      "[EPOCH #19, step #2204] loss: 1.3687505411723304\n",
      "[EPOCH #19, step #2206] loss: 1.3687119458020949\n",
      "[EPOCH #19, step #2208] loss: 1.3686688925789297\n",
      "[EPOCH #19, step #2210] loss: 1.3690943939014022\n",
      "[EPOCH #19, step #2212] loss: 1.3690283319500847\n",
      "[EPOCH #19, step #2214] loss: 1.3688816499494807\n",
      "[EPOCH #19, step #2216] loss: 1.3688161839329018\n",
      "[EPOCH #19, step #2218] loss: 1.3691466523484639\n",
      "[EPOCH #19, step #2220] loss: 1.3692135010040434\n",
      "[EPOCH #19, step #2222] loss: 1.3691166584630083\n",
      "[EPOCH #19, step #2224] loss: 1.3689392472920794\n",
      "[EPOCH #19, step #2226] loss: 1.3688620805847416\n",
      "[EPOCH #19, step #2228] loss: 1.3687993993455383\n",
      "[EPOCH #19, step #2230] loss: 1.3688365278196997\n",
      "[EPOCH #19, step #2232] loss: 1.368779333941455\n",
      "[EPOCH #19, step #2234] loss: 1.3687021091747071\n",
      "[EPOCH #19, step #2236] loss: 1.3689151578414211\n",
      "[EPOCH #19, step #2238] loss: 1.3690167796723594\n",
      "[EPOCH #19, step #2240] loss: 1.3690467278960559\n",
      "[EPOCH #19, step #2242] loss: 1.3692925021258306\n",
      "[EPOCH #19, step #2244] loss: 1.3692008902341593\n",
      "[EPOCH #19, step #2246] loss: 1.3691029693213472\n",
      "[EPOCH #19, step #2248] loss: 1.3693062046094702\n",
      "[EPOCH #19, step #2250] loss: 1.3692220461363265\n",
      "[EPOCH #19, step #2252] loss: 1.3690885829227106\n",
      "[EPOCH #19, step #2254] loss: 1.369141287972816\n",
      "[EPOCH #19, step #2256] loss: 1.3693731231503534\n",
      "[EPOCH #19, step #2258] loss: 1.36928263819814\n",
      "[EPOCH #19, step #2260] loss: 1.3692352399526577\n",
      "[EPOCH #19, step #2262] loss: 1.369019281400604\n",
      "[EPOCH #19, step #2264] loss: 1.3692387177454715\n",
      "[EPOCH #19, step #2266] loss: 1.3693301210489681\n",
      "[EPOCH #19, step #2268] loss: 1.3690848916624547\n",
      "[EPOCH #19, step #2270] loss: 1.3691026746885517\n",
      "[EPOCH #19, step #2272] loss: 1.3695049010810483\n",
      "[EPOCH #19, step #2274] loss: 1.369265912758125\n",
      "[EPOCH #19, step #2276] loss: 1.3691384515900542\n",
      "[EPOCH #19, step #2278] loss: 1.368904118634149\n",
      "[EPOCH #19, step #2280] loss: 1.368910533511184\n",
      "[EPOCH #19, step #2282] loss: 1.3693280915549801\n",
      "[EPOCH #19, step #2284] loss: 1.3693706436282436\n",
      "[EPOCH #19, step #2286] loss: 1.3693741996787654\n",
      "[EPOCH #19, step #2288] loss: 1.369609543932427\n",
      "[EPOCH #19, step #2290] loss: 1.3693827609732805\n",
      "[EPOCH #19, step #2292] loss: 1.3695513104643824\n",
      "[EPOCH #19, step #2294] loss: 1.3693963668445097\n",
      "[EPOCH #19, step #2296] loss: 1.3692683538095194\n",
      "[EPOCH #19, step #2298] loss: 1.3690601879485331\n",
      "[EPOCH #19, step #2300] loss: 1.3690949878139322\n",
      "[EPOCH #19, step #2302] loss: 1.3691145533900442\n",
      "[EPOCH #19, step #2304] loss: 1.3690945665903567\n",
      "[EPOCH #19, step #2306] loss: 1.369297978911092\n",
      "[EPOCH #19, step #2308] loss: 1.369239325722661\n",
      "[EPOCH #19, step #2310] loss: 1.3693733956327896\n",
      "[EPOCH #19, step #2312] loss: 1.369426165135248\n",
      "[EPOCH #19, step #2314] loss: 1.3690629368466898\n",
      "[EPOCH #19, step #2316] loss: 1.368813055571061\n",
      "[EPOCH #19, step #2318] loss: 1.36878502340654\n",
      "[EPOCH #19, step #2320] loss: 1.3688674178785005\n",
      "[EPOCH #19, step #2322] loss: 1.3690088462634586\n",
      "[EPOCH #19, step #2324] loss: 1.368870725324077\n",
      "[EPOCH #19, step #2326] loss: 1.3688820073878145\n",
      "[EPOCH #19, step #2328] loss: 1.3688978105463558\n",
      "[EPOCH #19, step #2330] loss: 1.3688292280127183\n",
      "[EPOCH #19, step #2332] loss: 1.3686526432039396\n",
      "[EPOCH #19, step #2334] loss: 1.368603104059395\n",
      "[EPOCH #19, step #2336] loss: 1.3687395669223408\n",
      "[EPOCH #19, step #2338] loss: 1.3686650636971838\n",
      "[EPOCH #19, step #2340] loss: 1.3688961917495484\n",
      "[EPOCH #19, step #2342] loss: 1.3686561385281717\n",
      "[EPOCH #19, step #2344] loss: 1.368488434408265\n",
      "[EPOCH #19, step #2346] loss: 1.3684473034418234\n",
      "[EPOCH #19, step #2348] loss: 1.368242346895355\n",
      "[EPOCH #19, step #2350] loss: 1.3680636970756512\n",
      "[EPOCH #19, step #2352] loss: 1.3679740749872649\n",
      "[EPOCH #19, step #2354] loss: 1.367905051212149\n",
      "[EPOCH #19, step #2356] loss: 1.3678032183323465\n",
      "[EPOCH #19, step #2358] loss: 1.3679866098205433\n",
      "[EPOCH #19, step #2360] loss: 1.3677843291342435\n",
      "[EPOCH #19, step #2362] loss: 1.3676224695995507\n",
      "[EPOCH #19, step #2364] loss: 1.367560943463388\n",
      "[EPOCH #19, step #2366] loss: 1.367407961615944\n",
      "[EPOCH #19, step #2368] loss: 1.3672746058856953\n",
      "[EPOCH #19, step #2370] loss: 1.367161344974064\n",
      "[EPOCH #19, step #2372] loss: 1.3672137315445092\n",
      "[EPOCH #19, step #2374] loss: 1.3671239839604026\n",
      "[EPOCH #19, step #2376] loss: 1.3671627718458468\n",
      "[EPOCH #19, step #2378] loss: 1.3669942785532048\n",
      "[EPOCH #19, step #2380] loss: 1.3671307510460489\n",
      "[EPOCH #19, step #2382] loss: 1.3669345778574524\n",
      "[EPOCH #19, step #2384] loss: 1.366985133009137\n",
      "[EPOCH #19, step #2386] loss: 1.3668630941172848\n",
      "[EPOCH #19, step #2388] loss: 1.3667798660548973\n",
      "[EPOCH #19, step #2390] loss: 1.3667774428288242\n",
      "[EPOCH #19, step #2392] loss: 1.3668884934613856\n",
      "[EPOCH #19, step #2394] loss: 1.3668283843297302\n",
      "[EPOCH #19, step #2396] loss: 1.366485787223765\n",
      "[EPOCH #19, step #2398] loss: 1.3668048571625964\n",
      "[EPOCH #19, step #2400] loss: 1.3669422519350984\n",
      "[EPOCH #19, step #2402] loss: 1.3666729953107464\n",
      "[EPOCH #19, step #2404] loss: 1.3665075377714113\n",
      "[EPOCH #19, step #2406] loss: 1.366429352369059\n",
      "[EPOCH #19, step #2408] loss: 1.366705165136004\n",
      "[EPOCH #19, step #2410] loss: 1.3666254089908054\n",
      "[EPOCH #19, step #2412] loss: 1.3665266861275327\n",
      "[EPOCH #19, step #2414] loss: 1.3664241107847874\n",
      "[EPOCH #19, step #2416] loss: 1.3662068770599602\n",
      "[EPOCH #19, step #2418] loss: 1.3662902272255177\n",
      "[EPOCH #19, step #2420] loss: 1.366342488988674\n",
      "[EPOCH #19, step #2422] loss: 1.3664717337487897\n",
      "[EPOCH #19, step #2424] loss: 1.3664189247986704\n",
      "[EPOCH #19, step #2426] loss: 1.3663091511946428\n",
      "[EPOCH #19, step #2428] loss: 1.366283684245055\n",
      "[EPOCH #19, step #2430] loss: 1.3663371052824387\n",
      "[EPOCH #19, step #2432] loss: 1.3661277386027992\n",
      "[EPOCH #19, step #2434] loss: 1.3660741583522584\n",
      "[EPOCH #19, step #2436] loss: 1.36617502955369\n",
      "[EPOCH #19, step #2438] loss: 1.36587463736583\n",
      "[EPOCH #19, step #2440] loss: 1.3657227379286303\n",
      "[EPOCH #19, step #2442] loss: 1.3657626545775683\n",
      "[EPOCH #19, step #2444] loss: 1.3654672742377518\n",
      "[EPOCH #19, step #2446] loss: 1.3651248180578814\n",
      "[EPOCH #19, step #2448] loss: 1.3649625047073894\n",
      "[EPOCH #19, step #2450] loss: 1.3649871788526837\n",
      "[EPOCH #19, step #2452] loss: 1.3650572436515818\n",
      "[EPOCH #19, step #2454] loss: 1.3649288038129477\n",
      "[EPOCH #19, step #2456] loss: 1.3647572913691917\n",
      "[EPOCH #19, step #2458] loss: 1.3650492967847596\n",
      "[EPOCH #19, step #2460] loss: 1.3650605204336916\n",
      "[EPOCH #19, step #2462] loss: 1.3651352666327492\n",
      "[EPOCH #19, step #2464] loss: 1.3652357659523675\n",
      "[EPOCH #19, step #2466] loss: 1.365155375723806\n",
      "[EPOCH #19, step #2468] loss: 1.3651923844089098\n",
      "[EPOCH #19, step #2470] loss: 1.3650070966761492\n",
      "[EPOCH #19, step #2472] loss: 1.3652560176321047\n",
      "[EPOCH #19, step #2474] loss: 1.3652893335650667\n",
      "[EPOCH #19, step #2476] loss: 1.365147484133308\n",
      "[EPOCH #19, step #2478] loss: 1.3652597231555246\n",
      "[EPOCH #19, step #2480] loss: 1.3652377978585892\n",
      "[EPOCH #19, step #2482] loss: 1.3652317559483835\n",
      "[EPOCH #19, step #2484] loss: 1.3654601217995228\n",
      "[EPOCH #19, step #2486] loss: 1.3655351156396562\n",
      "[EPOCH #19, step #2488] loss: 1.3656155837496968\n",
      "[EPOCH #19, step #2490] loss: 1.3654906721729583\n",
      "[EPOCH #19, step #2492] loss: 1.3654701322185625\n",
      "[EPOCH #19, step #2494] loss: 1.3655854580875388\n",
      "[EPOCH #19, step #2496] loss: 1.3656113802026069\n",
      "[EPOCH #19, step #2498] loss: 1.3655282183378494\n",
      "[EPOCH #19, elapsed time: 9659.562[sec]] loss: 1.3656115090608596\n",
      "[EPOCH #20, step #0] loss: 1.1061583757400513\n",
      "[EPOCH #20, step #2] loss: 1.4116075038909912\n",
      "[EPOCH #20, step #4] loss: 1.287486696243286\n",
      "[EPOCH #20, step #6] loss: 1.243531448500497\n",
      "[EPOCH #20, step #8] loss: 1.2354803217781916\n",
      "[EPOCH #20, step #10] loss: 1.2127657261761753\n",
      "[EPOCH #20, step #12] loss: 1.196722420362326\n",
      "[EPOCH #20, step #14] loss: 1.19130251010259\n",
      "[EPOCH #20, step #16] loss: 1.2305334631134481\n",
      "[EPOCH #20, step #18] loss: 1.2551906391193992\n",
      "[EPOCH #20, step #20] loss: 1.2527361852782113\n",
      "[EPOCH #20, step #22] loss: 1.2839612675749736\n",
      "[EPOCH #20, step #24] loss: 1.2843664383888245\n",
      "[EPOCH #20, step #26] loss: 1.2868192968545136\n",
      "[EPOCH #20, step #28] loss: 1.3000908452889015\n",
      "[EPOCH #20, step #30] loss: 1.2854778901223214\n",
      "[EPOCH #20, step #32] loss: 1.2919875654307278\n",
      "[EPOCH #20, step #34] loss: 1.2910695740154812\n",
      "[EPOCH #20, step #36] loss: 1.2674590284759935\n",
      "[EPOCH #20, step #38] loss: 1.2791580511973455\n",
      "[EPOCH #20, step #40] loss: 1.2893783144834565\n",
      "[EPOCH #20, step #42] loss: 1.276166859061219\n",
      "[EPOCH #20, step #44] loss: 1.2829197261068557\n",
      "[EPOCH #20, step #46] loss: 1.2761523977239082\n",
      "[EPOCH #20, step #48] loss: 1.2836155623805767\n",
      "[EPOCH #20, step #50] loss: 1.2772390947622412\n",
      "[EPOCH #20, step #52] loss: 1.2849967198551826\n",
      "[EPOCH #20, step #54] loss: 1.289275324344635\n",
      "[EPOCH #20, step #56] loss: 1.2808396387518497\n",
      "[EPOCH #20, step #58] loss: 1.2796399522635897\n",
      "[EPOCH #20, step #60] loss: 1.2767855915866915\n",
      "[EPOCH #20, step #62] loss: 1.2873844826032246\n",
      "[EPOCH #20, step #64] loss: 1.2827265170904307\n",
      "[EPOCH #20, step #66] loss: 1.274981447120211\n",
      "[EPOCH #20, step #68] loss: 1.2788753008496934\n",
      "[EPOCH #20, step #70] loss: 1.2787800171005894\n",
      "[EPOCH #20, step #72] loss: 1.2795716156698254\n",
      "[EPOCH #20, step #74] loss: 1.275648868083954\n",
      "[EPOCH #20, step #76] loss: 1.2706984088018343\n",
      "[EPOCH #20, step #78] loss: 1.2710715222962294\n",
      "[EPOCH #20, step #80] loss: 1.2776248109193495\n",
      "[EPOCH #20, step #82] loss: 1.2759483715137803\n",
      "[EPOCH #20, step #84] loss: 1.2801384512115928\n",
      "[EPOCH #20, step #86] loss: 1.2776941040466572\n",
      "[EPOCH #20, step #88] loss: 1.2794807874754575\n",
      "[EPOCH #20, step #90] loss: 1.2754755458988987\n",
      "[EPOCH #20, step #92] loss: 1.274902113663253\n",
      "[EPOCH #20, step #94] loss: 1.2799741726172598\n",
      "[EPOCH #20, step #96] loss: 1.2793025915155705\n",
      "[EPOCH #20, step #98] loss: 1.2803454453294927\n",
      "[EPOCH #20, step #100] loss: 1.2794874877032667\n",
      "[EPOCH #20, step #102] loss: 1.279036108151223\n",
      "[EPOCH #20, step #104] loss: 1.2800402522087098\n",
      "[EPOCH #20, step #106] loss: 1.275049067546274\n",
      "[EPOCH #20, step #108] loss: 1.2783812694593306\n",
      "[EPOCH #20, step #110] loss: 1.2844140126898482\n",
      "[EPOCH #20, step #112] loss: 1.2856304060041377\n",
      "[EPOCH #20, step #114] loss: 1.2864272620366968\n",
      "[EPOCH #20, step #116] loss: 1.2845462698202867\n",
      "[EPOCH #20, step #118] loss: 1.288094373811193\n",
      "[EPOCH #20, step #120] loss: 1.289121668693448\n",
      "[EPOCH #20, step #122] loss: 1.2932847723728274\n",
      "[EPOCH #20, step #124] loss: 1.2954611411094665\n",
      "[EPOCH #20, step #126] loss: 1.2913421171856678\n",
      "[EPOCH #20, step #128] loss: 1.289283904456353\n",
      "[EPOCH #20, step #130] loss: 1.2866441061478535\n",
      "[EPOCH #20, step #132] loss: 1.2893870903137035\n",
      "[EPOCH #20, step #134] loss: 1.2863977048132154\n",
      "[EPOCH #20, step #136] loss: 1.2890264713851205\n",
      "[EPOCH #20, step #138] loss: 1.28470459644743\n",
      "[EPOCH #20, step #140] loss: 1.2848432761557558\n",
      "[EPOCH #20, step #142] loss: 1.2865289003698976\n",
      "[EPOCH #20, step #144] loss: 1.2843359610130047\n",
      "[EPOCH #20, step #146] loss: 1.2840676899669932\n",
      "[EPOCH #20, step #148] loss: 1.2859495410183133\n",
      "[EPOCH #20, step #150] loss: 1.2885548803979987\n",
      "[EPOCH #20, step #152] loss: 1.285789752318189\n",
      "[EPOCH #20, step #154] loss: 1.2864954056278353\n",
      "[EPOCH #20, step #156] loss: 1.287313414227431\n",
      "[EPOCH #20, step #158] loss: 1.2885331890118197\n",
      "[EPOCH #20, step #160] loss: 1.2896023211271868\n",
      "[EPOCH #20, step #162] loss: 1.2905539720336352\n",
      "[EPOCH #20, step #164] loss: 1.2894743355837734\n",
      "[EPOCH #20, step #166] loss: 1.2922980207169128\n",
      "[EPOCH #20, step #168] loss: 1.2911402932285556\n",
      "[EPOCH #20, step #170] loss: 1.2902226838452078\n",
      "[EPOCH #20, step #172] loss: 1.2910954132245456\n",
      "[EPOCH #20, step #174] loss: 1.292041175706046\n",
      "[EPOCH #20, step #176] loss: 1.2910627463443132\n",
      "[EPOCH #20, step #178] loss: 1.2889579980733008\n",
      "[EPOCH #20, step #180] loss: 1.2915905068592473\n",
      "[EPOCH #20, step #182] loss: 1.2907284960720709\n",
      "[EPOCH #20, step #184] loss: 1.2885538384721087\n",
      "[EPOCH #20, step #186] loss: 1.2873905693145997\n",
      "[EPOCH #20, step #188] loss: 1.2883303928627539\n",
      "[EPOCH #20, step #190] loss: 1.2885840631904402\n",
      "[EPOCH #20, step #192] loss: 1.2857981336549156\n",
      "[EPOCH #20, step #194] loss: 1.2849021749618725\n",
      "[EPOCH #20, step #196] loss: 1.2859156522048911\n",
      "[EPOCH #20, step #198] loss: 1.2874639025285615\n",
      "[EPOCH #20, step #200] loss: 1.291317588357783\n",
      "[EPOCH #20, step #202] loss: 1.2913035092682674\n",
      "[EPOCH #20, step #204] loss: 1.2941123255869238\n",
      "[EPOCH #20, step #206] loss: 1.2973811681143903\n",
      "[EPOCH #20, step #208] loss: 1.2962358143341028\n",
      "[EPOCH #20, step #210] loss: 1.29563603214743\n",
      "[EPOCH #20, step #212] loss: 1.293342628669291\n",
      "[EPOCH #20, step #214] loss: 1.2944786773171535\n",
      "[EPOCH #20, step #216] loss: 1.2934361221054183\n",
      "[EPOCH #20, step #218] loss: 1.2905492515868793\n",
      "[EPOCH #20, step #220] loss: 1.292037000483517\n",
      "[EPOCH #20, step #222] loss: 1.2927025823849734\n",
      "[EPOCH #20, step #224] loss: 1.2940427494049072\n",
      "[EPOCH #20, step #226] loss: 1.294701983224978\n",
      "[EPOCH #20, step #228] loss: 1.295573362616993\n",
      "[EPOCH #20, step #230] loss: 1.2944901655246686\n",
      "[EPOCH #20, step #232] loss: 1.2946010152669423\n",
      "[EPOCH #20, step #234] loss: 1.2951784580311876\n",
      "[EPOCH #20, step #236] loss: 1.295666424030996\n",
      "[EPOCH #20, step #238] loss: 1.2934798027182224\n",
      "[EPOCH #20, step #240] loss: 1.2940227104915127\n",
      "[EPOCH #20, step #242] loss: 1.2937587323012176\n",
      "[EPOCH #20, step #244] loss: 1.2970541233919104\n",
      "[EPOCH #20, step #246] loss: 1.295520042600902\n",
      "[EPOCH #20, step #248] loss: 1.297943548026334\n",
      "[EPOCH #20, step #250] loss: 1.3002343120802922\n",
      "[EPOCH #20, step #252] loss: 1.3016030519847341\n",
      "[EPOCH #20, step #254] loss: 1.3006747255138322\n",
      "[EPOCH #20, step #256] loss: 1.2990325394771443\n",
      "[EPOCH #20, step #258] loss: 1.2987995311100051\n",
      "[EPOCH #20, step #260] loss: 1.2976342451070004\n",
      "[EPOCH #20, step #262] loss: 1.2988479488702782\n",
      "[EPOCH #20, step #264] loss: 1.2982833167292036\n",
      "[EPOCH #20, step #266] loss: 1.2971195596434204\n",
      "[EPOCH #20, step #268] loss: 1.2956924188092738\n",
      "[EPOCH #20, step #270] loss: 1.2950957404291499\n",
      "[EPOCH #20, step #272] loss: 1.2941122954581683\n",
      "[EPOCH #20, step #274] loss: 1.2945594609867443\n",
      "[EPOCH #20, step #276] loss: 1.294622240514101\n",
      "[EPOCH #20, step #278] loss: 1.2947554532772323\n",
      "[EPOCH #20, step #280] loss: 1.293999465334882\n",
      "[EPOCH #20, step #282] loss: 1.2953329499113264\n",
      "[EPOCH #20, step #284] loss: 1.2954702561361748\n",
      "[EPOCH #20, step #286] loss: 1.2959132223594478\n",
      "[EPOCH #20, step #288] loss: 1.2957702206905326\n",
      "[EPOCH #20, step #290] loss: 1.2950449288915522\n",
      "[EPOCH #20, step #292] loss: 1.2970969583394178\n",
      "[EPOCH #20, step #294] loss: 1.296187516390267\n",
      "[EPOCH #20, step #296] loss: 1.2966326575487952\n",
      "[EPOCH #20, step #298] loss: 1.2977646720847955\n",
      "[EPOCH #20, step #300] loss: 1.2988628418342616\n",
      "[EPOCH #20, step #302] loss: 1.2970110789777423\n",
      "[EPOCH #20, step #304] loss: 1.2971504647223675\n",
      "[EPOCH #20, step #306] loss: 1.2972020040894177\n",
      "[EPOCH #20, step #308] loss: 1.298277848553889\n",
      "[EPOCH #20, step #310] loss: 1.2971253262838751\n",
      "[EPOCH #20, step #312] loss: 1.2980951575425486\n",
      "[EPOCH #20, step #314] loss: 1.2977710226225474\n",
      "[EPOCH #20, step #316] loss: 1.2990865660390642\n",
      "[EPOCH #20, step #318] loss: 1.301087939066573\n",
      "[EPOCH #20, step #320] loss: 1.3012493872939612\n",
      "[EPOCH #20, step #322] loss: 1.3010436349978018\n",
      "[EPOCH #20, step #324] loss: 1.3010127863517174\n",
      "[EPOCH #20, step #326] loss: 1.3030281599143958\n",
      "[EPOCH #20, step #328] loss: 1.3009009437358126\n",
      "[EPOCH #20, step #330] loss: 1.3023577669235875\n",
      "[EPOCH #20, step #332] loss: 1.3011130846298493\n",
      "[EPOCH #20, step #334] loss: 1.3020798910909623\n",
      "[EPOCH #20, step #336] loss: 1.303045331901188\n",
      "[EPOCH #20, step #338] loss: 1.3013377372494137\n",
      "[EPOCH #20, step #340] loss: 1.3002643718048275\n",
      "[EPOCH #20, step #342] loss: 1.3002534517393862\n",
      "[EPOCH #20, step #344] loss: 1.299296530260556\n",
      "[EPOCH #20, step #346] loss: 1.2988490596284783\n",
      "[EPOCH #20, step #348] loss: 1.2975085278636747\n",
      "[EPOCH #20, step #350] loss: 1.296212952191334\n",
      "[EPOCH #20, step #352] loss: 1.2952126923093714\n",
      "[EPOCH #20, step #354] loss: 1.2964262233653538\n",
      "[EPOCH #20, step #356] loss: 1.2974742440616382\n",
      "[EPOCH #20, step #358] loss: 1.2964523901182297\n",
      "[EPOCH #20, step #360] loss: 1.295642072474197\n",
      "[EPOCH #20, step #362] loss: 1.2950493977417958\n",
      "[EPOCH #20, step #364] loss: 1.2944632569404497\n",
      "[EPOCH #20, step #366] loss: 1.2928259427930744\n",
      "[EPOCH #20, step #368] loss: 1.2919368218923326\n",
      "[EPOCH #20, step #370] loss: 1.2931209916695752\n",
      "[EPOCH #20, step #372] loss: 1.2924782255060232\n",
      "[EPOCH #20, step #374] loss: 1.2910709908803304\n",
      "[EPOCH #20, step #376] loss: 1.2903556460094705\n",
      "[EPOCH #20, step #378] loss: 1.2910256961404805\n",
      "[EPOCH #20, step #380] loss: 1.29211930308755\n",
      "[EPOCH #20, step #382] loss: 1.2910341288962501\n",
      "[EPOCH #20, step #384] loss: 1.2919389062113575\n",
      "[EPOCH #20, step #386] loss: 1.2913112221454157\n",
      "[EPOCH #20, step #388] loss: 1.2915568615293136\n",
      "[EPOCH #20, step #390] loss: 1.2914817830180878\n",
      "[EPOCH #20, step #392] loss: 1.291342497630277\n",
      "[EPOCH #20, step #394] loss: 1.2928474313096154\n",
      "[EPOCH #20, step #396] loss: 1.2921714477935426\n",
      "[EPOCH #20, step #398] loss: 1.2917551305658537\n",
      "[EPOCH #20, step #400] loss: 1.291169909913641\n",
      "[EPOCH #20, step #402] loss: 1.2923393046885507\n",
      "[EPOCH #20, step #404] loss: 1.292799527409636\n",
      "[EPOCH #20, step #406] loss: 1.2923439265176178\n",
      "[EPOCH #20, step #408] loss: 1.2913126323217285\n",
      "[EPOCH #20, step #410] loss: 1.2915845327713773\n",
      "[EPOCH #20, step #412] loss: 1.2928220147659357\n",
      "[EPOCH #20, step #414] loss: 1.2947409137185797\n",
      "[EPOCH #20, step #416] loss: 1.2938381189065014\n",
      "[EPOCH #20, step #418] loss: 1.2932491130362262\n",
      "[EPOCH #20, step #420] loss: 1.293502536493922\n",
      "[EPOCH #20, step #422] loss: 1.2937023951088564\n",
      "[EPOCH #20, step #424] loss: 1.2930303437569561\n",
      "[EPOCH #20, step #426] loss: 1.2939955709410496\n",
      "[EPOCH #20, step #428] loss: 1.2942998266164518\n",
      "[EPOCH #20, step #430] loss: 1.2936151410753378\n",
      "[EPOCH #20, step #432] loss: 1.29326887122478\n",
      "[EPOCH #20, step #434] loss: 1.2930612299634123\n",
      "[EPOCH #20, step #436] loss: 1.2929702076540932\n",
      "[EPOCH #20, step #438] loss: 1.29372380928461\n",
      "[EPOCH #20, step #440] loss: 1.2939320506692744\n",
      "[EPOCH #20, step #442] loss: 1.2929628839880296\n",
      "[EPOCH #20, step #444] loss: 1.2935112422771669\n",
      "[EPOCH #20, step #446] loss: 1.2948226843370954\n",
      "[EPOCH #20, step #448] loss: 1.2944195448423017\n",
      "[EPOCH #20, step #450] loss: 1.2939692603510922\n",
      "[EPOCH #20, step #452] loss: 1.293084593798151\n",
      "[EPOCH #20, step #454] loss: 1.2928669271888313\n",
      "[EPOCH #20, step #456] loss: 1.2921360142903986\n",
      "[EPOCH #20, step #458] loss: 1.2907607702128507\n",
      "[EPOCH #20, step #460] loss: 1.2906170740820582\n",
      "[EPOCH #20, step #462] loss: 1.2898252625702267\n",
      "[EPOCH #20, step #464] loss: 1.2896184386745575\n",
      "[EPOCH #20, step #466] loss: 1.2907562798299932\n",
      "[EPOCH #20, step #468] loss: 1.2912403280292746\n",
      "[EPOCH #20, step #470] loss: 1.292201970160134\n",
      "[EPOCH #20, step #472] loss: 1.2923596866791143\n",
      "[EPOCH #20, step #474] loss: 1.292440355326\n",
      "[EPOCH #20, step #476] loss: 1.2940875393039775\n",
      "[EPOCH #20, step #478] loss: 1.2941089822504366\n",
      "[EPOCH #20, step #480] loss: 1.2940656983926737\n",
      "[EPOCH #20, step #482] loss: 1.293326641461864\n",
      "[EPOCH #20, step #484] loss: 1.2936661958694458\n",
      "[EPOCH #20, step #486] loss: 1.293081624307182\n",
      "[EPOCH #20, step #488] loss: 1.2922862068519514\n",
      "[EPOCH #20, step #490] loss: 1.2923236637397113\n",
      "[EPOCH #20, step #492] loss: 1.2928759932034397\n",
      "[EPOCH #20, step #494] loss: 1.292281069779637\n",
      "[EPOCH #20, step #496] loss: 1.290452061044858\n",
      "[EPOCH #20, step #498] loss: 1.2913660921888026\n",
      "[EPOCH #20, step #500] loss: 1.2911208006674182\n",
      "[EPOCH #20, step #502] loss: 1.2913899286603834\n",
      "[EPOCH #20, step #504] loss: 1.2924617906608205\n",
      "[EPOCH #20, step #506] loss: 1.2917608027392355\n",
      "[EPOCH #20, step #508] loss: 1.2915115548491711\n",
      "[EPOCH #20, step #510] loss: 1.292691071439396\n",
      "[EPOCH #20, step #512] loss: 1.293447538426048\n",
      "[EPOCH #20, step #514] loss: 1.2935811519622802\n",
      "[EPOCH #20, step #516] loss: 1.2939059012632537\n",
      "[EPOCH #20, step #518] loss: 1.2947984743210161\n",
      "[EPOCH #20, step #520] loss: 1.2947750258583024\n",
      "[EPOCH #20, step #522] loss: 1.29535293670275\n",
      "[EPOCH #20, step #524] loss: 1.2958821028754826\n",
      "[EPOCH #20, step #526] loss: 1.2971975070475628\n",
      "[EPOCH #20, step #528] loss: 1.296402864284912\n",
      "[EPOCH #20, step #530] loss: 1.2962234116767983\n",
      "[EPOCH #20, step #532] loss: 1.2975244110565471\n",
      "[EPOCH #20, step #534] loss: 1.2973839470159227\n",
      "[EPOCH #20, step #536] loss: 1.296434636444575\n",
      "[EPOCH #20, step #538] loss: 1.2957020898475717\n",
      "[EPOCH #20, step #540] loss: 1.2965651984135458\n",
      "[EPOCH #20, step #542] loss: 1.2973645244953163\n",
      "[EPOCH #20, step #544] loss: 1.2972048639157496\n",
      "[EPOCH #20, step #546] loss: 1.2974175561280747\n",
      "[EPOCH #20, step #548] loss: 1.2980999976993692\n",
      "[EPOCH #20, step #550] loss: 1.2982367456716548\n",
      "[EPOCH #20, step #552] loss: 1.2979530013060268\n",
      "[EPOCH #20, step #554] loss: 1.2978027172990747\n",
      "[EPOCH #20, step #556] loss: 1.297984924628876\n",
      "[EPOCH #20, step #558] loss: 1.2973976643865992\n",
      "[EPOCH #20, step #560] loss: 1.2976368785754457\n",
      "[EPOCH #20, step #562] loss: 1.2978448909087037\n",
      "[EPOCH #20, step #564] loss: 1.2971752088681787\n",
      "[EPOCH #20, step #566] loss: 1.296391051702819\n",
      "[EPOCH #20, step #568] loss: 1.2956618108313616\n",
      "[EPOCH #20, step #570] loss: 1.2950516454810228\n",
      "[EPOCH #20, step #572] loss: 1.2954403673791137\n",
      "[EPOCH #20, step #574] loss: 1.2953655806831692\n",
      "[EPOCH #20, step #576] loss: 1.2957426443876798\n",
      "[EPOCH #20, step #578] loss: 1.2964903801834027\n",
      "[EPOCH #20, step #580] loss: 1.2966849346374276\n",
      "[EPOCH #20, step #582] loss: 1.2971381762833374\n",
      "[EPOCH #20, step #584] loss: 1.297743238750686\n",
      "[EPOCH #20, step #586] loss: 1.2978719956220923\n",
      "[EPOCH #20, step #588] loss: 1.2977148745784532\n",
      "[EPOCH #20, step #590] loss: 1.29781833699512\n",
      "[EPOCH #20, step #592] loss: 1.2980726999536936\n",
      "[EPOCH #20, step #594] loss: 1.297565152865498\n",
      "[EPOCH #20, step #596] loss: 1.2973873088108234\n",
      "[EPOCH #20, step #598] loss: 1.2975833601067979\n",
      "[EPOCH #20, step #600] loss: 1.2977163551651103\n",
      "[EPOCH #20, step #602] loss: 1.2983441829286009\n",
      "[EPOCH #20, step #604] loss: 1.297701678197246\n",
      "[EPOCH #20, step #606] loss: 1.297547602574947\n",
      "[EPOCH #20, step #608] loss: 1.2977317377851514\n",
      "[EPOCH #20, step #610] loss: 1.2966854887391073\n",
      "[EPOCH #20, step #612] loss: 1.2976824145332635\n",
      "[EPOCH #20, step #614] loss: 1.2978329461764513\n",
      "[EPOCH #20, step #616] loss: 1.2983425290503416\n",
      "[EPOCH #20, step #618] loss: 1.299430661035855\n",
      "[EPOCH #20, step #620] loss: 1.2999460408269112\n",
      "[EPOCH #20, step #622] loss: 1.30000761490955\n",
      "[EPOCH #20, step #624] loss: 1.2996357562065124\n",
      "[EPOCH #20, step #626] loss: 1.2992878683636253\n",
      "[EPOCH #20, step #628] loss: 1.2990231666542198\n",
      "[EPOCH #20, step #630] loss: 1.2999521109457062\n",
      "[EPOCH #20, step #632] loss: 1.2997147751645455\n",
      "[EPOCH #20, step #634] loss: 1.300500176553651\n",
      "[EPOCH #20, step #636] loss: 1.3006472072009951\n",
      "[EPOCH #20, step #638] loss: 1.3014069464471605\n",
      "[EPOCH #20, step #640] loss: 1.3006534474130353\n",
      "[EPOCH #20, step #642] loss: 1.3002701107858685\n",
      "[EPOCH #20, step #644] loss: 1.3003315949624823\n",
      "[EPOCH #20, step #646] loss: 1.3001203524089855\n",
      "[EPOCH #20, step #648] loss: 1.3004890939304017\n",
      "[EPOCH #20, step #650] loss: 1.3003539995114375\n",
      "[EPOCH #20, step #652] loss: 1.2996826855548491\n",
      "[EPOCH #20, step #654] loss: 1.2997932061894248\n",
      "[EPOCH #20, step #656] loss: 1.3003650374789941\n",
      "[EPOCH #20, step #658] loss: 1.3004798307585246\n",
      "[EPOCH #20, step #660] loss: 1.299926624626327\n",
      "[EPOCH #20, step #662] loss: 1.300353775646532\n",
      "[EPOCH #20, step #664] loss: 1.3008097775000378\n",
      "[EPOCH #20, step #666] loss: 1.3019573925317138\n",
      "[EPOCH #20, step #668] loss: 1.3012097512660006\n",
      "[EPOCH #20, step #670] loss: 1.3012456710931974\n",
      "[EPOCH #20, step #672] loss: 1.3004487358797536\n",
      "[EPOCH #20, step #674] loss: 1.3009528950408653\n",
      "[EPOCH #20, step #676] loss: 1.3004576426489138\n",
      "[EPOCH #20, step #678] loss: 1.3000019457800223\n",
      "[EPOCH #20, step #680] loss: 1.2993876051797741\n",
      "[EPOCH #20, step #682] loss: 1.3000674647433168\n",
      "[EPOCH #20, step #684] loss: 1.3000307855814912\n",
      "[EPOCH #20, step #686] loss: 1.3008364749614154\n",
      "[EPOCH #20, step #688] loss: 1.3005988276056697\n",
      "[EPOCH #20, step #690] loss: 1.299848467844785\n",
      "[EPOCH #20, step #692] loss: 1.3004149265619585\n",
      "[EPOCH #20, step #694] loss: 1.3002422662090054\n",
      "[EPOCH #20, step #696] loss: 1.3003033249073768\n",
      "[EPOCH #20, step #698] loss: 1.3004393570753978\n",
      "[EPOCH #20, step #700] loss: 1.3000664989890454\n",
      "[EPOCH #20, step #702] loss: 1.2998961968238798\n",
      "[EPOCH #20, step #704] loss: 1.2994292373352863\n",
      "[EPOCH #20, step #706] loss: 1.298905576219653\n",
      "[EPOCH #20, step #708] loss: 1.2987110738357468\n",
      "[EPOCH #20, step #710] loss: 1.2979854485321314\n",
      "[EPOCH #20, step #712] loss: 1.2973403929828093\n",
      "[EPOCH #20, step #714] loss: 1.2964766759972473\n",
      "[EPOCH #20, step #716] loss: 1.297064970809878\n",
      "[EPOCH #20, step #718] loss: 1.2980980781089613\n",
      "[EPOCH #20, step #720] loss: 1.2977937684806475\n",
      "[EPOCH #20, step #722] loss: 1.2973608992901087\n",
      "[EPOCH #20, step #724] loss: 1.2975765437915407\n",
      "[EPOCH #20, step #726] loss: 1.2975563433180157\n",
      "[EPOCH #20, step #728] loss: 1.2987811973392556\n",
      "[EPOCH #20, step #730] loss: 1.2979507794458465\n",
      "[EPOCH #20, step #732] loss: 1.2978948264460284\n",
      "[EPOCH #20, step #734] loss: 1.2975695513543628\n",
      "[EPOCH #20, step #736] loss: 1.296294695810191\n",
      "[EPOCH #20, step #738] loss: 1.2965553758592825\n",
      "[EPOCH #20, step #740] loss: 1.2963986393572027\n",
      "[EPOCH #20, step #742] loss: 1.2966054569664105\n",
      "[EPOCH #20, step #744] loss: 1.2965932026005431\n",
      "[EPOCH #20, step #746] loss: 1.2971246327102743\n",
      "[EPOCH #20, step #748] loss: 1.2973579091923895\n",
      "[EPOCH #20, step #750] loss: 1.2979023039102873\n",
      "[EPOCH #20, step #752] loss: 1.2985199430232661\n",
      "[EPOCH #20, step #754] loss: 1.298412703994094\n",
      "[EPOCH #20, step #756] loss: 1.2978568834546693\n",
      "[EPOCH #20, step #758] loss: 1.2975438049502366\n",
      "[EPOCH #20, step #760] loss: 1.2967674438492853\n",
      "[EPOCH #20, step #762] loss: 1.2968611035246993\n",
      "[EPOCH #20, step #764] loss: 1.296799583918129\n",
      "[EPOCH #20, step #766] loss: 1.2965579142471024\n",
      "[EPOCH #20, step #768] loss: 1.2961484064361364\n",
      "[EPOCH #20, step #770] loss: 1.295287724830761\n",
      "[EPOCH #20, step #772] loss: 1.2958985382804278\n",
      "[EPOCH #20, step #774] loss: 1.2959081184479497\n",
      "[EPOCH #20, step #776] loss: 1.296228618465335\n",
      "[EPOCH #20, step #778] loss: 1.2963452162424316\n",
      "[EPOCH #20, step #780] loss: 1.2962105097905012\n",
      "[EPOCH #20, step #782] loss: 1.296112602165071\n",
      "[EPOCH #20, step #784] loss: 1.2963165818505986\n",
      "[EPOCH #20, step #786] loss: 1.2968843258169434\n",
      "[EPOCH #20, step #788] loss: 1.2969215672430128\n",
      "[EPOCH #20, step #790] loss: 1.2969920709823386\n",
      "[EPOCH #20, step #792] loss: 1.2975068608719345\n",
      "[EPOCH #20, step #794] loss: 1.297200641542111\n",
      "[EPOCH #20, step #796] loss: 1.2972191078600053\n",
      "[EPOCH #20, step #798] loss: 1.2971595813693928\n",
      "[EPOCH #20, step #800] loss: 1.2975033319249434\n",
      "[EPOCH #20, step #802] loss: 1.2978834605602962\n",
      "[EPOCH #20, step #804] loss: 1.297674386545738\n",
      "[EPOCH #20, step #806] loss: 1.2981388805228686\n",
      "[EPOCH #20, step #808] loss: 1.2973473682833838\n",
      "[EPOCH #20, step #810] loss: 1.2981424320640753\n",
      "[EPOCH #20, step #812] loss: 1.2985590236653262\n",
      "[EPOCH #20, step #814] loss: 1.2989017614557699\n",
      "[EPOCH #20, step #816] loss: 1.2986538581632197\n",
      "[EPOCH #20, step #818] loss: 1.2989940833259415\n",
      "[EPOCH #20, step #820] loss: 1.298724224230549\n",
      "[EPOCH #20, step #822] loss: 1.2995333749063105\n",
      "[EPOCH #20, step #824] loss: 1.300583446892825\n",
      "[EPOCH #20, step #826] loss: 1.3006700861843206\n",
      "[EPOCH #20, step #828] loss: 1.3004642673942235\n",
      "[EPOCH #20, step #830] loss: 1.3001671013132043\n",
      "[EPOCH #20, step #832] loss: 1.2996005045981252\n",
      "[EPOCH #20, step #834] loss: 1.2987294779566234\n",
      "[EPOCH #20, step #836] loss: 1.2990475452928987\n",
      "[EPOCH #20, step #838] loss: 1.298864783774684\n",
      "[EPOCH #20, step #840] loss: 1.2990362863903522\n",
      "[EPOCH #20, step #842] loss: 1.2991290830632545\n",
      "[EPOCH #20, step #844] loss: 1.2991131920786299\n",
      "[EPOCH #20, step #846] loss: 1.2990564694793052\n",
      "[EPOCH #20, step #848] loss: 1.2994027588476984\n",
      "[EPOCH #20, step #850] loss: 1.2990137684639416\n",
      "[EPOCH #20, step #852] loss: 1.2993786379712409\n",
      "[EPOCH #20, step #854] loss: 1.2993292808532715\n",
      "[EPOCH #20, step #856] loss: 1.2993962451763443\n",
      "[EPOCH #20, step #858] loss: 1.2985745020323498\n",
      "[EPOCH #20, step #860] loss: 1.2986882781733204\n",
      "[EPOCH #20, step #862] loss: 1.2987261351677108\n",
      "[EPOCH #20, step #864] loss: 1.298192533454454\n",
      "[EPOCH #20, step #866] loss: 1.2977915617283928\n",
      "[EPOCH #20, step #868] loss: 1.2980372839884873\n",
      "[EPOCH #20, step #870] loss: 1.2982336334738749\n",
      "[EPOCH #20, step #872] loss: 1.298253099123637\n",
      "[EPOCH #20, step #874] loss: 1.2982888788495746\n",
      "[EPOCH #20, step #876] loss: 1.2978755473546861\n",
      "[EPOCH #20, step #878] loss: 1.2977800001734623\n",
      "[EPOCH #20, step #880] loss: 1.2973867825292702\n",
      "[EPOCH #20, step #882] loss: 1.2970276035511885\n",
      "[EPOCH #20, step #884] loss: 1.2961456475958313\n",
      "[EPOCH #20, step #886] loss: 1.295970218426211\n",
      "[EPOCH #20, step #888] loss: 1.2967028326875583\n",
      "[EPOCH #20, step #890] loss: 1.2975100530384633\n",
      "[EPOCH #20, step #892] loss: 1.2973789505301772\n",
      "[EPOCH #20, step #894] loss: 1.2973701856655782\n",
      "[EPOCH #20, step #896] loss: 1.297748950678635\n",
      "[EPOCH #20, step #898] loss: 1.2975097152096808\n",
      "[EPOCH #20, step #900] loss: 1.2977717294544808\n",
      "[EPOCH #20, step #902] loss: 1.2968304482013284\n",
      "[EPOCH #20, step #904] loss: 1.2975932411067395\n",
      "[EPOCH #20, step #906] loss: 1.2971095047160046\n",
      "[EPOCH #20, step #908] loss: 1.296865432766011\n",
      "[EPOCH #20, step #910] loss: 1.2969261871734645\n",
      "[EPOCH #20, step #912] loss: 1.2976312752882466\n",
      "[EPOCH #20, step #914] loss: 1.2977474393088961\n",
      "[EPOCH #20, step #916] loss: 1.2972124329440076\n",
      "[EPOCH #20, step #918] loss: 1.2973785184412967\n",
      "[EPOCH #20, step #920] loss: 1.298031138221811\n",
      "[EPOCH #20, step #922] loss: 1.2989985884075435\n",
      "[EPOCH #20, step #924] loss: 1.2990199165730862\n",
      "[EPOCH #20, step #926] loss: 1.2987040800827092\n",
      "[EPOCH #20, step #928] loss: 1.2982183447181859\n",
      "[EPOCH #20, step #930] loss: 1.297762556183607\n",
      "[EPOCH #20, step #932] loss: 1.2973667309087444\n",
      "[EPOCH #20, step #934] loss: 1.2975184630582677\n",
      "[EPOCH #20, step #936] loss: 1.2970832665167598\n",
      "[EPOCH #20, step #938] loss: 1.2971007529412089\n",
      "[EPOCH #20, step #940] loss: 1.2967273860884776\n",
      "[EPOCH #20, step #942] loss: 1.297632760232984\n",
      "[EPOCH #20, step #944] loss: 1.2976533754792794\n",
      "[EPOCH #20, step #946] loss: 1.297279131639092\n",
      "[EPOCH #20, step #948] loss: 1.2971083810759043\n",
      "[EPOCH #20, step #950] loss: 1.2967704254370007\n",
      "[EPOCH #20, step #952] loss: 1.2964903848619052\n",
      "[EPOCH #20, step #954] loss: 1.2961861332673676\n",
      "[EPOCH #20, step #956] loss: 1.2959917089283903\n",
      "[EPOCH #20, step #958] loss: 1.295876151080922\n",
      "[EPOCH #20, step #960] loss: 1.2959497271417704\n",
      "[EPOCH #20, step #962] loss: 1.295957034622026\n",
      "[EPOCH #20, step #964] loss: 1.295358008424235\n",
      "[EPOCH #20, step #966] loss: 1.2959596960349808\n",
      "[EPOCH #20, step #968] loss: 1.2961586926620687\n",
      "[EPOCH #20, step #970] loss: 1.2960552106065681\n",
      "[EPOCH #20, step #972] loss: 1.2960753608705573\n",
      "[EPOCH #20, step #974] loss: 1.296432662132459\n",
      "[EPOCH #20, step #976] loss: 1.2965109035937057\n",
      "[EPOCH #20, step #978] loss: 1.296995593651566\n",
      "[EPOCH #20, step #980] loss: 1.2968404161820717\n",
      "[EPOCH #20, step #982] loss: 1.2969084256541814\n",
      "[EPOCH #20, step #984] loss: 1.2969892013496553\n",
      "[EPOCH #20, step #986] loss: 1.2972015993331825\n",
      "[EPOCH #20, step #988] loss: 1.2973890179811522\n",
      "[EPOCH #20, step #990] loss: 1.297323936831458\n",
      "[EPOCH #20, step #992] loss: 1.2970530755690337\n",
      "[EPOCH #20, step #994] loss: 1.29721995040999\n",
      "[EPOCH #20, step #996] loss: 1.2977260991467636\n",
      "[EPOCH #20, step #998] loss: 1.2978444233670965\n",
      "[EPOCH #20, step #1000] loss: 1.2979439379690172\n",
      "[EPOCH #20, step #1002] loss: 1.2977791085081585\n",
      "[EPOCH #20, step #1004] loss: 1.2976375983722175\n",
      "[EPOCH #20, step #1006] loss: 1.2973910471888734\n",
      "[EPOCH #20, step #1008] loss: 1.2969863597890667\n",
      "[EPOCH #20, step #1010] loss: 1.2968878955916527\n",
      "[EPOCH #20, step #1012] loss: 1.2974353887486434\n",
      "[EPOCH #20, step #1014] loss: 1.29685309614454\n",
      "[EPOCH #20, step #1016] loss: 1.2965233723908633\n",
      "[EPOCH #20, step #1018] loss: 1.2961849914214796\n",
      "[EPOCH #20, step #1020] loss: 1.2960345026444968\n",
      "[EPOCH #20, step #1022] loss: 1.2953550423461788\n",
      "[EPOCH #20, step #1024] loss: 1.2952966715068353\n",
      "[EPOCH #20, step #1026] loss: 1.295041892927833\n",
      "[EPOCH #20, step #1028] loss: 1.2957332300491073\n",
      "[EPOCH #20, step #1030] loss: 1.2955446693645185\n",
      "[EPOCH #20, step #1032] loss: 1.2948575480286635\n",
      "[EPOCH #20, step #1034] loss: 1.2950936641094188\n",
      "[EPOCH #20, step #1036] loss: 1.2948990788960986\n",
      "[EPOCH #20, step #1038] loss: 1.2949954234601444\n",
      "[EPOCH #20, step #1040] loss: 1.2950797070687374\n",
      "[EPOCH #20, step #1042] loss: 1.2941988401422106\n",
      "[EPOCH #20, step #1044] loss: 1.2942900459161786\n",
      "[EPOCH #20, step #1046] loss: 1.2948242140135087\n",
      "[EPOCH #20, step #1048] loss: 1.2954026237911447\n",
      "[EPOCH #20, step #1050] loss: 1.2950533508800757\n",
      "[EPOCH #20, step #1052] loss: 1.294790098017324\n",
      "[EPOCH #20, step #1054] loss: 1.2951700800403034\n",
      "[EPOCH #20, step #1056] loss: 1.2951174563355567\n",
      "[EPOCH #20, step #1058] loss: 1.2946652755971446\n",
      "[EPOCH #20, step #1060] loss: 1.294584183789558\n",
      "[EPOCH #20, step #1062] loss: 1.2950131078430311\n",
      "[EPOCH #20, step #1064] loss: 1.2945301888134557\n",
      "[EPOCH #20, step #1066] loss: 1.2945568899518436\n",
      "[EPOCH #20, step #1068] loss: 1.2944521895628092\n",
      "[EPOCH #20, step #1070] loss: 1.2940606197723155\n",
      "[EPOCH #20, step #1072] loss: 1.294357787696202\n",
      "[EPOCH #20, step #1074] loss: 1.294373431039411\n",
      "[EPOCH #20, step #1076] loss: 1.2940501932092807\n",
      "[EPOCH #20, step #1078] loss: 1.2945194871918375\n",
      "[EPOCH #20, step #1080] loss: 1.29439042355593\n",
      "[EPOCH #20, step #1082] loss: 1.2944024916831145\n",
      "[EPOCH #20, step #1084] loss: 1.2944277692500348\n",
      "[EPOCH #20, step #1086] loss: 1.293922325231224\n",
      "[EPOCH #20, step #1088] loss: 1.2942479625002192\n",
      "[EPOCH #20, step #1090] loss: 1.2940278677739319\n",
      "[EPOCH #20, step #1092] loss: 1.2937695825743436\n",
      "[EPOCH #20, step #1094] loss: 1.2938502961097786\n",
      "[EPOCH #20, step #1096] loss: 1.2942371509133845\n",
      "[EPOCH #20, step #1098] loss: 1.2941149590881007\n",
      "[EPOCH #20, step #1100] loss: 1.2942177427020753\n",
      "[EPOCH #20, step #1102] loss: 1.2941648210597276\n",
      "[EPOCH #20, step #1104] loss: 1.2937147059052239\n",
      "[EPOCH #20, step #1106] loss: 1.293737392384616\n",
      "[EPOCH #20, step #1108] loss: 1.294004824647396\n",
      "[EPOCH #20, step #1110] loss: 1.2936353449559663\n",
      "[EPOCH #20, step #1112] loss: 1.2935340463418952\n",
      "[EPOCH #20, step #1114] loss: 1.2935047729132956\n",
      "[EPOCH #20, step #1116] loss: 1.2939853604179252\n",
      "[EPOCH #20, step #1118] loss: 1.2945029884709962\n",
      "[EPOCH #20, step #1120] loss: 1.2946965548739062\n",
      "[EPOCH #20, step #1122] loss: 1.294399477495005\n",
      "[EPOCH #20, step #1124] loss: 1.2942728861702812\n",
      "[EPOCH #20, step #1126] loss: 1.294164161292874\n",
      "[EPOCH #20, step #1128] loss: 1.2938648754775366\n",
      "[EPOCH #20, step #1130] loss: 1.2937402911780684\n",
      "[EPOCH #20, step #1132] loss: 1.2939624865288664\n",
      "[EPOCH #20, step #1134] loss: 1.2941319842695664\n",
      "[EPOCH #20, step #1136] loss: 1.294652987805604\n",
      "[EPOCH #20, step #1138] loss: 1.2948710297784647\n",
      "[EPOCH #20, step #1140] loss: 1.295002464031985\n",
      "[EPOCH #20, step #1142] loss: 1.2949330302986886\n",
      "[EPOCH #20, step #1144] loss: 1.295410147608628\n",
      "[EPOCH #20, step #1146] loss: 1.295234704079998\n",
      "[EPOCH #20, step #1148] loss: 1.2955066233328678\n",
      "[EPOCH #20, step #1150] loss: 1.2961427142162307\n",
      "[EPOCH #20, step #1152] loss: 1.2958963131346293\n",
      "[EPOCH #20, step #1154] loss: 1.2959106619223888\n",
      "[EPOCH #20, step #1156] loss: 1.295668705692555\n",
      "[EPOCH #20, step #1158] loss: 1.2954630435695929\n",
      "[EPOCH #20, step #1160] loss: 1.296195993179088\n",
      "[EPOCH #20, step #1162] loss: 1.2960910669504724\n",
      "[EPOCH #20, step #1164] loss: 1.2961301209588931\n",
      "[EPOCH #20, step #1166] loss: 1.296100345705959\n",
      "[EPOCH #20, step #1168] loss: 1.2961396247632897\n",
      "[EPOCH #20, step #1170] loss: 1.2960082717577073\n",
      "[EPOCH #20, step #1172] loss: 1.2960263404801475\n",
      "[EPOCH #20, step #1174] loss: 1.2963683097413246\n",
      "[EPOCH #20, step #1176] loss: 1.2966034111069134\n",
      "[EPOCH #20, step #1178] loss: 1.2963075255114107\n",
      "[EPOCH #20, step #1180] loss: 1.296229697757611\n",
      "[EPOCH #20, step #1182] loss: 1.2959246830424311\n",
      "[EPOCH #20, step #1184] loss: 1.2959797362738017\n",
      "[EPOCH #20, step #1186] loss: 1.2962813676156812\n",
      "[EPOCH #20, step #1188] loss: 1.2962057173903796\n",
      "[EPOCH #20, step #1190] loss: 1.296106398205713\n",
      "[EPOCH #20, step #1192] loss: 1.2961037067535637\n",
      "[EPOCH #20, step #1194] loss: 1.296269088459813\n",
      "[EPOCH #20, step #1196] loss: 1.2962807184373126\n",
      "[EPOCH #20, step #1198] loss: 1.2962841395540372\n",
      "[EPOCH #20, step #1200] loss: 1.2962626138396505\n",
      "[EPOCH #20, step #1202] loss: 1.2966589498599173\n",
      "[EPOCH #20, step #1204] loss: 1.296543249846494\n",
      "[EPOCH #20, step #1206] loss: 1.2961412678104645\n",
      "[EPOCH #20, step #1208] loss: 1.2964520188182518\n",
      "[EPOCH #20, step #1210] loss: 1.2963508071237906\n",
      "[EPOCH #20, step #1212] loss: 1.2960834050119563\n",
      "[EPOCH #20, step #1214] loss: 1.296294222054658\n",
      "[EPOCH #20, step #1216] loss: 1.296349445129871\n",
      "[EPOCH #20, step #1218] loss: 1.296092699256659\n",
      "[EPOCH #20, step #1220] loss: 1.2960625693604753\n",
      "[EPOCH #20, step #1222] loss: 1.2958396900314244\n",
      "[EPOCH #20, step #1224] loss: 1.2950867852872732\n",
      "[EPOCH #20, step #1226] loss: 1.2957852320546723\n",
      "[EPOCH #20, step #1228] loss: 1.296268657274223\n",
      "[EPOCH #20, step #1230] loss: 1.2968543845884786\n",
      "[EPOCH #20, step #1232] loss: 1.296842896976997\n",
      "[EPOCH #20, step #1234] loss: 1.2968653778798185\n",
      "[EPOCH #20, step #1236] loss: 1.2969734437926315\n",
      "[EPOCH #20, step #1238] loss: 1.2969686712248851\n",
      "[EPOCH #20, step #1240] loss: 1.2968676986951775\n",
      "[EPOCH #20, step #1242] loss: 1.2963400837498524\n",
      "[EPOCH #20, step #1244] loss: 1.2964833513321168\n",
      "[EPOCH #20, step #1246] loss: 1.2966886615409026\n",
      "[EPOCH #20, step #1248] loss: 1.2968808194940047\n",
      "[EPOCH #20, step #1250] loss: 1.2972088879723247\n",
      "[EPOCH #20, step #1252] loss: 1.2976481829846467\n",
      "[EPOCH #20, step #1254] loss: 1.2976175236037053\n",
      "[EPOCH #20, step #1256] loss: 1.2977474028853642\n",
      "[EPOCH #20, step #1258] loss: 1.2977105589306857\n",
      "[EPOCH #20, step #1260] loss: 1.2974981542242414\n",
      "[EPOCH #20, step #1262] loss: 1.2971502647263986\n",
      "[EPOCH #20, step #1264] loss: 1.2968608891068711\n",
      "[EPOCH #20, step #1266] loss: 1.2968449213416349\n",
      "[EPOCH #20, step #1268] loss: 1.296604710831428\n",
      "[EPOCH #20, step #1270] loss: 1.2971164841618152\n",
      "[EPOCH #20, step #1272] loss: 1.2970531112269352\n",
      "[EPOCH #20, step #1274] loss: 1.2964231038093568\n",
      "[EPOCH #20, step #1276] loss: 1.2962916574631245\n",
      "[EPOCH #20, step #1278] loss: 1.2967175338024082\n",
      "[EPOCH #20, step #1280] loss: 1.296353876962967\n",
      "[EPOCH #20, step #1282] loss: 1.2968675105811467\n",
      "[EPOCH #20, step #1284] loss: 1.2964713681532716\n",
      "[EPOCH #20, step #1286] loss: 1.2959897981286512\n",
      "[EPOCH #20, step #1288] loss: 1.2957149981712537\n",
      "[EPOCH #20, step #1290] loss: 1.2967092094266257\n",
      "[EPOCH #20, step #1292] loss: 1.2964902796306448\n",
      "[EPOCH #20, step #1294] loss: 1.296659270676867\n",
      "[EPOCH #20, step #1296] loss: 1.2968688274955602\n",
      "[EPOCH #20, step #1298] loss: 1.296780148453672\n",
      "[EPOCH #20, step #1300] loss: 1.2967373467609573\n",
      "[EPOCH #20, step #1302] loss: 1.2965395500453178\n",
      "[EPOCH #20, step #1304] loss: 1.2962682061268451\n",
      "[EPOCH #20, step #1306] loss: 1.29595332781413\n",
      "[EPOCH #20, step #1308] loss: 1.2958313437069164\n",
      "[EPOCH #20, step #1310] loss: 1.295721989792781\n",
      "[EPOCH #20, step #1312] loss: 1.296200519060235\n",
      "[EPOCH #20, step #1314] loss: 1.2961565386206477\n",
      "[EPOCH #20, step #1316] loss: 1.2961462121074998\n",
      "[EPOCH #20, step #1318] loss: 1.296105189383075\n",
      "[EPOCH #20, step #1320] loss: 1.296134202927915\n",
      "[EPOCH #20, step #1322] loss: 1.2959693004845312\n",
      "[EPOCH #20, step #1324] loss: 1.2955814860451895\n",
      "[EPOCH #20, step #1326] loss: 1.2956376449003557\n",
      "[EPOCH #20, step #1328] loss: 1.2958695266460278\n",
      "[EPOCH #20, step #1330] loss: 1.2953480924546137\n",
      "[EPOCH #20, step #1332] loss: 1.2955567264413799\n",
      "[EPOCH #20, step #1334] loss: 1.295909553163507\n",
      "[EPOCH #20, step #1336] loss: 1.295883660095346\n",
      "[EPOCH #20, step #1338] loss: 1.2957045805819272\n",
      "[EPOCH #20, step #1340] loss: 1.295194264226312\n",
      "[EPOCH #20, step #1342] loss: 1.2950249211786402\n",
      "[EPOCH #20, step #1344] loss: 1.294959605316247\n",
      "[EPOCH #20, step #1346] loss: 1.2953314814818906\n",
      "[EPOCH #20, step #1348] loss: 1.2949190812697668\n",
      "[EPOCH #20, step #1350] loss: 1.2943789253933706\n",
      "[EPOCH #20, step #1352] loss: 1.2950195185977798\n",
      "[EPOCH #20, step #1354] loss: 1.2949823208840572\n",
      "[EPOCH #20, step #1356] loss: 1.294671760381981\n",
      "[EPOCH #20, step #1358] loss: 1.2945628316635767\n",
      "[EPOCH #20, step #1360] loss: 1.2944389338619475\n",
      "[EPOCH #20, step #1362] loss: 1.2942992549824173\n",
      "[EPOCH #20, step #1364] loss: 1.294470411473578\n",
      "[EPOCH #20, step #1366] loss: 1.294161217746372\n",
      "[EPOCH #20, step #1368] loss: 1.2939516969019693\n",
      "[EPOCH #20, step #1370] loss: 1.293477448079814\n",
      "[EPOCH #20, step #1372] loss: 1.2931715855612342\n",
      "[EPOCH #20, step #1374] loss: 1.293335218039426\n",
      "[EPOCH #20, step #1376] loss: 1.2930457414105567\n",
      "[EPOCH #20, step #1378] loss: 1.2931656536198424\n",
      "[EPOCH #20, step #1380] loss: 1.293532355681094\n",
      "[EPOCH #20, step #1382] loss: 1.2937108633833696\n",
      "[EPOCH #20, step #1384] loss: 1.2937071843698136\n",
      "[EPOCH #20, step #1386] loss: 1.2936931005810006\n",
      "[EPOCH #20, step #1388] loss: 1.2933726677197703\n",
      "[EPOCH #20, step #1390] loss: 1.2932550272951873\n",
      "[EPOCH #20, step #1392] loss: 1.2928525664698538\n",
      "[EPOCH #20, step #1394] loss: 1.292662078419894\n",
      "[EPOCH #20, step #1396] loss: 1.2928786782938493\n",
      "[EPOCH #20, step #1398] loss: 1.2930100837974057\n",
      "[EPOCH #20, step #1400] loss: 1.2925851893459024\n",
      "[EPOCH #20, step #1402] loss: 1.2923824010962515\n",
      "[EPOCH #20, step #1404] loss: 1.2921611248386289\n",
      "[EPOCH #20, step #1406] loss: 1.29217491754845\n",
      "[EPOCH #20, step #1408] loss: 1.2916495400679882\n",
      "[EPOCH #20, step #1410] loss: 1.2914374907501702\n",
      "[EPOCH #20, step #1412] loss: 1.2914481610587025\n",
      "[EPOCH #20, step #1414] loss: 1.291411679919954\n",
      "[EPOCH #20, step #1416] loss: 1.2910241146447714\n",
      "[EPOCH #20, step #1418] loss: 1.2907120227981739\n",
      "[EPOCH #20, step #1420] loss: 1.2906786289792258\n",
      "[EPOCH #20, step #1422] loss: 1.29037926243965\n",
      "[EPOCH #20, step #1424] loss: 1.290532094637553\n",
      "[EPOCH #20, step #1426] loss: 1.2907594911853333\n",
      "[EPOCH #20, step #1428] loss: 1.2907600449130952\n",
      "[EPOCH #20, step #1430] loss: 1.2904867148332708\n",
      "[EPOCH #20, step #1432] loss: 1.2905043507071532\n",
      "[EPOCH #20, step #1434] loss: 1.2908252506305946\n",
      "[EPOCH #20, step #1436] loss: 1.2912606105011375\n",
      "[EPOCH #20, step #1438] loss: 1.2912409998129606\n",
      "[EPOCH #20, step #1440] loss: 1.2910375672855947\n",
      "[EPOCH #20, step #1442] loss: 1.29123783062005\n",
      "[EPOCH #20, step #1444] loss: 1.29125533730926\n",
      "[EPOCH #20, step #1446] loss: 1.2911504273094963\n",
      "[EPOCH #20, step #1448] loss: 1.2908063070621056\n",
      "[EPOCH #20, step #1450] loss: 1.2907068554406984\n",
      "[EPOCH #20, step #1452] loss: 1.2903952806962413\n",
      "[EPOCH #20, step #1454] loss: 1.2903020770279403\n",
      "[EPOCH #20, step #1456] loss: 1.2907093810806065\n",
      "[EPOCH #20, step #1458] loss: 1.290500363680988\n",
      "[EPOCH #20, step #1460] loss: 1.290374117914248\n",
      "[EPOCH #20, step #1462] loss: 1.2905997980235784\n",
      "[EPOCH #20, step #1464] loss: 1.2904616491379592\n",
      "[EPOCH #20, step #1466] loss: 1.290202427820519\n",
      "[EPOCH #20, step #1468] loss: 1.2902071445957182\n",
      "[EPOCH #20, step #1470] loss: 1.2900713788336593\n",
      "[EPOCH #20, step #1472] loss: 1.289943426139324\n",
      "[EPOCH #20, step #1474] loss: 1.2897727504827208\n",
      "[EPOCH #20, step #1476] loss: 1.2894123065043883\n",
      "[EPOCH #20, step #1478] loss: 1.2890942470297126\n",
      "[EPOCH #20, step #1480] loss: 1.2891556024953854\n",
      "[EPOCH #20, step #1482] loss: 1.289514973809891\n",
      "[EPOCH #20, step #1484] loss: 1.289871454600132\n",
      "[EPOCH #20, step #1486] loss: 1.2900218471794538\n",
      "[EPOCH #20, step #1488] loss: 1.2895652986037163\n",
      "[EPOCH #20, step #1490] loss: 1.2896326298205185\n",
      "[EPOCH #20, step #1492] loss: 1.2896315933311855\n",
      "[EPOCH #20, step #1494] loss: 1.2892738291252417\n",
      "[EPOCH #20, step #1496] loss: 1.2887182305794043\n",
      "[EPOCH #20, step #1498] loss: 1.288529854841913\n",
      "[EPOCH #20, step #1500] loss: 1.288790718544967\n",
      "[EPOCH #20, step #1502] loss: 1.2890286010182546\n",
      "[EPOCH #20, step #1504] loss: 1.288648716318251\n",
      "[EPOCH #20, step #1506] loss: 1.2887462137863979\n",
      "[EPOCH #20, step #1508] loss: 1.288425946646451\n",
      "[EPOCH #20, step #1510] loss: 1.2884865515599733\n",
      "[EPOCH #20, step #1512] loss: 1.2888751643742462\n",
      "[EPOCH #20, step #1514] loss: 1.288755943594199\n",
      "[EPOCH #20, step #1516] loss: 1.2888014290626693\n",
      "[EPOCH #20, step #1518] loss: 1.288958358403646\n",
      "[EPOCH #20, step #1520] loss: 1.2891513530867889\n",
      "[EPOCH #20, step #1522] loss: 1.2892696256318221\n",
      "[EPOCH #20, step #1524] loss: 1.2888360320544634\n",
      "[EPOCH #20, step #1526] loss: 1.288864479239813\n",
      "[EPOCH #20, step #1528] loss: 1.2891651660184442\n",
      "[EPOCH #20, step #1530] loss: 1.289318195361082\n",
      "[EPOCH #20, step #1532] loss: 1.2894738770277767\n",
      "[EPOCH #20, step #1534] loss: 1.2893108226965615\n",
      "[EPOCH #20, step #1536] loss: 1.2892088587204977\n",
      "[EPOCH #20, step #1538] loss: 1.289248262890908\n",
      "[EPOCH #20, step #1540] loss: 1.2892490645107861\n",
      "[EPOCH #20, step #1542] loss: 1.2892600921014647\n",
      "[EPOCH #20, step #1544] loss: 1.2895746265414463\n",
      "[EPOCH #20, step #1546] loss: 1.2893083854190133\n",
      "[EPOCH #20, step #1548] loss: 1.289088163666759\n",
      "[EPOCH #20, step #1550] loss: 1.2889176027226033\n",
      "[EPOCH #20, step #1552] loss: 1.2889308934432802\n",
      "[EPOCH #20, step #1554] loss: 1.2892220551944622\n",
      "[EPOCH #20, step #1556] loss: 1.289264919632279\n",
      "[EPOCH #20, step #1558] loss: 1.2895635791204159\n",
      "[EPOCH #20, step #1560] loss: 1.2893828814568846\n",
      "[EPOCH #20, step #1562] loss: 1.2891953640158025\n",
      "[EPOCH #20, step #1564] loss: 1.2892077076168487\n",
      "[EPOCH #20, step #1566] loss: 1.2890403075209071\n",
      "[EPOCH #20, step #1568] loss: 1.288886345823226\n",
      "[EPOCH #20, step #1570] loss: 1.2889602460503047\n",
      "[EPOCH #20, step #1572] loss: 1.28901545454269\n",
      "[EPOCH #20, step #1574] loss: 1.2891548576052227\n",
      "[EPOCH #20, step #1576] loss: 1.2890179748390018\n",
      "[EPOCH #20, step #1578] loss: 1.2890575665171347\n",
      "[EPOCH #20, step #1580] loss: 1.2887853781759249\n",
      "[EPOCH #20, step #1582] loss: 1.2885075791380636\n",
      "[EPOCH #20, step #1584] loss: 1.288469209543162\n",
      "[EPOCH #20, step #1586] loss: 1.2884438953162292\n",
      "[EPOCH #20, step #1588] loss: 1.2886978437721992\n",
      "[EPOCH #20, step #1590] loss: 1.2885846937699261\n",
      "[EPOCH #20, step #1592] loss: 1.2884531370215049\n",
      "[EPOCH #20, step #1594] loss: 1.288492381871681\n",
      "[EPOCH #20, step #1596] loss: 1.2885055296407615\n",
      "[EPOCH #20, step #1598] loss: 1.288422056777243\n",
      "[EPOCH #20, step #1600] loss: 1.288213476399047\n",
      "[EPOCH #20, step #1602] loss: 1.2877808353414553\n",
      "[EPOCH #20, step #1604] loss: 1.2874669032676198\n",
      "[EPOCH #20, step #1606] loss: 1.2872389805710085\n",
      "[EPOCH #20, step #1608] loss: 1.287036294963806\n",
      "[EPOCH #20, step #1610] loss: 1.2868939161596646\n",
      "[EPOCH #20, step #1612] loss: 1.2868686720072964\n",
      "[EPOCH #20, step #1614] loss: 1.2869798190084405\n",
      "[EPOCH #20, step #1616] loss: 1.2869248305416874\n",
      "[EPOCH #20, step #1618] loss: 1.2870475801882588\n",
      "[EPOCH #20, step #1620] loss: 1.2872154300114316\n",
      "[EPOCH #20, step #1622] loss: 1.2872864622726017\n",
      "[EPOCH #20, step #1624] loss: 1.2875165322377131\n",
      "[EPOCH #20, step #1626] loss: 1.2875398986531534\n",
      "[EPOCH #20, step #1628] loss: 1.288121693773896\n",
      "[EPOCH #20, step #1630] loss: 1.2875563462477824\n",
      "[EPOCH #20, step #1632] loss: 1.2876683964148228\n",
      "[EPOCH #20, step #1634] loss: 1.2877808772824955\n",
      "[EPOCH #20, step #1636] loss: 1.2877867575746231\n",
      "[EPOCH #20, step #1638] loss: 1.287662642623245\n",
      "[EPOCH #20, step #1640] loss: 1.2873597633613456\n",
      "[EPOCH #20, step #1642] loss: 1.287855502206671\n",
      "[EPOCH #20, step #1644] loss: 1.2879470374808848\n",
      "[EPOCH #20, step #1646] loss: 1.2878055323885655\n",
      "[EPOCH #20, step #1648] loss: 1.2873428850697344\n",
      "[EPOCH #20, step #1650] loss: 1.2871989465568514\n",
      "[EPOCH #20, step #1652] loss: 1.2875147978248411\n",
      "[EPOCH #20, step #1654] loss: 1.2872649256916564\n",
      "[EPOCH #20, step #1656] loss: 1.287054217573959\n",
      "[EPOCH #20, step #1658] loss: 1.2870650808088315\n",
      "[EPOCH #20, step #1660] loss: 1.2870731444907146\n",
      "[EPOCH #20, step #1662] loss: 1.2874452844127717\n",
      "[EPOCH #20, step #1664] loss: 1.2873849696225232\n",
      "[EPOCH #20, step #1666] loss: 1.2876473433540907\n",
      "[EPOCH #20, step #1668] loss: 1.2875368890825183\n",
      "[EPOCH #20, step #1670] loss: 1.2874641431298248\n",
      "[EPOCH #20, step #1672] loss: 1.2877560347336463\n",
      "[EPOCH #20, step #1674] loss: 1.2879124701201026\n",
      "[EPOCH #20, step #1676] loss: 1.2876070615572808\n",
      "[EPOCH #20, step #1678] loss: 1.2875732270786633\n",
      "[EPOCH #20, step #1680] loss: 1.2871743379995129\n",
      "[EPOCH #20, step #1682] loss: 1.2872622062319883\n",
      "[EPOCH #20, step #1684] loss: 1.2873043402366184\n",
      "[EPOCH #20, step #1686] loss: 1.2873721953390898\n",
      "[EPOCH #20, step #1688] loss: 1.2876772130643779\n",
      "[EPOCH #20, step #1690] loss: 1.2873783574733135\n",
      "[EPOCH #20, step #1692] loss: 1.2873291034214045\n",
      "[EPOCH #20, step #1694] loss: 1.2870121640793342\n",
      "[EPOCH #20, step #1696] loss: 1.2869485473379922\n",
      "[EPOCH #20, step #1698] loss: 1.2870552282322147\n",
      "[EPOCH #20, step #1700] loss: 1.2870760742599021\n",
      "[EPOCH #20, step #1702] loss: 1.2871572895744445\n",
      "[EPOCH #20, step #1704] loss: 1.2874306552920523\n",
      "[EPOCH #20, step #1706] loss: 1.287528485705717\n",
      "[EPOCH #20, step #1708] loss: 1.2873409577389778\n",
      "[EPOCH #20, step #1710] loss: 1.2873652440842518\n",
      "[EPOCH #20, step #1712] loss: 1.2872699106289363\n",
      "[EPOCH #20, step #1714] loss: 1.2868987988800071\n",
      "[EPOCH #20, step #1716] loss: 1.287202638009293\n",
      "[EPOCH #20, step #1718] loss: 1.2870941179793127\n",
      "[EPOCH #20, step #1720] loss: 1.2867907268373444\n",
      "[EPOCH #20, step #1722] loss: 1.2865279485372632\n",
      "[EPOCH #20, step #1724] loss: 1.2867091166454814\n",
      "[EPOCH #20, step #1726] loss: 1.2867047236569022\n",
      "[EPOCH #20, step #1728] loss: 1.2864070508506271\n",
      "[EPOCH #20, step #1730] loss: 1.2863985998378469\n",
      "[EPOCH #20, step #1732] loss: 1.285832183731132\n",
      "[EPOCH #20, step #1734] loss: 1.2858321375393387\n",
      "[EPOCH #20, step #1736] loss: 1.285839506724681\n",
      "[EPOCH #20, step #1738] loss: 1.2855706483622678\n",
      "[EPOCH #20, step #1740] loss: 1.2859086304954384\n",
      "[EPOCH #20, step #1742] loss: 1.286509490669697\n",
      "[EPOCH #20, step #1744] loss: 1.2867537680191434\n",
      "[EPOCH #20, step #1746] loss: 1.2867677310022136\n",
      "[EPOCH #20, step #1748] loss: 1.2865372795319816\n",
      "[EPOCH #20, step #1750] loss: 1.2862141720571905\n",
      "[EPOCH #20, step #1752] loss: 1.2866061161534146\n",
      "[EPOCH #20, step #1754] loss: 1.2863337573502478\n",
      "[EPOCH #20, step #1756] loss: 1.286141034243252\n",
      "[EPOCH #20, step #1758] loss: 1.2859040222566462\n",
      "[EPOCH #20, step #1760] loss: 1.285868563921461\n",
      "[EPOCH #20, step #1762] loss: 1.2862658411754644\n",
      "[EPOCH #20, step #1764] loss: 1.2862178958171488\n",
      "[EPOCH #20, step #1766] loss: 1.286118557005193\n",
      "[EPOCH #20, step #1768] loss: 1.285971211268445\n",
      "[EPOCH #20, step #1770] loss: 1.285989412138652\n",
      "[EPOCH #20, step #1772] loss: 1.2860367207357726\n",
      "[EPOCH #20, step #1774] loss: 1.2862372570978085\n",
      "[EPOCH #20, step #1776] loss: 1.2864440613807286\n",
      "[EPOCH #20, step #1778] loss: 1.286380703359457\n",
      "[EPOCH #20, step #1780] loss: 1.2863049684515968\n",
      "[EPOCH #20, step #1782] loss: 1.286217525175162\n",
      "[EPOCH #20, step #1784] loss: 1.2860447573728588\n",
      "[EPOCH #20, step #1786] loss: 1.2858292675578669\n",
      "[EPOCH #20, step #1788] loss: 1.2855515941819244\n",
      "[EPOCH #20, step #1790] loss: 1.2855407706457167\n",
      "[EPOCH #20, step #1792] loss: 1.2854790775987335\n",
      "[EPOCH #20, step #1794] loss: 1.285794560291641\n",
      "[EPOCH #20, step #1796] loss: 1.2855577551462813\n",
      "[EPOCH #20, step #1798] loss: 1.2854243227016138\n",
      "[EPOCH #20, step #1800] loss: 1.2857390541887364\n",
      "[EPOCH #20, step #1802] loss: 1.2855695654006383\n",
      "[EPOCH #20, step #1804] loss: 1.2858184587262014\n",
      "[EPOCH #20, step #1806] loss: 1.2856020978556593\n",
      "[EPOCH #20, step #1808] loss: 1.2857644531264234\n",
      "[EPOCH #20, step #1810] loss: 1.2858301361314108\n",
      "[EPOCH #20, step #1812] loss: 1.2858187324817971\n",
      "[EPOCH #20, step #1814] loss: 1.2860289193710348\n",
      "[EPOCH #20, step #1816] loss: 1.2857299024217654\n",
      "[EPOCH #20, step #1818] loss: 1.285922846995978\n",
      "[EPOCH #20, step #1820] loss: 1.2858105897903442\n",
      "[EPOCH #20, step #1822] loss: 1.2857993529906198\n",
      "[EPOCH #20, step #1824] loss: 1.2859423232405154\n",
      "[EPOCH #20, step #1826] loss: 1.2857194420543603\n",
      "[EPOCH #20, step #1828] loss: 1.2854944535328952\n",
      "[EPOCH #20, step #1830] loss: 1.285448221155101\n",
      "[EPOCH #20, step #1832] loss: 1.285304389426569\n",
      "[EPOCH #20, step #1834] loss: 1.2854612026942198\n",
      "[EPOCH #20, step #1836] loss: 1.2852896181344338\n",
      "[EPOCH #20, step #1838] loss: 1.2854523055251361\n",
      "[EPOCH #20, step #1840] loss: 1.2856605863001345\n",
      "[EPOCH #20, step #1842] loss: 1.2855110523562294\n",
      "[EPOCH #20, step #1844] loss: 1.2856432395252755\n",
      "[EPOCH #20, step #1846] loss: 1.28556616363102\n",
      "[EPOCH #20, step #1848] loss: 1.2858056051141833\n",
      "[EPOCH #20, step #1850] loss: 1.285440076047958\n",
      "[EPOCH #20, step #1852] loss: 1.285582943600831\n",
      "[EPOCH #20, step #1854] loss: 1.2855614294581656\n",
      "[EPOCH #20, step #1856] loss: 1.2853915001926206\n",
      "[EPOCH #20, step #1858] loss: 1.285302759114615\n",
      "[EPOCH #20, step #1860] loss: 1.2850705993105045\n",
      "[EPOCH #20, step #1862] loss: 1.2852552575061735\n",
      "[EPOCH #20, step #1864] loss: 1.285179063813616\n",
      "[EPOCH #20, step #1866] loss: 1.284926240688093\n",
      "[EPOCH #20, step #1868] loss: 1.285088529811306\n",
      "[EPOCH #20, step #1870] loss: 1.2851685395793824\n",
      "[EPOCH #20, step #1872] loss: 1.2848837374049715\n",
      "[EPOCH #20, step #1874] loss: 1.2849307354927062\n",
      "[EPOCH #20, step #1876] loss: 1.2847775652425113\n",
      "[EPOCH #20, step #1878] loss: 1.2847205383654539\n",
      "[EPOCH #20, step #1880] loss: 1.2850568836702432\n",
      "[EPOCH #20, step #1882] loss: 1.2850250140884996\n",
      "[EPOCH #20, step #1884] loss: 1.2849139282178499\n",
      "[EPOCH #20, step #1886] loss: 1.2846267467525565\n",
      "[EPOCH #20, step #1888] loss: 1.2844342495979866\n",
      "[EPOCH #20, step #1890] loss: 1.2842168073248195\n",
      "[EPOCH #20, step #1892] loss: 1.2842824600451974\n",
      "[EPOCH #20, step #1894] loss: 1.284136540310993\n",
      "[EPOCH #20, step #1896] loss: 1.284016641774929\n",
      "[EPOCH #20, step #1898] loss: 1.2838407094821358\n",
      "[EPOCH #20, step #1900] loss: 1.283728708191209\n",
      "[EPOCH #20, step #1902] loss: 1.2835687304633077\n",
      "[EPOCH #20, step #1904] loss: 1.2834343372680383\n",
      "[EPOCH #20, step #1906] loss: 1.283390575262909\n",
      "[EPOCH #20, step #1908] loss: 1.2830852009102336\n",
      "[EPOCH #20, step #1910] loss: 1.2830774634374742\n",
      "[EPOCH #20, step #1912] loss: 1.2833437785638668\n",
      "[EPOCH #20, step #1914] loss: 1.2832062661492172\n",
      "[EPOCH #20, step #1916] loss: 1.2831728286773012\n",
      "[EPOCH #20, step #1918] loss: 1.2830044494562314\n",
      "[EPOCH #20, step #1920] loss: 1.2827979083609793\n",
      "[EPOCH #20, step #1922] loss: 1.2828257574244086\n",
      "[EPOCH #20, step #1924] loss: 1.2829000224695577\n",
      "[EPOCH #20, step #1926] loss: 1.2833043484719975\n",
      "[EPOCH #20, step #1928] loss: 1.2831765269293818\n",
      "[EPOCH #20, step #1930] loss: 1.2834633935738697\n",
      "[EPOCH #20, step #1932] loss: 1.2833830160732043\n",
      "[EPOCH #20, step #1934] loss: 1.2836286306997293\n",
      "[EPOCH #20, step #1936] loss: 1.2837832673160945\n",
      "[EPOCH #20, step #1938] loss: 1.2839640401084746\n",
      "[EPOCH #20, step #1940] loss: 1.2840262772433848\n",
      "[EPOCH #20, step #1942] loss: 1.2839586069089386\n",
      "[EPOCH #20, step #1944] loss: 1.2841108941173798\n",
      "[EPOCH #20, step #1946] loss: 1.2839978130646221\n",
      "[EPOCH #20, step #1948] loss: 1.2838713870775156\n",
      "[EPOCH #20, step #1950] loss: 1.2837022688069875\n",
      "[EPOCH #20, step #1952] loss: 1.2837929399393182\n",
      "[EPOCH #20, step #1954] loss: 1.2836344133252684\n",
      "[EPOCH #20, step #1956] loss: 1.2834724224704106\n",
      "[EPOCH #20, step #1958] loss: 1.2836391068101234\n",
      "[EPOCH #20, step #1960] loss: 1.2838144373796474\n",
      "[EPOCH #20, step #1962] loss: 1.2841986883858667\n",
      "[EPOCH #20, step #1964] loss: 1.2843006255062481\n",
      "[EPOCH #20, step #1966] loss: 1.284410542228468\n",
      "[EPOCH #20, step #1968] loss: 1.2845707498207015\n",
      "[EPOCH #20, step #1970] loss: 1.2846038465811964\n",
      "[EPOCH #20, step #1972] loss: 1.284493919773508\n",
      "[EPOCH #20, step #1974] loss: 1.284518539845189\n",
      "[EPOCH #20, step #1976] loss: 1.2843774281249964\n",
      "[EPOCH #20, step #1978] loss: 1.2840106938751494\n",
      "[EPOCH #20, step #1980] loss: 1.2843379991515484\n",
      "[EPOCH #20, step #1982] loss: 1.2844360799003116\n",
      "[EPOCH #20, step #1984] loss: 1.2844687155872507\n",
      "[EPOCH #20, step #1986] loss: 1.2847089399389124\n",
      "[EPOCH #20, step #1988] loss: 1.2847240990343376\n",
      "[EPOCH #20, step #1990] loss: 1.28456567762965\n",
      "[EPOCH #20, step #1992] loss: 1.2844812555703098\n",
      "[EPOCH #20, step #1994] loss: 1.2841336148125784\n",
      "[EPOCH #20, step #1996] loss: 1.2840184405796755\n",
      "[EPOCH #20, step #1998] loss: 1.284291299746715\n",
      "[EPOCH #20, step #2000] loss: 1.284244169508559\n",
      "[EPOCH #20, step #2002] loss: 1.2846116686664815\n",
      "[EPOCH #20, step #2004] loss: 1.2845815232567062\n",
      "[EPOCH #20, step #2006] loss: 1.2843171196846328\n",
      "[EPOCH #20, step #2008] loss: 1.2841885812309857\n",
      "[EPOCH #20, step #2010] loss: 1.2841947463126635\n",
      "[EPOCH #20, step #2012] loss: 1.284214500136122\n",
      "[EPOCH #20, step #2014] loss: 1.2841937872375506\n",
      "[EPOCH #20, step #2016] loss: 1.2841744231125714\n",
      "[EPOCH #20, step #2018] loss: 1.284250863269156\n",
      "[EPOCH #20, step #2020] loss: 1.284585194886173\n",
      "[EPOCH #20, step #2022] loss: 1.2843754447985567\n",
      "[EPOCH #20, step #2024] loss: 1.2841870209022805\n",
      "[EPOCH #20, step #2026] loss: 1.2838270776249472\n",
      "[EPOCH #20, step #2028] loss: 1.2836968248674234\n",
      "[EPOCH #20, step #2030] loss: 1.2837079300016443\n",
      "[EPOCH #20, step #2032] loss: 1.2837669165393606\n",
      "[EPOCH #20, step #2034] loss: 1.2837869763667227\n",
      "[EPOCH #20, step #2036] loss: 1.2838249235218744\n",
      "[EPOCH #20, step #2038] loss: 1.2837722714243127\n",
      "[EPOCH #20, step #2040] loss: 1.2838649377117315\n",
      "[EPOCH #20, step #2042] loss: 1.283953186115446\n",
      "[EPOCH #20, step #2044] loss: 1.2838687051770739\n",
      "[EPOCH #20, step #2046] loss: 1.2841763252680862\n",
      "[EPOCH #20, step #2048] loss: 1.2841509982921717\n",
      "[EPOCH #20, step #2050] loss: 1.284147247374203\n",
      "[EPOCH #20, step #2052] loss: 1.2842868925650643\n",
      "[EPOCH #20, step #2054] loss: 1.2845044481493262\n",
      "[EPOCH #20, step #2056] loss: 1.2842146692255139\n",
      "[EPOCH #20, step #2058] loss: 1.284193894856181\n",
      "[EPOCH #20, step #2060] loss: 1.2842686337964273\n",
      "[EPOCH #20, step #2062] loss: 1.284274373624259\n",
      "[EPOCH #20, step #2064] loss: 1.28416059805175\n",
      "[EPOCH #20, step #2066] loss: 1.284172578456613\n",
      "[EPOCH #20, step #2068] loss: 1.2841655870691597\n",
      "[EPOCH #20, step #2070] loss: 1.284155002514099\n",
      "[EPOCH #20, step #2072] loss: 1.2840479200897272\n",
      "[EPOCH #20, step #2074] loss: 1.2838780579796756\n",
      "[EPOCH #20, step #2076] loss: 1.2836471595440453\n",
      "[EPOCH #20, step #2078] loss: 1.2839518572459603\n",
      "[EPOCH #20, step #2080] loss: 1.2839283525284984\n",
      "[EPOCH #20, step #2082] loss: 1.2839302081816826\n",
      "[EPOCH #20, step #2084] loss: 1.2840057200093349\n",
      "[EPOCH #20, step #2086] loss: 1.284240198152512\n",
      "[EPOCH #20, step #2088] loss: 1.2844750706860755\n",
      "[EPOCH #20, step #2090] loss: 1.2843630791052514\n",
      "[EPOCH #20, step #2092] loss: 1.2845573821138436\n",
      "[EPOCH #20, step #2094] loss: 1.2843968504937566\n",
      "[EPOCH #20, step #2096] loss: 1.2844214859211167\n",
      "[EPOCH #20, step #2098] loss: 1.2844113614969221\n",
      "[EPOCH #20, step #2100] loss: 1.284163332535845\n",
      "[EPOCH #20, step #2102] loss: 1.2841314023809665\n",
      "[EPOCH #20, step #2104] loss: 1.2840520357859107\n",
      "[EPOCH #20, step #2106] loss: 1.2840927345072652\n",
      "[EPOCH #20, step #2108] loss: 1.284087211642575\n",
      "[EPOCH #20, step #2110] loss: 1.2841660196834241\n",
      "[EPOCH #20, step #2112] loss: 1.2840813485525595\n",
      "[EPOCH #20, step #2114] loss: 1.2838665682936954\n",
      "[EPOCH #20, step #2116] loss: 1.2840020544809387\n",
      "[EPOCH #20, step #2118] loss: 1.2837876003550268\n",
      "[EPOCH #20, step #2120] loss: 1.2838351366543534\n",
      "[EPOCH #20, step #2122] loss: 1.2838118469103068\n",
      "[EPOCH #20, step #2124] loss: 1.2838437869128059\n",
      "[EPOCH #20, step #2126] loss: 1.2837627522531787\n",
      "[EPOCH #20, step #2128] loss: 1.2837082591623474\n",
      "[EPOCH #20, step #2130] loss: 1.2836119425179309\n",
      "[EPOCH #20, step #2132] loss: 1.2834720949974632\n",
      "[EPOCH #20, step #2134] loss: 1.2832047872297658\n",
      "[EPOCH #20, step #2136] loss: 1.2831512520008685\n",
      "[EPOCH #20, step #2138] loss: 1.2830872200203032\n",
      "[EPOCH #20, step #2140] loss: 1.2831798332531505\n",
      "[EPOCH #20, step #2142] loss: 1.283717613881067\n",
      "[EPOCH #20, step #2144] loss: 1.2836041698922644\n",
      "[EPOCH #20, step #2146] loss: 1.283729104480468\n",
      "[EPOCH #20, step #2148] loss: 1.283989491436081\n",
      "[EPOCH #20, step #2150] loss: 1.2840345306542795\n",
      "[EPOCH #20, step #2152] loss: 1.2841289818591426\n",
      "[EPOCH #20, step #2154] loss: 1.2840518004379804\n",
      "[EPOCH #20, step #2156] loss: 1.2839683949201264\n",
      "[EPOCH #20, step #2158] loss: 1.2838545166380486\n",
      "[EPOCH #20, step #2160] loss: 1.2838559784529553\n",
      "[EPOCH #20, step #2162] loss: 1.2839893638894782\n",
      "[EPOCH #20, step #2164] loss: 1.2839466258504926\n",
      "[EPOCH #20, step #2166] loss: 1.2841173904416305\n",
      "[EPOCH #20, step #2168] loss: 1.2843221077560665\n",
      "[EPOCH #20, step #2170] loss: 1.2843714028336057\n",
      "[EPOCH #20, step #2172] loss: 1.2842401474563416\n",
      "[EPOCH #20, step #2174] loss: 1.2842787493782482\n",
      "[EPOCH #20, step #2176] loss: 1.2842055681817401\n",
      "[EPOCH #20, step #2178] loss: 1.2841376309659625\n",
      "[EPOCH #20, step #2180] loss: 1.283985839257378\n",
      "[EPOCH #20, step #2182] loss: 1.2838782881357995\n",
      "[EPOCH #20, step #2184] loss: 1.2840659655477145\n",
      "[EPOCH #20, step #2186] loss: 1.284020704497035\n",
      "[EPOCH #20, step #2188] loss: 1.2841302271355446\n",
      "[EPOCH #20, step #2190] loss: 1.2841111358471082\n",
      "[EPOCH #20, step #2192] loss: 1.284090959830095\n",
      "[EPOCH #20, step #2194] loss: 1.2841845032022863\n",
      "[EPOCH #20, step #2196] loss: 1.2840997340139824\n",
      "[EPOCH #20, step #2198] loss: 1.2840970300066845\n",
      "[EPOCH #20, step #2200] loss: 1.2839765725543097\n",
      "[EPOCH #20, step #2202] loss: 1.2842842453834526\n",
      "[EPOCH #20, step #2204] loss: 1.2841992454193616\n",
      "[EPOCH #20, step #2206] loss: 1.2842813233039365\n",
      "[EPOCH #20, step #2208] loss: 1.2842975406692059\n",
      "[EPOCH #20, step #2210] loss: 1.284298903286484\n",
      "[EPOCH #20, step #2212] loss: 1.2838617459821637\n",
      "[EPOCH #20, step #2214] loss: 1.283757455623446\n",
      "[EPOCH #20, step #2216] loss: 1.2838292623566354\n",
      "[EPOCH #20, step #2218] loss: 1.283509971913909\n",
      "[EPOCH #20, step #2220] loss: 1.283560297554648\n",
      "[EPOCH #20, step #2222] loss: 1.2835439770703267\n",
      "[EPOCH #20, step #2224] loss: 1.2835733712121342\n",
      "[EPOCH #20, step #2226] loss: 1.2837117781915308\n",
      "[EPOCH #20, step #2228] loss: 1.2838724014629639\n",
      "[EPOCH #20, step #2230] loss: 1.2836809803530114\n",
      "[EPOCH #20, step #2232] loss: 1.283727031863435\n",
      "[EPOCH #20, step #2234] loss: 1.2836752593117273\n",
      "[EPOCH #20, step #2236] loss: 1.2835223819455985\n",
      "[EPOCH #20, step #2238] loss: 1.2833192331176508\n",
      "[EPOCH #20, step #2240] loss: 1.2830418879195336\n",
      "[EPOCH #20, step #2242] loss: 1.283056240234851\n",
      "[EPOCH #20, step #2244] loss: 1.2832029792407573\n",
      "[EPOCH #20, step #2246] loss: 1.2829860149089845\n",
      "[EPOCH #20, step #2248] loss: 1.283050619744894\n",
      "[EPOCH #20, step #2250] loss: 1.2828399798489845\n",
      "[EPOCH #20, step #2252] loss: 1.282884494363071\n",
      "[EPOCH #20, step #2254] loss: 1.2828688163979354\n",
      "[EPOCH #20, step #2256] loss: 1.282710123627282\n",
      "[EPOCH #20, step #2258] loss: 1.2826491154469764\n",
      "[EPOCH #20, step #2260] loss: 1.2823812032842572\n",
      "[EPOCH #20, step #2262] loss: 1.282585166720653\n",
      "[EPOCH #20, step #2264] loss: 1.2826154876492144\n",
      "[EPOCH #20, step #2266] loss: 1.2823875979226647\n",
      "[EPOCH #20, step #2268] loss: 1.2820576448018144\n",
      "[EPOCH #20, step #2270] loss: 1.2818889908463038\n",
      "[EPOCH #20, step #2272] loss: 1.2817561522853884\n",
      "[EPOCH #20, step #2274] loss: 1.2816960620618127\n",
      "[EPOCH #20, step #2276] loss: 1.2817594990638144\n",
      "[EPOCH #20, step #2278] loss: 1.281541508951434\n",
      "[EPOCH #20, step #2280] loss: 1.281442504528059\n",
      "[EPOCH #20, step #2282] loss: 1.2812222549124763\n",
      "[EPOCH #20, step #2284] loss: 1.280968127782809\n",
      "[EPOCH #20, step #2286] loss: 1.280871499637667\n",
      "[EPOCH #20, step #2288] loss: 1.280699104682594\n",
      "[EPOCH #20, step #2290] loss: 1.2805920046575723\n",
      "[EPOCH #20, step #2292] loss: 1.280650129783013\n",
      "[EPOCH #20, step #2294] loss: 1.2805817412654819\n",
      "[EPOCH #20, step #2296] loss: 1.2806596305767868\n",
      "[EPOCH #20, step #2298] loss: 1.2806614543521544\n",
      "[EPOCH #20, step #2300] loss: 1.2806206374311384\n",
      "[EPOCH #20, step #2302] loss: 1.2806207095339563\n",
      "[EPOCH #20, step #2304] loss: 1.280896465121536\n",
      "[EPOCH #20, step #2306] loss: 1.2808084664119495\n",
      "[EPOCH #20, step #2308] loss: 1.2808211601983421\n",
      "[EPOCH #20, step #2310] loss: 1.2805843762328026\n",
      "[EPOCH #20, step #2312] loss: 1.2806055834424275\n",
      "[EPOCH #20, step #2314] loss: 1.280590097023653\n",
      "[EPOCH #20, step #2316] loss: 1.2808619266344548\n",
      "[EPOCH #20, step #2318] loss: 1.2810877879769085\n",
      "[EPOCH #20, step #2320] loss: 1.2812153475903991\n",
      "[EPOCH #20, step #2322] loss: 1.2808543160153625\n",
      "[EPOCH #20, step #2324] loss: 1.280954156870483\n",
      "[EPOCH #20, step #2326] loss: 1.2808165536656315\n",
      "[EPOCH #20, step #2328] loss: 1.2807636125346733\n",
      "[EPOCH #20, step #2330] loss: 1.2806030478614536\n",
      "[EPOCH #20, step #2332] loss: 1.280644426568608\n",
      "[EPOCH #20, step #2334] loss: 1.2807106711879788\n",
      "[EPOCH #20, step #2336] loss: 1.2807893943827429\n",
      "[EPOCH #20, step #2338] loss: 1.2807705481371445\n",
      "[EPOCH #20, step #2340] loss: 1.281001457950082\n",
      "[EPOCH #20, step #2342] loss: 1.2810446337863923\n",
      "[EPOCH #20, step #2344] loss: 1.2811168946182805\n",
      "[EPOCH #20, step #2346] loss: 1.2810037693268297\n",
      "[EPOCH #20, step #2348] loss: 1.2809949207935196\n",
      "[EPOCH #20, step #2350] loss: 1.281011073957449\n",
      "[EPOCH #20, step #2352] loss: 1.2807485001471213\n",
      "[EPOCH #20, step #2354] loss: 1.2807400387057326\n",
      "[EPOCH #20, step #2356] loss: 1.2807007651233957\n",
      "[EPOCH #20, step #2358] loss: 1.2805656009733095\n",
      "[EPOCH #20, step #2360] loss: 1.2804225112663796\n",
      "[EPOCH #20, step #2362] loss: 1.280284160130921\n",
      "[EPOCH #20, step #2364] loss: 1.2801333958956453\n",
      "[EPOCH #20, step #2366] loss: 1.2801670380216839\n",
      "[EPOCH #20, step #2368] loss: 1.2801326978503527\n",
      "[EPOCH #20, step #2370] loss: 1.2804643616350528\n",
      "[EPOCH #20, step #2372] loss: 1.2803079194777434\n",
      "[EPOCH #20, step #2374] loss: 1.2801087200767116\n",
      "[EPOCH #20, step #2376] loss: 1.2798846325906426\n",
      "[EPOCH #20, step #2378] loss: 1.279622125495327\n",
      "[EPOCH #20, step #2380] loss: 1.2795519212723179\n",
      "[EPOCH #20, step #2382] loss: 1.2796980084814646\n",
      "[EPOCH #20, step #2384] loss: 1.279753293156374\n",
      "[EPOCH #20, step #2386] loss: 1.2797681928979436\n",
      "[EPOCH #20, step #2388] loss: 1.2795558451059326\n",
      "[EPOCH #20, step #2390] loss: 1.279630973592357\n",
      "[EPOCH #20, step #2392] loss: 1.2794210219104272\n",
      "[EPOCH #20, step #2394] loss: 1.2791717582555304\n",
      "[EPOCH #20, step #2396] loss: 1.2790402207814209\n",
      "[EPOCH #20, step #2398] loss: 1.278916199836397\n",
      "[EPOCH #20, step #2400] loss: 1.278822307237135\n",
      "[EPOCH #20, step #2402] loss: 1.278938372731457\n",
      "[EPOCH #20, step #2404] loss: 1.278877201050582\n",
      "[EPOCH #20, step #2406] loss: 1.2788854161881786\n",
      "[EPOCH #20, step #2408] loss: 1.2787867856253328\n",
      "[EPOCH #20, step #2410] loss: 1.2787738655771472\n",
      "[EPOCH #20, step #2412] loss: 1.2788345147305586\n",
      "[EPOCH #20, step #2414] loss: 1.2789406616001642\n",
      "[EPOCH #20, step #2416] loss: 1.278891097281065\n",
      "[EPOCH #20, step #2418] loss: 1.2790086165397017\n",
      "[EPOCH #20, step #2420] loss: 1.278956541784634\n",
      "[EPOCH #20, step #2422] loss: 1.2788509459127535\n",
      "[EPOCH #20, step #2424] loss: 1.278619727473898\n",
      "[EPOCH #20, step #2426] loss: 1.278704941960387\n",
      "[EPOCH #20, step #2428] loss: 1.2787878751607529\n",
      "[EPOCH #20, step #2430] loss: 1.2788381285502655\n",
      "[EPOCH #20, step #2432] loss: 1.2790107304943084\n",
      "[EPOCH #20, step #2434] loss: 1.278831078947447\n",
      "[EPOCH #20, step #2436] loss: 1.278867505958543\n",
      "[EPOCH #20, step #2438] loss: 1.2787811185992024\n",
      "[EPOCH #20, step #2440] loss: 1.2787485517521757\n",
      "[EPOCH #20, step #2442] loss: 1.2783668778052937\n",
      "[EPOCH #20, step #2444] loss: 1.278328108007435\n",
      "[EPOCH #20, step #2446] loss: 1.2785241173197408\n",
      "[EPOCH #20, step #2448] loss: 1.2787214129639919\n",
      "[EPOCH #20, step #2450] loss: 1.2788614399430218\n",
      "[EPOCH #20, step #2452] loss: 1.2788352353982035\n",
      "[EPOCH #20, step #2454] loss: 1.2788520196304787\n",
      "[EPOCH #20, step #2456] loss: 1.278964263227445\n",
      "[EPOCH #20, step #2458] loss: 1.2792155619509193\n",
      "[EPOCH #20, step #2460] loss: 1.279333171927798\n",
      "[EPOCH #20, step #2462] loss: 1.279551457594044\n",
      "[EPOCH #20, step #2464] loss: 1.2796126147070956\n",
      "[EPOCH #20, step #2466] loss: 1.2793421830829454\n",
      "[EPOCH #20, step #2468] loss: 1.279349815077799\n",
      "[EPOCH #20, step #2470] loss: 1.2793703073434433\n",
      "[EPOCH #20, step #2472] loss: 1.2795415293866692\n",
      "[EPOCH #20, step #2474] loss: 1.279478614450705\n",
      "[EPOCH #20, step #2476] loss: 1.2791936190127364\n",
      "[EPOCH #20, step #2478] loss: 1.2790204730424346\n",
      "[EPOCH #20, step #2480] loss: 1.2790726938828112\n",
      "[EPOCH #20, step #2482] loss: 1.2790352826247136\n",
      "[EPOCH #20, step #2484] loss: 1.2789931967464732\n",
      "[EPOCH #20, step #2486] loss: 1.279104258911553\n",
      "[EPOCH #20, step #2488] loss: 1.279103416666634\n",
      "[EPOCH #20, step #2490] loss: 1.2789799647128328\n",
      "[EPOCH #20, step #2492] loss: 1.2790230888226306\n",
      "[EPOCH #20, step #2494] loss: 1.279076696278337\n",
      "[EPOCH #20, step #2496] loss: 1.2791950439853004\n",
      "[EPOCH #20, step #2498] loss: 1.2791322519083699\n",
      "[EPOCH #20, elapsed time: 10155.934[sec]] loss: 1.279159293627739\n",
      "[EPOCH #21, step #0] loss: 0.7207942008972168\n",
      "[EPOCH #21, step #2] loss: 0.962766170501709\n",
      "[EPOCH #21, step #4] loss: 1.0958098411560058\n",
      "[EPOCH #21, step #6] loss: 1.128634239946093\n",
      "[EPOCH #21, step #8] loss: 1.1774365040991042\n",
      "[EPOCH #21, step #10] loss: 1.1905000805854797\n",
      "[EPOCH #21, step #12] loss: 1.194325836805197\n",
      "[EPOCH #21, step #14] loss: 1.160721731185913\n",
      "[EPOCH #21, step #16] loss: 1.1590141689076143\n",
      "[EPOCH #21, step #18] loss: 1.1811302053300958\n",
      "[EPOCH #21, step #20] loss: 1.1737615324202038\n",
      "[EPOCH #21, step #22] loss: 1.1789315576138704\n",
      "[EPOCH #21, step #24] loss: 1.1721193170547486\n",
      "[EPOCH #21, step #26] loss: 1.1741912276656539\n",
      "[EPOCH #21, step #28] loss: 1.1892540537077805\n",
      "[EPOCH #21, step #30] loss: 1.181905342686561\n",
      "[EPOCH #21, step #32] loss: 1.1761146422588464\n",
      "[EPOCH #21, step #34] loss: 1.1646696499415807\n",
      "[EPOCH #21, step #36] loss: 1.1549424674059894\n",
      "[EPOCH #21, step #38] loss: 1.1511348730478532\n",
      "[EPOCH #21, step #40] loss: 1.1438522266178597\n",
      "[EPOCH #21, step #42] loss: 1.1297919597736625\n",
      "[EPOCH #21, step #44] loss: 1.1334920949406093\n",
      "[EPOCH #21, step #46] loss: 1.1406107697081058\n",
      "[EPOCH #21, step #48] loss: 1.1460221288155537\n",
      "[EPOCH #21, step #50] loss: 1.1577320905292736\n",
      "[EPOCH #21, step #52] loss: 1.1456942018472924\n",
      "[EPOCH #21, step #54] loss: 1.1485877622257579\n",
      "[EPOCH #21, step #56] loss: 1.152835998618812\n",
      "[EPOCH #21, step #58] loss: 1.16403421709093\n",
      "[EPOCH #21, step #60] loss: 1.156458737420254\n",
      "[EPOCH #21, step #62] loss: 1.1562013077357458\n",
      "[EPOCH #21, step #64] loss: 1.161080314562871\n",
      "[EPOCH #21, step #66] loss: 1.1688799057433854\n",
      "[EPOCH #21, step #68] loss: 1.1643452946690545\n",
      "[EPOCH #21, step #70] loss: 1.1707967209144376\n",
      "[EPOCH #21, step #72] loss: 1.1708049700684744\n",
      "[EPOCH #21, step #74] loss: 1.1702237391471864\n",
      "[EPOCH #21, step #76] loss: 1.166799367248238\n",
      "[EPOCH #21, step #78] loss: 1.1631267432925068\n",
      "[EPOCH #21, step #80] loss: 1.1640483523592537\n",
      "[EPOCH #21, step #82] loss: 1.1667925090674895\n",
      "[EPOCH #21, step #84] loss: 1.1755089423235725\n",
      "[EPOCH #21, step #86] loss: 1.1680256265333329\n",
      "[EPOCH #21, step #88] loss: 1.1706417330195396\n",
      "[EPOCH #21, step #90] loss: 1.1696528288034291\n",
      "[EPOCH #21, step #92] loss: 1.167268886361071\n",
      "[EPOCH #21, step #94] loss: 1.1688529955713371\n",
      "[EPOCH #21, step #96] loss: 1.1641228352625346\n",
      "[EPOCH #21, step #98] loss: 1.1609261710234362\n",
      "[EPOCH #21, step #100] loss: 1.1588889372230757\n",
      "[EPOCH #21, step #102] loss: 1.166819246069899\n",
      "[EPOCH #21, step #104] loss: 1.1671439454669044\n",
      "[EPOCH #21, step #106] loss: 1.1693625639532215\n",
      "[EPOCH #21, step #108] loss: 1.1766265313559716\n",
      "[EPOCH #21, step #110] loss: 1.1778832716984793\n",
      "[EPOCH #21, step #112] loss: 1.1809291618060223\n",
      "[EPOCH #21, step #114] loss: 1.17583661183067\n",
      "[EPOCH #21, step #116] loss: 1.1734038321380942\n",
      "[EPOCH #21, step #118] loss: 1.1783417217871721\n",
      "[EPOCH #21, step #120] loss: 1.1776881735186933\n",
      "[EPOCH #21, step #122] loss: 1.1756703819685834\n",
      "[EPOCH #21, step #124] loss: 1.1758881497383118\n",
      "[EPOCH #21, step #126] loss: 1.1762470236913425\n",
      "[EPOCH #21, step #128] loss: 1.172534733317619\n",
      "[EPOCH #21, step #130] loss: 1.1714663232555826\n",
      "[EPOCH #21, step #132] loss: 1.1741268984357218\n",
      "[EPOCH #21, step #134] loss: 1.17259554333157\n",
      "[EPOCH #21, step #136] loss: 1.1719706493572597\n",
      "[EPOCH #21, step #138] loss: 1.1712935103786934\n",
      "[EPOCH #21, step #140] loss: 1.1711868170305346\n",
      "[EPOCH #21, step #142] loss: 1.1712660735303706\n",
      "[EPOCH #21, step #144] loss: 1.169956455559566\n",
      "[EPOCH #21, step #146] loss: 1.1686271112792346\n",
      "[EPOCH #21, step #148] loss: 1.1695113414085951\n",
      "[EPOCH #21, step #150] loss: 1.169523412423418\n",
      "[EPOCH #21, step #152] loss: 1.1687314864856746\n",
      "[EPOCH #21, step #154] loss: 1.170776952851203\n",
      "[EPOCH #21, step #156] loss: 1.1755975359564375\n",
      "[EPOCH #21, step #158] loss: 1.1733395592221674\n",
      "[EPOCH #21, step #160] loss: 1.1719429322651453\n",
      "[EPOCH #21, step #162] loss: 1.1729870383724845\n",
      "[EPOCH #21, step #164] loss: 1.1735569426507662\n",
      "[EPOCH #21, step #166] loss: 1.1725241545431628\n",
      "[EPOCH #21, step #168] loss: 1.173559724226506\n",
      "[EPOCH #21, step #170] loss: 1.1721507262068185\n",
      "[EPOCH #21, step #172] loss: 1.1726709611154016\n",
      "[EPOCH #21, step #174] loss: 1.1739233418873378\n",
      "[EPOCH #21, step #176] loss: 1.1725124390111805\n",
      "[EPOCH #21, step #178] loss: 1.1713327868690704\n",
      "[EPOCH #21, step #180] loss: 1.169202852315007\n",
      "[EPOCH #21, step #182] loss: 1.170644834067652\n",
      "[EPOCH #21, step #184] loss: 1.169253716597686\n",
      "[EPOCH #21, step #186] loss: 1.1746343342378178\n",
      "[EPOCH #21, step #188] loss: 1.1737520423515764\n",
      "[EPOCH #21, step #190] loss: 1.1752107467950952\n",
      "[EPOCH #21, step #192] loss: 1.17500697022275\n",
      "[EPOCH #21, step #194] loss: 1.1771043673539774\n",
      "[EPOCH #21, step #196] loss: 1.180468747458482\n",
      "[EPOCH #21, step #198] loss: 1.177843869331494\n",
      "[EPOCH #21, step #200] loss: 1.1791004449573916\n",
      "[EPOCH #21, step #202] loss: 1.1801288888372223\n",
      "[EPOCH #21, step #204] loss: 1.181119182923945\n",
      "[EPOCH #21, step #206] loss: 1.1800905817372787\n",
      "[EPOCH #21, step #208] loss: 1.1807163086804477\n",
      "[EPOCH #21, step #210] loss: 1.177818359356921\n",
      "[EPOCH #21, step #212] loss: 1.1774640872444906\n",
      "[EPOCH #21, step #214] loss: 1.1808103783186092\n",
      "[EPOCH #21, step #216] loss: 1.1799611202033433\n",
      "[EPOCH #21, step #218] loss: 1.1786678776349107\n",
      "[EPOCH #21, step #220] loss: 1.1753175692860358\n",
      "[EPOCH #21, step #222] loss: 1.177574539665684\n",
      "[EPOCH #21, step #224] loss: 1.1776737448904249\n",
      "[EPOCH #21, step #226] loss: 1.1795424561668597\n",
      "[EPOCH #21, step #228] loss: 1.1781497191654022\n",
      "[EPOCH #21, step #230] loss: 1.178425149742143\n",
      "[EPOCH #21, step #232] loss: 1.1784847550126105\n",
      "[EPOCH #21, step #234] loss: 1.1808586800352057\n",
      "[EPOCH #21, step #236] loss: 1.1828584303835776\n",
      "[EPOCH #21, step #238] loss: 1.1811074143174303\n",
      "[EPOCH #21, step #240] loss: 1.182278980358013\n",
      "[EPOCH #21, step #242] loss: 1.184498375825921\n",
      "[EPOCH #21, step #244] loss: 1.1841887464328689\n",
      "[EPOCH #21, step #246] loss: 1.1818332310147615\n",
      "[EPOCH #21, step #248] loss: 1.18307062181603\n",
      "[EPOCH #21, step #250] loss: 1.18265154922151\n",
      "[EPOCH #21, step #252] loss: 1.1836837523068364\n",
      "[EPOCH #21, step #254] loss: 1.1868810151137559\n",
      "[EPOCH #21, step #256] loss: 1.189842145962474\n",
      "[EPOCH #21, step #258] loss: 1.1903789759142518\n",
      "[EPOCH #21, step #260] loss: 1.189096650858035\n",
      "[EPOCH #21, step #262] loss: 1.1880269510664414\n",
      "[EPOCH #21, step #264] loss: 1.1868456608844253\n",
      "[EPOCH #21, step #266] loss: 1.185951615317484\n",
      "[EPOCH #21, step #268] loss: 1.187403034765038\n",
      "[EPOCH #21, step #270] loss: 1.1877273767636711\n",
      "[EPOCH #21, step #272] loss: 1.1909239071629423\n",
      "[EPOCH #21, step #274] loss: 1.1906784896417097\n",
      "[EPOCH #21, step #276] loss: 1.191421759042499\n",
      "[EPOCH #21, step #278] loss: 1.1917723722782614\n",
      "[EPOCH #21, step #280] loss: 1.1938633479681728\n",
      "[EPOCH #21, step #282] loss: 1.1926453562170372\n",
      "[EPOCH #21, step #284] loss: 1.1912190163344667\n",
      "[EPOCH #21, step #286] loss: 1.1896740258363065\n",
      "[EPOCH #21, step #288] loss: 1.1880723906223336\n",
      "[EPOCH #21, step #290] loss: 1.187154345291177\n",
      "[EPOCH #21, step #292] loss: 1.185809099836968\n",
      "[EPOCH #21, step #294] loss: 1.184328452409324\n",
      "[EPOCH #21, step #296] loss: 1.1841218202603787\n",
      "[EPOCH #21, step #298] loss: 1.1835373915158784\n",
      "[EPOCH #21, step #300] loss: 1.1821727140797333\n",
      "[EPOCH #21, step #302] loss: 1.1826253592377842\n",
      "[EPOCH #21, step #304] loss: 1.182741105165638\n",
      "[EPOCH #21, step #306] loss: 1.1809677124411742\n",
      "[EPOCH #21, step #308] loss: 1.1813427937069372\n",
      "[EPOCH #21, step #310] loss: 1.1809419698270571\n",
      "[EPOCH #21, step #312] loss: 1.1818087194293452\n",
      "[EPOCH #21, step #314] loss: 1.1821954333592974\n",
      "[EPOCH #21, step #316] loss: 1.1816229523168378\n",
      "[EPOCH #21, step #318] loss: 1.183535783642138\n",
      "[EPOCH #21, step #320] loss: 1.183762621285388\n",
      "[EPOCH #21, step #322] loss: 1.1857236295292621\n",
      "[EPOCH #21, step #324] loss: 1.1851022228827843\n",
      "[EPOCH #21, step #326] loss: 1.1847455815073182\n",
      "[EPOCH #21, step #328] loss: 1.1842937911535107\n",
      "[EPOCH #21, step #330] loss: 1.183240449860737\n",
      "[EPOCH #21, step #332] loss: 1.1819894641369313\n",
      "[EPOCH #21, step #334] loss: 1.1807626423551076\n",
      "[EPOCH #21, step #336] loss: 1.1790299542933613\n",
      "[EPOCH #21, step #338] loss: 1.179035889363922\n",
      "[EPOCH #21, step #340] loss: 1.1795308537497198\n",
      "[EPOCH #21, step #342] loss: 1.1800819253087391\n",
      "[EPOCH #21, step #344] loss: 1.1809297057165615\n",
      "[EPOCH #21, step #346] loss: 1.1794341663462284\n",
      "[EPOCH #21, step #348] loss: 1.1789121494593797\n",
      "[EPOCH #21, step #350] loss: 1.1784347458782358\n",
      "[EPOCH #21, step #352] loss: 1.177600722306173\n",
      "[EPOCH #21, step #354] loss: 1.1779578932574097\n",
      "[EPOCH #21, step #356] loss: 1.178323066702076\n",
      "[EPOCH #21, step #358] loss: 1.178438873842234\n",
      "[EPOCH #21, step #360] loss: 1.176691445947684\n",
      "[EPOCH #21, step #362] loss: 1.176403394415359\n",
      "[EPOCH #21, step #364] loss: 1.1770859349263858\n",
      "[EPOCH #21, step #366] loss: 1.1774723471347903\n",
      "[EPOCH #21, step #368] loss: 1.17779757821463\n",
      "[EPOCH #21, step #370] loss: 1.1796265085431121\n",
      "[EPOCH #21, step #372] loss: 1.1788007075281628\n",
      "[EPOCH #21, step #374] loss: 1.180573324839274\n",
      "[EPOCH #21, step #376] loss: 1.179857600114706\n",
      "[EPOCH #21, step #378] loss: 1.1810287072035757\n",
      "[EPOCH #21, step #380] loss: 1.1811816287165864\n",
      "[EPOCH #21, step #382] loss: 1.1811769368131853\n",
      "[EPOCH #21, step #384] loss: 1.1802235015026934\n",
      "[EPOCH #21, step #386] loss: 1.1811381100992209\n",
      "[EPOCH #21, step #388] loss: 1.182096062711701\n",
      "[EPOCH #21, step #390] loss: 1.182709685981731\n",
      "[EPOCH #21, step #392] loss: 1.1835057999341543\n",
      "[EPOCH #21, step #394] loss: 1.1833987730967848\n",
      "[EPOCH #21, step #396] loss: 1.1828466403093987\n",
      "[EPOCH #21, step #398] loss: 1.1812702052874076\n",
      "[EPOCH #21, step #400] loss: 1.182928216427639\n",
      "[EPOCH #21, step #402] loss: 1.1824798782173516\n",
      "[EPOCH #21, step #404] loss: 1.1818443685402105\n",
      "[EPOCH #21, step #406] loss: 1.1830564888162167\n",
      "[EPOCH #21, step #408] loss: 1.1840006878148663\n",
      "[EPOCH #21, step #410] loss: 1.18532815046264\n",
      "[EPOCH #21, step #412] loss: 1.1844553321094837\n",
      "[EPOCH #21, step #414] loss: 1.1839962785502514\n",
      "[EPOCH #21, step #416] loss: 1.1833357776669289\n",
      "[EPOCH #21, step #418] loss: 1.1835750547684463\n",
      "[EPOCH #21, step #420] loss: 1.183297214060668\n",
      "[EPOCH #21, step #422] loss: 1.1833733431554574\n",
      "[EPOCH #21, step #424] loss: 1.185084868178648\n",
      "[EPOCH #21, step #426] loss: 1.184511661948309\n",
      "[EPOCH #21, step #428] loss: 1.1850042978088895\n",
      "[EPOCH #21, step #430] loss: 1.185325714523997\n",
      "[EPOCH #21, step #432] loss: 1.185555720852374\n",
      "[EPOCH #21, step #434] loss: 1.1853222505799654\n",
      "[EPOCH #21, step #436] loss: 1.184201705510338\n",
      "[EPOCH #21, step #438] loss: 1.183250843663965\n",
      "[EPOCH #21, step #440] loss: 1.1832588821852288\n",
      "[EPOCH #21, step #442] loss: 1.1842921520194405\n",
      "[EPOCH #21, step #444] loss: 1.1841704470388006\n",
      "[EPOCH #21, step #446] loss: 1.184369707000869\n",
      "[EPOCH #21, step #448] loss: 1.1846057630594165\n",
      "[EPOCH #21, step #450] loss: 1.1849075016584205\n",
      "[EPOCH #21, step #452] loss: 1.1843152901457898\n",
      "[EPOCH #21, step #454] loss: 1.1847095414832398\n",
      "[EPOCH #21, step #456] loss: 1.1847072530627512\n",
      "[EPOCH #21, step #458] loss: 1.1855677009148275\n",
      "[EPOCH #21, step #460] loss: 1.185190839519211\n",
      "[EPOCH #21, step #462] loss: 1.1837524004425395\n",
      "[EPOCH #21, step #464] loss: 1.1844147462998666\n",
      "[EPOCH #21, step #466] loss: 1.1831768493325603\n",
      "[EPOCH #21, step #468] loss: 1.1830381124512728\n",
      "[EPOCH #21, step #470] loss: 1.182314951455264\n",
      "[EPOCH #21, step #472] loss: 1.18196143988071\n",
      "[EPOCH #21, step #474] loss: 1.1810571211262753\n",
      "[EPOCH #21, step #476] loss: 1.1814590899949304\n",
      "[EPOCH #21, step #478] loss: 1.1813115033326915\n",
      "[EPOCH #21, step #480] loss: 1.181484944111592\n",
      "[EPOCH #21, step #482] loss: 1.180153439010399\n",
      "[EPOCH #21, step #484] loss: 1.1809667835530546\n",
      "[EPOCH #21, step #486] loss: 1.1799702045853868\n",
      "[EPOCH #21, step #488] loss: 1.1802228488073758\n",
      "[EPOCH #21, step #490] loss: 1.1809307131650735\n",
      "[EPOCH #21, step #492] loss: 1.180507900265119\n",
      "[EPOCH #21, step #494] loss: 1.1800095938672923\n",
      "[EPOCH #21, step #496] loss: 1.1809660735984204\n",
      "[EPOCH #21, step #498] loss: 1.1806126030270228\n",
      "[EPOCH #21, step #500] loss: 1.181752256528584\n",
      "[EPOCH #21, step #502] loss: 1.1818543357356168\n",
      "[EPOCH #21, step #504] loss: 1.181527353041243\n",
      "[EPOCH #21, step #506] loss: 1.1830625454114503\n",
      "[EPOCH #21, step #508] loss: 1.1850650326910561\n",
      "[EPOCH #21, step #510] loss: 1.1858435290666942\n",
      "[EPOCH #21, step #512] loss: 1.1861264129363538\n",
      "[EPOCH #21, step #514] loss: 1.1867153524195106\n",
      "[EPOCH #21, step #516] loss: 1.1874948182004563\n",
      "[EPOCH #21, step #518] loss: 1.1864288835167196\n",
      "[EPOCH #21, step #520] loss: 1.186711644600083\n",
      "[EPOCH #21, step #522] loss: 1.1872817085304406\n",
      "[EPOCH #21, step #524] loss: 1.187738360563914\n",
      "[EPOCH #21, step #526] loss: 1.1885624998434672\n",
      "[EPOCH #21, step #528] loss: 1.1893485055528652\n",
      "[EPOCH #21, step #530] loss: 1.189280298919103\n",
      "[EPOCH #21, step #532] loss: 1.1895111387710857\n",
      "[EPOCH #21, step #534] loss: 1.189543332451972\n",
      "[EPOCH #21, step #536] loss: 1.1896623152150345\n",
      "[EPOCH #21, step #538] loss: 1.1901355775035158\n",
      "[EPOCH #21, step #540] loss: 1.1898122178648844\n",
      "[EPOCH #21, step #542] loss: 1.1888450660758256\n",
      "[EPOCH #21, step #544] loss: 1.1888518068768563\n",
      "[EPOCH #21, step #546] loss: 1.1890325300000486\n",
      "[EPOCH #21, step #548] loss: 1.1897026471970078\n",
      "[EPOCH #21, step #550] loss: 1.1890981129206677\n",
      "[EPOCH #21, step #552] loss: 1.1896068895703844\n",
      "[EPOCH #21, step #554] loss: 1.1894282505318925\n",
      "[EPOCH #21, step #556] loss: 1.1903280971080226\n",
      "[EPOCH #21, step #558] loss: 1.1910667318137687\n",
      "[EPOCH #21, step #560] loss: 1.1901206644036129\n",
      "[EPOCH #21, step #562] loss: 1.1897112549304114\n",
      "[EPOCH #21, step #564] loss: 1.189954911185577\n",
      "[EPOCH #21, step #566] loss: 1.1895670593310497\n",
      "[EPOCH #21, step #568] loss: 1.1894635928955146\n",
      "[EPOCH #21, step #570] loss: 1.189666734581027\n",
      "[EPOCH #21, step #572] loss: 1.1901123268858091\n",
      "[EPOCH #21, step #574] loss: 1.1897041473181351\n",
      "[EPOCH #21, step #576] loss: 1.1897892283608222\n",
      "[EPOCH #21, step #578] loss: 1.1889333821743058\n",
      "[EPOCH #21, step #580] loss: 1.1889971732682902\n",
      "[EPOCH #21, step #582] loss: 1.1893281914153189\n",
      "[EPOCH #21, step #584] loss: 1.1888972819360912\n",
      "[EPOCH #21, step #586] loss: 1.1886843720124163\n",
      "[EPOCH #21, step #588] loss: 1.1892487848958662\n",
      "[EPOCH #21, step #590] loss: 1.188854124340309\n",
      "[EPOCH #21, step #592] loss: 1.1879548630465142\n",
      "[EPOCH #21, step #594] loss: 1.1887142554050734\n",
      "[EPOCH #21, step #596] loss: 1.1891084518065205\n",
      "[EPOCH #21, step #598] loss: 1.189021798724523\n",
      "[EPOCH #21, step #600] loss: 1.1895979337406635\n",
      "[EPOCH #21, step #602] loss: 1.1892291185867727\n",
      "[EPOCH #21, step #604] loss: 1.1888797002390397\n",
      "[EPOCH #21, step #606] loss: 1.1884374525244585\n",
      "[EPOCH #21, step #608] loss: 1.1879207980260864\n",
      "[EPOCH #21, step #610] loss: 1.1878962140231593\n",
      "[EPOCH #21, step #612] loss: 1.1881526385784926\n",
      "[EPOCH #21, step #614] loss: 1.1885234045788524\n",
      "[EPOCH #21, step #616] loss: 1.1891239184034894\n",
      "[EPOCH #21, step #618] loss: 1.1883024559845254\n",
      "[EPOCH #21, step #620] loss: 1.1879498120667278\n",
      "[EPOCH #21, step #622] loss: 1.1885362587043982\n",
      "[EPOCH #21, step #624] loss: 1.1883924130439758\n",
      "[EPOCH #21, step #626] loss: 1.1883037749089693\n",
      "[EPOCH #21, step #628] loss: 1.1889619392317694\n",
      "[EPOCH #21, step #630] loss: 1.1889851458854797\n",
      "[EPOCH #21, step #632] loss: 1.1895606405738783\n",
      "[EPOCH #21, step #634] loss: 1.1886018313760833\n",
      "[EPOCH #21, step #636] loss: 1.1895848239422593\n",
      "[EPOCH #21, step #638] loss: 1.1906325837629315\n",
      "[EPOCH #21, step #640] loss: 1.1906214380599036\n",
      "[EPOCH #21, step #642] loss: 1.1910661493267278\n",
      "[EPOCH #21, step #644] loss: 1.1898804720982101\n",
      "[EPOCH #21, step #646] loss: 1.190765090390372\n",
      "[EPOCH #21, step #648] loss: 1.1911763947439855\n",
      "[EPOCH #21, step #650] loss: 1.191661290767189\n",
      "[EPOCH #21, step #652] loss: 1.1914533699818446\n",
      "[EPOCH #21, step #654] loss: 1.1909609610797796\n",
      "[EPOCH #21, step #656] loss: 1.1907425509195895\n",
      "[EPOCH #21, step #658] loss: 1.1907200753598366\n",
      "[EPOCH #21, step #660] loss: 1.1912269612123314\n",
      "[EPOCH #21, step #662] loss: 1.1905633367564343\n",
      "[EPOCH #21, step #664] loss: 1.1904335324029278\n",
      "[EPOCH #21, step #666] loss: 1.190832364416194\n",
      "[EPOCH #21, step #668] loss: 1.1905731886669837\n",
      "[EPOCH #21, step #670] loss: 1.191000423559311\n",
      "[EPOCH #21, step #672] loss: 1.190952342828351\n",
      "[EPOCH #21, step #674] loss: 1.1915456930796304\n",
      "[EPOCH #21, step #676] loss: 1.1914623699300926\n",
      "[EPOCH #21, step #678] loss: 1.1925252137022622\n",
      "[EPOCH #21, step #680] loss: 1.1926498994253105\n",
      "[EPOCH #21, step #682] loss: 1.193105717180065\n",
      "[EPOCH #21, step #684] loss: 1.1926977396011353\n",
      "[EPOCH #21, step #686] loss: 1.192467794321163\n",
      "[EPOCH #21, step #688] loss: 1.1922006315520608\n",
      "[EPOCH #21, step #690] loss: 1.191948973062932\n",
      "[EPOCH #21, step #692] loss: 1.191791087431997\n",
      "[EPOCH #21, step #694] loss: 1.191772145418812\n",
      "[EPOCH #21, step #696] loss: 1.1925026257889855\n",
      "[EPOCH #21, step #698] loss: 1.191772767573126\n",
      "[EPOCH #21, step #700] loss: 1.1920257910512144\n",
      "[EPOCH #21, step #702] loss: 1.19193197059767\n",
      "[EPOCH #21, step #704] loss: 1.1918106717420809\n",
      "[EPOCH #21, step #706] loss: 1.1918480727595016\n",
      "[EPOCH #21, step #708] loss: 1.192284591191242\n",
      "[EPOCH #21, step #710] loss: 1.1919149086612857\n",
      "[EPOCH #21, step #712] loss: 1.1915087974088223\n",
      "[EPOCH #21, step #714] loss: 1.1916771110121187\n",
      "[EPOCH #21, step #716] loss: 1.1913418475554078\n",
      "[EPOCH #21, step #718] loss: 1.1916224157362554\n",
      "[EPOCH #21, step #720] loss: 1.1912985901230748\n",
      "[EPOCH #21, step #722] loss: 1.1913102176014647\n",
      "[EPOCH #21, step #724] loss: 1.1905489650265924\n",
      "[EPOCH #21, step #726] loss: 1.1902369487072448\n",
      "[EPOCH #21, step #728] loss: 1.189509066943442\n",
      "[EPOCH #21, step #730] loss: 1.1891641115359504\n",
      "[EPOCH #21, step #732] loss: 1.188866796223561\n",
      "[EPOCH #21, step #734] loss: 1.1886518034805247\n",
      "[EPOCH #21, step #736] loss: 1.1896210272405978\n",
      "[EPOCH #21, step #738] loss: 1.1903368245119654\n",
      "[EPOCH #21, step #740] loss: 1.1905057617688146\n",
      "[EPOCH #21, step #742] loss: 1.190842782023136\n",
      "[EPOCH #21, step #744] loss: 1.1905480779257396\n",
      "[EPOCH #21, step #746] loss: 1.190536650069746\n",
      "[EPOCH #21, step #748] loss: 1.1907847845188289\n",
      "[EPOCH #21, step #750] loss: 1.19102108803951\n",
      "[EPOCH #21, step #752] loss: 1.1908281234156088\n",
      "[EPOCH #21, step #754] loss: 1.1909314847150385\n",
      "[EPOCH #21, step #756] loss: 1.1910646867248151\n",
      "[EPOCH #21, step #758] loss: 1.1910223294937878\n",
      "[EPOCH #21, step #760] loss: 1.1910405626591496\n",
      "[EPOCH #21, step #762] loss: 1.1910041518323855\n",
      "[EPOCH #21, step #764] loss: 1.191356041774251\n",
      "[EPOCH #21, step #766] loss: 1.190893413268292\n",
      "[EPOCH #21, step #768] loss: 1.191495195089298\n",
      "[EPOCH #21, step #770] loss: 1.19166442400132\n",
      "[EPOCH #21, step #772] loss: 1.1919084091081655\n",
      "[EPOCH #21, step #774] loss: 1.1913043092143152\n",
      "[EPOCH #21, step #776] loss: 1.1916954318682353\n",
      "[EPOCH #21, step #778] loss: 1.1911212163803973\n",
      "[EPOCH #21, step #780] loss: 1.1909279765301264\n",
      "[EPOCH #21, step #782] loss: 1.1900826809811258\n",
      "[EPOCH #21, step #784] loss: 1.19000891925423\n",
      "[EPOCH #21, step #786] loss: 1.1903562039856384\n",
      "[EPOCH #21, step #788] loss: 1.1900801053518577\n",
      "[EPOCH #21, step #790] loss: 1.1898060514863613\n",
      "[EPOCH #21, step #792] loss: 1.1899729337998928\n",
      "[EPOCH #21, step #794] loss: 1.1897655394092297\n",
      "[EPOCH #21, step #796] loss: 1.189983732428126\n",
      "[EPOCH #21, step #798] loss: 1.1898166450749947\n",
      "[EPOCH #21, step #800] loss: 1.1894302754366441\n",
      "[EPOCH #21, step #802] loss: 1.1888008378956416\n",
      "[EPOCH #21, step #804] loss: 1.1895330485349858\n",
      "[EPOCH #21, step #806] loss: 1.190923755349132\n",
      "[EPOCH #21, step #808] loss: 1.1912060981922599\n",
      "[EPOCH #21, step #810] loss: 1.1919194965562456\n",
      "[EPOCH #21, step #812] loss: 1.1914417881514021\n",
      "[EPOCH #21, step #814] loss: 1.1920730536700759\n",
      "[EPOCH #21, step #816] loss: 1.191798145870246\n",
      "[EPOCH #21, step #818] loss: 1.1919933949780261\n",
      "[EPOCH #21, step #820] loss: 1.1921140544307072\n",
      "[EPOCH #21, step #822] loss: 1.1928240177408314\n",
      "[EPOCH #21, step #824] loss: 1.1924132922201445\n",
      "[EPOCH #21, step #826] loss: 1.192167970909317\n",
      "[EPOCH #21, step #828] loss: 1.1919432048055605\n",
      "[EPOCH #21, step #830] loss: 1.1918953121354003\n",
      "[EPOCH #21, step #832] loss: 1.1919682025193883\n",
      "[EPOCH #21, step #834] loss: 1.1924966969889794\n",
      "[EPOCH #21, step #836] loss: 1.1925754016587953\n",
      "[EPOCH #21, step #838] loss: 1.192380370556669\n",
      "[EPOCH #21, step #840] loss: 1.1921552557865873\n",
      "[EPOCH #21, step #842] loss: 1.1923949948267862\n",
      "[EPOCH #21, step #844] loss: 1.1926578927322253\n",
      "[EPOCH #21, step #846] loss: 1.192855183250648\n",
      "[EPOCH #21, step #848] loss: 1.1927335137332427\n",
      "[EPOCH #21, step #850] loss: 1.192805751090044\n",
      "[EPOCH #21, step #852] loss: 1.1933833817664232\n",
      "[EPOCH #21, step #854] loss: 1.1934382106825623\n",
      "[EPOCH #21, step #856] loss: 1.19331653616114\n",
      "[EPOCH #21, step #858] loss: 1.1936391694720605\n",
      "[EPOCH #21, step #860] loss: 1.1930082573984835\n",
      "[EPOCH #21, step #862] loss: 1.1925105592743133\n",
      "[EPOCH #21, step #864] loss: 1.1930994848295444\n",
      "[EPOCH #21, step #866] loss: 1.1933779537746514\n",
      "[EPOCH #21, step #868] loss: 1.1931733943787763\n",
      "[EPOCH #21, step #870] loss: 1.1929954005711114\n",
      "[EPOCH #21, step #872] loss: 1.1932661362666581\n",
      "[EPOCH #21, step #874] loss: 1.1930280757631575\n",
      "[EPOCH #21, step #876] loss: 1.1928728948025502\n",
      "[EPOCH #21, step #878] loss: 1.1932105706142213\n",
      "[EPOCH #21, step #880] loss: 1.1932078832665312\n",
      "[EPOCH #21, step #882] loss: 1.1935162032582076\n",
      "[EPOCH #21, step #884] loss: 1.1937746165162426\n",
      "[EPOCH #21, step #886] loss: 1.1932881723799593\n",
      "[EPOCH #21, step #888] loss: 1.1930010270482376\n",
      "[EPOCH #21, step #890] loss: 1.1932053442889727\n",
      "[EPOCH #21, step #892] loss: 1.1941511904672706\n",
      "[EPOCH #21, step #894] loss: 1.194829110060324\n",
      "[EPOCH #21, step #896] loss: 1.1955896576112728\n",
      "[EPOCH #21, step #898] loss: 1.1953363362886218\n",
      "[EPOCH #21, step #900] loss: 1.1951177128808745\n",
      "[EPOCH #21, step #902] loss: 1.194582930104941\n",
      "[EPOCH #21, step #904] loss: 1.1947931562998018\n",
      "[EPOCH #21, step #906] loss: 1.1945491657893212\n",
      "[EPOCH #21, step #908] loss: 1.1951264464946993\n",
      "[EPOCH #21, step #910] loss: 1.1954494312356516\n",
      "[EPOCH #21, step #912] loss: 1.1955623569911569\n",
      "[EPOCH #21, step #914] loss: 1.1960388152977157\n",
      "[EPOCH #21, step #916] loss: 1.1956940752859333\n",
      "[EPOCH #21, step #918] loss: 1.1948343149596121\n",
      "[EPOCH #21, step #920] loss: 1.1948247586218206\n",
      "[EPOCH #21, step #922] loss: 1.1942649401667833\n",
      "[EPOCH #21, step #924] loss: 1.1940106198594378\n",
      "[EPOCH #21, step #926] loss: 1.1944678749209983\n",
      "[EPOCH #21, step #928] loss: 1.1942398324207804\n",
      "[EPOCH #21, step #930] loss: 1.1934836133594287\n",
      "[EPOCH #21, step #932] loss: 1.1940006066237487\n",
      "[EPOCH #21, step #934] loss: 1.1937142509827638\n",
      "[EPOCH #21, step #936] loss: 1.1942162101525762\n",
      "[EPOCH #21, step #938] loss: 1.1945506024538393\n",
      "[EPOCH #21, step #940] loss: 1.194250940009714\n",
      "[EPOCH #21, step #942] loss: 1.1943352680064714\n",
      "[EPOCH #21, step #944] loss: 1.1937593809511295\n",
      "[EPOCH #21, step #946] loss: 1.194411901133617\n",
      "[EPOCH #21, step #948] loss: 1.1942395108140558\n",
      "[EPOCH #21, step #950] loss: 1.1940523011200561\n",
      "[EPOCH #21, step #952] loss: 1.1934470730713507\n",
      "[EPOCH #21, step #954] loss: 1.1929017254195289\n",
      "[EPOCH #21, step #956] loss: 1.1935269182378596\n",
      "[EPOCH #21, step #958] loss: 1.1938573866616449\n",
      "[EPOCH #21, step #960] loss: 1.193732750031256\n",
      "[EPOCH #21, step #962] loss: 1.193449175060724\n",
      "[EPOCH #21, step #964] loss: 1.1934005397589096\n",
      "[EPOCH #21, step #966] loss: 1.1930520387198833\n",
      "[EPOCH #21, step #968] loss: 1.1936066859892893\n",
      "[EPOCH #21, step #970] loss: 1.193453952040903\n",
      "[EPOCH #21, step #972] loss: 1.1928744254842447\n",
      "[EPOCH #21, step #974] loss: 1.1926665198497284\n",
      "[EPOCH #21, step #976] loss: 1.1922027713322714\n",
      "[EPOCH #21, step #978] loss: 1.192404949750306\n",
      "[EPOCH #21, step #980] loss: 1.192143960344196\n",
      "[EPOCH #21, step #982] loss: 1.1920787697527198\n",
      "[EPOCH #21, step #984] loss: 1.1919327619717206\n",
      "[EPOCH #21, step #986] loss: 1.1919595266427192\n",
      "[EPOCH #21, step #988] loss: 1.1911222571309343\n",
      "[EPOCH #21, step #990] loss: 1.191662978392196\n",
      "[EPOCH #21, step #992] loss: 1.1917622378105364\n",
      "[EPOCH #21, step #994] loss: 1.1915764689445496\n",
      "[EPOCH #21, step #996] loss: 1.1911654819098256\n",
      "[EPOCH #21, step #998] loss: 1.1910500686328571\n",
      "[EPOCH #21, step #1000] loss: 1.1908308172916675\n",
      "[EPOCH #21, step #1002] loss: 1.1909570204890736\n",
      "[EPOCH #21, step #1004] loss: 1.191063371641719\n",
      "[EPOCH #21, step #1006] loss: 1.1908770861786668\n",
      "[EPOCH #21, step #1008] loss: 1.1915520209268962\n",
      "[EPOCH #21, step #1010] loss: 1.1914765966280514\n",
      "[EPOCH #21, step #1012] loss: 1.1917942399333754\n",
      "[EPOCH #21, step #1014] loss: 1.191501671046459\n",
      "[EPOCH #21, step #1016] loss: 1.1913965340912518\n",
      "[EPOCH #21, step #1018] loss: 1.1911036305502423\n",
      "[EPOCH #21, step #1020] loss: 1.1907335252416238\n",
      "[EPOCH #21, step #1022] loss: 1.1906935955422364\n",
      "[EPOCH #21, step #1024] loss: 1.1912811603778746\n",
      "[EPOCH #21, step #1026] loss: 1.191034694087076\n",
      "[EPOCH #21, step #1028] loss: 1.191049669122557\n",
      "[EPOCH #21, step #1030] loss: 1.19112362911352\n",
      "[EPOCH #21, step #1032] loss: 1.1911105519342746\n",
      "[EPOCH #21, step #1034] loss: 1.1911966250714472\n",
      "[EPOCH #21, step #1036] loss: 1.1903039277347098\n",
      "[EPOCH #21, step #1038] loss: 1.1907550731568066\n",
      "[EPOCH #21, step #1040] loss: 1.1906734004716937\n",
      "[EPOCH #21, step #1042] loss: 1.1908619754152123\n",
      "[EPOCH #21, step #1044] loss: 1.190917780467768\n",
      "[EPOCH #21, step #1046] loss: 1.1911021070812813\n",
      "[EPOCH #21, step #1048] loss: 1.1914072473692372\n",
      "[EPOCH #21, step #1050] loss: 1.1915789981550766\n",
      "[EPOCH #21, step #1052] loss: 1.1918757092579138\n",
      "[EPOCH #21, step #1054] loss: 1.1913561574655687\n",
      "[EPOCH #21, step #1056] loss: 1.191615858840401\n",
      "[EPOCH #21, step #1058] loss: 1.1915698424052021\n",
      "[EPOCH #21, step #1060] loss: 1.1919044067452922\n",
      "[EPOCH #21, step #1062] loss: 1.1918337352973385\n",
      "[EPOCH #21, step #1064] loss: 1.1916568290459717\n",
      "[EPOCH #21, step #1066] loss: 1.191436256162452\n",
      "[EPOCH #21, step #1068] loss: 1.1911110560731202\n",
      "[EPOCH #21, step #1070] loss: 1.1913093065236018\n",
      "[EPOCH #21, step #1072] loss: 1.1915157302894663\n",
      "[EPOCH #21, step #1074] loss: 1.1917228344429371\n",
      "[EPOCH #21, step #1076] loss: 1.1918192925338071\n",
      "[EPOCH #21, step #1078] loss: 1.1913062462218942\n",
      "[EPOCH #21, step #1080] loss: 1.1916534683419862\n",
      "[EPOCH #21, step #1082] loss: 1.191602336567855\n",
      "[EPOCH #21, step #1084] loss: 1.1916928368779371\n",
      "[EPOCH #21, step #1086] loss: 1.1915318897369265\n",
      "[EPOCH #21, step #1088] loss: 1.1913843882861106\n",
      "[EPOCH #21, step #1090] loss: 1.192157747765182\n",
      "[EPOCH #21, step #1092] loss: 1.1921925304793264\n",
      "[EPOCH #21, step #1094] loss: 1.1922784515711815\n",
      "[EPOCH #21, step #1096] loss: 1.192355267492988\n",
      "[EPOCH #21, step #1098] loss: 1.192835086307491\n",
      "[EPOCH #21, step #1100] loss: 1.192914523015122\n",
      "[EPOCH #21, step #1102] loss: 1.192681463274865\n",
      "[EPOCH #21, step #1104] loss: 1.192517973341014\n",
      "[EPOCH #21, step #1106] loss: 1.1928992140583876\n",
      "[EPOCH #21, step #1108] loss: 1.193204406739571\n",
      "[EPOCH #21, step #1110] loss: 1.1937817088877372\n",
      "[EPOCH #21, step #1112] loss: 1.193834347170104\n",
      "[EPOCH #21, step #1114] loss: 1.1935847506394834\n",
      "[EPOCH #21, step #1116] loss: 1.1935806216250175\n",
      "[EPOCH #21, step #1118] loss: 1.1941891095273935\n",
      "[EPOCH #21, step #1120] loss: 1.1945334235330867\n",
      "[EPOCH #21, step #1122] loss: 1.1944079587529626\n",
      "[EPOCH #21, step #1124] loss: 1.1942838904062907\n",
      "[EPOCH #21, step #1126] loss: 1.1938829388148824\n",
      "[EPOCH #21, step #1128] loss: 1.1939771917670885\n",
      "[EPOCH #21, step #1130] loss: 1.1933814841071448\n",
      "[EPOCH #21, step #1132] loss: 1.193440626968037\n",
      "[EPOCH #21, step #1134] loss: 1.192730044058241\n",
      "[EPOCH #21, step #1136] loss: 1.1929251450452243\n",
      "[EPOCH #21, step #1138] loss: 1.1928282036291495\n",
      "[EPOCH #21, step #1140] loss: 1.192445835034958\n",
      "[EPOCH #21, step #1142] loss: 1.1922168685799612\n",
      "[EPOCH #21, step #1144] loss: 1.192001475829745\n",
      "[EPOCH #21, step #1146] loss: 1.1917884417378393\n",
      "[EPOCH #21, step #1148] loss: 1.1919661573579354\n",
      "[EPOCH #21, step #1150] loss: 1.191458428299603\n",
      "[EPOCH #21, step #1152] loss: 1.1918572960784926\n",
      "[EPOCH #21, step #1154] loss: 1.1918924589177746\n",
      "[EPOCH #21, step #1156] loss: 1.192358058747693\n",
      "[EPOCH #21, step #1158] loss: 1.1922613795303496\n",
      "[EPOCH #21, step #1160] loss: 1.1918964048688725\n",
      "[EPOCH #21, step #1162] loss: 1.1915060738910404\n",
      "[EPOCH #21, step #1164] loss: 1.1918415761300933\n",
      "[EPOCH #21, step #1166] loss: 1.1920536151786287\n",
      "[EPOCH #21, step #1168] loss: 1.1913945617280117\n",
      "[EPOCH #21, step #1170] loss: 1.1918071467178077\n",
      "[EPOCH #21, step #1172] loss: 1.1917265780136714\n",
      "[EPOCH #21, step #1174] loss: 1.1922706946413568\n",
      "[EPOCH #21, step #1176] loss: 1.1918749054205449\n",
      "[EPOCH #21, step #1178] loss: 1.191946797951285\n",
      "[EPOCH #21, step #1180] loss: 1.1920551176196332\n",
      "[EPOCH #21, step #1182] loss: 1.1920252856518994\n",
      "[EPOCH #21, step #1184] loss: 1.1922052337650508\n",
      "[EPOCH #21, step #1186] loss: 1.1923870217328123\n",
      "[EPOCH #21, step #1188] loss: 1.192342084581056\n",
      "[EPOCH #21, step #1190] loss: 1.192715262335754\n",
      "[EPOCH #21, step #1192] loss: 1.192531502856393\n",
      "[EPOCH #21, step #1194] loss: 1.1926912975111765\n",
      "[EPOCH #21, step #1196] loss: 1.1929484279133822\n",
      "[EPOCH #21, step #1198] loss: 1.1928131747882103\n",
      "[EPOCH #21, step #1200] loss: 1.192656291166412\n",
      "[EPOCH #21, step #1202] loss: 1.1922425320519077\n",
      "[EPOCH #21, step #1204] loss: 1.1921245661513935\n",
      "[EPOCH #21, step #1206] loss: 1.1923657740159972\n",
      "[EPOCH #21, step #1208] loss: 1.1921167295268984\n",
      "[EPOCH #21, step #1210] loss: 1.191847784916888\n",
      "[EPOCH #21, step #1212] loss: 1.1918880256953952\n",
      "[EPOCH #21, step #1214] loss: 1.1918075713601133\n",
      "[EPOCH #21, step #1216] loss: 1.1914023673720504\n",
      "[EPOCH #21, step #1218] loss: 1.1911820856834456\n",
      "[EPOCH #21, step #1220] loss: 1.1912768194657872\n",
      "[EPOCH #21, step #1222] loss: 1.1912049973293688\n",
      "[EPOCH #21, step #1224] loss: 1.1912286482051928\n",
      "[EPOCH #21, step #1226] loss: 1.1917786950878526\n",
      "[EPOCH #21, step #1228] loss: 1.1916644547022486\n",
      "[EPOCH #21, step #1230] loss: 1.1915747778479593\n",
      "[EPOCH #21, step #1232] loss: 1.1915005577935114\n",
      "[EPOCH #21, step #1234] loss: 1.1916442994646699\n",
      "[EPOCH #21, step #1236] loss: 1.1918163141514277\n",
      "[EPOCH #21, step #1238] loss: 1.191921367531731\n",
      "[EPOCH #21, step #1240] loss: 1.1916975202241509\n",
      "[EPOCH #21, step #1242] loss: 1.1919457967590155\n",
      "[EPOCH #21, step #1244] loss: 1.1918686590520253\n",
      "[EPOCH #21, step #1246] loss: 1.1921235041419507\n",
      "[EPOCH #21, step #1248] loss: 1.1917379366769325\n",
      "[EPOCH #21, step #1250] loss: 1.1915193955770595\n",
      "[EPOCH #21, step #1252] loss: 1.191315013840973\n",
      "[EPOCH #21, step #1254] loss: 1.1916218961377543\n",
      "[EPOCH #21, step #1256] loss: 1.1916033308849319\n",
      "[EPOCH #21, step #1258] loss: 1.1914548642868272\n",
      "[EPOCH #21, step #1260] loss: 1.1912144393225117\n",
      "[EPOCH #21, step #1262] loss: 1.1911782531255026\n",
      "[EPOCH #21, step #1264] loss: 1.1910109852142485\n",
      "[EPOCH #21, step #1266] loss: 1.1906592374066245\n",
      "[EPOCH #21, step #1268] loss: 1.1904296373362802\n",
      "[EPOCH #21, step #1270] loss: 1.190322253762222\n",
      "[EPOCH #21, step #1272] loss: 1.190374291139799\n",
      "[EPOCH #21, step #1274] loss: 1.1906942158119351\n",
      "[EPOCH #21, step #1276] loss: 1.1906419093476297\n",
      "[EPOCH #21, step #1278] loss: 1.1905195475836299\n",
      "[EPOCH #21, step #1280] loss: 1.1901180770227817\n",
      "[EPOCH #21, step #1282] loss: 1.1902316777109636\n",
      "[EPOCH #21, step #1284] loss: 1.1899072156342088\n",
      "[EPOCH #21, step #1286] loss: 1.1896699602138932\n",
      "[EPOCH #21, step #1288] loss: 1.189869098833497\n",
      "[EPOCH #21, step #1290] loss: 1.1898922057783392\n",
      "[EPOCH #21, step #1292] loss: 1.1901926731565435\n",
      "[EPOCH #21, step #1294] loss: 1.190061735462498\n",
      "[EPOCH #21, step #1296] loss: 1.190285674130448\n",
      "[EPOCH #21, step #1298] loss: 1.190389479096804\n",
      "[EPOCH #21, step #1300] loss: 1.1909600108701572\n",
      "[EPOCH #21, step #1302] loss: 1.190614885261035\n",
      "[EPOCH #21, step #1304] loss: 1.1905540389119438\n",
      "[EPOCH #21, step #1306] loss: 1.1908391028665457\n",
      "[EPOCH #21, step #1308] loss: 1.1905602903836006\n",
      "[EPOCH #21, step #1310] loss: 1.1903722847262745\n",
      "[EPOCH #21, step #1312] loss: 1.1903784443019276\n",
      "[EPOCH #21, step #1314] loss: 1.1898459812080906\n",
      "[EPOCH #21, step #1316] loss: 1.1900814935033215\n",
      "[EPOCH #21, step #1318] loss: 1.1908910648220863\n",
      "[EPOCH #21, step #1320] loss: 1.1907184356816514\n",
      "[EPOCH #21, step #1322] loss: 1.1903608179596996\n",
      "[EPOCH #21, step #1324] loss: 1.1912755591014645\n",
      "[EPOCH #21, step #1326] loss: 1.1919743289782216\n",
      "[EPOCH #21, step #1328] loss: 1.1918462734638613\n",
      "[EPOCH #21, step #1330] loss: 1.1925843766002526\n",
      "[EPOCH #21, step #1332] loss: 1.1926601868505686\n",
      "[EPOCH #21, step #1334] loss: 1.1925045391147056\n",
      "[EPOCH #21, step #1336] loss: 1.1927097860163687\n",
      "[EPOCH #21, step #1338] loss: 1.1929550931202644\n",
      "[EPOCH #21, step #1340] loss: 1.1927872328150193\n",
      "[EPOCH #21, step #1342] loss: 1.193030435827714\n",
      "[EPOCH #21, step #1344] loss: 1.1931558533672064\n",
      "[EPOCH #21, step #1346] loss: 1.193509240458431\n",
      "[EPOCH #21, step #1348] loss: 1.1940750266287925\n",
      "[EPOCH #21, step #1350] loss: 1.1937761032343088\n",
      "[EPOCH #21, step #1352] loss: 1.1938031258093191\n",
      "[EPOCH #21, step #1354] loss: 1.194423245591871\n",
      "[EPOCH #21, step #1356] loss: 1.1946594303112832\n",
      "[EPOCH #21, step #1358] loss: 1.1944317435235816\n",
      "[EPOCH #21, step #1360] loss: 1.1944450701885938\n",
      "[EPOCH #21, step #1362] loss: 1.1947936871343907\n",
      "[EPOCH #21, step #1364] loss: 1.1946075940306806\n",
      "[EPOCH #21, step #1366] loss: 1.194539144384486\n",
      "[EPOCH #21, step #1368] loss: 1.1946685731715752\n",
      "[EPOCH #21, step #1370] loss: 1.194391020191229\n",
      "[EPOCH #21, step #1372] loss: 1.194378095826179\n",
      "[EPOCH #21, step #1374] loss: 1.1949004823511298\n",
      "[EPOCH #21, step #1376] loss: 1.1942948955249855\n",
      "[EPOCH #21, step #1378] loss: 1.1942696099353927\n",
      "[EPOCH #21, step #1380] loss: 1.1942031044272907\n",
      "[EPOCH #21, step #1382] loss: 1.195027488776074\n",
      "[EPOCH #21, step #1384] loss: 1.1948691964579834\n",
      "[EPOCH #21, step #1386] loss: 1.1950140576957367\n",
      "[EPOCH #21, step #1388] loss: 1.1952794427233175\n",
      "[EPOCH #21, step #1390] loss: 1.1952799927579851\n",
      "[EPOCH #21, step #1392] loss: 1.1953413141175986\n",
      "[EPOCH #21, step #1394] loss: 1.1953540094009865\n",
      "[EPOCH #21, step #1396] loss: 1.1953109190902629\n",
      "[EPOCH #21, step #1398] loss: 1.1948635215585448\n",
      "[EPOCH #21, step #1400] loss: 1.1947813019592535\n",
      "[EPOCH #21, step #1402] loss: 1.194547886688711\n",
      "[EPOCH #21, step #1404] loss: 1.1942029667918792\n",
      "[EPOCH #21, step #1406] loss: 1.1944190173091496\n",
      "[EPOCH #21, step #1408] loss: 1.1941411671611415\n",
      "[EPOCH #21, step #1410] loss: 1.1939408940934357\n",
      "[EPOCH #21, step #1412] loss: 1.1936555471052452\n",
      "[EPOCH #21, step #1414] loss: 1.1939285753893767\n",
      "[EPOCH #21, step #1416] loss: 1.194125595232426\n",
      "[EPOCH #21, step #1418] loss: 1.194227451711914\n",
      "[EPOCH #21, step #1420] loss: 1.1941649712029685\n",
      "[EPOCH #21, step #1422] loss: 1.1943737580503113\n",
      "[EPOCH #21, step #1424] loss: 1.194626919052057\n",
      "[EPOCH #21, step #1426] loss: 1.194725249268078\n",
      "[EPOCH #21, step #1428] loss: 1.1946904562919436\n",
      "[EPOCH #21, step #1430] loss: 1.195270983386423\n",
      "[EPOCH #21, step #1432] loss: 1.1950837972275627\n",
      "[EPOCH #21, step #1434] loss: 1.1949237279360303\n",
      "[EPOCH #21, step #1436] loss: 1.1948987456270614\n",
      "[EPOCH #21, step #1438] loss: 1.194831562588992\n",
      "[EPOCH #21, step #1440] loss: 1.1947750503366643\n",
      "[EPOCH #21, step #1442] loss: 1.1946287588864999\n",
      "[EPOCH #21, step #1444] loss: 1.1941916198878966\n",
      "[EPOCH #21, step #1446] loss: 1.1940681012070582\n",
      "[EPOCH #21, step #1448] loss: 1.1938761228771355\n",
      "[EPOCH #21, step #1450] loss: 1.1936390379804485\n",
      "[EPOCH #21, step #1452] loss: 1.1935532585719661\n",
      "[EPOCH #21, step #1454] loss: 1.1937002986157472\n",
      "[EPOCH #21, step #1456] loss: 1.1933297148369402\n",
      "[EPOCH #21, step #1458] loss: 1.1935353968305242\n",
      "[EPOCH #21, step #1460] loss: 1.1936635592063758\n",
      "[EPOCH #21, step #1462] loss: 1.1940630800253058\n",
      "[EPOCH #21, step #1464] loss: 1.1941787930071963\n",
      "[EPOCH #21, step #1466] loss: 1.1943168100972685\n",
      "[EPOCH #21, step #1468] loss: 1.1948082933546005\n",
      "[EPOCH #21, step #1470] loss: 1.1950297821224505\n",
      "[EPOCH #21, step #1472] loss: 1.1949639287192402\n",
      "[EPOCH #21, step #1474] loss: 1.1949628796819913\n",
      "[EPOCH #21, step #1476] loss: 1.1949994428462891\n",
      "[EPOCH #21, step #1478] loss: 1.1947296593058665\n",
      "[EPOCH #21, step #1480] loss: 1.194977132916692\n",
      "[EPOCH #21, step #1482] loss: 1.1951809339803052\n",
      "[EPOCH #21, step #1484] loss: 1.1953450998874626\n",
      "[EPOCH #21, step #1486] loss: 1.1953345824185841\n",
      "[EPOCH #21, step #1488] loss: 1.194937881605188\n",
      "[EPOCH #21, step #1490] loss: 1.195345024747548\n",
      "[EPOCH #21, step #1492] loss: 1.1954061490373171\n",
      "[EPOCH #21, step #1494] loss: 1.1949801332177128\n",
      "[EPOCH #21, step #1496] loss: 1.195172847511773\n",
      "[EPOCH #21, step #1498] loss: 1.1952580502623316\n",
      "[EPOCH #21, step #1500] loss: 1.1950123103200239\n",
      "[EPOCH #21, step #1502] loss: 1.1949309787985014\n",
      "[EPOCH #21, step #1504] loss: 1.1949493824049484\n",
      "[EPOCH #21, step #1506] loss: 1.1950540374507157\n",
      "[EPOCH #21, step #1508] loss: 1.1948183987850065\n",
      "[EPOCH #21, step #1510] loss: 1.1948127045606163\n",
      "[EPOCH #21, step #1512] loss: 1.1952451553789103\n",
      "[EPOCH #21, step #1514] loss: 1.1952582576093893\n",
      "[EPOCH #21, step #1516] loss: 1.1955294416150375\n",
      "[EPOCH #21, step #1518] loss: 1.1956834447391729\n",
      "[EPOCH #21, step #1520] loss: 1.1957759593443835\n",
      "[EPOCH #21, step #1522] loss: 1.1955971774582164\n",
      "[EPOCH #21, step #1524] loss: 1.1954555326211649\n",
      "[EPOCH #21, step #1526] loss: 1.195780546117157\n",
      "[EPOCH #21, step #1528] loss: 1.1953084471570345\n",
      "[EPOCH #21, step #1530] loss: 1.195403605757937\n",
      "[EPOCH #21, step #1532] loss: 1.1955800336012246\n",
      "[EPOCH #21, step #1534] loss: 1.1955158801731147\n",
      "[EPOCH #21, step #1536] loss: 1.1955612197120855\n",
      "[EPOCH #21, step #1538] loss: 1.1955028756475046\n",
      "[EPOCH #21, step #1540] loss: 1.1953597606040687\n",
      "[EPOCH #21, step #1542] loss: 1.1949874842931756\n",
      "[EPOCH #21, step #1544] loss: 1.1947114482280892\n",
      "[EPOCH #21, step #1546] loss: 1.194292550520043\n",
      "[EPOCH #21, step #1548] loss: 1.1944398746481244\n",
      "[EPOCH #21, step #1550] loss: 1.194088076945661\n",
      "[EPOCH #21, step #1552] loss: 1.19419589283692\n",
      "[EPOCH #21, step #1554] loss: 1.1943100639478186\n",
      "[EPOCH #21, step #1556] loss: 1.1942940210790762\n",
      "[EPOCH #21, step #1558] loss: 1.1946087213874705\n",
      "[EPOCH #21, step #1560] loss: 1.1945273246160308\n",
      "[EPOCH #21, step #1562] loss: 1.1945888882482654\n",
      "[EPOCH #21, step #1564] loss: 1.1943239651168116\n",
      "[EPOCH #21, step #1566] loss: 1.1941577827162095\n",
      "[EPOCH #21, step #1568] loss: 1.1935925687324325\n",
      "[EPOCH #21, step #1570] loss: 1.1935870029757845\n",
      "[EPOCH #21, step #1572] loss: 1.193402901812867\n",
      "[EPOCH #21, step #1574] loss: 1.1932508491334461\n",
      "[EPOCH #21, step #1576] loss: 1.1930917549072826\n",
      "[EPOCH #21, step #1578] loss: 1.1933981250402972\n",
      "[EPOCH #21, step #1580] loss: 1.1938034673041742\n",
      "[EPOCH #21, step #1582] loss: 1.1935307776634254\n",
      "[EPOCH #21, step #1584] loss: 1.1937214069562003\n",
      "[EPOCH #21, step #1586] loss: 1.1933701145401072\n",
      "[EPOCH #21, step #1588] loss: 1.1933510093061785\n",
      "[EPOCH #21, step #1590] loss: 1.1935348494632825\n",
      "[EPOCH #21, step #1592] loss: 1.1937474749107744\n",
      "[EPOCH #21, step #1594] loss: 1.193813931119853\n",
      "[EPOCH #21, step #1596] loss: 1.1942452132216677\n",
      "[EPOCH #21, step #1598] loss: 1.194747463884467\n",
      "[EPOCH #21, step #1600] loss: 1.194681269574508\n",
      "[EPOCH #21, step #1602] loss: 1.19496762577772\n",
      "[EPOCH #21, step #1604] loss: 1.1949877645739142\n",
      "[EPOCH #21, step #1606] loss: 1.1948087489523351\n",
      "[EPOCH #21, step #1608] loss: 1.19505177183578\n",
      "[EPOCH #21, step #1610] loss: 1.1950169885698718\n",
      "[EPOCH #21, step #1612] loss: 1.1948244419810348\n",
      "[EPOCH #21, step #1614] loss: 1.1953279303692443\n",
      "[EPOCH #21, step #1616] loss: 1.195453561340207\n",
      "[EPOCH #21, step #1618] loss: 1.1950889063735595\n",
      "[EPOCH #21, step #1620] loss: 1.1950520632224344\n",
      "[EPOCH #21, step #1622] loss: 1.1951179769548896\n",
      "[EPOCH #21, step #1624] loss: 1.195334074313824\n",
      "[EPOCH #21, step #1626] loss: 1.1956229191582557\n",
      "[EPOCH #21, step #1628] loss: 1.1955089185631589\n",
      "[EPOCH #21, step #1630] loss: 1.195332071592587\n",
      "[EPOCH #21, step #1632] loss: 1.195162379880369\n",
      "[EPOCH #21, step #1634] loss: 1.1949130775367083\n",
      "[EPOCH #21, step #1636] loss: 1.1947572974075102\n",
      "[EPOCH #21, step #1638] loss: 1.1946501456214713\n",
      "[EPOCH #21, step #1640] loss: 1.1941909719574095\n",
      "[EPOCH #21, step #1642] loss: 1.1939822116133214\n",
      "[EPOCH #21, step #1644] loss: 1.1937528459134434\n",
      "[EPOCH #21, step #1646] loss: 1.1940892539244388\n",
      "[EPOCH #21, step #1648] loss: 1.1943995381861907\n",
      "[EPOCH #21, step #1650] loss: 1.1942695461570096\n",
      "[EPOCH #21, step #1652] loss: 1.194202897048184\n",
      "[EPOCH #21, step #1654] loss: 1.1942458615922495\n",
      "[EPOCH #21, step #1656] loss: 1.194161525820132\n",
      "[EPOCH #21, step #1658] loss: 1.1942855765691647\n",
      "[EPOCH #21, step #1660] loss: 1.193980566569655\n",
      "[EPOCH #21, step #1662] loss: 1.1940693873923296\n",
      "[EPOCH #21, step #1664] loss: 1.194527479120203\n",
      "[EPOCH #21, step #1666] loss: 1.1946408016351289\n",
      "[EPOCH #21, step #1668] loss: 1.1946152916848838\n",
      "[EPOCH #21, step #1670] loss: 1.1947252730064803\n",
      "[EPOCH #21, step #1672] loss: 1.1947208744497693\n",
      "[EPOCH #21, step #1674] loss: 1.194626404527408\n",
      "[EPOCH #21, step #1676] loss: 1.1946437293813565\n",
      "[EPOCH #21, step #1678] loss: 1.1945367467552512\n",
      "[EPOCH #21, step #1680] loss: 1.194793422508637\n",
      "[EPOCH #21, step #1682] loss: 1.1947857704958742\n",
      "[EPOCH #21, step #1684] loss: 1.195033697310824\n",
      "[EPOCH #21, step #1686] loss: 1.1949379005655425\n",
      "[EPOCH #21, step #1688] loss: 1.195210121205885\n",
      "[EPOCH #21, step #1690] loss: 1.1952326798636415\n",
      "[EPOCH #21, step #1692] loss: 1.1951767379056049\n",
      "[EPOCH #21, step #1694] loss: 1.1951663767342018\n",
      "[EPOCH #21, step #1696] loss: 1.1950405111506748\n",
      "[EPOCH #21, step #1698] loss: 1.1948277174970414\n",
      "[EPOCH #21, step #1700] loss: 1.1951653082744995\n",
      "[EPOCH #21, step #1702] loss: 1.1950874984509372\n",
      "[EPOCH #21, step #1704] loss: 1.1948181816210146\n",
      "[EPOCH #21, step #1706] loss: 1.1949311562218579\n",
      "[EPOCH #21, step #1708] loss: 1.1948556856428272\n",
      "[EPOCH #21, step #1710] loss: 1.1950720690412873\n",
      "[EPOCH #21, step #1712] loss: 1.1950656398652384\n",
      "[EPOCH #21, step #1714] loss: 1.1951398147785977\n",
      "[EPOCH #21, step #1716] loss: 1.1956774698625696\n",
      "[EPOCH #21, step #1718] loss: 1.1955017473823877\n",
      "[EPOCH #21, step #1720] loss: 1.1955035751396526\n",
      "[EPOCH #21, step #1722] loss: 1.1951037538791907\n",
      "[EPOCH #21, step #1724] loss: 1.1950033706167469\n",
      "[EPOCH #21, step #1726] loss: 1.1949624517575537\n",
      "[EPOCH #21, step #1728] loss: 1.1948507386456342\n",
      "[EPOCH #21, step #1730] loss: 1.1947280826216002\n",
      "[EPOCH #21, step #1732] loss: 1.194616757681517\n",
      "[EPOCH #21, step #1734] loss: 1.1943609593581055\n",
      "[EPOCH #21, step #1736] loss: 1.1943136738440603\n",
      "[EPOCH #21, step #1738] loss: 1.1940080798721093\n",
      "[EPOCH #21, step #1740] loss: 1.1937452244183444\n",
      "[EPOCH #21, step #1742] loss: 1.193993000312571\n",
      "[EPOCH #21, step #1744] loss: 1.1938878127360413\n",
      "[EPOCH #21, step #1746] loss: 1.194386132628698\n",
      "[EPOCH #21, step #1748] loss: 1.1942893547150255\n",
      "[EPOCH #21, step #1750] loss: 1.1943222784710095\n",
      "[EPOCH #21, step #1752] loss: 1.1941907184843465\n",
      "[EPOCH #21, step #1754] loss: 1.1941628366454036\n",
      "[EPOCH #21, step #1756] loss: 1.1941950091192108\n",
      "[EPOCH #21, step #1758] loss: 1.1940899373049625\n",
      "[EPOCH #21, step #1760] loss: 1.1940924020601498\n",
      "[EPOCH #21, step #1762] loss: 1.1938408005663568\n",
      "[EPOCH #21, step #1764] loss: 1.1938859782205424\n",
      "[EPOCH #21, step #1766] loss: 1.1937864769226965\n",
      "[EPOCH #21, step #1768] loss: 1.193624396624708\n",
      "[EPOCH #21, step #1770] loss: 1.1935375752521733\n",
      "[EPOCH #21, step #1772] loss: 1.193380911203676\n",
      "[EPOCH #21, step #1774] loss: 1.1931882281370565\n",
      "[EPOCH #21, step #1776] loss: 1.1931182195044128\n",
      "[EPOCH #21, step #1778] loss: 1.1926912474055984\n",
      "[EPOCH #21, step #1780] loss: 1.1925585880365217\n",
      "[EPOCH #21, step #1782] loss: 1.1930026733935448\n",
      "[EPOCH #21, step #1784] loss: 1.193333206590818\n",
      "[EPOCH #21, step #1786] loss: 1.1932699660982709\n",
      "[EPOCH #21, step #1788] loss: 1.1927527520095522\n",
      "[EPOCH #21, step #1790] loss: 1.1927191927271938\n",
      "[EPOCH #21, step #1792] loss: 1.1924649612636322\n",
      "[EPOCH #21, step #1794] loss: 1.1924066566159135\n",
      "[EPOCH #21, step #1796] loss: 1.1923220536412964\n",
      "[EPOCH #21, step #1798] loss: 1.1923347732767653\n",
      "[EPOCH #21, step #1800] loss: 1.1923853494537202\n",
      "[EPOCH #21, step #1802] loss: 1.1921744218681893\n",
      "[EPOCH #21, step #1804] loss: 1.1922858558863485\n",
      "[EPOCH #21, step #1806] loss: 1.192185373779945\n",
      "[EPOCH #21, step #1808] loss: 1.192251839085532\n",
      "[EPOCH #21, step #1810] loss: 1.1921511232227597\n",
      "[EPOCH #21, step #1812] loss: 1.1921752112646886\n",
      "[EPOCH #21, step #1814] loss: 1.1920970670447861\n",
      "[EPOCH #21, step #1816] loss: 1.1923346703828004\n",
      "[EPOCH #21, step #1818] loss: 1.192285292878657\n",
      "[EPOCH #21, step #1820] loss: 1.1925041577372166\n",
      "[EPOCH #21, step #1822] loss: 1.1927335279300457\n",
      "[EPOCH #21, step #1824] loss: 1.192559197242946\n",
      "[EPOCH #21, step #1826] loss: 1.192691253584855\n",
      "[EPOCH #21, step #1828] loss: 1.1928448547360153\n",
      "[EPOCH #21, step #1830] loss: 1.1927032628259915\n",
      "[EPOCH #21, step #1832] loss: 1.192785625046742\n",
      "[EPOCH #21, step #1834] loss: 1.192792744207772\n",
      "[EPOCH #21, step #1836] loss: 1.1932966626722266\n",
      "[EPOCH #21, step #1838] loss: 1.1933398622089653\n",
      "[EPOCH #21, step #1840] loss: 1.193230429594443\n",
      "[EPOCH #21, step #1842] loss: 1.1931081138029735\n",
      "[EPOCH #21, step #1844] loss: 1.1932255753010592\n",
      "[EPOCH #21, step #1846] loss: 1.1930952687552638\n",
      "[EPOCH #21, step #1848] loss: 1.1931524525918853\n",
      "[EPOCH #21, step #1850] loss: 1.1935506967967553\n",
      "[EPOCH #21, step #1852] loss: 1.193831586188004\n",
      "[EPOCH #21, step #1854] loss: 1.193902683161661\n",
      "[EPOCH #21, step #1856] loss: 1.1936950620362112\n",
      "[EPOCH #21, step #1858] loss: 1.1935442747962033\n",
      "[EPOCH #21, step #1860] loss: 1.193545678141039\n",
      "[EPOCH #21, step #1862] loss: 1.1934561574260714\n",
      "[EPOCH #21, step #1864] loss: 1.1933233059443353\n",
      "[EPOCH #21, step #1866] loss: 1.1930780716611538\n",
      "[EPOCH #21, step #1868] loss: 1.1929802339047655\n",
      "[EPOCH #21, step #1870] loss: 1.1928835642140285\n",
      "[EPOCH #21, step #1872] loss: 1.1924588895391413\n",
      "[EPOCH #21, step #1874] loss: 1.1920713697751364\n",
      "[EPOCH #21, step #1876] loss: 1.192283392111291\n",
      "[EPOCH #21, step #1878] loss: 1.1924244654248406\n",
      "[EPOCH #21, step #1880] loss: 1.1927931670937242\n",
      "[EPOCH #21, step #1882] loss: 1.192527464204688\n",
      "[EPOCH #21, step #1884] loss: 1.1926104525672345\n",
      "[EPOCH #21, step #1886] loss: 1.192365569226882\n",
      "[EPOCH #21, step #1888] loss: 1.1919797408385149\n",
      "[EPOCH #21, step #1890] loss: 1.192214594260528\n",
      "[EPOCH #21, step #1892] loss: 1.1920828401129269\n",
      "[EPOCH #21, step #1894] loss: 1.1922202565110138\n",
      "[EPOCH #21, step #1896] loss: 1.192108964002566\n",
      "[EPOCH #21, step #1898] loss: 1.1919133757967395\n",
      "[EPOCH #21, step #1900] loss: 1.1919134388717458\n",
      "[EPOCH #21, step #1902] loss: 1.1915957829667843\n",
      "[EPOCH #21, step #1904] loss: 1.191621748856672\n",
      "[EPOCH #21, step #1906] loss: 1.1917651476632505\n",
      "[EPOCH #21, step #1908] loss: 1.191763540036145\n",
      "[EPOCH #21, step #1910] loss: 1.1917549979930022\n",
      "[EPOCH #21, step #1912] loss: 1.1916856609335509\n",
      "[EPOCH #21, step #1914] loss: 1.1916958641756918\n",
      "[EPOCH #21, step #1916] loss: 1.1918708829439488\n",
      "[EPOCH #21, step #1918] loss: 1.1918004514215637\n",
      "[EPOCH #21, step #1920] loss: 1.1918364455773147\n",
      "[EPOCH #21, step #1922] loss: 1.191895826279466\n",
      "[EPOCH #21, step #1924] loss: 1.1921455530377179\n",
      "[EPOCH #21, step #1926] loss: 1.1919309774333477\n",
      "[EPOCH #21, step #1928] loss: 1.191514774701211\n",
      "[EPOCH #21, step #1930] loss: 1.1912339367068907\n",
      "[EPOCH #21, step #1932] loss: 1.191209023873299\n",
      "[EPOCH #21, step #1934] loss: 1.1917173361593438\n",
      "[EPOCH #21, step #1936] loss: 1.1920672711109954\n",
      "[EPOCH #21, step #1938] loss: 1.1921872159388338\n",
      "[EPOCH #21, step #1940] loss: 1.192668507358329\n",
      "[EPOCH #21, step #1942] loss: 1.1927137899447886\n",
      "[EPOCH #21, step #1944] loss: 1.192586037953286\n",
      "[EPOCH #21, step #1946] loss: 1.1923758527469683\n",
      "[EPOCH #21, step #1948] loss: 1.1924667323534766\n",
      "[EPOCH #21, step #1950] loss: 1.1925544085593054\n",
      "[EPOCH #21, step #1952] loss: 1.1925200684157262\n",
      "[EPOCH #21, step #1954] loss: 1.192353430306515\n",
      "[EPOCH #21, step #1956] loss: 1.1929692460007977\n",
      "[EPOCH #21, step #1958] loss: 1.1934492840579483\n",
      "[EPOCH #21, step #1960] loss: 1.193220833501665\n",
      "[EPOCH #21, step #1962] loss: 1.193073545374314\n",
      "[EPOCH #21, step #1964] loss: 1.1930241843822955\n",
      "[EPOCH #21, step #1966] loss: 1.1931278067127242\n",
      "[EPOCH #21, step #1968] loss: 1.192932142074366\n",
      "[EPOCH #21, step #1970] loss: 1.1935725435576785\n",
      "[EPOCH #21, step #1972] loss: 1.1934153254238773\n",
      "[EPOCH #21, step #1974] loss: 1.1936336201052122\n",
      "[EPOCH #21, step #1976] loss: 1.193455031892538\n",
      "[EPOCH #21, step #1978] loss: 1.1934502363626616\n",
      "[EPOCH #21, step #1980] loss: 1.1935921331236665\n",
      "[EPOCH #21, step #1982] loss: 1.193505869961362\n",
      "[EPOCH #21, step #1984] loss: 1.193769175730064\n",
      "[EPOCH #21, step #1986] loss: 1.1938238734567832\n",
      "[EPOCH #21, step #1988] loss: 1.1937294824450624\n",
      "[EPOCH #21, step #1990] loss: 1.193745707040573\n",
      "[EPOCH #21, step #1992] loss: 1.1934909128209663\n",
      "[EPOCH #21, step #1994] loss: 1.193437221564147\n",
      "[EPOCH #21, step #1996] loss: 1.1937727152435673\n",
      "[EPOCH #21, step #1998] loss: 1.193908356171122\n",
      "[EPOCH #21, step #2000] loss: 1.194001239755641\n",
      "[EPOCH #21, step #2002] loss: 1.1943563534150525\n",
      "[EPOCH #21, step #2004] loss: 1.1943035507439972\n",
      "[EPOCH #21, step #2006] loss: 1.1940797183367526\n",
      "[EPOCH #21, step #2008] loss: 1.1937618921383393\n",
      "[EPOCH #21, step #2010] loss: 1.1941864779788662\n",
      "[EPOCH #21, step #2012] loss: 1.1940764670814972\n",
      "[EPOCH #21, step #2014] loss: 1.1942283372429405\n",
      "[EPOCH #21, step #2016] loss: 1.1941583125261488\n",
      "[EPOCH #21, step #2018] loss: 1.1941908421405416\n",
      "[EPOCH #21, step #2020] loss: 1.1943152835025816\n",
      "[EPOCH #21, step #2022] loss: 1.1941786806770793\n",
      "[EPOCH #21, step #2024] loss: 1.1938375150715863\n",
      "[EPOCH #21, step #2026] loss: 1.1936627278553775\n",
      "[EPOCH #21, step #2028] loss: 1.1934868444827698\n",
      "[EPOCH #21, step #2030] loss: 1.1932297242151464\n",
      "[EPOCH #21, step #2032] loss: 1.1931538131221784\n",
      "[EPOCH #21, step #2034] loss: 1.192722934469837\n",
      "[EPOCH #21, step #2036] loss: 1.1924760111067654\n",
      "[EPOCH #21, step #2038] loss: 1.1924557333895247\n",
      "[EPOCH #21, step #2040] loss: 1.1925262068487277\n",
      "[EPOCH #21, step #2042] loss: 1.1924361859649288\n",
      "[EPOCH #21, step #2044] loss: 1.1921271682368515\n",
      "[EPOCH #21, step #2046] loss: 1.1919651810984293\n",
      "[EPOCH #21, step #2048] loss: 1.1922955338753625\n",
      "[EPOCH #21, step #2050] loss: 1.192235176909673\n",
      "[EPOCH #21, step #2052] loss: 1.1922250181015561\n",
      "[EPOCH #21, step #2054] loss: 1.1922558593924029\n",
      "[EPOCH #21, step #2056] loss: 1.1922656333324801\n",
      "[EPOCH #21, step #2058] loss: 1.1921300284199021\n",
      "[EPOCH #21, step #2060] loss: 1.1923570325801467\n",
      "[EPOCH #21, step #2062] loss: 1.1921965035199542\n",
      "[EPOCH #21, step #2064] loss: 1.1923708987871036\n",
      "[EPOCH #21, step #2066] loss: 1.192342568205126\n",
      "[EPOCH #21, step #2068] loss: 1.192496910194316\n",
      "[EPOCH #21, step #2070] loss: 1.1926157665621078\n",
      "[EPOCH #21, step #2072] loss: 1.1924764197400612\n",
      "[EPOCH #21, step #2074] loss: 1.1924321696844447\n",
      "[EPOCH #21, step #2076] loss: 1.192066817141291\n",
      "[EPOCH #21, step #2078] loss: 1.1924691558629632\n",
      "[EPOCH #21, step #2080] loss: 1.1927045402705583\n",
      "[EPOCH #21, step #2082] loss: 1.19273254159432\n",
      "[EPOCH #21, step #2084] loss: 1.1925646910850378\n",
      "[EPOCH #21, step #2086] loss: 1.192597170823147\n",
      "[EPOCH #21, step #2088] loss: 1.1924765150246865\n",
      "[EPOCH #21, step #2090] loss: 1.1923345605019233\n",
      "[EPOCH #21, step #2092] loss: 1.1923531487235257\n",
      "[EPOCH #21, step #2094] loss: 1.1922641395384486\n",
      "[EPOCH #21, step #2096] loss: 1.1921697577579737\n",
      "[EPOCH #21, step #2098] loss: 1.192376433979505\n",
      "[EPOCH #21, step #2100] loss: 1.1925252008188458\n",
      "[EPOCH #21, step #2102] loss: 1.1927345360226707\n",
      "[EPOCH #21, step #2104] loss: 1.1928770833796956\n",
      "[EPOCH #21, step #2106] loss: 1.1928924994837575\n",
      "[EPOCH #21, step #2108] loss: 1.1926614716755037\n",
      "[EPOCH #21, step #2110] loss: 1.1923627929911123\n",
      "[EPOCH #21, step #2112] loss: 1.1924017600916146\n",
      "[EPOCH #21, step #2114] loss: 1.1920800269072782\n",
      "[EPOCH #21, step #2116] loss: 1.1919860230282786\n",
      "[EPOCH #21, step #2118] loss: 1.1919546793124878\n",
      "[EPOCH #21, step #2120] loss: 1.1920408516040337\n",
      "[EPOCH #21, step #2122] loss: 1.191950315666603\n",
      "[EPOCH #21, step #2124] loss: 1.191921290986678\n",
      "[EPOCH #21, step #2126] loss: 1.191823225235457\n",
      "[EPOCH #21, step #2128] loss: 1.191903725847385\n",
      "[EPOCH #21, step #2130] loss: 1.1918908472018643\n",
      "[EPOCH #21, step #2132] loss: 1.1916259872035917\n",
      "[EPOCH #21, step #2134] loss: 1.1916361054436104\n",
      "[EPOCH #21, step #2136] loss: 1.191717362203049\n",
      "[EPOCH #21, step #2138] loss: 1.1917194986298798\n",
      "[EPOCH #21, step #2140] loss: 1.1916168762222177\n",
      "[EPOCH #21, step #2142] loss: 1.1914289751956244\n",
      "[EPOCH #21, step #2144] loss: 1.191203508927272\n",
      "[EPOCH #21, step #2146] loss: 1.1913201680947416\n",
      "[EPOCH #21, step #2148] loss: 1.1911665572572054\n",
      "[EPOCH #21, step #2150] loss: 1.1912660874471395\n",
      "[EPOCH #21, step #2152] loss: 1.1911477016339567\n",
      "[EPOCH #21, step #2154] loss: 1.1912469854211032\n",
      "[EPOCH #21, step #2156] loss: 1.1910900061861143\n",
      "[EPOCH #21, step #2158] loss: 1.190963677202678\n",
      "[EPOCH #21, step #2160] loss: 1.1907625791100869\n",
      "[EPOCH #21, step #2162] loss: 1.1907444428196121\n",
      "[EPOCH #21, step #2164] loss: 1.1907034600854747\n",
      "[EPOCH #21, step #2166] loss: 1.1907871623274693\n",
      "[EPOCH #21, step #2168] loss: 1.1910028191083255\n",
      "[EPOCH #21, step #2170] loss: 1.1909826719393\n",
      "[EPOCH #21, step #2172] loss: 1.1908112479364383\n",
      "[EPOCH #21, step #2174] loss: 1.1908387174551514\n",
      "[EPOCH #21, step #2176] loss: 1.1907371953095545\n",
      "[EPOCH #21, step #2178] loss: 1.1906863642209382\n",
      "[EPOCH #21, step #2180] loss: 1.1907716130018782\n",
      "[EPOCH #21, step #2182] loss: 1.1906251647414496\n",
      "[EPOCH #21, step #2184] loss: 1.1907562412440913\n",
      "[EPOCH #21, step #2186] loss: 1.190975323898584\n",
      "[EPOCH #21, step #2188] loss: 1.1911013561495367\n",
      "[EPOCH #21, step #2190] loss: 1.1912256227895475\n",
      "[EPOCH #21, step #2192] loss: 1.1913715569439187\n",
      "[EPOCH #21, step #2194] loss: 1.1914681670877547\n",
      "[EPOCH #21, step #2196] loss: 1.1915840347843056\n",
      "[EPOCH #21, step #2198] loss: 1.1915533594133205\n",
      "[EPOCH #21, step #2200] loss: 1.1912445566536134\n",
      "[EPOCH #21, step #2202] loss: 1.1912040830037294\n",
      "[EPOCH #21, step #2204] loss: 1.1910302320034867\n",
      "[EPOCH #21, step #2206] loss: 1.1909878421380717\n",
      "[EPOCH #21, step #2208] loss: 1.1910136969934604\n",
      "[EPOCH #21, step #2210] loss: 1.1910805909787838\n",
      "[EPOCH #21, step #2212] loss: 1.1908373357858584\n",
      "[EPOCH #21, step #2214] loss: 1.1909100963891763\n",
      "[EPOCH #21, step #2216] loss: 1.1908279777809903\n",
      "[EPOCH #21, step #2218] loss: 1.1907589921224973\n",
      "[EPOCH #21, step #2220] loss: 1.1906854954725554\n",
      "[EPOCH #21, step #2222] loss: 1.190488324983668\n",
      "[EPOCH #21, step #2224] loss: 1.1902135658532047\n",
      "[EPOCH #21, step #2226] loss: 1.1904380652044833\n",
      "[EPOCH #21, step #2228] loss: 1.1906341928545805\n",
      "[EPOCH #21, step #2230] loss: 1.1906574136577128\n",
      "[EPOCH #21, step #2232] loss: 1.1905889844766284\n",
      "[EPOCH #21, step #2234] loss: 1.1907111135371846\n",
      "[EPOCH #21, step #2236] loss: 1.1906055630612278\n",
      "[EPOCH #21, step #2238] loss: 1.19059306239379\n",
      "[EPOCH #21, step #2240] loss: 1.190840205860053\n",
      "[EPOCH #21, step #2242] loss: 1.1907443335637735\n",
      "[EPOCH #21, step #2244] loss: 1.1908191865430378\n",
      "[EPOCH #21, step #2246] loss: 1.190804746743038\n",
      "[EPOCH #21, step #2248] loss: 1.1909629212267507\n",
      "[EPOCH #21, step #2250] loss: 1.1908630394554307\n",
      "[EPOCH #21, step #2252] loss: 1.1910985905860616\n",
      "[EPOCH #21, step #2254] loss: 1.1909607558715634\n",
      "[EPOCH #21, step #2256] loss: 1.1910241422106007\n",
      "[EPOCH #21, step #2258] loss: 1.190855751923092\n",
      "[EPOCH #21, step #2260] loss: 1.1910632836876691\n",
      "[EPOCH #21, step #2262] loss: 1.1908475801947893\n",
      "[EPOCH #21, step #2264] loss: 1.190813100074827\n",
      "[EPOCH #21, step #2266] loss: 1.1907409021230748\n",
      "[EPOCH #21, step #2268] loss: 1.1905932074446361\n",
      "[EPOCH #21, step #2270] loss: 1.1905737610862728\n",
      "[EPOCH #21, step #2272] loss: 1.190446106835813\n",
      "[EPOCH #21, step #2274] loss: 1.1903834154055668\n",
      "[EPOCH #21, step #2276] loss: 1.1904452667720076\n",
      "[EPOCH #21, step #2278] loss: 1.1903174766692848\n",
      "[EPOCH #21, step #2280] loss: 1.1902294748449262\n",
      "[EPOCH #21, step #2282] loss: 1.1901455793890365\n",
      "[EPOCH #21, step #2284] loss: 1.1898970894792669\n",
      "[EPOCH #21, step #2286] loss: 1.1899943481796842\n",
      "[EPOCH #21, step #2288] loss: 1.1897735752721914\n",
      "[EPOCH #21, step #2290] loss: 1.1899379088804745\n",
      "[EPOCH #21, step #2292] loss: 1.1898577876398775\n",
      "[EPOCH #21, step #2294] loss: 1.1896191395445848\n",
      "[EPOCH #21, step #2296] loss: 1.1894244413350943\n",
      "[EPOCH #21, step #2298] loss: 1.1891537578586082\n",
      "[EPOCH #21, step #2300] loss: 1.1891574377808454\n",
      "[EPOCH #21, step #2302] loss: 1.1890077429701855\n",
      "[EPOCH #21, step #2304] loss: 1.1894430390924797\n",
      "[EPOCH #21, step #2306] loss: 1.1893599259424479\n",
      "[EPOCH #21, step #2308] loss: 1.1892160795477367\n",
      "[EPOCH #21, step #2310] loss: 1.1890136579423176\n",
      "[EPOCH #21, step #2312] loss: 1.1891119873889637\n",
      "[EPOCH #21, step #2314] loss: 1.1891488239523145\n",
      "[EPOCH #21, step #2316] loss: 1.1892008861694863\n",
      "[EPOCH #21, step #2318] loss: 1.1890505080903693\n",
      "[EPOCH #21, step #2320] loss: 1.1890721854234965\n",
      "[EPOCH #21, step #2322] loss: 1.189193824832931\n",
      "[EPOCH #21, step #2324] loss: 1.189014523875329\n",
      "[EPOCH #21, step #2326] loss: 1.188845979101831\n",
      "[EPOCH #21, step #2328] loss: 1.1887902733899842\n",
      "[EPOCH #21, step #2330] loss: 1.1886932073310432\n",
      "[EPOCH #21, step #2332] loss: 1.188624202872978\n",
      "[EPOCH #21, step #2334] loss: 1.1886975755528157\n",
      "[EPOCH #21, step #2336] loss: 1.1887897744258347\n",
      "[EPOCH #21, step #2338] loss: 1.1887240480693704\n",
      "[EPOCH #21, step #2340] loss: 1.188861441938147\n",
      "[EPOCH #21, step #2342] loss: 1.1889102626345476\n",
      "[EPOCH #21, step #2344] loss: 1.1887200746963273\n",
      "[EPOCH #21, step #2346] loss: 1.1887902093533003\n",
      "[EPOCH #21, step #2348] loss: 1.1887836502480376\n",
      "[EPOCH #21, step #2350] loss: 1.1886550016932567\n",
      "[EPOCH #21, step #2352] loss: 1.1885763563301226\n",
      "[EPOCH #21, step #2354] loss: 1.1887250386479047\n",
      "[EPOCH #21, step #2356] loss: 1.1886307308620248\n",
      "[EPOCH #21, step #2358] loss: 1.1884048516692727\n",
      "[EPOCH #21, step #2360] loss: 1.1883945912438296\n",
      "[EPOCH #21, step #2362] loss: 1.1882919255223154\n",
      "[EPOCH #21, step #2364] loss: 1.188200099977328\n",
      "[EPOCH #21, step #2366] loss: 1.1880103175933219\n",
      "[EPOCH #21, step #2368] loss: 1.1880545732390282\n",
      "[EPOCH #21, step #2370] loss: 1.1882207494705148\n",
      "[EPOCH #21, step #2372] loss: 1.1878917202183932\n",
      "[EPOCH #21, step #2374] loss: 1.1877655283275403\n",
      "[EPOCH #21, step #2376] loss: 1.1879079458239101\n",
      "[EPOCH #21, step #2378] loss: 1.1876894888531115\n",
      "[EPOCH #21, step #2380] loss: 1.1875566659930974\n",
      "[EPOCH #21, step #2382] loss: 1.1874617810165287\n",
      "[EPOCH #21, step #2384] loss: 1.1875101578060685\n",
      "[EPOCH #21, step #2386] loss: 1.1873163864309937\n",
      "[EPOCH #21, step #2388] loss: 1.1874057412796213\n",
      "[EPOCH #21, step #2390] loss: 1.1874201511648697\n",
      "[EPOCH #21, step #2392] loss: 1.1872726072091415\n",
      "[EPOCH #21, step #2394] loss: 1.1874224121734842\n",
      "[EPOCH #21, step #2396] loss: 1.1873523429825648\n",
      "[EPOCH #21, step #2398] loss: 1.1872543964151443\n",
      "[EPOCH #21, step #2400] loss: 1.1871840979644825\n",
      "[EPOCH #21, step #2402] loss: 1.186948123545732\n",
      "[EPOCH #21, step #2404] loss: 1.186923196558645\n",
      "[EPOCH #21, step #2406] loss: 1.1868449449539185\n",
      "[EPOCH #21, step #2408] loss: 1.1867846379194975\n",
      "[EPOCH #21, step #2410] loss: 1.1867843271043477\n",
      "[EPOCH #21, step #2412] loss: 1.1867821444824826\n",
      "[EPOCH #21, step #2414] loss: 1.1866320785775195\n",
      "[EPOCH #21, step #2416] loss: 1.1865928211535706\n",
      "[EPOCH #21, step #2418] loss: 1.186911801653196\n",
      "[EPOCH #21, step #2420] loss: 1.1868435095184748\n",
      "[EPOCH #21, step #2422] loss: 1.1869687831357545\n",
      "[EPOCH #21, step #2424] loss: 1.1869008664986522\n",
      "[EPOCH #21, step #2426] loss: 1.1870014852685697\n",
      "[EPOCH #21, step #2428] loss: 1.1868663302857771\n",
      "[EPOCH #21, step #2430] loss: 1.186538202117275\n",
      "[EPOCH #21, step #2432] loss: 1.1863785179563868\n",
      "[EPOCH #21, step #2434] loss: 1.1865116222683165\n",
      "[EPOCH #21, step #2436] loss: 1.1866832354736954\n",
      "[EPOCH #21, step #2438] loss: 1.1867099868415467\n",
      "[EPOCH #21, step #2440] loss: 1.1868131730655138\n",
      "[EPOCH #21, step #2442] loss: 1.1869540035944224\n",
      "[EPOCH #21, step #2444] loss: 1.1870679912391615\n",
      "[EPOCH #21, step #2446] loss: 1.1869296868772081\n",
      "[EPOCH #21, step #2448] loss: 1.186864121026436\n",
      "[EPOCH #21, step #2450] loss: 1.186862772798013\n",
      "[EPOCH #21, step #2452] loss: 1.1866156746550962\n",
      "[EPOCH #21, step #2454] loss: 1.1862554031331283\n",
      "[EPOCH #21, step #2456] loss: 1.1862858301699526\n",
      "[EPOCH #21, step #2458] loss: 1.1861646054914785\n",
      "[EPOCH #21, step #2460] loss: 1.1862057229456306\n",
      "[EPOCH #21, step #2462] loss: 1.1861926276558936\n",
      "[EPOCH #21, step #2464] loss: 1.1862763344395233\n",
      "[EPOCH #21, step #2466] loss: 1.1862441665207175\n",
      "[EPOCH #21, step #2468] loss: 1.186480633012193\n",
      "[EPOCH #21, step #2470] loss: 1.1863433031454977\n",
      "[EPOCH #21, step #2472] loss: 1.1863712642629571\n",
      "[EPOCH #21, step #2474] loss: 1.186492533298454\n",
      "[EPOCH #21, step #2476] loss: 1.1864373566019568\n",
      "[EPOCH #21, step #2478] loss: 1.1866665505843568\n",
      "[EPOCH #21, step #2480] loss: 1.18641719958418\n",
      "[EPOCH #21, step #2482] loss: 1.1863260159221716\n",
      "[EPOCH #21, step #2484] loss: 1.1862497972050903\n",
      "[EPOCH #21, step #2486] loss: 1.1862102180875158\n",
      "[EPOCH #21, step #2488] loss: 1.186257741593989\n",
      "[EPOCH #21, step #2490] loss: 1.1862388684394511\n",
      "[EPOCH #21, step #2492] loss: 1.186307044833528\n",
      "[EPOCH #21, step #2494] loss: 1.1862485359809203\n",
      "[EPOCH #21, step #2496] loss: 1.1862913970952995\n",
      "[EPOCH #21, step #2498] loss: 1.186194166725948\n",
      "[EPOCH #21, elapsed time: 10651.264[sec]] loss: 1.1862935556650163\n",
      "[EPOCH #22, step #0] loss: 1.1617977619171143\n",
      "[EPOCH #22, step #2] loss: 1.0000982880592346\n",
      "[EPOCH #22, step #4] loss: 1.0961845993995667\n",
      "[EPOCH #22, step #6] loss: 1.160721276487623\n",
      "[EPOCH #22, step #8] loss: 1.1624654597706265\n",
      "[EPOCH #22, step #10] loss: 1.1581035581502048\n",
      "[EPOCH #22, step #12] loss: 1.1375404321230376\n",
      "[EPOCH #22, step #14] loss: 1.1265100161234538\n",
      "[EPOCH #22, step #16] loss: 1.1063182389034945\n",
      "[EPOCH #22, step #18] loss: 1.11312924247039\n",
      "[EPOCH #22, step #20] loss: 1.0911082029342651\n",
      "[EPOCH #22, step #22] loss: 1.0962707607642463\n",
      "[EPOCH #22, step #24] loss: 1.1097641396522522\n",
      "[EPOCH #22, step #26] loss: 1.127295717045113\n",
      "[EPOCH #22, step #28] loss: 1.1474776740731865\n",
      "[EPOCH #22, step #30] loss: 1.1494751572608948\n",
      "[EPOCH #22, step #32] loss: 1.150776055726138\n",
      "[EPOCH #22, step #34] loss: 1.164527714252472\n",
      "[EPOCH #22, step #36] loss: 1.169019098217423\n",
      "[EPOCH #22, step #38] loss: 1.1671403279671302\n",
      "[EPOCH #22, step #40] loss: 1.1570438510034142\n",
      "[EPOCH #22, step #42] loss: 1.1619837464288223\n",
      "[EPOCH #22, step #44] loss: 1.160115725464291\n",
      "[EPOCH #22, step #46] loss: 1.1506105179482318\n",
      "[EPOCH #22, step #48] loss: 1.1483758894764646\n",
      "[EPOCH #22, step #50] loss: 1.145236822904325\n",
      "[EPOCH #22, step #52] loss: 1.1502608566913965\n",
      "[EPOCH #22, step #54] loss: 1.1583139343695208\n",
      "[EPOCH #22, step #56] loss: 1.1597559755308586\n",
      "[EPOCH #22, step #58] loss: 1.1523864834995594\n",
      "[EPOCH #22, step #60] loss: 1.1504182796009252\n",
      "[EPOCH #22, step #62] loss: 1.1496741166190496\n",
      "[EPOCH #22, step #64] loss: 1.149337889597966\n",
      "[EPOCH #22, step #66] loss: 1.1502040428901785\n",
      "[EPOCH #22, step #68] loss: 1.1416309726411018\n",
      "[EPOCH #22, step #70] loss: 1.1341577793510866\n",
      "[EPOCH #22, step #72] loss: 1.1316664194407529\n",
      "[EPOCH #22, step #74] loss: 1.1345804754892985\n",
      "[EPOCH #22, step #76] loss: 1.1393073332774175\n",
      "[EPOCH #22, step #78] loss: 1.1428745849223076\n",
      "[EPOCH #22, step #80] loss: 1.1388313704066806\n",
      "[EPOCH #22, step #82] loss: 1.1372938579823597\n",
      "[EPOCH #22, step #84] loss: 1.142755980351392\n",
      "[EPOCH #22, step #86] loss: 1.1373889350343025\n",
      "[EPOCH #22, step #88] loss: 1.1344976472050956\n",
      "[EPOCH #22, step #90] loss: 1.1358016028509035\n",
      "[EPOCH #22, step #92] loss: 1.1368224402909637\n",
      "[EPOCH #22, step #94] loss: 1.1364962929173519\n",
      "[EPOCH #22, step #96] loss: 1.138892524021188\n",
      "[EPOCH #22, step #98] loss: 1.139976148051445\n",
      "[EPOCH #22, step #100] loss: 1.1370585985703043\n",
      "[EPOCH #22, step #102] loss: 1.1312627479868027\n",
      "[EPOCH #22, step #104] loss: 1.1300714504151117\n",
      "[EPOCH #22, step #106] loss: 1.1259757971095148\n",
      "[EPOCH #22, step #108] loss: 1.12649724899082\n",
      "[EPOCH #22, step #110] loss: 1.1271951649640057\n",
      "[EPOCH #22, step #112] loss: 1.1223638635293571\n",
      "[EPOCH #22, step #114] loss: 1.1212924394918524\n",
      "[EPOCH #22, step #116] loss: 1.1208565309006944\n",
      "[EPOCH #22, step #118] loss: 1.1225789337098098\n",
      "[EPOCH #22, step #120] loss: 1.117872615244763\n",
      "[EPOCH #22, step #122] loss: 1.1212059964494008\n",
      "[EPOCH #22, step #124] loss: 1.124042484998703\n",
      "[EPOCH #22, step #126] loss: 1.1242747867670584\n",
      "[EPOCH #22, step #128] loss: 1.1220293065836264\n",
      "[EPOCH #22, step #130] loss: 1.125409702535804\n",
      "[EPOCH #22, step #132] loss: 1.124660506508404\n",
      "[EPOCH #22, step #134] loss: 1.1257629423229782\n",
      "[EPOCH #22, step #136] loss: 1.124409192017395\n",
      "[EPOCH #22, step #138] loss: 1.1265083356298131\n",
      "[EPOCH #22, step #140] loss: 1.1296537778478988\n",
      "[EPOCH #22, step #142] loss: 1.127900555625662\n",
      "[EPOCH #22, step #144] loss: 1.1295628911462323\n",
      "[EPOCH #22, step #146] loss: 1.1329351057406185\n",
      "[EPOCH #22, step #148] loss: 1.1325115331467366\n",
      "[EPOCH #22, step #150] loss: 1.1346473060301598\n",
      "[EPOCH #22, step #152] loss: 1.131016963642407\n",
      "[EPOCH #22, step #154] loss: 1.1283182788279749\n",
      "[EPOCH #22, step #156] loss: 1.1278014758210273\n",
      "[EPOCH #22, step #158] loss: 1.1251207078402896\n",
      "[EPOCH #22, step #160] loss: 1.1235049498377379\n",
      "[EPOCH #22, step #162] loss: 1.1243148612464133\n",
      "[EPOCH #22, step #164] loss: 1.1240694459640619\n",
      "[EPOCH #22, step #166] loss: 1.1233454223521455\n",
      "[EPOCH #22, step #168] loss: 1.1253072434275813\n",
      "[EPOCH #22, step #170] loss: 1.124291196378351\n",
      "[EPOCH #22, step #172] loss: 1.1277230290663725\n",
      "[EPOCH #22, step #174] loss: 1.1257279782635825\n",
      "[EPOCH #22, step #176] loss: 1.1253608948430098\n",
      "[EPOCH #22, step #178] loss: 1.1260612115846667\n",
      "[EPOCH #22, step #180] loss: 1.1280999722072433\n",
      "[EPOCH #22, step #182] loss: 1.129531868005711\n",
      "[EPOCH #22, step #184] loss: 1.128969241316254\n",
      "[EPOCH #22, step #186] loss: 1.1311816071125276\n",
      "[EPOCH #22, step #188] loss: 1.1339969349601282\n",
      "[EPOCH #22, step #190] loss: 1.1322403748310048\n",
      "[EPOCH #22, step #192] loss: 1.1327305922545299\n",
      "[EPOCH #22, step #194] loss: 1.1320254101203038\n",
      "[EPOCH #22, step #196] loss: 1.131394460267827\n",
      "[EPOCH #22, step #198] loss: 1.1313156759619114\n",
      "[EPOCH #22, step #200] loss: 1.1332451729335595\n",
      "[EPOCH #22, step #202] loss: 1.1342101104447406\n",
      "[EPOCH #22, step #204] loss: 1.1329923529450487\n",
      "[EPOCH #22, step #206] loss: 1.1325785697658282\n",
      "[EPOCH #22, step #208] loss: 1.1295397970379826\n",
      "[EPOCH #22, step #210] loss: 1.1291377839601435\n",
      "[EPOCH #22, step #212] loss: 1.1284984732177896\n",
      "[EPOCH #22, step #214] loss: 1.1253681985444801\n",
      "[EPOCH #22, step #216] loss: 1.1264784505015695\n",
      "[EPOCH #22, step #218] loss: 1.1250586698860883\n",
      "[EPOCH #22, step #220] loss: 1.123160496151825\n",
      "[EPOCH #22, step #222] loss: 1.124138144500587\n",
      "[EPOCH #22, step #224] loss: 1.1221212001641592\n",
      "[EPOCH #22, step #226] loss: 1.121802533906987\n",
      "[EPOCH #22, step #228] loss: 1.1239673712628377\n",
      "[EPOCH #22, step #230] loss: 1.1242642429741947\n",
      "[EPOCH #22, step #232] loss: 1.1229309425589353\n",
      "[EPOCH #22, step #234] loss: 1.1217310267560026\n",
      "[EPOCH #22, step #236] loss: 1.12096282915224\n",
      "[EPOCH #22, step #238] loss: 1.120584481056764\n",
      "[EPOCH #22, step #240] loss: 1.119525647138659\n",
      "[EPOCH #22, step #242] loss: 1.1211168301203613\n",
      "[EPOCH #22, step #244] loss: 1.1197173144136157\n",
      "[EPOCH #22, step #246] loss: 1.11805615359955\n",
      "[EPOCH #22, step #248] loss: 1.1169401068524663\n",
      "[EPOCH #22, step #250] loss: 1.1157070276034307\n",
      "[EPOCH #22, step #252] loss: 1.1135485543328312\n",
      "[EPOCH #22, step #254] loss: 1.1139772839405957\n",
      "[EPOCH #22, step #256] loss: 1.115867285760924\n",
      "[EPOCH #22, step #258] loss: 1.1155448992049832\n",
      "[EPOCH #22, step #260] loss: 1.1147281046799773\n",
      "[EPOCH #22, step #262] loss: 1.1144620505349265\n",
      "[EPOCH #22, step #264] loss: 1.1154738883927184\n",
      "[EPOCH #22, step #266] loss: 1.1160440667068467\n",
      "[EPOCH #22, step #268] loss: 1.115877683610278\n",
      "[EPOCH #22, step #270] loss: 1.1151622664664504\n",
      "[EPOCH #22, step #272] loss: 1.114834882728346\n",
      "[EPOCH #22, step #274] loss: 1.1169183084097776\n",
      "[EPOCH #22, step #276] loss: 1.1172547670693174\n",
      "[EPOCH #22, step #278] loss: 1.1172698474485814\n",
      "[EPOCH #22, step #280] loss: 1.116161520264751\n",
      "[EPOCH #22, step #282] loss: 1.116567316303826\n",
      "[EPOCH #22, step #284] loss: 1.1156122085295226\n",
      "[EPOCH #22, step #286] loss: 1.1152057148230616\n",
      "[EPOCH #22, step #288] loss: 1.1153002343169545\n",
      "[EPOCH #22, step #290] loss: 1.1154346327806257\n",
      "[EPOCH #22, step #292] loss: 1.1159971782575289\n",
      "[EPOCH #22, step #294] loss: 1.1165229218491053\n",
      "[EPOCH #22, step #296] loss: 1.118300714376398\n",
      "[EPOCH #22, step #298] loss: 1.1182443731803957\n",
      "[EPOCH #22, step #300] loss: 1.1175380668964894\n",
      "[EPOCH #22, step #302] loss: 1.1179575303403457\n",
      "[EPOCH #22, step #304] loss: 1.1198948814243568\n",
      "[EPOCH #22, step #306] loss: 1.1190559789295693\n",
      "[EPOCH #22, step #308] loss: 1.1196006566382535\n",
      "[EPOCH #22, step #310] loss: 1.120711516241552\n",
      "[EPOCH #22, step #312] loss: 1.1215997613466586\n",
      "[EPOCH #22, step #314] loss: 1.1199939564106955\n",
      "[EPOCH #22, step #316] loss: 1.1209287247635213\n",
      "[EPOCH #22, step #318] loss: 1.1215935806308794\n",
      "[EPOCH #22, step #320] loss: 1.1223184192477729\n",
      "[EPOCH #22, step #322] loss: 1.1224763469983918\n",
      "[EPOCH #22, step #324] loss: 1.1220934254389543\n",
      "[EPOCH #22, step #326] loss: 1.121823083278965\n",
      "[EPOCH #22, step #328] loss: 1.121149632072014\n",
      "[EPOCH #22, step #330] loss: 1.1202959087860187\n",
      "[EPOCH #22, step #332] loss: 1.119402972159085\n",
      "[EPOCH #22, step #334] loss: 1.1186660061131661\n",
      "[EPOCH #22, step #336] loss: 1.1188011738065442\n",
      "[EPOCH #22, step #338] loss: 1.1180426081900752\n",
      "[EPOCH #22, step #340] loss: 1.1179324618357718\n",
      "[EPOCH #22, step #342] loss: 1.118773812368382\n",
      "[EPOCH #22, step #344] loss: 1.1191914764867312\n",
      "[EPOCH #22, step #346] loss: 1.1192453775866231\n",
      "[EPOCH #22, step #348] loss: 1.1186003887380092\n",
      "[EPOCH #22, step #350] loss: 1.1183413116850405\n",
      "[EPOCH #22, step #352] loss: 1.1171271757937693\n",
      "[EPOCH #22, step #354] loss: 1.118402726633448\n",
      "[EPOCH #22, step #356] loss: 1.1171842026276415\n",
      "[EPOCH #22, step #358] loss: 1.1181776849838352\n",
      "[EPOCH #22, step #360] loss: 1.1168500765373832\n",
      "[EPOCH #22, step #362] loss: 1.1177594762695722\n",
      "[EPOCH #22, step #364] loss: 1.1178774347860518\n",
      "[EPOCH #22, step #366] loss: 1.1164764062747643\n",
      "[EPOCH #22, step #368] loss: 1.1163644203487126\n",
      "[EPOCH #22, step #370] loss: 1.1163043202254972\n",
      "[EPOCH #22, step #372] loss: 1.1163998549010095\n",
      "[EPOCH #22, step #374] loss: 1.115281964858373\n",
      "[EPOCH #22, step #376] loss: 1.1159780592279662\n",
      "[EPOCH #22, step #378] loss: 1.116781905568684\n",
      "[EPOCH #22, step #380] loss: 1.116865426771284\n",
      "[EPOCH #22, step #382] loss: 1.116584071991649\n",
      "[EPOCH #22, step #384] loss: 1.116879532940976\n",
      "[EPOCH #22, step #386] loss: 1.116475338082597\n",
      "[EPOCH #22, step #388] loss: 1.1159201309582873\n",
      "[EPOCH #22, step #390] loss: 1.1155799036593084\n",
      "[EPOCH #22, step #392] loss: 1.1159498954698936\n",
      "[EPOCH #22, step #394] loss: 1.1150304577773131\n",
      "[EPOCH #22, step #396] loss: 1.1140562060948282\n",
      "[EPOCH #22, step #398] loss: 1.1148734489329775\n",
      "[EPOCH #22, step #400] loss: 1.1165491193161343\n",
      "[EPOCH #22, step #402] loss: 1.116725945517088\n",
      "[EPOCH #22, step #404] loss: 1.116019441831259\n",
      "[EPOCH #22, step #406] loss: 1.1161229157184207\n",
      "[EPOCH #22, step #408] loss: 1.116811953794694\n",
      "[EPOCH #22, step #410] loss: 1.1163393742701724\n",
      "[EPOCH #22, step #412] loss: 1.1159115217932778\n",
      "[EPOCH #22, step #414] loss: 1.1167485181825707\n",
      "[EPOCH #22, step #416] loss: 1.1156825629784335\n",
      "[EPOCH #22, step #418] loss: 1.1151396923105017\n",
      "[EPOCH #22, step #420] loss: 1.1152816441025133\n",
      "[EPOCH #22, step #422] loss: 1.1151565202725413\n",
      "[EPOCH #22, step #424] loss: 1.114015655447455\n",
      "[EPOCH #22, step #426] loss: 1.1140676462538628\n",
      "[EPOCH #22, step #428] loss: 1.113156799183581\n",
      "[EPOCH #22, step #430] loss: 1.1138264397872297\n",
      "[EPOCH #22, step #432] loss: 1.114017146082453\n",
      "[EPOCH #22, step #434] loss: 1.112769940872302\n",
      "[EPOCH #22, step #436] loss: 1.113408081932526\n",
      "[EPOCH #22, step #438] loss: 1.1136708233106651\n",
      "[EPOCH #22, step #440] loss: 1.1142396981618843\n",
      "[EPOCH #22, step #442] loss: 1.114485514150516\n",
      "[EPOCH #22, step #444] loss: 1.1134521486384146\n",
      "[EPOCH #22, step #446] loss: 1.1144151777629083\n",
      "[EPOCH #22, step #448] loss: 1.1139396516012987\n",
      "[EPOCH #22, step #450] loss: 1.1135929769396518\n",
      "[EPOCH #22, step #452] loss: 1.115018221650429\n",
      "[EPOCH #22, step #454] loss: 1.1150327294082432\n",
      "[EPOCH #22, step #456] loss: 1.115669632049306\n",
      "[EPOCH #22, step #458] loss: 1.1159820526124087\n",
      "[EPOCH #22, step #460] loss: 1.1178589408283897\n",
      "[EPOCH #22, step #462] loss: 1.1179958704867063\n",
      "[EPOCH #22, step #464] loss: 1.1176003500338523\n",
      "[EPOCH #22, step #466] loss: 1.1167723229533855\n",
      "[EPOCH #22, step #468] loss: 1.11654230939554\n",
      "[EPOCH #22, step #470] loss: 1.1172315252434677\n",
      "[EPOCH #22, step #472] loss: 1.117170120205486\n",
      "[EPOCH #22, step #474] loss: 1.118031065401278\n",
      "[EPOCH #22, step #476] loss: 1.1175993196744338\n",
      "[EPOCH #22, step #478] loss: 1.1186815319205625\n",
      "[EPOCH #22, step #480] loss: 1.1198218595585059\n",
      "[EPOCH #22, step #482] loss: 1.120301875330153\n",
      "[EPOCH #22, step #484] loss: 1.1199654589608772\n",
      "[EPOCH #22, step #486] loss: 1.1220001271740367\n",
      "[EPOCH #22, step #488] loss: 1.1225672736611592\n",
      "[EPOCH #22, step #490] loss: 1.12299020111925\n",
      "[EPOCH #22, step #492] loss: 1.1227947211773353\n",
      "[EPOCH #22, step #494] loss: 1.121500264574783\n",
      "[EPOCH #22, step #496] loss: 1.121083376693054\n",
      "[EPOCH #22, step #498] loss: 1.121114844012117\n",
      "[EPOCH #22, step #500] loss: 1.1217393082178044\n",
      "[EPOCH #22, step #502] loss: 1.1213137947659844\n",
      "[EPOCH #22, step #504] loss: 1.1203051592453872\n",
      "[EPOCH #22, step #506] loss: 1.1194957917376147\n",
      "[EPOCH #22, step #508] loss: 1.1193014299588493\n",
      "[EPOCH #22, step #510] loss: 1.1191840151401415\n",
      "[EPOCH #22, step #512] loss: 1.1185620998197596\n",
      "[EPOCH #22, step #514] loss: 1.1183709512057813\n",
      "[EPOCH #22, step #516] loss: 1.1180196194053849\n",
      "[EPOCH #22, step #518] loss: 1.1183298525897525\n",
      "[EPOCH #22, step #520] loss: 1.1182608945928014\n",
      "[EPOCH #22, step #522] loss: 1.1181969114402968\n",
      "[EPOCH #22, step #524] loss: 1.1174734006041571\n",
      "[EPOCH #22, step #526] loss: 1.1177559027296315\n",
      "[EPOCH #22, step #528] loss: 1.1174112569068917\n",
      "[EPOCH #22, step #530] loss: 1.1171725933946908\n",
      "[EPOCH #22, step #532] loss: 1.1165317806361093\n",
      "[EPOCH #22, step #534] loss: 1.1159383990497234\n",
      "[EPOCH #22, step #536] loss: 1.1156286840887264\n",
      "[EPOCH #22, step #538] loss: 1.116113462618419\n",
      "[EPOCH #22, step #540] loss: 1.1163223259660542\n",
      "[EPOCH #22, step #542] loss: 1.1168099374512064\n",
      "[EPOCH #22, step #544] loss: 1.1166271256197484\n",
      "[EPOCH #22, step #546] loss: 1.1165372292890845\n",
      "[EPOCH #22, step #548] loss: 1.1170758567546886\n",
      "[EPOCH #22, step #550] loss: 1.1178886657293392\n",
      "[EPOCH #22, step #552] loss: 1.1180407758970587\n",
      "[EPOCH #22, step #554] loss: 1.117108298046095\n",
      "[EPOCH #22, step #556] loss: 1.1171320268559928\n",
      "[EPOCH #22, step #558] loss: 1.116688574309426\n",
      "[EPOCH #22, step #560] loss: 1.1167734975589576\n",
      "[EPOCH #22, step #562] loss: 1.118494916078676\n",
      "[EPOCH #22, step #564] loss: 1.1184178723170695\n",
      "[EPOCH #22, step #566] loss: 1.1178082946221455\n",
      "[EPOCH #22, step #568] loss: 1.1168247679729664\n",
      "[EPOCH #22, step #570] loss: 1.1170358113461742\n",
      "[EPOCH #22, step #572] loss: 1.1167786566062747\n",
      "[EPOCH #22, step #574] loss: 1.1178660506269207\n",
      "[EPOCH #22, step #576] loss: 1.1181851674510452\n",
      "[EPOCH #22, step #578] loss: 1.1195848498216772\n",
      "[EPOCH #22, step #580] loss: 1.1197221424308783\n",
      "[EPOCH #22, step #582] loss: 1.1198098967762387\n",
      "[EPOCH #22, step #584] loss: 1.1196697373166045\n",
      "[EPOCH #22, step #586] loss: 1.1204976324226827\n",
      "[EPOCH #22, step #588] loss: 1.1209689408591323\n",
      "[EPOCH #22, step #590] loss: 1.1205993919505686\n",
      "[EPOCH #22, step #592] loss: 1.1193938197514661\n",
      "[EPOCH #22, step #594] loss: 1.1187239644407225\n",
      "[EPOCH #22, step #596] loss: 1.1182096172716949\n",
      "[EPOCH #22, step #598] loss: 1.1174477869660309\n",
      "[EPOCH #22, step #600] loss: 1.1165870982973825\n",
      "[EPOCH #22, step #602] loss: 1.116193856420011\n",
      "[EPOCH #22, step #604] loss: 1.1162756110518433\n",
      "[EPOCH #22, step #606] loss: 1.1151950314665549\n",
      "[EPOCH #22, step #608] loss: 1.114281195088952\n",
      "[EPOCH #22, step #610] loss: 1.113891798569996\n",
      "[EPOCH #22, step #612] loss: 1.1135516323720456\n",
      "[EPOCH #22, step #614] loss: 1.1132139690038634\n",
      "[EPOCH #22, step #616] loss: 1.1130356637450052\n",
      "[EPOCH #22, step #618] loss: 1.1126603382565863\n",
      "[EPOCH #22, step #620] loss: 1.1123823438577607\n",
      "[EPOCH #22, step #622] loss: 1.1129894672293532\n",
      "[EPOCH #22, step #624] loss: 1.1134504618167878\n",
      "[EPOCH #22, step #626] loss: 1.1137998522848984\n",
      "[EPOCH #22, step #628] loss: 1.1140409596678942\n",
      "[EPOCH #22, step #630] loss: 1.1141451735598538\n",
      "[EPOCH #22, step #632] loss: 1.113823497135304\n",
      "[EPOCH #22, step #634] loss: 1.1134970421396841\n",
      "[EPOCH #22, step #636] loss: 1.113489633873456\n",
      "[EPOCH #22, step #638] loss: 1.1129695134636755\n",
      "[EPOCH #22, step #640] loss: 1.113005461679792\n",
      "[EPOCH #22, step #642] loss: 1.1124932346503433\n",
      "[EPOCH #22, step #644] loss: 1.1127418658068013\n",
      "[EPOCH #22, step #646] loss: 1.112080223455311\n",
      "[EPOCH #22, step #648] loss: 1.1113157778840588\n",
      "[EPOCH #22, step #650] loss: 1.1119636269300581\n",
      "[EPOCH #22, step #652] loss: 1.1126627804765656\n",
      "[EPOCH #22, step #654] loss: 1.113229358969754\n",
      "[EPOCH #22, step #656] loss: 1.113365555054521\n",
      "[EPOCH #22, step #658] loss: 1.1133223407999338\n",
      "[EPOCH #22, step #660] loss: 1.1138826077987134\n",
      "[EPOCH #22, step #662] loss: 1.1142921113770112\n",
      "[EPOCH #22, step #664] loss: 1.1148828609097272\n",
      "[EPOCH #22, step #666] loss: 1.1141260528582326\n",
      "[EPOCH #22, step #668] loss: 1.1141169407531641\n",
      "[EPOCH #22, step #670] loss: 1.1144080801177132\n",
      "[EPOCH #22, step #672] loss: 1.1143225299922355\n",
      "[EPOCH #22, step #674] loss: 1.1143656099725652\n",
      "[EPOCH #22, step #676] loss: 1.1140639012021891\n",
      "[EPOCH #22, step #678] loss: 1.1132810519177012\n",
      "[EPOCH #22, step #680] loss: 1.1122350575902913\n",
      "[EPOCH #22, step #682] loss: 1.1127946869433363\n",
      "[EPOCH #22, step #684] loss: 1.1132651512205165\n",
      "[EPOCH #22, step #686] loss: 1.1141550515329648\n",
      "[EPOCH #22, step #688] loss: 1.1138621544024767\n",
      "[EPOCH #22, step #690] loss: 1.114162872091216\n",
      "[EPOCH #22, step #692] loss: 1.1146802353910554\n",
      "[EPOCH #22, step #694] loss: 1.1145994881503016\n",
      "[EPOCH #22, step #696] loss: 1.1150373473998634\n",
      "[EPOCH #22, step #698] loss: 1.1152887863236265\n",
      "[EPOCH #22, step #700] loss: 1.1162528082324503\n",
      "[EPOCH #22, step #702] loss: 1.1166635596141707\n",
      "[EPOCH #22, step #704] loss: 1.1164766354341034\n",
      "[EPOCH #22, step #706] loss: 1.115932764519728\n",
      "[EPOCH #22, step #708] loss: 1.1159637833095573\n",
      "[EPOCH #22, step #710] loss: 1.1155041257959546\n",
      "[EPOCH #22, step #712] loss: 1.115386604719376\n",
      "[EPOCH #22, step #714] loss: 1.114381691417494\n",
      "[EPOCH #22, step #716] loss: 1.1135923906100844\n",
      "[EPOCH #22, step #718] loss: 1.114450664488762\n",
      "[EPOCH #22, step #720] loss: 1.1141804767961145\n",
      "[EPOCH #22, step #722] loss: 1.1146469982250762\n",
      "[EPOCH #22, step #724] loss: 1.1151928130922646\n",
      "[EPOCH #22, step #726] loss: 1.1155687620174115\n",
      "[EPOCH #22, step #728] loss: 1.115388631616273\n",
      "[EPOCH #22, step #730] loss: 1.1149827248828357\n",
      "[EPOCH #22, step #732] loss: 1.1142553292306352\n",
      "[EPOCH #22, step #734] loss: 1.1143366574835616\n",
      "[EPOCH #22, step #736] loss: 1.1144379373725752\n",
      "[EPOCH #22, step #738] loss: 1.1139565768761306\n",
      "[EPOCH #22, step #740] loss: 1.1133085644116447\n",
      "[EPOCH #22, step #742] loss: 1.1134258383937672\n",
      "[EPOCH #22, step #744] loss: 1.1139567085960567\n",
      "[EPOCH #22, step #746] loss: 1.1136124025147602\n",
      "[EPOCH #22, step #748] loss: 1.1138256665304282\n",
      "[EPOCH #22, step #750] loss: 1.1140827881432722\n",
      "[EPOCH #22, step #752] loss: 1.114533015575067\n",
      "[EPOCH #22, step #754] loss: 1.114413969840435\n",
      "[EPOCH #22, step #756] loss: 1.1148362770341977\n",
      "[EPOCH #22, step #758] loss: 1.11508195567508\n",
      "[EPOCH #22, step #760] loss: 1.1153791859726399\n",
      "[EPOCH #22, step #762] loss: 1.1153773078365377\n",
      "[EPOCH #22, step #764] loss: 1.1154078041416369\n",
      "[EPOCH #22, step #766] loss: 1.1155598964420725\n",
      "[EPOCH #22, step #768] loss: 1.1159394507832894\n",
      "[EPOCH #22, step #770] loss: 1.1164492697644637\n",
      "[EPOCH #22, step #772] loss: 1.1166617891535568\n",
      "[EPOCH #22, step #774] loss: 1.11633770892697\n",
      "[EPOCH #22, step #776] loss: 1.1158448185776497\n",
      "[EPOCH #22, step #778] loss: 1.1158613221712688\n",
      "[EPOCH #22, step #780] loss: 1.1157552591893494\n",
      "[EPOCH #22, step #782] loss: 1.1149759435333968\n",
      "[EPOCH #22, step #784] loss: 1.1154260030597638\n",
      "[EPOCH #22, step #786] loss: 1.1159078112627074\n",
      "[EPOCH #22, step #788] loss: 1.1159892031977234\n",
      "[EPOCH #22, step #790] loss: 1.1154916631964455\n",
      "[EPOCH #22, step #792] loss: 1.1147539779863322\n",
      "[EPOCH #22, step #794] loss: 1.114948473973844\n",
      "[EPOCH #22, step #796] loss: 1.1152707732830622\n",
      "[EPOCH #22, step #798] loss: 1.1153230657789377\n",
      "[EPOCH #22, step #800] loss: 1.1158859012055486\n",
      "[EPOCH #22, step #802] loss: 1.116246896804047\n",
      "[EPOCH #22, step #804] loss: 1.1157798192145663\n",
      "[EPOCH #22, step #806] loss: 1.116131246126865\n",
      "[EPOCH #22, step #808] loss: 1.1155952291450335\n",
      "[EPOCH #22, step #810] loss: 1.1158955703901745\n",
      "[EPOCH #22, step #812] loss: 1.1157466135415057\n",
      "[EPOCH #22, step #814] loss: 1.1151755043699698\n",
      "[EPOCH #22, step #816] loss: 1.11481807343525\n",
      "[EPOCH #22, step #818] loss: 1.1155839722162346\n",
      "[EPOCH #22, step #820] loss: 1.1149166319678094\n",
      "[EPOCH #22, step #822] loss: 1.1147066278344662\n",
      "[EPOCH #22, step #824] loss: 1.1138137422547196\n",
      "[EPOCH #22, step #826] loss: 1.11450321682275\n",
      "[EPOCH #22, step #828] loss: 1.1142110377729875\n",
      "[EPOCH #22, step #830] loss: 1.114490048011718\n",
      "[EPOCH #22, step #832] loss: 1.1145588139883753\n",
      "[EPOCH #22, step #834] loss: 1.1150216409903086\n",
      "[EPOCH #22, step #836] loss: 1.1145074151394045\n",
      "[EPOCH #22, step #838] loss: 1.1148673607496027\n",
      "[EPOCH #22, step #840] loss: 1.1151280645879071\n",
      "[EPOCH #22, step #842] loss: 1.1148748647063653\n",
      "[EPOCH #22, step #844] loss: 1.1147371503375691\n",
      "[EPOCH #22, step #846] loss: 1.1146332075843564\n",
      "[EPOCH #22, step #848] loss: 1.1152621952397803\n",
      "[EPOCH #22, step #850] loss: 1.1151372291296546\n",
      "[EPOCH #22, step #852] loss: 1.11499888386145\n",
      "[EPOCH #22, step #854] loss: 1.115105647545809\n",
      "[EPOCH #22, step #856] loss: 1.1148613921193842\n",
      "[EPOCH #22, step #858] loss: 1.1146070717446879\n",
      "[EPOCH #22, step #860] loss: 1.1144996067026627\n",
      "[EPOCH #22, step #862] loss: 1.1139706289989233\n",
      "[EPOCH #22, step #864] loss: 1.1147248163044108\n",
      "[EPOCH #22, step #866] loss: 1.1150227795766436\n",
      "[EPOCH #22, step #868] loss: 1.1148285695337727\n",
      "[EPOCH #22, step #870] loss: 1.1145388571252506\n",
      "[EPOCH #22, step #872] loss: 1.1142925543951687\n",
      "[EPOCH #22, step #874] loss: 1.1138500916957854\n",
      "[EPOCH #22, step #876] loss: 1.1143696895686903\n",
      "[EPOCH #22, step #878] loss: 1.1146381719459582\n",
      "[EPOCH #22, step #880] loss: 1.1146419148777995\n",
      "[EPOCH #22, step #882] loss: 1.1141309928853542\n",
      "[EPOCH #22, step #884] loss: 1.1143737010026382\n",
      "[EPOCH #22, step #886] loss: 1.113901719266156\n",
      "[EPOCH #22, step #888] loss: 1.1133889168735565\n",
      "[EPOCH #22, step #890] loss: 1.1132266685015424\n",
      "[EPOCH #22, step #892] loss: 1.1129656597921855\n",
      "[EPOCH #22, step #894] loss: 1.1134013491968868\n",
      "[EPOCH #22, step #896] loss: 1.1143841633496343\n",
      "[EPOCH #22, step #898] loss: 1.114468338392733\n",
      "[EPOCH #22, step #900] loss: 1.113701133927812\n",
      "[EPOCH #22, step #902] loss: 1.1134803102063975\n",
      "[EPOCH #22, step #904] loss: 1.1131059736507374\n",
      "[EPOCH #22, step #906] loss: 1.1135583677326042\n",
      "[EPOCH #22, step #908] loss: 1.1135060718678536\n",
      "[EPOCH #22, step #910] loss: 1.1130135798362686\n",
      "[EPOCH #22, step #912] loss: 1.113137357761147\n",
      "[EPOCH #22, step #914] loss: 1.113368399840235\n",
      "[EPOCH #22, step #916] loss: 1.1138930720162366\n",
      "[EPOCH #22, step #918] loss: 1.1144915157939197\n",
      "[EPOCH #22, step #920] loss: 1.1145591288319627\n",
      "[EPOCH #22, step #922] loss: 1.1141657459580885\n",
      "[EPOCH #22, step #924] loss: 1.1148415188853804\n",
      "[EPOCH #22, step #926] loss: 1.1149316893362047\n",
      "[EPOCH #22, step #928] loss: 1.1146600644542275\n",
      "[EPOCH #22, step #930] loss: 1.1147123679246604\n",
      "[EPOCH #22, step #932] loss: 1.1144852289113456\n",
      "[EPOCH #22, step #934] loss: 1.1140412392782018\n",
      "[EPOCH #22, step #936] loss: 1.113680495428301\n",
      "[EPOCH #22, step #938] loss: 1.1136099262930714\n",
      "[EPOCH #22, step #940] loss: 1.1135181625958583\n",
      "[EPOCH #22, step #942] loss: 1.113307773719284\n",
      "[EPOCH #22, step #944] loss: 1.1138647832252362\n",
      "[EPOCH #22, step #946] loss: 1.1141543101043359\n",
      "[EPOCH #22, step #948] loss: 1.114347845001894\n",
      "[EPOCH #22, step #950] loss: 1.114452822696022\n",
      "[EPOCH #22, step #952] loss: 1.114662118217002\n",
      "[EPOCH #22, step #954] loss: 1.1145779066372916\n",
      "[EPOCH #22, step #956] loss: 1.1145264937648454\n",
      "[EPOCH #22, step #958] loss: 1.1143383714715185\n",
      "[EPOCH #22, step #960] loss: 1.1142722759919161\n",
      "[EPOCH #22, step #962] loss: 1.114111479600023\n",
      "[EPOCH #22, step #964] loss: 1.114659901140885\n",
      "[EPOCH #22, step #966] loss: 1.1148534831056427\n",
      "[EPOCH #22, step #968] loss: 1.1152585586465673\n",
      "[EPOCH #22, step #970] loss: 1.1160099358133873\n",
      "[EPOCH #22, step #972] loss: 1.11662682223173\n",
      "[EPOCH #22, step #974] loss: 1.1158067541550367\n",
      "[EPOCH #22, step #976] loss: 1.1163653831704001\n",
      "[EPOCH #22, step #978] loss: 1.116215679356952\n",
      "[EPOCH #22, step #980] loss: 1.1161155710708839\n",
      "[EPOCH #22, step #982] loss: 1.1163979759354556\n",
      "[EPOCH #22, step #984] loss: 1.116118864631895\n",
      "[EPOCH #22, step #986] loss: 1.1161084101736365\n",
      "[EPOCH #22, step #988] loss: 1.1172279158364171\n",
      "[EPOCH #22, step #990] loss: 1.1175394123485904\n",
      "[EPOCH #22, step #992] loss: 1.1174270641227504\n",
      "[EPOCH #22, step #994] loss: 1.1172223915107287\n",
      "[EPOCH #22, step #996] loss: 1.1177401024635243\n",
      "[EPOCH #22, step #998] loss: 1.1174753163610254\n",
      "[EPOCH #22, step #1000] loss: 1.1174443257855369\n",
      "[EPOCH #22, step #1002] loss: 1.1177586121252503\n",
      "[EPOCH #22, step #1004] loss: 1.1177770441147818\n",
      "[EPOCH #22, step #1006] loss: 1.117501920686578\n",
      "[EPOCH #22, step #1008] loss: 1.11707918119974\n",
      "[EPOCH #22, step #1010] loss: 1.1165735101074894\n",
      "[EPOCH #22, step #1012] loss: 1.1166336092461722\n",
      "[EPOCH #22, step #1014] loss: 1.1161810260394525\n",
      "[EPOCH #22, step #1016] loss: 1.1160279486910782\n",
      "[EPOCH #22, step #1018] loss: 1.1160532277921933\n",
      "[EPOCH #22, step #1020] loss: 1.1160382100405586\n",
      "[EPOCH #22, step #1022] loss: 1.1155694248564432\n",
      "[EPOCH #22, step #1024] loss: 1.1156204026792107\n",
      "[EPOCH #22, step #1026] loss: 1.1157195519623297\n",
      "[EPOCH #22, step #1028] loss: 1.1157505220586055\n",
      "[EPOCH #22, step #1030] loss: 1.1155109243353631\n",
      "[EPOCH #22, step #1032] loss: 1.1157301033974156\n",
      "[EPOCH #22, step #1034] loss: 1.1152049299887412\n",
      "[EPOCH #22, step #1036] loss: 1.1151618150816358\n",
      "[EPOCH #22, step #1038] loss: 1.1149115263268394\n",
      "[EPOCH #22, step #1040] loss: 1.1146875225673147\n",
      "[EPOCH #22, step #1042] loss: 1.1145281367368232\n",
      "[EPOCH #22, step #1044] loss: 1.114068714939236\n",
      "[EPOCH #22, step #1046] loss: 1.114027017252493\n",
      "[EPOCH #22, step #1048] loss: 1.1136242655541808\n",
      "[EPOCH #22, step #1050] loss: 1.113378498550827\n",
      "[EPOCH #22, step #1052] loss: 1.1137634490573283\n",
      "[EPOCH #22, step #1054] loss: 1.113690304784413\n",
      "[EPOCH #22, step #1056] loss: 1.1136281514291844\n",
      "[EPOCH #22, step #1058] loss: 1.1138675754592597\n",
      "[EPOCH #22, step #1060] loss: 1.1138577259283489\n",
      "[EPOCH #22, step #1062] loss: 1.1141129715590687\n",
      "[EPOCH #22, step #1064] loss: 1.1140518333150746\n",
      "[EPOCH #22, step #1066] loss: 1.1139035751412936\n",
      "[EPOCH #22, step #1068] loss: 1.1138245748570301\n",
      "[EPOCH #22, step #1070] loss: 1.113696728239095\n",
      "[EPOCH #22, step #1072] loss: 1.113723975553317\n",
      "[EPOCH #22, step #1074] loss: 1.1142855001327603\n",
      "[EPOCH #22, step #1076] loss: 1.1146179280739308\n",
      "[EPOCH #22, step #1078] loss: 1.1149579367502847\n",
      "[EPOCH #22, step #1080] loss: 1.114705350777267\n",
      "[EPOCH #22, step #1082] loss: 1.1147518900127622\n",
      "[EPOCH #22, step #1084] loss: 1.1154370412573837\n",
      "[EPOCH #22, step #1086] loss: 1.1149220562299238\n",
      "[EPOCH #22, step #1088] loss: 1.1147923612123898\n",
      "[EPOCH #22, step #1090] loss: 1.115235845420909\n",
      "[EPOCH #22, step #1092] loss: 1.1149150359717837\n",
      "[EPOCH #22, step #1094] loss: 1.1148243616432905\n",
      "[EPOCH #22, step #1096] loss: 1.1146527644223045\n",
      "[EPOCH #22, step #1098] loss: 1.1144935079495184\n",
      "[EPOCH #22, step #1100] loss: 1.1142771987077\n",
      "[EPOCH #22, step #1102] loss: 1.1145866762640686\n",
      "[EPOCH #22, step #1104] loss: 1.1149690914207993\n",
      "[EPOCH #22, step #1106] loss: 1.1148316537946221\n",
      "[EPOCH #22, step #1108] loss: 1.1153553043592073\n",
      "[EPOCH #22, step #1110] loss: 1.1149731887610081\n",
      "[EPOCH #22, step #1112] loss: 1.1155641133840943\n",
      "[EPOCH #22, step #1114] loss: 1.1154377714133583\n",
      "[EPOCH #22, step #1116] loss: 1.115308135961355\n",
      "[EPOCH #22, step #1118] loss: 1.1153055117053576\n",
      "[EPOCH #22, step #1120] loss: 1.1153829252209437\n",
      "[EPOCH #22, step #1122] loss: 1.115336310221272\n",
      "[EPOCH #22, step #1124] loss: 1.1156455539332495\n",
      "[EPOCH #22, step #1126] loss: 1.1159130779905666\n",
      "[EPOCH #22, step #1128] loss: 1.115587414815639\n",
      "[EPOCH #22, step #1130] loss: 1.115942296441101\n",
      "[EPOCH #22, step #1132] loss: 1.1160651197869065\n",
      "[EPOCH #22, step #1134] loss: 1.1157458401198954\n",
      "[EPOCH #22, step #1136] loss: 1.1161788997937423\n",
      "[EPOCH #22, step #1138] loss: 1.1162786208766924\n",
      "[EPOCH #22, step #1140] loss: 1.1164637616232338\n",
      "[EPOCH #22, step #1142] loss: 1.1162737940918013\n",
      "[EPOCH #22, step #1144] loss: 1.1159907799360533\n",
      "[EPOCH #22, step #1146] loss: 1.1161544547719133\n",
      "[EPOCH #22, step #1148] loss: 1.1170363646418868\n",
      "[EPOCH #22, step #1150] loss: 1.1162960908135364\n",
      "[EPOCH #22, step #1152] loss: 1.1162733876332964\n",
      "[EPOCH #22, step #1154] loss: 1.1160150385780252\n",
      "[EPOCH #22, step #1156] loss: 1.1163180680396543\n",
      "[EPOCH #22, step #1158] loss: 1.1162466072799626\n",
      "[EPOCH #22, step #1160] loss: 1.115787441595991\n",
      "[EPOCH #22, step #1162] loss: 1.1155960145995008\n",
      "[EPOCH #22, step #1164] loss: 1.1151670840932575\n",
      "[EPOCH #22, step #1166] loss: 1.1152332845720963\n",
      "[EPOCH #22, step #1168] loss: 1.1146011539918934\n",
      "[EPOCH #22, step #1170] loss: 1.1143143146237586\n",
      "[EPOCH #22, step #1172] loss: 1.1143867857468404\n",
      "[EPOCH #22, step #1174] loss: 1.1140507457357771\n",
      "[EPOCH #22, step #1176] loss: 1.1145779766212\n",
      "[EPOCH #22, step #1178] loss: 1.1147376142941459\n",
      "[EPOCH #22, step #1180] loss: 1.1152125540221778\n",
      "[EPOCH #22, step #1182] loss: 1.1147884683949607\n",
      "[EPOCH #22, step #1184] loss: 1.115024296769613\n",
      "[EPOCH #22, step #1186] loss: 1.1148987534222927\n",
      "[EPOCH #22, step #1188] loss: 1.1151336441278659\n",
      "[EPOCH #22, step #1190] loss: 1.115379831427591\n",
      "[EPOCH #22, step #1192] loss: 1.1148235073183528\n",
      "[EPOCH #22, step #1194] loss: 1.1148602891417227\n",
      "[EPOCH #22, step #1196] loss: 1.1147026593175249\n",
      "[EPOCH #22, step #1198] loss: 1.1143983974120735\n",
      "[EPOCH #22, step #1200] loss: 1.1142361881979101\n",
      "[EPOCH #22, step #1202] loss: 1.114109518001799\n",
      "[EPOCH #22, step #1204] loss: 1.1142117090492327\n",
      "[EPOCH #22, step #1206] loss: 1.1140248391533452\n",
      "[EPOCH #22, step #1208] loss: 1.1138248770221193\n",
      "[EPOCH #22, step #1210] loss: 1.1137120639313163\n",
      "[EPOCH #22, step #1212] loss: 1.1141905803525143\n",
      "[EPOCH #22, step #1214] loss: 1.1142942843859087\n",
      "[EPOCH #22, step #1216] loss: 1.1149147016500585\n",
      "[EPOCH #22, step #1218] loss: 1.11535490383077\n",
      "[EPOCH #22, step #1220] loss: 1.1154307948332356\n",
      "[EPOCH #22, step #1222] loss: 1.1154436059448432\n",
      "[EPOCH #22, step #1224] loss: 1.1153780170119538\n",
      "[EPOCH #22, step #1226] loss: 1.1148988258430603\n",
      "[EPOCH #22, step #1228] loss: 1.1148604452610016\n",
      "[EPOCH #22, step #1230] loss: 1.1150382837805681\n",
      "[EPOCH #22, step #1232] loss: 1.1148277842360401\n",
      "[EPOCH #22, step #1234] loss: 1.1144069317140077\n",
      "[EPOCH #22, step #1236] loss: 1.1146177719125077\n",
      "[EPOCH #22, step #1238] loss: 1.114836165340222\n",
      "[EPOCH #22, step #1240] loss: 1.1149008927039807\n",
      "[EPOCH #22, step #1242] loss: 1.1149650179898654\n",
      "[EPOCH #22, step #1244] loss: 1.1150934358437856\n",
      "[EPOCH #22, step #1246] loss: 1.1150962558620532\n",
      "[EPOCH #22, step #1248] loss: 1.1159184448379245\n",
      "[EPOCH #22, step #1250] loss: 1.116046471728219\n",
      "[EPOCH #22, step #1252] loss: 1.1160613440886937\n",
      "[EPOCH #22, step #1254] loss: 1.1162028700944437\n",
      "[EPOCH #22, step #1256] loss: 1.1160142371222057\n",
      "[EPOCH #22, step #1258] loss: 1.1160539499202164\n",
      "[EPOCH #22, step #1260] loss: 1.1157084987761008\n",
      "[EPOCH #22, step #1262] loss: 1.1154429052476362\n",
      "[EPOCH #22, step #1264] loss: 1.1154828923257443\n",
      "[EPOCH #22, step #1266] loss: 1.1155481797414402\n",
      "[EPOCH #22, step #1268] loss: 1.115510086852608\n",
      "[EPOCH #22, step #1270] loss: 1.115698824732628\n",
      "[EPOCH #22, step #1272] loss: 1.1157864137652906\n",
      "[EPOCH #22, step #1274] loss: 1.1159391960676979\n",
      "[EPOCH #22, step #1276] loss: 1.115414781199831\n",
      "[EPOCH #22, step #1278] loss: 1.1154598922026726\n",
      "[EPOCH #22, step #1280] loss: 1.1153195226080803\n",
      "[EPOCH #22, step #1282] loss: 1.115384847576137\n",
      "[EPOCH #22, step #1284] loss: 1.1151653801188859\n",
      "[EPOCH #22, step #1286] loss: 1.1150091409729541\n",
      "[EPOCH #22, step #1288] loss: 1.114713746438755\n",
      "[EPOCH #22, step #1290] loss: 1.114638396952154\n",
      "[EPOCH #22, step #1292] loss: 1.1143916747824498\n",
      "[EPOCH #22, step #1294] loss: 1.1145173208363728\n",
      "[EPOCH #22, step #1296] loss: 1.1146230509442923\n",
      "[EPOCH #22, step #1298] loss: 1.1148292432159896\n",
      "[EPOCH #22, step #1300] loss: 1.114607862080179\n",
      "[EPOCH #22, step #1302] loss: 1.114416538548305\n",
      "[EPOCH #22, step #1304] loss: 1.1143709580331926\n",
      "[EPOCH #22, step #1306] loss: 1.1142791970458392\n",
      "[EPOCH #22, step #1308] loss: 1.1146745375998608\n",
      "[EPOCH #22, step #1310] loss: 1.115063125195165\n",
      "[EPOCH #22, step #1312] loss: 1.1152348842724351\n",
      "[EPOCH #22, step #1314] loss: 1.1149952615848513\n",
      "[EPOCH #22, step #1316] loss: 1.115054413438658\n",
      "[EPOCH #22, step #1318] loss: 1.1149156593616665\n",
      "[EPOCH #22, step #1320] loss: 1.1148402634260783\n",
      "[EPOCH #22, step #1322] loss: 1.114573804587013\n",
      "[EPOCH #22, step #1324] loss: 1.1146338656038608\n",
      "[EPOCH #22, step #1326] loss: 1.115080496805812\n",
      "[EPOCH #22, step #1328] loss: 1.1152230725196899\n",
      "[EPOCH #22, step #1330] loss: 1.1150840456596807\n",
      "[EPOCH #22, step #1332] loss: 1.1146921743733134\n",
      "[EPOCH #22, step #1334] loss: 1.1147006220808637\n",
      "[EPOCH #22, step #1336] loss: 1.1146753897797108\n",
      "[EPOCH #22, step #1338] loss: 1.1143113191088605\n",
      "[EPOCH #22, step #1340] loss: 1.1144370140867568\n",
      "[EPOCH #22, step #1342] loss: 1.1145332858842962\n",
      "[EPOCH #22, step #1344] loss: 1.1142982491108564\n",
      "[EPOCH #22, step #1346] loss: 1.1141761995592026\n",
      "[EPOCH #22, step #1348] loss: 1.114417462745713\n",
      "[EPOCH #22, step #1350] loss: 1.1145263828011815\n",
      "[EPOCH #22, step #1352] loss: 1.1146511797850343\n",
      "[EPOCH #22, step #1354] loss: 1.1147147587524568\n",
      "[EPOCH #22, step #1356] loss: 1.1146422288351052\n",
      "[EPOCH #22, step #1358] loss: 1.1142231722234188\n",
      "[EPOCH #22, step #1360] loss: 1.1142302269579996\n",
      "[EPOCH #22, step #1362] loss: 1.114480128619746\n",
      "[EPOCH #22, step #1364] loss: 1.1143528573897294\n",
      "[EPOCH #22, step #1366] loss: 1.1142850547658325\n",
      "[EPOCH #22, step #1368] loss: 1.1143226743919994\n",
      "[EPOCH #22, step #1370] loss: 1.1144035761805018\n",
      "[EPOCH #22, step #1372] loss: 1.1146725728098528\n",
      "[EPOCH #22, step #1374] loss: 1.1142746988426555\n",
      "[EPOCH #22, step #1376] loss: 1.1142529497435756\n",
      "[EPOCH #22, step #1378] loss: 1.1145908885066107\n",
      "[EPOCH #22, step #1380] loss: 1.114165977474402\n",
      "[EPOCH #22, step #1382] loss: 1.1139496292700737\n",
      "[EPOCH #22, step #1384] loss: 1.114008350729512\n",
      "[EPOCH #22, step #1386] loss: 1.1142767043576107\n",
      "[EPOCH #22, step #1388] loss: 1.1139105201153725\n",
      "[EPOCH #22, step #1390] loss: 1.114216841762654\n",
      "[EPOCH #22, step #1392] loss: 1.11460484894847\n",
      "[EPOCH #22, step #1394] loss: 1.1144229877165996\n",
      "[EPOCH #22, step #1396] loss: 1.1152957930638265\n",
      "[EPOCH #22, step #1398] loss: 1.1155297747887059\n",
      "[EPOCH #22, step #1400] loss: 1.1150179538745526\n",
      "[EPOCH #22, step #1402] loss: 1.1147156280657264\n",
      "[EPOCH #22, step #1404] loss: 1.1146738193001187\n",
      "[EPOCH #22, step #1406] loss: 1.1145081710078315\n",
      "[EPOCH #22, step #1408] loss: 1.1150383111049809\n",
      "[EPOCH #22, step #1410] loss: 1.115205742909839\n",
      "[EPOCH #22, step #1412] loss: 1.1151172162072505\n",
      "[EPOCH #22, step #1414] loss: 1.1152728926377247\n",
      "[EPOCH #22, step #1416] loss: 1.1154235111590247\n",
      "[EPOCH #22, step #1418] loss: 1.1154875622365237\n",
      "[EPOCH #22, step #1420] loss: 1.1152971887110321\n",
      "[EPOCH #22, step #1422] loss: 1.1155676699111936\n",
      "[EPOCH #22, step #1424] loss: 1.1153069341600987\n",
      "[EPOCH #22, step #1426] loss: 1.1155487690133987\n",
      "[EPOCH #22, step #1428] loss: 1.1154266429206054\n",
      "[EPOCH #22, step #1430] loss: 1.1152085347620446\n",
      "[EPOCH #22, step #1432] loss: 1.1153726377482192\n",
      "[EPOCH #22, step #1434] loss: 1.1154221829013957\n",
      "[EPOCH #22, step #1436] loss: 1.115577245492776\n",
      "[EPOCH #22, step #1438] loss: 1.1158637630392727\n",
      "[EPOCH #22, step #1440] loss: 1.115761874224228\n",
      "[EPOCH #22, step #1442] loss: 1.1158460960029648\n",
      "[EPOCH #22, step #1444] loss: 1.1157941447616035\n",
      "[EPOCH #22, step #1446] loss: 1.1159876092969754\n",
      "[EPOCH #22, step #1448] loss: 1.1162247014218483\n",
      "[EPOCH #22, step #1450] loss: 1.1161853776850592\n",
      "[EPOCH #22, step #1452] loss: 1.1161260508252109\n",
      "[EPOCH #22, step #1454] loss: 1.116055949795287\n",
      "[EPOCH #22, step #1456] loss: 1.1158505088880444\n",
      "[EPOCH #22, step #1458] loss: 1.1160003025904348\n",
      "[EPOCH #22, step #1460] loss: 1.1161056257412092\n",
      "[EPOCH #22, step #1462] loss: 1.1163866505872202\n",
      "[EPOCH #22, step #1464] loss: 1.1163504011191605\n",
      "[EPOCH #22, step #1466] loss: 1.1164572568636975\n",
      "[EPOCH #22, step #1468] loss: 1.1162506512551993\n",
      "[EPOCH #22, step #1470] loss: 1.115902129056744\n",
      "[EPOCH #22, step #1472] loss: 1.1159088870779803\n",
      "[EPOCH #22, step #1474] loss: 1.1157413211717444\n",
      "[EPOCH #22, step #1476] loss: 1.1159543668045413\n",
      "[EPOCH #22, step #1478] loss: 1.115817744095959\n",
      "[EPOCH #22, step #1480] loss: 1.1158936469438991\n",
      "[EPOCH #22, step #1482] loss: 1.1157873533942453\n",
      "[EPOCH #22, step #1484] loss: 1.1153595381914967\n",
      "[EPOCH #22, step #1486] loss: 1.1151093174205502\n",
      "[EPOCH #22, step #1488] loss: 1.1148859746228776\n",
      "[EPOCH #22, step #1490] loss: 1.1148343518985988\n",
      "[EPOCH #22, step #1492] loss: 1.1145952831596955\n",
      "[EPOCH #22, step #1494] loss: 1.1146679894381941\n",
      "[EPOCH #22, step #1496] loss: 1.1144321574994382\n",
      "[EPOCH #22, step #1498] loss: 1.114394319562454\n",
      "[EPOCH #22, step #1500] loss: 1.1148199488090564\n",
      "[EPOCH #22, step #1502] loss: 1.1149406100183983\n",
      "[EPOCH #22, step #1504] loss: 1.1148602625262303\n",
      "[EPOCH #22, step #1506] loss: 1.1149123861406842\n",
      "[EPOCH #22, step #1508] loss: 1.114894004295487\n",
      "[EPOCH #22, step #1510] loss: 1.1150568239070342\n",
      "[EPOCH #22, step #1512] loss: 1.1150788254518817\n",
      "[EPOCH #22, step #1514] loss: 1.115355761511491\n",
      "[EPOCH #22, step #1516] loss: 1.1151619200142262\n",
      "[EPOCH #22, step #1518] loss: 1.1151254057217146\n",
      "[EPOCH #22, step #1520] loss: 1.1149157684818056\n",
      "[EPOCH #22, step #1522] loss: 1.1152737737289011\n",
      "[EPOCH #22, step #1524] loss: 1.115102236055937\n",
      "[EPOCH #22, step #1526] loss: 1.1150372035962426\n",
      "[EPOCH #22, step #1528] loss: 1.1147382523866944\n",
      "[EPOCH #22, step #1530] loss: 1.1152422399516202\n",
      "[EPOCH #22, step #1532] loss: 1.114876028629043\n",
      "[EPOCH #22, step #1534] loss: 1.114980247684721\n",
      "[EPOCH #22, step #1536] loss: 1.1152838260109887\n",
      "[EPOCH #22, step #1538] loss: 1.115355029769963\n",
      "[EPOCH #22, step #1540] loss: 1.1154487300700449\n",
      "[EPOCH #22, step #1542] loss: 1.115632538875047\n",
      "[EPOCH #22, step #1544] loss: 1.1150674757255319\n",
      "[EPOCH #22, step #1546] loss: 1.1147914096741962\n",
      "[EPOCH #22, step #1548] loss: 1.1145284535463122\n",
      "[EPOCH #22, step #1550] loss: 1.1147554984675307\n",
      "[EPOCH #22, step #1552] loss: 1.1151636713985005\n",
      "[EPOCH #22, step #1554] loss: 1.1149550933354921\n",
      "[EPOCH #22, step #1556] loss: 1.1146139681109573\n",
      "[EPOCH #22, step #1558] loss: 1.1144515542245355\n",
      "[EPOCH #22, step #1560] loss: 1.114411265421647\n",
      "[EPOCH #22, step #1562] loss: 1.1143798392816606\n",
      "[EPOCH #22, step #1564] loss: 1.1141570287581068\n",
      "[EPOCH #22, step #1566] loss: 1.1141106880578404\n",
      "[EPOCH #22, step #1568] loss: 1.114472947943507\n",
      "[EPOCH #22, step #1570] loss: 1.1142275729693856\n",
      "[EPOCH #22, step #1572] loss: 1.1146076730649637\n",
      "[EPOCH #22, step #1574] loss: 1.114458748064344\n",
      "[EPOCH #22, step #1576] loss: 1.1145437130197817\n",
      "[EPOCH #22, step #1578] loss: 1.114255326752273\n",
      "[EPOCH #22, step #1580] loss: 1.1141865376917943\n",
      "[EPOCH #22, step #1582] loss: 1.113895980131754\n",
      "[EPOCH #22, step #1584] loss: 1.113555679204712\n",
      "[EPOCH #22, step #1586] loss: 1.1136253687782565\n",
      "[EPOCH #22, step #1588] loss: 1.1132963182530065\n",
      "[EPOCH #22, step #1590] loss: 1.1133439593499446\n",
      "[EPOCH #22, step #1592] loss: 1.1129982832723344\n",
      "[EPOCH #22, step #1594] loss: 1.1129699127614312\n",
      "[EPOCH #22, step #1596] loss: 1.1129011394795434\n",
      "[EPOCH #22, step #1598] loss: 1.1131969009473073\n",
      "[EPOCH #22, step #1600] loss: 1.1132123449271654\n",
      "[EPOCH #22, step #1602] loss: 1.1131575847333919\n",
      "[EPOCH #22, step #1604] loss: 1.1130867429054414\n",
      "[EPOCH #22, step #1606] loss: 1.1131888452752747\n",
      "[EPOCH #22, step #1608] loss: 1.1132368915306254\n",
      "[EPOCH #22, step #1610] loss: 1.113138412019616\n",
      "[EPOCH #22, step #1612] loss: 1.1134750362478718\n",
      "[EPOCH #22, step #1614] loss: 1.1133174433243165\n",
      "[EPOCH #22, step #1616] loss: 1.1134013212346412\n",
      "[EPOCH #22, step #1618] loss: 1.113381924914165\n",
      "[EPOCH #22, step #1620] loss: 1.1133956965254383\n",
      "[EPOCH #22, step #1622] loss: 1.1132277444014194\n",
      "[EPOCH #22, step #1624] loss: 1.1135668301765735\n",
      "[EPOCH #22, step #1626] loss: 1.1133955898245347\n",
      "[EPOCH #22, step #1628] loss: 1.1132570872685894\n",
      "[EPOCH #22, step #1630] loss: 1.113510401701357\n",
      "[EPOCH #22, step #1632] loss: 1.1131355049817457\n",
      "[EPOCH #22, step #1634] loss: 1.113433945999233\n",
      "[EPOCH #22, step #1636] loss: 1.113407745311081\n",
      "[EPOCH #22, step #1638] loss: 1.1132994576915871\n",
      "[EPOCH #22, step #1640] loss: 1.1133294797648314\n",
      "[EPOCH #22, step #1642] loss: 1.113905202794641\n",
      "[EPOCH #22, step #1644] loss: 1.113965142588485\n",
      "[EPOCH #22, step #1646] loss: 1.113678881469899\n",
      "[EPOCH #22, step #1648] loss: 1.1136371635573787\n",
      "[EPOCH #22, step #1650] loss: 1.1134179410502667\n",
      "[EPOCH #22, step #1652] loss: 1.1136674015758548\n",
      "[EPOCH #22, step #1654] loss: 1.1138410040439075\n",
      "[EPOCH #22, step #1656] loss: 1.1135774778722638\n",
      "[EPOCH #22, step #1658] loss: 1.1131726815766638\n",
      "[EPOCH #22, step #1660] loss: 1.113388934654331\n",
      "[EPOCH #22, step #1662] loss: 1.1131450830814857\n",
      "[EPOCH #22, step #1664] loss: 1.11324519629593\n",
      "[EPOCH #22, step #1666] loss: 1.1133608601196268\n",
      "[EPOCH #22, step #1668] loss: 1.1129180412045347\n",
      "[EPOCH #22, step #1670] loss: 1.1128881133330362\n",
      "[EPOCH #22, step #1672] loss: 1.1129028093330318\n",
      "[EPOCH #22, step #1674] loss: 1.113163409926998\n",
      "[EPOCH #22, step #1676] loss: 1.1133483051009738\n",
      "[EPOCH #22, step #1678] loss: 1.113225309656375\n",
      "[EPOCH #22, step #1680] loss: 1.11347409210554\n",
      "[EPOCH #22, step #1682] loss: 1.1132796635708495\n",
      "[EPOCH #22, step #1684] loss: 1.1131141699916884\n",
      "[EPOCH #22, step #1686] loss: 1.112801275082997\n",
      "[EPOCH #22, step #1688] loss: 1.1127565974769964\n",
      "[EPOCH #22, step #1690] loss: 1.1128830083335806\n",
      "[EPOCH #22, step #1692] loss: 1.1130512686467213\n",
      "[EPOCH #22, step #1694] loss: 1.1130111569676076\n",
      "[EPOCH #22, step #1696] loss: 1.112857009831357\n",
      "[EPOCH #22, step #1698] loss: 1.1125490248133114\n",
      "[EPOCH #22, step #1700] loss: 1.1122996322306937\n",
      "[EPOCH #22, step #1702] loss: 1.1122543427325386\n",
      "[EPOCH #22, step #1704] loss: 1.112002111617421\n",
      "[EPOCH #22, step #1706] loss: 1.1119740040210093\n",
      "[EPOCH #22, step #1708] loss: 1.1118920881926768\n",
      "[EPOCH #22, step #1710] loss: 1.112040380596209\n",
      "[EPOCH #22, step #1712] loss: 1.1118924445007812\n",
      "[EPOCH #22, step #1714] loss: 1.1119283673540843\n",
      "[EPOCH #22, step #1716] loss: 1.1116255620536792\n",
      "[EPOCH #22, step #1718] loss: 1.1115583560194922\n",
      "[EPOCH #22, step #1720] loss: 1.1115470972087478\n",
      "[EPOCH #22, step #1722] loss: 1.1114067041417297\n",
      "[EPOCH #22, step #1724] loss: 1.1115313987628272\n",
      "[EPOCH #22, step #1726] loss: 1.1114712999297762\n",
      "[EPOCH #22, step #1728] loss: 1.1114798427972579\n",
      "[EPOCH #22, step #1730] loss: 1.1114650599912437\n",
      "[EPOCH #22, step #1732] loss: 1.11135955774846\n",
      "[EPOCH #22, step #1734] loss: 1.1116150230255182\n",
      "[EPOCH #22, step #1736] loss: 1.1116603270267438\n",
      "[EPOCH #22, step #1738] loss: 1.111411239666936\n",
      "[EPOCH #22, step #1740] loss: 1.1111691376554904\n",
      "[EPOCH #22, step #1742] loss: 1.1113835358270885\n",
      "[EPOCH #22, step #1744] loss: 1.111365391753806\n",
      "[EPOCH #22, step #1746] loss: 1.1113766674560073\n",
      "[EPOCH #22, step #1748] loss: 1.1111872748792888\n",
      "[EPOCH #22, step #1750] loss: 1.1111969263433796\n",
      "[EPOCH #22, step #1752] loss: 1.1112204506372767\n",
      "[EPOCH #22, step #1754] loss: 1.1112176767951063\n",
      "[EPOCH #22, step #1756] loss: 1.1110796553374829\n",
      "[EPOCH #22, step #1758] loss: 1.1111664532293577\n",
      "[EPOCH #22, step #1760] loss: 1.1111781532320362\n",
      "[EPOCH #22, step #1762] loss: 1.1111559897103367\n",
      "[EPOCH #22, step #1764] loss: 1.1110139161095065\n",
      "[EPOCH #22, step #1766] loss: 1.1112252989089213\n",
      "[EPOCH #22, step #1768] loss: 1.1109031467298924\n",
      "[EPOCH #22, step #1770] loss: 1.111088789044498\n",
      "[EPOCH #22, step #1772] loss: 1.11131839792875\n",
      "[EPOCH #22, step #1774] loss: 1.1114584995827206\n",
      "[EPOCH #22, step #1776] loss: 1.111519675393687\n",
      "[EPOCH #22, step #1778] loss: 1.1116171331972537\n",
      "[EPOCH #22, step #1780] loss: 1.1114234368932308\n",
      "[EPOCH #22, step #1782] loss: 1.111777364923522\n",
      "[EPOCH #22, step #1784] loss: 1.1114317824025781\n",
      "[EPOCH #22, step #1786] loss: 1.1112113005466546\n",
      "[EPOCH #22, step #1788] loss: 1.1112006591011387\n",
      "[EPOCH #22, step #1790] loss: 1.1114077037735932\n",
      "[EPOCH #22, step #1792] loss: 1.1113479171827128\n",
      "[EPOCH #22, step #1794] loss: 1.111210858307177\n",
      "[EPOCH #22, step #1796] loss: 1.1111265388242257\n",
      "[EPOCH #22, step #1798] loss: 1.111094744305534\n",
      "[EPOCH #22, step #1800] loss: 1.1110743484617538\n",
      "[EPOCH #22, step #1802] loss: 1.1109095957797563\n",
      "[EPOCH #22, step #1804] loss: 1.1108529294131535\n",
      "[EPOCH #22, step #1806] loss: 1.1108709278361337\n",
      "[EPOCH #22, step #1808] loss: 1.1107664682411766\n",
      "[EPOCH #22, step #1810] loss: 1.1110835573180877\n",
      "[EPOCH #22, step #1812] loss: 1.1110900894456717\n",
      "[EPOCH #22, step #1814] loss: 1.111461272006521\n",
      "[EPOCH #22, step #1816] loss: 1.1116272695424074\n",
      "[EPOCH #22, step #1818] loss: 1.1114859176802727\n",
      "[EPOCH #22, step #1820] loss: 1.1113890207023296\n",
      "[EPOCH #22, step #1822] loss: 1.1113241624027834\n",
      "[EPOCH #22, step #1824] loss: 1.111643150816225\n",
      "[EPOCH #22, step #1826] loss: 1.1118396244123456\n",
      "[EPOCH #22, step #1828] loss: 1.1117344074167144\n",
      "[EPOCH #22, step #1830] loss: 1.1117488972187564\n",
      "[EPOCH #22, step #1832] loss: 1.1118071672536607\n",
      "[EPOCH #22, step #1834] loss: 1.1119489716736433\n",
      "[EPOCH #22, step #1836] loss: 1.1120415183760644\n",
      "[EPOCH #22, step #1838] loss: 1.1121686538676323\n",
      "[EPOCH #22, step #1840] loss: 1.1123231532034958\n",
      "[EPOCH #22, step #1842] loss: 1.1121132566077645\n",
      "[EPOCH #22, step #1844] loss: 1.1122938956510084\n",
      "[EPOCH #22, step #1846] loss: 1.1125669208131872\n",
      "[EPOCH #22, step #1848] loss: 1.1127825022356261\n",
      "[EPOCH #22, step #1850] loss: 1.1129628377209348\n",
      "[EPOCH #22, step #1852] loss: 1.1130138585938034\n",
      "[EPOCH #22, step #1854] loss: 1.1127990524884503\n",
      "[EPOCH #22, step #1856] loss: 1.112779900584095\n",
      "[EPOCH #22, step #1858] loss: 1.1127023799339888\n",
      "[EPOCH #22, step #1860] loss: 1.1124994918615956\n",
      "[EPOCH #22, step #1862] loss: 1.1124741303396046\n",
      "[EPOCH #22, step #1864] loss: 1.1125055700940039\n",
      "[EPOCH #22, step #1866] loss: 1.112859428902648\n",
      "[EPOCH #22, step #1868] loss: 1.112892062779478\n",
      "[EPOCH #22, step #1870] loss: 1.112990492474007\n",
      "[EPOCH #22, step #1872] loss: 1.1129727467170578\n",
      "[EPOCH #22, step #1874] loss: 1.1129890724023184\n",
      "[EPOCH #22, step #1876] loss: 1.1129953034805629\n",
      "[EPOCH #22, step #1878] loss: 1.1129488559750054\n",
      "[EPOCH #22, step #1880] loss: 1.1131488606214903\n",
      "[EPOCH #22, step #1882] loss: 1.1130739950431008\n",
      "[EPOCH #22, step #1884] loss: 1.1133173461776198\n",
      "[EPOCH #22, step #1886] loss: 1.1131745209028054\n",
      "[EPOCH #22, step #1888] loss: 1.1128511512923203\n",
      "[EPOCH #22, step #1890] loss: 1.1128120497538891\n",
      "[EPOCH #22, step #1892] loss: 1.1126865078486026\n",
      "[EPOCH #22, step #1894] loss: 1.1126918529614924\n",
      "[EPOCH #22, step #1896] loss: 1.1127220125624426\n",
      "[EPOCH #22, step #1898] loss: 1.1129001783125647\n",
      "[EPOCH #22, step #1900] loss: 1.112908468238308\n",
      "[EPOCH #22, step #1902] loss: 1.1132256071221747\n",
      "[EPOCH #22, step #1904] loss: 1.1131096481807587\n",
      "[EPOCH #22, step #1906] loss: 1.1131034801158846\n",
      "[EPOCH #22, step #1908] loss: 1.1131567046272624\n",
      "[EPOCH #22, step #1910] loss: 1.1130870603909984\n",
      "[EPOCH #22, step #1912] loss: 1.1130986805524243\n",
      "[EPOCH #22, step #1914] loss: 1.1131896243549826\n",
      "[EPOCH #22, step #1916] loss: 1.1132360586569094\n",
      "[EPOCH #22, step #1918] loss: 1.1132332540508856\n",
      "[EPOCH #22, step #1920] loss: 1.1135196934479838\n",
      "[EPOCH #22, step #1922] loss: 1.1134880485320178\n",
      "[EPOCH #22, step #1924] loss: 1.1130784530299052\n",
      "[EPOCH #22, step #1926] loss: 1.113214392286542\n",
      "[EPOCH #22, step #1928] loss: 1.1131024781040975\n",
      "[EPOCH #22, step #1930] loss: 1.1130454111969699\n",
      "[EPOCH #22, step #1932] loss: 1.1130801636785408\n",
      "[EPOCH #22, step #1934] loss: 1.1130084311469273\n",
      "[EPOCH #22, step #1936] loss: 1.112870074066232\n",
      "[EPOCH #22, step #1938] loss: 1.1128950086280573\n",
      "[EPOCH #22, step #1940] loss: 1.112810410140778\n",
      "[EPOCH #22, step #1942] loss: 1.1128875251995554\n",
      "[EPOCH #22, step #1944] loss: 1.1125260735998423\n",
      "[EPOCH #22, step #1946] loss: 1.1123805835146627\n",
      "[EPOCH #22, step #1948] loss: 1.112350645968705\n",
      "[EPOCH #22, step #1950] loss: 1.1125906679124358\n",
      "[EPOCH #22, step #1952] loss: 1.1127394960436892\n",
      "[EPOCH #22, step #1954] loss: 1.1125224748993163\n",
      "[EPOCH #22, step #1956] loss: 1.112473987366511\n",
      "[EPOCH #22, step #1958] loss: 1.112563745488069\n",
      "[EPOCH #22, step #1960] loss: 1.1128626317925625\n",
      "[EPOCH #22, step #1962] loss: 1.1126825200223946\n",
      "[EPOCH #22, step #1964] loss: 1.1124964676892182\n",
      "[EPOCH #22, step #1966] loss: 1.1124246911191673\n",
      "[EPOCH #22, step #1968] loss: 1.1122786834828438\n",
      "[EPOCH #22, step #1970] loss: 1.1122632963381582\n",
      "[EPOCH #22, step #1972] loss: 1.1124523757710048\n",
      "[EPOCH #22, step #1974] loss: 1.1123639485654953\n",
      "[EPOCH #22, step #1976] loss: 1.1122556421180294\n",
      "[EPOCH #22, step #1978] loss: 1.1120615355922696\n",
      "[EPOCH #22, step #1980] loss: 1.1119587311745893\n",
      "[EPOCH #22, step #1982] loss: 1.1122365206314708\n",
      "[EPOCH #22, step #1984] loss: 1.1119292177691569\n",
      "[EPOCH #22, step #1986] loss: 1.112051932833935\n",
      "[EPOCH #22, step #1988] loss: 1.1118841808216244\n",
      "[EPOCH #22, step #1990] loss: 1.1118733190011283\n",
      "[EPOCH #22, step #1992] loss: 1.1120466531459494\n",
      "[EPOCH #22, step #1994] loss: 1.1122574668032186\n",
      "[EPOCH #22, step #1996] loss: 1.1120895660842844\n",
      "[EPOCH #22, step #1998] loss: 1.1122350413808828\n",
      "[EPOCH #22, step #2000] loss: 1.112318709351193\n",
      "[EPOCH #22, step #2002] loss: 1.1121342680451873\n",
      "[EPOCH #22, step #2004] loss: 1.1119705781526399\n",
      "[EPOCH #22, step #2006] loss: 1.1120568535698547\n",
      "[EPOCH #22, step #2008] loss: 1.1122798120844952\n",
      "[EPOCH #22, step #2010] loss: 1.1119429185608618\n",
      "[EPOCH #22, step #2012] loss: 1.1116813069336224\n",
      "[EPOCH #22, step #2014] loss: 1.1118626924809392\n",
      "[EPOCH #22, step #2016] loss: 1.1119783516413633\n",
      "[EPOCH #22, step #2018] loss: 1.1122011578779754\n",
      "[EPOCH #22, step #2020] loss: 1.1121204823830646\n",
      "[EPOCH #22, step #2022] loss: 1.112025772013761\n",
      "[EPOCH #22, step #2024] loss: 1.1120137349617334\n",
      "[EPOCH #22, step #2026] loss: 1.1118328302407652\n",
      "[EPOCH #22, step #2028] loss: 1.1118585787100297\n",
      "[EPOCH #22, step #2030] loss: 1.1114955402576883\n",
      "[EPOCH #22, step #2032] loss: 1.1116561138946555\n",
      "[EPOCH #22, step #2034] loss: 1.111599785645998\n",
      "[EPOCH #22, step #2036] loss: 1.111619105029469\n",
      "[EPOCH #22, step #2038] loss: 1.1112257668848071\n",
      "[EPOCH #22, step #2040] loss: 1.111288273132998\n",
      "[EPOCH #22, step #2042] loss: 1.1111681778612992\n",
      "[EPOCH #22, step #2044] loss: 1.1114945913439567\n",
      "[EPOCH #22, step #2046] loss: 1.1115741660580964\n",
      "[EPOCH #22, step #2048] loss: 1.111747655841186\n",
      "[EPOCH #22, step #2050] loss: 1.1119137338200527\n",
      "[EPOCH #22, step #2052] loss: 1.1119852980142446\n",
      "[EPOCH #22, step #2054] loss: 1.1118741692562752\n",
      "[EPOCH #22, step #2056] loss: 1.1120977183105765\n",
      "[EPOCH #22, step #2058] loss: 1.111962862374309\n",
      "[EPOCH #22, step #2060] loss: 1.112068926995961\n",
      "[EPOCH #22, step #2062] loss: 1.1121414403602214\n",
      "[EPOCH #22, step #2064] loss: 1.111957345213786\n",
      "[EPOCH #22, step #2066] loss: 1.1119075077394385\n",
      "[EPOCH #22, step #2068] loss: 1.11176972655123\n",
      "[EPOCH #22, step #2070] loss: 1.1116960688900221\n",
      "[EPOCH #22, step #2072] loss: 1.1117752796345384\n",
      "[EPOCH #22, step #2074] loss: 1.111983442493232\n",
      "[EPOCH #22, step #2076] loss: 1.1119052072270421\n",
      "[EPOCH #22, step #2078] loss: 1.1116507649278342\n",
      "[EPOCH #22, step #2080] loss: 1.1115096640924833\n",
      "[EPOCH #22, step #2082] loss: 1.1115525164429065\n",
      "[EPOCH #22, step #2084] loss: 1.1114812343383578\n",
      "[EPOCH #22, step #2086] loss: 1.1117267002742943\n",
      "[EPOCH #22, step #2088] loss: 1.1114660373225973\n",
      "[EPOCH #22, step #2090] loss: 1.1113102440198948\n",
      "[EPOCH #22, step #2092] loss: 1.111320961464323\n",
      "[EPOCH #22, step #2094] loss: 1.1112085607427402\n",
      "[EPOCH #22, step #2096] loss: 1.1112595673083805\n",
      "[EPOCH #22, step #2098] loss: 1.1108252776555074\n",
      "[EPOCH #22, step #2100] loss: 1.11065746112587\n",
      "[EPOCH #22, step #2102] loss: 1.1107217976863306\n",
      "[EPOCH #22, step #2104] loss: 1.1108364039956815\n",
      "[EPOCH #22, step #2106] loss: 1.1106015267420788\n",
      "[EPOCH #22, step #2108] loss: 1.1105353485610938\n",
      "[EPOCH #22, step #2110] loss: 1.110322531550939\n",
      "[EPOCH #22, step #2112] loss: 1.1101738507438486\n",
      "[EPOCH #22, step #2114] loss: 1.1102102787359387\n",
      "[EPOCH #22, step #2116] loss: 1.1099298161524447\n",
      "[EPOCH #22, step #2118] loss: 1.1099524462684363\n",
      "[EPOCH #22, step #2120] loss: 1.1097908868844752\n",
      "[EPOCH #22, step #2122] loss: 1.1094775796638476\n",
      "[EPOCH #22, step #2124] loss: 1.1097808160641613\n",
      "[EPOCH #22, step #2126] loss: 1.1097099290776264\n",
      "[EPOCH #22, step #2128] loss: 1.1097293705686038\n",
      "[EPOCH #22, step #2130] loss: 1.1098047341471375\n",
      "[EPOCH #22, step #2132] loss: 1.1100607259671453\n",
      "[EPOCH #22, step #2134] loss: 1.1099176605216792\n",
      "[EPOCH #22, step #2136] loss: 1.109817983295854\n",
      "[EPOCH #22, step #2138] loss: 1.109761293146754\n",
      "[EPOCH #22, step #2140] loss: 1.1095308464495504\n",
      "[EPOCH #22, step #2142] loss: 1.1095384968339534\n",
      "[EPOCH #22, step #2144] loss: 1.1095227864099828\n",
      "[EPOCH #22, step #2146] loss: 1.1095254737302542\n",
      "[EPOCH #22, step #2148] loss: 1.1093387231126726\n",
      "[EPOCH #22, step #2150] loss: 1.1093417163479333\n",
      "[EPOCH #22, step #2152] loss: 1.1093576767945146\n",
      "[EPOCH #22, step #2154] loss: 1.1093662884146873\n",
      "[EPOCH #22, step #2156] loss: 1.1094095712328156\n",
      "[EPOCH #22, step #2158] loss: 1.1094274175089782\n",
      "[EPOCH #22, step #2160] loss: 1.1096076431758755\n",
      "[EPOCH #22, step #2162] loss: 1.1097865301566272\n",
      "[EPOCH #22, step #2164] loss: 1.1096663276125047\n",
      "[EPOCH #22, step #2166] loss: 1.109761802389372\n",
      "[EPOCH #22, step #2168] loss: 1.109795536504137\n",
      "[EPOCH #22, step #2170] loss: 1.1098984026760619\n",
      "[EPOCH #22, step #2172] loss: 1.1098544914301123\n",
      "[EPOCH #22, step #2174] loss: 1.1095341077755236\n",
      "[EPOCH #22, step #2176] loss: 1.1094306346386684\n",
      "[EPOCH #22, step #2178] loss: 1.109287100204255\n",
      "[EPOCH #22, step #2180] loss: 1.1092377308993535\n",
      "[EPOCH #22, step #2182] loss: 1.1090501054978075\n",
      "[EPOCH #22, step #2184] loss: 1.108881577106035\n",
      "[EPOCH #22, step #2186] loss: 1.1088454858129517\n",
      "[EPOCH #22, step #2188] loss: 1.1087380317777953\n",
      "[EPOCH #22, step #2190] loss: 1.108771190217291\n",
      "[EPOCH #22, step #2192] loss: 1.1086383559662514\n",
      "[EPOCH #22, step #2194] loss: 1.1086933352273798\n",
      "[EPOCH #22, step #2196] loss: 1.1088837077658882\n",
      "[EPOCH #22, step #2198] loss: 1.108885524746178\n",
      "[EPOCH #22, step #2200] loss: 1.1087506965229263\n",
      "[EPOCH #22, step #2202] loss: 1.1087012626585828\n",
      "[EPOCH #22, step #2204] loss: 1.1089582912100144\n",
      "[EPOCH #22, step #2206] loss: 1.1089285872319623\n",
      "[EPOCH #22, step #2208] loss: 1.1087225520837463\n",
      "[EPOCH #22, step #2210] loss: 1.108886891296146\n",
      "[EPOCH #22, step #2212] loss: 1.1085884579559606\n",
      "[EPOCH #22, step #2214] loss: 1.1083799997382455\n",
      "[EPOCH #22, step #2216] loss: 1.108337962404263\n",
      "[EPOCH #22, step #2218] loss: 1.1083185261651813\n",
      "[EPOCH #22, step #2220] loss: 1.1082429351945118\n",
      "[EPOCH #22, step #2222] loss: 1.1082597841859347\n",
      "[EPOCH #22, step #2224] loss: 1.1083735030018882\n",
      "[EPOCH #22, step #2226] loss: 1.108335076250407\n",
      "[EPOCH #22, step #2228] loss: 1.1084606748169556\n",
      "[EPOCH #22, step #2230] loss: 1.1086136099603987\n",
      "[EPOCH #22, step #2232] loss: 1.108751530998019\n",
      "[EPOCH #22, step #2234] loss: 1.108668936565685\n",
      "[EPOCH #22, step #2236] loss: 1.1085187233901206\n",
      "[EPOCH #22, step #2238] loss: 1.1083439914522133\n",
      "[EPOCH #22, step #2240] loss: 1.108202855603496\n",
      "[EPOCH #22, step #2242] loss: 1.108150968940142\n",
      "[EPOCH #22, step #2244] loss: 1.1080335738000466\n",
      "[EPOCH #22, step #2246] loss: 1.1078330097884987\n",
      "[EPOCH #22, step #2248] loss: 1.1078651795630032\n",
      "[EPOCH #22, step #2250] loss: 1.1078474166948284\n",
      "[EPOCH #22, step #2252] loss: 1.1080709240381525\n",
      "[EPOCH #22, step #2254] loss: 1.1080878986619793\n",
      "[EPOCH #22, step #2256] loss: 1.10800629652175\n",
      "[EPOCH #22, step #2258] loss: 1.1080206729844377\n",
      "[EPOCH #22, step #2260] loss: 1.1082222605769163\n",
      "[EPOCH #22, step #2262] loss: 1.1080693658268457\n",
      "[EPOCH #22, step #2264] loss: 1.1081603997195792\n",
      "[EPOCH #22, step #2266] loss: 1.1082578158794019\n",
      "[EPOCH #22, step #2268] loss: 1.108218563856034\n",
      "[EPOCH #22, step #2270] loss: 1.1083458266112312\n",
      "[EPOCH #22, step #2272] loss: 1.1082940408038087\n",
      "[EPOCH #22, step #2274] loss: 1.1081425687375959\n",
      "[EPOCH #22, step #2276] loss: 1.1082162300667115\n",
      "[EPOCH #22, step #2278] loss: 1.1083117114733896\n",
      "[EPOCH #22, step #2280] loss: 1.1080575604048908\n",
      "[EPOCH #22, step #2282] loss: 1.1079872825064265\n",
      "[EPOCH #22, step #2284] loss: 1.1079047590037665\n",
      "[EPOCH #22, step #2286] loss: 1.1078049060841757\n",
      "[EPOCH #22, step #2288] loss: 1.1080233657682967\n",
      "[EPOCH #22, step #2290] loss: 1.1077929591960858\n",
      "[EPOCH #22, step #2292] loss: 1.1077263186163013\n",
      "[EPOCH #22, step #2294] loss: 1.10774376017076\n",
      "[EPOCH #22, step #2296] loss: 1.1078750689002708\n",
      "[EPOCH #22, step #2298] loss: 1.1077835597308525\n",
      "[EPOCH #22, step #2300] loss: 1.1074024120888881\n",
      "[EPOCH #22, step #2302] loss: 1.107429215727399\n",
      "[EPOCH #22, step #2304] loss: 1.1072496994327827\n",
      "[EPOCH #22, step #2306] loss: 1.10712750216661\n",
      "[EPOCH #22, step #2308] loss: 1.1072714907129693\n",
      "[EPOCH #22, step #2310] loss: 1.1075324322149795\n",
      "[EPOCH #22, step #2312] loss: 1.107965996873054\n",
      "[EPOCH #22, step #2314] loss: 1.1080299050581377\n",
      "[EPOCH #22, step #2316] loss: 1.1080962483950818\n",
      "[EPOCH #22, step #2318] loss: 1.1080804320567124\n",
      "[EPOCH #22, step #2320] loss: 1.1081701956885173\n",
      "[EPOCH #22, step #2322] loss: 1.1082029554718689\n",
      "[EPOCH #22, step #2324] loss: 1.1079689421320473\n",
      "[EPOCH #22, step #2326] loss: 1.108068597088774\n",
      "[EPOCH #22, step #2328] loss: 1.1078863567858614\n",
      "[EPOCH #22, step #2330] loss: 1.1078700954210394\n",
      "[EPOCH #22, step #2332] loss: 1.1078442262443309\n",
      "[EPOCH #22, step #2334] loss: 1.1079495102613846\n",
      "[EPOCH #22, step #2336] loss: 1.1078953351100185\n",
      "[EPOCH #22, step #2338] loss: 1.1078414080004348\n",
      "[EPOCH #22, step #2340] loss: 1.1079583735687006\n",
      "[EPOCH #22, step #2342] loss: 1.1079784447929057\n",
      "[EPOCH #22, step #2344] loss: 1.1078350421080965\n",
      "[EPOCH #22, step #2346] loss: 1.1078294897186132\n",
      "[EPOCH #22, step #2348] loss: 1.1078835188479768\n",
      "[EPOCH #22, step #2350] loss: 1.1076245077591356\n",
      "[EPOCH #22, step #2352] loss: 1.1076304780210884\n",
      "[EPOCH #22, step #2354] loss: 1.1072099214526498\n",
      "[EPOCH #22, step #2356] loss: 1.1071152681382874\n",
      "[EPOCH #22, step #2358] loss: 1.1070313918459158\n",
      "[EPOCH #22, step #2360] loss: 1.1071988684375726\n",
      "[EPOCH #22, step #2362] loss: 1.1072135481524659\n",
      "[EPOCH #22, step #2364] loss: 1.107196290057003\n",
      "[EPOCH #22, step #2366] loss: 1.1070881430917416\n",
      "[EPOCH #22, step #2368] loss: 1.1067887522868338\n",
      "[EPOCH #22, step #2370] loss: 1.1068733786415421\n",
      "[EPOCH #22, step #2372] loss: 1.1066808591424488\n",
      "[EPOCH #22, step #2374] loss: 1.1066035556165796\n",
      "[EPOCH #22, step #2376] loss: 1.1065758897895115\n",
      "[EPOCH #22, step #2378] loss: 1.1066026513368055\n",
      "[EPOCH #22, step #2380] loss: 1.1067108949384286\n",
      "[EPOCH #22, step #2382] loss: 1.10666904976475\n",
      "[EPOCH #22, step #2384] loss: 1.106584764064233\n",
      "[EPOCH #22, step #2386] loss: 1.1066467816803711\n",
      "[EPOCH #22, step #2388] loss: 1.1064986572224709\n",
      "[EPOCH #22, step #2390] loss: 1.1064649193494303\n",
      "[EPOCH #22, step #2392] loss: 1.106245556624425\n",
      "[EPOCH #22, step #2394] loss: 1.1067931777873468\n",
      "[EPOCH #22, step #2396] loss: 1.10684558033048\n",
      "[EPOCH #22, step #2398] loss: 1.1066452002043325\n",
      "[EPOCH #22, step #2400] loss: 1.106783704390778\n",
      "[EPOCH #22, step #2402] loss: 1.1068373332780648\n",
      "[EPOCH #22, step #2404] loss: 1.1066595232784129\n",
      "[EPOCH #22, step #2406] loss: 1.1066073763281368\n",
      "[EPOCH #22, step #2408] loss: 1.106634387600318\n",
      "[EPOCH #22, step #2410] loss: 1.106414022521328\n",
      "[EPOCH #22, step #2412] loss: 1.106332266214622\n",
      "[EPOCH #22, step #2414] loss: 1.10637420116004\n",
      "[EPOCH #22, step #2416] loss: 1.10621720784254\n",
      "[EPOCH #22, step #2418] loss: 1.1062128209979045\n",
      "[EPOCH #22, step #2420] loss: 1.1060340374228088\n",
      "[EPOCH #22, step #2422] loss: 1.1060322421029043\n",
      "[EPOCH #22, step #2424] loss: 1.106171200373738\n",
      "[EPOCH #22, step #2426] loss: 1.1060545349199682\n",
      "[EPOCH #22, step #2428] loss: 1.1059192364330692\n",
      "[EPOCH #22, step #2430] loss: 1.1058225409085247\n",
      "[EPOCH #22, step #2432] loss: 1.1057450691711936\n",
      "[EPOCH #22, step #2434] loss: 1.1056309166874974\n",
      "[EPOCH #22, step #2436] loss: 1.1055575354108078\n",
      "[EPOCH #22, step #2438] loss: 1.1054942674351402\n",
      "[EPOCH #22, step #2440] loss: 1.1055185412930837\n",
      "[EPOCH #22, step #2442] loss: 1.1052610176877316\n",
      "[EPOCH #22, step #2444] loss: 1.1051123450870164\n",
      "[EPOCH #22, step #2446] loss: 1.104908187631982\n",
      "[EPOCH #22, step #2448] loss: 1.1051502780750753\n",
      "[EPOCH #22, step #2450] loss: 1.105188769255303\n",
      "[EPOCH #22, step #2452] loss: 1.1050915196629092\n",
      "[EPOCH #22, step #2454] loss: 1.1051503301395176\n",
      "[EPOCH #22, step #2456] loss: 1.1052595419179243\n",
      "[EPOCH #22, step #2458] loss: 1.1050528898235257\n",
      "[EPOCH #22, step #2460] loss: 1.1051964930333242\n",
      "[EPOCH #22, step #2462] loss: 1.105285382299853\n",
      "[EPOCH #22, step #2464] loss: 1.1052630430786412\n",
      "[EPOCH #22, step #2466] loss: 1.1053061232810375\n",
      "[EPOCH #22, step #2468] loss: 1.1053517956200665\n",
      "[EPOCH #22, step #2470] loss: 1.1051533564967406\n",
      "[EPOCH #22, step #2472] loss: 1.1050865419037275\n",
      "[EPOCH #22, step #2474] loss: 1.10495889365071\n",
      "[EPOCH #22, step #2476] loss: 1.1050761445761208\n",
      "[EPOCH #22, step #2478] loss: 1.1050284084844801\n",
      "[EPOCH #22, step #2480] loss: 1.104851018849134\n",
      "[EPOCH #22, step #2482] loss: 1.1047758691453953\n",
      "[EPOCH #22, step #2484] loss: 1.1046496891159887\n",
      "[EPOCH #22, step #2486] loss: 1.1046188634995913\n",
      "[EPOCH #22, step #2488] loss: 1.104496843702777\n",
      "[EPOCH #22, step #2490] loss: 1.1049640039419468\n",
      "[EPOCH #22, step #2492] loss: 1.1049913244222571\n",
      "[EPOCH #22, step #2494] loss: 1.1050102577180805\n",
      "[EPOCH #22, step #2496] loss: 1.1049828569699058\n",
      "[EPOCH #22, step #2498] loss: 1.1049096142353654\n",
      "[EPOCH #22, elapsed time: 11146.506[sec]] loss: 1.105029723906517\n",
      "[EPOCH #23, step #0] loss: 0.7681272029876709\n",
      "[EPOCH #23, step #2] loss: 0.8685645461082458\n",
      "[EPOCH #23, step #4] loss: 0.9901327967643738\n",
      "[EPOCH #23, step #6] loss: 0.9712531651769366\n",
      "[EPOCH #23, step #8] loss: 0.9559747841623094\n",
      "[EPOCH #23, step #10] loss: 1.0130542245778171\n",
      "[EPOCH #23, step #12] loss: 1.0047151171244109\n",
      "[EPOCH #23, step #14] loss: 1.0049983660380046\n",
      "[EPOCH #23, step #16] loss: 0.998679006800932\n",
      "[EPOCH #23, step #18] loss: 1.019376842599166\n",
      "[EPOCH #23, step #20] loss: 0.989625388667697\n",
      "[EPOCH #23, step #22] loss: 0.9893891293069591\n",
      "[EPOCH #23, step #24] loss: 1.0096417713165282\n",
      "[EPOCH #23, step #26] loss: 0.9927467085697033\n",
      "[EPOCH #23, step #28] loss: 0.9951265618718904\n",
      "[EPOCH #23, step #30] loss: 0.9945442830362627\n",
      "[EPOCH #23, step #32] loss: 0.9808658379496951\n",
      "[EPOCH #23, step #34] loss: 0.9834402731486729\n",
      "[EPOCH #23, step #36] loss: 0.9888800430942226\n",
      "[EPOCH #23, step #38] loss: 0.9911788350496537\n",
      "[EPOCH #23, step #40] loss: 0.9904984003160058\n",
      "[EPOCH #23, step #42] loss: 0.991451621055603\n",
      "[EPOCH #23, step #44] loss: 0.9936349815792508\n",
      "[EPOCH #23, step #46] loss: 0.9946300095700203\n",
      "[EPOCH #23, step #48] loss: 0.9976412945864152\n",
      "[EPOCH #23, step #50] loss: 1.0090961503047569\n",
      "[EPOCH #23, step #52] loss: 1.0049547328139252\n",
      "[EPOCH #23, step #54] loss: 1.0135991562496531\n",
      "[EPOCH #23, step #56] loss: 1.0090663903637935\n",
      "[EPOCH #23, step #58] loss: 1.0138663770788807\n",
      "[EPOCH #23, step #60] loss: 1.0091901665828267\n",
      "[EPOCH #23, step #62] loss: 1.0153220910874625\n",
      "[EPOCH #23, step #64] loss: 1.016630301108727\n",
      "[EPOCH #23, step #66] loss: 1.0218468886702807\n",
      "[EPOCH #23, step #68] loss: 1.0176735917727153\n",
      "[EPOCH #23, step #70] loss: 1.0121102014058072\n",
      "[EPOCH #23, step #72] loss: 1.0060723072861972\n",
      "[EPOCH #23, step #74] loss: 1.0087939707438152\n",
      "[EPOCH #23, step #76] loss: 1.0022373656173804\n",
      "[EPOCH #23, step #78] loss: 1.0009893707082242\n",
      "[EPOCH #23, step #80] loss: 1.005736665961183\n",
      "[EPOCH #23, step #82] loss: 1.0019064904695534\n",
      "[EPOCH #23, step #84] loss: 1.0019302094683928\n",
      "[EPOCH #23, step #86] loss: 1.0071511111040226\n",
      "[EPOCH #23, step #88] loss: 1.0088869460513084\n",
      "[EPOCH #23, step #90] loss: 1.0079150736986935\n",
      "[EPOCH #23, step #92] loss: 1.0020864535403509\n",
      "[EPOCH #23, step #94] loss: 1.0007440516823216\n",
      "[EPOCH #23, step #96] loss: 1.0003167378533746\n",
      "[EPOCH #23, step #98] loss: 0.9979128157249605\n",
      "[EPOCH #23, step #100] loss: 0.9996974385610902\n",
      "[EPOCH #23, step #102] loss: 1.0023877244551205\n",
      "[EPOCH #23, step #104] loss: 1.011029342810313\n",
      "[EPOCH #23, step #106] loss: 1.015577567514972\n",
      "[EPOCH #23, step #108] loss: 1.0128500663906062\n",
      "[EPOCH #23, step #110] loss: 1.0125415797706123\n",
      "[EPOCH #23, step #112] loss: 1.018545994716408\n",
      "[EPOCH #23, step #114] loss: 1.020468605082968\n",
      "[EPOCH #23, step #116] loss: 1.019844256914579\n",
      "[EPOCH #23, step #118] loss: 1.0203045721815414\n",
      "[EPOCH #23, step #120] loss: 1.0256193669374325\n",
      "[EPOCH #23, step #122] loss: 1.02823954869092\n",
      "[EPOCH #23, step #124] loss: 1.0264700336456298\n",
      "[EPOCH #23, step #126] loss: 1.0283907689447478\n",
      "[EPOCH #23, step #128] loss: 1.0284308805022129\n",
      "[EPOCH #23, step #130] loss: 1.0304101068554943\n",
      "[EPOCH #23, step #132] loss: 1.0333820169133352\n",
      "[EPOCH #23, step #134] loss: 1.0289370152685378\n",
      "[EPOCH #23, step #136] loss: 1.0316139820718417\n",
      "[EPOCH #23, step #138] loss: 1.0322758645462475\n",
      "[EPOCH #23, step #140] loss: 1.0344826875003517\n",
      "[EPOCH #23, step #142] loss: 1.032413604793015\n",
      "[EPOCH #23, step #144] loss: 1.0324550369690204\n",
      "[EPOCH #23, step #146] loss: 1.0311353453973524\n",
      "[EPOCH #23, step #148] loss: 1.0358255457558088\n",
      "[EPOCH #23, step #150] loss: 1.0342315080150073\n",
      "[EPOCH #23, step #152] loss: 1.0343655106288936\n",
      "[EPOCH #23, step #154] loss: 1.03708471867346\n",
      "[EPOCH #23, step #156] loss: 1.0364137929715929\n",
      "[EPOCH #23, step #158] loss: 1.0353755246168412\n",
      "[EPOCH #23, step #160] loss: 1.035543097472339\n",
      "[EPOCH #23, step #162] loss: 1.038490703500853\n",
      "[EPOCH #23, step #164] loss: 1.0401971564148411\n",
      "[EPOCH #23, step #166] loss: 1.0388353524093856\n",
      "[EPOCH #23, step #168] loss: 1.0360154862234578\n",
      "[EPOCH #23, step #170] loss: 1.0354533882169\n",
      "[EPOCH #23, step #172] loss: 1.0351992270160961\n",
      "[EPOCH #23, step #174] loss: 1.0361265349388122\n",
      "[EPOCH #23, step #176] loss: 1.0374524893060242\n",
      "[EPOCH #23, step #178] loss: 1.0401256054473322\n",
      "[EPOCH #23, step #180] loss: 1.0432310410626027\n",
      "[EPOCH #23, step #182] loss: 1.0440792083088817\n",
      "[EPOCH #23, step #184] loss: 1.0421607542682338\n",
      "[EPOCH #23, step #186] loss: 1.0396791919667454\n",
      "[EPOCH #23, step #188] loss: 1.0384328825763924\n",
      "[EPOCH #23, step #190] loss: 1.0394660225089307\n",
      "[EPOCH #23, step #192] loss: 1.0397015680303228\n",
      "[EPOCH #23, step #194] loss: 1.0399237944529607\n",
      "[EPOCH #23, step #196] loss: 1.0422630854669561\n",
      "[EPOCH #23, step #198] loss: 1.0438093354354552\n",
      "[EPOCH #23, step #200] loss: 1.0444135974295696\n",
      "[EPOCH #23, step #202] loss: 1.0465076662636743\n",
      "[EPOCH #23, step #204] loss: 1.0476968015112529\n",
      "[EPOCH #23, step #206] loss: 1.0447313583991378\n",
      "[EPOCH #23, step #208] loss: 1.039818511625226\n",
      "[EPOCH #23, step #210] loss: 1.037266991432244\n",
      "[EPOCH #23, step #212] loss: 1.0354219126589421\n",
      "[EPOCH #23, step #214] loss: 1.0339156023291654\n",
      "[EPOCH #23, step #216] loss: 1.0338590469228508\n",
      "[EPOCH #23, step #218] loss: 1.031213307217376\n",
      "[EPOCH #23, step #220] loss: 1.0323770523610698\n",
      "[EPOCH #23, step #222] loss: 1.0343719621944856\n",
      "[EPOCH #23, step #224] loss: 1.0329789903428819\n",
      "[EPOCH #23, step #226] loss: 1.0335683641454723\n",
      "[EPOCH #23, step #228] loss: 1.0332321816136223\n",
      "[EPOCH #23, step #230] loss: 1.0328847538857233\n",
      "[EPOCH #23, step #232] loss: 1.0370037885694545\n",
      "[EPOCH #23, step #234] loss: 1.0349276342290512\n",
      "[EPOCH #23, step #236] loss: 1.036629236951659\n",
      "[EPOCH #23, step #238] loss: 1.037430619594941\n",
      "[EPOCH #23, step #240] loss: 1.0397977898229702\n",
      "[EPOCH #23, step #242] loss: 1.0417993951726843\n",
      "[EPOCH #23, step #244] loss: 1.0420702272531936\n",
      "[EPOCH #23, step #246] loss: 1.041920934370172\n",
      "[EPOCH #23, step #248] loss: 1.0430310751539635\n",
      "[EPOCH #23, step #250] loss: 1.0447568097912459\n",
      "[EPOCH #23, step #252] loss: 1.0448832346987817\n",
      "[EPOCH #23, step #254] loss: 1.0461523995679967\n",
      "[EPOCH #23, step #256] loss: 1.0438118586280467\n",
      "[EPOCH #23, step #258] loss: 1.041914021876788\n",
      "[EPOCH #23, step #260] loss: 1.0427458816104465\n",
      "[EPOCH #23, step #262] loss: 1.0410832277722233\n",
      "[EPOCH #23, step #264] loss: 1.0400929311536393\n",
      "[EPOCH #23, step #266] loss: 1.0405344295591004\n",
      "[EPOCH #23, step #268] loss: 1.042029803791897\n",
      "[EPOCH #23, step #270] loss: 1.040171771031904\n",
      "[EPOCH #23, step #272] loss: 1.0395201745924059\n",
      "[EPOCH #23, step #274] loss: 1.0397952717000787\n",
      "[EPOCH #23, step #276] loss: 1.037940383387817\n",
      "[EPOCH #23, step #278] loss: 1.0395076071916942\n",
      "[EPOCH #23, step #280] loss: 1.0407505368422783\n",
      "[EPOCH #23, step #282] loss: 1.0414724229923829\n",
      "[EPOCH #23, step #284] loss: 1.040010328251019\n",
      "[EPOCH #23, step #286] loss: 1.038348851718969\n",
      "[EPOCH #23, step #288] loss: 1.0381543267144464\n",
      "[EPOCH #23, step #290] loss: 1.0377576742385262\n",
      "[EPOCH #23, step #292] loss: 1.0376066766908145\n",
      "[EPOCH #23, step #294] loss: 1.0359741273572889\n",
      "[EPOCH #23, step #296] loss: 1.0350749191611703\n",
      "[EPOCH #23, step #298] loss: 1.0351847468012552\n",
      "[EPOCH #23, step #300] loss: 1.0351681667704915\n",
      "[EPOCH #23, step #302] loss: 1.0343935294906692\n",
      "[EPOCH #23, step #304] loss: 1.033242902013122\n",
      "[EPOCH #23, step #306] loss: 1.032504786691759\n",
      "[EPOCH #23, step #308] loss: 1.0330396911858741\n",
      "[EPOCH #23, step #310] loss: 1.0317648382815516\n",
      "[EPOCH #23, step #312] loss: 1.032827396933644\n",
      "[EPOCH #23, step #314] loss: 1.0329283835395935\n",
      "[EPOCH #23, step #316] loss: 1.0340527818782097\n",
      "[EPOCH #23, step #318] loss: 1.034081257435969\n",
      "[EPOCH #23, step #320] loss: 1.0341926744422438\n",
      "[EPOCH #23, step #322] loss: 1.0337423776325427\n",
      "[EPOCH #23, step #324] loss: 1.033726096703456\n",
      "[EPOCH #23, step #326] loss: 1.0324526596871355\n",
      "[EPOCH #23, step #328] loss: 1.0331563777474284\n",
      "[EPOCH #23, step #330] loss: 1.031902924044975\n",
      "[EPOCH #23, step #332] loss: 1.0316175954477924\n",
      "[EPOCH #23, step #334] loss: 1.032320193924121\n",
      "[EPOCH #23, step #336] loss: 1.0332371684493227\n",
      "[EPOCH #23, step #338] loss: 1.0334538377843423\n",
      "[EPOCH #23, step #340] loss: 1.0345365083462332\n",
      "[EPOCH #23, step #342] loss: 1.0347219792468902\n",
      "[EPOCH #23, step #344] loss: 1.0341976341993913\n",
      "[EPOCH #23, step #346] loss: 1.0321875051393976\n",
      "[EPOCH #23, step #348] loss: 1.0321945997227229\n",
      "[EPOCH #23, step #350] loss: 1.030943726372515\n",
      "[EPOCH #23, step #352] loss: 1.0308612046430874\n",
      "[EPOCH #23, step #354] loss: 1.0301806468359183\n",
      "[EPOCH #23, step #356] loss: 1.030041723358197\n",
      "[EPOCH #23, step #358] loss: 1.030493671515526\n",
      "[EPOCH #23, step #360] loss: 1.0307437670197843\n",
      "[EPOCH #23, step #362] loss: 1.0309819575840449\n",
      "[EPOCH #23, step #364] loss: 1.0311044134505807\n",
      "[EPOCH #23, step #366] loss: 1.0324286414102248\n",
      "[EPOCH #23, step #368] loss: 1.032686641061209\n",
      "[EPOCH #23, step #370] loss: 1.034069388863854\n",
      "[EPOCH #23, step #372] loss: 1.0339883054549188\n",
      "[EPOCH #23, step #374] loss: 1.0338435842196148\n",
      "[EPOCH #23, step #376] loss: 1.0331540022351697\n",
      "[EPOCH #23, step #378] loss: 1.0331853640740025\n",
      "[EPOCH #23, step #380] loss: 1.0321142008611224\n",
      "[EPOCH #23, step #382] loss: 1.0328588342542124\n",
      "[EPOCH #23, step #384] loss: 1.0325437285683372\n",
      "[EPOCH #23, step #386] loss: 1.0333459666841098\n",
      "[EPOCH #23, step #388] loss: 1.033697665963504\n",
      "[EPOCH #23, step #390] loss: 1.0334613460409061\n",
      "[EPOCH #23, step #392] loss: 1.0327552748090438\n",
      "[EPOCH #23, step #394] loss: 1.033828767945495\n",
      "[EPOCH #23, step #396] loss: 1.03384150696041\n",
      "[EPOCH #23, step #398] loss: 1.0341396525987707\n",
      "[EPOCH #23, step #400] loss: 1.0343689908113265\n",
      "[EPOCH #23, step #402] loss: 1.0343668435702549\n",
      "[EPOCH #23, step #404] loss: 1.0331036527951558\n",
      "[EPOCH #23, step #406] loss: 1.0341051762754268\n",
      "[EPOCH #23, step #408] loss: 1.0355271647495279\n",
      "[EPOCH #23, step #410] loss: 1.0364697662583233\n",
      "[EPOCH #23, step #412] loss: 1.0360875070528026\n",
      "[EPOCH #23, step #414] loss: 1.0353692337691065\n",
      "[EPOCH #23, step #416] loss: 1.0340153289069947\n",
      "[EPOCH #23, step #418] loss: 1.0336375528133002\n",
      "[EPOCH #23, step #420] loss: 1.0337061161383314\n",
      "[EPOCH #23, step #422] loss: 1.034557977607628\n",
      "[EPOCH #23, step #424] loss: 1.0353727271977593\n",
      "[EPOCH #23, step #426] loss: 1.0357639539716395\n",
      "[EPOCH #23, step #428] loss: 1.0350210968153182\n",
      "[EPOCH #23, step #430] loss: 1.0346982766746644\n",
      "[EPOCH #23, step #432] loss: 1.0357971304283407\n",
      "[EPOCH #23, step #434] loss: 1.034896429242759\n",
      "[EPOCH #23, step #436] loss: 1.035464027789965\n",
      "[EPOCH #23, step #438] loss: 1.0339896965407023\n",
      "[EPOCH #23, step #440] loss: 1.0323531124867549\n",
      "[EPOCH #23, step #442] loss: 1.032703565151912\n",
      "[EPOCH #23, step #444] loss: 1.0320659716477554\n",
      "[EPOCH #23, step #446] loss: 1.0321300361780512\n",
      "[EPOCH #23, step #448] loss: 1.0321975145945306\n",
      "[EPOCH #23, step #450] loss: 1.0327677178277144\n",
      "[EPOCH #23, step #452] loss: 1.0341893025318256\n",
      "[EPOCH #23, step #454] loss: 1.034972951045403\n",
      "[EPOCH #23, step #456] loss: 1.034216853278471\n",
      "[EPOCH #23, step #458] loss: 1.0350467625007131\n",
      "[EPOCH #23, step #460] loss: 1.0359478854046984\n",
      "[EPOCH #23, step #462] loss: 1.0359216347883895\n",
      "[EPOCH #23, step #464] loss: 1.0364619256347738\n",
      "[EPOCH #23, step #466] loss: 1.0359490927332728\n",
      "[EPOCH #23, step #468] loss: 1.0358629965070467\n",
      "[EPOCH #23, step #470] loss: 1.035669057991854\n",
      "[EPOCH #23, step #472] loss: 1.0352688847586167\n",
      "[EPOCH #23, step #474] loss: 1.034139768826334\n",
      "[EPOCH #23, step #476] loss: 1.034813512421254\n",
      "[EPOCH #23, step #478] loss: 1.0357274231432874\n",
      "[EPOCH #23, step #480] loss: 1.0350234135520682\n",
      "[EPOCH #23, step #482] loss: 1.0354914646711408\n",
      "[EPOCH #23, step #484] loss: 1.0338665201491917\n",
      "[EPOCH #23, step #486] loss: 1.0333524025685978\n",
      "[EPOCH #23, step #488] loss: 1.0331648630842354\n",
      "[EPOCH #23, step #490] loss: 1.0329156956216226\n",
      "[EPOCH #23, step #492] loss: 1.0338812857322228\n",
      "[EPOCH #23, step #494] loss: 1.034534419305397\n",
      "[EPOCH #23, step #496] loss: 1.0346462691813647\n",
      "[EPOCH #23, step #498] loss: 1.0348921702476686\n",
      "[EPOCH #23, step #500] loss: 1.0336706340907815\n",
      "[EPOCH #23, step #502] loss: 1.0334524379572858\n",
      "[EPOCH #23, step #504] loss: 1.0334488081459952\n",
      "[EPOCH #23, step #506] loss: 1.0341520710339442\n",
      "[EPOCH #23, step #508] loss: 1.0341182611077615\n",
      "[EPOCH #23, step #510] loss: 1.033874227809346\n",
      "[EPOCH #23, step #512] loss: 1.035194569396229\n",
      "[EPOCH #23, step #514] loss: 1.0362958482168254\n",
      "[EPOCH #23, step #516] loss: 1.036502752820574\n",
      "[EPOCH #23, step #518] loss: 1.0371379050675615\n",
      "[EPOCH #23, step #520] loss: 1.0372494387077507\n",
      "[EPOCH #23, step #522] loss: 1.0387379713997558\n",
      "[EPOCH #23, step #524] loss: 1.040077250912076\n",
      "[EPOCH #23, step #526] loss: 1.040993114010885\n",
      "[EPOCH #23, step #528] loss: 1.0411241545794365\n",
      "[EPOCH #23, step #530] loss: 1.040927571877697\n",
      "[EPOCH #23, step #532] loss: 1.0403320543314234\n",
      "[EPOCH #23, step #534] loss: 1.039536041411284\n",
      "[EPOCH #23, step #536] loss: 1.0398040854509094\n",
      "[EPOCH #23, step #538] loss: 1.040540066853525\n",
      "[EPOCH #23, step #540] loss: 1.0397508923315517\n",
      "[EPOCH #23, step #542] loss: 1.0403476906305738\n",
      "[EPOCH #23, step #544] loss: 1.0410836721779009\n",
      "[EPOCH #23, step #546] loss: 1.0412353770824412\n",
      "[EPOCH #23, step #548] loss: 1.0412063524805566\n",
      "[EPOCH #23, step #550] loss: 1.0407540732200262\n",
      "[EPOCH #23, step #552] loss: 1.0413183110747588\n",
      "[EPOCH #23, step #554] loss: 1.0406274464753298\n",
      "[EPOCH #23, step #556] loss: 1.0403641776935844\n",
      "[EPOCH #23, step #558] loss: 1.0398030162710623\n",
      "[EPOCH #23, step #560] loss: 1.03984365828747\n",
      "[EPOCH #23, step #562] loss: 1.0400920623572638\n",
      "[EPOCH #23, step #564] loss: 1.0399515493781166\n",
      "[EPOCH #23, step #566] loss: 1.0399983326594036\n",
      "[EPOCH #23, step #568] loss: 1.0395071591350442\n",
      "[EPOCH #23, step #570] loss: 1.039690521364663\n",
      "[EPOCH #23, step #572] loss: 1.039014832199556\n",
      "[EPOCH #23, step #574] loss: 1.0384046803350033\n",
      "[EPOCH #23, step #576] loss: 1.038364635493148\n",
      "[EPOCH #23, step #578] loss: 1.0372637214850062\n",
      "[EPOCH #23, step #580] loss: 1.0370603304311454\n",
      "[EPOCH #23, step #582] loss: 1.0378060597498258\n",
      "[EPOCH #23, step #584] loss: 1.0367848679550693\n",
      "[EPOCH #23, step #586] loss: 1.0368958433401443\n",
      "[EPOCH #23, step #588] loss: 1.0358415270296948\n",
      "[EPOCH #23, step #590] loss: 1.0351793030796923\n",
      "[EPOCH #23, step #592] loss: 1.0355155237810607\n",
      "[EPOCH #23, step #594] loss: 1.03487532659739\n",
      "[EPOCH #23, step #596] loss: 1.034824612751678\n",
      "[EPOCH #23, step #598] loss: 1.0343205773571695\n",
      "[EPOCH #23, step #600] loss: 1.0341287501243108\n",
      "[EPOCH #23, step #602] loss: 1.0334114026074386\n",
      "[EPOCH #23, step #604] loss: 1.0323980709737983\n",
      "[EPOCH #23, step #606] loss: 1.0318412684530167\n",
      "[EPOCH #23, step #608] loss: 1.0327525733922698\n",
      "[EPOCH #23, step #610] loss: 1.0322277646408144\n",
      "[EPOCH #23, step #612] loss: 1.0321233065443365\n",
      "[EPOCH #23, step #614] loss: 1.0331688897396492\n",
      "[EPOCH #23, step #616] loss: 1.0333828066311161\n",
      "[EPOCH #23, step #618] loss: 1.0333442495404614\n",
      "[EPOCH #23, step #620] loss: 1.0347200215534695\n",
      "[EPOCH #23, step #622] loss: 1.033183750046199\n",
      "[EPOCH #23, step #624] loss: 1.0319902574539184\n",
      "[EPOCH #23, step #626] loss: 1.0312495908003294\n",
      "[EPOCH #23, step #628] loss: 1.03115338196057\n",
      "[EPOCH #23, step #630] loss: 1.031134269741938\n",
      "[EPOCH #23, step #632] loss: 1.0311859364475684\n",
      "[EPOCH #23, step #634] loss: 1.0314682780757665\n",
      "[EPOCH #23, step #636] loss: 1.0320357088484982\n",
      "[EPOCH #23, step #638] loss: 1.0318132518136258\n",
      "[EPOCH #23, step #640] loss: 1.0316620402607644\n",
      "[EPOCH #23, step #642] loss: 1.0315125253207946\n",
      "[EPOCH #23, step #644] loss: 1.0321093558803085\n",
      "[EPOCH #23, step #646] loss: 1.031809958230583\n",
      "[EPOCH #23, step #648] loss: 1.031744456208542\n",
      "[EPOCH #23, step #650] loss: 1.0309039889484324\n",
      "[EPOCH #23, step #652] loss: 1.030658538865459\n",
      "[EPOCH #23, step #654] loss: 1.031480439064157\n",
      "[EPOCH #23, step #656] loss: 1.030967391471703\n",
      "[EPOCH #23, step #658] loss: 1.0314087399673029\n",
      "[EPOCH #23, step #660] loss: 1.0312703722093182\n",
      "[EPOCH #23, step #662] loss: 1.03109863130755\n",
      "[EPOCH #23, step #664] loss: 1.0311140414915587\n",
      "[EPOCH #23, step #666] loss: 1.031558311995359\n",
      "[EPOCH #23, step #668] loss: 1.0316567346565035\n",
      "[EPOCH #23, step #670] loss: 1.0313355886722997\n",
      "[EPOCH #23, step #672] loss: 1.0317067607108055\n",
      "[EPOCH #23, step #674] loss: 1.031161048633081\n",
      "[EPOCH #23, step #676] loss: 1.0305543985201302\n",
      "[EPOCH #23, step #678] loss: 1.0309864204920094\n",
      "[EPOCH #23, step #680] loss: 1.0300924175373782\n",
      "[EPOCH #23, step #682] loss: 1.0298629045748258\n",
      "[EPOCH #23, step #684] loss: 1.0295133875669353\n",
      "[EPOCH #23, step #686] loss: 1.0301410613535447\n",
      "[EPOCH #23, step #688] loss: 1.030225148611041\n",
      "[EPOCH #23, step #690] loss: 1.0298428372864095\n",
      "[EPOCH #23, step #692] loss: 1.029305470325214\n",
      "[EPOCH #23, step #694] loss: 1.0296386763775092\n",
      "[EPOCH #23, step #696] loss: 1.03025338849002\n",
      "[EPOCH #23, step #698] loss: 1.0302113504795216\n",
      "[EPOCH #23, step #700] loss: 1.0295481454373767\n",
      "[EPOCH #23, step #702] loss: 1.0291522697652895\n",
      "[EPOCH #23, step #704] loss: 1.0296341627624863\n",
      "[EPOCH #23, step #706] loss: 1.0293755527517245\n",
      "[EPOCH #23, step #708] loss: 1.0291750347412523\n",
      "[EPOCH #23, step #710] loss: 1.0284272378255546\n",
      "[EPOCH #23, step #712] loss: 1.0271420080481204\n",
      "[EPOCH #23, step #714] loss: 1.027341638453357\n",
      "[EPOCH #23, step #716] loss: 1.0270155351115404\n",
      "[EPOCH #23, step #718] loss: 1.0271345758719967\n",
      "[EPOCH #23, step #720] loss: 1.0283244827170643\n",
      "[EPOCH #23, step #722] loss: 1.0274364920655061\n",
      "[EPOCH #23, step #724] loss: 1.0276752326817349\n",
      "[EPOCH #23, step #726] loss: 1.0273032524152832\n",
      "[EPOCH #23, step #728] loss: 1.0271604218518946\n",
      "[EPOCH #23, step #730] loss: 1.027099896838988\n",
      "[EPOCH #23, step #732] loss: 1.0267474941228292\n",
      "[EPOCH #23, step #734] loss: 1.027167485076554\n",
      "[EPOCH #23, step #736] loss: 1.0270301715408932\n",
      "[EPOCH #23, step #738] loss: 1.027606457310536\n",
      "[EPOCH #23, step #740] loss: 1.0280072103869096\n",
      "[EPOCH #23, step #742] loss: 1.0277321886165947\n",
      "[EPOCH #23, step #744] loss: 1.0279180325517718\n",
      "[EPOCH #23, step #746] loss: 1.0287074024977294\n",
      "[EPOCH #23, step #748] loss: 1.0280084181452624\n",
      "[EPOCH #23, step #750] loss: 1.0276480358783477\n",
      "[EPOCH #23, step #752] loss: 1.027710240081962\n",
      "[EPOCH #23, step #754] loss: 1.027517423211344\n",
      "[EPOCH #23, step #756] loss: 1.0274867977223592\n",
      "[EPOCH #23, step #758] loss: 1.0282296380899327\n",
      "[EPOCH #23, step #760] loss: 1.028188860486904\n",
      "[EPOCH #23, step #762] loss: 1.028377611585557\n",
      "[EPOCH #23, step #764] loss: 1.0285026754818711\n",
      "[EPOCH #23, step #766] loss: 1.0284893148647916\n",
      "[EPOCH #23, step #768] loss: 1.0288783215344806\n",
      "[EPOCH #23, step #770] loss: 1.0286089900480015\n",
      "[EPOCH #23, step #772] loss: 1.0283011313320594\n",
      "[EPOCH #23, step #774] loss: 1.0281835261083418\n",
      "[EPOCH #23, step #776] loss: 1.0286835124056926\n",
      "[EPOCH #23, step #778] loss: 1.0283536874666446\n",
      "[EPOCH #23, step #780] loss: 1.0285568388796646\n",
      "[EPOCH #23, step #782] loss: 1.0289553605200839\n",
      "[EPOCH #23, step #784] loss: 1.029219382773539\n",
      "[EPOCH #23, step #786] loss: 1.0294744205368822\n",
      "[EPOCH #23, step #788] loss: 1.0292731006411393\n",
      "[EPOCH #23, step #790] loss: 1.0289451597840085\n",
      "[EPOCH #23, step #792] loss: 1.0284074896295916\n",
      "[EPOCH #23, step #794] loss: 1.0287670153866775\n",
      "[EPOCH #23, step #796] loss: 1.0289831372770193\n",
      "[EPOCH #23, step #798] loss: 1.0290105344729967\n",
      "[EPOCH #23, step #800] loss: 1.0294649878170308\n",
      "[EPOCH #23, step #802] loss: 1.0292156046606684\n",
      "[EPOCH #23, step #804] loss: 1.0297128456349698\n",
      "[EPOCH #23, step #806] loss: 1.028974300460449\n",
      "[EPOCH #23, step #808] loss: 1.0289629919198888\n",
      "[EPOCH #23, step #810] loss: 1.0287338633793055\n",
      "[EPOCH #23, step #812] loss: 1.0285820767081826\n",
      "[EPOCH #23, step #814] loss: 1.0286648812103856\n",
      "[EPOCH #23, step #816] loss: 1.0283116201802887\n",
      "[EPOCH #23, step #818] loss: 1.0278924733072847\n",
      "[EPOCH #23, step #820] loss: 1.02857134856928\n",
      "[EPOCH #23, step #822] loss: 1.028315425607153\n",
      "[EPOCH #23, step #824] loss: 1.0281676416324848\n",
      "[EPOCH #23, step #826] loss: 1.0277452953565223\n",
      "[EPOCH #23, step #828] loss: 1.0281995032679185\n",
      "[EPOCH #23, step #830] loss: 1.0282159305293064\n",
      "[EPOCH #23, step #832] loss: 1.0280630337018497\n",
      "[EPOCH #23, step #834] loss: 1.027728446122415\n",
      "[EPOCH #23, step #836] loss: 1.0273883445644607\n",
      "[EPOCH #23, step #838] loss: 1.0266075748794838\n",
      "[EPOCH #23, step #840] loss: 1.0268781510459681\n",
      "[EPOCH #23, step #842] loss: 1.0273300639109537\n",
      "[EPOCH #23, step #844] loss: 1.027500071186991\n",
      "[EPOCH #23, step #846] loss: 1.0272012194607587\n",
      "[EPOCH #23, step #848] loss: 1.0266815349547405\n",
      "[EPOCH #23, step #850] loss: 1.0264910177954776\n",
      "[EPOCH #23, step #852] loss: 1.0270931895424864\n",
      "[EPOCH #23, step #854] loss: 1.0271060385899238\n",
      "[EPOCH #23, step #856] loss: 1.0265180941501604\n",
      "[EPOCH #23, step #858] loss: 1.0265726055754771\n",
      "[EPOCH #23, step #860] loss: 1.0269420792832191\n",
      "[EPOCH #23, step #862] loss: 1.027141442511615\n",
      "[EPOCH #23, step #864] loss: 1.0268344242448753\n",
      "[EPOCH #23, step #866] loss: 1.0267174915596413\n",
      "[EPOCH #23, step #868] loss: 1.0269259597818925\n",
      "[EPOCH #23, step #870] loss: 1.027383511841092\n",
      "[EPOCH #23, step #872] loss: 1.027928314804348\n",
      "[EPOCH #23, step #874] loss: 1.0282665170260838\n",
      "[EPOCH #23, step #876] loss: 1.0284585585072212\n",
      "[EPOCH #23, step #878] loss: 1.0286250313123066\n",
      "[EPOCH #23, step #880] loss: 1.0288692513199589\n",
      "[EPOCH #23, step #882] loss: 1.0282397560463081\n",
      "[EPOCH #23, step #884] loss: 1.027982151036882\n",
      "[EPOCH #23, step #886] loss: 1.0287922842526784\n",
      "[EPOCH #23, step #888] loss: 1.0288822767570933\n",
      "[EPOCH #23, step #890] loss: 1.028719033723996\n",
      "[EPOCH #23, step #892] loss: 1.0288932119878915\n",
      "[EPOCH #23, step #894] loss: 1.028344432868105\n",
      "[EPOCH #23, step #896] loss: 1.0281702570426159\n",
      "[EPOCH #23, step #898] loss: 1.0281599116935347\n",
      "[EPOCH #23, step #900] loss: 1.0282013100074743\n",
      "[EPOCH #23, step #902] loss: 1.0279735180890706\n",
      "[EPOCH #23, step #904] loss: 1.027727851749125\n",
      "[EPOCH #23, step #906] loss: 1.0278810682606934\n",
      "[EPOCH #23, step #908] loss: 1.028653177818974\n",
      "[EPOCH #23, step #910] loss: 1.0286431328917962\n",
      "[EPOCH #23, step #912] loss: 1.0282469996356234\n",
      "[EPOCH #23, step #914] loss: 1.0286782654908186\n",
      "[EPOCH #23, step #916] loss: 1.0287990785217078\n",
      "[EPOCH #23, step #918] loss: 1.0288358426716693\n",
      "[EPOCH #23, step #920] loss: 1.0291699474590479\n",
      "[EPOCH #23, step #922] loss: 1.0300521751783005\n",
      "[EPOCH #23, step #924] loss: 1.0299080067711908\n",
      "[EPOCH #23, step #926] loss: 1.0301334648327791\n",
      "[EPOCH #23, step #928] loss: 1.029879492502038\n",
      "[EPOCH #23, step #930] loss: 1.0293884496299588\n",
      "[EPOCH #23, step #932] loss: 1.029245478611156\n",
      "[EPOCH #23, step #934] loss: 1.0290617940260127\n",
      "[EPOCH #23, step #936] loss: 1.028795458400262\n",
      "[EPOCH #23, step #938] loss: 1.0285211960220744\n",
      "[EPOCH #23, step #940] loss: 1.027858640733358\n",
      "[EPOCH #23, step #942] loss: 1.0278652752507655\n",
      "[EPOCH #23, step #944] loss: 1.0284122512769447\n",
      "[EPOCH #23, step #946] loss: 1.0285291791654565\n",
      "[EPOCH #23, step #948] loss: 1.0281713668677026\n",
      "[EPOCH #23, step #950] loss: 1.0278177084293525\n",
      "[EPOCH #23, step #952] loss: 1.0272536112341526\n",
      "[EPOCH #23, step #954] loss: 1.027309288061102\n",
      "[EPOCH #23, step #956] loss: 1.0268703835199868\n",
      "[EPOCH #23, step #958] loss: 1.0266846625039177\n",
      "[EPOCH #23, step #960] loss: 1.0271660407363563\n",
      "[EPOCH #23, step #962] loss: 1.0276830084041644\n",
      "[EPOCH #23, step #964] loss: 1.0273925505462707\n",
      "[EPOCH #23, step #966] loss: 1.0275664687341592\n",
      "[EPOCH #23, step #968] loss: 1.0274525999838353\n",
      "[EPOCH #23, step #970] loss: 1.0275711383129615\n",
      "[EPOCH #23, step #972] loss: 1.0274541244171138\n",
      "[EPOCH #23, step #974] loss: 1.0275348186187254\n",
      "[EPOCH #23, step #976] loss: 1.0274623867006116\n",
      "[EPOCH #23, step #978] loss: 1.028121616215701\n",
      "[EPOCH #23, step #980] loss: 1.0277177100577728\n",
      "[EPOCH #23, step #982] loss: 1.028521308972901\n",
      "[EPOCH #23, step #984] loss: 1.028330283056056\n",
      "[EPOCH #23, step #986] loss: 1.0277619478127635\n",
      "[EPOCH #23, step #988] loss: 1.0279959311560023\n",
      "[EPOCH #23, step #990] loss: 1.0278416761656703\n",
      "[EPOCH #23, step #992] loss: 1.0280155824330397\n",
      "[EPOCH #23, step #994] loss: 1.0277454505913222\n",
      "[EPOCH #23, step #996] loss: 1.0278814141764683\n",
      "[EPOCH #23, step #998] loss: 1.0279662309883832\n",
      "[EPOCH #23, step #1000] loss: 1.0276462299066347\n",
      "[EPOCH #23, step #1002] loss: 1.0274112314609802\n",
      "[EPOCH #23, step #1004] loss: 1.0273813059970514\n",
      "[EPOCH #23, step #1006] loss: 1.0276028893022338\n",
      "[EPOCH #23, step #1008] loss: 1.0278548352841226\n",
      "[EPOCH #23, step #1010] loss: 1.0283210471817812\n",
      "[EPOCH #23, step #1012] loss: 1.0287389863219925\n",
      "[EPOCH #23, step #1014] loss: 1.0288251473105012\n",
      "[EPOCH #23, step #1016] loss: 1.028685731199756\n",
      "[EPOCH #23, step #1018] loss: 1.028664763969341\n",
      "[EPOCH #23, step #1020] loss: 1.0291339457035065\n",
      "[EPOCH #23, step #1022] loss: 1.0286934223983761\n",
      "[EPOCH #23, step #1024] loss: 1.0285581105802117\n",
      "[EPOCH #23, step #1026] loss: 1.0287589882631962\n",
      "[EPOCH #23, step #1028] loss: 1.0292857129731376\n",
      "[EPOCH #23, step #1030] loss: 1.0290698472385147\n",
      "[EPOCH #23, step #1032] loss: 1.0288555658740666\n",
      "[EPOCH #23, step #1034] loss: 1.0286007246821398\n",
      "[EPOCH #23, step #1036] loss: 1.0283406270217068\n",
      "[EPOCH #23, step #1038] loss: 1.0279714838315708\n",
      "[EPOCH #23, step #1040] loss: 1.0279671657726699\n",
      "[EPOCH #23, step #1042] loss: 1.0276992351016743\n",
      "[EPOCH #23, step #1044] loss: 1.0272949287480715\n",
      "[EPOCH #23, step #1046] loss: 1.0271346593825386\n",
      "[EPOCH #23, step #1048] loss: 1.0274303021660525\n",
      "[EPOCH #23, step #1050] loss: 1.0268135965437577\n",
      "[EPOCH #23, step #1052] loss: 1.026917808047953\n",
      "[EPOCH #23, step #1054] loss: 1.0271333310558897\n",
      "[EPOCH #23, step #1056] loss: 1.0269699899960827\n",
      "[EPOCH #23, step #1058] loss: 1.0271533260770964\n",
      "[EPOCH #23, step #1060] loss: 1.0267539894828024\n",
      "[EPOCH #23, step #1062] loss: 1.0271303306911088\n",
      "[EPOCH #23, step #1064] loss: 1.0272198090251063\n",
      "[EPOCH #23, step #1066] loss: 1.0270424660892272\n",
      "[EPOCH #23, step #1068] loss: 1.027348865823728\n",
      "[EPOCH #23, step #1070] loss: 1.0272202482577466\n",
      "[EPOCH #23, step #1072] loss: 1.0274842519517935\n",
      "[EPOCH #23, step #1074] loss: 1.0274259188840555\n",
      "[EPOCH #23, step #1076] loss: 1.0268297865364213\n",
      "[EPOCH #23, step #1078] loss: 1.02682033573399\n",
      "[EPOCH #23, step #1080] loss: 1.0268836409873592\n",
      "[EPOCH #23, step #1082] loss: 1.0267545179922275\n",
      "[EPOCH #23, step #1084] loss: 1.0266283370108098\n",
      "[EPOCH #23, step #1086] loss: 1.026878041171545\n",
      "[EPOCH #23, step #1088] loss: 1.0268159304275986\n",
      "[EPOCH #23, step #1090] loss: 1.0270114876773793\n",
      "[EPOCH #23, step #1092] loss: 1.027125544730175\n",
      "[EPOCH #23, step #1094] loss: 1.0273340611425164\n",
      "[EPOCH #23, step #1096] loss: 1.027188148271418\n",
      "[EPOCH #23, step #1098] loss: 1.0271095647336788\n",
      "[EPOCH #23, step #1100] loss: 1.0273141221335322\n",
      "[EPOCH #23, step #1102] loss: 1.027309492162867\n",
      "[EPOCH #23, step #1104] loss: 1.027068023201567\n",
      "[EPOCH #23, step #1106] loss: 1.0272558869654356\n",
      "[EPOCH #23, step #1108] loss: 1.0273067668228133\n",
      "[EPOCH #23, step #1110] loss: 1.0271684201476168\n",
      "[EPOCH #23, step #1112] loss: 1.0280157848991796\n",
      "[EPOCH #23, step #1114] loss: 1.0280961425047819\n",
      "[EPOCH #23, step #1116] loss: 1.0290268669463527\n",
      "[EPOCH #23, step #1118] loss: 1.0291320065018106\n",
      "[EPOCH #23, step #1120] loss: 1.0289569557457499\n",
      "[EPOCH #23, step #1122] loss: 1.0290159451197218\n",
      "[EPOCH #23, step #1124] loss: 1.0286888547208575\n",
      "[EPOCH #23, step #1126] loss: 1.0283034198191066\n",
      "[EPOCH #23, step #1128] loss: 1.0285804360656214\n",
      "[EPOCH #23, step #1130] loss: 1.0285921963994002\n",
      "[EPOCH #23, step #1132] loss: 1.0280054889468102\n",
      "[EPOCH #23, step #1134] loss: 1.027847226311982\n",
      "[EPOCH #23, step #1136] loss: 1.027606344867822\n",
      "[EPOCH #23, step #1138] loss: 1.027319858454109\n",
      "[EPOCH #23, step #1140] loss: 1.0268842220358636\n",
      "[EPOCH #23, step #1142] loss: 1.0268870814005118\n",
      "[EPOCH #23, step #1144] loss: 1.0273432947923002\n",
      "[EPOCH #23, step #1146] loss: 1.0280823882964765\n",
      "[EPOCH #23, step #1148] loss: 1.0285064596990796\n",
      "[EPOCH #23, step #1150] loss: 1.0287062073406399\n",
      "[EPOCH #23, step #1152] loss: 1.0286093560230805\n",
      "[EPOCH #23, step #1154] loss: 1.0286575343959776\n",
      "[EPOCH #23, step #1156] loss: 1.028770872381296\n",
      "[EPOCH #23, step #1158] loss: 1.0287455819977882\n",
      "[EPOCH #23, step #1160] loss: 1.0289557600052166\n",
      "[EPOCH #23, step #1162] loss: 1.0285084843379306\n",
      "[EPOCH #23, step #1164] loss: 1.0288080556454064\n",
      "[EPOCH #23, step #1166] loss: 1.0291235202024815\n",
      "[EPOCH #23, step #1168] loss: 1.0287575926966297\n",
      "[EPOCH #23, step #1170] loss: 1.0297630678426497\n",
      "[EPOCH #23, step #1172] loss: 1.0292514759510476\n",
      "[EPOCH #23, step #1174] loss: 1.0291864228502232\n",
      "[EPOCH #23, step #1176] loss: 1.0293986934823511\n",
      "[EPOCH #23, step #1178] loss: 1.029151575938436\n",
      "[EPOCH #23, step #1180] loss: 1.028971669610328\n",
      "[EPOCH #23, step #1182] loss: 1.02861979926227\n",
      "[EPOCH #23, step #1184] loss: 1.0289868310282502\n",
      "[EPOCH #23, step #1186] loss: 1.029293223173556\n",
      "[EPOCH #23, step #1188] loss: 1.0292645015818818\n",
      "[EPOCH #23, step #1190] loss: 1.0289137301627174\n",
      "[EPOCH #23, step #1192] loss: 1.0292053878407266\n",
      "[EPOCH #23, step #1194] loss: 1.0292260665524455\n",
      "[EPOCH #23, step #1196] loss: 1.0290768701480444\n",
      "[EPOCH #23, step #1198] loss: 1.0291368150780655\n",
      "[EPOCH #23, step #1200] loss: 1.0295128950121797\n",
      "[EPOCH #23, step #1202] loss: 1.0296949921849363\n",
      "[EPOCH #23, step #1204] loss: 1.0297108626217268\n",
      "[EPOCH #23, step #1206] loss: 1.0296141283761002\n",
      "[EPOCH #23, step #1208] loss: 1.0295767228252342\n",
      "[EPOCH #23, step #1210] loss: 1.0296109192485556\n",
      "[EPOCH #23, step #1212] loss: 1.0300455778616082\n",
      "[EPOCH #23, step #1214] loss: 1.0304543369836767\n",
      "[EPOCH #23, step #1216] loss: 1.0304026389915433\n",
      "[EPOCH #23, step #1218] loss: 1.0304876012182118\n",
      "[EPOCH #23, step #1220] loss: 1.0307728610353133\n",
      "[EPOCH #23, step #1222] loss: 1.0307308955701373\n",
      "[EPOCH #23, step #1224] loss: 1.0305781683873156\n",
      "[EPOCH #23, step #1226] loss: 1.0306220865142763\n",
      "[EPOCH #23, step #1228] loss: 1.030954098318339\n",
      "[EPOCH #23, step #1230] loss: 1.0310929197058456\n",
      "[EPOCH #23, step #1232] loss: 1.0315068665067064\n",
      "[EPOCH #23, step #1234] loss: 1.0316895240472879\n",
      "[EPOCH #23, step #1236] loss: 1.031799415064706\n",
      "[EPOCH #23, step #1238] loss: 1.0321601126778983\n",
      "[EPOCH #23, step #1240] loss: 1.0319207939142954\n",
      "[EPOCH #23, step #1242] loss: 1.0320347955844522\n",
      "[EPOCH #23, step #1244] loss: 1.0320512287827381\n",
      "[EPOCH #23, step #1246] loss: 1.0319670568061239\n",
      "[EPOCH #23, step #1248] loss: 1.032079634592951\n",
      "[EPOCH #23, step #1250] loss: 1.032741901280878\n",
      "[EPOCH #23, step #1252] loss: 1.032938800877033\n",
      "[EPOCH #23, step #1254] loss: 1.0328812291660157\n",
      "[EPOCH #23, step #1256] loss: 1.0329277020602732\n",
      "[EPOCH #23, step #1258] loss: 1.0337725899776264\n",
      "[EPOCH #23, step #1260] loss: 1.0336687228067067\n",
      "[EPOCH #23, step #1262] loss: 1.0340116221991589\n",
      "[EPOCH #23, step #1264] loss: 1.0342131095677025\n",
      "[EPOCH #23, step #1266] loss: 1.0340750188976173\n",
      "[EPOCH #23, step #1268] loss: 1.0337430142200867\n",
      "[EPOCH #23, step #1270] loss: 1.0340137685451989\n",
      "[EPOCH #23, step #1272] loss: 1.0338538632042653\n",
      "[EPOCH #23, step #1274] loss: 1.0336391603011712\n",
      "[EPOCH #23, step #1276] loss: 1.033820352310675\n",
      "[EPOCH #23, step #1278] loss: 1.0342408644910712\n",
      "[EPOCH #23, step #1280] loss: 1.0346817553136425\n",
      "[EPOCH #23, step #1282] loss: 1.0350533276680198\n",
      "[EPOCH #23, step #1284] loss: 1.035049069971426\n",
      "[EPOCH #23, step #1286] loss: 1.0346675331081265\n",
      "[EPOCH #23, step #1288] loss: 1.0346530978535384\n",
      "[EPOCH #23, step #1290] loss: 1.0347073088543624\n",
      "[EPOCH #23, step #1292] loss: 1.03441360505256\n",
      "[EPOCH #23, step #1294] loss: 1.034216800044402\n",
      "[EPOCH #23, step #1296] loss: 1.034159411603704\n",
      "[EPOCH #23, step #1298] loss: 1.0339402774602657\n",
      "[EPOCH #23, step #1300] loss: 1.0339236966148877\n",
      "[EPOCH #23, step #1302] loss: 1.0345055239299399\n",
      "[EPOCH #23, step #1304] loss: 1.0341427035487019\n",
      "[EPOCH #23, step #1306] loss: 1.0337979145741407\n",
      "[EPOCH #23, step #1308] loss: 1.0336055485368048\n",
      "[EPOCH #23, step #1310] loss: 1.0335503989144375\n",
      "[EPOCH #23, step #1312] loss: 1.0337803014933564\n",
      "[EPOCH #23, step #1314] loss: 1.0334795029897654\n",
      "[EPOCH #23, step #1316] loss: 1.0334572293311244\n",
      "[EPOCH #23, step #1318] loss: 1.0331640725247873\n",
      "[EPOCH #23, step #1320] loss: 1.0329549074353457\n",
      "[EPOCH #23, step #1322] loss: 1.0328766886519376\n",
      "[EPOCH #23, step #1324] loss: 1.0325404042567847\n",
      "[EPOCH #23, step #1326] loss: 1.0326304128049637\n",
      "[EPOCH #23, step #1328] loss: 1.032876347087217\n",
      "[EPOCH #23, step #1330] loss: 1.032734897331937\n",
      "[EPOCH #23, step #1332] loss: 1.032259376489034\n",
      "[EPOCH #23, step #1334] loss: 1.0319408051083596\n",
      "[EPOCH #23, step #1336] loss: 1.0317971054617825\n",
      "[EPOCH #23, step #1338] loss: 1.0316362397896879\n",
      "[EPOCH #23, step #1340] loss: 1.0317469731273268\n",
      "[EPOCH #23, step #1342] loss: 1.0318867509611844\n",
      "[EPOCH #23, step #1344] loss: 1.0318397485190607\n",
      "[EPOCH #23, step #1346] loss: 1.0321165477689673\n",
      "[EPOCH #23, step #1348] loss: 1.0321297087520913\n",
      "[EPOCH #23, step #1350] loss: 1.0322038229088886\n",
      "[EPOCH #23, step #1352] loss: 1.0322291563373094\n",
      "[EPOCH #23, step #1354] loss: 1.0321372193164051\n",
      "[EPOCH #23, step #1356] loss: 1.0319015346385139\n",
      "[EPOCH #23, step #1358] loss: 1.0320297345420382\n",
      "[EPOCH #23, step #1360] loss: 1.0319766225313807\n",
      "[EPOCH #23, step #1362] loss: 1.0323321351826584\n",
      "[EPOCH #23, step #1364] loss: 1.032110753207853\n",
      "[EPOCH #23, step #1366] loss: 1.0322370278460316\n",
      "[EPOCH #23, step #1368] loss: 1.0321256871028395\n",
      "[EPOCH #23, step #1370] loss: 1.0322651426171316\n",
      "[EPOCH #23, step #1372] loss: 1.0325379293067387\n",
      "[EPOCH #23, step #1374] loss: 1.0330369979251515\n",
      "[EPOCH #23, step #1376] loss: 1.0327730150264334\n",
      "[EPOCH #23, step #1378] loss: 1.0326347542120289\n",
      "[EPOCH #23, step #1380] loss: 1.0329260266750813\n",
      "[EPOCH #23, step #1382] loss: 1.03284066221633\n",
      "[EPOCH #23, step #1384] loss: 1.0329364951767215\n",
      "[EPOCH #23, step #1386] loss: 1.0335043785205915\n",
      "[EPOCH #23, step #1388] loss: 1.0332910563981816\n",
      "[EPOCH #23, step #1390] loss: 1.0333602020502262\n",
      "[EPOCH #23, step #1392] loss: 1.032908392525883\n",
      "[EPOCH #23, step #1394] loss: 1.0331952892751248\n",
      "[EPOCH #23, step #1396] loss: 1.0328919875596196\n",
      "[EPOCH #23, step #1398] loss: 1.0330758092231287\n",
      "[EPOCH #23, step #1400] loss: 1.0332366012403746\n",
      "[EPOCH #23, step #1402] loss: 1.0330236357446236\n",
      "[EPOCH #23, step #1404] loss: 1.0330721075848752\n",
      "[EPOCH #23, step #1406] loss: 1.0329572335997623\n",
      "[EPOCH #23, step #1408] loss: 1.032980861521681\n",
      "[EPOCH #23, step #1410] loss: 1.0330136755862869\n",
      "[EPOCH #23, step #1412] loss: 1.0329296186471442\n",
      "[EPOCH #23, step #1414] loss: 1.0329065574352818\n",
      "[EPOCH #23, step #1416] loss: 1.032768697114418\n",
      "[EPOCH #23, step #1418] loss: 1.0326774975546151\n",
      "[EPOCH #23, step #1420] loss: 1.0325242653856137\n",
      "[EPOCH #23, step #1422] loss: 1.0320348397410426\n",
      "[EPOCH #23, step #1424] loss: 1.0318935489654542\n",
      "[EPOCH #23, step #1426] loss: 1.0317926790301584\n",
      "[EPOCH #23, step #1428] loss: 1.0318677602655157\n",
      "[EPOCH #23, step #1430] loss: 1.0316638738687516\n",
      "[EPOCH #23, step #1432] loss: 1.031742503197145\n",
      "[EPOCH #23, step #1434] loss: 1.0317622926592411\n",
      "[EPOCH #23, step #1436] loss: 1.0321404769674472\n",
      "[EPOCH #23, step #1438] loss: 1.0324766378256909\n",
      "[EPOCH #23, step #1440] loss: 1.032589730994723\n",
      "[EPOCH #23, step #1442] loss: 1.0324038162218228\n",
      "[EPOCH #23, step #1444] loss: 1.0322581676050866\n",
      "[EPOCH #23, step #1446] loss: 1.0325334061815068\n",
      "[EPOCH #23, step #1448] loss: 1.03218084133601\n",
      "[EPOCH #23, step #1450] loss: 1.0321047342209715\n",
      "[EPOCH #23, step #1452] loss: 1.0319468178424192\n",
      "[EPOCH #23, step #1454] loss: 1.0317437282952246\n",
      "[EPOCH #23, step #1456] loss: 1.032044331178161\n",
      "[EPOCH #23, step #1458] loss: 1.0320458866865199\n",
      "[EPOCH #23, step #1460] loss: 1.0322390582200847\n",
      "[EPOCH #23, step #1462] loss: 1.0319645823229688\n",
      "[EPOCH #23, step #1464] loss: 1.0318530282876597\n",
      "[EPOCH #23, step #1466] loss: 1.0316538536069177\n",
      "[EPOCH #23, step #1468] loss: 1.03131870642416\n",
      "[EPOCH #23, step #1470] loss: 1.0313301725423232\n",
      "[EPOCH #23, step #1472] loss: 1.0312000350408301\n",
      "[EPOCH #23, step #1474] loss: 1.0315742505606957\n",
      "[EPOCH #23, step #1476] loss: 1.031689452172617\n",
      "[EPOCH #23, step #1478] loss: 1.0314815003699431\n",
      "[EPOCH #23, step #1480] loss: 1.0314070381158755\n",
      "[EPOCH #23, step #1482] loss: 1.0316832433338512\n",
      "[EPOCH #23, step #1484] loss: 1.0315528479088034\n",
      "[EPOCH #23, step #1486] loss: 1.031477920465527\n",
      "[EPOCH #23, step #1488] loss: 1.031613665590997\n",
      "[EPOCH #23, step #1490] loss: 1.0313741208561948\n",
      "[EPOCH #23, step #1492] loss: 1.0316858355502354\n",
      "[EPOCH #23, step #1494] loss: 1.0316554455454134\n",
      "[EPOCH #23, step #1496] loss: 1.0319540384377968\n",
      "[EPOCH #23, step #1498] loss: 1.0319573633109353\n",
      "[EPOCH #23, step #1500] loss: 1.0322142280712674\n",
      "[EPOCH #23, step #1502] loss: 1.0324735190578087\n",
      "[EPOCH #23, step #1504] loss: 1.032614908067887\n",
      "[EPOCH #23, step #1506] loss: 1.032401284320353\n",
      "[EPOCH #23, step #1508] loss: 1.0323665951402714\n",
      "[EPOCH #23, step #1510] loss: 1.0320706210887487\n",
      "[EPOCH #23, step #1512] loss: 1.0322087695483568\n",
      "[EPOCH #23, step #1514] loss: 1.0325787850732457\n",
      "[EPOCH #23, step #1516] loss: 1.0324250592867952\n",
      "[EPOCH #23, step #1518] loss: 1.032624332311516\n",
      "[EPOCH #23, step #1520] loss: 1.0327432649375419\n",
      "[EPOCH #23, step #1522] loss: 1.032707113109759\n",
      "[EPOCH #23, step #1524] loss: 1.0325206608850448\n",
      "[EPOCH #23, step #1526] loss: 1.032510946604186\n",
      "[EPOCH #23, step #1528] loss: 1.032412688976959\n",
      "[EPOCH #23, step #1530] loss: 1.0320993929342224\n",
      "[EPOCH #23, step #1532] loss: 1.0321815916314594\n",
      "[EPOCH #23, step #1534] loss: 1.0319997187157794\n",
      "[EPOCH #23, step #1536] loss: 1.0317124549878753\n",
      "[EPOCH #23, step #1538] loss: 1.031845046956482\n",
      "[EPOCH #23, step #1540] loss: 1.0316458397450035\n",
      "[EPOCH #23, step #1542] loss: 1.0315658017867428\n",
      "[EPOCH #23, step #1544] loss: 1.0314150211494717\n",
      "[EPOCH #23, step #1546] loss: 1.0311594853959087\n",
      "[EPOCH #23, step #1548] loss: 1.0311541678137437\n",
      "[EPOCH #23, step #1550] loss: 1.0311820689975486\n",
      "[EPOCH #23, step #1552] loss: 1.0309737520070514\n",
      "[EPOCH #23, step #1554] loss: 1.0307606446781343\n",
      "[EPOCH #23, step #1556] loss: 1.03078827600718\n",
      "[EPOCH #23, step #1558] loss: 1.0310622874248325\n",
      "[EPOCH #23, step #1560] loss: 1.0310674763733878\n",
      "[EPOCH #23, step #1562] loss: 1.0305640832094984\n",
      "[EPOCH #23, step #1564] loss: 1.0304305809755294\n",
      "[EPOCH #23, step #1566] loss: 1.0305706585526238\n",
      "[EPOCH #23, step #1568] loss: 1.0307825191754911\n",
      "[EPOCH #23, step #1570] loss: 1.0307462696889493\n",
      "[EPOCH #23, step #1572] loss: 1.0305438143617396\n",
      "[EPOCH #23, step #1574] loss: 1.0304700591450646\n",
      "[EPOCH #23, step #1576] loss: 1.030240503987256\n",
      "[EPOCH #23, step #1578] loss: 1.030081406245132\n",
      "[EPOCH #23, step #1580] loss: 1.0299241746776395\n",
      "[EPOCH #23, step #1582] loss: 1.0302039401785754\n",
      "[EPOCH #23, step #1584] loss: 1.0301994447452414\n",
      "[EPOCH #23, step #1586] loss: 1.0304523778172057\n",
      "[EPOCH #23, step #1588] loss: 1.0304984517109477\n",
      "[EPOCH #23, step #1590] loss: 1.0303750977360326\n",
      "[EPOCH #23, step #1592] loss: 1.0302616426649889\n",
      "[EPOCH #23, step #1594] loss: 1.0305183624025422\n",
      "[EPOCH #23, step #1596] loss: 1.0306646078545076\n",
      "[EPOCH #23, step #1598] loss: 1.0305145594237222\n",
      "[EPOCH #23, step #1600] loss: 1.0305599802214975\n",
      "[EPOCH #23, step #1602] loss: 1.0304919708466722\n",
      "[EPOCH #23, step #1604] loss: 1.0307095398784054\n",
      "[EPOCH #23, step #1606] loss: 1.0305361220683826\n",
      "[EPOCH #23, step #1608] loss: 1.0302986020327651\n",
      "[EPOCH #23, step #1610] loss: 1.0306604956707401\n",
      "[EPOCH #23, step #1612] loss: 1.0308002564970633\n",
      "[EPOCH #23, step #1614] loss: 1.0307921277849297\n",
      "[EPOCH #23, step #1616] loss: 1.0307615504415226\n",
      "[EPOCH #23, step #1618] loss: 1.0304750969853205\n",
      "[EPOCH #23, step #1620] loss: 1.0300645544748113\n",
      "[EPOCH #23, step #1622] loss: 1.0298545936045644\n",
      "[EPOCH #23, step #1624] loss: 1.0297809128027695\n",
      "[EPOCH #23, step #1626] loss: 1.0298856885138654\n",
      "[EPOCH #23, step #1628] loss: 1.0299406505714097\n",
      "[EPOCH #23, step #1630] loss: 1.0299815294349361\n",
      "[EPOCH #23, step #1632] loss: 1.0298564657432057\n",
      "[EPOCH #23, step #1634] loss: 1.0299007136158258\n",
      "[EPOCH #23, step #1636] loss: 1.0300179938754441\n",
      "[EPOCH #23, step #1638] loss: 1.029715356810781\n",
      "[EPOCH #23, step #1640] loss: 1.0296687333413843\n",
      "[EPOCH #23, step #1642] loss: 1.0294315777242873\n",
      "[EPOCH #23, step #1644] loss: 1.029302597335769\n",
      "[EPOCH #23, step #1646] loss: 1.0292576462410403\n",
      "[EPOCH #23, step #1648] loss: 1.0290295679038621\n",
      "[EPOCH #23, step #1650] loss: 1.0287983670587038\n",
      "[EPOCH #23, step #1652] loss: 1.028541172156533\n",
      "[EPOCH #23, step #1654] loss: 1.028428638917802\n",
      "[EPOCH #23, step #1656] loss: 1.0284309121737945\n",
      "[EPOCH #23, step #1658] loss: 1.028959894769518\n",
      "[EPOCH #23, step #1660] loss: 1.0290015679321542\n",
      "[EPOCH #23, step #1662] loss: 1.0290757349938136\n",
      "[EPOCH #23, step #1664] loss: 1.028905847838691\n",
      "[EPOCH #23, step #1666] loss: 1.0285693958768176\n",
      "[EPOCH #23, step #1668] loss: 1.0285782473683\n",
      "[EPOCH #23, step #1670] loss: 1.028902452517098\n",
      "[EPOCH #23, step #1672] loss: 1.0288478215868004\n",
      "[EPOCH #23, step #1674] loss: 1.0289373032014761\n",
      "[EPOCH #23, step #1676] loss: 1.0286684788687996\n",
      "[EPOCH #23, step #1678] loss: 1.0288023422203154\n",
      "[EPOCH #23, step #1680] loss: 1.0288095983063303\n",
      "[EPOCH #23, step #1682] loss: 1.0288575260113622\n",
      "[EPOCH #23, step #1684] loss: 1.0289104342106896\n",
      "[EPOCH #23, step #1686] loss: 1.028541540527174\n",
      "[EPOCH #23, step #1688] loss: 1.028859952168044\n",
      "[EPOCH #23, step #1690] loss: 1.0288600322412076\n",
      "[EPOCH #23, step #1692] loss: 1.0285990192069152\n",
      "[EPOCH #23, step #1694] loss: 1.028307230247509\n",
      "[EPOCH #23, step #1696] loss: 1.0283855010849206\n",
      "[EPOCH #23, step #1698] loss: 1.028671221707834\n",
      "[EPOCH #23, step #1700] loss: 1.0284595635272278\n",
      "[EPOCH #23, step #1702] loss: 1.0285037245669229\n",
      "[EPOCH #23, step #1704] loss: 1.0290458570127963\n",
      "[EPOCH #23, step #1706] loss: 1.0288958240826367\n",
      "[EPOCH #23, step #1708] loss: 1.028889900344795\n",
      "[EPOCH #23, step #1710] loss: 1.0291255621238455\n",
      "[EPOCH #23, step #1712] loss: 1.0291315617090906\n",
      "[EPOCH #23, step #1714] loss: 1.0293965052585212\n",
      "[EPOCH #23, step #1716] loss: 1.0294196045044626\n",
      "[EPOCH #23, step #1718] loss: 1.029363304324591\n",
      "[EPOCH #23, step #1720] loss: 1.0292885053788141\n",
      "[EPOCH #23, step #1722] loss: 1.0293423773518704\n",
      "[EPOCH #23, step #1724] loss: 1.0292258066370867\n",
      "[EPOCH #23, step #1726] loss: 1.028895081021431\n",
      "[EPOCH #23, step #1728] loss: 1.0285456157820014\n",
      "[EPOCH #23, step #1730] loss: 1.0284763338041059\n",
      "[EPOCH #23, step #1732] loss: 1.0287240932459647\n",
      "[EPOCH #23, step #1734] loss: 1.0283625265019771\n",
      "[EPOCH #23, step #1736] loss: 1.0283657239302864\n",
      "[EPOCH #23, step #1738] loss: 1.0282907170629694\n",
      "[EPOCH #23, step #1740] loss: 1.0280129962238616\n",
      "[EPOCH #23, step #1742] loss: 1.0279832298360334\n",
      "[EPOCH #23, step #1744] loss: 1.0278107319656962\n",
      "[EPOCH #23, step #1746] loss: 1.0279593687775344\n",
      "[EPOCH #23, step #1748] loss: 1.0277542805521742\n",
      "[EPOCH #23, step #1750] loss: 1.0280635863423415\n",
      "[EPOCH #23, step #1752] loss: 1.028001515102332\n",
      "[EPOCH #23, step #1754] loss: 1.0280138689907867\n",
      "[EPOCH #23, step #1756] loss: 1.0279043896604005\n",
      "[EPOCH #23, step #1758] loss: 1.027864637227137\n",
      "[EPOCH #23, step #1760] loss: 1.0280943599564998\n",
      "[EPOCH #23, step #1762] loss: 1.028461696171179\n",
      "[EPOCH #23, step #1764] loss: 1.02845669231739\n",
      "[EPOCH #23, step #1766] loss: 1.0283418796328279\n",
      "[EPOCH #23, step #1768] loss: 1.0284205942318356\n",
      "[EPOCH #23, step #1770] loss: 1.0284852535626365\n",
      "[EPOCH #23, step #1772] loss: 1.0282697299746424\n",
      "[EPOCH #23, step #1774] loss: 1.0281573533004438\n",
      "[EPOCH #23, step #1776] loss: 1.0280382328980682\n",
      "[EPOCH #23, step #1778] loss: 1.028068747662506\n",
      "[EPOCH #23, step #1780] loss: 1.0281001348163492\n",
      "[EPOCH #23, step #1782] loss: 1.0281366398343863\n",
      "[EPOCH #23, step #1784] loss: 1.0278221598192423\n",
      "[EPOCH #23, step #1786] loss: 1.0276482210322073\n",
      "[EPOCH #23, step #1788] loss: 1.0277126889244814\n",
      "[EPOCH #23, step #1790] loss: 1.0275400037674982\n",
      "[EPOCH #23, step #1792] loss: 1.0274454663069768\n",
      "[EPOCH #23, step #1794] loss: 1.0270395739496916\n",
      "[EPOCH #23, step #1796] loss: 1.0267971954083004\n",
      "[EPOCH #23, step #1798] loss: 1.0267545463576324\n",
      "[EPOCH #23, step #1800] loss: 1.0268769600800447\n",
      "[EPOCH #23, step #1802] loss: 1.0267555603899032\n",
      "[EPOCH #23, step #1804] loss: 1.026583915668181\n",
      "[EPOCH #23, step #1806] loss: 1.026654985871972\n",
      "[EPOCH #23, step #1808] loss: 1.0265690333412258\n",
      "[EPOCH #23, step #1810] loss: 1.0267771335019387\n",
      "[EPOCH #23, step #1812] loss: 1.0265884146266921\n",
      "[EPOCH #23, step #1814] loss: 1.0266743330259296\n",
      "[EPOCH #23, step #1816] loss: 1.0267779180225463\n",
      "[EPOCH #23, step #1818] loss: 1.0270974740279515\n",
      "[EPOCH #23, step #1820] loss: 1.0269017539987977\n",
      "[EPOCH #23, step #1822] loss: 1.0268811641390743\n",
      "[EPOCH #23, step #1824] loss: 1.0267375391803375\n",
      "[EPOCH #23, step #1826] loss: 1.0266323510453423\n",
      "[EPOCH #23, step #1828] loss: 1.0269091769344108\n",
      "[EPOCH #23, step #1830] loss: 1.027131681231317\n",
      "[EPOCH #23, step #1832] loss: 1.0275510661405614\n",
      "[EPOCH #23, step #1834] loss: 1.0276535043599495\n",
      "[EPOCH #23, step #1836] loss: 1.027716181008272\n",
      "[EPOCH #23, step #1838] loss: 1.0276609730824238\n",
      "[EPOCH #23, step #1840] loss: 1.0276777157312111\n",
      "[EPOCH #23, step #1842] loss: 1.027819521098569\n",
      "[EPOCH #23, step #1844] loss: 1.0278847805852813\n",
      "[EPOCH #23, step #1846] loss: 1.0276264534747852\n",
      "[EPOCH #23, step #1848] loss: 1.027502990078449\n",
      "[EPOCH #23, step #1850] loss: 1.0272298826197557\n",
      "[EPOCH #23, step #1852] loss: 1.0269716643540845\n",
      "[EPOCH #23, step #1854] loss: 1.0270627206547884\n",
      "[EPOCH #23, step #1856] loss: 1.027253565540478\n",
      "[EPOCH #23, step #1858] loss: 1.027223812084547\n",
      "[EPOCH #23, step #1860] loss: 1.0271264976996495\n",
      "[EPOCH #23, step #1862] loss: 1.0272718032585058\n",
      "[EPOCH #23, step #1864] loss: 1.0272024693501858\n",
      "[EPOCH #23, step #1866] loss: 1.027532081522275\n",
      "[EPOCH #23, step #1868] loss: 1.0273918081184579\n",
      "[EPOCH #23, step #1870] loss: 1.0272955584182004\n",
      "[EPOCH #23, step #1872] loss: 1.027336246561253\n",
      "[EPOCH #23, step #1874] loss: 1.0275606522242229\n",
      "[EPOCH #23, step #1876] loss: 1.0273514275355229\n",
      "[EPOCH #23, step #1878] loss: 1.0273695111338161\n",
      "[EPOCH #23, step #1880] loss: 1.0274675156067559\n",
      "[EPOCH #23, step #1882] loss: 1.0275929862998359\n",
      "[EPOCH #23, step #1884] loss: 1.0274856442798037\n",
      "[EPOCH #23, step #1886] loss: 1.0279657145183303\n",
      "[EPOCH #23, step #1888] loss: 1.0277901678378143\n",
      "[EPOCH #23, step #1890] loss: 1.0274863962078145\n",
      "[EPOCH #23, step #1892] loss: 1.0273204361768986\n",
      "[EPOCH #23, step #1894] loss: 1.0272525801193118\n",
      "[EPOCH #23, step #1896] loss: 1.0271184684479935\n",
      "[EPOCH #23, step #1898] loss: 1.0271918584071316\n",
      "[EPOCH #23, step #1900] loss: 1.0271495075867967\n",
      "[EPOCH #23, step #1902] loss: 1.0270841043056842\n",
      "[EPOCH #23, step #1904] loss: 1.026786109093293\n",
      "[EPOCH #23, step #1906] loss: 1.0264501521021019\n",
      "[EPOCH #23, step #1908] loss: 1.0267051773710736\n",
      "[EPOCH #23, step #1910] loss: 1.0269171318291745\n",
      "[EPOCH #23, step #1912] loss: 1.0266772225086314\n",
      "[EPOCH #23, step #1914] loss: 1.027009978400198\n",
      "[EPOCH #23, step #1916] loss: 1.0267368155528185\n",
      "[EPOCH #23, step #1918] loss: 1.0266907695620677\n",
      "[EPOCH #23, step #1920] loss: 1.0269616032130764\n",
      "[EPOCH #23, step #1922] loss: 1.0268061164450781\n",
      "[EPOCH #23, step #1924] loss: 1.0267553257013295\n",
      "[EPOCH #23, step #1926] loss: 1.0266357238390438\n",
      "[EPOCH #23, step #1928] loss: 1.0267475729102358\n",
      "[EPOCH #23, step #1930] loss: 1.0266669474692618\n",
      "[EPOCH #23, step #1932] loss: 1.0267617308100578\n",
      "[EPOCH #23, step #1934] loss: 1.0269229795581611\n",
      "[EPOCH #23, step #1936] loss: 1.0268477209770133\n",
      "[EPOCH #23, step #1938] loss: 1.0269817806446042\n",
      "[EPOCH #23, step #1940] loss: 1.0269367133508571\n",
      "[EPOCH #23, step #1942] loss: 1.026879838030791\n",
      "[EPOCH #23, step #1944] loss: 1.0268349328813333\n",
      "[EPOCH #23, step #1946] loss: 1.026879834957348\n",
      "[EPOCH #23, step #1948] loss: 1.0270370303085976\n",
      "[EPOCH #23, step #1950] loss: 1.0269569358356423\n",
      "[EPOCH #23, step #1952] loss: 1.0269812596680503\n",
      "[EPOCH #23, step #1954] loss: 1.0269726295300456\n",
      "[EPOCH #23, step #1956] loss: 1.0269440644604855\n",
      "[EPOCH #23, step #1958] loss: 1.0271247583667256\n",
      "[EPOCH #23, step #1960] loss: 1.0269408660965997\n",
      "[EPOCH #23, step #1962] loss: 1.026956186116015\n",
      "[EPOCH #23, step #1964] loss: 1.027106398662538\n",
      "[EPOCH #23, step #1966] loss: 1.0273808016653405\n",
      "[EPOCH #23, step #1968] loss: 1.0270939000128732\n",
      "[EPOCH #23, step #1970] loss: 1.0270394838322001\n",
      "[EPOCH #23, step #1972] loss: 1.0270016851669268\n",
      "[EPOCH #23, step #1974] loss: 1.0270223633247086\n",
      "[EPOCH #23, step #1976] loss: 1.0271134429588182\n",
      "[EPOCH #23, step #1978] loss: 1.0272544282081453\n",
      "[EPOCH #23, step #1980] loss: 1.0274414446304567\n",
      "[EPOCH #23, step #1982] loss: 1.0273728944470168\n",
      "[EPOCH #23, step #1984] loss: 1.027611138508362\n",
      "[EPOCH #23, step #1986] loss: 1.0275919028545182\n",
      "[EPOCH #23, step #1988] loss: 1.0277311374878633\n",
      "[EPOCH #23, step #1990] loss: 1.0275986802332489\n",
      "[EPOCH #23, step #1992] loss: 1.0277859866170505\n",
      "[EPOCH #23, step #1994] loss: 1.027584981858581\n",
      "[EPOCH #23, step #1996] loss: 1.0275684356032817\n",
      "[EPOCH #23, step #1998] loss: 1.0276214121698797\n",
      "[EPOCH #23, step #2000] loss: 1.0274941810127023\n",
      "[EPOCH #23, step #2002] loss: 1.0274911280637733\n",
      "[EPOCH #23, step #2004] loss: 1.0275292207475315\n",
      "[EPOCH #23, step #2006] loss: 1.0277833487183285\n",
      "[EPOCH #23, step #2008] loss: 1.027959496658082\n",
      "[EPOCH #23, step #2010] loss: 1.0278746714229194\n",
      "[EPOCH #23, step #2012] loss: 1.0280899088950046\n",
      "[EPOCH #23, step #2014] loss: 1.0276708820025915\n",
      "[EPOCH #23, step #2016] loss: 1.0277669428301497\n",
      "[EPOCH #23, step #2018] loss: 1.0277595124131327\n",
      "[EPOCH #23, step #2020] loss: 1.0277783881019449\n",
      "[EPOCH #23, step #2022] loss: 1.0278539133437248\n",
      "[EPOCH #23, step #2024] loss: 1.0279720010286495\n",
      "[EPOCH #23, step #2026] loss: 1.0277329378370352\n",
      "[EPOCH #23, step #2028] loss: 1.027791571564249\n",
      "[EPOCH #23, step #2030] loss: 1.0278267649697999\n",
      "[EPOCH #23, step #2032] loss: 1.027847073404178\n",
      "[EPOCH #23, step #2034] loss: 1.027945180402048\n",
      "[EPOCH #23, step #2036] loss: 1.0279156859153968\n",
      "[EPOCH #23, step #2038] loss: 1.0277536938212677\n",
      "[EPOCH #23, step #2040] loss: 1.0276681623991537\n",
      "[EPOCH #23, step #2042] loss: 1.0274993026309076\n",
      "[EPOCH #23, step #2044] loss: 1.0274926861224372\n",
      "[EPOCH #23, step #2046] loss: 1.0274984295565033\n",
      "[EPOCH #23, step #2048] loss: 1.0276554457556044\n",
      "[EPOCH #23, step #2050] loss: 1.0275357174385122\n",
      "[EPOCH #23, step #2052] loss: 1.0275023889379042\n",
      "[EPOCH #23, step #2054] loss: 1.0271307806028938\n",
      "[EPOCH #23, step #2056] loss: 1.0271009024509714\n",
      "[EPOCH #23, step #2058] loss: 1.02697397369734\n",
      "[EPOCH #23, step #2060] loss: 1.0268281315033554\n",
      "[EPOCH #23, step #2062] loss: 1.0271026503675722\n",
      "[EPOCH #23, step #2064] loss: 1.0272318061558443\n",
      "[EPOCH #23, step #2066] loss: 1.027017008035611\n",
      "[EPOCH #23, step #2068] loss: 1.0269550221619714\n",
      "[EPOCH #23, step #2070] loss: 1.0269127514326648\n",
      "[EPOCH #23, step #2072] loss: 1.026835598493623\n",
      "[EPOCH #23, step #2074] loss: 1.0270267745385686\n",
      "[EPOCH #23, step #2076] loss: 1.0268123684505688\n",
      "[EPOCH #23, step #2078] loss: 1.0269677654775993\n",
      "[EPOCH #23, step #2080] loss: 1.0272222992492834\n",
      "[EPOCH #23, step #2082] loss: 1.0271460653152593\n",
      "[EPOCH #23, step #2084] loss: 1.027065673349001\n",
      "[EPOCH #23, step #2086] loss: 1.0270817256110905\n",
      "[EPOCH #23, step #2088] loss: 1.0270000033084143\n",
      "[EPOCH #23, step #2090] loss: 1.0269419559162236\n",
      "[EPOCH #23, step #2092] loss: 1.0271117541987076\n",
      "[EPOCH #23, step #2094] loss: 1.0270932932457661\n",
      "[EPOCH #23, step #2096] loss: 1.027038530048212\n",
      "[EPOCH #23, step #2098] loss: 1.027539918001292\n",
      "[EPOCH #23, step #2100] loss: 1.0275562662615316\n",
      "[EPOCH #23, step #2102] loss: 1.027491244343537\n",
      "[EPOCH #23, step #2104] loss: 1.0275160645928916\n",
      "[EPOCH #23, step #2106] loss: 1.02758943845041\n",
      "[EPOCH #23, step #2108] loss: 1.027688587175381\n",
      "[EPOCH #23, step #2110] loss: 1.0276518453923744\n",
      "[EPOCH #23, step #2112] loss: 1.0274131419361907\n",
      "[EPOCH #23, step #2114] loss: 1.0272216547747313\n",
      "[EPOCH #23, step #2116] loss: 1.027482992362796\n",
      "[EPOCH #23, step #2118] loss: 1.0273997855107702\n",
      "[EPOCH #23, step #2120] loss: 1.0276925487374429\n",
      "[EPOCH #23, step #2122] loss: 1.0279002773048627\n",
      "[EPOCH #23, step #2124] loss: 1.0279770412445068\n",
      "[EPOCH #23, step #2126] loss: 1.0277959126287297\n",
      "[EPOCH #23, step #2128] loss: 1.0280283970584216\n",
      "[EPOCH #23, step #2130] loss: 1.0281475745473654\n",
      "[EPOCH #23, step #2132] loss: 1.028254493602944\n",
      "[EPOCH #23, step #2134] loss: 1.028457368397322\n",
      "[EPOCH #23, step #2136] loss: 1.0284822593797407\n",
      "[EPOCH #23, step #2138] loss: 1.0283705061314652\n",
      "[EPOCH #23, step #2140] loss: 1.0285425787214808\n",
      "[EPOCH #23, step #2142] loss: 1.0285176072674715\n",
      "[EPOCH #23, step #2144] loss: 1.02849351384423\n",
      "[EPOCH #23, step #2146] loss: 1.0284424381418233\n",
      "[EPOCH #23, step #2148] loss: 1.0283678273036347\n",
      "[EPOCH #23, step #2150] loss: 1.0285641839480966\n",
      "[EPOCH #23, step #2152] loss: 1.0285056136510453\n",
      "[EPOCH #23, step #2154] loss: 1.0286307452173078\n",
      "[EPOCH #23, step #2156] loss: 1.0283609543843684\n",
      "[EPOCH #23, step #2158] loss: 1.0283488311553344\n",
      "[EPOCH #23, step #2160] loss: 1.0282616172328916\n",
      "[EPOCH #23, step #2162] loss: 1.028345386214792\n",
      "[EPOCH #23, step #2164] loss: 1.0284438935768796\n",
      "[EPOCH #23, step #2166] loss: 1.0284412375066376\n",
      "[EPOCH #23, step #2168] loss: 1.028393244704875\n",
      "[EPOCH #23, step #2170] loss: 1.0285763668333094\n",
      "[EPOCH #23, step #2172] loss: 1.0285942625516689\n",
      "[EPOCH #23, step #2174] loss: 1.0285640936062255\n",
      "[EPOCH #23, step #2176] loss: 1.0284646517320353\n",
      "[EPOCH #23, step #2178] loss: 1.0284807960502376\n",
      "[EPOCH #23, step #2180] loss: 1.028481886426225\n",
      "[EPOCH #23, step #2182] loss: 1.0285357807242865\n",
      "[EPOCH #23, step #2184] loss: 1.0283943223189436\n",
      "[EPOCH #23, step #2186] loss: 1.0283619576411864\n",
      "[EPOCH #23, step #2188] loss: 1.0281685632404642\n",
      "[EPOCH #23, step #2190] loss: 1.0282716847673936\n",
      "[EPOCH #23, step #2192] loss: 1.0282015544445178\n",
      "[EPOCH #23, step #2194] loss: 1.028282788728527\n",
      "[EPOCH #23, step #2196] loss: 1.0282295666665557\n",
      "[EPOCH #23, step #2198] loss: 1.0281866339457582\n",
      "[EPOCH #23, step #2200] loss: 1.02826129390889\n",
      "[EPOCH #23, step #2202] loss: 1.0281031103064893\n",
      "[EPOCH #23, step #2204] loss: 1.0278646093106865\n",
      "[EPOCH #23, step #2206] loss: 1.027967403742\n",
      "[EPOCH #23, step #2208] loss: 1.0281274734227677\n",
      "[EPOCH #23, step #2210] loss: 1.0283483274378749\n",
      "[EPOCH #23, step #2212] loss: 1.028490065558701\n",
      "[EPOCH #23, step #2214] loss: 1.028378264791002\n",
      "[EPOCH #23, step #2216] loss: 1.028222270467876\n",
      "[EPOCH #23, step #2218] loss: 1.028121366405229\n",
      "[EPOCH #23, step #2220] loss: 1.0281615017073373\n",
      "[EPOCH #23, step #2222] loss: 1.0278751497272967\n",
      "[EPOCH #23, step #2224] loss: 1.0279287635610346\n",
      "[EPOCH #23, step #2226] loss: 1.0278510410902368\n",
      "[EPOCH #23, step #2228] loss: 1.0276768857879777\n",
      "[EPOCH #23, step #2230] loss: 1.0275523293344284\n",
      "[EPOCH #23, step #2232] loss: 1.0276276448677326\n",
      "[EPOCH #23, step #2234] loss: 1.0277589961719726\n",
      "[EPOCH #23, step #2236] loss: 1.027424227008342\n",
      "[EPOCH #23, step #2238] loss: 1.0275394966315883\n",
      "[EPOCH #23, step #2240] loss: 1.0277388380713253\n",
      "[EPOCH #23, step #2242] loss: 1.027636785141549\n",
      "[EPOCH #23, step #2244] loss: 1.0278753332146557\n",
      "[EPOCH #23, step #2246] loss: 1.0277661459945708\n",
      "[EPOCH #23, step #2248] loss: 1.027821020477875\n",
      "[EPOCH #23, step #2250] loss: 1.0278076626681476\n",
      "[EPOCH #23, step #2252] loss: 1.0279107841977637\n",
      "[EPOCH #23, step #2254] loss: 1.0278361015203523\n",
      "[EPOCH #23, step #2256] loss: 1.0278938360376912\n",
      "[EPOCH #23, step #2258] loss: 1.027958662676674\n",
      "[EPOCH #23, step #2260] loss: 1.0280949519251048\n",
      "[EPOCH #23, step #2262] loss: 1.028423245296613\n",
      "[EPOCH #23, step #2264] loss: 1.0284809722279344\n",
      "[EPOCH #23, step #2266] loss: 1.0286109759043007\n",
      "[EPOCH #23, step #2268] loss: 1.0284643138279836\n",
      "[EPOCH #23, step #2270] loss: 1.0286218479885922\n",
      "[EPOCH #23, step #2272] loss: 1.028547059687234\n",
      "[EPOCH #23, step #2274] loss: 1.0283292346472268\n",
      "[EPOCH #23, step #2276] loss: 1.02866198022375\n",
      "[EPOCH #23, step #2278] loss: 1.0287906245580625\n",
      "[EPOCH #23, step #2280] loss: 1.0288244512769957\n",
      "[EPOCH #23, step #2282] loss: 1.0286916336415892\n",
      "[EPOCH #23, step #2284] loss: 1.028724911750276\n",
      "[EPOCH #23, step #2286] loss: 1.028590352893866\n",
      "[EPOCH #23, step #2288] loss: 1.0286306828429679\n",
      "[EPOCH #23, step #2290] loss: 1.0285044718860592\n",
      "[EPOCH #23, step #2292] loss: 1.028540048961082\n",
      "[EPOCH #23, step #2294] loss: 1.0285986765797102\n",
      "[EPOCH #23, step #2296] loss: 1.0284565812253308\n",
      "[EPOCH #23, step #2298] loss: 1.0285432405604544\n",
      "[EPOCH #23, step #2300] loss: 1.0286881336177343\n",
      "[EPOCH #23, step #2302] loss: 1.0290316521370872\n",
      "[EPOCH #23, step #2304] loss: 1.028972655470097\n",
      "[EPOCH #23, step #2306] loss: 1.0289102312957357\n",
      "[EPOCH #23, step #2308] loss: 1.0287803978618475\n",
      "[EPOCH #23, step #2310] loss: 1.0287025529602707\n",
      "[EPOCH #23, step #2312] loss: 1.028585049016518\n",
      "[EPOCH #23, step #2314] loss: 1.0285390003453578\n",
      "[EPOCH #23, step #2316] loss: 1.0285152153151786\n",
      "[EPOCH #23, step #2318] loss: 1.0288007425408572\n",
      "[EPOCH #23, step #2320] loss: 1.0289618382418992\n",
      "[EPOCH #23, step #2322] loss: 1.028757707009375\n",
      "[EPOCH #23, step #2324] loss: 1.0284091927415582\n",
      "[EPOCH #23, step #2326] loss: 1.0284290166438061\n",
      "[EPOCH #23, step #2328] loss: 1.0285617723491582\n",
      "[EPOCH #23, step #2330] loss: 1.0287962947112712\n",
      "[EPOCH #23, step #2332] loss: 1.02870534930779\n",
      "[EPOCH #23, step #2334] loss: 1.028603003801064\n",
      "[EPOCH #23, step #2336] loss: 1.0287030586637285\n",
      "[EPOCH #23, step #2338] loss: 1.0286788426183544\n",
      "[EPOCH #23, step #2340] loss: 1.0286442550620887\n",
      "[EPOCH #23, step #2342] loss: 1.0286767507688235\n",
      "[EPOCH #23, step #2344] loss: 1.0288905051725505\n",
      "[EPOCH #23, step #2346] loss: 1.0287696349148452\n",
      "[EPOCH #23, step #2348] loss: 1.0287442318730378\n",
      "[EPOCH #23, step #2350] loss: 1.028924740385066\n",
      "[EPOCH #23, step #2352] loss: 1.0287928926757282\n",
      "[EPOCH #23, step #2354] loss: 1.0286627002076232\n",
      "[EPOCH #23, step #2356] loss: 1.0286506185806754\n",
      "[EPOCH #23, step #2358] loss: 1.028596597740639\n",
      "[EPOCH #23, step #2360] loss: 1.0285046846368766\n",
      "[EPOCH #23, step #2362] loss: 1.028766013382352\n",
      "[EPOCH #23, step #2364] loss: 1.028640191373563\n",
      "[EPOCH #23, step #2366] loss: 1.0285360780153086\n",
      "[EPOCH #23, step #2368] loss: 1.0285778574774465\n",
      "[EPOCH #23, step #2370] loss: 1.0285318099411667\n",
      "[EPOCH #23, step #2372] loss: 1.0289272956590938\n",
      "[EPOCH #23, step #2374] loss: 1.0289786173418949\n",
      "[EPOCH #23, step #2376] loss: 1.0289247038738538\n",
      "[EPOCH #23, step #2378] loss: 1.0288090472363685\n",
      "[EPOCH #23, step #2380] loss: 1.0287779269725121\n",
      "[EPOCH #23, step #2382] loss: 1.0288471034030378\n",
      "[EPOCH #23, step #2384] loss: 1.0287664557153073\n",
      "[EPOCH #23, step #2386] loss: 1.028607808849429\n",
      "[EPOCH #23, step #2388] loss: 1.0286501623836708\n",
      "[EPOCH #23, step #2390] loss: 1.0286137235807804\n",
      "[EPOCH #23, step #2392] loss: 1.0287789081212022\n",
      "[EPOCH #23, step #2394] loss: 1.0286966312404466\n",
      "[EPOCH #23, step #2396] loss: 1.0288604482989734\n",
      "[EPOCH #23, step #2398] loss: 1.0290500036424872\n",
      "[EPOCH #23, step #2400] loss: 1.02900664295469\n",
      "[EPOCH #23, step #2402] loss: 1.028994211989842\n",
      "[EPOCH #23, step #2404] loss: 1.0287849135309644\n",
      "[EPOCH #23, step #2406] loss: 1.0291541106581044\n",
      "[EPOCH #23, step #2408] loss: 1.029170789007034\n",
      "[EPOCH #23, step #2410] loss: 1.0290929402666238\n",
      "[EPOCH #23, step #2412] loss: 1.0289496083848466\n",
      "[EPOCH #23, step #2414] loss: 1.0288885684734053\n",
      "[EPOCH #23, step #2416] loss: 1.0287169462943009\n",
      "[EPOCH #23, step #2418] loss: 1.0284924092692942\n",
      "[EPOCH #23, step #2420] loss: 1.028561651805175\n",
      "[EPOCH #23, step #2422] loss: 1.0287308904242034\n",
      "[EPOCH #23, step #2424] loss: 1.0289309613975053\n",
      "[EPOCH #23, step #2426] loss: 1.029300977258364\n",
      "[EPOCH #23, step #2428] loss: 1.0291957028268444\n",
      "[EPOCH #23, step #2430] loss: 1.029260610685776\n",
      "[EPOCH #23, step #2432] loss: 1.0296280545998246\n",
      "[EPOCH #23, step #2434] loss: 1.02930872628821\n",
      "[EPOCH #23, step #2436] loss: 1.0292599164025922\n",
      "[EPOCH #23, step #2438] loss: 1.0290373396609542\n",
      "[EPOCH #23, step #2440] loss: 1.0290458958591413\n",
      "[EPOCH #23, step #2442] loss: 1.0291993673883204\n",
      "[EPOCH #23, step #2444] loss: 1.0290135635920097\n",
      "[EPOCH #23, step #2446] loss: 1.0289707682938491\n",
      "[EPOCH #23, step #2448] loss: 1.0291048218737626\n",
      "[EPOCH #23, step #2450] loss: 1.0288970621446356\n",
      "[EPOCH #23, step #2452] loss: 1.028876940838619\n",
      "[EPOCH #23, step #2454] loss: 1.0289920261823962\n",
      "[EPOCH #23, step #2456] loss: 1.0288616610728099\n",
      "[EPOCH #23, step #2458] loss: 1.0288067278991924\n",
      "[EPOCH #23, step #2460] loss: 1.0288200849733038\n",
      "[EPOCH #23, step #2462] loss: 1.0288292621869262\n",
      "[EPOCH #23, step #2464] loss: 1.0288924565179836\n",
      "[EPOCH #23, step #2466] loss: 1.0288356308710929\n",
      "[EPOCH #23, step #2468] loss: 1.028762237800669\n",
      "[EPOCH #23, step #2470] loss: 1.0287359606298248\n",
      "[EPOCH #23, step #2472] loss: 1.0288261817478237\n",
      "[EPOCH #23, step #2474] loss: 1.028825763355602\n",
      "[EPOCH #23, step #2476] loss: 1.0288728819675006\n",
      "[EPOCH #23, step #2478] loss: 1.02879417832218\n",
      "[EPOCH #23, step #2480] loss: 1.0289711067629457\n",
      "[EPOCH #23, step #2482] loss: 1.028991661890831\n",
      "[EPOCH #23, step #2484] loss: 1.0288741940943529\n",
      "[EPOCH #23, step #2486] loss: 1.0288001397885995\n",
      "[EPOCH #23, step #2488] loss: 1.0285655937553075\n",
      "[EPOCH #23, step #2490] loss: 1.0285153620360798\n",
      "[EPOCH #23, step #2492] loss: 1.0286729921789663\n",
      "[EPOCH #23, step #2494] loss: 1.0287536712113268\n",
      "[EPOCH #23, step #2496] loss: 1.0284976077452153\n",
      "[EPOCH #23, step #2498] loss: 1.0283040992018222\n",
      "[EPOCH #23, elapsed time: 11641.479[sec]] loss: 1.0283253944158555\n",
      "[EPOCH #24, step #0] loss: 0.7129783034324646\n",
      "[EPOCH #24, step #2] loss: 0.8684400717417399\n",
      "[EPOCH #24, step #4] loss: 0.7634156346321106\n",
      "[EPOCH #24, step #6] loss: 0.7887373481478009\n",
      "[EPOCH #24, step #8] loss: 0.8491173717710707\n",
      "[EPOCH #24, step #10] loss: 0.8869969032027505\n",
      "[EPOCH #24, step #12] loss: 0.9269660802987906\n",
      "[EPOCH #24, step #14] loss: 0.9150910576184591\n",
      "[EPOCH #24, step #16] loss: 0.9475653977955089\n",
      "[EPOCH #24, step #18] loss: 0.9516478149514449\n",
      "[EPOCH #24, step #20] loss: 0.9540775730496361\n",
      "[EPOCH #24, step #22] loss: 0.9783649185429448\n",
      "[EPOCH #24, step #24] loss: 0.9690608954429627\n",
      "[EPOCH #24, step #26] loss: 0.9464013708962334\n",
      "[EPOCH #24, step #28] loss: 0.9561045025957042\n",
      "[EPOCH #24, step #30] loss: 0.9632334882213224\n",
      "[EPOCH #24, step #32] loss: 0.9561949950275999\n",
      "[EPOCH #24, step #34] loss: 0.9550437501498631\n",
      "[EPOCH #24, step #36] loss: 0.9575037634050524\n",
      "[EPOCH #24, step #38] loss: 0.9735751824501233\n",
      "[EPOCH #24, step #40] loss: 0.9760719101603438\n",
      "[EPOCH #24, step #42] loss: 0.9748577586440152\n",
      "[EPOCH #24, step #44] loss: 0.9885906100273132\n",
      "[EPOCH #24, step #46] loss: 0.9833511748212449\n",
      "[EPOCH #24, step #48] loss: 0.9883901343053701\n",
      "[EPOCH #24, step #50] loss: 0.9903651522655114\n",
      "[EPOCH #24, step #52] loss: 0.9916471062966112\n",
      "[EPOCH #24, step #54] loss: 0.9921728047457609\n",
      "[EPOCH #24, step #56] loss: 0.998136043548584\n",
      "[EPOCH #24, step #58] loss: 0.9947157966888557\n",
      "[EPOCH #24, step #60] loss: 0.9961946303727197\n",
      "[EPOCH #24, step #62] loss: 0.9951637936016869\n",
      "[EPOCH #24, step #64] loss: 0.9927058540857755\n",
      "[EPOCH #24, step #66] loss: 0.9969989853118782\n",
      "[EPOCH #24, step #68] loss: 0.9942424919294275\n",
      "[EPOCH #24, step #70] loss: 0.9906878580509777\n",
      "[EPOCH #24, step #72] loss: 0.9803827013054939\n",
      "[EPOCH #24, step #74] loss: 0.9778158783912658\n",
      "[EPOCH #24, step #76] loss: 0.9841428987391583\n",
      "[EPOCH #24, step #78] loss: 0.982781037499633\n",
      "[EPOCH #24, step #80] loss: 0.9829449925893619\n",
      "[EPOCH #24, step #82] loss: 0.9840812561023666\n",
      "[EPOCH #24, step #84] loss: 0.9835656832246219\n",
      "[EPOCH #24, step #86] loss: 0.9875031771330998\n",
      "[EPOCH #24, step #88] loss: 0.9956389404414745\n",
      "[EPOCH #24, step #90] loss: 0.9944587238542326\n",
      "[EPOCH #24, step #92] loss: 0.9915132016263982\n",
      "[EPOCH #24, step #94] loss: 0.9900426889720716\n",
      "[EPOCH #24, step #96] loss: 0.9954747453178328\n",
      "[EPOCH #24, step #98] loss: 0.9896419343322215\n",
      "[EPOCH #24, step #100] loss: 0.9840750163144404\n",
      "[EPOCH #24, step #102] loss: 0.9836014902707443\n",
      "[EPOCH #24, step #104] loss: 0.9831201388722375\n",
      "[EPOCH #24, step #106] loss: 0.9832093398147654\n",
      "[EPOCH #24, step #108] loss: 0.9837334544286815\n",
      "[EPOCH #24, step #110] loss: 0.9812297305545291\n",
      "[EPOCH #24, step #112] loss: 0.9793679213101885\n",
      "[EPOCH #24, step #114] loss: 0.9772828350896421\n",
      "[EPOCH #24, step #116] loss: 0.9763198204529591\n",
      "[EPOCH #24, step #118] loss: 0.9748356146972721\n",
      "[EPOCH #24, step #120] loss: 0.97693362314839\n",
      "[EPOCH #24, step #122] loss: 0.9727583309499229\n",
      "[EPOCH #24, step #124] loss: 0.9723456063270569\n",
      "[EPOCH #24, step #126] loss: 0.9717331599062822\n",
      "[EPOCH #24, step #128] loss: 0.9710947829623555\n",
      "[EPOCH #24, step #130] loss: 0.9675131121664556\n",
      "[EPOCH #24, step #132] loss: 0.9667804752077375\n",
      "[EPOCH #24, step #134] loss: 0.9667183275575991\n",
      "[EPOCH #24, step #136] loss: 0.9677215862448199\n",
      "[EPOCH #24, step #138] loss: 0.9610642745769281\n",
      "[EPOCH #24, step #140] loss: 0.9571212215203766\n",
      "[EPOCH #24, step #142] loss: 0.9578335741599957\n",
      "[EPOCH #24, step #144] loss: 0.9586152292531113\n",
      "[EPOCH #24, step #146] loss: 0.9569254993986921\n",
      "[EPOCH #24, step #148] loss: 0.9560187993033621\n",
      "[EPOCH #24, step #150] loss: 0.9557736000872605\n",
      "[EPOCH #24, step #152] loss: 0.9556197268900528\n",
      "[EPOCH #24, step #154] loss: 0.9558491304997475\n",
      "[EPOCH #24, step #156] loss: 0.950451409361165\n",
      "[EPOCH #24, step #158] loss: 0.94973512790488\n",
      "[EPOCH #24, step #160] loss: 0.9495758021840398\n",
      "[EPOCH #24, step #162] loss: 0.9496609272401025\n",
      "[EPOCH #24, step #164] loss: 0.9520373828483351\n",
      "[EPOCH #24, step #166] loss: 0.9536768612033593\n",
      "[EPOCH #24, step #168] loss: 0.9548467062634124\n",
      "[EPOCH #24, step #170] loss: 0.9552552581530566\n",
      "[EPOCH #24, step #172] loss: 0.953265405459211\n",
      "[EPOCH #24, step #174] loss: 0.9540743034226554\n",
      "[EPOCH #24, step #176] loss: 0.9509245766758245\n",
      "[EPOCH #24, step #178] loss: 0.9484193511515356\n",
      "[EPOCH #24, step #180] loss: 0.9507975591480403\n",
      "[EPOCH #24, step #182] loss: 0.9520167252405094\n",
      "[EPOCH #24, step #184] loss: 0.9545337490133337\n",
      "[EPOCH #24, step #186] loss: 0.9524490297796891\n",
      "[EPOCH #24, step #188] loss: 0.9523910624640328\n",
      "[EPOCH #24, step #190] loss: 0.954424517316968\n",
      "[EPOCH #24, step #192] loss: 0.9530711550786706\n",
      "[EPOCH #24, step #194] loss: 0.9548819572497637\n",
      "[EPOCH #24, step #196] loss: 0.9529445440636068\n",
      "[EPOCH #24, step #198] loss: 0.9527843055413596\n",
      "[EPOCH #24, step #200] loss: 0.9518053516819702\n",
      "[EPOCH #24, step #202] loss: 0.953596098669644\n",
      "[EPOCH #24, step #204] loss: 0.9552829405156578\n",
      "[EPOCH #24, step #206] loss: 0.9573768406098592\n",
      "[EPOCH #24, step #208] loss: 0.960151721986287\n",
      "[EPOCH #24, step #210] loss: 0.9595296219061901\n",
      "[EPOCH #24, step #212] loss: 0.957880652006803\n",
      "[EPOCH #24, step #214] loss: 0.9583774769028952\n",
      "[EPOCH #24, step #216] loss: 0.9579817548325534\n",
      "[EPOCH #24, step #218] loss: 0.9604044643711281\n",
      "[EPOCH #24, step #220] loss: 0.9587403444143442\n",
      "[EPOCH #24, step #222] loss: 0.9605850195136305\n",
      "[EPOCH #24, step #224] loss: 0.9596017347441779\n",
      "[EPOCH #24, step #226] loss: 0.9572318290823881\n",
      "[EPOCH #24, step #228] loss: 0.9558063500833303\n",
      "[EPOCH #24, step #230] loss: 0.9544869204620262\n",
      "[EPOCH #24, step #232] loss: 0.9558763639609701\n",
      "[EPOCH #24, step #234] loss: 0.9556169033050537\n",
      "[EPOCH #24, step #236] loss: 0.9556694234473796\n",
      "[EPOCH #24, step #238] loss: 0.9571799785522237\n",
      "[EPOCH #24, step #240] loss: 0.9548251668447281\n",
      "[EPOCH #24, step #242] loss: 0.9545862149799802\n",
      "[EPOCH #24, step #244] loss: 0.9546984254097451\n",
      "[EPOCH #24, step #246] loss: 0.9548988745280123\n",
      "[EPOCH #24, step #248] loss: 0.9537113557857682\n",
      "[EPOCH #24, step #250] loss: 0.9540289794781294\n",
      "[EPOCH #24, step #252] loss: 0.954718771423747\n",
      "[EPOCH #24, step #254] loss: 0.9543718076219746\n",
      "[EPOCH #24, step #256] loss: 0.9533668172034772\n",
      "[EPOCH #24, step #258] loss: 0.950601377312281\n",
      "[EPOCH #24, step #260] loss: 0.9497114783045889\n",
      "[EPOCH #24, step #262] loss: 0.9500888735622508\n",
      "[EPOCH #24, step #264] loss: 0.9507891591989769\n",
      "[EPOCH #24, step #266] loss: 0.9499757243006417\n",
      "[EPOCH #24, step #268] loss: 0.9520837358825712\n",
      "[EPOCH #24, step #270] loss: 0.9518360746302728\n",
      "[EPOCH #24, step #272] loss: 0.9516236127077878\n",
      "[EPOCH #24, step #274] loss: 0.9535091131383723\n",
      "[EPOCH #24, step #276] loss: 0.9543323843918122\n",
      "[EPOCH #24, step #278] loss: 0.9545586835526224\n",
      "[EPOCH #24, step #280] loss: 0.9550649530098532\n",
      "[EPOCH #24, step #282] loss: 0.9551766613768183\n",
      "[EPOCH #24, step #284] loss: 0.9540735654663621\n",
      "[EPOCH #24, step #286] loss: 0.9544390535520759\n",
      "[EPOCH #24, step #288] loss: 0.9524132091693812\n",
      "[EPOCH #24, step #290] loss: 0.9539111864935491\n",
      "[EPOCH #24, step #292] loss: 0.9544476057075396\n",
      "[EPOCH #24, step #294] loss: 0.9549034484362198\n",
      "[EPOCH #24, step #296] loss: 0.9545627252421395\n",
      "[EPOCH #24, step #298] loss: 0.9534074827580149\n",
      "[EPOCH #24, step #300] loss: 0.9538518388405987\n",
      "[EPOCH #24, step #302] loss: 0.9527763279751189\n",
      "[EPOCH #24, step #304] loss: 0.9534163867841001\n",
      "[EPOCH #24, step #306] loss: 0.9541527452220357\n",
      "[EPOCH #24, step #308] loss: 0.9556520614037621\n",
      "[EPOCH #24, step #310] loss: 0.9576210201361555\n",
      "[EPOCH #24, step #312] loss: 0.9579730791786608\n",
      "[EPOCH #24, step #314] loss: 0.9581539288399712\n",
      "[EPOCH #24, step #316] loss: 0.9608662009991306\n",
      "[EPOCH #24, step #318] loss: 0.9599188134588045\n",
      "[EPOCH #24, step #320] loss: 0.9579505153534197\n",
      "[EPOCH #24, step #322] loss: 0.9586233537263545\n",
      "[EPOCH #24, step #324] loss: 0.9579790333601145\n",
      "[EPOCH #24, step #326] loss: 0.9601073835603323\n",
      "[EPOCH #24, step #328] loss: 0.9588898846081325\n",
      "[EPOCH #24, step #330] loss: 0.9587213398826807\n",
      "[EPOCH #24, step #332] loss: 0.9576933725818142\n",
      "[EPOCH #24, step #334] loss: 0.9574102423084316\n",
      "[EPOCH #24, step #336] loss: 0.957911055413481\n",
      "[EPOCH #24, step #338] loss: 0.9583574572144005\n",
      "[EPOCH #24, step #340] loss: 0.9588025951665168\n",
      "[EPOCH #24, step #342] loss: 0.9582872260416214\n",
      "[EPOCH #24, step #344] loss: 0.9596890254297118\n",
      "[EPOCH #24, step #346] loss: 0.9589283864848552\n",
      "[EPOCH #24, step #348] loss: 0.9580712622421177\n",
      "[EPOCH #24, step #350] loss: 0.9563858969259126\n",
      "[EPOCH #24, step #352] loss: 0.9560780550535273\n",
      "[EPOCH #24, step #354] loss: 0.9551931542409977\n",
      "[EPOCH #24, step #356] loss: 0.9545882042048692\n",
      "[EPOCH #24, step #358] loss: 0.9554376326563631\n",
      "[EPOCH #24, step #360] loss: 0.9576087239046176\n",
      "[EPOCH #24, step #362] loss: 0.9570168974314183\n",
      "[EPOCH #24, step #364] loss: 0.9565013078794088\n",
      "[EPOCH #24, step #366] loss: 0.9576964813617009\n",
      "[EPOCH #24, step #368] loss: 0.9577233708970915\n",
      "[EPOCH #24, step #370] loss: 0.958238365836542\n",
      "[EPOCH #24, step #372] loss: 0.958702428411223\n",
      "[EPOCH #24, step #374] loss: 0.958385839621226\n",
      "[EPOCH #24, step #376] loss: 0.95903159310394\n",
      "[EPOCH #24, step #378] loss: 0.9594579323300586\n",
      "[EPOCH #24, step #380] loss: 0.9605033386723576\n",
      "[EPOCH #24, step #382] loss: 0.9597985949902248\n",
      "[EPOCH #24, step #384] loss: 0.9613406949229054\n",
      "[EPOCH #24, step #386] loss: 0.9615547241166581\n",
      "[EPOCH #24, step #388] loss: 0.9622835581284256\n",
      "[EPOCH #24, step #390] loss: 0.9633026298354653\n",
      "[EPOCH #24, step #392] loss: 0.9639930104784686\n",
      "[EPOCH #24, step #394] loss: 0.9630315315874317\n",
      "[EPOCH #24, step #396] loss: 0.9632023205084524\n",
      "[EPOCH #24, step #398] loss: 0.9633897003673372\n",
      "[EPOCH #24, step #400] loss: 0.962504006829345\n",
      "[EPOCH #24, step #402] loss: 0.9628653175777596\n",
      "[EPOCH #24, step #404] loss: 0.9620270661365838\n",
      "[EPOCH #24, step #406] loss: 0.9619008992462252\n",
      "[EPOCH #24, step #408] loss: 0.9615554844546144\n",
      "[EPOCH #24, step #410] loss: 0.9605022461454944\n",
      "[EPOCH #24, step #412] loss: 0.9606833939979498\n",
      "[EPOCH #24, step #414] loss: 0.9610268377395997\n",
      "[EPOCH #24, step #416] loss: 0.9609817676692843\n",
      "[EPOCH #24, step #418] loss: 0.9610740425763096\n",
      "[EPOCH #24, step #420] loss: 0.9624338324166251\n",
      "[EPOCH #24, step #422] loss: 0.9632982380564895\n",
      "[EPOCH #24, step #424] loss: 0.9640155670222114\n",
      "[EPOCH #24, step #426] loss: 0.9630818815086151\n",
      "[EPOCH #24, step #428] loss: 0.9635479052861532\n",
      "[EPOCH #24, step #430] loss: 0.9632420321351691\n",
      "[EPOCH #24, step #432] loss: 0.962649975582854\n",
      "[EPOCH #24, step #434] loss: 0.9636969469059473\n",
      "[EPOCH #24, step #436] loss: 0.963886046573281\n",
      "[EPOCH #24, step #438] loss: 0.964140100468264\n",
      "[EPOCH #24, step #440] loss: 0.9628396099116526\n",
      "[EPOCH #24, step #442] loss: 0.9632313743940056\n",
      "[EPOCH #24, step #444] loss: 0.9617227694961462\n",
      "[EPOCH #24, step #446] loss: 0.9609473068975496\n",
      "[EPOCH #24, step #448] loss: 0.9601448861952614\n",
      "[EPOCH #24, step #450] loss: 0.9588561784930345\n",
      "[EPOCH #24, step #452] loss: 0.9597740952279131\n",
      "[EPOCH #24, step #454] loss: 0.959982846726428\n",
      "[EPOCH #24, step #456] loss: 0.9605543123032384\n",
      "[EPOCH #24, step #458] loss: 0.9601770871864684\n",
      "[EPOCH #24, step #460] loss: 0.9600510642481987\n",
      "[EPOCH #24, step #462] loss: 0.9604752191199597\n",
      "[EPOCH #24, step #464] loss: 0.961280063275368\n",
      "[EPOCH #24, step #466] loss: 0.9619087640682686\n",
      "[EPOCH #24, step #468] loss: 0.9614713466497881\n",
      "[EPOCH #24, step #470] loss: 0.9603353004799781\n",
      "[EPOCH #24, step #472] loss: 0.9595328571932512\n",
      "[EPOCH #24, step #474] loss: 0.9592730602465178\n",
      "[EPOCH #24, step #476] loss: 0.9584442168411719\n",
      "[EPOCH #24, step #478] loss: 0.9586465363711554\n",
      "[EPOCH #24, step #480] loss: 0.9589807548542776\n",
      "[EPOCH #24, step #482] loss: 0.9590711745416155\n",
      "[EPOCH #24, step #484] loss: 0.9591129299291631\n",
      "[EPOCH #24, step #486] loss: 0.9589097197540487\n",
      "[EPOCH #24, step #488] loss: 0.9597822645934325\n",
      "[EPOCH #24, step #490] loss: 0.9594016247514309\n",
      "[EPOCH #24, step #492] loss: 0.9595374425091077\n",
      "[EPOCH #24, step #494] loss: 0.9588260973342742\n",
      "[EPOCH #24, step #496] loss: 0.9584630456728714\n",
      "[EPOCH #24, step #498] loss: 0.9593044259027393\n",
      "[EPOCH #24, step #500] loss: 0.9593413296098005\n",
      "[EPOCH #24, step #502] loss: 0.9602322038077928\n",
      "[EPOCH #24, step #504] loss: 0.9604714057233074\n",
      "[EPOCH #24, step #506] loss: 0.9599556947013095\n",
      "[EPOCH #24, step #508] loss: 0.958913381184014\n",
      "[EPOCH #24, step #510] loss: 0.9593741548504615\n",
      "[EPOCH #24, step #512] loss: 0.9592535744401214\n",
      "[EPOCH #24, step #514] loss: 0.9595659966607696\n",
      "[EPOCH #24, step #516] loss: 0.9592121733457023\n",
      "[EPOCH #24, step #518] loss: 0.9593794836244601\n",
      "[EPOCH #24, step #520] loss: 0.9595067326029523\n",
      "[EPOCH #24, step #522] loss: 0.9589264920519142\n",
      "[EPOCH #24, step #524] loss: 0.9592716894830976\n",
      "[EPOCH #24, step #526] loss: 0.9589542348425574\n",
      "[EPOCH #24, step #528] loss: 0.9592040696081007\n",
      "[EPOCH #24, step #530] loss: 0.9591890115522396\n",
      "[EPOCH #24, step #532] loss: 0.9584730271997863\n",
      "[EPOCH #24, step #534] loss: 0.958093793926952\n",
      "[EPOCH #24, step #536] loss: 0.9574221059596738\n",
      "[EPOCH #24, step #538] loss: 0.9562600193085609\n",
      "[EPOCH #24, step #540] loss: 0.9563772575912546\n",
      "[EPOCH #24, step #542] loss: 0.9568843985350312\n",
      "[EPOCH #24, step #544] loss: 0.9559205522231006\n",
      "[EPOCH #24, step #546] loss: 0.9562138485734162\n",
      "[EPOCH #24, step #548] loss: 0.9564056626651674\n",
      "[EPOCH #24, step #550] loss: 0.9561969859630356\n",
      "[EPOCH #24, step #552] loss: 0.9556055563699056\n",
      "[EPOCH #24, step #554] loss: 0.9551148314733763\n",
      "[EPOCH #24, step #556] loss: 0.9557989907435925\n",
      "[EPOCH #24, step #558] loss: 0.9559333437457281\n",
      "[EPOCH #24, step #560] loss: 0.9556163279555485\n",
      "[EPOCH #24, step #562] loss: 0.9561316136991999\n",
      "[EPOCH #24, step #564] loss: 0.9546789652478378\n",
      "[EPOCH #24, step #566] loss: 0.9545068770279119\n",
      "[EPOCH #24, step #568] loss: 0.954121742495753\n",
      "[EPOCH #24, step #570] loss: 0.9529230124896128\n",
      "[EPOCH #24, step #572] loss: 0.9536369587530432\n",
      "[EPOCH #24, step #574] loss: 0.9533731639903524\n",
      "[EPOCH #24, step #576] loss: 0.9526993775904902\n",
      "[EPOCH #24, step #578] loss: 0.9525047524193614\n",
      "[EPOCH #24, step #580] loss: 0.9523460691644074\n",
      "[EPOCH #24, step #582] loss: 0.953107495352907\n",
      "[EPOCH #24, step #584] loss: 0.9533884335786869\n",
      "[EPOCH #24, step #586] loss: 0.953106669997844\n",
      "[EPOCH #24, step #588] loss: 0.9536962672081383\n",
      "[EPOCH #24, step #590] loss: 0.9533018173300071\n",
      "[EPOCH #24, step #592] loss: 0.9531789732622657\n",
      "[EPOCH #24, step #594] loss: 0.9526887188438607\n",
      "[EPOCH #24, step #596] loss: 0.9533357228865376\n",
      "[EPOCH #24, step #598] loss: 0.9525773726242015\n",
      "[EPOCH #24, step #600] loss: 0.9529837250907885\n",
      "[EPOCH #24, step #602] loss: 0.9527047208292567\n",
      "[EPOCH #24, step #604] loss: 0.9523241914008275\n",
      "[EPOCH #24, step #606] loss: 0.9539177341162668\n",
      "[EPOCH #24, step #608] loss: 0.953842994516902\n",
      "[EPOCH #24, step #610] loss: 0.9538792517103267\n",
      "[EPOCH #24, step #612] loss: 0.9530172799189756\n",
      "[EPOCH #24, step #614] loss: 0.9539503357274746\n",
      "[EPOCH #24, step #616] loss: 0.9530683912373052\n",
      "[EPOCH #24, step #618] loss: 0.9533891029812408\n",
      "[EPOCH #24, step #620] loss: 0.9529861873090747\n",
      "[EPOCH #24, step #622] loss: 0.952783909597902\n",
      "[EPOCH #24, step #624] loss: 0.953245371055603\n",
      "[EPOCH #24, step #626] loss: 0.9538583804926043\n",
      "[EPOCH #24, step #628] loss: 0.9533688730200448\n",
      "[EPOCH #24, step #630] loss: 0.9526240461979728\n",
      "[EPOCH #24, step #632] loss: 0.952497175990311\n",
      "[EPOCH #24, step #634] loss: 0.9529867229499216\n",
      "[EPOCH #24, step #636] loss: 0.9523055325123354\n",
      "[EPOCH #24, step #638] loss: 0.9523643592900141\n",
      "[EPOCH #24, step #640] loss: 0.9515200586475188\n",
      "[EPOCH #24, step #642] loss: 0.9517996822879251\n",
      "[EPOCH #24, step #644] loss: 0.9512944833252781\n",
      "[EPOCH #24, step #646] loss: 0.9519101232981203\n",
      "[EPOCH #24, step #648] loss: 0.9521711427368258\n",
      "[EPOCH #24, step #650] loss: 0.9525039653807374\n",
      "[EPOCH #24, step #652] loss: 0.9526327758981842\n",
      "[EPOCH #24, step #654] loss: 0.952270118698819\n",
      "[EPOCH #24, step #656] loss: 0.9530402524467654\n",
      "[EPOCH #24, step #658] loss: 0.9533265208619136\n",
      "[EPOCH #24, step #660] loss: 0.9531691127573668\n",
      "[EPOCH #24, step #662] loss: 0.9525210540938341\n",
      "[EPOCH #24, step #664] loss: 0.9520130887963718\n",
      "[EPOCH #24, step #666] loss: 0.9523016463691506\n",
      "[EPOCH #24, step #668] loss: 0.9528276093515758\n",
      "[EPOCH #24, step #670] loss: 0.9529385564046539\n",
      "[EPOCH #24, step #672] loss: 0.951976377755005\n",
      "[EPOCH #24, step #674] loss: 0.9516163577856841\n",
      "[EPOCH #24, step #676] loss: 0.9525798262486254\n",
      "[EPOCH #24, step #678] loss: 0.9527897084233335\n",
      "[EPOCH #24, step #680] loss: 0.9528696827601406\n",
      "[EPOCH #24, step #682] loss: 0.9532055824253255\n",
      "[EPOCH #24, step #684] loss: 0.9531856247108348\n",
      "[EPOCH #24, step #686] loss: 0.9538532237819188\n",
      "[EPOCH #24, step #688] loss: 0.9540234388045545\n",
      "[EPOCH #24, step #690] loss: 0.9534794418235591\n",
      "[EPOCH #24, step #692] loss: 0.9536883363992105\n",
      "[EPOCH #24, step #694] loss: 0.9536507563625308\n",
      "[EPOCH #24, step #696] loss: 0.9529890867011619\n",
      "[EPOCH #24, step #698] loss: 0.9532038632551146\n",
      "[EPOCH #24, step #700] loss: 0.9532310842787488\n",
      "[EPOCH #24, step #702] loss: 0.9544043116176112\n",
      "[EPOCH #24, step #704] loss: 0.9552670449229842\n",
      "[EPOCH #24, step #706] loss: 0.955808992854608\n",
      "[EPOCH #24, step #708] loss: 0.9564946192948539\n",
      "[EPOCH #24, step #710] loss: 0.9572147834317761\n",
      "[EPOCH #24, step #712] loss: 0.9568831692404032\n",
      "[EPOCH #24, step #714] loss: 0.9572806015714899\n",
      "[EPOCH #24, step #716] loss: 0.9569165367461647\n",
      "[EPOCH #24, step #718] loss: 0.9559508175776963\n",
      "[EPOCH #24, step #720] loss: 0.9559739859524117\n",
      "[EPOCH #24, step #722] loss: 0.9560326463948642\n",
      "[EPOCH #24, step #724] loss: 0.9562105772413056\n",
      "[EPOCH #24, step #726] loss: 0.956289221692774\n",
      "[EPOCH #24, step #728] loss: 0.9562051794165937\n",
      "[EPOCH #24, step #730] loss: 0.9560253793824713\n",
      "[EPOCH #24, step #732] loss: 0.9558749305437564\n",
      "[EPOCH #24, step #734] loss: 0.956120882958782\n",
      "[EPOCH #24, step #736] loss: 0.9557503300088394\n",
      "[EPOCH #24, step #738] loss: 0.9562603595776229\n",
      "[EPOCH #24, step #740] loss: 0.9557602119188399\n",
      "[EPOCH #24, step #742] loss: 0.9567852514428694\n",
      "[EPOCH #24, step #744] loss: 0.9564374797296205\n",
      "[EPOCH #24, step #746] loss: 0.9560695280990448\n",
      "[EPOCH #24, step #748] loss: 0.9559280066210055\n",
      "[EPOCH #24, step #750] loss: 0.9557532980026164\n",
      "[EPOCH #24, step #752] loss: 0.9550009984102541\n",
      "[EPOCH #24, step #754] loss: 0.9546553936225689\n",
      "[EPOCH #24, step #756] loss: 0.954999094122782\n",
      "[EPOCH #24, step #758] loss: 0.9555424934005234\n",
      "[EPOCH #24, step #760] loss: 0.9554862453652431\n",
      "[EPOCH #24, step #762] loss: 0.9561580667177003\n",
      "[EPOCH #24, step #764] loss: 0.9567304348633959\n",
      "[EPOCH #24, step #766] loss: 0.9571937216151958\n",
      "[EPOCH #24, step #768] loss: 0.9574603827474021\n",
      "[EPOCH #24, step #770] loss: 0.9576218128204346\n",
      "[EPOCH #24, step #772] loss: 0.9586148510312356\n",
      "[EPOCH #24, step #774] loss: 0.9589959746022378\n",
      "[EPOCH #24, step #776] loss: 0.9584370794750395\n",
      "[EPOCH #24, step #778] loss: 0.958239644038968\n",
      "[EPOCH #24, step #780] loss: 0.9573184531873686\n",
      "[EPOCH #24, step #782] loss: 0.9573899263927611\n",
      "[EPOCH #24, step #784] loss: 0.9567846876041145\n",
      "[EPOCH #24, step #786] loss: 0.9566216491531992\n",
      "[EPOCH #24, step #788] loss: 0.9571211025288803\n",
      "[EPOCH #24, step #790] loss: 0.9570059936809178\n",
      "[EPOCH #24, step #792] loss: 0.9565093729264499\n",
      "[EPOCH #24, step #794] loss: 0.9565321698878546\n",
      "[EPOCH #24, step #796] loss: 0.9564076387598045\n",
      "[EPOCH #24, step #798] loss: 0.9560485692585216\n",
      "[EPOCH #24, step #800] loss: 0.955635395463784\n",
      "[EPOCH #24, step #802] loss: 0.9561164880155181\n",
      "[EPOCH #24, step #804] loss: 0.9565465917498429\n",
      "[EPOCH #24, step #806] loss: 0.956372165620844\n",
      "[EPOCH #24, step #808] loss: 0.956629908792168\n",
      "[EPOCH #24, step #810] loss: 0.957066910701968\n",
      "[EPOCH #24, step #812] loss: 0.957207028936196\n",
      "[EPOCH #24, step #814] loss: 0.9571088213130741\n",
      "[EPOCH #24, step #816] loss: 0.9582649103138993\n",
      "[EPOCH #24, step #818] loss: 0.95785119259896\n",
      "[EPOCH #24, step #820] loss: 0.95856122892173\n",
      "[EPOCH #24, step #822] loss: 0.9584994605071345\n",
      "[EPOCH #24, step #824] loss: 0.959117158615228\n",
      "[EPOCH #24, step #826] loss: 0.9594014436907463\n",
      "[EPOCH #24, step #828] loss: 0.9593893152238089\n",
      "[EPOCH #24, step #830] loss: 0.9599251284496019\n",
      "[EPOCH #24, step #832] loss: 0.9595796505944068\n",
      "[EPOCH #24, step #834] loss: 0.9595142031144239\n",
      "[EPOCH #24, step #836] loss: 0.9598302386852433\n",
      "[EPOCH #24, step #838] loss: 0.9598842828009495\n",
      "[EPOCH #24, step #840] loss: 0.9596697238055761\n",
      "[EPOCH #24, step #842] loss: 0.9591772048640222\n",
      "[EPOCH #24, step #844] loss: 0.9600485035653651\n",
      "[EPOCH #24, step #846] loss: 0.9594018760510009\n",
      "[EPOCH #24, step #848] loss: 0.9595611932982545\n",
      "[EPOCH #24, step #850] loss: 0.9598132549105464\n",
      "[EPOCH #24, step #852] loss: 0.95953200270115\n",
      "[EPOCH #24, step #854] loss: 0.9592448830604553\n",
      "[EPOCH #24, step #856] loss: 0.959539641855478\n",
      "[EPOCH #24, step #858] loss: 0.9597260515542746\n",
      "[EPOCH #24, step #860] loss: 0.9593752187857367\n",
      "[EPOCH #24, step #862] loss: 0.9593222149553885\n",
      "[EPOCH #24, step #864] loss: 0.9593038381868704\n",
      "[EPOCH #24, step #866] loss: 0.9591103020148843\n",
      "[EPOCH #24, step #868] loss: 0.9600401480946908\n",
      "[EPOCH #24, step #870] loss: 0.9602722660408501\n",
      "[EPOCH #24, step #872] loss: 0.9600456300333466\n",
      "[EPOCH #24, step #874] loss: 0.959348281792232\n",
      "[EPOCH #24, step #876] loss: 0.9591229673530248\n",
      "[EPOCH #24, step #878] loss: 0.9592304276524957\n",
      "[EPOCH #24, step #880] loss: 0.9596978587676664\n",
      "[EPOCH #24, step #882] loss: 0.9597603638876875\n",
      "[EPOCH #24, step #884] loss: 0.9601419817929887\n",
      "[EPOCH #24, step #886] loss: 0.9599762317696177\n",
      "[EPOCH #24, step #888] loss: 0.9595934739933507\n",
      "[EPOCH #24, step #890] loss: 0.9599010180410178\n",
      "[EPOCH #24, step #892] loss: 0.9599567186525394\n",
      "[EPOCH #24, step #894] loss: 0.9601547067391806\n",
      "[EPOCH #24, step #896] loss: 0.960030389204206\n",
      "[EPOCH #24, step #898] loss: 0.9599403330561052\n",
      "[EPOCH #24, step #900] loss: 0.9597505652547279\n",
      "[EPOCH #24, step #902] loss: 0.9598136712546365\n",
      "[EPOCH #24, step #904] loss: 0.9601620423859655\n",
      "[EPOCH #24, step #906] loss: 0.9603432341342198\n",
      "[EPOCH #24, step #908] loss: 0.9608755228411903\n",
      "[EPOCH #24, step #910] loss: 0.9608788160539746\n",
      "[EPOCH #24, step #912] loss: 0.960586285538898\n",
      "[EPOCH #24, step #914] loss: 0.9603519082720814\n",
      "[EPOCH #24, step #916] loss: 0.9603757665227518\n",
      "[EPOCH #24, step #918] loss: 0.9608717790365997\n",
      "[EPOCH #24, step #920] loss: 0.9604639847167281\n",
      "[EPOCH #24, step #922] loss: 0.9600989724290462\n",
      "[EPOCH #24, step #924] loss: 0.9600699967951388\n",
      "[EPOCH #24, step #926] loss: 0.9605253400540275\n",
      "[EPOCH #24, step #928] loss: 0.9610158426384366\n",
      "[EPOCH #24, step #930] loss: 0.9618305818734952\n",
      "[EPOCH #24, step #932] loss: 0.9620977770477246\n",
      "[EPOCH #24, step #934] loss: 0.9623959432311237\n",
      "[EPOCH #24, step #936] loss: 0.9624226280948268\n",
      "[EPOCH #24, step #938] loss: 0.9626472306708558\n",
      "[EPOCH #24, step #940] loss: 0.9622149588451122\n",
      "[EPOCH #24, step #942] loss: 0.9620860668406886\n",
      "[EPOCH #24, step #944] loss: 0.961872692461367\n",
      "[EPOCH #24, step #946] loss: 0.9616164318359641\n",
      "[EPOCH #24, step #948] loss: 0.9611291948183821\n",
      "[EPOCH #24, step #950] loss: 0.9613335431562238\n",
      "[EPOCH #24, step #952] loss: 0.9607739392257563\n",
      "[EPOCH #24, step #954] loss: 0.9604942024066186\n",
      "[EPOCH #24, step #956] loss: 0.9604481591326316\n",
      "[EPOCH #24, step #958] loss: 0.9603253299053817\n",
      "[EPOCH #24, step #960] loss: 0.9604536621181079\n",
      "[EPOCH #24, step #962] loss: 0.9598145085084228\n",
      "[EPOCH #24, step #964] loss: 0.9592564037735598\n",
      "[EPOCH #24, step #966] loss: 0.9589423368672427\n",
      "[EPOCH #24, step #968] loss: 0.9592655686463611\n",
      "[EPOCH #24, step #970] loss: 0.9595410780545734\n",
      "[EPOCH #24, step #972] loss: 0.9588753858242348\n",
      "[EPOCH #24, step #974] loss: 0.9588761820854285\n",
      "[EPOCH #24, step #976] loss: 0.9586791767373666\n",
      "[EPOCH #24, step #978] loss: 0.9582450295188697\n",
      "[EPOCH #24, step #980] loss: 0.9580988972376611\n",
      "[EPOCH #24, step #982] loss: 0.9581787801164819\n",
      "[EPOCH #24, step #984] loss: 0.9588722309182743\n",
      "[EPOCH #24, step #986] loss: 0.9586032184846737\n",
      "[EPOCH #24, step #988] loss: 0.9590029903622561\n",
      "[EPOCH #24, step #990] loss: 0.9591228228464618\n",
      "[EPOCH #24, step #992] loss: 0.9589952065685364\n",
      "[EPOCH #24, step #994] loss: 0.959082908816074\n",
      "[EPOCH #24, step #996] loss: 0.9592011896454343\n",
      "[EPOCH #24, step #998] loss: 0.9592319143128706\n",
      "[EPOCH #24, step #1000] loss: 0.959171679857132\n",
      "[EPOCH #24, step #1002] loss: 0.9587102773954956\n",
      "[EPOCH #24, step #1004] loss: 0.9591578249611071\n",
      "[EPOCH #24, step #1006] loss: 0.9588568441148074\n",
      "[EPOCH #24, step #1008] loss: 0.959373928953564\n",
      "[EPOCH #24, step #1010] loss: 0.9593577896393135\n",
      "[EPOCH #24, step #1012] loss: 0.9601214234179358\n",
      "[EPOCH #24, step #1014] loss: 0.9599113803191726\n",
      "[EPOCH #24, step #1016] loss: 0.9595389570692882\n",
      "[EPOCH #24, step #1018] loss: 0.9597540422908457\n",
      "[EPOCH #24, step #1020] loss: 0.9598470898846805\n",
      "[EPOCH #24, step #1022] loss: 0.9597979372081402\n",
      "[EPOCH #24, step #1024] loss: 0.9601577921029998\n",
      "[EPOCH #24, step #1026] loss: 0.9601388881245978\n",
      "[EPOCH #24, step #1028] loss: 0.9605061348719546\n",
      "[EPOCH #24, step #1030] loss: 0.9599627044799834\n",
      "[EPOCH #24, step #1032] loss: 0.959899940426098\n",
      "[EPOCH #24, step #1034] loss: 0.9600978039313054\n",
      "[EPOCH #24, step #1036] loss: 0.9597787886369423\n",
      "[EPOCH #24, step #1038] loss: 0.9595800366277759\n",
      "[EPOCH #24, step #1040] loss: 0.9589904618309051\n",
      "[EPOCH #24, step #1042] loss: 0.9587932433629425\n",
      "[EPOCH #24, step #1044] loss: 0.9586907018314709\n",
      "[EPOCH #24, step #1046] loss: 0.9585473357549483\n",
      "[EPOCH #24, step #1048] loss: 0.9579554543936105\n",
      "[EPOCH #24, step #1050] loss: 0.9579917092078306\n",
      "[EPOCH #24, step #1052] loss: 0.9577947900845454\n",
      "[EPOCH #24, step #1054] loss: 0.9577095010834282\n",
      "[EPOCH #24, step #1056] loss: 0.9576840544491302\n",
      "[EPOCH #24, step #1058] loss: 0.9580773439353316\n",
      "[EPOCH #24, step #1060] loss: 0.9582894294470914\n",
      "[EPOCH #24, step #1062] loss: 0.9580027123497885\n",
      "[EPOCH #24, step #1064] loss: 0.9579129310840732\n",
      "[EPOCH #24, step #1066] loss: 0.9578940930384392\n",
      "[EPOCH #24, step #1068] loss: 0.9579593376426412\n",
      "[EPOCH #24, step #1070] loss: 0.9582724596271995\n",
      "[EPOCH #24, step #1072] loss: 0.9586648298331987\n",
      "[EPOCH #24, step #1074] loss: 0.9587452384482983\n",
      "[EPOCH #24, step #1076] loss: 0.9592169745165436\n",
      "[EPOCH #24, step #1078] loss: 0.9587144695353574\n",
      "[EPOCH #24, step #1080] loss: 0.9585930542412122\n",
      "[EPOCH #24, step #1082] loss: 0.9591525980200023\n",
      "[EPOCH #24, step #1084] loss: 0.9590972326867592\n",
      "[EPOCH #24, step #1086] loss: 0.9586882945475714\n",
      "[EPOCH #24, step #1088] loss: 0.9586613353399972\n",
      "[EPOCH #24, step #1090] loss: 0.9586234904559351\n",
      "[EPOCH #24, step #1092] loss: 0.9583767783390963\n",
      "[EPOCH #24, step #1094] loss: 0.9582448885865408\n",
      "[EPOCH #24, step #1096] loss: 0.9585032579348972\n",
      "[EPOCH #24, step #1098] loss: 0.9582043582466757\n",
      "[EPOCH #24, step #1100] loss: 0.9581102683910124\n",
      "[EPOCH #24, step #1102] loss: 0.9582736179813512\n",
      "[EPOCH #24, step #1104] loss: 0.9579557622180266\n",
      "[EPOCH #24, step #1106] loss: 0.9581457601007084\n",
      "[EPOCH #24, step #1108] loss: 0.9581986474388886\n",
      "[EPOCH #24, step #1110] loss: 0.9580516093599163\n",
      "[EPOCH #24, step #1112] loss: 0.9576729685469779\n",
      "[EPOCH #24, step #1114] loss: 0.9577187671789674\n",
      "[EPOCH #24, step #1116] loss: 0.9582864007676619\n",
      "[EPOCH #24, step #1118] loss: 0.9580831326897172\n",
      "[EPOCH #24, step #1120] loss: 0.9583862765254345\n",
      "[EPOCH #24, step #1122] loss: 0.958391870172132\n",
      "[EPOCH #24, step #1124] loss: 0.9583877346780565\n",
      "[EPOCH #24, step #1126] loss: 0.9580365673778537\n",
      "[EPOCH #24, step #1128] loss: 0.9583786883852564\n",
      "[EPOCH #24, step #1130] loss: 0.9581981388264057\n",
      "[EPOCH #24, step #1132] loss: 0.9584571130488262\n",
      "[EPOCH #24, step #1134] loss: 0.9584161915968168\n",
      "[EPOCH #24, step #1136] loss: 0.9583322206608748\n",
      "[EPOCH #24, step #1138] loss: 0.9578776679298562\n",
      "[EPOCH #24, step #1140] loss: 0.9580720868892152\n",
      "[EPOCH #24, step #1142] loss: 0.958164848263391\n",
      "[EPOCH #24, step #1144] loss: 0.957856384947831\n",
      "[EPOCH #24, step #1146] loss: 0.9578215479850769\n",
      "[EPOCH #24, step #1148] loss: 0.9578988177554311\n",
      "[EPOCH #24, step #1150] loss: 0.9582565906874311\n",
      "[EPOCH #24, step #1152] loss: 0.9585323133162592\n",
      "[EPOCH #24, step #1154] loss: 0.9588020002687132\n",
      "[EPOCH #24, step #1156] loss: 0.959010240633939\n",
      "[EPOCH #24, step #1158] loss: 0.9592453979849301\n",
      "[EPOCH #24, step #1160] loss: 0.9595204302712209\n",
      "[EPOCH #24, step #1162] loss: 0.9598474853631247\n",
      "[EPOCH #24, step #1164] loss: 0.9606013062174228\n",
      "[EPOCH #24, step #1166] loss: 0.9605462654799402\n",
      "[EPOCH #24, step #1168] loss: 0.9602485907393913\n",
      "[EPOCH #24, step #1170] loss: 0.9597793064445231\n",
      "[EPOCH #24, step #1172] loss: 0.9596311690608152\n",
      "[EPOCH #24, step #1174] loss: 0.9592907672486407\n",
      "[EPOCH #24, step #1176] loss: 0.9594200247156488\n",
      "[EPOCH #24, step #1178] loss: 0.9595714854273986\n",
      "[EPOCH #24, step #1180] loss: 0.9599988408304694\n",
      "[EPOCH #24, step #1182] loss: 0.9602756112536835\n",
      "[EPOCH #24, step #1184] loss: 0.9607021871246869\n",
      "[EPOCH #24, step #1186] loss: 0.960609415472307\n",
      "[EPOCH #24, step #1188] loss: 0.960422524115536\n",
      "[EPOCH #24, step #1190] loss: 0.9608631379508251\n",
      "[EPOCH #24, step #1192] loss: 0.9607292189632057\n",
      "[EPOCH #24, step #1194] loss: 0.9606182756034899\n",
      "[EPOCH #24, step #1196] loss: 0.9605348144308566\n",
      "[EPOCH #24, step #1198] loss: 0.9605854804114166\n",
      "[EPOCH #24, step #1200] loss: 0.9602653395871537\n",
      "[EPOCH #24, step #1202] loss: 0.9603357809786983\n",
      "[EPOCH #24, step #1204] loss: 0.9606029978678929\n",
      "[EPOCH #24, step #1206] loss: 0.9605111537289798\n",
      "[EPOCH #24, step #1208] loss: 0.9603482531406743\n",
      "[EPOCH #24, step #1210] loss: 0.9601821062438848\n",
      "[EPOCH #24, step #1212] loss: 0.9602544390015236\n",
      "[EPOCH #24, step #1214] loss: 0.9602994898955027\n",
      "[EPOCH #24, step #1216] loss: 0.9603853806326795\n",
      "[EPOCH #24, step #1218] loss: 0.9606123127782804\n",
      "[EPOCH #24, step #1220] loss: 0.9605802949533221\n",
      "[EPOCH #24, step #1222] loss: 0.96081042833145\n",
      "[EPOCH #24, step #1224] loss: 0.9607942570228966\n",
      "[EPOCH #24, step #1226] loss: 0.960771268110695\n",
      "[EPOCH #24, step #1228] loss: 0.9608692413573346\n",
      "[EPOCH #24, step #1230] loss: 0.9607949915646926\n",
      "[EPOCH #24, step #1232] loss: 0.9606252068295676\n",
      "[EPOCH #24, step #1234] loss: 0.9609275278050889\n",
      "[EPOCH #24, step #1236] loss: 0.9602774566908275\n",
      "[EPOCH #24, step #1238] loss: 0.9604787987456195\n",
      "[EPOCH #24, step #1240] loss: 0.9602301355382303\n",
      "[EPOCH #24, step #1242] loss: 0.9598338979679255\n",
      "[EPOCH #24, step #1244] loss: 0.9603368307931356\n",
      "[EPOCH #24, step #1246] loss: 0.9601939283520485\n",
      "[EPOCH #24, step #1248] loss: 0.9603951565974994\n",
      "[EPOCH #24, step #1250] loss: 0.9603548343185422\n",
      "[EPOCH #24, step #1252] loss: 0.9600075806557228\n",
      "[EPOCH #24, step #1254] loss: 0.960194765215376\n",
      "[EPOCH #24, step #1256] loss: 0.9602230094734789\n",
      "[EPOCH #24, step #1258] loss: 0.9604943104212581\n",
      "[EPOCH #24, step #1260] loss: 0.9601357879145197\n",
      "[EPOCH #24, step #1262] loss: 0.9601522902836426\n",
      "[EPOCH #24, step #1264] loss: 0.9599647825178893\n",
      "[EPOCH #24, step #1266] loss: 0.9599232804662332\n",
      "[EPOCH #24, step #1268] loss: 0.9595256297723621\n",
      "[EPOCH #24, step #1270] loss: 0.9592346433435811\n",
      "[EPOCH #24, step #1272] loss: 0.959134193287997\n",
      "[EPOCH #24, step #1274] loss: 0.9597243774872201\n",
      "[EPOCH #24, step #1276] loss: 0.9595141139876217\n",
      "[EPOCH #24, step #1278] loss: 0.9592191645696445\n",
      "[EPOCH #24, step #1280] loss: 0.9589321166858554\n",
      "[EPOCH #24, step #1282] loss: 0.9592654543608683\n",
      "[EPOCH #24, step #1284] loss: 0.9592873572607449\n",
      "[EPOCH #24, step #1286] loss: 0.9595015444260933\n",
      "[EPOCH #24, step #1288] loss: 0.9599613356118613\n",
      "[EPOCH #24, step #1290] loss: 0.9601980647913344\n",
      "[EPOCH #24, step #1292] loss: 0.960357774507142\n",
      "[EPOCH #24, step #1294] loss: 0.9604795710690693\n",
      "[EPOCH #24, step #1296] loss: 0.9602165549143333\n",
      "[EPOCH #24, step #1298] loss: 0.9603010090476646\n",
      "[EPOCH #24, step #1300] loss: 0.9605560921917138\n",
      "[EPOCH #24, step #1302] loss: 0.961220536864179\n",
      "[EPOCH #24, step #1304] loss: 0.9610967715809628\n",
      "[EPOCH #24, step #1306] loss: 0.9610439881670995\n",
      "[EPOCH #24, step #1308] loss: 0.9613986527810486\n",
      "[EPOCH #24, step #1310] loss: 0.9615546235549004\n",
      "[EPOCH #24, step #1312] loss: 0.9614780614009271\n",
      "[EPOCH #24, step #1314] loss: 0.961586228817588\n",
      "[EPOCH #24, step #1316] loss: 0.9616502756274099\n",
      "[EPOCH #24, step #1318] loss: 0.9613816447787614\n",
      "[EPOCH #24, step #1320] loss: 0.9614024904756091\n",
      "[EPOCH #24, step #1322] loss: 0.9612177948066888\n",
      "[EPOCH #24, step #1324] loss: 0.9611677679250825\n",
      "[EPOCH #24, step #1326] loss: 0.9614144666309903\n",
      "[EPOCH #24, step #1328] loss: 0.9614494660682836\n",
      "[EPOCH #24, step #1330] loss: 0.961428922495387\n",
      "[EPOCH #24, step #1332] loss: 0.9612800161684713\n",
      "[EPOCH #24, step #1334] loss: 0.9606615396251392\n",
      "[EPOCH #24, step #1336] loss: 0.9607083649223388\n",
      "[EPOCH #24, step #1338] loss: 0.9602421775649429\n",
      "[EPOCH #24, step #1340] loss: 0.9602056265455142\n",
      "[EPOCH #24, step #1342] loss: 0.9603717615820984\n",
      "[EPOCH #24, step #1344] loss: 0.960187818060134\n",
      "[EPOCH #24, step #1346] loss: 0.9601155792286242\n",
      "[EPOCH #24, step #1348] loss: 0.9602499906666815\n",
      "[EPOCH #24, step #1350] loss: 0.9602173762044406\n",
      "[EPOCH #24, step #1352] loss: 0.9599467561541005\n",
      "[EPOCH #24, step #1354] loss: 0.9597273452475502\n",
      "[EPOCH #24, step #1356] loss: 0.9598616052174621\n",
      "[EPOCH #24, step #1358] loss: 0.9598038784496218\n",
      "[EPOCH #24, step #1360] loss: 0.9599536174058388\n",
      "[EPOCH #24, step #1362] loss: 0.9595034912895474\n",
      "[EPOCH #24, step #1364] loss: 0.9593761394530426\n",
      "[EPOCH #24, step #1366] loss: 0.9591813997229958\n",
      "[EPOCH #24, step #1368] loss: 0.9591802794233215\n",
      "[EPOCH #24, step #1370] loss: 0.9590052056929911\n",
      "[EPOCH #24, step #1372] loss: 0.9588229453268489\n",
      "[EPOCH #24, step #1374] loss: 0.9589882856932553\n",
      "[EPOCH #24, step #1376] loss: 0.9592037170844053\n",
      "[EPOCH #24, step #1378] loss: 0.9588607074861686\n",
      "[EPOCH #24, step #1380] loss: 0.9592976342889384\n",
      "[EPOCH #24, step #1382] loss: 0.9594646237806747\n",
      "[EPOCH #24, step #1384] loss: 0.9592964277155562\n",
      "[EPOCH #24, step #1386] loss: 0.9592967171976698\n",
      "[EPOCH #24, step #1388] loss: 0.959283038619785\n",
      "[EPOCH #24, step #1390] loss: 0.959588498691275\n",
      "[EPOCH #24, step #1392] loss: 0.9592996067437695\n",
      "[EPOCH #24, step #1394] loss: 0.959221202989633\n",
      "[EPOCH #24, step #1396] loss: 0.9590044308963126\n",
      "[EPOCH #24, step #1398] loss: 0.9590244060801641\n",
      "[EPOCH #24, step #1400] loss: 0.9593950179242645\n",
      "[EPOCH #24, step #1402] loss: 0.9598221112087805\n",
      "[EPOCH #24, step #1404] loss: 0.9598298061148551\n",
      "[EPOCH #24, step #1406] loss: 0.9596996224553516\n",
      "[EPOCH #24, step #1408] loss: 0.9595312912511521\n",
      "[EPOCH #24, step #1410] loss: 0.9598868939362883\n",
      "[EPOCH #24, step #1412] loss: 0.9596976047910365\n",
      "[EPOCH #24, step #1414] loss: 0.9595606990711428\n",
      "[EPOCH #24, step #1416] loss: 0.959820138352306\n",
      "[EPOCH #24, step #1418] loss: 0.9597447875984292\n",
      "[EPOCH #24, step #1420] loss: 0.9596612230939483\n",
      "[EPOCH #24, step #1422] loss: 0.9598544195807491\n",
      "[EPOCH #24, step #1424] loss: 0.9595900043479183\n",
      "[EPOCH #24, step #1426] loss: 0.9597132903717578\n",
      "[EPOCH #24, step #1428] loss: 0.9601030681957474\n",
      "[EPOCH #24, step #1430] loss: 0.95998746975163\n",
      "[EPOCH #24, step #1432] loss: 0.9596850937134889\n",
      "[EPOCH #24, step #1434] loss: 0.9598231723707312\n",
      "[EPOCH #24, step #1436] loss: 0.9597448646275634\n",
      "[EPOCH #24, step #1438] loss: 0.9597958627676616\n",
      "[EPOCH #24, step #1440] loss: 0.9598944916194053\n",
      "[EPOCH #24, step #1442] loss: 0.9597999098105969\n",
      "[EPOCH #24, step #1444] loss: 0.9598225735669318\n",
      "[EPOCH #24, step #1446] loss: 0.9601136324277152\n",
      "[EPOCH #24, step #1448] loss: 0.9600236975504992\n",
      "[EPOCH #24, step #1450] loss: 0.960725018540224\n",
      "[EPOCH #24, step #1452] loss: 0.9606520278201133\n",
      "[EPOCH #24, step #1454] loss: 0.9604114391344929\n",
      "[EPOCH #24, step #1456] loss: 0.9605932910514352\n",
      "[EPOCH #24, step #1458] loss: 0.9605592887355825\n",
      "[EPOCH #24, step #1460] loss: 0.9605694987405089\n",
      "[EPOCH #24, step #1462] loss: 0.9604448363826605\n",
      "[EPOCH #24, step #1464] loss: 0.9601800448455095\n",
      "[EPOCH #24, step #1466] loss: 0.959896834207865\n",
      "[EPOCH #24, step #1468] loss: 0.9599392058859073\n",
      "[EPOCH #24, step #1470] loss: 0.9593376532895965\n",
      "[EPOCH #24, step #1472] loss: 0.9595229559541962\n",
      "[EPOCH #24, step #1474] loss: 0.9593349737434064\n",
      "[EPOCH #24, step #1476] loss: 0.959262252156607\n",
      "[EPOCH #24, step #1478] loss: 0.9589980623664044\n",
      "[EPOCH #24, step #1480] loss: 0.9590353369109136\n",
      "[EPOCH #24, step #1482] loss: 0.9591026859394377\n",
      "[EPOCH #24, step #1484] loss: 0.9592040539389909\n",
      "[EPOCH #24, step #1486] loss: 0.9592016501040289\n",
      "[EPOCH #24, step #1488] loss: 0.9591282077128652\n",
      "[EPOCH #24, step #1490] loss: 0.9591836430617101\n",
      "[EPOCH #24, step #1492] loss: 0.9591288467381357\n",
      "[EPOCH #24, step #1494] loss: 0.9592827489344172\n",
      "[EPOCH #24, step #1496] loss: 0.9591264774302443\n",
      "[EPOCH #24, step #1498] loss: 0.9588985570555452\n",
      "[EPOCH #24, step #1500] loss: 0.9589800093469423\n",
      "[EPOCH #24, step #1502] loss: 0.9589278997180467\n",
      "[EPOCH #24, step #1504] loss: 0.9591506214830963\n",
      "[EPOCH #24, step #1506] loss: 0.9594397229830318\n",
      "[EPOCH #24, step #1508] loss: 0.9595390447446888\n",
      "[EPOCH #24, step #1510] loss: 0.9591983444125821\n",
      "[EPOCH #24, step #1512] loss: 0.9589609670977836\n",
      "[EPOCH #24, step #1514] loss: 0.9595113844564646\n",
      "[EPOCH #24, step #1516] loss: 0.9591346887003535\n",
      "[EPOCH #24, step #1518] loss: 0.9589928170620728\n",
      "[EPOCH #24, step #1520] loss: 0.9587625642695919\n",
      "[EPOCH #24, step #1522] loss: 0.9583560639866386\n",
      "[EPOCH #24, step #1524] loss: 0.9583988453716529\n",
      "[EPOCH #24, step #1526] loss: 0.9582250027501982\n",
      "[EPOCH #24, step #1528] loss: 0.95836839617819\n",
      "[EPOCH #24, step #1530] loss: 0.95848198389789\n",
      "[EPOCH #24, step #1532] loss: 0.958204921191608\n",
      "[EPOCH #24, step #1534] loss: 0.9579712181409717\n",
      "[EPOCH #24, step #1536] loss: 0.9580981498153938\n",
      "[EPOCH #24, step #1538] loss: 0.958047545773399\n",
      "[EPOCH #24, step #1540] loss: 0.9580950520976188\n",
      "[EPOCH #24, step #1542] loss: 0.9585520986103038\n",
      "[EPOCH #24, step #1544] loss: 0.9583175668631557\n",
      "[EPOCH #24, step #1546] loss: 0.9584105239233511\n",
      "[EPOCH #24, step #1548] loss: 0.9586450941836626\n",
      "[EPOCH #24, step #1550] loss: 0.9590606468673831\n",
      "[EPOCH #24, step #1552] loss: 0.9587423699138553\n",
      "[EPOCH #24, step #1554] loss: 0.9585370350305674\n",
      "[EPOCH #24, step #1556] loss: 0.9584114761519448\n",
      "[EPOCH #24, step #1558] loss: 0.9584659701780756\n",
      "[EPOCH #24, step #1560] loss: 0.9582390953034334\n",
      "[EPOCH #24, step #1562] loss: 0.9583353715414278\n",
      "[EPOCH #24, step #1564] loss: 0.9579813792111394\n",
      "[EPOCH #24, step #1566] loss: 0.9578885268503188\n",
      "[EPOCH #24, step #1568] loss: 0.9577142850580757\n",
      "[EPOCH #24, step #1570] loss: 0.957696491237054\n",
      "[EPOCH #24, step #1572] loss: 0.9576953179087521\n",
      "[EPOCH #24, step #1574] loss: 0.95739426576902\n",
      "[EPOCH #24, step #1576] loss: 0.9575243586781815\n",
      "[EPOCH #24, step #1578] loss: 0.9574295633612289\n",
      "[EPOCH #24, step #1580] loss: 0.956946344672691\n",
      "[EPOCH #24, step #1582] loss: 0.9569006412185903\n",
      "[EPOCH #24, step #1584] loss: 0.9571157343192055\n",
      "[EPOCH #24, step #1586] loss: 0.9570854177584646\n",
      "[EPOCH #24, step #1588] loss: 0.9570535609112962\n",
      "[EPOCH #24, step #1590] loss: 0.9573292360037546\n",
      "[EPOCH #24, step #1592] loss: 0.9574678052130242\n",
      "[EPOCH #24, step #1594] loss: 0.9573379636371397\n",
      "[EPOCH #24, step #1596] loss: 0.9573074142001312\n",
      "[EPOCH #24, step #1598] loss: 0.9572290952426333\n",
      "[EPOCH #24, step #1600] loss: 0.9573934930216738\n",
      "[EPOCH #24, step #1602] loss: 0.9577561092800597\n",
      "[EPOCH #24, step #1604] loss: 0.9580193506408703\n",
      "[EPOCH #24, step #1606] loss: 0.9577189572456837\n",
      "[EPOCH #24, step #1608] loss: 0.9579149001388538\n",
      "[EPOCH #24, step #1610] loss: 0.9576757859362348\n",
      "[EPOCH #24, step #1612] loss: 0.9578385447132906\n",
      "[EPOCH #24, step #1614] loss: 0.9578795386726273\n",
      "[EPOCH #24, step #1616] loss: 0.9578407094776447\n",
      "[EPOCH #24, step #1618] loss: 0.9576372790844666\n",
      "[EPOCH #24, step #1620] loss: 0.957551727594232\n",
      "[EPOCH #24, step #1622] loss: 0.9573760231519582\n",
      "[EPOCH #24, step #1624] loss: 0.9574772374629974\n",
      "[EPOCH #24, step #1626] loss: 0.9574720483106122\n",
      "[EPOCH #24, step #1628] loss: 0.9574083882544654\n",
      "[EPOCH #24, step #1630] loss: 0.9573208652231169\n",
      "[EPOCH #24, step #1632] loss: 0.9571673870269171\n",
      "[EPOCH #24, step #1634] loss: 0.956999665535189\n",
      "[EPOCH #24, step #1636] loss: 0.9574440804537142\n",
      "[EPOCH #24, step #1638] loss: 0.9577908369918797\n",
      "[EPOCH #24, step #1640] loss: 0.9577448183011166\n",
      "[EPOCH #24, step #1642] loss: 0.9575728316787387\n",
      "[EPOCH #24, step #1644] loss: 0.9574189057284938\n",
      "[EPOCH #24, step #1646] loss: 0.9572129729992706\n",
      "[EPOCH #24, step #1648] loss: 0.957595426053839\n",
      "[EPOCH #24, step #1650] loss: 0.957734903066827\n",
      "[EPOCH #24, step #1652] loss: 0.9576247122636796\n",
      "[EPOCH #24, step #1654] loss: 0.9579101508297589\n",
      "[EPOCH #24, step #1656] loss: 0.9577068876234537\n",
      "[EPOCH #24, step #1658] loss: 0.9577703710741994\n",
      "[EPOCH #24, step #1660] loss: 0.9578358101277807\n",
      "[EPOCH #24, step #1662] loss: 0.9580024137277597\n",
      "[EPOCH #24, step #1664] loss: 0.9584453422207017\n",
      "[EPOCH #24, step #1666] loss: 0.9584300636208265\n",
      "[EPOCH #24, step #1668] loss: 0.9586316765140387\n",
      "[EPOCH #24, step #1670] loss: 0.9589035190164793\n",
      "[EPOCH #24, step #1672] loss: 0.9588620828891042\n",
      "[EPOCH #24, step #1674] loss: 0.9591471119247266\n",
      "[EPOCH #24, step #1676] loss: 0.9590855224294611\n",
      "[EPOCH #24, step #1678] loss: 0.9590500409117477\n",
      "[EPOCH #24, step #1680] loss: 0.9587236423530726\n",
      "[EPOCH #24, step #1682] loss: 0.958693371506865\n",
      "[EPOCH #24, step #1684] loss: 0.9589150466798675\n",
      "[EPOCH #24, step #1686] loss: 0.9591626911631123\n",
      "[EPOCH #24, step #1688] loss: 0.9591446405440974\n",
      "[EPOCH #24, step #1690] loss: 0.9594804814657045\n",
      "[EPOCH #24, step #1692] loss: 0.9596372145523493\n",
      "[EPOCH #24, step #1694] loss: 0.9592881933250258\n",
      "[EPOCH #24, step #1696] loss: 0.9594312228556584\n",
      "[EPOCH #24, step #1698] loss: 0.9593956545389982\n",
      "[EPOCH #24, step #1700] loss: 0.9591801271482049\n",
      "[EPOCH #24, step #1702] loss: 0.959307773055151\n",
      "[EPOCH #24, step #1704] loss: 0.959083903028119\n",
      "[EPOCH #24, step #1706] loss: 0.9593283270246185\n",
      "[EPOCH #24, step #1708] loss: 0.9592963225001686\n",
      "[EPOCH #24, step #1710] loss: 0.9591241428233391\n",
      "[EPOCH #24, step #1712] loss: 0.9590672072060124\n",
      "[EPOCH #24, step #1714] loss: 0.9587784174058597\n",
      "[EPOCH #24, step #1716] loss: 0.9589938236206301\n",
      "[EPOCH #24, step #1718] loss: 0.9588521079416535\n",
      "[EPOCH #24, step #1720] loss: 0.9587800153842296\n",
      "[EPOCH #24, step #1722] loss: 0.9586746194337733\n",
      "[EPOCH #24, step #1724] loss: 0.9588750925789709\n",
      "[EPOCH #24, step #1726] loss: 0.9589318537649973\n",
      "[EPOCH #24, step #1728] loss: 0.9588603668126018\n",
      "[EPOCH #24, step #1730] loss: 0.9586197568425411\n",
      "[EPOCH #24, step #1732] loss: 0.95849706236847\n",
      "[EPOCH #24, step #1734] loss: 0.9583690224703862\n",
      "[EPOCH #24, step #1736] loss: 0.9582533113525459\n",
      "[EPOCH #24, step #1738] loss: 0.9579107439709916\n",
      "[EPOCH #24, step #1740] loss: 0.9579759260520793\n",
      "[EPOCH #24, step #1742] loss: 0.9577756881269311\n",
      "[EPOCH #24, step #1744] loss: 0.9575853338385039\n",
      "[EPOCH #24, step #1746] loss: 0.9577679393389734\n",
      "[EPOCH #24, step #1748] loss: 0.9577796466865834\n",
      "[EPOCH #24, step #1750] loss: 0.9577869414636436\n",
      "[EPOCH #24, step #1752] loss: 0.9578142188068668\n",
      "[EPOCH #24, step #1754] loss: 0.957988862043772\n",
      "[EPOCH #24, step #1756] loss: 0.9579789114561553\n",
      "[EPOCH #24, step #1758] loss: 0.9577008443606584\n",
      "[EPOCH #24, step #1760] loss: 0.9580834570389997\n",
      "[EPOCH #24, step #1762] loss: 0.957944430465801\n",
      "[EPOCH #24, step #1764] loss: 0.9577375770797135\n",
      "[EPOCH #24, step #1766] loss: 0.9575889534746514\n",
      "[EPOCH #24, step #1768] loss: 0.9573891698775013\n",
      "[EPOCH #24, step #1770] loss: 0.9572345189190665\n",
      "[EPOCH #24, step #1772] loss: 0.9572825967189759\n",
      "[EPOCH #24, step #1774] loss: 0.9570239575312172\n",
      "[EPOCH #24, step #1776] loss: 0.9571730390685826\n",
      "[EPOCH #24, step #1778] loss: 0.9568931063518824\n",
      "[EPOCH #24, step #1780] loss: 0.9567228092329345\n",
      "[EPOCH #24, step #1782] loss: 0.9565471130780002\n",
      "[EPOCH #24, step #1784] loss: 0.9563333861467217\n",
      "[EPOCH #24, step #1786] loss: 0.9562204966981382\n",
      "[EPOCH #24, step #1788] loss: 0.9562593668349433\n",
      "[EPOCH #24, step #1790] loss: 0.956235484378688\n",
      "[EPOCH #24, step #1792] loss: 0.9560592063997155\n",
      "[EPOCH #24, step #1794] loss: 0.9558085056566594\n",
      "[EPOCH #24, step #1796] loss: 0.955956919646356\n",
      "[EPOCH #24, step #1798] loss: 0.9558690076175168\n",
      "[EPOCH #24, step #1800] loss: 0.955826064353516\n",
      "[EPOCH #24, step #1802] loss: 0.9559396780568629\n",
      "[EPOCH #24, step #1804] loss: 0.9559240703932796\n",
      "[EPOCH #24, step #1806] loss: 0.9560780165171716\n",
      "[EPOCH #24, step #1808] loss: 0.9561559066151702\n",
      "[EPOCH #24, step #1810] loss: 0.956664313883626\n",
      "[EPOCH #24, step #1812] loss: 0.9564827533137779\n",
      "[EPOCH #24, step #1814] loss: 0.9563043487466071\n",
      "[EPOCH #24, step #1816] loss: 0.9563578191896553\n",
      "[EPOCH #24, step #1818] loss: 0.9563720166814268\n",
      "[EPOCH #24, step #1820] loss: 0.9562794215760344\n",
      "[EPOCH #24, step #1822] loss: 0.9561012094483817\n",
      "[EPOCH #24, step #1824] loss: 0.9558189307010337\n",
      "[EPOCH #24, step #1826] loss: 0.9558891666574953\n",
      "[EPOCH #24, step #1828] loss: 0.9557129858523005\n",
      "[EPOCH #24, step #1830] loss: 0.9558586694222861\n",
      "[EPOCH #24, step #1832] loss: 0.9563065999626008\n",
      "[EPOCH #24, step #1834] loss: 0.956329914188515\n",
      "[EPOCH #24, step #1836] loss: 0.956243400429018\n",
      "[EPOCH #24, step #1838] loss: 0.9560719926341712\n",
      "[EPOCH #24, step #1840] loss: 0.955995636310738\n",
      "[EPOCH #24, step #1842] loss: 0.9559595105089187\n",
      "[EPOCH #24, step #1844] loss: 0.9559443136056264\n",
      "[EPOCH #24, step #1846] loss: 0.9556832847462258\n",
      "[EPOCH #24, step #1848] loss: 0.9557221420814438\n",
      "[EPOCH #24, step #1850] loss: 0.955433816812542\n",
      "[EPOCH #24, step #1852] loss: 0.9551852720046262\n",
      "[EPOCH #24, step #1854] loss: 0.9551439160124632\n",
      "[EPOCH #24, step #1856] loss: 0.9549783329104761\n",
      "[EPOCH #24, step #1858] loss: 0.9550239523454915\n",
      "[EPOCH #24, step #1860] loss: 0.9548688180692602\n",
      "[EPOCH #24, step #1862] loss: 0.9549273944355375\n",
      "[EPOCH #24, step #1864] loss: 0.9548265846900582\n",
      "[EPOCH #24, step #1866] loss: 0.9548712057516928\n",
      "[EPOCH #24, step #1868] loss: 0.9546720766970154\n",
      "[EPOCH #24, step #1870] loss: 0.9550055358449384\n",
      "[EPOCH #24, step #1872] loss: 0.9551449628418547\n",
      "[EPOCH #24, step #1874] loss: 0.955142200533549\n",
      "[EPOCH #24, step #1876] loss: 0.9549590752806889\n",
      "[EPOCH #24, step #1878] loss: 0.9548730532687798\n",
      "[EPOCH #24, step #1880] loss: 0.9546145078097804\n",
      "[EPOCH #24, step #1882] loss: 0.9546688608014071\n",
      "[EPOCH #24, step #1884] loss: 0.9544645359724839\n",
      "[EPOCH #24, step #1886] loss: 0.9543063915085401\n",
      "[EPOCH #24, step #1888] loss: 0.9547112328530367\n",
      "[EPOCH #24, step #1890] loss: 0.9545628936564337\n",
      "[EPOCH #24, step #1892] loss: 0.9545800362512414\n",
      "[EPOCH #24, step #1894] loss: 0.954504510658083\n",
      "[EPOCH #24, step #1896] loss: 0.9544142740741804\n",
      "[EPOCH #24, step #1898] loss: 0.9544332811492189\n",
      "[EPOCH #24, step #1900] loss: 0.9543940413631558\n",
      "[EPOCH #24, step #1902] loss: 0.9542027946465653\n",
      "[EPOCH #24, step #1904] loss: 0.9542813143705132\n",
      "[EPOCH #24, step #1906] loss: 0.9541358149170438\n",
      "[EPOCH #24, step #1908] loss: 0.954219689133156\n",
      "[EPOCH #24, step #1910] loss: 0.9539260737157379\n",
      "[EPOCH #24, step #1912] loss: 0.9537666456991007\n",
      "[EPOCH #24, step #1914] loss: 0.9537444537831349\n",
      "[EPOCH #24, step #1916] loss: 0.95374600995812\n",
      "[EPOCH #24, step #1918] loss: 0.9534690188609913\n",
      "[EPOCH #24, step #1920] loss: 0.9533950434663158\n",
      "[EPOCH #24, step #1922] loss: 0.9534338644656798\n",
      "[EPOCH #24, step #1924] loss: 0.9535667000343273\n",
      "[EPOCH #24, step #1926] loss: 0.9535069170707114\n",
      "[EPOCH #24, step #1928] loss: 0.9538313085053979\n",
      "[EPOCH #24, step #1930] loss: 0.9539097410017564\n",
      "[EPOCH #24, step #1932] loss: 0.9542626127238355\n",
      "[EPOCH #24, step #1934] loss: 0.9541471216875761\n",
      "[EPOCH #24, step #1936] loss: 0.954243030185606\n",
      "[EPOCH #24, step #1938] loss: 0.9541676317588025\n",
      "[EPOCH #24, step #1940] loss: 0.9541930536797586\n",
      "[EPOCH #24, step #1942] loss: 0.954148784210801\n",
      "[EPOCH #24, step #1944] loss: 0.9541073359836343\n",
      "[EPOCH #24, step #1946] loss: 0.9539679818019906\n",
      "[EPOCH #24, step #1948] loss: 0.95415663546388\n",
      "[EPOCH #24, step #1950] loss: 0.9544075116599174\n",
      "[EPOCH #24, step #1952] loss: 0.9542126283087733\n",
      "[EPOCH #24, step #1954] loss: 0.9542069130084094\n",
      "[EPOCH #24, step #1956] loss: 0.9540627833739433\n",
      "[EPOCH #24, step #1958] loss: 0.9541118467353082\n",
      "[EPOCH #24, step #1960] loss: 0.953879508739342\n",
      "[EPOCH #24, step #1962] loss: 0.953877530153224\n",
      "[EPOCH #24, step #1964] loss: 0.9536953833721976\n",
      "[EPOCH #24, step #1966] loss: 0.9534656275906536\n",
      "[EPOCH #24, step #1968] loss: 0.9534422054304091\n",
      "[EPOCH #24, step #1970] loss: 0.9534772594739555\n",
      "[EPOCH #24, step #1972] loss: 0.9535689261952935\n",
      "[EPOCH #24, step #1974] loss: 0.9537344788448721\n",
      "[EPOCH #24, step #1976] loss: 0.9541478761380889\n",
      "[EPOCH #24, step #1978] loss: 0.954075541066786\n",
      "[EPOCH #24, step #1980] loss: 0.954031063820123\n",
      "[EPOCH #24, step #1982] loss: 0.9541981323493952\n",
      "[EPOCH #24, step #1984] loss: 0.9542781890339455\n",
      "[EPOCH #24, step #1986] loss: 0.9544556095453741\n",
      "[EPOCH #24, step #1988] loss: 0.9546106781804903\n",
      "[EPOCH #24, step #1990] loss: 0.9546385748281004\n",
      "[EPOCH #24, step #1992] loss: 0.9547496965137248\n",
      "[EPOCH #24, step #1994] loss: 0.9547774378369028\n",
      "[EPOCH #24, step #1996] loss: 0.9548019774120093\n",
      "[EPOCH #24, step #1998] loss: 0.9548888503014296\n",
      "[EPOCH #24, step #2000] loss: 0.9549223589545665\n",
      "[EPOCH #24, step #2002] loss: 0.9547993998883428\n",
      "[EPOCH #24, step #2004] loss: 0.9547963352720636\n",
      "[EPOCH #24, step #2006] loss: 0.9548279027262908\n",
      "[EPOCH #24, step #2008] loss: 0.9546239688925745\n",
      "[EPOCH #24, step #2010] loss: 0.9546061794091552\n",
      "[EPOCH #24, step #2012] loss: 0.9546404746682622\n",
      "[EPOCH #24, step #2014] loss: 0.9545359110861795\n",
      "[EPOCH #24, step #2016] loss: 0.9546247053010427\n",
      "[EPOCH #24, step #2018] loss: 0.9543939656907819\n",
      "[EPOCH #24, step #2020] loss: 0.9542966144530859\n",
      "[EPOCH #24, step #2022] loss: 0.9542860973753436\n",
      "[EPOCH #24, step #2024] loss: 0.9545777541766932\n",
      "[EPOCH #24, step #2026] loss: 0.9543476567429513\n",
      "[EPOCH #24, step #2028] loss: 0.9543034705021747\n",
      "[EPOCH #24, step #2030] loss: 0.9544295231765388\n",
      "[EPOCH #24, step #2032] loss: 0.9546077272103916\n",
      "[EPOCH #24, step #2034] loss: 0.9544592996340712\n",
      "[EPOCH #24, step #2036] loss: 0.9544523320159435\n",
      "[EPOCH #24, step #2038] loss: 0.9543386622496012\n",
      "[EPOCH #24, step #2040] loss: 0.9543315439262792\n",
      "[EPOCH #24, step #2042] loss: 0.9543783101187112\n",
      "[EPOCH #24, step #2044] loss: 0.9542845834875456\n",
      "[EPOCH #24, step #2046] loss: 0.9543214052056591\n",
      "[EPOCH #24, step #2048] loss: 0.9542092685149087\n",
      "[EPOCH #24, step #2050] loss: 0.9542783758135785\n",
      "[EPOCH #24, step #2052] loss: 0.9541502882519177\n",
      "[EPOCH #24, step #2054] loss: 0.9540387971412817\n",
      "[EPOCH #24, step #2056] loss: 0.9541275408091798\n",
      "[EPOCH #24, step #2058] loss: 0.9541116312703443\n",
      "[EPOCH #24, step #2060] loss: 0.9539765207036383\n",
      "[EPOCH #24, step #2062] loss: 0.9540408966296284\n",
      "[EPOCH #24, step #2064] loss: 0.9538823187928511\n",
      "[EPOCH #24, step #2066] loss: 0.9540104254842323\n",
      "[EPOCH #24, step #2068] loss: 0.9539443571507614\n",
      "[EPOCH #24, step #2070] loss: 0.9540111284247923\n",
      "[EPOCH #24, step #2072] loss: 0.954098015994883\n",
      "[EPOCH #24, step #2074] loss: 0.9538647966356163\n",
      "[EPOCH #24, step #2076] loss: 0.954030369343411\n",
      "[EPOCH #24, step #2078] loss: 0.9544067508816547\n",
      "[EPOCH #24, step #2080] loss: 0.9542752446061656\n",
      "[EPOCH #24, step #2082] loss: 0.9543486977075649\n",
      "[EPOCH #24, step #2084] loss: 0.9543077748313511\n",
      "[EPOCH #24, step #2086] loss: 0.9544488442218299\n",
      "[EPOCH #24, step #2088] loss: 0.9543896249146367\n",
      "[EPOCH #24, step #2090] loss: 0.9543192398456909\n",
      "[EPOCH #24, step #2092] loss: 0.9543713441005576\n",
      "[EPOCH #24, step #2094] loss: 0.9544476249764244\n",
      "[EPOCH #24, step #2096] loss: 0.9547300188809733\n",
      "[EPOCH #24, step #2098] loss: 0.9545029449059658\n",
      "[EPOCH #24, step #2100] loss: 0.9545403359646686\n",
      "[EPOCH #24, step #2102] loss: 0.9547790765507245\n",
      "[EPOCH #24, step #2104] loss: 0.9547835417286518\n",
      "[EPOCH #24, step #2106] loss: 0.9549828259566977\n",
      "[EPOCH #24, step #2108] loss: 0.9547423373443247\n",
      "[EPOCH #24, step #2110] loss: 0.9549275971966747\n",
      "[EPOCH #24, step #2112] loss: 0.9549538867906886\n",
      "[EPOCH #24, step #2114] loss: 0.9550063125489733\n",
      "[EPOCH #24, step #2116] loss: 0.9553203252925025\n",
      "[EPOCH #24, step #2118] loss: 0.9555112583815011\n",
      "[EPOCH #24, step #2120] loss: 0.955344891657755\n",
      "[EPOCH #24, step #2122] loss: 0.9551940100040293\n",
      "[EPOCH #24, step #2124] loss: 0.9551414966723498\n",
      "[EPOCH #24, step #2126] loss: 0.9549547180946747\n",
      "[EPOCH #24, step #2128] loss: 0.9549628075801917\n",
      "[EPOCH #24, step #2130] loss: 0.95490932038053\n",
      "[EPOCH #24, step #2132] loss: 0.954810174107831\n",
      "[EPOCH #24, step #2134] loss: 0.9551013290602932\n",
      "[EPOCH #24, step #2136] loss: 0.9552234654037206\n",
      "[EPOCH #24, step #2138] loss: 0.9554194787246371\n",
      "[EPOCH #24, step #2140] loss: 0.9555490043245705\n",
      "[EPOCH #24, step #2142] loss: 0.9555447715022994\n",
      "[EPOCH #24, step #2144] loss: 0.9556275129179299\n",
      "[EPOCH #24, step #2146] loss: 0.9557442401223922\n",
      "[EPOCH #24, step #2148] loss: 0.9560571189340518\n",
      "[EPOCH #24, step #2150] loss: 0.9558529135156708\n",
      "[EPOCH #24, step #2152] loss: 0.9558808105771507\n",
      "[EPOCH #24, step #2154] loss: 0.955872740283643\n",
      "[EPOCH #24, step #2156] loss: 0.9560534179929124\n",
      "[EPOCH #24, step #2158] loss: 0.9562898898715496\n",
      "[EPOCH #24, step #2160] loss: 0.9562772876931693\n",
      "[EPOCH #24, step #2162] loss: 0.9560353477217233\n",
      "[EPOCH #24, step #2164] loss: 0.9558671295092233\n",
      "[EPOCH #24, step #2166] loss: 0.9560733868688496\n",
      "[EPOCH #24, step #2168] loss: 0.9562827697021173\n",
      "[EPOCH #24, step #2170] loss: 0.956306144190186\n",
      "[EPOCH #24, step #2172] loss: 0.9562226763064555\n",
      "[EPOCH #24, step #2174] loss: 0.9563523588098328\n",
      "[EPOCH #24, step #2176] loss: 0.9562244750268425\n",
      "[EPOCH #24, step #2178] loss: 0.9562041803120801\n",
      "[EPOCH #24, step #2180] loss: 0.9562998102625156\n",
      "[EPOCH #24, step #2182] loss: 0.9564046813187881\n",
      "[EPOCH #24, step #2184] loss: 0.9565891990808928\n",
      "[EPOCH #24, step #2186] loss: 0.9563518829769776\n",
      "[EPOCH #24, step #2188] loss: 0.9561389579164105\n",
      "[EPOCH #24, step #2190] loss: 0.9558512606423829\n",
      "[EPOCH #24, step #2192] loss: 0.9561290935707919\n",
      "[EPOCH #24, step #2194] loss: 0.9561567052214455\n",
      "[EPOCH #24, step #2196] loss: 0.9560442992134641\n",
      "[EPOCH #24, step #2198] loss: 0.9561340514639932\n",
      "[EPOCH #24, step #2200] loss: 0.9560200089029376\n",
      "[EPOCH #24, step #2202] loss: 0.9562381565895505\n",
      "[EPOCH #24, step #2204] loss: 0.9561672617924186\n",
      "[EPOCH #24, step #2206] loss: 0.956036234974159\n",
      "[EPOCH #24, step #2208] loss: 0.9559063995758729\n",
      "[EPOCH #24, step #2210] loss: 0.9560917491478275\n",
      "[EPOCH #24, step #2212] loss: 0.9559956548093295\n",
      "[EPOCH #24, step #2214] loss: 0.956211589569432\n",
      "[EPOCH #24, step #2216] loss: 0.9561450935103735\n",
      "[EPOCH #24, step #2218] loss: 0.9560425841443009\n",
      "[EPOCH #24, step #2220] loss: 0.9559309268282212\n",
      "[EPOCH #24, step #2222] loss: 0.9557817509809272\n",
      "[EPOCH #24, step #2224] loss: 0.9557204740636804\n",
      "[EPOCH #24, step #2226] loss: 0.9559582729723939\n",
      "[EPOCH #24, step #2228] loss: 0.9560716371329818\n",
      "[EPOCH #24, step #2230] loss: 0.9559505463634997\n",
      "[EPOCH #24, step #2232] loss: 0.9559385475827289\n",
      "[EPOCH #24, step #2234] loss: 0.9559834501753984\n",
      "[EPOCH #24, step #2236] loss: 0.9561583847273766\n",
      "[EPOCH #24, step #2238] loss: 0.9559485612968719\n",
      "[EPOCH #24, step #2240] loss: 0.9559589825613805\n",
      "[EPOCH #24, step #2242] loss: 0.9559334935458494\n",
      "[EPOCH #24, step #2244] loss: 0.955856377948366\n",
      "[EPOCH #24, step #2246] loss: 0.9558734546436646\n",
      "[EPOCH #24, step #2248] loss: 0.9560706003367397\n",
      "[EPOCH #24, step #2250] loss: 0.9560135043843064\n",
      "[EPOCH #24, step #2252] loss: 0.9559458063884783\n",
      "[EPOCH #24, step #2254] loss: 0.9558634574952517\n",
      "[EPOCH #24, step #2256] loss: 0.9557644773306021\n",
      "[EPOCH #24, step #2258] loss: 0.9557432236134241\n",
      "[EPOCH #24, step #2260] loss: 0.9559351937241493\n",
      "[EPOCH #24, step #2262] loss: 0.9557612123370328\n",
      "[EPOCH #24, step #2264] loss: 0.9558775971398975\n",
      "[EPOCH #24, step #2266] loss: 0.9559709487452505\n",
      "[EPOCH #24, step #2268] loss: 0.9558883871917632\n",
      "[EPOCH #24, step #2270] loss: 0.9556114606818455\n",
      "[EPOCH #24, step #2272] loss: 0.9556250106092596\n",
      "[EPOCH #24, step #2274] loss: 0.9554733187418718\n",
      "[EPOCH #24, step #2276] loss: 0.9554286506624142\n",
      "[EPOCH #24, step #2278] loss: 0.9552422422047716\n",
      "[EPOCH #24, step #2280] loss: 0.9552615827005821\n",
      "[EPOCH #24, step #2282] loss: 0.9552103479311647\n",
      "[EPOCH #24, step #2284] loss: 0.9556303564646573\n",
      "[EPOCH #24, step #2286] loss: 0.955650700366179\n",
      "[EPOCH #24, step #2288] loss: 0.9555159289147355\n",
      "[EPOCH #24, step #2290] loss: 0.9557474640481392\n",
      "[EPOCH #24, step #2292] loss: 0.9556754157499512\n",
      "[EPOCH #24, step #2294] loss: 0.9558908656401831\n",
      "[EPOCH #24, step #2296] loss: 0.9561674501592822\n",
      "[EPOCH #24, step #2298] loss: 0.9563351096589444\n",
      "[EPOCH #24, step #2300] loss: 0.9562985897711804\n",
      "[EPOCH #24, step #2302] loss: 0.9563372191713004\n",
      "[EPOCH #24, step #2304] loss: 0.9564869368024607\n",
      "[EPOCH #24, step #2306] loss: 0.9564659657367752\n",
      "[EPOCH #24, step #2308] loss: 0.9563102047517734\n",
      "[EPOCH #24, step #2310] loss: 0.9564581704650386\n",
      "[EPOCH #24, step #2312] loss: 0.9563613808546755\n",
      "[EPOCH #24, step #2314] loss: 0.9561538234771456\n",
      "[EPOCH #24, step #2316] loss: 0.9559894031396857\n",
      "[EPOCH #24, step #2318] loss: 0.9558545945404212\n",
      "[EPOCH #24, step #2320] loss: 0.9556332535268109\n",
      "[EPOCH #24, step #2322] loss: 0.955513606246463\n",
      "[EPOCH #24, step #2324] loss: 0.9555194111408726\n",
      "[EPOCH #24, step #2326] loss: 0.9556053147507575\n",
      "[EPOCH #24, step #2328] loss: 0.9555782046810452\n",
      "[EPOCH #24, step #2330] loss: 0.9555154842580659\n",
      "[EPOCH #24, step #2332] loss: 0.9555385621305295\n",
      "[EPOCH #24, step #2334] loss: 0.9556638818609128\n",
      "[EPOCH #24, step #2336] loss: 0.9559222600961986\n",
      "[EPOCH #24, step #2338] loss: 0.9557561943575886\n",
      "[EPOCH #24, step #2340] loss: 0.9557685489356136\n",
      "[EPOCH #24, step #2342] loss: 0.9557508591831214\n",
      "[EPOCH #24, step #2344] loss: 0.9556560338814375\n",
      "[EPOCH #24, step #2346] loss: 0.9557877937859558\n",
      "[EPOCH #24, step #2348] loss: 0.9558045516094282\n",
      "[EPOCH #24, step #2350] loss: 0.9556211152136554\n",
      "[EPOCH #24, step #2352] loss: 0.9557911978470129\n",
      "[EPOCH #24, step #2354] loss: 0.9556861292151635\n",
      "[EPOCH #24, step #2356] loss: 0.9557538590519217\n",
      "[EPOCH #24, step #2358] loss: 0.9556939554017395\n",
      "[EPOCH #24, step #2360] loss: 0.9558897507311883\n",
      "[EPOCH #24, step #2362] loss: 0.9558712505229792\n",
      "[EPOCH #24, step #2364] loss: 0.9559191881602208\n",
      "[EPOCH #24, step #2366] loss: 0.9560263016503926\n",
      "[EPOCH #24, step #2368] loss: 0.9559770626149232\n",
      "[EPOCH #24, step #2370] loss: 0.9559531530238867\n",
      "[EPOCH #24, step #2372] loss: 0.9561958117697041\n",
      "[EPOCH #24, step #2374] loss: 0.9560896720258814\n",
      "[EPOCH #24, step #2376] loss: 0.9560788465764877\n",
      "[EPOCH #24, step #2378] loss: 0.9558107018245273\n",
      "[EPOCH #24, step #2380] loss: 0.9559272178102571\n",
      "[EPOCH #24, step #2382] loss: 0.9560640185533629\n",
      "[EPOCH #24, step #2384] loss: 0.9559425027240497\n",
      "[EPOCH #24, step #2386] loss: 0.9558118723479584\n",
      "[EPOCH #24, step #2388] loss: 0.9559228784397288\n",
      "[EPOCH #24, step #2390] loss: 0.9558590599828463\n",
      "[EPOCH #24, step #2392] loss: 0.9557149488085043\n",
      "[EPOCH #24, step #2394] loss: 0.9558904707680664\n",
      "[EPOCH #24, step #2396] loss: 0.9559301193749153\n",
      "[EPOCH #24, step #2398] loss: 0.955882862551901\n",
      "[EPOCH #24, step #2400] loss: 0.9557121479600631\n",
      "[EPOCH #24, step #2402] loss: 0.9556857919598737\n",
      "[EPOCH #24, step #2404] loss: 0.9556375316795341\n",
      "[EPOCH #24, step #2406] loss: 0.9557721779140438\n",
      "[EPOCH #24, step #2408] loss: 0.9558894484431083\n",
      "[EPOCH #24, step #2410] loss: 0.9558011929878106\n",
      "[EPOCH #24, step #2412] loss: 0.9556428551599785\n",
      "[EPOCH #24, step #2414] loss: 0.955583106249756\n",
      "[EPOCH #24, step #2416] loss: 0.9555248948207906\n",
      "[EPOCH #24, step #2418] loss: 0.9556190345764357\n",
      "[EPOCH #24, step #2420] loss: 0.9557456318404447\n",
      "[EPOCH #24, step #2422] loss: 0.955847807293139\n",
      "[EPOCH #24, step #2424] loss: 0.9560513983190674\n",
      "[EPOCH #24, step #2426] loss: 0.9562867535673447\n",
      "[EPOCH #24, step #2428] loss: 0.9562219424152532\n",
      "[EPOCH #24, step #2430] loss: 0.9563145873013076\n",
      "[EPOCH #24, step #2432] loss: 0.9561376781729186\n",
      "[EPOCH #24, step #2434] loss: 0.9562710461797655\n",
      "[EPOCH #24, step #2436] loss: 0.9562227931064712\n",
      "[EPOCH #24, step #2438] loss: 0.9563254473418572\n",
      "[EPOCH #24, step #2440] loss: 0.9564971661699546\n",
      "[EPOCH #24, step #2442] loss: 0.9563853391188849\n",
      "[EPOCH #24, step #2444] loss: 0.9562333469620024\n",
      "[EPOCH #24, step #2446] loss: 0.956231595973458\n",
      "[EPOCH #24, step #2448] loss: 0.9562403262635064\n",
      "[EPOCH #24, step #2450] loss: 0.956272014242345\n",
      "[EPOCH #24, step #2452] loss: 0.9562201666506368\n",
      "[EPOCH #24, step #2454] loss: 0.9559830221163522\n",
      "[EPOCH #24, step #2456] loss: 0.9559163488189913\n",
      "[EPOCH #24, step #2458] loss: 0.9559679215227797\n",
      "[EPOCH #24, step #2460] loss: 0.9558788300747312\n",
      "[EPOCH #24, step #2462] loss: 0.9558671133163931\n",
      "[EPOCH #24, step #2464] loss: 0.9559706928884766\n",
      "[EPOCH #24, step #2466] loss: 0.955718037071719\n",
      "[EPOCH #24, step #2468] loss: 0.9558728449423818\n",
      "[EPOCH #24, step #2470] loss: 0.9558353727522865\n",
      "[EPOCH #24, step #2472] loss: 0.9557083045910882\n",
      "[EPOCH #24, step #2474] loss: 0.9556928634884382\n",
      "[EPOCH #24, step #2476] loss: 0.9554917442014152\n",
      "[EPOCH #24, step #2478] loss: 0.9554724399242347\n",
      "[EPOCH #24, step #2480] loss: 0.9554004419815728\n",
      "[EPOCH #24, step #2482] loss: 0.9552084784137113\n",
      "[EPOCH #24, step #2484] loss: 0.9552051511328945\n",
      "[EPOCH #24, step #2486] loss: 0.9551157236914104\n",
      "[EPOCH #24, step #2488] loss: 0.9550058777766229\n",
      "[EPOCH #24, step #2490] loss: 0.9549052210660021\n",
      "[EPOCH #24, step #2492] loss: 0.9549503904530862\n",
      "[EPOCH #24, step #2494] loss: 0.9550749270376079\n",
      "[EPOCH #24, step #2496] loss: 0.9551236493901629\n",
      "[EPOCH #24, step #2498] loss: 0.9551271008653324\n",
      "[EPOCH #24, elapsed time: 12136.855[sec]] loss: 0.9551962039709091\n",
      "[EPOCH #25, step #0] loss: 0.73380047082901\n",
      "[EPOCH #25, step #2] loss: 0.6705710887908936\n",
      "[EPOCH #25, step #4] loss: 0.7127286195755005\n",
      "[EPOCH #25, step #6] loss: 0.821480563708714\n",
      "[EPOCH #25, step #8] loss: 0.8240536716249254\n",
      "[EPOCH #25, step #10] loss: 0.9012988805770874\n",
      "[EPOCH #25, step #12] loss: 0.8919557608090914\n",
      "[EPOCH #25, step #14] loss: 0.8532885551452637\n",
      "[EPOCH #25, step #16] loss: 0.8199855054126066\n",
      "[EPOCH #25, step #18] loss: 0.8283788342224924\n",
      "[EPOCH #25, step #20] loss: 0.8197415584609622\n",
      "[EPOCH #25, step #22] loss: 0.8201043994530387\n",
      "[EPOCH #25, step #24] loss: 0.8105807518959045\n",
      "[EPOCH #25, step #26] loss: 0.8293406808817828\n",
      "[EPOCH #25, step #28] loss: 0.83997492338049\n",
      "[EPOCH #25, step #30] loss: 0.8392740795689244\n",
      "[EPOCH #25, step #32] loss: 0.8546995936018048\n",
      "[EPOCH #25, step #34] loss: 0.8430285215377807\n",
      "[EPOCH #25, step #36] loss: 0.8453333297291318\n",
      "[EPOCH #25, step #38] loss: 0.8396352804624118\n",
      "[EPOCH #25, step #40] loss: 0.8258611792471351\n",
      "[EPOCH #25, step #42] loss: 0.8376900428949401\n",
      "[EPOCH #25, step #44] loss: 0.8377172496583727\n",
      "[EPOCH #25, step #46] loss: 0.829904908829547\n",
      "[EPOCH #25, step #48] loss: 0.8307478829305999\n",
      "[EPOCH #25, step #50] loss: 0.8368790231499017\n",
      "[EPOCH #25, step #52] loss: 0.8419135482806079\n",
      "[EPOCH #25, step #54] loss: 0.8435974608768116\n",
      "[EPOCH #25, step #56] loss: 0.8484266379423309\n",
      "[EPOCH #25, step #58] loss: 0.8470997517391786\n",
      "[EPOCH #25, step #60] loss: 0.8456573105249249\n",
      "[EPOCH #25, step #62] loss: 0.8467872057642255\n",
      "[EPOCH #25, step #64] loss: 0.848240014222952\n",
      "[EPOCH #25, step #66] loss: 0.8461971229581691\n",
      "[EPOCH #25, step #68] loss: 0.8453836933426235\n",
      "[EPOCH #25, step #70] loss: 0.8445868542496587\n",
      "[EPOCH #25, step #72] loss: 0.8458676174895404\n",
      "[EPOCH #25, step #74] loss: 0.8458593599001567\n",
      "[EPOCH #25, step #76] loss: 0.8487025329044887\n",
      "[EPOCH #25, step #78] loss: 0.8438232397731347\n",
      "[EPOCH #25, step #80] loss: 0.8474017102041362\n",
      "[EPOCH #25, step #82] loss: 0.8466808530221502\n",
      "[EPOCH #25, step #84] loss: 0.8452996587052065\n",
      "[EPOCH #25, step #86] loss: 0.8472662441346838\n",
      "[EPOCH #25, step #88] loss: 0.8443214374311855\n",
      "[EPOCH #25, step #90] loss: 0.8474500005716806\n",
      "[EPOCH #25, step #92] loss: 0.846894391441858\n",
      "[EPOCH #25, step #94] loss: 0.8456215685919711\n",
      "[EPOCH #25, step #96] loss: 0.847019352556504\n",
      "[EPOCH #25, step #98] loss: 0.8465717901485135\n",
      "[EPOCH #25, step #100] loss: 0.8462423242554806\n",
      "[EPOCH #25, step #102] loss: 0.8467276371219783\n",
      "[EPOCH #25, step #104] loss: 0.842542846146084\n",
      "[EPOCH #25, step #106] loss: 0.8474701200133172\n",
      "[EPOCH #25, step #108] loss: 0.8465723157475847\n",
      "[EPOCH #25, step #110] loss: 0.8445107101857126\n",
      "[EPOCH #25, step #112] loss: 0.8434033422870973\n",
      "[EPOCH #25, step #114] loss: 0.8459649752015653\n",
      "[EPOCH #25, step #116] loss: 0.850613041056527\n",
      "[EPOCH #25, step #118] loss: 0.8489461633838525\n",
      "[EPOCH #25, step #120] loss: 0.8462956037895739\n",
      "[EPOCH #25, step #122] loss: 0.8469449133892369\n",
      "[EPOCH #25, step #124] loss: 0.846581113576889\n",
      "[EPOCH #25, step #126] loss: 0.8483627886753383\n",
      "[EPOCH #25, step #128] loss: 0.8472484255483909\n",
      "[EPOCH #25, step #130] loss: 0.848208372602026\n",
      "[EPOCH #25, step #132] loss: 0.8468363825091743\n",
      "[EPOCH #25, step #134] loss: 0.8447354932626089\n",
      "[EPOCH #25, step #136] loss: 0.8439861577357689\n",
      "[EPOCH #25, step #138] loss: 0.8436219947372409\n",
      "[EPOCH #25, step #140] loss: 0.8458970157389946\n",
      "[EPOCH #25, step #142] loss: 0.8496775962672867\n",
      "[EPOCH #25, step #144] loss: 0.8473502662675134\n",
      "[EPOCH #25, step #146] loss: 0.8451812524779313\n",
      "[EPOCH #25, step #148] loss: 0.8488911972349922\n",
      "[EPOCH #25, step #150] loss: 0.8475202683186689\n",
      "[EPOCH #25, step #152] loss: 0.84634975066372\n",
      "[EPOCH #25, step #154] loss: 0.8478459337065297\n",
      "[EPOCH #25, step #156] loss: 0.850598710547587\n",
      "[EPOCH #25, step #158] loss: 0.8494895548565583\n",
      "[EPOCH #25, step #160] loss: 0.8487894362914636\n",
      "[EPOCH #25, step #162] loss: 0.8472495706169152\n",
      "[EPOCH #25, step #164] loss: 0.8474906121239517\n",
      "[EPOCH #25, step #166] loss: 0.8472745263290976\n",
      "[EPOCH #25, step #168] loss: 0.8473512740177516\n",
      "[EPOCH #25, step #170] loss: 0.8500454601837181\n",
      "[EPOCH #25, step #172] loss: 0.8521100553129449\n",
      "[EPOCH #25, step #174] loss: 0.8534584387711116\n",
      "[EPOCH #25, step #176] loss: 0.8547743062178293\n",
      "[EPOCH #25, step #178] loss: 0.854136787812803\n",
      "[EPOCH #25, step #180] loss: 0.8586213310449822\n",
      "[EPOCH #25, step #182] loss: 0.8589283965650152\n",
      "[EPOCH #25, step #184] loss: 0.8599060888225968\n",
      "[EPOCH #25, step #186] loss: 0.8601178888649864\n",
      "[EPOCH #25, step #188] loss: 0.859881677482494\n",
      "[EPOCH #25, step #190] loss: 0.8621068564072953\n",
      "[EPOCH #25, step #192] loss: 0.8632070522543063\n",
      "[EPOCH #25, step #194] loss: 0.8640238054287739\n",
      "[EPOCH #25, step #196] loss: 0.8637476250302368\n",
      "[EPOCH #25, step #198] loss: 0.8661070096133342\n",
      "[EPOCH #25, step #200] loss: 0.8666804547037058\n",
      "[EPOCH #25, step #202] loss: 0.8682965226654936\n",
      "[EPOCH #25, step #204] loss: 0.8673037786309312\n",
      "[EPOCH #25, step #206] loss: 0.8706081715470927\n",
      "[EPOCH #25, step #208] loss: 0.871502965118326\n",
      "[EPOCH #25, step #210] loss: 0.87297087159202\n",
      "[EPOCH #25, step #212] loss: 0.8708412511527818\n",
      "[EPOCH #25, step #214] loss: 0.8707924489365068\n",
      "[EPOCH #25, step #216] loss: 0.8740630013876797\n",
      "[EPOCH #25, step #218] loss: 0.8749146076370048\n",
      "[EPOCH #25, step #220] loss: 0.8719133110337667\n",
      "[EPOCH #25, step #222] loss: 0.8712763012524678\n",
      "[EPOCH #25, step #224] loss: 0.8757478651735517\n",
      "[EPOCH #25, step #226] loss: 0.8759514349410187\n",
      "[EPOCH #25, step #228] loss: 0.8756124620614614\n",
      "[EPOCH #25, step #230] loss: 0.8769487572180761\n",
      "[EPOCH #25, step #232] loss: 0.8757082053775951\n",
      "[EPOCH #25, step #234] loss: 0.8768716975729516\n",
      "[EPOCH #25, step #236] loss: 0.8771040536431823\n",
      "[EPOCH #25, step #238] loss: 0.8785495499936108\n",
      "[EPOCH #25, step #240] loss: 0.8773233735957087\n",
      "[EPOCH #25, step #242] loss: 0.8750435806841517\n",
      "[EPOCH #25, step #244] loss: 0.8771411473653754\n",
      "[EPOCH #25, step #246] loss: 0.8768908831513362\n",
      "[EPOCH #25, step #248] loss: 0.8773440446958963\n",
      "[EPOCH #25, step #250] loss: 0.8781794790490215\n",
      "[EPOCH #25, step #252] loss: 0.8787357101562937\n",
      "[EPOCH #25, step #254] loss: 0.8776149157215567\n",
      "[EPOCH #25, step #256] loss: 0.8771272070908824\n",
      "[EPOCH #25, step #258] loss: 0.8785090454526849\n",
      "[EPOCH #25, step #260] loss: 0.8796320823645684\n",
      "[EPOCH #25, step #262] loss: 0.8793901122341591\n",
      "[EPOCH #25, step #264] loss: 0.8807335942421319\n",
      "[EPOCH #25, step #266] loss: 0.8817682347717356\n",
      "[EPOCH #25, step #268] loss: 0.882422144417426\n",
      "[EPOCH #25, step #270] loss: 0.8823016700489494\n",
      "[EPOCH #25, step #272] loss: 0.8818905223638583\n",
      "[EPOCH #25, step #274] loss: 0.8834527823058042\n",
      "[EPOCH #25, step #276] loss: 0.8826865963772316\n",
      "[EPOCH #25, step #278] loss: 0.8825470244371763\n",
      "[EPOCH #25, step #280] loss: 0.8823462645142104\n",
      "[EPOCH #25, step #282] loss: 0.8826399480285577\n",
      "[EPOCH #25, step #284] loss: 0.8816206648684385\n",
      "[EPOCH #25, step #286] loss: 0.8805571938848662\n",
      "[EPOCH #25, step #288] loss: 0.8800452616594242\n",
      "[EPOCH #25, step #290] loss: 0.8815222096811864\n",
      "[EPOCH #25, step #292] loss: 0.8812172729204132\n",
      "[EPOCH #25, step #294] loss: 0.8823564429404371\n",
      "[EPOCH #25, step #296] loss: 0.8808848347126033\n",
      "[EPOCH #25, step #298] loss: 0.880942015245208\n",
      "[EPOCH #25, step #300] loss: 0.883822136840155\n",
      "[EPOCH #25, step #302] loss: 0.8839077934770301\n",
      "[EPOCH #25, step #304] loss: 0.8843033727075232\n",
      "[EPOCH #25, step #306] loss: 0.8837116204372059\n",
      "[EPOCH #25, step #308] loss: 0.8840795486297423\n",
      "[EPOCH #25, step #310] loss: 0.8820571235330158\n",
      "[EPOCH #25, step #312] loss: 0.8809838535877081\n",
      "[EPOCH #25, step #314] loss: 0.8808569576059069\n",
      "[EPOCH #25, step #316] loss: 0.8801047998459933\n",
      "[EPOCH #25, step #318] loss: 0.8791672941472463\n",
      "[EPOCH #25, step #320] loss: 0.8797608893422694\n",
      "[EPOCH #25, step #322] loss: 0.880716941212722\n",
      "[EPOCH #25, step #324] loss: 0.8799940717220306\n",
      "[EPOCH #25, step #326] loss: 0.8803400629704151\n",
      "[EPOCH #25, step #328] loss: 0.8805186419682662\n",
      "[EPOCH #25, step #330] loss: 0.8810499738170301\n",
      "[EPOCH #25, step #332] loss: 0.8828545061496643\n",
      "[EPOCH #25, step #334] loss: 0.8838758923224549\n",
      "[EPOCH #25, step #336] loss: 0.8841863064985247\n",
      "[EPOCH #25, step #338] loss: 0.8848406123024876\n",
      "[EPOCH #25, step #340] loss: 0.8841494091969432\n",
      "[EPOCH #25, step #342] loss: 0.8833657618688078\n",
      "[EPOCH #25, step #344] loss: 0.8855231970116713\n",
      "[EPOCH #25, step #346] loss: 0.8852658997523338\n",
      "[EPOCH #25, step #348] loss: 0.8848393690107886\n",
      "[EPOCH #25, step #350] loss: 0.8853350831063045\n",
      "[EPOCH #25, step #352] loss: 0.8840908999990134\n",
      "[EPOCH #25, step #354] loss: 0.8841196170155431\n",
      "[EPOCH #25, step #356] loss: 0.8837443589329386\n",
      "[EPOCH #25, step #358] loss: 0.8826805968304531\n",
      "[EPOCH #25, step #360] loss: 0.8811173525708534\n",
      "[EPOCH #25, step #362] loss: 0.8810358512992701\n",
      "[EPOCH #25, step #364] loss: 0.8800169426284424\n",
      "[EPOCH #25, step #366] loss: 0.880527857619995\n",
      "[EPOCH #25, step #368] loss: 0.8797354417926251\n",
      "[EPOCH #25, step #370] loss: 0.8787438164181465\n",
      "[EPOCH #25, step #372] loss: 0.8803053472700452\n",
      "[EPOCH #25, step #374] loss: 0.880794435342153\n",
      "[EPOCH #25, step #376] loss: 0.8810667643812671\n",
      "[EPOCH #25, step #378] loss: 0.8811504073382053\n",
      "[EPOCH #25, step #380] loss: 0.8828093167052181\n",
      "[EPOCH #25, step #382] loss: 0.8823602197998186\n",
      "[EPOCH #25, step #384] loss: 0.8818091390968917\n",
      "[EPOCH #25, step #386] loss: 0.8812742459681607\n",
      "[EPOCH #25, step #388] loss: 0.8833081038874648\n",
      "[EPOCH #25, step #390] loss: 0.8829848464492642\n",
      "[EPOCH #25, step #392] loss: 0.8839575322226411\n",
      "[EPOCH #25, step #394] loss: 0.8847106737426564\n",
      "[EPOCH #25, step #396] loss: 0.8846799971474808\n",
      "[EPOCH #25, step #398] loss: 0.885001079779221\n",
      "[EPOCH #25, step #400] loss: 0.8855539839761215\n",
      "[EPOCH #25, step #402] loss: 0.884429609065612\n",
      "[EPOCH #25, step #404] loss: 0.8845255603024988\n",
      "[EPOCH #25, step #406] loss: 0.883285108303848\n",
      "[EPOCH #25, step #408] loss: 0.8836082424103193\n",
      "[EPOCH #25, step #410] loss: 0.8826690124769281\n",
      "[EPOCH #25, step #412] loss: 0.8827762977551605\n",
      "[EPOCH #25, step #414] loss: 0.8822582812194365\n",
      "[EPOCH #25, step #416] loss: 0.8819588870167446\n",
      "[EPOCH #25, step #418] loss: 0.8810278362192231\n",
      "[EPOCH #25, step #420] loss: 0.8824309613245966\n",
      "[EPOCH #25, step #422] loss: 0.8817244952733917\n",
      "[EPOCH #25, step #424] loss: 0.8821912141407238\n",
      "[EPOCH #25, step #426] loss: 0.8816460072296286\n",
      "[EPOCH #25, step #428] loss: 0.8822667404210373\n",
      "[EPOCH #25, step #430] loss: 0.8844045038289647\n",
      "[EPOCH #25, step #432] loss: 0.883689008050923\n",
      "[EPOCH #25, step #434] loss: 0.8847488881527692\n",
      "[EPOCH #25, step #436] loss: 0.8842613758429783\n",
      "[EPOCH #25, step #438] loss: 0.8844269315854292\n",
      "[EPOCH #25, step #440] loss: 0.8832212310123876\n",
      "[EPOCH #25, step #442] loss: 0.8847788617384891\n",
      "[EPOCH #25, step #444] loss: 0.8843522435493684\n",
      "[EPOCH #25, step #446] loss: 0.8852782814161356\n",
      "[EPOCH #25, step #448] loss: 0.8852401664501309\n",
      "[EPOCH #25, step #450] loss: 0.8843437037420379\n",
      "[EPOCH #25, step #452] loss: 0.8843557773441668\n",
      "[EPOCH #25, step #454] loss: 0.8850825102119655\n",
      "[EPOCH #25, step #456] loss: 0.8856074832852612\n",
      "[EPOCH #25, step #458] loss: 0.886181748056204\n",
      "[EPOCH #25, step #460] loss: 0.8854378130198042\n",
      "[EPOCH #25, step #462] loss: 0.88535791976663\n",
      "[EPOCH #25, step #464] loss: 0.885467848149679\n",
      "[EPOCH #25, step #466] loss: 0.8850860716316379\n",
      "[EPOCH #25, step #468] loss: 0.8852768172460325\n",
      "[EPOCH #25, step #470] loss: 0.8860080222541866\n",
      "[EPOCH #25, step #472] loss: 0.8868232527570543\n",
      "[EPOCH #25, step #474] loss: 0.8870441402259626\n",
      "[EPOCH #25, step #476] loss: 0.886722478914061\n",
      "[EPOCH #25, step #478] loss: 0.8870943129560395\n",
      "[EPOCH #25, step #480] loss: 0.8860652978975411\n",
      "[EPOCH #25, step #482] loss: 0.8852918199253872\n",
      "[EPOCH #25, step #484] loss: 0.8852531709007381\n",
      "[EPOCH #25, step #486] loss: 0.8854865062775308\n",
      "[EPOCH #25, step #488] loss: 0.8843234806094921\n",
      "[EPOCH #25, step #490] loss: 0.8854582707289523\n",
      "[EPOCH #25, step #492] loss: 0.8857173308518547\n",
      "[EPOCH #25, step #494] loss: 0.8854386663798129\n",
      "[EPOCH #25, step #496] loss: 0.8852301794638336\n",
      "[EPOCH #25, step #498] loss: 0.8851521129240254\n",
      "[EPOCH #25, step #500] loss: 0.8863872241474198\n",
      "[EPOCH #25, step #502] loss: 0.886355181752332\n",
      "[EPOCH #25, step #504] loss: 0.8869328798043846\n",
      "[EPOCH #25, step #506] loss: 0.886862300615574\n",
      "[EPOCH #25, step #508] loss: 0.8863392827670091\n",
      "[EPOCH #25, step #510] loss: 0.8870319539203569\n",
      "[EPOCH #25, step #512] loss: 0.8866779769954161\n",
      "[EPOCH #25, step #514] loss: 0.8863565190903191\n",
      "[EPOCH #25, step #516] loss: 0.8858567465320085\n",
      "[EPOCH #25, step #518] loss: 0.8859084053880217\n",
      "[EPOCH #25, step #520] loss: 0.8863402920240633\n",
      "[EPOCH #25, step #522] loss: 0.8860555997200268\n",
      "[EPOCH #25, step #524] loss: 0.8849846921648298\n",
      "[EPOCH #25, step #526] loss: 0.8854127036552502\n",
      "[EPOCH #25, step #528] loss: 0.8853846334329399\n",
      "[EPOCH #25, step #530] loss: 0.8866868507390642\n",
      "[EPOCH #25, step #532] loss: 0.886295730244599\n",
      "[EPOCH #25, step #534] loss: 0.8867853010926291\n",
      "[EPOCH #25, step #536] loss: 0.8863007410722515\n",
      "[EPOCH #25, step #538] loss: 0.8860527823276555\n",
      "[EPOCH #25, step #540] loss: 0.8863333815126895\n",
      "[EPOCH #25, step #542] loss: 0.8861043261120553\n",
      "[EPOCH #25, step #544] loss: 0.8851215085852037\n",
      "[EPOCH #25, step #546] loss: 0.8853185218256614\n",
      "[EPOCH #25, step #548] loss: 0.8852778168323913\n",
      "[EPOCH #25, step #550] loss: 0.8862082758096947\n",
      "[EPOCH #25, step #552] loss: 0.8874604401278021\n",
      "[EPOCH #25, step #554] loss: 0.8864560997163927\n",
      "[EPOCH #25, step #556] loss: 0.8862417421606328\n",
      "[EPOCH #25, step #558] loss: 0.8856968009621171\n",
      "[EPOCH #25, step #560] loss: 0.885890846158944\n",
      "[EPOCH #25, step #562] loss: 0.8852024804635328\n",
      "[EPOCH #25, step #564] loss: 0.884858520685044\n",
      "[EPOCH #25, step #566] loss: 0.8847981765997683\n",
      "[EPOCH #25, step #568] loss: 0.8856997365272736\n",
      "[EPOCH #25, step #570] loss: 0.8852257313118715\n",
      "[EPOCH #25, step #572] loss: 0.8847333091923911\n",
      "[EPOCH #25, step #574] loss: 0.8841706304964811\n",
      "[EPOCH #25, step #576] loss: 0.8842570016247767\n",
      "[EPOCH #25, step #578] loss: 0.8840457166003028\n",
      "[EPOCH #25, step #580] loss: 0.8842194414795368\n",
      "[EPOCH #25, step #582] loss: 0.8835957444961443\n",
      "[EPOCH #25, step #584] loss: 0.8833549773591196\n",
      "[EPOCH #25, step #586] loss: 0.8831856302548917\n",
      "[EPOCH #25, step #588] loss: 0.8833955869407524\n",
      "[EPOCH #25, step #590] loss: 0.8835163474486363\n",
      "[EPOCH #25, step #592] loss: 0.8829558323848911\n",
      "[EPOCH #25, step #594] loss: 0.8839232224376262\n",
      "[EPOCH #25, step #596] loss: 0.8823448648704356\n",
      "[EPOCH #25, step #598] loss: 0.883905125331003\n",
      "[EPOCH #25, step #600] loss: 0.8840833352429299\n",
      "[EPOCH #25, step #602] loss: 0.8845121156220412\n",
      "[EPOCH #25, step #604] loss: 0.8844497693964273\n",
      "[EPOCH #25, step #606] loss: 0.8841112699402616\n",
      "[EPOCH #25, step #608] loss: 0.88447953048598\n",
      "[EPOCH #25, step #610] loss: 0.8839893601042159\n",
      "[EPOCH #25, step #612] loss: 0.8837687931772547\n",
      "[EPOCH #25, step #614] loss: 0.8838724753236383\n",
      "[EPOCH #25, step #616] loss: 0.8841821971067153\n",
      "[EPOCH #25, step #618] loss: 0.8849103060311763\n",
      "[EPOCH #25, step #620] loss: 0.8844434043539511\n",
      "[EPOCH #25, step #622] loss: 0.8841763219615238\n",
      "[EPOCH #25, step #624] loss: 0.8838382398605347\n",
      "[EPOCH #25, step #626] loss: 0.8846387263310203\n",
      "[EPOCH #25, step #628] loss: 0.8845747867525098\n",
      "[EPOCH #25, step #630] loss: 0.8845330253833825\n",
      "[EPOCH #25, step #632] loss: 0.883965071532022\n",
      "[EPOCH #25, step #634] loss: 0.883392737606379\n",
      "[EPOCH #25, step #636] loss: 0.8829945374508293\n",
      "[EPOCH #25, step #638] loss: 0.8835389533886141\n",
      "[EPOCH #25, step #640] loss: 0.8830101869407571\n",
      "[EPOCH #25, step #642] loss: 0.882695054748381\n",
      "[EPOCH #25, step #644] loss: 0.8827291842578917\n",
      "[EPOCH #25, step #646] loss: 0.882930926598574\n",
      "[EPOCH #25, step #648] loss: 0.8827601266201178\n",
      "[EPOCH #25, step #650] loss: 0.8831820645456856\n",
      "[EPOCH #25, step #652] loss: 0.8831834553942016\n",
      "[EPOCH #25, step #654] loss: 0.8838514095044318\n",
      "[EPOCH #25, step #656] loss: 0.8842464395128247\n",
      "[EPOCH #25, step #658] loss: 0.884525414844565\n",
      "[EPOCH #25, step #660] loss: 0.8853054457821752\n",
      "[EPOCH #25, step #662] loss: 0.8852241865470218\n",
      "[EPOCH #25, step #664] loss: 0.8861816753122144\n",
      "[EPOCH #25, step #666] loss: 0.8864765599749792\n",
      "[EPOCH #25, step #668] loss: 0.8858688461228158\n",
      "[EPOCH #25, step #670] loss: 0.8857008564312305\n",
      "[EPOCH #25, step #672] loss: 0.8864498761043861\n",
      "[EPOCH #25, step #674] loss: 0.8867009512583415\n",
      "[EPOCH #25, step #676] loss: 0.8864778030218015\n",
      "[EPOCH #25, step #678] loss: 0.8861232393795682\n",
      "[EPOCH #25, step #680] loss: 0.8860667648994625\n",
      "[EPOCH #25, step #682] loss: 0.8863315128477217\n",
      "[EPOCH #25, step #684] loss: 0.8864730342461244\n",
      "[EPOCH #25, step #686] loss: 0.8866824540682409\n",
      "[EPOCH #25, step #688] loss: 0.8867347615031614\n",
      "[EPOCH #25, step #690] loss: 0.8864777099378892\n",
      "[EPOCH #25, step #692] loss: 0.8858161704536812\n",
      "[EPOCH #25, step #694] loss: 0.8855131884273008\n",
      "[EPOCH #25, step #696] loss: 0.8852577193224618\n",
      "[EPOCH #25, step #698] loss: 0.8844202920602626\n",
      "[EPOCH #25, step #700] loss: 0.8845543015360322\n",
      "[EPOCH #25, step #702] loss: 0.8843658138304992\n",
      "[EPOCH #25, step #704] loss: 0.8844352148948832\n",
      "[EPOCH #25, step #706] loss: 0.8844314189746323\n",
      "[EPOCH #25, step #708] loss: 0.8846284262047837\n",
      "[EPOCH #25, step #710] loss: 0.8853094493957177\n",
      "[EPOCH #25, step #712] loss: 0.8853703771533672\n",
      "[EPOCH #25, step #714] loss: 0.8856997010591147\n",
      "[EPOCH #25, step #716] loss: 0.8852327119356419\n",
      "[EPOCH #25, step #718] loss: 0.8852242732910188\n",
      "[EPOCH #25, step #720] loss: 0.8858751043697998\n",
      "[EPOCH #25, step #722] loss: 0.8861073898576602\n",
      "[EPOCH #25, step #724] loss: 0.8863013052118236\n",
      "[EPOCH #25, step #726] loss: 0.8855842720035674\n",
      "[EPOCH #25, step #728] loss: 0.8854808864606588\n",
      "[EPOCH #25, step #730] loss: 0.885798033709076\n",
      "[EPOCH #25, step #732] loss: 0.8855575305215333\n",
      "[EPOCH #25, step #734] loss: 0.8860051357016272\n",
      "[EPOCH #25, step #736] loss: 0.8856198866946403\n",
      "[EPOCH #25, step #738] loss: 0.8858467416285823\n",
      "[EPOCH #25, step #740] loss: 0.8852709476281757\n",
      "[EPOCH #25, step #742] loss: 0.8847153636841242\n",
      "[EPOCH #25, step #744] loss: 0.8849323136694479\n",
      "[EPOCH #25, step #746] loss: 0.8848121565987307\n",
      "[EPOCH #25, step #748] loss: 0.8848745652607509\n",
      "[EPOCH #25, step #750] loss: 0.8847858789122692\n",
      "[EPOCH #25, step #752] loss: 0.8848139665832874\n",
      "[EPOCH #25, step #754] loss: 0.8859089058756039\n",
      "[EPOCH #25, step #756] loss: 0.8865546246343434\n",
      "[EPOCH #25, step #758] loss: 0.8865689118546145\n",
      "[EPOCH #25, step #760] loss: 0.8871026556845877\n",
      "[EPOCH #25, step #762] loss: 0.8870443684557944\n",
      "[EPOCH #25, step #764] loss: 0.8866070728675992\n",
      "[EPOCH #25, step #766] loss: 0.886885785139524\n",
      "[EPOCH #25, step #768] loss: 0.8867029305862357\n",
      "[EPOCH #25, step #770] loss: 0.8862968605161486\n",
      "[EPOCH #25, step #772] loss: 0.8862900819537864\n",
      "[EPOCH #25, step #774] loss: 0.8861793966447153\n",
      "[EPOCH #25, step #776] loss: 0.8865155049886175\n",
      "[EPOCH #25, step #778] loss: 0.8863862831724164\n",
      "[EPOCH #25, step #780] loss: 0.886528760309256\n",
      "[EPOCH #25, step #782] loss: 0.8868999785694888\n",
      "[EPOCH #25, step #784] loss: 0.8869163281598669\n",
      "[EPOCH #25, step #786] loss: 0.8870953161652843\n",
      "[EPOCH #25, step #788] loss: 0.8870175989257367\n",
      "[EPOCH #25, step #790] loss: 0.8868054349714827\n",
      "[EPOCH #25, step #792] loss: 0.8865062501211034\n",
      "[EPOCH #25, step #794] loss: 0.8867789013580706\n",
      "[EPOCH #25, step #796] loss: 0.88611871295771\n",
      "[EPOCH #25, step #798] loss: 0.8862407279104106\n",
      "[EPOCH #25, step #800] loss: 0.8862199298897933\n",
      "[EPOCH #25, step #802] loss: 0.8860274338039337\n",
      "[EPOCH #25, step #804] loss: 0.8858662654154049\n",
      "[EPOCH #25, step #806] loss: 0.8860517568156917\n",
      "[EPOCH #25, step #808] loss: 0.8863399226969045\n",
      "[EPOCH #25, step #810] loss: 0.8857146604434483\n",
      "[EPOCH #25, step #812] loss: 0.8859306289407747\n",
      "[EPOCH #25, step #814] loss: 0.8856869475241819\n",
      "[EPOCH #25, step #816] loss: 0.8854221260970779\n",
      "[EPOCH #25, step #818] loss: 0.8856371293283353\n",
      "[EPOCH #25, step #820] loss: 0.8856512505592876\n",
      "[EPOCH #25, step #822] loss: 0.8858525912353219\n",
      "[EPOCH #25, step #824] loss: 0.8858748922203526\n",
      "[EPOCH #25, step #826] loss: 0.8865279868839729\n",
      "[EPOCH #25, step #828] loss: 0.8861766599918591\n",
      "[EPOCH #25, step #830] loss: 0.8861718231590215\n",
      "[EPOCH #25, step #832] loss: 0.8857220384825607\n",
      "[EPOCH #25, step #834] loss: 0.8861250585424686\n",
      "[EPOCH #25, step #836] loss: 0.8863597020880724\n",
      "[EPOCH #25, step #838] loss: 0.8866267525396699\n",
      "[EPOCH #25, step #840] loss: 0.8868137960910231\n",
      "[EPOCH #25, step #842] loss: 0.886289061529922\n",
      "[EPOCH #25, step #844] loss: 0.8857074478674217\n",
      "[EPOCH #25, step #846] loss: 0.8859704112218432\n",
      "[EPOCH #25, step #848] loss: 0.886174413635537\n",
      "[EPOCH #25, step #850] loss: 0.8867490661410411\n",
      "[EPOCH #25, step #852] loss: 0.8867055419461249\n",
      "[EPOCH #25, step #854] loss: 0.8871726256364968\n",
      "[EPOCH #25, step #856] loss: 0.8873479024810301\n",
      "[EPOCH #25, step #858] loss: 0.8882402559792204\n",
      "[EPOCH #25, step #860] loss: 0.8891761311947538\n",
      "[EPOCH #25, step #862] loss: 0.8889900668333193\n",
      "[EPOCH #25, step #864] loss: 0.8887069808265378\n",
      "[EPOCH #25, step #866] loss: 0.8893635087359736\n",
      "[EPOCH #25, step #868] loss: 0.8897732708204464\n",
      "[EPOCH #25, step #870] loss: 0.8898630048459488\n",
      "[EPOCH #25, step #872] loss: 0.8891958767742363\n",
      "[EPOCH #25, step #874] loss: 0.8892930587359837\n",
      "[EPOCH #25, step #876] loss: 0.8890917356908661\n",
      "[EPOCH #25, step #878] loss: 0.8888342725674583\n",
      "[EPOCH #25, step #880] loss: 0.8882100416366413\n",
      "[EPOCH #25, step #882] loss: 0.8881489219373917\n",
      "[EPOCH #25, step #884] loss: 0.8882367437842202\n",
      "[EPOCH #25, step #886] loss: 0.8885163180992057\n",
      "[EPOCH #25, step #888] loss: 0.888174045340685\n",
      "[EPOCH #25, step #890] loss: 0.8881366925876416\n",
      "[EPOCH #25, step #892] loss: 0.8875684393079657\n",
      "[EPOCH #25, step #894] loss: 0.8872850276238425\n",
      "[EPOCH #25, step #896] loss: 0.8873706663997144\n",
      "[EPOCH #25, step #898] loss: 0.8878043431196118\n",
      "[EPOCH #25, step #900] loss: 0.8873593066958555\n",
      "[EPOCH #25, step #902] loss: 0.8868533267927329\n",
      "[EPOCH #25, step #904] loss: 0.8868311449967695\n",
      "[EPOCH #25, step #906] loss: 0.886822361141739\n",
      "[EPOCH #25, step #908] loss: 0.8871331237199152\n",
      "[EPOCH #25, step #910] loss: 0.8868696423969206\n",
      "[EPOCH #25, step #912] loss: 0.8864482179333059\n",
      "[EPOCH #25, step #914] loss: 0.8867872955043459\n",
      "[EPOCH #25, step #916] loss: 0.8863670984882305\n",
      "[EPOCH #25, step #918] loss: 0.8860780078192141\n",
      "[EPOCH #25, step #920] loss: 0.8862125077866317\n",
      "[EPOCH #25, step #922] loss: 0.8863707373679524\n",
      "[EPOCH #25, step #924] loss: 0.8861791804352322\n",
      "[EPOCH #25, step #926] loss: 0.8853245195254539\n",
      "[EPOCH #25, step #928] loss: 0.8846738025690434\n",
      "[EPOCH #25, step #930] loss: 0.8842424433418299\n",
      "[EPOCH #25, step #932] loss: 0.8839039245474632\n",
      "[EPOCH #25, step #934] loss: 0.8833103112995944\n",
      "[EPOCH #25, step #936] loss: 0.8831253921336781\n",
      "[EPOCH #25, step #938] loss: 0.8838211543643817\n",
      "[EPOCH #25, step #940] loss: 0.883848384766979\n",
      "[EPOCH #25, step #942] loss: 0.8848083480039053\n",
      "[EPOCH #25, step #944] loss: 0.8850004854656401\n",
      "[EPOCH #25, step #946] loss: 0.884612736757353\n",
      "[EPOCH #25, step #948] loss: 0.8842680771433767\n",
      "[EPOCH #25, step #950] loss: 0.8840181847288029\n",
      "[EPOCH #25, step #952] loss: 0.8839479619470999\n",
      "[EPOCH #25, step #954] loss: 0.8835781504034372\n",
      "[EPOCH #25, step #956] loss: 0.8834120710005705\n",
      "[EPOCH #25, step #958] loss: 0.8835362539985009\n",
      "[EPOCH #25, step #960] loss: 0.8834620527186577\n",
      "[EPOCH #25, step #962] loss: 0.8830993119491842\n",
      "[EPOCH #25, step #964] loss: 0.8832866809219894\n",
      "[EPOCH #25, step #966] loss: 0.88352484093457\n",
      "[EPOCH #25, step #968] loss: 0.8837449672113877\n",
      "[EPOCH #25, step #970] loss: 0.8837441888270491\n",
      "[EPOCH #25, step #972] loss: 0.8839010553700584\n",
      "[EPOCH #25, step #974] loss: 0.8836248154823597\n",
      "[EPOCH #25, step #976] loss: 0.8837613965191153\n",
      "[EPOCH #25, step #978] loss: 0.8837259288523365\n",
      "[EPOCH #25, step #980] loss: 0.8835550400520562\n",
      "[EPOCH #25, step #982] loss: 0.8838313566643976\n",
      "[EPOCH #25, step #984] loss: 0.8841772393829327\n",
      "[EPOCH #25, step #986] loss: 0.8845734802483305\n",
      "[EPOCH #25, step #988] loss: 0.8849099169667015\n",
      "[EPOCH #25, step #990] loss: 0.8845977913419125\n",
      "[EPOCH #25, step #992] loss: 0.8849877377471175\n",
      "[EPOCH #25, step #994] loss: 0.8847524764849313\n",
      "[EPOCH #25, step #996] loss: 0.885536308722606\n",
      "[EPOCH #25, step #998] loss: 0.8856620115859134\n",
      "[EPOCH #25, step #1000] loss: 0.8857443483023496\n",
      "[EPOCH #25, step #1002] loss: 0.8855389453181003\n",
      "[EPOCH #25, step #1004] loss: 0.8859679989850343\n",
      "[EPOCH #25, step #1006] loss: 0.8861706755544838\n",
      "[EPOCH #25, step #1008] loss: 0.886528830964218\n",
      "[EPOCH #25, step #1010] loss: 0.8865383787100912\n",
      "[EPOCH #25, step #1012] loss: 0.8870300594993076\n",
      "[EPOCH #25, step #1014] loss: 0.8863657899384428\n",
      "[EPOCH #25, step #1016] loss: 0.8865718943238141\n",
      "[EPOCH #25, step #1018] loss: 0.8865892155657105\n",
      "[EPOCH #25, step #1020] loss: 0.8860744325175925\n",
      "[EPOCH #25, step #1022] loss: 0.8859850636383888\n",
      "[EPOCH #25, step #1024] loss: 0.8864874113769066\n",
      "[EPOCH #25, step #1026] loss: 0.8861524707328495\n",
      "[EPOCH #25, step #1028] loss: 0.8858706987923621\n",
      "[EPOCH #25, step #1030] loss: 0.8854744128239721\n",
      "[EPOCH #25, step #1032] loss: 0.8855105013318815\n",
      "[EPOCH #25, step #1034] loss: 0.8852801849012789\n",
      "[EPOCH #25, step #1036] loss: 0.8848456637781175\n",
      "[EPOCH #25, step #1038] loss: 0.8855666727888917\n",
      "[EPOCH #25, step #1040] loss: 0.8858562314830986\n",
      "[EPOCH #25, step #1042] loss: 0.8855524536575818\n",
      "[EPOCH #25, step #1044] loss: 0.8857105711145264\n",
      "[EPOCH #25, step #1046] loss: 0.8859509578350052\n",
      "[EPOCH #25, step #1048] loss: 0.8867404689609266\n",
      "[EPOCH #25, step #1050] loss: 0.8870263268956675\n",
      "[EPOCH #25, step #1052] loss: 0.8870988546217042\n",
      "[EPOCH #25, step #1054] loss: 0.8869079137582915\n",
      "[EPOCH #25, step #1056] loss: 0.8869867403493699\n",
      "[EPOCH #25, step #1058] loss: 0.8870585717549293\n",
      "[EPOCH #25, step #1060] loss: 0.8870362978460202\n",
      "[EPOCH #25, step #1062] loss: 0.8867445191962474\n",
      "[EPOCH #25, step #1064] loss: 0.8868294943946068\n",
      "[EPOCH #25, step #1066] loss: 0.8869995410853496\n",
      "[EPOCH #25, step #1068] loss: 0.8871702936846481\n",
      "[EPOCH #25, step #1070] loss: 0.8881181727548718\n",
      "[EPOCH #25, step #1072] loss: 0.8880898378935242\n",
      "[EPOCH #25, step #1074] loss: 0.8876468911004621\n",
      "[EPOCH #25, step #1076] loss: 0.8874885222650615\n",
      "[EPOCH #25, step #1078] loss: 0.8875020439973907\n",
      "[EPOCH #25, step #1080] loss: 0.8876696804350553\n",
      "[EPOCH #25, step #1082] loss: 0.8874376838612315\n",
      "[EPOCH #25, step #1084] loss: 0.8880253733852492\n",
      "[EPOCH #25, step #1086] loss: 0.8881127949745806\n",
      "[EPOCH #25, step #1088] loss: 0.8877126740358421\n",
      "[EPOCH #25, step #1090] loss: 0.8878330849486682\n",
      "[EPOCH #25, step #1092] loss: 0.8877807943404321\n",
      "[EPOCH #25, step #1094] loss: 0.8874034923505565\n",
      "[EPOCH #25, step #1096] loss: 0.887164597361329\n",
      "[EPOCH #25, step #1098] loss: 0.8873781225050006\n",
      "[EPOCH #25, step #1100] loss: 0.8876603660964619\n",
      "[EPOCH #25, step #1102] loss: 0.8874040648597863\n",
      "[EPOCH #25, step #1104] loss: 0.8875873184851392\n",
      "[EPOCH #25, step #1106] loss: 0.8877877511736931\n",
      "[EPOCH #25, step #1108] loss: 0.8881604956871115\n",
      "[EPOCH #25, step #1110] loss: 0.887920114878166\n",
      "[EPOCH #25, step #1112] loss: 0.8878156723252096\n",
      "[EPOCH #25, step #1114] loss: 0.8879186320732527\n",
      "[EPOCH #25, step #1116] loss: 0.8879580633279567\n",
      "[EPOCH #25, step #1118] loss: 0.8882781879192383\n",
      "[EPOCH #25, step #1120] loss: 0.8881972518805198\n",
      "[EPOCH #25, step #1122] loss: 0.8883537623570206\n",
      "[EPOCH #25, step #1124] loss: 0.8881791634029812\n",
      "[EPOCH #25, step #1126] loss: 0.8879478934494499\n",
      "[EPOCH #25, step #1128] loss: 0.8873149829168463\n",
      "[EPOCH #25, step #1130] loss: 0.8871545389518602\n",
      "[EPOCH #25, step #1132] loss: 0.8868085018639426\n",
      "[EPOCH #25, step #1134] loss: 0.8871529242540771\n",
      "[EPOCH #25, step #1136] loss: 0.8876573426637507\n",
      "[EPOCH #25, step #1138] loss: 0.8883149864068672\n",
      "[EPOCH #25, step #1140] loss: 0.8880215175939589\n",
      "[EPOCH #25, step #1142] loss: 0.8880770367587333\n",
      "[EPOCH #25, step #1144] loss: 0.8878604192400603\n",
      "[EPOCH #25, step #1146] loss: 0.8877353603775436\n",
      "[EPOCH #25, step #1148] loss: 0.8879679278045037\n",
      "[EPOCH #25, step #1150] loss: 0.8884250843763144\n",
      "[EPOCH #25, step #1152] loss: 0.8881020479789529\n",
      "[EPOCH #25, step #1154] loss: 0.8879977965767766\n",
      "[EPOCH #25, step #1156] loss: 0.8879838160842065\n",
      "[EPOCH #25, step #1158] loss: 0.887694179034624\n",
      "[EPOCH #25, step #1160] loss: 0.8873664269819022\n",
      "[EPOCH #25, step #1162] loss: 0.8875193085172314\n",
      "[EPOCH #25, step #1164] loss: 0.8875415273746196\n",
      "[EPOCH #25, step #1166] loss: 0.8875893426176413\n",
      "[EPOCH #25, step #1168] loss: 0.8877454246844462\n",
      "[EPOCH #25, step #1170] loss: 0.8879230138738373\n",
      "[EPOCH #25, step #1172] loss: 0.8877052085732966\n",
      "[EPOCH #25, step #1174] loss: 0.8882233202457428\n",
      "[EPOCH #25, step #1176] loss: 0.8888674778713447\n",
      "[EPOCH #25, step #1178] loss: 0.8891045229479456\n",
      "[EPOCH #25, step #1180] loss: 0.8890372413533103\n",
      "[EPOCH #25, step #1182] loss: 0.8890949811405382\n",
      "[EPOCH #25, step #1184] loss: 0.8890560798252685\n",
      "[EPOCH #25, step #1186] loss: 0.8892925447692566\n",
      "[EPOCH #25, step #1188] loss: 0.8890415942648863\n",
      "[EPOCH #25, step #1190] loss: 0.8886601663406509\n",
      "[EPOCH #25, step #1192] loss: 0.8884319227129496\n",
      "[EPOCH #25, step #1194] loss: 0.8888670778922955\n",
      "[EPOCH #25, step #1196] loss: 0.8887207316127337\n",
      "[EPOCH #25, step #1198] loss: 0.8883632529119933\n",
      "[EPOCH #25, step #1200] loss: 0.8882437171437758\n",
      "[EPOCH #25, step #1202] loss: 0.8880366283907855\n",
      "[EPOCH #25, step #1204] loss: 0.8880206740001425\n",
      "[EPOCH #25, step #1206] loss: 0.8883966809723529\n",
      "[EPOCH #25, step #1208] loss: 0.8881657889453314\n",
      "[EPOCH #25, step #1210] loss: 0.8881010064450696\n",
      "[EPOCH #25, step #1212] loss: 0.8880927458786316\n",
      "[EPOCH #25, step #1214] loss: 0.8884141147136688\n",
      "[EPOCH #25, step #1216] loss: 0.8878816681605631\n",
      "[EPOCH #25, step #1218] loss: 0.8876431759896094\n",
      "[EPOCH #25, step #1220] loss: 0.8876246204149714\n",
      "[EPOCH #25, step #1222] loss: 0.8874332347271\n",
      "[EPOCH #25, step #1224] loss: 0.8876268755659765\n",
      "[EPOCH #25, step #1226] loss: 0.8878260124186335\n",
      "[EPOCH #25, step #1228] loss: 0.8878951863218265\n",
      "[EPOCH #25, step #1230] loss: 0.888104955565145\n",
      "[EPOCH #25, step #1232] loss: 0.8880049927101228\n",
      "[EPOCH #25, step #1234] loss: 0.8880130798227874\n",
      "[EPOCH #25, step #1236] loss: 0.8879702114345763\n",
      "[EPOCH #25, step #1238] loss: 0.8878976983635343\n",
      "[EPOCH #25, step #1240] loss: 0.8879572163177631\n",
      "[EPOCH #25, step #1242] loss: 0.8881153135844421\n",
      "[EPOCH #25, step #1244] loss: 0.8886717942823846\n",
      "[EPOCH #25, step #1246] loss: 0.8886411524621983\n",
      "[EPOCH #25, step #1248] loss: 0.888747045285612\n",
      "[EPOCH #25, step #1250] loss: 0.888720071287178\n",
      "[EPOCH #25, step #1252] loss: 0.888794330007442\n",
      "[EPOCH #25, step #1254] loss: 0.8887007628779012\n",
      "[EPOCH #25, step #1256] loss: 0.8884774922091713\n",
      "[EPOCH #25, step #1258] loss: 0.8887034293391385\n",
      "[EPOCH #25, step #1260] loss: 0.8885082633224959\n",
      "[EPOCH #25, step #1262] loss: 0.8883465150472953\n",
      "[EPOCH #25, step #1264] loss: 0.8880903040938698\n",
      "[EPOCH #25, step #1266] loss: 0.8880060306193797\n",
      "[EPOCH #25, step #1268] loss: 0.8879523740874397\n",
      "[EPOCH #25, step #1270] loss: 0.8880185851611836\n",
      "[EPOCH #25, step #1272] loss: 0.8881022767672273\n",
      "[EPOCH #25, step #1274] loss: 0.8880231006005231\n",
      "[EPOCH #25, step #1276] loss: 0.888016495092268\n",
      "[EPOCH #25, step #1278] loss: 0.8880388715287687\n",
      "[EPOCH #25, step #1280] loss: 0.888431740216591\n",
      "[EPOCH #25, step #1282] loss: 0.8881543998781444\n",
      "[EPOCH #25, step #1284] loss: 0.8882124591430337\n",
      "[EPOCH #25, step #1286] loss: 0.8879764081900121\n",
      "[EPOCH #25, step #1288] loss: 0.8879101561704655\n",
      "[EPOCH #25, step #1290] loss: 0.887739846865213\n",
      "[EPOCH #25, step #1292] loss: 0.8877780756467272\n",
      "[EPOCH #25, step #1294] loss: 0.8877321147550488\n",
      "[EPOCH #25, step #1296] loss: 0.8876791078950592\n",
      "[EPOCH #25, step #1298] loss: 0.8879004611796466\n",
      "[EPOCH #25, step #1300] loss: 0.8876416318742795\n",
      "[EPOCH #25, step #1302] loss: 0.887683767793916\n",
      "[EPOCH #25, step #1304] loss: 0.8873041920049894\n",
      "[EPOCH #25, step #1306] loss: 0.8871636663170926\n",
      "[EPOCH #25, step #1308] loss: 0.8870518753736232\n",
      "[EPOCH #25, step #1310] loss: 0.8871739893401515\n",
      "[EPOCH #25, step #1312] loss: 0.8872277936178223\n",
      "[EPOCH #25, step #1314] loss: 0.8873934667146705\n",
      "[EPOCH #25, step #1316] loss: 0.8872549295561188\n",
      "[EPOCH #25, step #1318] loss: 0.8873798382878756\n",
      "[EPOCH #25, step #1320] loss: 0.8876957994667893\n",
      "[EPOCH #25, step #1322] loss: 0.8875505195948903\n",
      "[EPOCH #25, step #1324] loss: 0.8875760008479064\n",
      "[EPOCH #25, step #1326] loss: 0.887327985132019\n",
      "[EPOCH #25, step #1328] loss: 0.8871546431848929\n",
      "[EPOCH #25, step #1330] loss: 0.8870711581183949\n",
      "[EPOCH #25, step #1332] loss: 0.8868916902833653\n",
      "[EPOCH #25, step #1334] loss: 0.886749546960945\n",
      "[EPOCH #25, step #1336] loss: 0.8870229915219096\n",
      "[EPOCH #25, step #1338] loss: 0.8870215606253213\n",
      "[EPOCH #25, step #1340] loss: 0.8869385613291055\n",
      "[EPOCH #25, step #1342] loss: 0.8871819734440219\n",
      "[EPOCH #25, step #1344] loss: 0.887060066514742\n",
      "[EPOCH #25, step #1346] loss: 0.8866690157649246\n",
      "[EPOCH #25, step #1348] loss: 0.8865959933062144\n",
      "[EPOCH #25, step #1350] loss: 0.8865438698398723\n",
      "[EPOCH #25, step #1352] loss: 0.8865391819545805\n",
      "[EPOCH #25, step #1354] loss: 0.8865592352138674\n",
      "[EPOCH #25, step #1356] loss: 0.8867890195277305\n",
      "[EPOCH #25, step #1358] loss: 0.8868906246203548\n",
      "[EPOCH #25, step #1360] loss: 0.8869253944422198\n",
      "[EPOCH #25, step #1362] loss: 0.8871576137080931\n",
      "[EPOCH #25, step #1364] loss: 0.8872568772826003\n",
      "[EPOCH #25, step #1366] loss: 0.8871418287829055\n",
      "[EPOCH #25, step #1368] loss: 0.8868921179680863\n",
      "[EPOCH #25, step #1370] loss: 0.8868068170582265\n",
      "[EPOCH #25, step #1372] loss: 0.8866083427058982\n",
      "[EPOCH #25, step #1374] loss: 0.8863855891661211\n",
      "[EPOCH #25, step #1376] loss: 0.8864236552817456\n",
      "[EPOCH #25, step #1378] loss: 0.8862055781701926\n",
      "[EPOCH #25, step #1380] loss: 0.886137093952132\n",
      "[EPOCH #25, step #1382] loss: 0.8862882481479851\n",
      "[EPOCH #25, step #1384] loss: 0.8859870001297134\n",
      "[EPOCH #25, step #1386] loss: 0.8858656964030469\n",
      "[EPOCH #25, step #1388] loss: 0.8859428272906441\n",
      "[EPOCH #25, step #1390] loss: 0.8863126732821434\n",
      "[EPOCH #25, step #1392] loss: 0.8863991488677858\n",
      "[EPOCH #25, step #1394] loss: 0.8863432072824048\n",
      "[EPOCH #25, step #1396] loss: 0.8865589035692263\n",
      "[EPOCH #25, step #1398] loss: 0.8870283862026016\n",
      "[EPOCH #25, step #1400] loss: 0.8867558984565871\n",
      "[EPOCH #25, step #1402] loss: 0.8869128892953618\n",
      "[EPOCH #25, step #1404] loss: 0.8866972162205978\n",
      "[EPOCH #25, step #1406] loss: 0.8872674982769742\n",
      "[EPOCH #25, step #1408] loss: 0.8871217460984283\n",
      "[EPOCH #25, step #1410] loss: 0.8871984687534146\n",
      "[EPOCH #25, step #1412] loss: 0.8870893263344384\n",
      "[EPOCH #25, step #1414] loss: 0.8868607386262173\n",
      "[EPOCH #25, step #1416] loss: 0.8867793489528863\n",
      "[EPOCH #25, step #1418] loss: 0.8868129239525906\n",
      "[EPOCH #25, step #1420] loss: 0.8867016178801561\n",
      "[EPOCH #25, step #1422] loss: 0.8867394904058246\n",
      "[EPOCH #25, step #1424] loss: 0.8866853380203247\n",
      "[EPOCH #25, step #1426] loss: 0.8866373550749861\n",
      "[EPOCH #25, step #1428] loss: 0.8867302094830593\n",
      "[EPOCH #25, step #1430] loss: 0.8864915582535569\n",
      "[EPOCH #25, step #1432] loss: 0.8868212193271453\n",
      "[EPOCH #25, step #1434] loss: 0.8869805150331105\n",
      "[EPOCH #25, step #1436] loss: 0.887022602699163\n",
      "[EPOCH #25, step #1438] loss: 0.886933326141299\n",
      "[EPOCH #25, step #1440] loss: 0.8869371676014828\n",
      "[EPOCH #25, step #1442] loss: 0.8865455644294279\n",
      "[EPOCH #25, step #1444] loss: 0.886877865114839\n",
      "[EPOCH #25, step #1446] loss: 0.886908075194896\n",
      "[EPOCH #25, step #1448] loss: 0.8868402247596725\n",
      "[EPOCH #25, step #1450] loss: 0.887069361650229\n",
      "[EPOCH #25, step #1452] loss: 0.8875680874317823\n",
      "[EPOCH #25, step #1454] loss: 0.8876851952362717\n",
      "[EPOCH #25, step #1456] loss: 0.8874770871318196\n",
      "[EPOCH #25, step #1458] loss: 0.8876829979107591\n",
      "[EPOCH #25, step #1460] loss: 0.8878884648803487\n",
      "[EPOCH #25, step #1462] loss: 0.8880214256858956\n",
      "[EPOCH #25, step #1464] loss: 0.8881577053574572\n",
      "[EPOCH #25, step #1466] loss: 0.8884737773175619\n",
      "[EPOCH #25, step #1468] loss: 0.8882254955718272\n",
      "[EPOCH #25, step #1470] loss: 0.8882464751104852\n",
      "[EPOCH #25, step #1472] loss: 0.8880419493004811\n",
      "[EPOCH #25, step #1474] loss: 0.8877069532467147\n",
      "[EPOCH #25, step #1476] loss: 0.888262669400097\n",
      "[EPOCH #25, step #1478] loss: 0.8885404793010361\n",
      "[EPOCH #25, step #1480] loss: 0.888327939557836\n",
      "[EPOCH #25, step #1482] loss: 0.8881934377002458\n",
      "[EPOCH #25, step #1484] loss: 0.8883096435053983\n",
      "[EPOCH #25, step #1486] loss: 0.888779015872169\n",
      "[EPOCH #25, step #1488] loss: 0.8888220861303958\n",
      "[EPOCH #25, step #1490] loss: 0.8889996210933931\n",
      "[EPOCH #25, step #1492] loss: 0.8891267351112506\n",
      "[EPOCH #25, step #1494] loss: 0.8891351554505402\n",
      "[EPOCH #25, step #1496] loss: 0.8888349282438944\n",
      "[EPOCH #25, step #1498] loss: 0.8886742716514723\n",
      "[EPOCH #25, step #1500] loss: 0.8885755155937899\n",
      "[EPOCH #25, step #1502] loss: 0.8884264399469176\n",
      "[EPOCH #25, step #1504] loss: 0.8884270717337281\n",
      "[EPOCH #25, step #1506] loss: 0.888278876244033\n",
      "[EPOCH #25, step #1508] loss: 0.8882312267287983\n",
      "[EPOCH #25, step #1510] loss: 0.8883750294905322\n",
      "[EPOCH #25, step #1512] loss: 0.888486388634942\n",
      "[EPOCH #25, step #1514] loss: 0.8887445230491877\n",
      "[EPOCH #25, step #1516] loss: 0.8886095915056014\n",
      "[EPOCH #25, step #1518] loss: 0.8884045456764806\n",
      "[EPOCH #25, step #1520] loss: 0.888447907686547\n",
      "[EPOCH #25, step #1522] loss: 0.8884348865605778\n",
      "[EPOCH #25, step #1524] loss: 0.888418265542046\n",
      "[EPOCH #25, step #1526] loss: 0.888464922852663\n",
      "[EPOCH #25, step #1528] loss: 0.8885339618002066\n",
      "[EPOCH #25, step #1530] loss: 0.8881066775960442\n",
      "[EPOCH #25, step #1532] loss: 0.8880153753286238\n",
      "[EPOCH #25, step #1534] loss: 0.8878349158196962\n",
      "[EPOCH #25, step #1536] loss: 0.88764087686154\n",
      "[EPOCH #25, step #1538] loss: 0.8877233759856519\n",
      "[EPOCH #25, step #1540] loss: 0.8874098287241402\n",
      "[EPOCH #25, step #1542] loss: 0.8875278566305466\n",
      "[EPOCH #25, step #1544] loss: 0.887936190532635\n",
      "[EPOCH #25, step #1546] loss: 0.8881338807406854\n",
      "[EPOCH #25, step #1548] loss: 0.8882288986286707\n",
      "[EPOCH #25, step #1550] loss: 0.888622356836908\n",
      "[EPOCH #25, step #1552] loss: 0.888992092606335\n",
      "[EPOCH #25, step #1554] loss: 0.8889794025007168\n",
      "[EPOCH #25, step #1556] loss: 0.8890880572926025\n",
      "[EPOCH #25, step #1558] loss: 0.8889678385565111\n",
      "[EPOCH #25, step #1560] loss: 0.8889688216746426\n",
      "[EPOCH #25, step #1562] loss: 0.8891334807499052\n",
      "[EPOCH #25, step #1564] loss: 0.8887658442932957\n",
      "[EPOCH #25, step #1566] loss: 0.8884465878148252\n",
      "[EPOCH #25, step #1568] loss: 0.8891817766667324\n",
      "[EPOCH #25, step #1570] loss: 0.8890764519411011\n",
      "[EPOCH #25, step #1572] loss: 0.8893177704453392\n",
      "[EPOCH #25, step #1574] loss: 0.8892638402514987\n",
      "[EPOCH #25, step #1576] loss: 0.8891051707573154\n",
      "[EPOCH #25, step #1578] loss: 0.8893116900556974\n",
      "[EPOCH #25, step #1580] loss: 0.8891516795722387\n",
      "[EPOCH #25, step #1582] loss: 0.8891955332069252\n",
      "[EPOCH #25, step #1584] loss: 0.889169593451527\n",
      "[EPOCH #25, step #1586] loss: 0.8889514506802141\n",
      "[EPOCH #25, step #1588] loss: 0.8889348183584483\n",
      "[EPOCH #25, step #1590] loss: 0.8890286240466806\n",
      "[EPOCH #25, step #1592] loss: 0.8891816388415752\n",
      "[EPOCH #25, step #1594] loss: 0.8893053832472678\n",
      "[EPOCH #25, step #1596] loss: 0.8893994763633498\n",
      "[EPOCH #25, step #1598] loss: 0.8893602216445036\n",
      "[EPOCH #25, step #1600] loss: 0.8890107603165449\n",
      "[EPOCH #25, step #1602] loss: 0.8891122520378956\n",
      "[EPOCH #25, step #1604] loss: 0.8888731625592597\n",
      "[EPOCH #25, step #1606] loss: 0.8890477689290239\n",
      "[EPOCH #25, step #1608] loss: 0.8889079522167843\n",
      "[EPOCH #25, step #1610] loss: 0.888575192122338\n",
      "[EPOCH #25, step #1612] loss: 0.8885557841086934\n",
      "[EPOCH #25, step #1614] loss: 0.8887623517505894\n",
      "[EPOCH #25, step #1616] loss: 0.8888058308915142\n",
      "[EPOCH #25, step #1618] loss: 0.8887253279594671\n",
      "[EPOCH #25, step #1620] loss: 0.8885237175251951\n",
      "[EPOCH #25, step #1622] loss: 0.8887149694519725\n",
      "[EPOCH #25, step #1624] loss: 0.8886921293552105\n",
      "[EPOCH #25, step #1626] loss: 0.8893771211135292\n",
      "[EPOCH #25, step #1628] loss: 0.889832479006824\n",
      "[EPOCH #25, step #1630] loss: 0.88973892783914\n",
      "[EPOCH #25, step #1632] loss: 0.8895803591406426\n",
      "[EPOCH #25, step #1634] loss: 0.8895420683633297\n",
      "[EPOCH #25, step #1636] loss: 0.8895280227547531\n",
      "[EPOCH #25, step #1638] loss: 0.8897095534989135\n",
      "[EPOCH #25, step #1640] loss: 0.8897054917851576\n",
      "[EPOCH #25, step #1642] loss: 0.8895570755875554\n",
      "[EPOCH #25, step #1644] loss: 0.8896192815166114\n",
      "[EPOCH #25, step #1646] loss: 0.8894188240143337\n",
      "[EPOCH #25, step #1648] loss: 0.8890933331899602\n",
      "[EPOCH #25, step #1650] loss: 0.8889601370697668\n",
      "[EPOCH #25, step #1652] loss: 0.8887965266299263\n",
      "[EPOCH #25, step #1654] loss: 0.8888531626891514\n",
      "[EPOCH #25, step #1656] loss: 0.8886399917309012\n",
      "[EPOCH #25, step #1658] loss: 0.888692233345464\n",
      "[EPOCH #25, step #1660] loss: 0.8886398457389937\n",
      "[EPOCH #25, step #1662] loss: 0.8885836269363752\n",
      "[EPOCH #25, step #1664] loss: 0.8884924761525862\n",
      "[EPOCH #25, step #1666] loss: 0.8885640816983164\n",
      "[EPOCH #25, step #1668] loss: 0.8885885258860899\n",
      "[EPOCH #25, step #1670] loss: 0.8884141619764782\n",
      "[EPOCH #25, step #1672] loss: 0.8883588085862882\n",
      "[EPOCH #25, step #1674] loss: 0.888142098508664\n",
      "[EPOCH #25, step #1676] loss: 0.8879995562700409\n",
      "[EPOCH #25, step #1678] loss: 0.888248218515219\n",
      "[EPOCH #25, step #1680] loss: 0.88838928673751\n",
      "[EPOCH #25, step #1682] loss: 0.8885622463513894\n",
      "[EPOCH #25, step #1684] loss: 0.888548514697955\n",
      "[EPOCH #25, step #1686] loss: 0.8885058332245662\n",
      "[EPOCH #25, step #1688] loss: 0.8885558955305212\n",
      "[EPOCH #25, step #1690] loss: 0.8886007107375713\n",
      "[EPOCH #25, step #1692] loss: 0.888596275556179\n",
      "[EPOCH #25, step #1694] loss: 0.8886529961694307\n",
      "[EPOCH #25, step #1696] loss: 0.888626049582791\n",
      "[EPOCH #25, step #1698] loss: 0.8884872761700279\n",
      "[EPOCH #25, step #1700] loss: 0.8886799761332321\n",
      "[EPOCH #25, step #1702] loss: 0.8889128672712632\n",
      "[EPOCH #25, step #1704] loss: 0.8888913532331193\n",
      "[EPOCH #25, step #1706] loss: 0.8890288774039777\n",
      "[EPOCH #25, step #1708] loss: 0.8892964942368797\n",
      "[EPOCH #25, step #1710] loss: 0.8896761234743006\n",
      "[EPOCH #25, step #1712] loss: 0.8898169051570914\n",
      "[EPOCH #25, step #1714] loss: 0.8897819760415714\n",
      "[EPOCH #25, step #1716] loss: 0.8897130459668543\n",
      "[EPOCH #25, step #1718] loss: 0.8895848527108604\n",
      "[EPOCH #25, step #1720] loss: 0.8893781350249125\n",
      "[EPOCH #25, step #1722] loss: 0.8896161549428971\n",
      "[EPOCH #25, step #1724] loss: 0.8897657238746035\n",
      "[EPOCH #25, step #1726] loss: 0.8896997700934474\n",
      "[EPOCH #25, step #1728] loss: 0.8897901144139404\n",
      "[EPOCH #25, step #1730] loss: 0.8897350239209671\n",
      "[EPOCH #25, step #1732] loss: 0.8897032306604281\n",
      "[EPOCH #25, step #1734] loss: 0.8896573175786208\n",
      "[EPOCH #25, step #1736] loss: 0.8896943089360811\n",
      "[EPOCH #25, step #1738] loss: 0.8896302802422871\n",
      "[EPOCH #25, step #1740] loss: 0.8897454825404867\n",
      "[EPOCH #25, step #1742] loss: 0.8898369070619122\n",
      "[EPOCH #25, step #1744] loss: 0.89001865778065\n",
      "[EPOCH #25, step #1746] loss: 0.8898502370768024\n",
      "[EPOCH #25, step #1748] loss: 0.8897744638194623\n",
      "[EPOCH #25, step #1750] loss: 0.8900710322358553\n",
      "[EPOCH #25, step #1752] loss: 0.8899498378387262\n",
      "[EPOCH #25, step #1754] loss: 0.8899857529038377\n",
      "[EPOCH #25, step #1756] loss: 0.8902269108056615\n",
      "[EPOCH #25, step #1758] loss: 0.8903277406067656\n",
      "[EPOCH #25, step #1760] loss: 0.8902312605676158\n",
      "[EPOCH #25, step #1762] loss: 0.8902795423145532\n",
      "[EPOCH #25, step #1764] loss: 0.8901978301427858\n",
      "[EPOCH #25, step #1766] loss: 0.8901738944907747\n",
      "[EPOCH #25, step #1768] loss: 0.889839842115303\n",
      "[EPOCH #25, step #1770] loss: 0.8897363507666876\n",
      "[EPOCH #25, step #1772] loss: 0.8897896579982061\n",
      "[EPOCH #25, step #1774] loss: 0.8896986140163852\n",
      "[EPOCH #25, step #1776] loss: 0.8893754141982781\n",
      "[EPOCH #25, step #1778] loss: 0.8893325534712538\n",
      "[EPOCH #25, step #1780] loss: 0.8890115848623722\n",
      "[EPOCH #25, step #1782] loss: 0.8886921398103471\n",
      "[EPOCH #25, step #1784] loss: 0.8888683100708392\n",
      "[EPOCH #25, step #1786] loss: 0.8889165132420651\n",
      "[EPOCH #25, step #1788] loss: 0.8887489045579184\n",
      "[EPOCH #25, step #1790] loss: 0.8889229603814786\n",
      "[EPOCH #25, step #1792] loss: 0.8888924136483596\n",
      "[EPOCH #25, step #1794] loss: 0.889003717633675\n",
      "[EPOCH #25, step #1796] loss: 0.8887377899258284\n",
      "[EPOCH #25, step #1798] loss: 0.8886945996601228\n",
      "[EPOCH #25, step #1800] loss: 0.8885316406767081\n",
      "[EPOCH #25, step #1802] loss: 0.8885624366902802\n",
      "[EPOCH #25, step #1804] loss: 0.8884989280284606\n",
      "[EPOCH #25, step #1806] loss: 0.8884856443775907\n",
      "[EPOCH #25, step #1808] loss: 0.8887381119877018\n",
      "[EPOCH #25, step #1810] loss: 0.888553488277586\n",
      "[EPOCH #25, step #1812] loss: 0.8884972810449353\n",
      "[EPOCH #25, step #1814] loss: 0.8885935154663959\n",
      "[EPOCH #25, step #1816] loss: 0.8885827710258482\n",
      "[EPOCH #25, step #1818] loss: 0.8883295271375665\n",
      "[EPOCH #25, step #1820] loss: 0.8883303045604597\n",
      "[EPOCH #25, step #1822] loss: 0.8884027565140288\n",
      "[EPOCH #25, step #1824] loss: 0.8883383390511552\n",
      "[EPOCH #25, step #1826] loss: 0.8885938945238095\n",
      "[EPOCH #25, step #1828] loss: 0.8888694552563134\n",
      "[EPOCH #25, step #1830] loss: 0.8887676520304625\n",
      "[EPOCH #25, step #1832] loss: 0.8884888883015528\n",
      "[EPOCH #25, step #1834] loss: 0.88884690166819\n",
      "[EPOCH #25, step #1836] loss: 0.888876697146899\n",
      "[EPOCH #25, step #1838] loss: 0.8891538863372647\n",
      "[EPOCH #25, step #1840] loss: 0.8893873321660377\n",
      "[EPOCH #25, step #1842] loss: 0.8895814907951841\n",
      "[EPOCH #25, step #1844] loss: 0.8894601568781586\n",
      "[EPOCH #25, step #1846] loss: 0.8893494471609108\n",
      "[EPOCH #25, step #1848] loss: 0.8893526749168621\n",
      "[EPOCH #25, step #1850] loss: 0.8892258535939768\n",
      "[EPOCH #25, step #1852] loss: 0.8892328006251078\n",
      "[EPOCH #25, step #1854] loss: 0.889285818216293\n",
      "[EPOCH #25, step #1856] loss: 0.8891455956248744\n",
      "[EPOCH #25, step #1858] loss: 0.8890118494894378\n",
      "[EPOCH #25, step #1860] loss: 0.8889714563520669\n",
      "[EPOCH #25, step #1862] loss: 0.8891829736790732\n",
      "[EPOCH #25, step #1864] loss: 0.8891043775682475\n",
      "[EPOCH #25, step #1866] loss: 0.8893824370870248\n",
      "[EPOCH #25, step #1868] loss: 0.8895154631571568\n",
      "[EPOCH #25, step #1870] loss: 0.8895620139030006\n",
      "[EPOCH #25, step #1872] loss: 0.8898355055956425\n",
      "[EPOCH #25, step #1874] loss: 0.8896426709651947\n",
      "[EPOCH #25, step #1876] loss: 0.8895798991287904\n",
      "[EPOCH #25, step #1878] loss: 0.8891924512297502\n",
      "[EPOCH #25, step #1880] loss: 0.889216799976216\n",
      "[EPOCH #25, step #1882] loss: 0.8892624370132554\n",
      "[EPOCH #25, step #1884] loss: 0.8892401504737945\n",
      "[EPOCH #25, step #1886] loss: 0.889218791095302\n",
      "[EPOCH #25, step #1888] loss: 0.8891112677725362\n",
      "[EPOCH #25, step #1890] loss: 0.8889387482092659\n",
      "[EPOCH #25, step #1892] loss: 0.8888265287913913\n",
      "[EPOCH #25, step #1894] loss: 0.8887365993377716\n",
      "[EPOCH #25, step #1896] loss: 0.8887417950030685\n",
      "[EPOCH #25, step #1898] loss: 0.8887943222906918\n",
      "[EPOCH #25, step #1900] loss: 0.8885743103016056\n",
      "[EPOCH #25, step #1902] loss: 0.8885207406577472\n",
      "[EPOCH #25, step #1904] loss: 0.8885703646761226\n",
      "[EPOCH #25, step #1906] loss: 0.8885974379722273\n",
      "[EPOCH #25, step #1908] loss: 0.8885626621025279\n",
      "[EPOCH #25, step #1910] loss: 0.888435651141271\n",
      "[EPOCH #25, step #1912] loss: 0.8883228164129212\n",
      "[EPOCH #25, step #1914] loss: 0.8884031400823718\n",
      "[EPOCH #25, step #1916] loss: 0.8884064728509776\n",
      "[EPOCH #25, step #1918] loss: 0.8881633016608419\n",
      "[EPOCH #25, step #1920] loss: 0.8881766695116163\n",
      "[EPOCH #25, step #1922] loss: 0.8880065525966699\n",
      "[EPOCH #25, step #1924] loss: 0.8882190345634113\n",
      "[EPOCH #25, step #1926] loss: 0.8880558953764034\n",
      "[EPOCH #25, step #1928] loss: 0.8881220761174795\n",
      "[EPOCH #25, step #1930] loss: 0.8882368763359886\n",
      "[EPOCH #25, step #1932] loss: 0.8881306589513138\n",
      "[EPOCH #25, step #1934] loss: 0.8879962560280349\n",
      "[EPOCH #25, step #1936] loss: 0.8879034738443411\n",
      "[EPOCH #25, step #1938] loss: 0.887828139790928\n",
      "[EPOCH #25, step #1940] loss: 0.8877173985389629\n",
      "[EPOCH #25, step #1942] loss: 0.8878221663843401\n",
      "[EPOCH #25, step #1944] loss: 0.8879421434702788\n",
      "[EPOCH #25, step #1946] loss: 0.8880905948759166\n",
      "[EPOCH #25, step #1948] loss: 0.88802958677034\n",
      "[EPOCH #25, step #1950] loss: 0.8879541906712912\n",
      "[EPOCH #25, step #1952] loss: 0.887821512761265\n",
      "[EPOCH #25, step #1954] loss: 0.8876448924736599\n",
      "[EPOCH #25, step #1956] loss: 0.8876841489033365\n",
      "[EPOCH #25, step #1958] loss: 0.8878945152238658\n",
      "[EPOCH #25, step #1960] loss: 0.8878902549314475\n",
      "[EPOCH #25, step #1962] loss: 0.8878643211969841\n",
      "[EPOCH #25, step #1964] loss: 0.8882654200831746\n",
      "[EPOCH #25, step #1966] loss: 0.8882861807828757\n",
      "[EPOCH #25, step #1968] loss: 0.8884078375787042\n",
      "[EPOCH #25, step #1970] loss: 0.8883491696318293\n",
      "[EPOCH #25, step #1972] loss: 0.8882033992435989\n",
      "[EPOCH #25, step #1974] loss: 0.8882658265964894\n",
      "[EPOCH #25, step #1976] loss: 0.8882462386386709\n",
      "[EPOCH #25, step #1978] loss: 0.8883739361532894\n",
      "[EPOCH #25, step #1980] loss: 0.8883128349586065\n",
      "[EPOCH #25, step #1982] loss: 0.8887070341508195\n",
      "[EPOCH #25, step #1984] loss: 0.8886946302967648\n",
      "[EPOCH #25, step #1986] loss: 0.8886386276821305\n",
      "[EPOCH #25, step #1988] loss: 0.8884505116951531\n",
      "[EPOCH #25, step #1990] loss: 0.8885660950919602\n",
      "[EPOCH #25, step #1992] loss: 0.8884627609263697\n",
      "[EPOCH #25, step #1994] loss: 0.888410107309657\n",
      "[EPOCH #25, step #1996] loss: 0.8884447460092183\n",
      "[EPOCH #25, step #1998] loss: 0.8887346099024119\n",
      "[EPOCH #25, step #2000] loss: 0.8887826499642282\n",
      "[EPOCH #25, step #2002] loss: 0.8887897186349525\n",
      "[EPOCH #25, step #2004] loss: 0.8889340082457535\n",
      "[EPOCH #25, step #2006] loss: 0.8891452440261604\n",
      "[EPOCH #25, step #2008] loss: 0.8890117971294255\n",
      "[EPOCH #25, step #2010] loss: 0.8889905480026072\n",
      "[EPOCH #25, step #2012] loss: 0.8887935407085912\n",
      "[EPOCH #25, step #2014] loss: 0.8887518508410631\n",
      "[EPOCH #25, step #2016] loss: 0.8884618441155481\n",
      "[EPOCH #25, step #2018] loss: 0.8883734936611436\n",
      "[EPOCH #25, step #2020] loss: 0.8885278895991324\n",
      "[EPOCH #25, step #2022] loss: 0.8886973002701777\n",
      "[EPOCH #25, step #2024] loss: 0.888791920505924\n",
      "[EPOCH #25, step #2026] loss: 0.8886037483171813\n",
      "[EPOCH #25, step #2028] loss: 0.8884878889012654\n",
      "[EPOCH #25, step #2030] loss: 0.8885001378039431\n",
      "[EPOCH #25, step #2032] loss: 0.8884658202770832\n",
      "[EPOCH #25, step #2034] loss: 0.8882721713485531\n",
      "[EPOCH #25, step #2036] loss: 0.8883099163286698\n",
      "[EPOCH #25, step #2038] loss: 0.8883426617675695\n",
      "[EPOCH #25, step #2040] loss: 0.8881120319929502\n",
      "[EPOCH #25, step #2042] loss: 0.888150992051562\n",
      "[EPOCH #25, step #2044] loss: 0.8883487240609447\n",
      "[EPOCH #25, step #2046] loss: 0.8884284515234104\n",
      "[EPOCH #25, step #2048] loss: 0.8882965718379191\n",
      "[EPOCH #25, step #2050] loss: 0.8883207619103032\n",
      "[EPOCH #25, step #2052] loss: 0.888269548844664\n",
      "[EPOCH #25, step #2054] loss: 0.8883739830223604\n",
      "[EPOCH #25, step #2056] loss: 0.8884992736835878\n",
      "[EPOCH #25, step #2058] loss: 0.8883168452454169\n",
      "[EPOCH #25, step #2060] loss: 0.8884757016828372\n",
      "[EPOCH #25, step #2062] loss: 0.8883676346620771\n",
      "[EPOCH #25, step #2064] loss: 0.8883602373825147\n",
      "[EPOCH #25, step #2066] loss: 0.888234361306907\n",
      "[EPOCH #25, step #2068] loss: 0.8882553164886356\n",
      "[EPOCH #25, step #2070] loss: 0.888300592717429\n",
      "[EPOCH #25, step #2072] loss: 0.8886239472012903\n",
      "[EPOCH #25, step #2074] loss: 0.8886397687211094\n",
      "[EPOCH #25, step #2076] loss: 0.8888591944626104\n",
      "[EPOCH #25, step #2078] loss: 0.8891290860315996\n",
      "[EPOCH #25, step #2080] loss: 0.889037105310771\n",
      "[EPOCH #25, step #2082] loss: 0.8888347779851777\n",
      "[EPOCH #25, step #2084] loss: 0.8889157598538936\n",
      "[EPOCH #25, step #2086] loss: 0.8886852393495334\n",
      "[EPOCH #25, step #2088] loss: 0.8885390802739966\n",
      "[EPOCH #25, step #2090] loss: 0.888638660162046\n",
      "[EPOCH #25, step #2092] loss: 0.8883936854850945\n",
      "[EPOCH #25, step #2094] loss: 0.8883369929750665\n",
      "[EPOCH #25, step #2096] loss: 0.8881075985100818\n",
      "[EPOCH #25, step #2098] loss: 0.8883505141013801\n",
      "[EPOCH #25, step #2100] loss: 0.8883732780565936\n",
      "[EPOCH #25, step #2102] loss: 0.8884732506131197\n",
      "[EPOCH #25, step #2104] loss: 0.8883969317988941\n",
      "[EPOCH #25, step #2106] loss: 0.8882651232009711\n",
      "[EPOCH #25, step #2108] loss: 0.8880753473909956\n",
      "[EPOCH #25, step #2110] loss: 0.8879787676541063\n",
      "[EPOCH #25, step #2112] loss: 0.8878188572728798\n",
      "[EPOCH #25, step #2114] loss: 0.8876990693962602\n",
      "[EPOCH #25, step #2116] loss: 0.8875583132089282\n",
      "[EPOCH #25, step #2118] loss: 0.8876675736966028\n",
      "[EPOCH #25, step #2120] loss: 0.8875525174192638\n",
      "[EPOCH #25, step #2122] loss: 0.8872350187611591\n",
      "[EPOCH #25, step #2124] loss: 0.8873510439536151\n",
      "[EPOCH #25, step #2126] loss: 0.8873605696203342\n",
      "[EPOCH #25, step #2128] loss: 0.8873776622980959\n",
      "[EPOCH #25, step #2130] loss: 0.8874422168015651\n",
      "[EPOCH #25, step #2132] loss: 0.8877588808396809\n",
      "[EPOCH #25, step #2134] loss: 0.8879669129150534\n",
      "[EPOCH #25, step #2136] loss: 0.8878516743101692\n",
      "[EPOCH #25, step #2138] loss: 0.887776226181469\n",
      "[EPOCH #25, step #2140] loss: 0.8878579477404167\n",
      "[EPOCH #25, step #2142] loss: 0.8879594068298037\n",
      "[EPOCH #25, step #2144] loss: 0.8878675091516721\n",
      "[EPOCH #25, step #2146] loss: 0.8878070204325704\n",
      "[EPOCH #25, step #2148] loss: 0.8877404043429283\n",
      "[EPOCH #25, step #2150] loss: 0.8882515191034293\n",
      "[EPOCH #25, step #2152] loss: 0.8880602788271817\n",
      "[EPOCH #25, step #2154] loss: 0.8879481135277626\n",
      "[EPOCH #25, step #2156] loss: 0.8879533658770428\n",
      "[EPOCH #25, step #2158] loss: 0.8878756444064375\n",
      "[EPOCH #25, step #2160] loss: 0.887962133781825\n",
      "[EPOCH #25, step #2162] loss: 0.8879338572050651\n",
      "[EPOCH #25, step #2164] loss: 0.8880338447198581\n",
      "[EPOCH #25, step #2166] loss: 0.8880694298134677\n",
      "[EPOCH #25, step #2168] loss: 0.8882511169913728\n",
      "[EPOCH #25, step #2170] loss: 0.8882375844114665\n",
      "[EPOCH #25, step #2172] loss: 0.8885266046012759\n",
      "[EPOCH #25, step #2174] loss: 0.8884401540646608\n",
      "[EPOCH #25, step #2176] loss: 0.8883412258856112\n",
      "[EPOCH #25, step #2178] loss: 0.8882323794542184\n",
      "[EPOCH #25, step #2180] loss: 0.8881593096261722\n",
      "[EPOCH #25, step #2182] loss: 0.8881982336937698\n",
      "[EPOCH #25, step #2184] loss: 0.8881918463881556\n",
      "[EPOCH #25, step #2186] loss: 0.8879631267299268\n",
      "[EPOCH #25, step #2188] loss: 0.8877834213711236\n",
      "[EPOCH #25, step #2190] loss: 0.8878169934916094\n",
      "[EPOCH #25, step #2192] loss: 0.8876122051567125\n",
      "[EPOCH #25, step #2194] loss: 0.8873924643140719\n",
      "[EPOCH #25, step #2196] loss: 0.8873619801845125\n",
      "[EPOCH #25, step #2198] loss: 0.8873056714889297\n",
      "[EPOCH #25, step #2200] loss: 0.8874126973069836\n",
      "[EPOCH #25, step #2202] loss: 0.8877303415517941\n",
      "[EPOCH #25, step #2204] loss: 0.88764172251803\n",
      "[EPOCH #25, step #2206] loss: 0.8876655019404502\n",
      "[EPOCH #25, step #2208] loss: 0.8874147189532323\n",
      "[EPOCH #25, step #2210] loss: 0.8873296077841281\n",
      "[EPOCH #25, step #2212] loss: 0.887314091938629\n",
      "[EPOCH #25, step #2214] loss: 0.8870490254989866\n",
      "[EPOCH #25, step #2216] loss: 0.8869840778044122\n",
      "[EPOCH #25, step #2218] loss: 0.8870894057678714\n",
      "[EPOCH #25, step #2220] loss: 0.8870273787446089\n",
      "[EPOCH #25, step #2222] loss: 0.8870123002210609\n",
      "[EPOCH #25, step #2224] loss: 0.8870142947689871\n",
      "[EPOCH #25, step #2226] loss: 0.886939162222002\n",
      "[EPOCH #25, step #2228] loss: 0.8870229882047336\n",
      "[EPOCH #25, step #2230] loss: 0.886940738242178\n",
      "[EPOCH #25, step #2232] loss: 0.8868365629980289\n",
      "[EPOCH #25, step #2234] loss: 0.8868680867839446\n",
      "[EPOCH #25, step #2236] loss: 0.8867629512804771\n",
      "[EPOCH #25, step #2238] loss: 0.8867000467865634\n",
      "[EPOCH #25, step #2240] loss: 0.8869521811518059\n",
      "[EPOCH #25, step #2242] loss: 0.8869981384681263\n",
      "[EPOCH #25, step #2244] loss: 0.8870459373915912\n",
      "[EPOCH #25, step #2246] loss: 0.8870825678653912\n",
      "[EPOCH #25, step #2248] loss: 0.8869907527883724\n",
      "[EPOCH #25, step #2250] loss: 0.8870925311245742\n",
      "[EPOCH #25, step #2252] loss: 0.8873684093574392\n",
      "[EPOCH #25, step #2254] loss: 0.8874379883055676\n",
      "[EPOCH #25, step #2256] loss: 0.8871903696258775\n",
      "[EPOCH #25, step #2258] loss: 0.8873773611663136\n",
      "[EPOCH #25, step #2260] loss: 0.8871618404898798\n",
      "[EPOCH #25, step #2262] loss: 0.8870811866175744\n",
      "[EPOCH #25, step #2264] loss: 0.8871314617971711\n",
      "[EPOCH #25, step #2266] loss: 0.8871300270970719\n",
      "[EPOCH #25, step #2268] loss: 0.8872099454941966\n",
      "[EPOCH #25, step #2270] loss: 0.8870663763746087\n",
      "[EPOCH #25, step #2272] loss: 0.8871325372574458\n",
      "[EPOCH #25, step #2274] loss: 0.8872012326874575\n",
      "[EPOCH #25, step #2276] loss: 0.8871203869986963\n",
      "[EPOCH #25, step #2278] loss: 0.8869954574233663\n",
      "[EPOCH #25, step #2280] loss: 0.8870201162971043\n",
      "[EPOCH #25, step #2282] loss: 0.886904709716664\n",
      "[EPOCH #25, step #2284] loss: 0.8869842959050277\n",
      "[EPOCH #25, step #2286] loss: 0.8869135336658034\n",
      "[EPOCH #25, step #2288] loss: 0.886954926139874\n",
      "[EPOCH #25, step #2290] loss: 0.8870560838139666\n",
      "[EPOCH #25, step #2292] loss: 0.8872325306915062\n",
      "[EPOCH #25, step #2294] loss: 0.8870970610569765\n",
      "[EPOCH #25, step #2296] loss: 0.8870464846602096\n",
      "[EPOCH #25, step #2298] loss: 0.886953411347558\n",
      "[EPOCH #25, step #2300] loss: 0.8869643898204015\n",
      "[EPOCH #25, step #2302] loss: 0.8871910596251021\n",
      "[EPOCH #25, step #2304] loss: 0.8871462013483564\n",
      "[EPOCH #25, step #2306] loss: 0.8873824186923445\n",
      "[EPOCH #25, step #2308] loss: 0.8874152188772967\n",
      "[EPOCH #25, step #2310] loss: 0.8871892746755541\n",
      "[EPOCH #25, step #2312] loss: 0.8870121652282166\n",
      "[EPOCH #25, step #2314] loss: 0.8871996080772409\n",
      "[EPOCH #25, step #2316] loss: 0.8872347328623771\n",
      "[EPOCH #25, step #2318] loss: 0.8873680219947392\n",
      "[EPOCH #25, step #2320] loss: 0.8872016503065119\n",
      "[EPOCH #25, step #2322] loss: 0.8872165974362678\n",
      "[EPOCH #25, step #2324] loss: 0.8872046304646358\n",
      "[EPOCH #25, step #2326] loss: 0.8872851529728972\n",
      "[EPOCH #25, step #2328] loss: 0.8873483485779368\n",
      "[EPOCH #25, step #2330] loss: 0.8871315567215232\n",
      "[EPOCH #25, step #2332] loss: 0.887022001889965\n",
      "[EPOCH #25, step #2334] loss: 0.8868402342597218\n",
      "[EPOCH #25, step #2336] loss: 0.8865977895147636\n",
      "[EPOCH #25, step #2338] loss: 0.886692325762573\n",
      "[EPOCH #25, step #2340] loss: 0.8866979571068099\n",
      "[EPOCH #25, step #2342] loss: 0.8866329821851383\n",
      "[EPOCH #25, step #2344] loss: 0.886935406186179\n",
      "[EPOCH #25, step #2346] loss: 0.8869384628155915\n",
      "[EPOCH #25, step #2348] loss: 0.8868818609269947\n",
      "[EPOCH #25, step #2350] loss: 0.8869594387149162\n",
      "[EPOCH #25, step #2352] loss: 0.8869443515413019\n",
      "[EPOCH #25, step #2354] loss: 0.8871942347148928\n",
      "[EPOCH #25, step #2356] loss: 0.8874391778753529\n",
      "[EPOCH #25, step #2358] loss: 0.8874213467744914\n",
      "[EPOCH #25, step #2360] loss: 0.8871504554098211\n",
      "[EPOCH #25, step #2362] loss: 0.8872351573777815\n",
      "[EPOCH #25, step #2364] loss: 0.8871883304376179\n",
      "[EPOCH #25, step #2366] loss: 0.8873486125272791\n",
      "[EPOCH #25, step #2368] loss: 0.8875831546990768\n",
      "[EPOCH #25, step #2370] loss: 0.8875940996149531\n",
      "[EPOCH #25, step #2372] loss: 0.8875130436312937\n",
      "[EPOCH #25, step #2374] loss: 0.8876382168217709\n",
      "[EPOCH #25, step #2376] loss: 0.8876178501582116\n",
      "[EPOCH #25, step #2378] loss: 0.8875160021108457\n",
      "[EPOCH #25, step #2380] loss: 0.8874446586969769\n",
      "[EPOCH #25, step #2382] loss: 0.8873509734406273\n",
      "[EPOCH #25, step #2384] loss: 0.8872750015128833\n",
      "[EPOCH #25, step #2386] loss: 0.8875010429339575\n",
      "[EPOCH #25, step #2388] loss: 0.8876328145225161\n",
      "[EPOCH #25, step #2390] loss: 0.8876426611072297\n",
      "[EPOCH #25, step #2392] loss: 0.8875452318153668\n",
      "[EPOCH #25, step #2394] loss: 0.887407397178618\n",
      "[EPOCH #25, step #2396] loss: 0.8872714777464263\n",
      "[EPOCH #25, step #2398] loss: 0.8872637883133071\n",
      "[EPOCH #25, step #2400] loss: 0.8873481502735531\n",
      "[EPOCH #25, step #2402] loss: 0.8872210667920123\n",
      "[EPOCH #25, step #2404] loss: 0.8872667999624463\n",
      "[EPOCH #25, step #2406] loss: 0.8871463284880777\n",
      "[EPOCH #25, step #2408] loss: 0.887138608804428\n",
      "[EPOCH #25, step #2410] loss: 0.8872944036740478\n",
      "[EPOCH #25, step #2412] loss: 0.8871694789652107\n",
      "[EPOCH #25, step #2414] loss: 0.8870570644088414\n",
      "[EPOCH #25, step #2416] loss: 0.8869652562660277\n",
      "[EPOCH #25, step #2418] loss: 0.8868912196740871\n",
      "[EPOCH #25, step #2420] loss: 0.8868475524613996\n",
      "[EPOCH #25, step #2422] loss: 0.8870446731175364\n",
      "[EPOCH #25, step #2424] loss: 0.8871149866113958\n",
      "[EPOCH #25, step #2426] loss: 0.8870569340083448\n",
      "[EPOCH #25, step #2428] loss: 0.886914868912318\n",
      "[EPOCH #25, step #2430] loss: 0.8869571456542382\n",
      "[EPOCH #25, step #2432] loss: 0.8869665445881619\n",
      "[EPOCH #25, step #2434] loss: 0.8870885412795833\n",
      "[EPOCH #25, step #2436] loss: 0.8868222144915033\n",
      "[EPOCH #25, step #2438] loss: 0.8868908925396637\n",
      "[EPOCH #25, step #2440] loss: 0.8869302059382212\n",
      "[EPOCH #25, step #2442] loss: 0.8868975013287107\n",
      "[EPOCH #25, step #2444] loss: 0.8868996430028435\n",
      "[EPOCH #25, step #2446] loss: 0.8867989665252801\n",
      "[EPOCH #25, step #2448] loss: 0.8866853029837946\n",
      "[EPOCH #25, step #2450] loss: 0.8867033094787831\n",
      "[EPOCH #25, step #2452] loss: 0.8867676157490653\n",
      "[EPOCH #25, step #2454] loss: 0.8866474424991491\n",
      "[EPOCH #25, step #2456] loss: 0.8865749777503551\n",
      "[EPOCH #25, step #2458] loss: 0.8864792334980091\n",
      "[EPOCH #25, step #2460] loss: 0.8865418713153838\n",
      "[EPOCH #25, step #2462] loss: 0.8864280768782445\n",
      "[EPOCH #25, step #2464] loss: 0.8863617746389904\n",
      "[EPOCH #25, step #2466] loss: 0.886216546052083\n",
      "[EPOCH #25, step #2468] loss: 0.8861946323565888\n",
      "[EPOCH #25, step #2470] loss: 0.886046154013726\n",
      "[EPOCH #25, step #2472] loss: 0.8860770042637702\n",
      "[EPOCH #25, step #2474] loss: 0.8860719073902477\n",
      "[EPOCH #25, step #2476] loss: 0.8858966600476228\n",
      "[EPOCH #25, step #2478] loss: 0.8859452910844526\n",
      "[EPOCH #25, step #2480] loss: 0.886125707184293\n",
      "[EPOCH #25, step #2482] loss: 0.8860758584543337\n",
      "[EPOCH #25, step #2484] loss: 0.8859057860115405\n",
      "[EPOCH #25, step #2486] loss: 0.8859459558643392\n",
      "[EPOCH #25, step #2488] loss: 0.885923942848112\n",
      "[EPOCH #25, step #2490] loss: 0.8859302754002084\n",
      "[EPOCH #25, step #2492] loss: 0.8859809778131638\n",
      "[EPOCH #25, step #2494] loss: 0.8858565362278589\n",
      "[EPOCH #25, step #2496] loss: 0.8858466985514988\n",
      "[EPOCH #25, step #2498] loss: 0.8860272815963086\n",
      "[EPOCH #25, elapsed time: 12631.820[sec]] loss: 0.8860322237491608\n",
      "[EPOCH #26, step #0] loss: 0.6760270595550537\n",
      "[EPOCH #26, step #2] loss: 0.6477089524269104\n",
      "[EPOCH #26, step #4] loss: 0.7327721238136291\n",
      "[EPOCH #26, step #6] loss: 0.8317718505859375\n",
      "[EPOCH #26, step #8] loss: 0.8234241008758545\n",
      "[EPOCH #26, step #10] loss: 0.8712293451482599\n",
      "[EPOCH #26, step #12] loss: 0.8545162035868719\n",
      "[EPOCH #26, step #14] loss: 0.8625394145647685\n",
      "[EPOCH #26, step #16] loss: 0.8546886479153353\n",
      "[EPOCH #26, step #18] loss: 0.8575494540365118\n",
      "[EPOCH #26, step #20] loss: 0.8629168413934254\n",
      "[EPOCH #26, step #22] loss: 0.868537003579347\n",
      "[EPOCH #26, step #24] loss: 0.8634451007843018\n",
      "[EPOCH #26, step #26] loss: 0.8475261551362497\n",
      "[EPOCH #26, step #28] loss: 0.8625962343709223\n",
      "[EPOCH #26, step #30] loss: 0.8600811689130722\n",
      "[EPOCH #26, step #32] loss: 0.8707597761443167\n",
      "[EPOCH #26, step #34] loss: 0.860033825465611\n",
      "[EPOCH #26, step #36] loss: 0.8516911429327887\n",
      "[EPOCH #26, step #38] loss: 0.8437139384257488\n",
      "[EPOCH #26, step #40] loss: 0.8443824554361948\n",
      "[EPOCH #26, step #42] loss: 0.8451163969760718\n",
      "[EPOCH #26, step #44] loss: 0.8334264695644379\n",
      "[EPOCH #26, step #46] loss: 0.8292387108853523\n",
      "[EPOCH #26, step #48] loss: 0.83026451541453\n",
      "[EPOCH #26, step #50] loss: 0.8265934580681371\n",
      "[EPOCH #26, step #52] loss: 0.8240647119171215\n",
      "[EPOCH #26, step #54] loss: 0.8169381493871862\n",
      "[EPOCH #26, step #56] loss: 0.8159370479876535\n",
      "[EPOCH #26, step #58] loss: 0.8145671380778491\n",
      "[EPOCH #26, step #60] loss: 0.8102797196536767\n",
      "[EPOCH #26, step #62] loss: 0.8041490434654175\n",
      "[EPOCH #26, step #64] loss: 0.8029450237751007\n",
      "[EPOCH #26, step #66] loss: 0.7993053175620178\n",
      "[EPOCH #26, step #68] loss: 0.8027849037578141\n",
      "[EPOCH #26, step #70] loss: 0.8069535128667321\n",
      "[EPOCH #26, step #72] loss: 0.8109399802880745\n",
      "[EPOCH #26, step #74] loss: 0.8078577284018199\n",
      "[EPOCH #26, step #76] loss: 0.8110160351573646\n",
      "[EPOCH #26, step #78] loss: 0.8113155987443803\n",
      "[EPOCH #26, step #80] loss: 0.8083960638370042\n",
      "[EPOCH #26, step #82] loss: 0.8144515217786812\n",
      "[EPOCH #26, step #84] loss: 0.8193314064951503\n",
      "[EPOCH #26, step #86] loss: 0.818899429735096\n",
      "[EPOCH #26, step #88] loss: 0.8201295020205251\n",
      "[EPOCH #26, step #90] loss: 0.8197044451813121\n",
      "[EPOCH #26, step #92] loss: 0.8218600516037274\n",
      "[EPOCH #26, step #94] loss: 0.8243015198331131\n",
      "[EPOCH #26, step #96] loss: 0.8221294839972073\n",
      "[EPOCH #26, step #98] loss: 0.825386559421366\n",
      "[EPOCH #26, step #100] loss: 0.8255556104796948\n",
      "[EPOCH #26, step #102] loss: 0.8230308725417239\n",
      "[EPOCH #26, step #104] loss: 0.8273976323150453\n",
      "[EPOCH #26, step #106] loss: 0.8286879856452763\n",
      "[EPOCH #26, step #108] loss: 0.8280896279243154\n",
      "[EPOCH #26, step #110] loss: 0.8267275231915552\n",
      "[EPOCH #26, step #112] loss: 0.8262988262999375\n",
      "[EPOCH #26, step #114] loss: 0.8261151259360107\n",
      "[EPOCH #26, step #116] loss: 0.8279019820893931\n",
      "[EPOCH #26, step #118] loss: 0.8266953167294254\n",
      "[EPOCH #26, step #120] loss: 0.8293552080954402\n",
      "[EPOCH #26, step #122] loss: 0.8262740981772663\n",
      "[EPOCH #26, step #124] loss: 0.8232083389759064\n",
      "[EPOCH #26, step #126] loss: 0.821898670412424\n",
      "[EPOCH #26, step #128] loss: 0.8216353121191956\n",
      "[EPOCH #26, step #130] loss: 0.8198194064711797\n",
      "[EPOCH #26, step #132] loss: 0.8228437028881302\n",
      "[EPOCH #26, step #134] loss: 0.8261799730636455\n",
      "[EPOCH #26, step #136] loss: 0.8252910986869004\n",
      "[EPOCH #26, step #138] loss: 0.8248738168383674\n",
      "[EPOCH #26, step #140] loss: 0.8306783376433325\n",
      "[EPOCH #26, step #142] loss: 0.8324053539679601\n",
      "[EPOCH #26, step #144] loss: 0.8330174168636059\n",
      "[EPOCH #26, step #146] loss: 0.8315698603789011\n",
      "[EPOCH #26, step #148] loss: 0.8320924301675502\n",
      "[EPOCH #26, step #150] loss: 0.827588199582321\n",
      "[EPOCH #26, step #152] loss: 0.8255298233110141\n",
      "[EPOCH #26, step #154] loss: 0.8236354599075932\n",
      "[EPOCH #26, step #156] loss: 0.820916133511598\n",
      "[EPOCH #26, step #158] loss: 0.8240875682365969\n",
      "[EPOCH #26, step #160] loss: 0.8205473902432815\n",
      "[EPOCH #26, step #162] loss: 0.8199101476215878\n",
      "[EPOCH #26, step #164] loss: 0.8214983996116754\n",
      "[EPOCH #26, step #166] loss: 0.8215122560184159\n",
      "[EPOCH #26, step #168] loss: 0.8220575111504842\n",
      "[EPOCH #26, step #170] loss: 0.8209973655597508\n",
      "[EPOCH #26, step #172] loss: 0.8177630258777927\n",
      "[EPOCH #26, step #174] loss: 0.8193813056605203\n",
      "[EPOCH #26, step #176] loss: 0.8185732612165354\n",
      "[EPOCH #26, step #178] loss: 0.8195414697990737\n",
      "[EPOCH #26, step #180] loss: 0.8219241491668132\n",
      "[EPOCH #26, step #182] loss: 0.8214241521931737\n",
      "[EPOCH #26, step #184] loss: 0.8219417834604109\n",
      "[EPOCH #26, step #186] loss: 0.8219840649296256\n",
      "[EPOCH #26, step #188] loss: 0.8238883786415928\n",
      "[EPOCH #26, step #190] loss: 0.8238883341482173\n",
      "[EPOCH #26, step #192] loss: 0.821795666619286\n",
      "[EPOCH #26, step #194] loss: 0.8200216598999805\n",
      "[EPOCH #26, step #196] loss: 0.8208062524722918\n",
      "[EPOCH #26, step #198] loss: 0.8207332617673443\n",
      "[EPOCH #26, step #200] loss: 0.820306979008575\n",
      "[EPOCH #26, step #202] loss: 0.8203890115169469\n",
      "[EPOCH #26, step #204] loss: 0.8201650116501785\n",
      "[EPOCH #26, step #206] loss: 0.8198659926796881\n",
      "[EPOCH #26, step #208] loss: 0.8179489438328447\n",
      "[EPOCH #26, step #210] loss: 0.8188141200214766\n",
      "[EPOCH #26, step #212] loss: 0.8192903925555413\n",
      "[EPOCH #26, step #214] loss: 0.8202094205590181\n",
      "[EPOCH #26, step #216] loss: 0.8199945257006702\n",
      "[EPOCH #26, step #218] loss: 0.8207638231042313\n",
      "[EPOCH #26, step #220] loss: 0.8200884561193474\n",
      "[EPOCH #26, step #222] loss: 0.8194899711373675\n",
      "[EPOCH #26, step #224] loss: 0.8192697988616096\n",
      "[EPOCH #26, step #226] loss: 0.8180363354178777\n",
      "[EPOCH #26, step #228] loss: 0.8191183305723698\n",
      "[EPOCH #26, step #230] loss: 0.8173312121655518\n",
      "[EPOCH #26, step #232] loss: 0.8174750014436092\n",
      "[EPOCH #26, step #234] loss: 0.8165632850312172\n",
      "[EPOCH #26, step #236] loss: 0.8174157762577765\n",
      "[EPOCH #26, step #238] loss: 0.8215277076515692\n",
      "[EPOCH #26, step #240] loss: 0.8227322352625027\n",
      "[EPOCH #26, step #242] loss: 0.8226240528709113\n",
      "[EPOCH #26, step #244] loss: 0.823020091470407\n",
      "[EPOCH #26, step #246] loss: 0.8258455722679493\n",
      "[EPOCH #26, step #248] loss: 0.825058888359721\n",
      "[EPOCH #26, step #250] loss: 0.8242810768672669\n",
      "[EPOCH #26, step #252] loss: 0.824642291064319\n",
      "[EPOCH #26, step #254] loss: 0.8237397286237454\n",
      "[EPOCH #26, step #256] loss: 0.8254315033265125\n",
      "[EPOCH #26, step #258] loss: 0.8246208108299947\n",
      "[EPOCH #26, step #260] loss: 0.8251665185466124\n",
      "[EPOCH #26, step #262] loss: 0.8243701395653047\n",
      "[EPOCH #26, step #264] loss: 0.8257251461721816\n",
      "[EPOCH #26, step #266] loss: 0.825531856732422\n",
      "[EPOCH #26, step #268] loss: 0.8238074995549638\n",
      "[EPOCH #26, step #270] loss: 0.8243386515612092\n",
      "[EPOCH #26, step #272] loss: 0.8231390464655209\n",
      "[EPOCH #26, step #274] loss: 0.8218842706897042\n",
      "[EPOCH #26, step #276] loss: 0.8207496362687878\n",
      "[EPOCH #26, step #278] loss: 0.8224058301859004\n",
      "[EPOCH #26, step #280] loss: 0.8225534527539359\n",
      "[EPOCH #26, step #282] loss: 0.8218145786452209\n",
      "[EPOCH #26, step #284] loss: 0.8227131719129127\n",
      "[EPOCH #26, step #286] loss: 0.8213514676285122\n",
      "[EPOCH #26, step #288] loss: 0.8221125981180726\n",
      "[EPOCH #26, step #290] loss: 0.8214052894066289\n",
      "[EPOCH #26, step #292] loss: 0.8206932228376435\n",
      "[EPOCH #26, step #294] loss: 0.8198169214240575\n",
      "[EPOCH #26, step #296] loss: 0.8202792649919336\n",
      "[EPOCH #26, step #298] loss: 0.8207262803280234\n",
      "[EPOCH #26, step #300] loss: 0.82211766934078\n",
      "[EPOCH #26, step #302] loss: 0.8223069321007619\n",
      "[EPOCH #26, step #304] loss: 0.821007417655382\n",
      "[EPOCH #26, step #306] loss: 0.8207166187149694\n",
      "[EPOCH #26, step #308] loss: 0.8195413864160432\n",
      "[EPOCH #26, step #310] loss: 0.8209035365911159\n",
      "[EPOCH #26, step #312] loss: 0.8219861801439962\n",
      "[EPOCH #26, step #314] loss: 0.8211111801011222\n",
      "[EPOCH #26, step #316] loss: 0.8217817994322311\n",
      "[EPOCH #26, step #318] loss: 0.8229207671174436\n",
      "[EPOCH #26, step #320] loss: 0.8223769622985447\n",
      "[EPOCH #26, step #322] loss: 0.8219231604238043\n",
      "[EPOCH #26, step #324] loss: 0.8208677788881155\n",
      "[EPOCH #26, step #326] loss: 0.8210810699958685\n",
      "[EPOCH #26, step #328] loss: 0.82121675735549\n",
      "[EPOCH #26, step #330] loss: 0.8206283191719804\n",
      "[EPOCH #26, step #332] loss: 0.821595051356622\n",
      "[EPOCH #26, step #334] loss: 0.821632143365803\n",
      "[EPOCH #26, step #336] loss: 0.8209042790558643\n",
      "[EPOCH #26, step #338] loss: 0.8200943792639932\n",
      "[EPOCH #26, step #340] loss: 0.819971561868869\n",
      "[EPOCH #26, step #342] loss: 0.8183882937660718\n",
      "[EPOCH #26, step #344] loss: 0.8179438692072164\n",
      "[EPOCH #26, step #346] loss: 0.8190085864719808\n",
      "[EPOCH #26, step #348] loss: 0.819124962077783\n",
      "[EPOCH #26, step #350] loss: 0.8191091634778895\n",
      "[EPOCH #26, step #352] loss: 0.8200874987979111\n",
      "[EPOCH #26, step #354] loss: 0.819570676457714\n",
      "[EPOCH #26, step #356] loss: 0.8193508619520845\n",
      "[EPOCH #26, step #358] loss: 0.8194322296337829\n",
      "[EPOCH #26, step #360] loss: 0.820977681809185\n",
      "[EPOCH #26, step #362] loss: 0.8207475256492941\n",
      "[EPOCH #26, step #364] loss: 0.8207790729934222\n",
      "[EPOCH #26, step #366] loss: 0.8198118286983843\n",
      "[EPOCH #26, step #368] loss: 0.8190655022617278\n",
      "[EPOCH #26, step #370] loss: 0.8198658487385495\n",
      "[EPOCH #26, step #372] loss: 0.8202722520834639\n",
      "[EPOCH #26, step #374] loss: 0.820281938791275\n",
      "[EPOCH #26, step #376] loss: 0.8189448642319647\n",
      "[EPOCH #26, step #378] loss: 0.8192977904487097\n",
      "[EPOCH #26, step #380] loss: 0.8191632826340793\n",
      "[EPOCH #26, step #382] loss: 0.8192278080602851\n",
      "[EPOCH #26, step #384] loss: 0.8191484724546407\n",
      "[EPOCH #26, step #386] loss: 0.8178734186391806\n",
      "[EPOCH #26, step #388] loss: 0.8187714522479432\n",
      "[EPOCH #26, step #390] loss: 0.8172240210768512\n",
      "[EPOCH #26, step #392] loss: 0.8169898403661549\n",
      "[EPOCH #26, step #394] loss: 0.817429767303829\n",
      "[EPOCH #26, step #396] loss: 0.8183399691839963\n",
      "[EPOCH #26, step #398] loss: 0.8179226808231277\n",
      "[EPOCH #26, step #400] loss: 0.8176751463044611\n",
      "[EPOCH #26, step #402] loss: 0.8175003064921121\n",
      "[EPOCH #26, step #404] loss: 0.817298216657874\n",
      "[EPOCH #26, step #406] loss: 0.8176315171273393\n",
      "[EPOCH #26, step #408] loss: 0.8174123245958594\n",
      "[EPOCH #26, step #410] loss: 0.8181733781258845\n",
      "[EPOCH #26, step #412] loss: 0.8183352227794056\n",
      "[EPOCH #26, step #414] loss: 0.8179101970540472\n",
      "[EPOCH #26, step #416] loss: 0.8175651852032549\n",
      "[EPOCH #26, step #418] loss: 0.8191013011130057\n",
      "[EPOCH #26, step #420] loss: 0.8185167791866067\n",
      "[EPOCH #26, step #422] loss: 0.8187084980749351\n",
      "[EPOCH #26, step #424] loss: 0.819064349637312\n",
      "[EPOCH #26, step #426] loss: 0.8181437279776053\n",
      "[EPOCH #26, step #428] loss: 0.8195689638038893\n",
      "[EPOCH #26, step #430] loss: 0.8196198963095583\n",
      "[EPOCH #26, step #432] loss: 0.8213253346794472\n",
      "[EPOCH #26, step #434] loss: 0.8222619824710934\n",
      "[EPOCH #26, step #436] loss: 0.8214407093328524\n",
      "[EPOCH #26, step #438] loss: 0.820909817628817\n",
      "[EPOCH #26, step #440] loss: 0.8207858292018475\n",
      "[EPOCH #26, step #442] loss: 0.8216577218698325\n",
      "[EPOCH #26, step #444] loss: 0.822415020827497\n",
      "[EPOCH #26, step #446] loss: 0.8236970032754893\n",
      "[EPOCH #26, step #448] loss: 0.8233061633954335\n",
      "[EPOCH #26, step #450] loss: 0.8235980115682217\n",
      "[EPOCH #26, step #452] loss: 0.8234519584157872\n",
      "[EPOCH #26, step #454] loss: 0.8231407865718171\n",
      "[EPOCH #26, step #456] loss: 0.8236869154273811\n",
      "[EPOCH #26, step #458] loss: 0.8239105461339805\n",
      "[EPOCH #26, step #460] loss: 0.8236327143527422\n",
      "[EPOCH #26, step #462] loss: 0.8241582532809568\n",
      "[EPOCH #26, step #464] loss: 0.8239622276957317\n",
      "[EPOCH #26, step #466] loss: 0.8234722531964999\n",
      "[EPOCH #26, step #468] loss: 0.8229961885190976\n",
      "[EPOCH #26, step #470] loss: 0.8228358577644242\n",
      "[EPOCH #26, step #472] loss: 0.8229656764493181\n",
      "[EPOCH #26, step #474] loss: 0.8225061628065611\n",
      "[EPOCH #26, step #476] loss: 0.8234964412338329\n",
      "[EPOCH #26, step #478] loss: 0.8234947808475733\n",
      "[EPOCH #26, step #480] loss: 0.8232395686751344\n",
      "[EPOCH #26, step #482] loss: 0.8231108568099715\n",
      "[EPOCH #26, step #484] loss: 0.823155384887125\n",
      "[EPOCH #26, step #486] loss: 0.8231086030265878\n",
      "[EPOCH #26, step #488] loss: 0.8234291942694923\n",
      "[EPOCH #26, step #490] loss: 0.8229256726937965\n",
      "[EPOCH #26, step #492] loss: 0.8226365499636706\n",
      "[EPOCH #26, step #494] loss: 0.8218460250984538\n",
      "[EPOCH #26, step #496] loss: 0.822346864751647\n",
      "[EPOCH #26, step #498] loss: 0.8218071227202673\n",
      "[EPOCH #26, step #500] loss: 0.8217162892609061\n",
      "[EPOCH #26, step #502] loss: 0.821160029760649\n",
      "[EPOCH #26, step #504] loss: 0.8228197792378983\n",
      "[EPOCH #26, step #506] loss: 0.823496700097353\n",
      "[EPOCH #26, step #508] loss: 0.8232072616958431\n",
      "[EPOCH #26, step #510] loss: 0.8233433824812596\n",
      "[EPOCH #26, step #512] loss: 0.8228120542409127\n",
      "[EPOCH #26, step #514] loss: 0.8211200435763424\n",
      "[EPOCH #26, step #516] loss: 0.8201808368560194\n",
      "[EPOCH #26, step #518] loss: 0.8198591262274395\n",
      "[EPOCH #26, step #520] loss: 0.8206195528699431\n",
      "[EPOCH #26, step #522] loss: 0.8205753433202922\n",
      "[EPOCH #26, step #524] loss: 0.8211421795686086\n",
      "[EPOCH #26, step #526] loss: 0.8215011754682892\n",
      "[EPOCH #26, step #528] loss: 0.8220214171648477\n",
      "[EPOCH #26, step #530] loss: 0.8228353904577748\n",
      "[EPOCH #26, step #532] loss: 0.8229618927439427\n",
      "[EPOCH #26, step #534] loss: 0.822362742969923\n",
      "[EPOCH #26, step #536] loss: 0.8227047991819222\n",
      "[EPOCH #26, step #538] loss: 0.8232827988869627\n",
      "[EPOCH #26, step #540] loss: 0.8228675118766298\n",
      "[EPOCH #26, step #542] loss: 0.8234328877311166\n",
      "[EPOCH #26, step #544] loss: 0.8230703719712179\n",
      "[EPOCH #26, step #546] loss: 0.8225259050263783\n",
      "[EPOCH #26, step #548] loss: 0.82234406042403\n",
      "[EPOCH #26, step #550] loss: 0.822535041726436\n",
      "[EPOCH #26, step #552] loss: 0.8231224404213442\n",
      "[EPOCH #26, step #554] loss: 0.8230847973544319\n",
      "[EPOCH #26, step #556] loss: 0.8234242955807938\n",
      "[EPOCH #26, step #558] loss: 0.8230071186699466\n",
      "[EPOCH #26, step #560] loss: 0.8237194982548236\n",
      "[EPOCH #26, step #562] loss: 0.8246625400881149\n",
      "[EPOCH #26, step #564] loss: 0.824206157437468\n",
      "[EPOCH #26, step #566] loss: 0.8240426605866279\n",
      "[EPOCH #26, step #568] loss: 0.823240234059902\n",
      "[EPOCH #26, step #570] loss: 0.8232722896201807\n",
      "[EPOCH #26, step #572] loss: 0.8233656044821881\n",
      "[EPOCH #26, step #574] loss: 0.82214598370635\n",
      "[EPOCH #26, step #576] loss: 0.8222158324470553\n",
      "[EPOCH #26, step #578] loss: 0.8215885095954559\n",
      "[EPOCH #26, step #580] loss: 0.8209153509181051\n",
      "[EPOCH #26, step #582] loss: 0.8212272865285596\n",
      "[EPOCH #26, step #584] loss: 0.8208279993798998\n",
      "[EPOCH #26, step #586] loss: 0.820874596373186\n",
      "[EPOCH #26, step #588] loss: 0.8207453913316257\n",
      "[EPOCH #26, step #590] loss: 0.8204608135013612\n",
      "[EPOCH #26, step #592] loss: 0.8207481520573968\n",
      "[EPOCH #26, step #594] loss: 0.8210923009559887\n",
      "[EPOCH #26, step #596] loss: 0.821773497802728\n",
      "[EPOCH #26, step #598] loss: 0.8225541667070532\n",
      "[EPOCH #26, step #600] loss: 0.8228635319854177\n",
      "[EPOCH #26, step #602] loss: 0.8226206264092555\n",
      "[EPOCH #26, step #604] loss: 0.8222811487095415\n",
      "[EPOCH #26, step #606] loss: 0.821978420166443\n",
      "[EPOCH #26, step #608] loss: 0.821288721119046\n",
      "[EPOCH #26, step #610] loss: 0.82153061602978\n",
      "[EPOCH #26, step #612] loss: 0.8211307251433952\n",
      "[EPOCH #26, step #614] loss: 0.8204278831559468\n",
      "[EPOCH #26, step #616] loss: 0.8200640046615848\n",
      "[EPOCH #26, step #618] loss: 0.8209113735759779\n",
      "[EPOCH #26, step #620] loss: 0.8215313740974464\n",
      "[EPOCH #26, step #622] loss: 0.8220404927076153\n",
      "[EPOCH #26, step #624] loss: 0.821692629623413\n",
      "[EPOCH #26, step #626] loss: 0.823197332485631\n",
      "[EPOCH #26, step #628] loss: 0.8244047845300696\n",
      "[EPOCH #26, step #630] loss: 0.8240254285218409\n",
      "[EPOCH #26, step #632] loss: 0.8237278387068195\n",
      "[EPOCH #26, step #634] loss: 0.824447441382671\n",
      "[EPOCH #26, step #636] loss: 0.8240640866138872\n",
      "[EPOCH #26, step #638] loss: 0.8237803435661424\n",
      "[EPOCH #26, step #640] loss: 0.8236013401689098\n",
      "[EPOCH #26, step #642] loss: 0.8232038481795398\n",
      "[EPOCH #26, step #644] loss: 0.8229843902033429\n",
      "[EPOCH #26, step #646] loss: 0.8232354096135548\n",
      "[EPOCH #26, step #648] loss: 0.8228991329210749\n",
      "[EPOCH #26, step #650] loss: 0.8230172397537349\n",
      "[EPOCH #26, step #652] loss: 0.822468423186181\n",
      "[EPOCH #26, step #654] loss: 0.822831520324445\n",
      "[EPOCH #26, step #656] loss: 0.8227552694454222\n",
      "[EPOCH #26, step #658] loss: 0.8225353782564085\n",
      "[EPOCH #26, step #660] loss: 0.8224632456876146\n",
      "[EPOCH #26, step #662] loss: 0.8227658067713316\n",
      "[EPOCH #26, step #664] loss: 0.8224317700343025\n",
      "[EPOCH #26, step #666] loss: 0.8217735635018957\n",
      "[EPOCH #26, step #668] loss: 0.8216163173473826\n",
      "[EPOCH #26, step #670] loss: 0.821117834300469\n",
      "[EPOCH #26, step #672] loss: 0.8216050749459203\n",
      "[EPOCH #26, step #674] loss: 0.8223043203795398\n",
      "[EPOCH #26, step #676] loss: 0.8219948487144453\n",
      "[EPOCH #26, step #678] loss: 0.8224731102168823\n",
      "[EPOCH #26, step #680] loss: 0.8226280818514187\n",
      "[EPOCH #26, step #682] loss: 0.8217564315083784\n",
      "[EPOCH #26, step #684] loss: 0.8214185093006078\n",
      "[EPOCH #26, step #686] loss: 0.8218716114455783\n",
      "[EPOCH #26, step #688] loss: 0.8220137391017726\n",
      "[EPOCH #26, step #690] loss: 0.8214151989102536\n",
      "[EPOCH #26, step #692] loss: 0.8211779130399657\n",
      "[EPOCH #26, step #694] loss: 0.8213207623512625\n",
      "[EPOCH #26, step #696] loss: 0.8216366576755064\n",
      "[EPOCH #26, step #698] loss: 0.8225740029320696\n",
      "[EPOCH #26, step #700] loss: 0.8230883545865346\n",
      "[EPOCH #26, step #702] loss: 0.8231934018613265\n",
      "[EPOCH #26, step #704] loss: 0.8231231908848945\n",
      "[EPOCH #26, step #706] loss: 0.8233748117548741\n",
      "[EPOCH #26, step #708] loss: 0.8243952467932519\n",
      "[EPOCH #26, step #710] loss: 0.8245611014329264\n",
      "[EPOCH #26, step #712] loss: 0.8240266744501962\n",
      "[EPOCH #26, step #714] loss: 0.8244568253313744\n",
      "[EPOCH #26, step #716] loss: 0.8244827618741922\n",
      "[EPOCH #26, step #718] loss: 0.8244973742331848\n",
      "[EPOCH #26, step #720] loss: 0.8246838627757709\n",
      "[EPOCH #26, step #722] loss: 0.8247790700584692\n",
      "[EPOCH #26, step #724] loss: 0.8253623858402516\n",
      "[EPOCH #26, step #726] loss: 0.8253569780468449\n",
      "[EPOCH #26, step #728] loss: 0.8258889374337243\n",
      "[EPOCH #26, step #730] loss: 0.825933379326245\n",
      "[EPOCH #26, step #732] loss: 0.8261214726862446\n",
      "[EPOCH #26, step #734] loss: 0.8262162613625429\n",
      "[EPOCH #26, step #736] loss: 0.8265203146549546\n",
      "[EPOCH #26, step #738] loss: 0.8260884927396684\n",
      "[EPOCH #26, step #740] loss: 0.8259856300717584\n",
      "[EPOCH #26, step #742] loss: 0.8256565883535074\n",
      "[EPOCH #26, step #744] loss: 0.8260240100374158\n",
      "[EPOCH #26, step #746] loss: 0.8264816658723466\n",
      "[EPOCH #26, step #748] loss: 0.8260485284796385\n",
      "[EPOCH #26, step #750] loss: 0.8259523412517796\n",
      "[EPOCH #26, step #752] loss: 0.8264383885806617\n",
      "[EPOCH #26, step #754] loss: 0.8268970426344714\n",
      "[EPOCH #26, step #756] loss: 0.8270302577881706\n",
      "[EPOCH #26, step #758] loss: 0.8271403713188624\n",
      "[EPOCH #26, step #760] loss: 0.8269027949319406\n",
      "[EPOCH #26, step #762] loss: 0.8267662804842307\n",
      "[EPOCH #26, step #764] loss: 0.8271176585964128\n",
      "[EPOCH #26, step #766] loss: 0.827162615556605\n",
      "[EPOCH #26, step #768] loss: 0.8271824498945467\n",
      "[EPOCH #26, step #770] loss: 0.8274415231245811\n",
      "[EPOCH #26, step #772] loss: 0.8271508411170594\n",
      "[EPOCH #26, step #774] loss: 0.826738107127528\n",
      "[EPOCH #26, step #776] loss: 0.8268050216186308\n",
      "[EPOCH #26, step #778] loss: 0.8270004563827417\n",
      "[EPOCH #26, step #780] loss: 0.8271495274789202\n",
      "[EPOCH #26, step #782] loss: 0.8271234985512336\n",
      "[EPOCH #26, step #784] loss: 0.8278707765469885\n",
      "[EPOCH #26, step #786] loss: 0.8277274629969761\n",
      "[EPOCH #26, step #788] loss: 0.8276459854214212\n",
      "[EPOCH #26, step #790] loss: 0.8274118476058681\n",
      "[EPOCH #26, step #792] loss: 0.8275277334233702\n",
      "[EPOCH #26, step #794] loss: 0.8275176665318087\n",
      "[EPOCH #26, step #796] loss: 0.827607296117426\n",
      "[EPOCH #26, step #798] loss: 0.8277685570627339\n",
      "[EPOCH #26, step #800] loss: 0.8281484476933616\n",
      "[EPOCH #26, step #802] loss: 0.8280831758735486\n",
      "[EPOCH #26, step #804] loss: 0.8281189865207079\n",
      "[EPOCH #26, step #806] loss: 0.8281250110789302\n",
      "[EPOCH #26, step #808] loss: 0.8281455426781964\n",
      "[EPOCH #26, step #810] loss: 0.8281773665389356\n",
      "[EPOCH #26, step #812] loss: 0.8284507512606378\n",
      "[EPOCH #26, step #814] loss: 0.8281892662399386\n",
      "[EPOCH #26, step #816] loss: 0.8287228610699442\n",
      "[EPOCH #26, step #818] loss: 0.8284334399906852\n",
      "[EPOCH #26, step #820] loss: 0.8276084639340748\n",
      "[EPOCH #26, step #822] loss: 0.8276860659278902\n",
      "[EPOCH #26, step #824] loss: 0.828250790906675\n",
      "[EPOCH #26, step #826] loss: 0.8282191091393906\n",
      "[EPOCH #26, step #828] loss: 0.8276200686346636\n",
      "[EPOCH #26, step #830] loss: 0.8276697569375434\n",
      "[EPOCH #26, step #832] loss: 0.8272831697567027\n",
      "[EPOCH #26, step #834] loss: 0.827223569832876\n",
      "[EPOCH #26, step #836] loss: 0.8274319589209244\n",
      "[EPOCH #26, step #838] loss: 0.8276616749803273\n",
      "[EPOCH #26, step #840] loss: 0.8276305184494727\n",
      "[EPOCH #26, step #842] loss: 0.8276872054396434\n",
      "[EPOCH #26, step #844] loss: 0.8277699953000222\n",
      "[EPOCH #26, step #846] loss: 0.827942557852834\n",
      "[EPOCH #26, step #848] loss: 0.8274699715618812\n",
      "[EPOCH #26, step #850] loss: 0.827879981834936\n",
      "[EPOCH #26, step #852] loss: 0.8286461150939691\n",
      "[EPOCH #26, step #854] loss: 0.8289695748111658\n",
      "[EPOCH #26, step #856] loss: 0.8287574913843927\n",
      "[EPOCH #26, step #858] loss: 0.8286969564568871\n",
      "[EPOCH #26, step #860] loss: 0.8284039502221394\n",
      "[EPOCH #26, step #862] loss: 0.8280810856045605\n",
      "[EPOCH #26, step #864] loss: 0.8278126446842459\n",
      "[EPOCH #26, step #866] loss: 0.8273447284855232\n",
      "[EPOCH #26, step #868] loss: 0.8277332412702716\n",
      "[EPOCH #26, step #870] loss: 0.827938941911496\n",
      "[EPOCH #26, step #872] loss: 0.8286601136025694\n",
      "[EPOCH #26, step #874] loss: 0.828301701102938\n",
      "[EPOCH #26, step #876] loss: 0.8289666611153288\n",
      "[EPOCH #26, step #878] loss: 0.8289733511799432\n",
      "[EPOCH #26, step #880] loss: 0.8290612904965945\n",
      "[EPOCH #26, step #882] loss: 0.8286477974357583\n",
      "[EPOCH #26, step #884] loss: 0.8281347980270278\n",
      "[EPOCH #26, step #886] loss: 0.8281891365129219\n",
      "[EPOCH #26, step #888] loss: 0.8284934376637767\n",
      "[EPOCH #26, step #890] loss: 0.8282977694145892\n",
      "[EPOCH #26, step #892] loss: 0.8288340654979227\n",
      "[EPOCH #26, step #894] loss: 0.8288792651791812\n",
      "[EPOCH #26, step #896] loss: 0.8286268834352759\n",
      "[EPOCH #26, step #898] loss: 0.8285440710084192\n",
      "[EPOCH #26, step #900] loss: 0.8284044583616458\n",
      "[EPOCH #26, step #902] loss: 0.8282560941454844\n",
      "[EPOCH #26, step #904] loss: 0.8276018727550191\n",
      "[EPOCH #26, step #906] loss: 0.8275418209924456\n",
      "[EPOCH #26, step #908] loss: 0.8280962504962883\n",
      "[EPOCH #26, step #910] loss: 0.8280645491132098\n",
      "[EPOCH #26, step #912] loss: 0.8280253393365415\n",
      "[EPOCH #26, step #914] loss: 0.8280846149543596\n",
      "[EPOCH #26, step #916] loss: 0.827769866166484\n",
      "[EPOCH #26, step #918] loss: 0.8274294643848323\n",
      "[EPOCH #26, step #920] loss: 0.8276852514275251\n",
      "[EPOCH #26, step #922] loss: 0.8275338145919379\n",
      "[EPOCH #26, step #924] loss: 0.8274142506960276\n",
      "[EPOCH #26, step #926] loss: 0.8272441545865039\n",
      "[EPOCH #26, step #928] loss: 0.8270922409063777\n",
      "[EPOCH #26, step #930] loss: 0.82663091700264\n",
      "[EPOCH #26, step #932] loss: 0.8265180086910661\n",
      "[EPOCH #26, step #934] loss: 0.8266118629730959\n",
      "[EPOCH #26, step #936] loss: 0.8264657080873227\n",
      "[EPOCH #26, step #938] loss: 0.8261554553485907\n",
      "[EPOCH #26, step #940] loss: 0.8263361106263464\n",
      "[EPOCH #26, step #942] loss: 0.8259260893373702\n",
      "[EPOCH #26, step #944] loss: 0.8259794552490194\n",
      "[EPOCH #26, step #946] loss: 0.8262951428182778\n",
      "[EPOCH #26, step #948] loss: 0.826672173526189\n",
      "[EPOCH #26, step #950] loss: 0.8271345481135491\n",
      "[EPOCH #26, step #952] loss: 0.8268765678936136\n",
      "[EPOCH #26, step #954] loss: 0.8269834869819161\n",
      "[EPOCH #26, step #956] loss: 0.8265136878318547\n",
      "[EPOCH #26, step #958] loss: 0.8264042948905818\n",
      "[EPOCH #26, step #960] loss: 0.826195567443145\n",
      "[EPOCH #26, step #962] loss: 0.8263109270038387\n",
      "[EPOCH #26, step #964] loss: 0.8268858526654812\n",
      "[EPOCH #26, step #966] loss: 0.8266150818862245\n",
      "[EPOCH #26, step #968] loss: 0.8265561882187339\n",
      "[EPOCH #26, step #970] loss: 0.8270485435529055\n",
      "[EPOCH #26, step #972] loss: 0.8269135339409572\n",
      "[EPOCH #26, step #974] loss: 0.8270418366407737\n",
      "[EPOCH #26, step #976] loss: 0.8264939960706197\n",
      "[EPOCH #26, step #978] loss: 0.8263565870544153\n",
      "[EPOCH #26, step #980] loss: 0.8260031915464411\n",
      "[EPOCH #26, step #982] loss: 0.826525308714757\n",
      "[EPOCH #26, step #984] loss: 0.8264763872938108\n",
      "[EPOCH #26, step #986] loss: 0.8263991395088919\n",
      "[EPOCH #26, step #988] loss: 0.8263308570708013\n",
      "[EPOCH #26, step #990] loss: 0.8264182684219449\n",
      "[EPOCH #26, step #992] loss: 0.8267879275696995\n",
      "[EPOCH #26, step #994] loss: 0.8263558619285948\n",
      "[EPOCH #26, step #996] loss: 0.8261478601570952\n",
      "[EPOCH #26, step #998] loss: 0.8258620898227195\n",
      "[EPOCH #26, step #1000] loss: 0.8255207879500432\n",
      "[EPOCH #26, step #1002] loss: 0.8255012745217811\n",
      "[EPOCH #26, step #1004] loss: 0.825467521663922\n",
      "[EPOCH #26, step #1006] loss: 0.825152079096617\n",
      "[EPOCH #26, step #1008] loss: 0.8251119307117727\n",
      "[EPOCH #26, step #1010] loss: 0.8246313653937904\n",
      "[EPOCH #26, step #1012] loss: 0.8249835895938911\n",
      "[EPOCH #26, step #1014] loss: 0.8249923446201926\n",
      "[EPOCH #26, step #1016] loss: 0.8247964400047163\n",
      "[EPOCH #26, step #1018] loss: 0.8250941423894846\n",
      "[EPOCH #26, step #1020] loss: 0.8249212988268266\n",
      "[EPOCH #26, step #1022] loss: 0.8250420202782427\n",
      "[EPOCH #26, step #1024] loss: 0.8253028008705232\n",
      "[EPOCH #26, step #1026] loss: 0.8250897734805928\n",
      "[EPOCH #26, step #1028] loss: 0.8250638826653376\n",
      "[EPOCH #26, step #1030] loss: 0.825235731415559\n",
      "[EPOCH #26, step #1032] loss: 0.8254963948615869\n",
      "[EPOCH #26, step #1034] loss: 0.8254488997125395\n",
      "[EPOCH #26, step #1036] loss: 0.8255144252209218\n",
      "[EPOCH #26, step #1038] loss: 0.8251286391401887\n",
      "[EPOCH #26, step #1040] loss: 0.8256504382512296\n",
      "[EPOCH #26, step #1042] loss: 0.8255052549669863\n",
      "[EPOCH #26, step #1044] loss: 0.8251559890343242\n",
      "[EPOCH #26, step #1046] loss: 0.8250462768924953\n",
      "[EPOCH #26, step #1048] loss: 0.8251630014698204\n",
      "[EPOCH #26, step #1050] loss: 0.8248748802265363\n",
      "[EPOCH #26, step #1052] loss: 0.8250465187308682\n",
      "[EPOCH #26, step #1054] loss: 0.8249252864817307\n",
      "[EPOCH #26, step #1056] loss: 0.8251158746493348\n",
      "[EPOCH #26, step #1058] loss: 0.8251131286983562\n",
      "[EPOCH #26, step #1060] loss: 0.8250983254905021\n",
      "[EPOCH #26, step #1062] loss: 0.8256610391673791\n",
      "[EPOCH #26, step #1064] loss: 0.8262547306891338\n",
      "[EPOCH #26, step #1066] loss: 0.8263240397088195\n",
      "[EPOCH #26, step #1068] loss: 0.8260838146015681\n",
      "[EPOCH #26, step #1070] loss: 0.8259382170845035\n",
      "[EPOCH #26, step #1072] loss: 0.8259080210969699\n",
      "[EPOCH #26, step #1074] loss: 0.826158660872038\n",
      "[EPOCH #26, step #1076] loss: 0.8264938165384415\n",
      "[EPOCH #26, step #1078] loss: 0.8266824023993177\n",
      "[EPOCH #26, step #1080] loss: 0.8267304311462512\n",
      "[EPOCH #26, step #1082] loss: 0.8272684465539972\n",
      "[EPOCH #26, step #1084] loss: 0.8267162259547941\n",
      "[EPOCH #26, step #1086] loss: 0.8264995099155861\n",
      "[EPOCH #26, step #1088] loss: 0.8267720045301211\n",
      "[EPOCH #26, step #1090] loss: 0.8263607298858007\n",
      "[EPOCH #26, step #1092] loss: 0.82584032972581\n",
      "[EPOCH #26, step #1094] loss: 0.8262616609057335\n",
      "[EPOCH #26, step #1096] loss: 0.826295477619145\n",
      "[EPOCH #26, step #1098] loss: 0.8256971167910631\n",
      "[EPOCH #26, step #1100] loss: 0.8255814648454131\n",
      "[EPOCH #26, step #1102] loss: 0.8256245869349482\n",
      "[EPOCH #26, step #1104] loss: 0.8258032223757575\n",
      "[EPOCH #26, step #1106] loss: 0.825640026631394\n",
      "[EPOCH #26, step #1108] loss: 0.8255064297732843\n",
      "[EPOCH #26, step #1110] loss: 0.8251143660661232\n",
      "[EPOCH #26, step #1112] loss: 0.8253623662718973\n",
      "[EPOCH #26, step #1114] loss: 0.8254250119085269\n",
      "[EPOCH #26, step #1116] loss: 0.8257475655956149\n",
      "[EPOCH #26, step #1118] loss: 0.825909926595168\n",
      "[EPOCH #26, step #1120] loss: 0.8258424398093006\n",
      "[EPOCH #26, step #1122] loss: 0.8259994123306852\n",
      "[EPOCH #26, step #1124] loss: 0.8259110810491774\n",
      "[EPOCH #26, step #1126] loss: 0.8255557927708765\n",
      "[EPOCH #26, step #1128] loss: 0.8255251199930933\n",
      "[EPOCH #26, step #1130] loss: 0.825773938212323\n",
      "[EPOCH #26, step #1132] loss: 0.8259089091975186\n",
      "[EPOCH #26, step #1134] loss: 0.8257112277236804\n",
      "[EPOCH #26, step #1136] loss: 0.8260079753325503\n",
      "[EPOCH #26, step #1138] loss: 0.8266580088082063\n",
      "[EPOCH #26, step #1140] loss: 0.8266086972250842\n",
      "[EPOCH #26, step #1142] loss: 0.826833027815047\n",
      "[EPOCH #26, step #1144] loss: 0.8270981820389693\n",
      "[EPOCH #26, step #1146] loss: 0.8268624707315939\n",
      "[EPOCH #26, step #1148] loss: 0.826529923343368\n",
      "[EPOCH #26, step #1150] loss: 0.8267810457846478\n",
      "[EPOCH #26, step #1152] loss: 0.8275744596824166\n",
      "[EPOCH #26, step #1154] loss: 0.8276723938844937\n",
      "[EPOCH #26, step #1156] loss: 0.8277316089065918\n",
      "[EPOCH #26, step #1158] loss: 0.8277646743654691\n",
      "[EPOCH #26, step #1160] loss: 0.8279675161345676\n",
      "[EPOCH #26, step #1162] loss: 0.8280364873843877\n",
      "[EPOCH #26, step #1164] loss: 0.8282765908046853\n",
      "[EPOCH #26, step #1166] loss: 0.8279456390768621\n",
      "[EPOCH #26, step #1168] loss: 0.8281776525456238\n",
      "[EPOCH #26, step #1170] loss: 0.8284162855321378\n",
      "[EPOCH #26, step #1172] loss: 0.8282111639002908\n",
      "[EPOCH #26, step #1174] loss: 0.8281372148178994\n",
      "[EPOCH #26, step #1176] loss: 0.8278415311213358\n",
      "[EPOCH #26, step #1178] loss: 0.8277858555114704\n",
      "[EPOCH #26, step #1180] loss: 0.8275749913774033\n",
      "[EPOCH #26, step #1182] loss: 0.8278809133114093\n",
      "[EPOCH #26, step #1184] loss: 0.8281083048898963\n",
      "[EPOCH #26, step #1186] loss: 0.8275372671950436\n",
      "[EPOCH #26, step #1188] loss: 0.8275319659930502\n",
      "[EPOCH #26, step #1190] loss: 0.8278001135232367\n",
      "[EPOCH #26, step #1192] loss: 0.8277289156691926\n",
      "[EPOCH #26, step #1194] loss: 0.8277000112264227\n",
      "[EPOCH #26, step #1196] loss: 0.8274459960118073\n",
      "[EPOCH #26, step #1198] loss: 0.8274030866624913\n",
      "[EPOCH #26, step #1200] loss: 0.8270920339621275\n",
      "[EPOCH #26, step #1202] loss: 0.8272113752731758\n",
      "[EPOCH #26, step #1204] loss: 0.8267028229117888\n",
      "[EPOCH #26, step #1206] loss: 0.8265474591999876\n",
      "[EPOCH #26, step #1208] loss: 0.8269223140181343\n",
      "[EPOCH #26, step #1210] loss: 0.8270858076611006\n",
      "[EPOCH #26, step #1212] loss: 0.8267637144064766\n",
      "[EPOCH #26, step #1214] loss: 0.8263756780467406\n",
      "[EPOCH #26, step #1216] loss: 0.8265149573272824\n",
      "[EPOCH #26, step #1218] loss: 0.826356931041752\n",
      "[EPOCH #26, step #1220] loss: 0.8263573936513953\n",
      "[EPOCH #26, step #1222] loss: 0.8260175760223157\n",
      "[EPOCH #26, step #1224] loss: 0.8258069934650343\n",
      "[EPOCH #26, step #1226] loss: 0.8261518867013895\n",
      "[EPOCH #26, step #1228] loss: 0.8258704441751863\n",
      "[EPOCH #26, step #1230] loss: 0.8257917322151841\n",
      "[EPOCH #26, step #1232] loss: 0.8259793010457975\n",
      "[EPOCH #26, step #1234] loss: 0.8259345730789277\n",
      "[EPOCH #26, step #1236] loss: 0.8264268888710194\n",
      "[EPOCH #26, step #1238] loss: 0.82672964853082\n",
      "[EPOCH #26, step #1240] loss: 0.8266335231080159\n",
      "[EPOCH #26, step #1242] loss: 0.826113320749226\n",
      "[EPOCH #26, step #1244] loss: 0.8261175104413166\n",
      "[EPOCH #26, step #1246] loss: 0.8264659424256399\n",
      "[EPOCH #26, step #1248] loss: 0.8264609319959477\n",
      "[EPOCH #26, step #1250] loss: 0.8261061070634307\n",
      "[EPOCH #26, step #1252] loss: 0.8259758252385894\n",
      "[EPOCH #26, step #1254] loss: 0.8258907525662882\n",
      "[EPOCH #26, step #1256] loss: 0.8260873353661482\n",
      "[EPOCH #26, step #1258] loss: 0.8262929454789074\n",
      "[EPOCH #26, step #1260] loss: 0.8265836003940319\n",
      "[EPOCH #26, step #1262] loss: 0.8267224884561764\n",
      "[EPOCH #26, step #1264] loss: 0.8265172599803788\n",
      "[EPOCH #26, step #1266] loss: 0.8270535688750276\n",
      "[EPOCH #26, step #1268] loss: 0.8269745287132414\n",
      "[EPOCH #26, step #1270] loss: 0.82695787558867\n",
      "[EPOCH #26, step #1272] loss: 0.8275807600553262\n",
      "[EPOCH #26, step #1274] loss: 0.8273980144425934\n",
      "[EPOCH #26, step #1276] loss: 0.8276232209818011\n",
      "[EPOCH #26, step #1278] loss: 0.8279227788230233\n",
      "[EPOCH #26, step #1280] loss: 0.8277242387485727\n",
      "[EPOCH #26, step #1282] loss: 0.8278168959257106\n",
      "[EPOCH #26, step #1284] loss: 0.8277643656916192\n",
      "[EPOCH #26, step #1286] loss: 0.8279782384055108\n",
      "[EPOCH #26, step #1288] loss: 0.8281959077015323\n",
      "[EPOCH #26, step #1290] loss: 0.8283601671480375\n",
      "[EPOCH #26, step #1292] loss: 0.8284141626914896\n",
      "[EPOCH #26, step #1294] loss: 0.8285424915519921\n",
      "[EPOCH #26, step #1296] loss: 0.828408200738976\n",
      "[EPOCH #26, step #1298] loss: 0.828186411505208\n",
      "[EPOCH #26, step #1300] loss: 0.8280837362679402\n",
      "[EPOCH #26, step #1302] loss: 0.8282616692877511\n",
      "[EPOCH #26, step #1304] loss: 0.8284859161267335\n",
      "[EPOCH #26, step #1306] loss: 0.8289059095922644\n",
      "[EPOCH #26, step #1308] loss: 0.8293678334325757\n",
      "[EPOCH #26, step #1310] loss: 0.8291753413657211\n",
      "[EPOCH #26, step #1312] loss: 0.8290368237753271\n",
      "[EPOCH #26, step #1314] loss: 0.8287461879135538\n",
      "[EPOCH #26, step #1316] loss: 0.8292374398641362\n",
      "[EPOCH #26, step #1318] loss: 0.8290054116672056\n",
      "[EPOCH #26, step #1320] loss: 0.8290132455623664\n",
      "[EPOCH #26, step #1322] loss: 0.8291230199018033\n",
      "[EPOCH #26, step #1324] loss: 0.8291283356468633\n",
      "[EPOCH #26, step #1326] loss: 0.8290004930329126\n",
      "[EPOCH #26, step #1328] loss: 0.8288592414312385\n",
      "[EPOCH #26, step #1330] loss: 0.8289742696607677\n",
      "[EPOCH #26, step #1332] loss: 0.8293865438206967\n",
      "[EPOCH #26, step #1334] loss: 0.8295315634222067\n",
      "[EPOCH #26, step #1336] loss: 0.8292260865444734\n",
      "[EPOCH #26, step #1338] loss: 0.8288612749435903\n",
      "[EPOCH #26, step #1340] loss: 0.8285155730137267\n",
      "[EPOCH #26, step #1342] loss: 0.828357556153835\n",
      "[EPOCH #26, step #1344] loss: 0.8283087903682184\n",
      "[EPOCH #26, step #1346] loss: 0.8282327675429998\n",
      "[EPOCH #26, step #1348] loss: 0.828379956813456\n",
      "[EPOCH #26, step #1350] loss: 0.8284106594293229\n",
      "[EPOCH #26, step #1352] loss: 0.8281852512208074\n",
      "[EPOCH #26, step #1354] loss: 0.8283375673188494\n",
      "[EPOCH #26, step #1356] loss: 0.8282083816711043\n",
      "[EPOCH #26, step #1358] loss: 0.8280122489329206\n",
      "[EPOCH #26, step #1360] loss: 0.8280916543325723\n",
      "[EPOCH #26, step #1362] loss: 0.8276876327926764\n",
      "[EPOCH #26, step #1364] loss: 0.8275888235141069\n",
      "[EPOCH #26, step #1366] loss: 0.827745231469356\n",
      "[EPOCH #26, step #1368] loss: 0.8273645177472674\n",
      "[EPOCH #26, step #1370] loss: 0.8273098193147076\n",
      "[EPOCH #26, step #1372] loss: 0.8269432657666217\n",
      "[EPOCH #26, step #1374] loss: 0.8266982963301919\n",
      "[EPOCH #26, step #1376] loss: 0.8264535533490177\n",
      "[EPOCH #26, step #1378] loss: 0.8268757768521022\n",
      "[EPOCH #26, step #1380] loss: 0.8271363343905919\n",
      "[EPOCH #26, step #1382] loss: 0.8267788263825687\n",
      "[EPOCH #26, step #1384] loss: 0.8268111480272203\n",
      "[EPOCH #26, step #1386] loss: 0.8269298196526509\n",
      "[EPOCH #26, step #1388] loss: 0.8270804375689007\n",
      "[EPOCH #26, step #1390] loss: 0.8271253458636001\n",
      "[EPOCH #26, step #1392] loss: 0.8269084782713365\n",
      "[EPOCH #26, step #1394] loss: 0.8271862032165664\n",
      "[EPOCH #26, step #1396] loss: 0.8274511856186278\n",
      "[EPOCH #26, step #1398] loss: 0.8270919303795199\n",
      "[EPOCH #26, step #1400] loss: 0.8271673595284156\n",
      "[EPOCH #26, step #1402] loss: 0.8273192201863844\n",
      "[EPOCH #26, step #1404] loss: 0.8275989699618248\n",
      "[EPOCH #26, step #1406] loss: 0.8278911729696039\n",
      "[EPOCH #26, step #1408] loss: 0.8277601544699659\n",
      "[EPOCH #26, step #1410] loss: 0.82803772333917\n",
      "[EPOCH #26, step #1412] loss: 0.8280402325773948\n",
      "[EPOCH #26, step #1414] loss: 0.8280687582787692\n",
      "[EPOCH #26, step #1416] loss: 0.8280536322082191\n",
      "[EPOCH #26, step #1418] loss: 0.8281347195475433\n",
      "[EPOCH #26, step #1420] loss: 0.8281933097752109\n",
      "[EPOCH #26, step #1422] loss: 0.828138180710611\n",
      "[EPOCH #26, step #1424] loss: 0.8281577372550964\n",
      "[EPOCH #26, step #1426] loss: 0.828133718317509\n",
      "[EPOCH #26, step #1428] loss: 0.828155004869732\n",
      "[EPOCH #26, step #1430] loss: 0.8282551830836229\n",
      "[EPOCH #26, step #1432] loss: 0.8283322844069402\n",
      "[EPOCH #26, step #1434] loss: 0.8282422638936325\n",
      "[EPOCH #26, step #1436] loss: 0.828237401128396\n",
      "[EPOCH #26, step #1438] loss: 0.8283958902700317\n",
      "[EPOCH #26, step #1440] loss: 0.8287069501767632\n",
      "[EPOCH #26, step #1442] loss: 0.8287685903012546\n",
      "[EPOCH #26, step #1444] loss: 0.8286186426981098\n",
      "[EPOCH #26, step #1446] loss: 0.8283901308517087\n",
      "[EPOCH #26, step #1448] loss: 0.8288830368991059\n",
      "[EPOCH #26, step #1450] loss: 0.8286838671160435\n",
      "[EPOCH #26, step #1452] loss: 0.8287539738502817\n",
      "[EPOCH #26, step #1454] loss: 0.8285513574724754\n",
      "[EPOCH #26, step #1456] loss: 0.8288530433267948\n",
      "[EPOCH #26, step #1458] loss: 0.8288956847886993\n",
      "[EPOCH #26, step #1460] loss: 0.8286956636812652\n",
      "[EPOCH #26, step #1462] loss: 0.8284902195774034\n",
      "[EPOCH #26, step #1464] loss: 0.8287600879376252\n",
      "[EPOCH #26, step #1466] loss: 0.8287198086864053\n",
      "[EPOCH #26, step #1468] loss: 0.8288021097790229\n",
      "[EPOCH #26, step #1470] loss: 0.8286102513404706\n",
      "[EPOCH #26, step #1472] loss: 0.8288179312283217\n",
      "[EPOCH #26, step #1474] loss: 0.8290905527745263\n",
      "[EPOCH #26, step #1476] loss: 0.8290083447500266\n",
      "[EPOCH #26, step #1478] loss: 0.8289742985232768\n",
      "[EPOCH #26, step #1480] loss: 0.8291665612242658\n",
      "[EPOCH #26, step #1482] loss: 0.8290928284702314\n",
      "[EPOCH #26, step #1484] loss: 0.8289096967138425\n",
      "[EPOCH #26, step #1486] loss: 0.8290552578681094\n",
      "[EPOCH #26, step #1488] loss: 0.8290389933947991\n",
      "[EPOCH #26, step #1490] loss: 0.8290351253879862\n",
      "[EPOCH #26, step #1492] loss: 0.829159746574062\n",
      "[EPOCH #26, step #1494] loss: 0.8290128756526322\n",
      "[EPOCH #26, step #1496] loss: 0.8289899086267373\n",
      "[EPOCH #26, step #1498] loss: 0.8291295124261359\n",
      "[EPOCH #26, step #1500] loss: 0.8291553803716478\n",
      "[EPOCH #26, step #1502] loss: 0.8293297385582509\n",
      "[EPOCH #26, step #1504] loss: 0.8293024531630583\n",
      "[EPOCH #26, step #1506] loss: 0.8290162177456082\n",
      "[EPOCH #26, step #1508] loss: 0.8290351986332078\n",
      "[EPOCH #26, step #1510] loss: 0.8292166922046679\n",
      "[EPOCH #26, step #1512] loss: 0.8292844282107407\n",
      "[EPOCH #26, step #1514] loss: 0.8293339959465631\n",
      "[EPOCH #26, step #1516] loss: 0.8292901738348492\n",
      "[EPOCH #26, step #1518] loss: 0.8291143713380413\n",
      "[EPOCH #26, step #1520] loss: 0.828968589867047\n",
      "[EPOCH #26, step #1522] loss: 0.8286846435469228\n",
      "[EPOCH #26, step #1524] loss: 0.8286806095623579\n",
      "[EPOCH #26, step #1526] loss: 0.8287515614886806\n",
      "[EPOCH #26, step #1528] loss: 0.8286694792690739\n",
      "[EPOCH #26, step #1530] loss: 0.8288774687740866\n",
      "[EPOCH #26, step #1532] loss: 0.8287041225389803\n",
      "[EPOCH #26, step #1534] loss: 0.8293931508297252\n",
      "[EPOCH #26, step #1536] loss: 0.8297055303546307\n",
      "[EPOCH #26, step #1538] loss: 0.8294915079373365\n",
      "[EPOCH #26, step #1540] loss: 0.8295272822352217\n",
      "[EPOCH #26, step #1542] loss: 0.8295934036499637\n",
      "[EPOCH #26, step #1544] loss: 0.8298954636147878\n",
      "[EPOCH #26, step #1546] loss: 0.8297726298888884\n",
      "[EPOCH #26, step #1548] loss: 0.8298169326751443\n",
      "[EPOCH #26, step #1550] loss: 0.8297337202546213\n",
      "[EPOCH #26, step #1552] loss: 0.8297047814245156\n",
      "[EPOCH #26, step #1554] loss: 0.8296496339549589\n",
      "[EPOCH #26, step #1556] loss: 0.829472092994146\n",
      "[EPOCH #26, step #1558] loss: 0.8293730804673979\n",
      "[EPOCH #26, step #1560] loss: 0.829120079383569\n",
      "[EPOCH #26, step #1562] loss: 0.8288943243575874\n",
      "[EPOCH #26, step #1564] loss: 0.829209356033764\n",
      "[EPOCH #26, step #1566] loss: 0.8290455153434233\n",
      "[EPOCH #26, step #1568] loss: 0.8292469116743391\n",
      "[EPOCH #26, step #1570] loss: 0.8292088015757876\n",
      "[EPOCH #26, step #1572] loss: 0.8294266697637457\n",
      "[EPOCH #26, step #1574] loss: 0.8291613447098505\n",
      "[EPOCH #26, step #1576] loss: 0.8293954076159205\n",
      "[EPOCH #26, step #1578] loss: 0.829371363056695\n",
      "[EPOCH #26, step #1580] loss: 0.8295350461953204\n",
      "[EPOCH #26, step #1582] loss: 0.8295091066041177\n",
      "[EPOCH #26, step #1584] loss: 0.8294633297514088\n",
      "[EPOCH #26, step #1586] loss: 0.8293950312454594\n",
      "[EPOCH #26, step #1588] loss: 0.8293924148612386\n",
      "[EPOCH #26, step #1590] loss: 0.8292721886068376\n",
      "[EPOCH #26, step #1592] loss: 0.8294932000006959\n",
      "[EPOCH #26, step #1594] loss: 0.8294604797348334\n",
      "[EPOCH #26, step #1596] loss: 0.8299274065752812\n",
      "[EPOCH #26, step #1598] loss: 0.8300484731243579\n",
      "[EPOCH #26, step #1600] loss: 0.8304364588914404\n",
      "[EPOCH #26, step #1602] loss: 0.8305109437747963\n",
      "[EPOCH #26, step #1604] loss: 0.8303070020638522\n",
      "[EPOCH #26, step #1606] loss: 0.8302289340424849\n",
      "[EPOCH #26, step #1608] loss: 0.830186878045647\n",
      "[EPOCH #26, step #1610] loss: 0.8301689701188358\n",
      "[EPOCH #26, step #1612] loss: 0.8302141206093036\n",
      "[EPOCH #26, step #1614] loss: 0.830059175871474\n",
      "[EPOCH #26, step #1616] loss: 0.830207210395833\n",
      "[EPOCH #26, step #1618] loss: 0.8301230343018439\n",
      "[EPOCH #26, step #1620] loss: 0.8301265980453126\n",
      "[EPOCH #26, step #1622] loss: 0.8300245193258451\n",
      "[EPOCH #26, step #1624] loss: 0.829665443622149\n",
      "[EPOCH #26, step #1626] loss: 0.8293118488041257\n",
      "[EPOCH #26, step #1628] loss: 0.829129913180353\n",
      "[EPOCH #26, step #1630] loss: 0.8290176333677981\n",
      "[EPOCH #26, step #1632] loss: 0.8285590824873551\n",
      "[EPOCH #26, step #1634] loss: 0.8285939846199222\n",
      "[EPOCH #26, step #1636] loss: 0.8289683905402261\n",
      "[EPOCH #26, step #1638] loss: 0.8289747192337427\n",
      "[EPOCH #26, step #1640] loss: 0.8290340469640468\n",
      "[EPOCH #26, step #1642] loss: 0.8291049103365391\n",
      "[EPOCH #26, step #1644] loss: 0.8287157894267861\n",
      "[EPOCH #26, step #1646] loss: 0.8286273272817759\n",
      "[EPOCH #26, step #1648] loss: 0.8286312407909414\n",
      "[EPOCH #26, step #1650] loss: 0.8289360245526162\n",
      "[EPOCH #26, step #1652] loss: 0.829028680659177\n",
      "[EPOCH #26, step #1654] loss: 0.8289635719489475\n",
      "[EPOCH #26, step #1656] loss: 0.8289420966938021\n",
      "[EPOCH #26, step #1658] loss: 0.829141152271526\n",
      "[EPOCH #26, step #1660] loss: 0.8289931223092489\n",
      "[EPOCH #26, step #1662] loss: 0.8288187177440738\n",
      "[EPOCH #26, step #1664] loss: 0.8289222954271792\n",
      "[EPOCH #26, step #1666] loss: 0.828982241724377\n",
      "[EPOCH #26, step #1668] loss: 0.8290527223683604\n",
      "[EPOCH #26, step #1670] loss: 0.8291295293845651\n",
      "[EPOCH #26, step #1672] loss: 0.8290796553169405\n",
      "[EPOCH #26, step #1674] loss: 0.8290295723658889\n",
      "[EPOCH #26, step #1676] loss: 0.8289157458551597\n",
      "[EPOCH #26, step #1678] loss: 0.8288903019128633\n",
      "[EPOCH #26, step #1680] loss: 0.8288063793080255\n",
      "[EPOCH #26, step #1682] loss: 0.8289026986681416\n",
      "[EPOCH #26, step #1684] loss: 0.8287479675134495\n",
      "[EPOCH #26, step #1686] loss: 0.8289866408937134\n",
      "[EPOCH #26, step #1688] loss: 0.8286838126718963\n",
      "[EPOCH #26, step #1690] loss: 0.8289325883020529\n",
      "[EPOCH #26, step #1692] loss: 0.8288328205067521\n",
      "[EPOCH #26, step #1694] loss: 0.8287438844157531\n",
      "[EPOCH #26, step #1696] loss: 0.828546432234922\n",
      "[EPOCH #26, step #1698] loss: 0.8287494686366952\n",
      "[EPOCH #26, step #1700] loss: 0.8286833613848139\n",
      "[EPOCH #26, step #1702] loss: 0.8286027787575915\n",
      "[EPOCH #26, step #1704] loss: 0.8286402037416385\n",
      "[EPOCH #26, step #1706] loss: 0.8288113973820915\n",
      "[EPOCH #26, step #1708] loss: 0.8289249828504917\n",
      "[EPOCH #26, step #1710] loss: 0.8289670457204554\n",
      "[EPOCH #26, step #1712] loss: 0.8290937255852694\n",
      "[EPOCH #26, step #1714] loss: 0.8290650032004532\n",
      "[EPOCH #26, step #1716] loss: 0.8290913940934018\n",
      "[EPOCH #26, step #1718] loss: 0.8289989956663818\n",
      "[EPOCH #26, step #1720] loss: 0.8291642446285206\n",
      "[EPOCH #26, step #1722] loss: 0.8291042740443246\n",
      "[EPOCH #26, step #1724] loss: 0.8291399517439414\n",
      "[EPOCH #26, step #1726] loss: 0.8292865419946934\n",
      "[EPOCH #26, step #1728] loss: 0.8292749313655928\n",
      "[EPOCH #26, step #1730] loss: 0.8295425237051536\n",
      "[EPOCH #26, step #1732] loss: 0.8293847128860674\n",
      "[EPOCH #26, step #1734] loss: 0.8292727950498763\n",
      "[EPOCH #26, step #1736] loss: 0.8294926832891705\n",
      "[EPOCH #26, step #1738] loss: 0.8293718449715707\n",
      "[EPOCH #26, step #1740] loss: 0.8295104292225112\n",
      "[EPOCH #26, step #1742] loss: 0.82974824470073\n",
      "[EPOCH #26, step #1744] loss: 0.829606974654348\n",
      "[EPOCH #26, step #1746] loss: 0.8297238750292631\n",
      "[EPOCH #26, step #1748] loss: 0.8298329223797211\n",
      "[EPOCH #26, step #1750] loss: 0.829689613057844\n",
      "[EPOCH #26, step #1752] loss: 0.8292852840250856\n",
      "[EPOCH #26, step #1754] loss: 0.8290942196832424\n",
      "[EPOCH #26, step #1756] loss: 0.8292879047350376\n",
      "[EPOCH #26, step #1758] loss: 0.8290058117891456\n",
      "[EPOCH #26, step #1760] loss: 0.8290355278307033\n",
      "[EPOCH #26, step #1762] loss: 0.8290126474824604\n",
      "[EPOCH #26, step #1764] loss: 0.8291485190729244\n",
      "[EPOCH #26, step #1766] loss: 0.8289065190169794\n",
      "[EPOCH #26, step #1768] loss: 0.8289938071914282\n",
      "[EPOCH #26, step #1770] loss: 0.8292559693083125\n",
      "[EPOCH #26, step #1772] loss: 0.82930143487635\n",
      "[EPOCH #26, step #1774] loss: 0.8291795477900706\n",
      "[EPOCH #26, step #1776] loss: 0.8293286938813542\n",
      "[EPOCH #26, step #1778] loss: 0.8293796297102044\n",
      "[EPOCH #26, step #1780] loss: 0.8296308262939871\n",
      "[EPOCH #26, step #1782] loss: 0.8295428225884461\n",
      "[EPOCH #26, step #1784] loss: 0.8293789231977543\n",
      "[EPOCH #26, step #1786] loss: 0.8295347991607412\n",
      "[EPOCH #26, step #1788] loss: 0.8295409174822375\n",
      "[EPOCH #26, step #1790] loss: 0.8296595636624188\n",
      "[EPOCH #26, step #1792] loss: 0.8294144442509621\n",
      "[EPOCH #26, step #1794] loss: 0.829714055961221\n",
      "[EPOCH #26, step #1796] loss: 0.8294610677491179\n",
      "[EPOCH #26, step #1798] loss: 0.8294020067691272\n",
      "[EPOCH #26, step #1800] loss: 0.8295260379706271\n",
      "[EPOCH #26, step #1802] loss: 0.8294871556745658\n",
      "[EPOCH #26, step #1804] loss: 0.8294159334947528\n",
      "[EPOCH #26, step #1806] loss: 0.8294463608399504\n",
      "[EPOCH #26, step #1808] loss: 0.8292220127951578\n",
      "[EPOCH #26, step #1810] loss: 0.8293851163260915\n",
      "[EPOCH #26, step #1812] loss: 0.8292155466846386\n",
      "[EPOCH #26, step #1814] loss: 0.8291521545119851\n",
      "[EPOCH #26, step #1816] loss: 0.8292576062626804\n",
      "[EPOCH #26, step #1818] loss: 0.829118924900488\n",
      "[EPOCH #26, step #1820] loss: 0.8291367139055597\n",
      "[EPOCH #26, step #1822] loss: 0.8291217264766819\n",
      "[EPOCH #26, step #1824] loss: 0.8293156915984742\n",
      "[EPOCH #26, step #1826] loss: 0.8294706614244551\n",
      "[EPOCH #26, step #1828] loss: 0.8296572222059186\n",
      "[EPOCH #26, step #1830] loss: 0.8295375358726339\n",
      "[EPOCH #26, step #1832] loss: 0.8298473302224134\n",
      "[EPOCH #26, step #1834] loss: 0.830025287317645\n",
      "[EPOCH #26, step #1836] loss: 0.829824467294555\n",
      "[EPOCH #26, step #1838] loss: 0.8297376835910181\n",
      "[EPOCH #26, step #1840] loss: 0.8298031846380053\n",
      "[EPOCH #26, step #1842] loss: 0.8298403471950856\n",
      "[EPOCH #26, step #1844] loss: 0.829898297269816\n",
      "[EPOCH #26, step #1846] loss: 0.8296305193537045\n",
      "[EPOCH #26, step #1848] loss: 0.8297865111934875\n",
      "[EPOCH #26, step #1850] loss: 0.8295576667412109\n",
      "[EPOCH #26, step #1852] loss: 0.8294858730167424\n",
      "[EPOCH #26, step #1854] loss: 0.829574597010394\n",
      "[EPOCH #26, step #1856] loss: 0.8292199094640869\n",
      "[EPOCH #26, step #1858] loss: 0.8292562575863535\n",
      "[EPOCH #26, step #1860] loss: 0.8290946963716104\n",
      "[EPOCH #26, step #1862] loss: 0.8288335681793451\n",
      "[EPOCH #26, step #1864] loss: 0.8287044352245075\n",
      "[EPOCH #26, step #1866] loss: 0.8284866171018542\n",
      "[EPOCH #26, step #1868] loss: 0.828214993254905\n",
      "[EPOCH #26, step #1870] loss: 0.8280018967845617\n",
      "[EPOCH #26, step #1872] loss: 0.8283601051909492\n",
      "[EPOCH #26, step #1874] loss: 0.8285952675501506\n",
      "[EPOCH #26, step #1876] loss: 0.8284914983862184\n",
      "[EPOCH #26, step #1878] loss: 0.8284056563527106\n",
      "[EPOCH #26, step #1880] loss: 0.8282283512852662\n",
      "[EPOCH #26, step #1882] loss: 0.828142134546917\n",
      "[EPOCH #26, step #1884] loss: 0.8283320324806699\n",
      "[EPOCH #26, step #1886] loss: 0.8282792531250012\n",
      "[EPOCH #26, step #1888] loss: 0.8280448348134709\n",
      "[EPOCH #26, step #1890] loss: 0.8279248504711799\n",
      "[EPOCH #26, step #1892] loss: 0.8281518652901345\n",
      "[EPOCH #26, step #1894] loss: 0.8283784803111195\n",
      "[EPOCH #26, step #1896] loss: 0.8285733518879478\n",
      "[EPOCH #26, step #1898] loss: 0.8283196344634243\n",
      "[EPOCH #26, step #1900] loss: 0.828220347960581\n",
      "[EPOCH #26, step #1902] loss: 0.8282855158095227\n",
      "[EPOCH #26, step #1904] loss: 0.8282756152428354\n",
      "[EPOCH #26, step #1906] loss: 0.8284275934029826\n",
      "[EPOCH #26, step #1908] loss: 0.8282474972241334\n",
      "[EPOCH #26, step #1910] loss: 0.8283356567878863\n",
      "[EPOCH #26, step #1912] loss: 0.8284520856448012\n",
      "[EPOCH #26, step #1914] loss: 0.8285106829190068\n",
      "[EPOCH #26, step #1916] loss: 0.8288052834193409\n",
      "[EPOCH #26, step #1918] loss: 0.8289340914010132\n",
      "[EPOCH #26, step #1920] loss: 0.828424526837144\n",
      "[EPOCH #26, step #1922] loss: 0.8282550682763662\n",
      "[EPOCH #26, step #1924] loss: 0.8284202723998528\n",
      "[EPOCH #26, step #1926] loss: 0.8284226229726557\n",
      "[EPOCH #26, step #1928] loss: 0.828394698101724\n",
      "[EPOCH #26, step #1930] loss: 0.8283609899753489\n",
      "[EPOCH #26, step #1932] loss: 0.828303441197158\n",
      "[EPOCH #26, step #1934] loss: 0.8281635136567345\n",
      "[EPOCH #26, step #1936] loss: 0.8280667045341673\n",
      "[EPOCH #26, step #1938] loss: 0.8279755973151937\n",
      "[EPOCH #26, step #1940] loss: 0.8277103585843141\n",
      "[EPOCH #26, step #1942] loss: 0.8274808917165846\n",
      "[EPOCH #26, step #1944] loss: 0.8274286235819133\n",
      "[EPOCH #26, step #1946] loss: 0.8273096384607833\n",
      "[EPOCH #26, step #1948] loss: 0.8271130065602361\n",
      "[EPOCH #26, step #1950] loss: 0.8273701515948082\n",
      "[EPOCH #26, step #1952] loss: 0.8273776149786379\n",
      "[EPOCH #26, step #1954] loss: 0.8272032699011781\n",
      "[EPOCH #26, step #1956] loss: 0.8270757966158521\n",
      "[EPOCH #26, step #1958] loss: 0.8270693979377708\n",
      "[EPOCH #26, step #1960] loss: 0.8270527532914048\n",
      "[EPOCH #26, step #1962] loss: 0.8268401593926362\n",
      "[EPOCH #26, step #1964] loss: 0.8265824830865739\n",
      "[EPOCH #26, step #1966] loss: 0.8265981974793256\n",
      "[EPOCH #26, step #1968] loss: 0.8263903427027155\n",
      "[EPOCH #26, step #1970] loss: 0.8261459102822947\n",
      "[EPOCH #26, step #1972] loss: 0.8261063525928076\n",
      "[EPOCH #26, step #1974] loss: 0.8257963584948189\n",
      "[EPOCH #26, step #1976] loss: 0.8256473153543159\n",
      "[EPOCH #26, step #1978] loss: 0.8257746693761497\n",
      "[EPOCH #26, step #1980] loss: 0.8255940776229928\n",
      "[EPOCH #26, step #1982] loss: 0.8252751979482817\n",
      "[EPOCH #26, step #1984] loss: 0.8252767313787859\n",
      "[EPOCH #26, step #1986] loss: 0.8254080269135119\n",
      "[EPOCH #26, step #1988] loss: 0.8255733946959177\n",
      "[EPOCH #26, step #1990] loss: 0.8256892484525291\n",
      "[EPOCH #26, step #1992] loss: 0.825821640694255\n",
      "[EPOCH #26, step #1994] loss: 0.825723304709695\n",
      "[EPOCH #26, step #1996] loss: 0.8255008203749306\n",
      "[EPOCH #26, step #1998] loss: 0.8253833037754963\n",
      "[EPOCH #26, step #2000] loss: 0.825303579094647\n",
      "[EPOCH #26, step #2002] loss: 0.8252108772427097\n",
      "[EPOCH #26, step #2004] loss: 0.8253938458952821\n",
      "[EPOCH #26, step #2006] loss: 0.8251187917778726\n",
      "[EPOCH #26, step #2008] loss: 0.825064986810689\n",
      "[EPOCH #26, step #2010] loss: 0.8250296762604905\n",
      "[EPOCH #26, step #2012] loss: 0.8250979132398822\n",
      "[EPOCH #26, step #2014] loss: 0.8251196016153094\n",
      "[EPOCH #26, step #2016] loss: 0.8251313706938441\n",
      "[EPOCH #26, step #2018] loss: 0.8253177871439585\n",
      "[EPOCH #26, step #2020] loss: 0.8252913136107092\n",
      "[EPOCH #26, step #2022] loss: 0.8250851160779897\n",
      "[EPOCH #26, step #2024] loss: 0.825154670447479\n",
      "[EPOCH #26, step #2026] loss: 0.8250121537340528\n",
      "[EPOCH #26, step #2028] loss: 0.8247814410099436\n",
      "[EPOCH #26, step #2030] loss: 0.8248889687054266\n",
      "[EPOCH #26, step #2032] loss: 0.8246644823145409\n",
      "[EPOCH #26, step #2034] loss: 0.8246849674704034\n",
      "[EPOCH #26, step #2036] loss: 0.8245506800297844\n",
      "[EPOCH #26, step #2038] loss: 0.8247183653845279\n",
      "[EPOCH #26, step #2040] loss: 0.8244957777140831\n",
      "[EPOCH #26, step #2042] loss: 0.8246115882695451\n",
      "[EPOCH #26, step #2044] loss: 0.8246798902822882\n",
      "[EPOCH #26, step #2046] loss: 0.8247230310788315\n",
      "[EPOCH #26, step #2048] loss: 0.8247283188496176\n",
      "[EPOCH #26, step #2050] loss: 0.8247233018794913\n",
      "[EPOCH #26, step #2052] loss: 0.8247456072860965\n",
      "[EPOCH #26, step #2054] loss: 0.8246560770664771\n",
      "[EPOCH #26, step #2056] loss: 0.8247491540147311\n",
      "[EPOCH #26, step #2058] loss: 0.8248766594543336\n",
      "[EPOCH #26, step #2060] loss: 0.8247688024267301\n",
      "[EPOCH #26, step #2062] loss: 0.8248312614580063\n",
      "[EPOCH #26, step #2064] loss: 0.8247978395324642\n",
      "[EPOCH #26, step #2066] loss: 0.824899448235945\n",
      "[EPOCH #26, step #2068] loss: 0.8249493004648855\n",
      "[EPOCH #26, step #2070] loss: 0.8248223126337529\n",
      "[EPOCH #26, step #2072] loss: 0.8247993438501492\n",
      "[EPOCH #26, step #2074] loss: 0.8247327375842864\n",
      "[EPOCH #26, step #2076] loss: 0.8248218373863182\n",
      "[EPOCH #26, step #2078] loss: 0.824534932686309\n",
      "[EPOCH #26, step #2080] loss: 0.8243804144664546\n",
      "[EPOCH #26, step #2082] loss: 0.8242874032193174\n",
      "[EPOCH #26, step #2084] loss: 0.8240694919078471\n",
      "[EPOCH #26, step #2086] loss: 0.8240295899045713\n",
      "[EPOCH #26, step #2088] loss: 0.8239107446102163\n",
      "[EPOCH #26, step #2090] loss: 0.8237492321553497\n",
      "[EPOCH #26, step #2092] loss: 0.82397156127947\n",
      "[EPOCH #26, step #2094] loss: 0.8239146691802578\n",
      "[EPOCH #26, step #2096] loss: 0.823650200223718\n",
      "[EPOCH #26, step #2098] loss: 0.8234380727838823\n",
      "[EPOCH #26, step #2100] loss: 0.8233348540837625\n",
      "[EPOCH #26, step #2102] loss: 0.8233379914371728\n",
      "[EPOCH #26, step #2104] loss: 0.8232442519443901\n",
      "[EPOCH #26, step #2106] loss: 0.8232473663430561\n",
      "[EPOCH #26, step #2108] loss: 0.8231766722167256\n",
      "[EPOCH #26, step #2110] loss: 0.8230715710819756\n",
      "[EPOCH #26, step #2112] loss: 0.8231829870271841\n",
      "[EPOCH #26, step #2114] loss: 0.8228927547768217\n",
      "[EPOCH #26, step #2116] loss: 0.8228847060949103\n",
      "[EPOCH #26, step #2118] loss: 0.8229754262231554\n",
      "[EPOCH #26, step #2120] loss: 0.8230940063906863\n",
      "[EPOCH #26, step #2122] loss: 0.8232424951531783\n",
      "[EPOCH #26, step #2124] loss: 0.8234157367594102\n",
      "[EPOCH #26, step #2126] loss: 0.8234911790239345\n",
      "[EPOCH #26, step #2128] loss: 0.8234324581385667\n",
      "[EPOCH #26, step #2130] loss: 0.8232345696711753\n",
      "[EPOCH #26, step #2132] loss: 0.8231757915724179\n",
      "[EPOCH #26, step #2134] loss: 0.8230615774557797\n",
      "[EPOCH #26, step #2136] loss: 0.8229430791898816\n",
      "[EPOCH #26, step #2138] loss: 0.8231268819245627\n",
      "[EPOCH #26, step #2140] loss: 0.8230695295617827\n",
      "[EPOCH #26, step #2142] loss: 0.8233901729135384\n",
      "[EPOCH #26, step #2144] loss: 0.823216271080893\n",
      "[EPOCH #26, step #2146] loss: 0.8231708897259494\n",
      "[EPOCH #26, step #2148] loss: 0.8231117737160111\n",
      "[EPOCH #26, step #2150] loss: 0.8230456976295348\n",
      "[EPOCH #26, step #2152] loss: 0.8230402042048508\n",
      "[EPOCH #26, step #2154] loss: 0.8228861054383961\n",
      "[EPOCH #26, step #2156] loss: 0.8227620263949665\n",
      "[EPOCH #26, step #2158] loss: 0.8227144191943147\n",
      "[EPOCH #26, step #2160] loss: 0.8227453383650287\n",
      "[EPOCH #26, step #2162] loss: 0.8224778606199413\n",
      "[EPOCH #26, step #2164] loss: 0.8223883280164925\n",
      "[EPOCH #26, step #2166] loss: 0.8224566976183507\n",
      "[EPOCH #26, step #2168] loss: 0.8223969090666404\n",
      "[EPOCH #26, step #2170] loss: 0.822530533094002\n",
      "[EPOCH #26, step #2172] loss: 0.822535387818516\n",
      "[EPOCH #26, step #2174] loss: 0.8226856152079571\n",
      "[EPOCH #26, step #2176] loss: 0.8226172070219586\n",
      "[EPOCH #26, step #2178] loss: 0.8225194678196069\n",
      "[EPOCH #26, step #2180] loss: 0.822915795949663\n",
      "[EPOCH #26, step #2182] loss: 0.8227696448933134\n",
      "[EPOCH #26, step #2184] loss: 0.8230420998495831\n",
      "[EPOCH #26, step #2186] loss: 0.8228119282238441\n",
      "[EPOCH #26, step #2188] loss: 0.8228473064016131\n",
      "[EPOCH #26, step #2190] loss: 0.8227628928131842\n",
      "[EPOCH #26, step #2192] loss: 0.822936006376203\n",
      "[EPOCH #26, step #2194] loss: 0.8228827613089785\n",
      "[EPOCH #26, step #2196] loss: 0.8226982071202182\n",
      "[EPOCH #26, step #2198] loss: 0.8228069654563819\n",
      "[EPOCH #26, step #2200] loss: 0.8226911545151854\n",
      "[EPOCH #26, step #2202] loss: 0.822869607888727\n",
      "[EPOCH #26, step #2204] loss: 0.8229003922604109\n",
      "[EPOCH #26, step #2206] loss: 0.8228102598894652\n",
      "[EPOCH #26, step #2208] loss: 0.8227481316958902\n",
      "[EPOCH #26, step #2210] loss: 0.8227300570864098\n",
      "[EPOCH #26, step #2212] loss: 0.8227330601113014\n",
      "[EPOCH #26, step #2214] loss: 0.82295275213487\n",
      "[EPOCH #26, step #2216] loss: 0.8228615904962043\n",
      "[EPOCH #26, step #2218] loss: 0.8227043042531041\n",
      "[EPOCH #26, step #2220] loss: 0.8229644695202116\n",
      "[EPOCH #26, step #2222] loss: 0.8228515805395884\n",
      "[EPOCH #26, step #2224] loss: 0.8228362473209253\n",
      "[EPOCH #26, step #2226] loss: 0.8227115440754061\n",
      "[EPOCH #26, step #2228] loss: 0.8227901812517466\n",
      "[EPOCH #26, step #2230] loss: 0.8227717504806981\n",
      "[EPOCH #26, step #2232] loss: 0.8227034585522901\n",
      "[EPOCH #26, step #2234] loss: 0.8227612851583451\n",
      "[EPOCH #26, step #2236] loss: 0.8227195556029497\n",
      "[EPOCH #26, step #2238] loss: 0.8226129756995001\n",
      "[EPOCH #26, step #2240] loss: 0.8224788467860658\n",
      "[EPOCH #26, step #2242] loss: 0.8224133512588999\n",
      "[EPOCH #26, step #2244] loss: 0.8224221837414399\n",
      "[EPOCH #26, step #2246] loss: 0.8224563092377963\n",
      "[EPOCH #26, step #2248] loss: 0.8225201198846936\n",
      "[EPOCH #26, step #2250] loss: 0.8225043227888647\n",
      "[EPOCH #26, step #2252] loss: 0.8222989792486217\n",
      "[EPOCH #26, step #2254] loss: 0.822128776581483\n",
      "[EPOCH #26, step #2256] loss: 0.8219730679076174\n",
      "[EPOCH #26, step #2258] loss: 0.8218782874349473\n",
      "[EPOCH #26, step #2260] loss: 0.8218824574110097\n",
      "[EPOCH #26, step #2262] loss: 0.8220305019414272\n",
      "[EPOCH #26, step #2264] loss: 0.8219041169479193\n",
      "[EPOCH #26, step #2266] loss: 0.822075183466767\n",
      "[EPOCH #26, step #2268] loss: 0.8221121376413981\n",
      "[EPOCH #26, step #2270] loss: 0.8218951012950697\n",
      "[EPOCH #26, step #2272] loss: 0.8218603845320239\n",
      "[EPOCH #26, step #2274] loss: 0.821769253212017\n",
      "[EPOCH #26, step #2276] loss: 0.8218410946739626\n",
      "[EPOCH #26, step #2278] loss: 0.8218494017116853\n",
      "[EPOCH #26, step #2280] loss: 0.821975868138134\n",
      "[EPOCH #26, step #2282] loss: 0.8217856578016511\n",
      "[EPOCH #26, step #2284] loss: 0.8217834726465088\n",
      "[EPOCH #26, step #2286] loss: 0.8217554177109936\n",
      "[EPOCH #26, step #2288] loss: 0.8217442692914557\n",
      "[EPOCH #26, step #2290] loss: 0.8216791666527078\n",
      "[EPOCH #26, step #2292] loss: 0.8217737737099157\n",
      "[EPOCH #26, step #2294] loss: 0.8217936114548079\n",
      "[EPOCH #26, step #2296] loss: 0.8218022159353048\n",
      "[EPOCH #26, step #2298] loss: 0.8216545738153429\n",
      "[EPOCH #26, step #2300] loss: 0.8215148909772702\n",
      "[EPOCH #26, step #2302] loss: 0.8213783879151719\n",
      "[EPOCH #26, step #2304] loss: 0.8212668394318372\n",
      "[EPOCH #26, step #2306] loss: 0.8213233954988107\n",
      "[EPOCH #26, step #2308] loss: 0.82119359803334\n",
      "[EPOCH #26, step #2310] loss: 0.8212630033802543\n",
      "[EPOCH #26, step #2312] loss: 0.8213356017190246\n",
      "[EPOCH #26, step #2314] loss: 0.8212729419281879\n",
      "[EPOCH #26, step #2316] loss: 0.821320130051237\n",
      "[EPOCH #26, step #2318] loss: 0.8215257639564179\n",
      "[EPOCH #26, step #2320] loss: 0.8216669505035913\n",
      "[EPOCH #26, step #2322] loss: 0.821687071886855\n",
      "[EPOCH #26, step #2324] loss: 0.8215507220196467\n",
      "[EPOCH #26, step #2326] loss: 0.8213831024155578\n",
      "[EPOCH #26, step #2328] loss: 0.8213596496012857\n",
      "[EPOCH #26, step #2330] loss: 0.8214015788093036\n",
      "[EPOCH #26, step #2332] loss: 0.8213206156609245\n",
      "[EPOCH #26, step #2334] loss: 0.8213742989033652\n",
      "[EPOCH #26, step #2336] loss: 0.8212164519023936\n",
      "[EPOCH #26, step #2338] loss: 0.8212853174221827\n",
      "[EPOCH #26, step #2340] loss: 0.8212970501080072\n",
      "[EPOCH #26, step #2342] loss: 0.8213235442067536\n",
      "[EPOCH #26, step #2344] loss: 0.8214748365792639\n",
      "[EPOCH #26, step #2346] loss: 0.8218314435363171\n",
      "[EPOCH #26, step #2348] loss: 0.8219044538141058\n",
      "[EPOCH #26, step #2350] loss: 0.8218737113531576\n",
      "[EPOCH #26, step #2352] loss: 0.8216948090235933\n",
      "[EPOCH #26, step #2354] loss: 0.8217317376167151\n",
      "[EPOCH #26, step #2356] loss: 0.8218700942418613\n",
      "[EPOCH #26, step #2358] loss: 0.8217635710848848\n",
      "[EPOCH #26, step #2360] loss: 0.8217776037029976\n",
      "[EPOCH #26, step #2362] loss: 0.8216969277008176\n",
      "[EPOCH #26, step #2364] loss: 0.8216809901576213\n",
      "[EPOCH #26, step #2366] loss: 0.8216562675281471\n",
      "[EPOCH #26, step #2368] loss: 0.8217198946094553\n",
      "[EPOCH #26, step #2370] loss: 0.8216734412650628\n",
      "[EPOCH #26, step #2372] loss: 0.8218903734972344\n",
      "[EPOCH #26, step #2374] loss: 0.8219662284851075\n",
      "[EPOCH #26, step #2376] loss: 0.8221578189792079\n",
      "[EPOCH #26, step #2378] loss: 0.8220073183878673\n",
      "[EPOCH #26, step #2380] loss: 0.8218991078283044\n",
      "[EPOCH #26, step #2382] loss: 0.8219283067824907\n",
      "[EPOCH #26, step #2384] loss: 0.8221383185256702\n",
      "[EPOCH #26, step #2386] loss: 0.8221553509136499\n",
      "[EPOCH #26, step #2388] loss: 0.8221399664080458\n",
      "[EPOCH #26, step #2390] loss: 0.8219380544000767\n",
      "[EPOCH #26, step #2392] loss: 0.821748143750855\n",
      "[EPOCH #26, step #2394] loss: 0.8219013517983025\n",
      "[EPOCH #26, step #2396] loss: 0.8218526962055084\n",
      "[EPOCH #26, step #2398] loss: 0.8217600244142056\n",
      "[EPOCH #26, step #2400] loss: 0.8217158103823314\n",
      "[EPOCH #26, step #2402] loss: 0.8215594356674182\n",
      "[EPOCH #26, step #2404] loss: 0.8213799281452401\n",
      "[EPOCH #26, step #2406] loss: 0.8214918138156752\n",
      "[EPOCH #26, step #2408] loss: 0.8215066528434128\n",
      "[EPOCH #26, step #2410] loss: 0.8214061222275181\n",
      "[EPOCH #26, step #2412] loss: 0.8213481868864637\n",
      "[EPOCH #26, step #2414] loss: 0.8213066756231691\n",
      "[EPOCH #26, step #2416] loss: 0.8213445345108599\n",
      "[EPOCH #26, step #2418] loss: 0.821273637919349\n",
      "[EPOCH #26, step #2420] loss: 0.8210555060202305\n",
      "[EPOCH #26, step #2422] loss: 0.8210108791359977\n",
      "[EPOCH #26, step #2424] loss: 0.8211213157349027\n",
      "[EPOCH #26, step #2426] loss: 0.821060076141043\n",
      "[EPOCH #26, step #2428] loss: 0.821061706459537\n",
      "[EPOCH #26, step #2430] loss: 0.8211576110269247\n",
      "[EPOCH #26, step #2432] loss: 0.8211612808841567\n",
      "[EPOCH #26, step #2434] loss: 0.8212052005394773\n",
      "[EPOCH #26, step #2436] loss: 0.8211200097984694\n",
      "[EPOCH #26, step #2438] loss: 0.821115299405598\n",
      "[EPOCH #26, step #2440] loss: 0.8208952399977207\n",
      "[EPOCH #26, step #2442] loss: 0.8209428223512527\n",
      "[EPOCH #26, step #2444] loss: 0.820894458384114\n",
      "[EPOCH #26, step #2446] loss: 0.8206774463179066\n",
      "[EPOCH #26, step #2448] loss: 0.8204822382935703\n",
      "[EPOCH #26, step #2450] loss: 0.8205071328878889\n",
      "[EPOCH #26, step #2452] loss: 0.8204839515943602\n",
      "[EPOCH #26, step #2454] loss: 0.8203629277874156\n",
      "[EPOCH #26, step #2456] loss: 0.8203968453756619\n",
      "[EPOCH #26, step #2458] loss: 0.8203579846946821\n",
      "[EPOCH #26, step #2460] loss: 0.820304872276627\n",
      "[EPOCH #26, step #2462] loss: 0.820349596328867\n",
      "[EPOCH #26, step #2464] loss: 0.8201913706912956\n",
      "[EPOCH #26, step #2466] loss: 0.8202052308713853\n",
      "[EPOCH #26, step #2468] loss: 0.8200982237161534\n",
      "[EPOCH #26, step #2470] loss: 0.8200470058602488\n",
      "[EPOCH #26, step #2472] loss: 0.8198222419148363\n",
      "[EPOCH #26, step #2474] loss: 0.8197999170813898\n",
      "[EPOCH #26, step #2476] loss: 0.8200116431371406\n",
      "[EPOCH #26, step #2478] loss: 0.8199300054534399\n",
      "[EPOCH #26, step #2480] loss: 0.8197930928969854\n",
      "[EPOCH #26, step #2482] loss: 0.8197642290395352\n",
      "[EPOCH #26, step #2484] loss: 0.8196642541789433\n",
      "[EPOCH #26, step #2486] loss: 0.8199171553091396\n",
      "[EPOCH #26, step #2488] loss: 0.8198608737626005\n",
      "[EPOCH #26, step #2490] loss: 0.8197409719025357\n",
      "[EPOCH #26, step #2492] loss: 0.8198127332720659\n",
      "[EPOCH #26, step #2494] loss: 0.8196704154024144\n",
      "[EPOCH #26, step #2496] loss: 0.8195093048301563\n",
      "[EPOCH #26, step #2498] loss: 0.8193483578176105\n",
      "[EPOCH #26, elapsed time: 13126.835[sec]] loss: 0.8193024808526039\n",
      "[EPOCH #27, step #0] loss: 0.6184426546096802\n",
      "[EPOCH #27, step #2] loss: 0.5625668366750082\n",
      "[EPOCH #27, step #4] loss: 0.5994393110275269\n",
      "[EPOCH #27, step #6] loss: 0.5772117716925484\n",
      "[EPOCH #27, step #8] loss: 0.5888377891646491\n",
      "[EPOCH #27, step #10] loss: 0.675660561431538\n",
      "[EPOCH #27, step #12] loss: 0.681267133125892\n",
      "[EPOCH #27, step #14] loss: 0.7336742162704468\n",
      "[EPOCH #27, step #16] loss: 0.7313049873884987\n",
      "[EPOCH #27, step #18] loss: 0.762673872081857\n",
      "[EPOCH #27, step #20] loss: 0.7469303054468972\n",
      "[EPOCH #27, step #22] loss: 0.7501440501731375\n",
      "[EPOCH #27, step #24] loss: 0.7503545391559601\n",
      "[EPOCH #27, step #26] loss: 0.7649609038123378\n",
      "[EPOCH #27, step #28] loss: 0.7645178899682802\n",
      "[EPOCH #27, step #30] loss: 0.7766590243385684\n",
      "[EPOCH #27, step #32] loss: 0.778379092613856\n",
      "[EPOCH #27, step #34] loss: 0.7884844056197575\n",
      "[EPOCH #27, step #36] loss: 0.7940976869415592\n",
      "[EPOCH #27, step #38] loss: 0.7860621236837827\n",
      "[EPOCH #27, step #40] loss: 0.7840035346949973\n",
      "[EPOCH #27, step #42] loss: 0.784972898488821\n",
      "[EPOCH #27, step #44] loss: 0.7790619552135467\n",
      "[EPOCH #27, step #46] loss: 0.7707648974783877\n",
      "[EPOCH #27, step #48] loss: 0.7661535156016447\n",
      "[EPOCH #27, step #50] loss: 0.756537386599709\n",
      "[EPOCH #27, step #52] loss: 0.7499753534793854\n",
      "[EPOCH #27, step #54] loss: 0.741915534843098\n",
      "[EPOCH #27, step #56] loss: 0.7418336293153596\n",
      "[EPOCH #27, step #58] loss: 0.7375708565873614\n",
      "[EPOCH #27, step #60] loss: 0.7446792106159398\n",
      "[EPOCH #27, step #62] loss: 0.7477103159541175\n",
      "[EPOCH #27, step #64] loss: 0.7432153472533592\n",
      "[EPOCH #27, step #66] loss: 0.7535085224393588\n",
      "[EPOCH #27, step #68] loss: 0.7540403561315675\n",
      "[EPOCH #27, step #70] loss: 0.7534778982820646\n",
      "[EPOCH #27, step #72] loss: 0.7482891515509723\n",
      "[EPOCH #27, step #74] loss: 0.7438659715652466\n",
      "[EPOCH #27, step #76] loss: 0.7501748699646491\n",
      "[EPOCH #27, step #78] loss: 0.7477200061460084\n",
      "[EPOCH #27, step #80] loss: 0.7467667511951777\n",
      "[EPOCH #27, step #82] loss: 0.7502638905881399\n",
      "[EPOCH #27, step #84] loss: 0.7516154485590317\n",
      "[EPOCH #27, step #86] loss: 0.747026591465391\n",
      "[EPOCH #27, step #88] loss: 0.7526626580216912\n",
      "[EPOCH #27, step #90] loss: 0.7496112178970169\n",
      "[EPOCH #27, step #92] loss: 0.744619168261046\n",
      "[EPOCH #27, step #94] loss: 0.746239825926329\n",
      "[EPOCH #27, step #96] loss: 0.7459932326041546\n",
      "[EPOCH #27, step #98] loss: 0.7463128837672147\n",
      "[EPOCH #27, step #100] loss: 0.7416535515596371\n",
      "[EPOCH #27, step #102] loss: 0.7385714748530712\n",
      "[EPOCH #27, step #104] loss: 0.7421648093632289\n",
      "[EPOCH #27, step #106] loss: 0.745525543934831\n",
      "[EPOCH #27, step #108] loss: 0.7468862971034619\n",
      "[EPOCH #27, step #110] loss: 0.7443380723665426\n",
      "[EPOCH #27, step #112] loss: 0.7487152121235839\n",
      "[EPOCH #27, step #114] loss: 0.7486763562845147\n",
      "[EPOCH #27, step #116] loss: 0.7494534811912439\n",
      "[EPOCH #27, step #118] loss: 0.7469521237521612\n",
      "[EPOCH #27, step #120] loss: 0.749607621884543\n",
      "[EPOCH #27, step #122] loss: 0.7508338755223809\n",
      "[EPOCH #27, step #124] loss: 0.7490561950206757\n",
      "[EPOCH #27, step #126] loss: 0.7500948063501223\n",
      "[EPOCH #27, step #128] loss: 0.7495269722254702\n",
      "[EPOCH #27, step #130] loss: 0.7518151149949954\n",
      "[EPOCH #27, step #132] loss: 0.7488630443139184\n",
      "[EPOCH #27, step #134] loss: 0.7480072072258702\n",
      "[EPOCH #27, step #136] loss: 0.7502885871995104\n",
      "[EPOCH #27, step #138] loss: 0.7468252010482679\n",
      "[EPOCH #27, step #140] loss: 0.7446174777991382\n",
      "[EPOCH #27, step #142] loss: 0.7480727192405221\n",
      "[EPOCH #27, step #144] loss: 0.7489813245576004\n",
      "[EPOCH #27, step #146] loss: 0.7479117717467197\n",
      "[EPOCH #27, step #148] loss: 0.7467860013446552\n",
      "[EPOCH #27, step #150] loss: 0.7465582705096693\n",
      "[EPOCH #27, step #152] loss: 0.7487313079288582\n",
      "[EPOCH #27, step #154] loss: 0.7504826043882677\n",
      "[EPOCH #27, step #156] loss: 0.753111001982051\n",
      "[EPOCH #27, step #158] loss: 0.7521379625647323\n",
      "[EPOCH #27, step #160] loss: 0.7551905803428673\n",
      "[EPOCH #27, step #162] loss: 0.7565659597241805\n",
      "[EPOCH #27, step #164] loss: 0.7576862044406659\n",
      "[EPOCH #27, step #166] loss: 0.7588364062551967\n",
      "[EPOCH #27, step #168] loss: 0.7591307627026146\n",
      "[EPOCH #27, step #170] loss: 0.7637593075197343\n",
      "[EPOCH #27, step #172] loss: 0.7635016784158056\n",
      "[EPOCH #27, step #174] loss: 0.7635291990212032\n",
      "[EPOCH #27, step #176] loss: 0.7632004731455765\n",
      "[EPOCH #27, step #178] loss: 0.7609599587304632\n",
      "[EPOCH #27, step #180] loss: 0.7604739693976239\n",
      "[EPOCH #27, step #182] loss: 0.7644398728680741\n",
      "[EPOCH #27, step #184] loss: 0.7639603835505409\n",
      "[EPOCH #27, step #186] loss: 0.7631011928785294\n",
      "[EPOCH #27, step #188] loss: 0.7656414983449159\n",
      "[EPOCH #27, step #190] loss: 0.7653074796599243\n",
      "[EPOCH #27, step #192] loss: 0.7654989905307947\n",
      "[EPOCH #27, step #194] loss: 0.7658991883962583\n",
      "[EPOCH #27, step #196] loss: 0.76451014534471\n",
      "[EPOCH #27, step #198] loss: 0.7648400872496505\n",
      "[EPOCH #27, step #200] loss: 0.7662548044724251\n",
      "[EPOCH #27, step #202] loss: 0.7634263712490721\n",
      "[EPOCH #27, step #204] loss: 0.7669497453584904\n",
      "[EPOCH #27, step #206] loss: 0.7675386147510602\n",
      "[EPOCH #27, step #208] loss: 0.7676325752689508\n",
      "[EPOCH #27, step #210] loss: 0.768132620089427\n",
      "[EPOCH #27, step #212] loss: 0.7713401713561564\n",
      "[EPOCH #27, step #214] loss: 0.7721401529256687\n",
      "[EPOCH #27, step #216] loss: 0.7737238628249015\n",
      "[EPOCH #27, step #218] loss: 0.7740757062554904\n",
      "[EPOCH #27, step #220] loss: 0.7732017552690809\n",
      "[EPOCH #27, step #222] loss: 0.7716251384517002\n",
      "[EPOCH #27, step #224] loss: 0.7710813071992663\n",
      "[EPOCH #27, step #226] loss: 0.7723731561379286\n",
      "[EPOCH #27, step #228] loss: 0.77126624334327\n",
      "[EPOCH #27, step #230] loss: 0.7716048109583008\n",
      "[EPOCH #27, step #232] loss: 0.7725656636283121\n",
      "[EPOCH #27, step #234] loss: 0.7728022243114228\n",
      "[EPOCH #27, step #236] loss: 0.7741068123765132\n",
      "[EPOCH #27, step #238] loss: 0.775893251516829\n",
      "[EPOCH #27, step #240] loss: 0.7743739913608029\n",
      "[EPOCH #27, step #242] loss: 0.7737735002129166\n",
      "[EPOCH #27, step #244] loss: 0.7748459687038344\n",
      "[EPOCH #27, step #246] loss: 0.773390693703161\n",
      "[EPOCH #27, step #248] loss: 0.7747998962919396\n",
      "[EPOCH #27, step #250] loss: 0.7746540554966109\n",
      "[EPOCH #27, step #252] loss: 0.7749767812344397\n",
      "[EPOCH #27, step #254] loss: 0.7754204962767807\n",
      "[EPOCH #27, step #256] loss: 0.7742739952955728\n",
      "[EPOCH #27, step #258] loss: 0.7732206654364538\n",
      "[EPOCH #27, step #260] loss: 0.7729944273886553\n",
      "[EPOCH #27, step #262] loss: 0.7735184619181963\n",
      "[EPOCH #27, step #264] loss: 0.7739419469293558\n",
      "[EPOCH #27, step #266] loss: 0.7733842261721579\n",
      "[EPOCH #27, step #268] loss: 0.7741151332412067\n",
      "[EPOCH #27, step #270] loss: 0.7733356229053652\n",
      "[EPOCH #27, step #272] loss: 0.7735732828741109\n",
      "[EPOCH #27, step #274] loss: 0.7748167222196406\n",
      "[EPOCH #27, step #276] loss: 0.7737573109809242\n",
      "[EPOCH #27, step #278] loss: 0.7752992329204381\n",
      "[EPOCH #27, step #280] loss: 0.7753892835773183\n",
      "[EPOCH #27, step #282] loss: 0.7760436374812582\n",
      "[EPOCH #27, step #284] loss: 0.7742633741152914\n",
      "[EPOCH #27, step #286] loss: 0.774307087634914\n",
      "[EPOCH #27, step #288] loss: 0.7763368938002206\n",
      "[EPOCH #27, step #290] loss: 0.7780668287957248\n",
      "[EPOCH #27, step #292] loss: 0.7769786315769872\n",
      "[EPOCH #27, step #294] loss: 0.7755030826996949\n",
      "[EPOCH #27, step #296] loss: 0.7764926848788856\n",
      "[EPOCH #27, step #298] loss: 0.7757786489450015\n",
      "[EPOCH #27, step #300] loss: 0.7745015462767643\n",
      "[EPOCH #27, step #302] loss: 0.7753253962733958\n",
      "[EPOCH #27, step #304] loss: 0.7748534935419676\n",
      "[EPOCH #27, step #306] loss: 0.7759318543956023\n",
      "[EPOCH #27, step #308] loss: 0.7760995618733774\n",
      "[EPOCH #27, step #310] loss: 0.7771608752836369\n",
      "[EPOCH #27, step #312] loss: 0.7762360555676225\n",
      "[EPOCH #27, step #314] loss: 0.775727575355106\n",
      "[EPOCH #27, step #316] loss: 0.7768205970243701\n",
      "[EPOCH #27, step #318] loss: 0.7773516630304271\n",
      "[EPOCH #27, step #320] loss: 0.7787727656022781\n",
      "[EPOCH #27, step #322] loss: 0.7779542772393477\n",
      "[EPOCH #27, step #324] loss: 0.7769143264110272\n",
      "[EPOCH #27, step #326] loss: 0.7768588069746618\n",
      "[EPOCH #27, step #328] loss: 0.7772290974764838\n",
      "[EPOCH #27, step #330] loss: 0.778142894502853\n",
      "[EPOCH #27, step #332] loss: 0.777568624900268\n",
      "[EPOCH #27, step #334] loss: 0.7769015443858815\n",
      "[EPOCH #27, step #336] loss: 0.7760857926455025\n",
      "[EPOCH #27, step #338] loss: 0.775508965274929\n",
      "[EPOCH #27, step #340] loss: 0.7745803927571193\n",
      "[EPOCH #27, step #342] loss: 0.7746787139868945\n",
      "[EPOCH #27, step #344] loss: 0.7742482224236364\n",
      "[EPOCH #27, step #346] loss: 0.7727595509301002\n",
      "[EPOCH #27, step #348] loss: 0.7732168663197055\n",
      "[EPOCH #27, step #350] loss: 0.7735476014960525\n",
      "[EPOCH #27, step #352] loss: 0.7747761353892577\n",
      "[EPOCH #27, step #354] loss: 0.7741565041139092\n",
      "[EPOCH #27, step #356] loss: 0.7736302949801213\n",
      "[EPOCH #27, step #358] loss: 0.7733044855109829\n",
      "[EPOCH #27, step #360] loss: 0.7733443785572316\n",
      "[EPOCH #27, step #362] loss: 0.7739430718513888\n",
      "[EPOCH #27, step #364] loss: 0.7740001164070548\n",
      "[EPOCH #27, step #366] loss: 0.773710696184018\n",
      "[EPOCH #27, step #368] loss: 0.7736745636637617\n",
      "[EPOCH #27, step #370] loss: 0.7748267197544684\n",
      "[EPOCH #27, step #372] loss: 0.7762120973328802\n",
      "[EPOCH #27, step #374] loss: 0.7758903433481852\n",
      "[EPOCH #27, step #376] loss: 0.7774926825606855\n",
      "[EPOCH #27, step #378] loss: 0.7767436720607778\n",
      "[EPOCH #27, step #380] loss: 0.7771256781156295\n",
      "[EPOCH #27, step #382] loss: 0.7770340703330526\n",
      "[EPOCH #27, step #384] loss: 0.7780927497845191\n",
      "[EPOCH #27, step #386] loss: 0.7774716333055373\n",
      "[EPOCH #27, step #388] loss: 0.7786483094287715\n",
      "[EPOCH #27, step #390] loss: 0.7788089221853125\n",
      "[EPOCH #27, step #392] loss: 0.7798271407456192\n",
      "[EPOCH #27, step #394] loss: 0.7801101214523557\n",
      "[EPOCH #27, step #396] loss: 0.7800811699565772\n",
      "[EPOCH #27, step #398] loss: 0.7802058424716606\n",
      "[EPOCH #27, step #400] loss: 0.7797093752613686\n",
      "[EPOCH #27, step #402] loss: 0.7797664897909236\n",
      "[EPOCH #27, step #404] loss: 0.779727738580586\n",
      "[EPOCH #27, step #406] loss: 0.7794310118115212\n",
      "[EPOCH #27, step #408] loss: 0.7791652689644644\n",
      "[EPOCH #27, step #410] loss: 0.778229602351966\n",
      "[EPOCH #27, step #412] loss: 0.7774805521127964\n",
      "[EPOCH #27, step #414] loss: 0.7768773407103068\n",
      "[EPOCH #27, step #416] loss: 0.7769270562868325\n",
      "[EPOCH #27, step #418] loss: 0.7764203829384078\n",
      "[EPOCH #27, step #420] loss: 0.7764473558180123\n",
      "[EPOCH #27, step #422] loss: 0.7770343625094592\n",
      "[EPOCH #27, step #424] loss: 0.7768717075095457\n",
      "[EPOCH #27, step #426] loss: 0.7756076483034139\n",
      "[EPOCH #27, step #428] loss: 0.7753837429560148\n",
      "[EPOCH #27, step #430] loss: 0.7757851069322041\n",
      "[EPOCH #27, step #432] loss: 0.7759644899852832\n",
      "[EPOCH #27, step #434] loss: 0.7763310277599028\n",
      "[EPOCH #27, step #436] loss: 0.7756638336645384\n",
      "[EPOCH #27, step #438] loss: 0.7755509811137423\n",
      "[EPOCH #27, step #440] loss: 0.7760683167683564\n",
      "[EPOCH #27, step #442] loss: 0.7761183855361379\n",
      "[EPOCH #27, step #444] loss: 0.775701913204086\n",
      "[EPOCH #27, step #446] loss: 0.7767629706752913\n",
      "[EPOCH #27, step #448] loss: 0.7768535165983212\n",
      "[EPOCH #27, step #450] loss: 0.777147452278835\n",
      "[EPOCH #27, step #452] loss: 0.777382921106768\n",
      "[EPOCH #27, step #454] loss: 0.7765458351308173\n",
      "[EPOCH #27, step #456] loss: 0.7764081111752491\n",
      "[EPOCH #27, step #458] loss: 0.778099509301009\n",
      "[EPOCH #27, step #460] loss: 0.7776877994521838\n",
      "[EPOCH #27, step #462] loss: 0.7788552453270742\n",
      "[EPOCH #27, step #464] loss: 0.7791972572444588\n",
      "[EPOCH #27, step #466] loss: 0.778881619331413\n",
      "[EPOCH #27, step #468] loss: 0.7790860069840193\n",
      "[EPOCH #27, step #470] loss: 0.7783299103663985\n",
      "[EPOCH #27, step #472] loss: 0.778214378916436\n",
      "[EPOCH #27, step #474] loss: 0.7772126574265329\n",
      "[EPOCH #27, step #476] loss: 0.7763289559312336\n",
      "[EPOCH #27, step #478] loss: 0.7764870545560483\n",
      "[EPOCH #27, step #480] loss: 0.7764398282134359\n",
      "[EPOCH #27, step #482] loss: 0.7763243497775455\n",
      "[EPOCH #27, step #484] loss: 0.7772485150504358\n",
      "[EPOCH #27, step #486] loss: 0.7765836808715758\n",
      "[EPOCH #27, step #488] loss: 0.7781118195968659\n",
      "[EPOCH #27, step #490] loss: 0.7777759037046957\n",
      "[EPOCH #27, step #492] loss: 0.7777678521603164\n",
      "[EPOCH #27, step #494] loss: 0.7771042204866505\n",
      "[EPOCH #27, step #496] loss: 0.7781272637292413\n",
      "[EPOCH #27, step #498] loss: 0.7782201567489303\n",
      "[EPOCH #27, step #500] loss: 0.7781994402289628\n",
      "[EPOCH #27, step #502] loss: 0.7783747712376103\n",
      "[EPOCH #27, step #504] loss: 0.77796735621915\n",
      "[EPOCH #27, step #506] loss: 0.7775643165765195\n",
      "[EPOCH #27, step #508] loss: 0.7761874169052702\n",
      "[EPOCH #27, step #510] loss: 0.7762194145798916\n",
      "[EPOCH #27, step #512] loss: 0.7758771286257061\n",
      "[EPOCH #27, step #514] loss: 0.775609405121757\n",
      "[EPOCH #27, step #516] loss: 0.7750951867384883\n",
      "[EPOCH #27, step #518] loss: 0.7752201295886655\n",
      "[EPOCH #27, step #520] loss: 0.7750568094157441\n",
      "[EPOCH #27, step #522] loss: 0.7757786116340192\n",
      "[EPOCH #27, step #524] loss: 0.7761803478854044\n",
      "[EPOCH #27, step #526] loss: 0.7759117425845289\n",
      "[EPOCH #27, step #528] loss: 0.7769165270607954\n",
      "[EPOCH #27, step #530] loss: 0.7769655474722946\n",
      "[EPOCH #27, step #532] loss: 0.7764688695013858\n",
      "[EPOCH #27, step #534] loss: 0.7763304654125855\n",
      "[EPOCH #27, step #536] loss: 0.777043080252198\n",
      "[EPOCH #27, step #538] loss: 0.7771029952837496\n",
      "[EPOCH #27, step #540] loss: 0.7779753241763758\n",
      "[EPOCH #27, step #542] loss: 0.7780731463629896\n",
      "[EPOCH #27, step #544] loss: 0.7772043947232973\n",
      "[EPOCH #27, step #546] loss: 0.7771680899359409\n",
      "[EPOCH #27, step #548] loss: 0.7758253196115268\n",
      "[EPOCH #27, step #550] loss: 0.7757066994526858\n",
      "[EPOCH #27, step #552] loss: 0.7755239387101764\n",
      "[EPOCH #27, step #554] loss: 0.7746858534512219\n",
      "[EPOCH #27, step #556] loss: 0.774533348515817\n",
      "[EPOCH #27, step #558] loss: 0.7742478444452576\n",
      "[EPOCH #27, step #560] loss: 0.7741308737141138\n",
      "[EPOCH #27, step #562] loss: 0.7733563174680537\n",
      "[EPOCH #27, step #564] loss: 0.7741638997487262\n",
      "[EPOCH #27, step #566] loss: 0.7745563876166335\n",
      "[EPOCH #27, step #568] loss: 0.7739436858462952\n",
      "[EPOCH #27, step #570] loss: 0.7736718255354519\n",
      "[EPOCH #27, step #572] loss: 0.7732896261294266\n",
      "[EPOCH #27, step #574] loss: 0.7736030800964522\n",
      "[EPOCH #27, step #576] loss: 0.772818700021433\n",
      "[EPOCH #27, step #578] loss: 0.772322394635805\n",
      "[EPOCH #27, step #580] loss: 0.7721680247332265\n",
      "[EPOCH #27, step #582] loss: 0.7724716226293946\n",
      "[EPOCH #27, step #584] loss: 0.7729532193424355\n",
      "[EPOCH #27, step #586] loss: 0.7728537238334675\n",
      "[EPOCH #27, step #588] loss: 0.7729236716831479\n",
      "[EPOCH #27, step #590] loss: 0.7729822784006697\n",
      "[EPOCH #27, step #592] loss: 0.7722079981036774\n",
      "[EPOCH #27, step #594] loss: 0.7722591168740216\n",
      "[EPOCH #27, step #596] loss: 0.7724329702418853\n",
      "[EPOCH #27, step #598] loss: 0.7727667260448602\n",
      "[EPOCH #27, step #600] loss: 0.7727747848148949\n",
      "[EPOCH #27, step #602] loss: 0.7722356408389647\n",
      "[EPOCH #27, step #604] loss: 0.7719689583975422\n",
      "[EPOCH #27, step #606] loss: 0.7726132724391177\n",
      "[EPOCH #27, step #608] loss: 0.7719546222236552\n",
      "[EPOCH #27, step #610] loss: 0.7715973498485678\n",
      "[EPOCH #27, step #612] loss: 0.7713764691527866\n",
      "[EPOCH #27, step #614] loss: 0.7703844394625687\n",
      "[EPOCH #27, step #616] loss: 0.7700447118939225\n",
      "[EPOCH #27, step #618] loss: 0.770409454195873\n",
      "[EPOCH #27, step #620] loss: 0.7712545191896134\n",
      "[EPOCH #27, step #622] loss: 0.7705345559464604\n",
      "[EPOCH #27, step #624] loss: 0.770355385875702\n",
      "[EPOCH #27, step #626] loss: 0.770720314181022\n",
      "[EPOCH #27, step #628] loss: 0.7700661081104097\n",
      "[EPOCH #27, step #630] loss: 0.7696023736910661\n",
      "[EPOCH #27, step #632] loss: 0.770602490429253\n",
      "[EPOCH #27, step #634] loss: 0.7716214737084907\n",
      "[EPOCH #27, step #636] loss: 0.771047440999344\n",
      "[EPOCH #27, step #638] loss: 0.7706323292613589\n",
      "[EPOCH #27, step #640] loss: 0.7707520825163623\n",
      "[EPOCH #27, step #642] loss: 0.7705559800516576\n",
      "[EPOCH #27, step #644] loss: 0.7702170500921649\n",
      "[EPOCH #27, step #646] loss: 0.770705867357195\n",
      "[EPOCH #27, step #648] loss: 0.7708432421386701\n",
      "[EPOCH #27, step #650] loss: 0.7713979578329487\n",
      "[EPOCH #27, step #652] loss: 0.7715439819723687\n",
      "[EPOCH #27, step #654] loss: 0.7717806887535649\n",
      "[EPOCH #27, step #656] loss: 0.7715714284909189\n",
      "[EPOCH #27, step #658] loss: 0.771310099113693\n",
      "[EPOCH #27, step #660] loss: 0.7728665818695581\n",
      "[EPOCH #27, step #662] loss: 0.7729353800887975\n",
      "[EPOCH #27, step #664] loss: 0.7729022608215648\n",
      "[EPOCH #27, step #666] loss: 0.7732365697488256\n",
      "[EPOCH #27, step #668] loss: 0.7728353497782452\n",
      "[EPOCH #27, step #670] loss: 0.7721276969472627\n",
      "[EPOCH #27, step #672] loss: 0.7721603797502362\n",
      "[EPOCH #27, step #674] loss: 0.7720393694330144\n",
      "[EPOCH #27, step #676] loss: 0.7717986744739104\n",
      "[EPOCH #27, step #678] loss: 0.771587032325489\n",
      "[EPOCH #27, step #680] loss: 0.7715826312438332\n",
      "[EPOCH #27, step #682] loss: 0.7725816035253237\n",
      "[EPOCH #27, step #684] loss: 0.773586597103272\n",
      "[EPOCH #27, step #686] loss: 0.773394962802551\n",
      "[EPOCH #27, step #688] loss: 0.7738123347087937\n",
      "[EPOCH #27, step #690] loss: 0.7736453843962093\n",
      "[EPOCH #27, step #692] loss: 0.7734731942802281\n",
      "[EPOCH #27, step #694] loss: 0.7730923606766213\n",
      "[EPOCH #27, step #696] loss: 0.7730463177521567\n",
      "[EPOCH #27, step #698] loss: 0.7726550756691181\n",
      "[EPOCH #27, step #700] loss: 0.7723095273750484\n",
      "[EPOCH #27, step #702] loss: 0.7727120519956179\n",
      "[EPOCH #27, step #704] loss: 0.7723213284996384\n",
      "[EPOCH #27, step #706] loss: 0.772161383482152\n",
      "[EPOCH #27, step #708] loss: 0.7721900322457463\n",
      "[EPOCH #27, step #710] loss: 0.7717180524110459\n",
      "[EPOCH #27, step #712] loss: 0.7714633179663943\n",
      "[EPOCH #27, step #714] loss: 0.7714799357877745\n",
      "[EPOCH #27, step #716] loss: 0.7708150896982834\n",
      "[EPOCH #27, step #718] loss: 0.7701083542325732\n",
      "[EPOCH #27, step #720] loss: 0.7695666173377415\n",
      "[EPOCH #27, step #722] loss: 0.7697017507351945\n",
      "[EPOCH #27, step #724] loss: 0.7698540890216827\n",
      "[EPOCH #27, step #726] loss: 0.7696439315151151\n",
      "[EPOCH #27, step #728] loss: 0.7694432077666206\n",
      "[EPOCH #27, step #730] loss: 0.7696004395364248\n",
      "[EPOCH #27, step #732] loss: 0.7690237043743081\n",
      "[EPOCH #27, step #734] loss: 0.7686074052132716\n",
      "[EPOCH #27, step #736] loss: 0.7686552731686725\n",
      "[EPOCH #27, step #738] loss: 0.7691929831153163\n",
      "[EPOCH #27, step #740] loss: 0.7691963907436803\n",
      "[EPOCH #27, step #742] loss: 0.7688107167647633\n",
      "[EPOCH #27, step #744] loss: 0.7692153543833918\n",
      "[EPOCH #27, step #746] loss: 0.7697597439269943\n",
      "[EPOCH #27, step #748] loss: 0.76977262808102\n",
      "[EPOCH #27, step #750] loss: 0.7698475199834643\n",
      "[EPOCH #27, step #752] loss: 0.7700169814297877\n",
      "[EPOCH #27, step #754] loss: 0.7701135338931684\n",
      "[EPOCH #27, step #756] loss: 0.7699008062383458\n",
      "[EPOCH #27, step #758] loss: 0.7701039447379207\n",
      "[EPOCH #27, step #760] loss: 0.769789008719849\n",
      "[EPOCH #27, step #762] loss: 0.7697411123687599\n",
      "[EPOCH #27, step #764] loss: 0.7694524434267306\n",
      "[EPOCH #27, step #766] loss: 0.769046998202723\n",
      "[EPOCH #27, step #768] loss: 0.7690391587420464\n",
      "[EPOCH #27, step #770] loss: 0.7688645936558374\n",
      "[EPOCH #27, step #772] loss: 0.7688131630420685\n",
      "[EPOCH #27, step #774] loss: 0.7686899231710742\n",
      "[EPOCH #27, step #776] loss: 0.7682459917077686\n",
      "[EPOCH #27, step #778] loss: 0.7679450451868642\n",
      "[EPOCH #27, step #780] loss: 0.7677074078942688\n",
      "[EPOCH #27, step #782] loss: 0.768065867410309\n",
      "[EPOCH #27, step #784] loss: 0.7682006351127746\n",
      "[EPOCH #27, step #786] loss: 0.768297784399653\n",
      "[EPOCH #27, step #788] loss: 0.7685724226769688\n",
      "[EPOCH #27, step #790] loss: 0.7682209630907713\n",
      "[EPOCH #27, step #792] loss: 0.7683841839038108\n",
      "[EPOCH #27, step #794] loss: 0.7687240585216186\n",
      "[EPOCH #27, step #796] loss: 0.7683447634934482\n",
      "[EPOCH #27, step #798] loss: 0.7680406482034691\n",
      "[EPOCH #27, step #800] loss: 0.7680450489235281\n",
      "[EPOCH #27, step #802] loss: 0.7680181254114339\n",
      "[EPOCH #27, step #804] loss: 0.7680398448283627\n",
      "[EPOCH #27, step #806] loss: 0.7679440424566375\n",
      "[EPOCH #27, step #808] loss: 0.7679410679599705\n",
      "[EPOCH #27, step #810] loss: 0.768348932302983\n",
      "[EPOCH #27, step #812] loss: 0.7680320280431088\n",
      "[EPOCH #27, step #814] loss: 0.7677018432163754\n",
      "[EPOCH #27, step #816] loss: 0.7677598904585751\n",
      "[EPOCH #27, step #818] loss: 0.7668536263944465\n",
      "[EPOCH #27, step #820] loss: 0.7667475546030702\n",
      "[EPOCH #27, step #822] loss: 0.7661811889014586\n",
      "[EPOCH #27, step #824] loss: 0.7660960503058\n",
      "[EPOCH #27, step #826] loss: 0.7662576600602922\n",
      "[EPOCH #27, step #828] loss: 0.7664413994989292\n",
      "[EPOCH #27, step #830] loss: 0.7666396317929567\n",
      "[EPOCH #27, step #832] loss: 0.7660574407494511\n",
      "[EPOCH #27, step #834] loss: 0.76595971480815\n",
      "[EPOCH #27, step #836] loss: 0.765643498696734\n",
      "[EPOCH #27, step #838] loss: 0.7656347462119306\n",
      "[EPOCH #27, step #840] loss: 0.7658535800918529\n",
      "[EPOCH #27, step #842] loss: 0.7664852411367998\n",
      "[EPOCH #27, step #844] loss: 0.7665141089780796\n",
      "[EPOCH #27, step #846] loss: 0.7667072523372092\n",
      "[EPOCH #27, step #848] loss: 0.7671852276448788\n",
      "[EPOCH #27, step #850] loss: 0.7669785539986244\n",
      "[EPOCH #27, step #852] loss: 0.7669723180296273\n",
      "[EPOCH #27, step #854] loss: 0.7676704488651097\n",
      "[EPOCH #27, step #856] loss: 0.7682630728882419\n",
      "[EPOCH #27, step #858] loss: 0.7682621072765279\n",
      "[EPOCH #27, step #860] loss: 0.7680315795191213\n",
      "[EPOCH #27, step #862] loss: 0.7682119472209161\n",
      "[EPOCH #27, step #864] loss: 0.7687712665582668\n",
      "[EPOCH #27, step #866] loss: 0.7688333281802471\n",
      "[EPOCH #27, step #868] loss: 0.7687221677380135\n",
      "[EPOCH #27, step #870] loss: 0.7684868572773808\n",
      "[EPOCH #27, step #872] loss: 0.7689775373244749\n",
      "[EPOCH #27, step #874] loss: 0.7687832982199533\n",
      "[EPOCH #27, step #876] loss: 0.7687181856912245\n",
      "[EPOCH #27, step #878] loss: 0.768687097421414\n",
      "[EPOCH #27, step #880] loss: 0.7687546601360421\n",
      "[EPOCH #27, step #882] loss: 0.7688515356415936\n",
      "[EPOCH #27, step #884] loss: 0.7682534092900444\n",
      "[EPOCH #27, step #886] loss: 0.7686445538664348\n",
      "[EPOCH #27, step #888] loss: 0.7684257478024747\n",
      "[EPOCH #27, step #890] loss: 0.7682061227149299\n",
      "[EPOCH #27, step #892] loss: 0.7683356576844266\n",
      "[EPOCH #27, step #894] loss: 0.7683502001136375\n",
      "[EPOCH #27, step #896] loss: 0.7681380005650962\n",
      "[EPOCH #27, step #898] loss: 0.7683208678601449\n",
      "[EPOCH #27, step #900] loss: 0.7689692668128887\n",
      "[EPOCH #27, step #902] loss: 0.7696441272366482\n",
      "[EPOCH #27, step #904] loss: 0.7698221271538602\n",
      "[EPOCH #27, step #906] loss: 0.7696369304480862\n",
      "[EPOCH #27, step #908] loss: 0.769567656798987\n",
      "[EPOCH #27, step #910] loss: 0.76897041955973\n",
      "[EPOCH #27, step #912] loss: 0.7688251385161284\n",
      "[EPOCH #27, step #914] loss: 0.7692646527550911\n",
      "[EPOCH #27, step #916] loss: 0.7697325771351547\n",
      "[EPOCH #27, step #918] loss: 0.7694358835088027\n",
      "[EPOCH #27, step #920] loss: 0.7691790205583251\n",
      "[EPOCH #27, step #922] loss: 0.7693061552546264\n",
      "[EPOCH #27, step #924] loss: 0.7691061276680714\n",
      "[EPOCH #27, step #926] loss: 0.7688998481923837\n",
      "[EPOCH #27, step #928] loss: 0.7687212488943845\n",
      "[EPOCH #27, step #930] loss: 0.7686946584766072\n",
      "[EPOCH #27, step #932] loss: 0.7687796540837835\n",
      "[EPOCH #27, step #934] loss: 0.7687492349887277\n",
      "[EPOCH #27, step #936] loss: 0.7682491819848373\n",
      "[EPOCH #27, step #938] loss: 0.767788810693164\n",
      "[EPOCH #27, step #940] loss: 0.7680001764001045\n",
      "[EPOCH #27, step #942] loss: 0.7682545657564954\n",
      "[EPOCH #27, step #944] loss: 0.768405831900854\n",
      "[EPOCH #27, step #946] loss: 0.7685316492977464\n",
      "[EPOCH #27, step #948] loss: 0.768743347977185\n",
      "[EPOCH #27, step #950] loss: 0.7680891052468216\n",
      "[EPOCH #27, step #952] loss: 0.7681955166966318\n",
      "[EPOCH #27, step #954] loss: 0.7680311288821136\n",
      "[EPOCH #27, step #956] loss: 0.7677169567053844\n",
      "[EPOCH #27, step #958] loss: 0.767488537882615\n",
      "[EPOCH #27, step #960] loss: 0.7676747375236713\n",
      "[EPOCH #27, step #962] loss: 0.7674628843090121\n",
      "[EPOCH #27, step #964] loss: 0.7670899721316106\n",
      "[EPOCH #27, step #966] loss: 0.7669648860023581\n",
      "[EPOCH #27, step #968] loss: 0.7674784431209013\n",
      "[EPOCH #27, step #970] loss: 0.7673500447575268\n",
      "[EPOCH #27, step #972] loss: 0.7673650194353827\n",
      "[EPOCH #27, step #974] loss: 0.7679234495835426\n",
      "[EPOCH #27, step #976] loss: 0.7678072091988922\n",
      "[EPOCH #27, step #978] loss: 0.7677868823230692\n",
      "[EPOCH #27, step #980] loss: 0.7676910463337019\n",
      "[EPOCH #27, step #982] loss: 0.7678230176258184\n",
      "[EPOCH #27, step #984] loss: 0.7679499665492683\n",
      "[EPOCH #27, step #986] loss: 0.7678673001045876\n",
      "[EPOCH #27, step #988] loss: 0.767666421476582\n",
      "[EPOCH #27, step #990] loss: 0.7681590714440216\n",
      "[EPOCH #27, step #992] loss: 0.7676347778643006\n",
      "[EPOCH #27, step #994] loss: 0.7676910849072826\n",
      "[EPOCH #27, step #996] loss: 0.7677620482540417\n",
      "[EPOCH #27, step #998] loss: 0.7679215803280011\n",
      "[EPOCH #27, step #1000] loss: 0.768162131726325\n",
      "[EPOCH #27, step #1002] loss: 0.7679738469518431\n",
      "[EPOCH #27, step #1004] loss: 0.7678827404975891\n",
      "[EPOCH #27, step #1006] loss: 0.7680411911176475\n",
      "[EPOCH #27, step #1008] loss: 0.7680628153212125\n",
      "[EPOCH #27, step #1010] loss: 0.7683613728344971\n",
      "[EPOCH #27, step #1012] loss: 0.7680555562041002\n",
      "[EPOCH #27, step #1014] loss: 0.7679942779940337\n",
      "[EPOCH #27, step #1016] loss: 0.7676830815120198\n",
      "[EPOCH #27, step #1018] loss: 0.7679244171648896\n",
      "[EPOCH #27, step #1020] loss: 0.7679749087418679\n",
      "[EPOCH #27, step #1022] loss: 0.7679400640091005\n",
      "[EPOCH #27, step #1024] loss: 0.7678475098784376\n",
      "[EPOCH #27, step #1026] loss: 0.767995779476008\n",
      "[EPOCH #27, step #1028] loss: 0.7685679541674485\n",
      "[EPOCH #27, step #1030] loss: 0.7682776024454896\n",
      "[EPOCH #27, step #1032] loss: 0.7682168048672154\n",
      "[EPOCH #27, step #1034] loss: 0.7683303076863864\n",
      "[EPOCH #27, step #1036] loss: 0.7684615864818098\n",
      "[EPOCH #27, step #1038] loss: 0.7682384131503174\n",
      "[EPOCH #27, step #1040] loss: 0.7684775681935401\n",
      "[EPOCH #27, step #1042] loss: 0.7682380797136092\n",
      "[EPOCH #27, step #1044] loss: 0.7684760224020653\n",
      "[EPOCH #27, step #1046] loss: 0.7691160603546482\n",
      "[EPOCH #27, step #1048] loss: 0.7689985084295046\n",
      "[EPOCH #27, step #1050] loss: 0.7689019505405971\n",
      "[EPOCH #27, step #1052] loss: 0.7691765056546257\n",
      "[EPOCH #27, step #1054] loss: 0.7697268538282945\n",
      "[EPOCH #27, step #1056] loss: 0.7696076785773743\n",
      "[EPOCH #27, step #1058] loss: 0.7691839633120806\n",
      "[EPOCH #27, step #1060] loss: 0.7688850693046541\n",
      "[EPOCH #27, step #1062] loss: 0.7687444160372607\n",
      "[EPOCH #27, step #1064] loss: 0.7688756145781754\n",
      "[EPOCH #27, step #1066] loss: 0.7689177695567516\n",
      "[EPOCH #27, step #1068] loss: 0.7687969851761471\n",
      "[EPOCH #27, step #1070] loss: 0.7687421705987718\n",
      "[EPOCH #27, step #1072] loss: 0.7691092582806626\n",
      "[EPOCH #27, step #1074] loss: 0.7694467174175174\n",
      "[EPOCH #27, step #1076] loss: 0.7689708432557966\n",
      "[EPOCH #27, step #1078] loss: 0.7690651296906388\n",
      "[EPOCH #27, step #1080] loss: 0.7689131893127964\n",
      "[EPOCH #27, step #1082] loss: 0.7686052475939827\n",
      "[EPOCH #27, step #1084] loss: 0.7685920310459928\n",
      "[EPOCH #27, step #1086] loss: 0.7684663680571422\n",
      "[EPOCH #27, step #1088] loss: 0.7682582610675892\n",
      "[EPOCH #27, step #1090] loss: 0.7683204325593797\n",
      "[EPOCH #27, step #1092] loss: 0.7683508423415216\n",
      "[EPOCH #27, step #1094] loss: 0.7683301950698573\n",
      "[EPOCH #27, step #1096] loss: 0.768600677020352\n",
      "[EPOCH #27, step #1098] loss: 0.7690877896531046\n",
      "[EPOCH #27, step #1100] loss: 0.7693852023792527\n",
      "[EPOCH #27, step #1102] loss: 0.7697027629867859\n",
      "[EPOCH #27, step #1104] loss: 0.7694798048804788\n",
      "[EPOCH #27, step #1106] loss: 0.7692977416159984\n",
      "[EPOCH #27, step #1108] loss: 0.7697204762584353\n",
      "[EPOCH #27, step #1110] loss: 0.7694734275394683\n",
      "[EPOCH #27, step #1112] loss: 0.769113330185574\n",
      "[EPOCH #27, step #1114] loss: 0.7689608952389704\n",
      "[EPOCH #27, step #1116] loss: 0.7692362913193186\n",
      "[EPOCH #27, step #1118] loss: 0.769206696477077\n",
      "[EPOCH #27, step #1120] loss: 0.7691905827367018\n",
      "[EPOCH #27, step #1122] loss: 0.7694411738207588\n",
      "[EPOCH #27, step #1124] loss: 0.7697382611433665\n",
      "[EPOCH #27, step #1126] loss: 0.7695560093833581\n",
      "[EPOCH #27, step #1128] loss: 0.7698147867346782\n",
      "[EPOCH #27, step #1130] loss: 0.7697617512008555\n",
      "[EPOCH #27, step #1132] loss: 0.7699737833173319\n",
      "[EPOCH #27, step #1134] loss: 0.7698491345680758\n",
      "[EPOCH #27, step #1136] loss: 0.7698964489428958\n",
      "[EPOCH #27, step #1138] loss: 0.7700097819134475\n",
      "[EPOCH #27, step #1140] loss: 0.7698771364066185\n",
      "[EPOCH #27, step #1142] loss: 0.7696802589263398\n",
      "[EPOCH #27, step #1144] loss: 0.7699268412121518\n",
      "[EPOCH #27, step #1146] loss: 0.7696028560425991\n",
      "[EPOCH #27, step #1148] loss: 0.7692341998517772\n",
      "[EPOCH #27, step #1150] loss: 0.7691240897394076\n",
      "[EPOCH #27, step #1152] loss: 0.7687694435003831\n",
      "[EPOCH #27, step #1154] loss: 0.7689807414492488\n",
      "[EPOCH #27, step #1156] loss: 0.7690223360123465\n",
      "[EPOCH #27, step #1158] loss: 0.7690698661816542\n",
      "[EPOCH #27, step #1160] loss: 0.7698218336298381\n",
      "[EPOCH #27, step #1162] loss: 0.7696865568976923\n",
      "[EPOCH #27, step #1164] loss: 0.7693796274488064\n",
      "[EPOCH #27, step #1166] loss: 0.7691795484776567\n",
      "[EPOCH #27, step #1168] loss: 0.769030079309302\n",
      "[EPOCH #27, step #1170] loss: 0.7688483292480293\n",
      "[EPOCH #27, step #1172] loss: 0.7689298127110149\n",
      "[EPOCH #27, step #1174] loss: 0.7691405212625544\n",
      "[EPOCH #27, step #1176] loss: 0.7694194109741671\n",
      "[EPOCH #27, step #1178] loss: 0.7696069031574647\n",
      "[EPOCH #27, step #1180] loss: 0.7697484505873026\n",
      "[EPOCH #27, step #1182] loss: 0.7696709301848584\n",
      "[EPOCH #27, step #1184] loss: 0.7698083058691226\n",
      "[EPOCH #27, step #1186] loss: 0.7697057211810837\n",
      "[EPOCH #27, step #1188] loss: 0.7701148182228897\n",
      "[EPOCH #27, step #1190] loss: 0.7705429198359562\n",
      "[EPOCH #27, step #1192] loss: 0.7703696837069502\n",
      "[EPOCH #27, step #1194] loss: 0.7701896905400264\n",
      "[EPOCH #27, step #1196] loss: 0.7701958757494526\n",
      "[EPOCH #27, step #1198] loss: 0.770307507437403\n",
      "[EPOCH #27, step #1200] loss: 0.7707759197010386\n",
      "[EPOCH #27, step #1202] loss: 0.7708300203456546\n",
      "[EPOCH #27, step #1204] loss: 0.7706918577435601\n",
      "[EPOCH #27, step #1206] loss: 0.7705794626657095\n",
      "[EPOCH #27, step #1208] loss: 0.7704759529053031\n",
      "[EPOCH #27, step #1210] loss: 0.7706391098182326\n",
      "[EPOCH #27, step #1212] loss: 0.7708294475658414\n",
      "[EPOCH #27, step #1214] loss: 0.7709278964701994\n",
      "[EPOCH #27, step #1216] loss: 0.7708395252535357\n",
      "[EPOCH #27, step #1218] loss: 0.7707600044216456\n",
      "[EPOCH #27, step #1220] loss: 0.7706225603013426\n",
      "[EPOCH #27, step #1222] loss: 0.7703920811634033\n",
      "[EPOCH #27, step #1224] loss: 0.7704947874740679\n",
      "[EPOCH #27, step #1226] loss: 0.7704858735458775\n",
      "[EPOCH #27, step #1228] loss: 0.7705193164631834\n",
      "[EPOCH #27, step #1230] loss: 0.7703252327480905\n",
      "[EPOCH #27, step #1232] loss: 0.7703833698211215\n",
      "[EPOCH #27, step #1234] loss: 0.7706984533230785\n",
      "[EPOCH #27, step #1236] loss: 0.7705769704876162\n",
      "[EPOCH #27, step #1238] loss: 0.7707040770531085\n",
      "[EPOCH #27, step #1240] loss: 0.7705348915721407\n",
      "[EPOCH #27, step #1242] loss: 0.770595980740706\n",
      "[EPOCH #27, step #1244] loss: 0.7709246654826475\n",
      "[EPOCH #27, step #1246] loss: 0.770883355173189\n",
      "[EPOCH #27, step #1248] loss: 0.7708739045622637\n",
      "[EPOCH #27, step #1250] loss: 0.771165424113651\n",
      "[EPOCH #27, step #1252] loss: 0.7711638292120822\n",
      "[EPOCH #27, step #1254] loss: 0.7711218234314862\n",
      "[EPOCH #27, step #1256] loss: 0.7708805528489389\n",
      "[EPOCH #27, step #1258] loss: 0.7709031467451\n",
      "[EPOCH #27, step #1260] loss: 0.7713547040081327\n",
      "[EPOCH #27, step #1262] loss: 0.771557386182927\n",
      "[EPOCH #27, step #1264] loss: 0.771640687945332\n",
      "[EPOCH #27, step #1266] loss: 0.771814193585395\n",
      "[EPOCH #27, step #1268] loss: 0.7716900784026177\n",
      "[EPOCH #27, step #1270] loss: 0.7717482936513602\n",
      "[EPOCH #27, step #1272] loss: 0.771813943525608\n",
      "[EPOCH #27, step #1274] loss: 0.7717412687049192\n",
      "[EPOCH #27, step #1276] loss: 0.7719572624986585\n",
      "[EPOCH #27, step #1278] loss: 0.7719219407362338\n",
      "[EPOCH #27, step #1280] loss: 0.7717323785969096\n",
      "[EPOCH #27, step #1282] loss: 0.7715071245319474\n",
      "[EPOCH #27, step #1284] loss: 0.771597567119487\n",
      "[EPOCH #27, step #1286] loss: 0.7714311707223582\n",
      "[EPOCH #27, step #1288] loss: 0.7712908122916847\n",
      "[EPOCH #27, step #1290] loss: 0.7713382302976043\n",
      "[EPOCH #27, step #1292] loss: 0.7710001479491465\n",
      "[EPOCH #27, step #1294] loss: 0.7706520383652573\n",
      "[EPOCH #27, step #1296] loss: 0.7706147169689996\n",
      "[EPOCH #27, step #1298] loss: 0.7705229955099472\n",
      "[EPOCH #27, step #1300] loss: 0.7705065875810261\n",
      "[EPOCH #27, step #1302] loss: 0.7706686613519468\n",
      "[EPOCH #27, step #1304] loss: 0.7711696025740598\n",
      "[EPOCH #27, step #1306] loss: 0.7710252123519311\n",
      "[EPOCH #27, step #1308] loss: 0.7706711502863852\n",
      "[EPOCH #27, step #1310] loss: 0.7705628626179277\n",
      "[EPOCH #27, step #1312] loss: 0.7705724791134938\n",
      "[EPOCH #27, step #1314] loss: 0.7705366370569164\n",
      "[EPOCH #27, step #1316] loss: 0.7703091774189572\n",
      "[EPOCH #27, step #1318] loss: 0.7701370606736941\n",
      "[EPOCH #27, step #1320] loss: 0.77064553361152\n",
      "[EPOCH #27, step #1322] loss: 0.7710102128423891\n",
      "[EPOCH #27, step #1324] loss: 0.7713503802497432\n",
      "[EPOCH #27, step #1326] loss: 0.7715692101067497\n",
      "[EPOCH #27, step #1328] loss: 0.7712707778759879\n",
      "[EPOCH #27, step #1330] loss: 0.7711213749212756\n",
      "[EPOCH #27, step #1332] loss: 0.7709774880237537\n",
      "[EPOCH #27, step #1334] loss: 0.7709952713844928\n",
      "[EPOCH #27, step #1336] loss: 0.7713933510840965\n",
      "[EPOCH #27, step #1338] loss: 0.7712455053352615\n",
      "[EPOCH #27, step #1340] loss: 0.771041687058478\n",
      "[EPOCH #27, step #1342] loss: 0.770917204295355\n",
      "[EPOCH #27, step #1344] loss: 0.7711344946051176\n",
      "[EPOCH #27, step #1346] loss: 0.7714603692625042\n",
      "[EPOCH #27, step #1348] loss: 0.7712869529064891\n",
      "[EPOCH #27, step #1350] loss: 0.7710822547788005\n",
      "[EPOCH #27, step #1352] loss: 0.7713784720619256\n",
      "[EPOCH #27, step #1354] loss: 0.7708654746138301\n",
      "[EPOCH #27, step #1356] loss: 0.7706059553031106\n",
      "[EPOCH #27, step #1358] loss: 0.7704396357073163\n",
      "[EPOCH #27, step #1360] loss: 0.7703032813073957\n",
      "[EPOCH #27, step #1362] loss: 0.7701511682829084\n",
      "[EPOCH #27, step #1364] loss: 0.7698907194556771\n",
      "[EPOCH #27, step #1366] loss: 0.7695233678416605\n",
      "[EPOCH #27, step #1368] loss: 0.7696405522487214\n",
      "[EPOCH #27, step #1370] loss: 0.7698485738252046\n",
      "[EPOCH #27, step #1372] loss: 0.7698441402198447\n",
      "[EPOCH #27, step #1374] loss: 0.7697386918934909\n",
      "[EPOCH #27, step #1376] loss: 0.7699775686710748\n",
      "[EPOCH #27, step #1378] loss: 0.7700503405623889\n",
      "[EPOCH #27, step #1380] loss: 0.7700923801892742\n",
      "[EPOCH #27, step #1382] loss: 0.7701278050697462\n",
      "[EPOCH #27, step #1384] loss: 0.7700034350909911\n",
      "[EPOCH #27, step #1386] loss: 0.7699565700300323\n",
      "[EPOCH #27, step #1388] loss: 0.7701833636705785\n",
      "[EPOCH #27, step #1390] loss: 0.7701570331021919\n",
      "[EPOCH #27, step #1392] loss: 0.7704646436113808\n",
      "[EPOCH #27, step #1394] loss: 0.7704715861855442\n",
      "[EPOCH #27, step #1396] loss: 0.770292867591062\n",
      "[EPOCH #27, step #1398] loss: 0.7702005974431818\n",
      "[EPOCH #27, step #1400] loss: 0.7700675269223213\n",
      "[EPOCH #27, step #1402] loss: 0.769762337823808\n",
      "[EPOCH #27, step #1404] loss: 0.7699348267075006\n",
      "[EPOCH #27, step #1406] loss: 0.7700944155475817\n",
      "[EPOCH #27, step #1408] loss: 0.7700501794380191\n",
      "[EPOCH #27, step #1410] loss: 0.770164322950247\n",
      "[EPOCH #27, step #1412] loss: 0.769955299125018\n",
      "[EPOCH #27, step #1414] loss: 0.7700039512698305\n",
      "[EPOCH #27, step #1416] loss: 0.7699890334419407\n",
      "[EPOCH #27, step #1418] loss: 0.7701497098944236\n",
      "[EPOCH #27, step #1420] loss: 0.7702886917320966\n",
      "[EPOCH #27, step #1422] loss: 0.7702082646873244\n",
      "[EPOCH #27, step #1424] loss: 0.7704476891065899\n",
      "[EPOCH #27, step #1426] loss: 0.7701834352098317\n",
      "[EPOCH #27, step #1428] loss: 0.7702982101180155\n",
      "[EPOCH #27, step #1430] loss: 0.7700835682561062\n",
      "[EPOCH #27, step #1432] loss: 0.7699769856791686\n",
      "[EPOCH #27, step #1434] loss: 0.770129740155117\n",
      "[EPOCH #27, step #1436] loss: 0.7700307682395064\n",
      "[EPOCH #27, step #1438] loss: 0.7702135961862634\n",
      "[EPOCH #27, step #1440] loss: 0.7703667809200485\n",
      "[EPOCH #27, step #1442] loss: 0.7706918407461334\n",
      "[EPOCH #27, step #1444] loss: 0.7708055567576398\n",
      "[EPOCH #27, step #1446] loss: 0.7707406296018245\n",
      "[EPOCH #27, step #1448] loss: 0.7707991109707176\n",
      "[EPOCH #27, step #1450] loss: 0.7708483406546032\n",
      "[EPOCH #27, step #1452] loss: 0.7704606627851868\n",
      "[EPOCH #27, step #1454] loss: 0.770208458044275\n",
      "[EPOCH #27, step #1456] loss: 0.7702986168264115\n",
      "[EPOCH #27, step #1458] loss: 0.7705172842663391\n",
      "[EPOCH #27, step #1460] loss: 0.7705769357128065\n",
      "[EPOCH #27, step #1462] loss: 0.7704418070782396\n",
      "[EPOCH #27, step #1464] loss: 0.7704557187117814\n",
      "[EPOCH #27, step #1466] loss: 0.7703134305191105\n",
      "[EPOCH #27, step #1468] loss: 0.7704962174489922\n",
      "[EPOCH #27, step #1470] loss: 0.7707897351964812\n",
      "[EPOCH #27, step #1472] loss: 0.771022518860266\n",
      "[EPOCH #27, step #1474] loss: 0.7712458328675416\n",
      "[EPOCH #27, step #1476] loss: 0.7714740535296051\n",
      "[EPOCH #27, step #1478] loss: 0.7714007176645226\n",
      "[EPOCH #27, step #1480] loss: 0.7714739941930867\n",
      "[EPOCH #27, step #1482] loss: 0.7713755230323254\n",
      "[EPOCH #27, step #1484] loss: 0.7715707171043563\n",
      "[EPOCH #27, step #1486] loss: 0.771519330799299\n",
      "[EPOCH #27, step #1488] loss: 0.7715550405495595\n",
      "[EPOCH #27, step #1490] loss: 0.7713814331212354\n",
      "[EPOCH #27, step #1492] loss: 0.7713518328141303\n",
      "[EPOCH #27, step #1494] loss: 0.7711995418454493\n",
      "[EPOCH #27, step #1496] loss: 0.7708523933021084\n",
      "[EPOCH #27, step #1498] loss: 0.7707050058784447\n",
      "[EPOCH #27, step #1500] loss: 0.7707134656990313\n",
      "[EPOCH #27, step #1502] loss: 0.7707085499784111\n",
      "[EPOCH #27, step #1504] loss: 0.7709006902981438\n",
      "[EPOCH #27, step #1506] loss: 0.7709151507808265\n",
      "[EPOCH #27, step #1508] loss: 0.7707785186465802\n",
      "[EPOCH #27, step #1510] loss: 0.7708903443213727\n",
      "[EPOCH #27, step #1512] loss: 0.7709110579936613\n",
      "[EPOCH #27, step #1514] loss: 0.7714869157906019\n",
      "[EPOCH #27, step #1516] loss: 0.7712858389810111\n",
      "[EPOCH #27, step #1518] loss: 0.7713506451125518\n",
      "[EPOCH #27, step #1520] loss: 0.7711476880927215\n",
      "[EPOCH #27, step #1522] loss: 0.7710336124865694\n",
      "[EPOCH #27, step #1524] loss: 0.7710896664173876\n",
      "[EPOCH #27, step #1526] loss: 0.77105728336308\n",
      "[EPOCH #27, step #1528] loss: 0.7711978529776679\n",
      "[EPOCH #27, step #1530] loss: 0.7711707339965775\n",
      "[EPOCH #27, step #1532] loss: 0.7711462196149782\n",
      "[EPOCH #27, step #1534] loss: 0.7712030455809851\n",
      "[EPOCH #27, step #1536] loss: 0.7709300940542463\n",
      "[EPOCH #27, step #1538] loss: 0.7713811926403318\n",
      "[EPOCH #27, step #1540] loss: 0.7711436562264298\n",
      "[EPOCH #27, step #1542] loss: 0.7715807015719695\n",
      "[EPOCH #27, step #1544] loss: 0.7717280906959645\n",
      "[EPOCH #27, step #1546] loss: 0.7717921573767449\n",
      "[EPOCH #27, step #1548] loss: 0.7717371927953058\n",
      "[EPOCH #27, step #1550] loss: 0.7715478112319452\n",
      "[EPOCH #27, step #1552] loss: 0.7714344433293524\n",
      "[EPOCH #27, step #1554] loss: 0.7712841356873895\n",
      "[EPOCH #27, step #1556] loss: 0.771163992282283\n",
      "[EPOCH #27, step #1558] loss: 0.7709700313610018\n",
      "[EPOCH #27, step #1560] loss: 0.7708509206428198\n",
      "[EPOCH #27, step #1562] loss: 0.7709763846905355\n",
      "[EPOCH #27, step #1564] loss: 0.7708912036479852\n",
      "[EPOCH #27, step #1566] loss: 0.7709773978802072\n",
      "[EPOCH #27, step #1568] loss: 0.7709488178264419\n",
      "[EPOCH #27, step #1570] loss: 0.770496487902047\n",
      "[EPOCH #27, step #1572] loss: 0.770651103411218\n",
      "[EPOCH #27, step #1574] loss: 0.7706728419235774\n",
      "[EPOCH #27, step #1576] loss: 0.7705927807731423\n",
      "[EPOCH #27, step #1578] loss: 0.7705689673751422\n",
      "[EPOCH #27, step #1580] loss: 0.770795430754801\n",
      "[EPOCH #27, step #1582] loss: 0.7709370290675799\n",
      "[EPOCH #27, step #1584] loss: 0.7708806266355965\n",
      "[EPOCH #27, step #1586] loss: 0.7711503227964916\n",
      "[EPOCH #27, step #1588] loss: 0.7708947594207815\n",
      "[EPOCH #27, step #1590] loss: 0.7711055523228301\n",
      "[EPOCH #27, step #1592] loss: 0.7712598625811405\n",
      "[EPOCH #27, step #1594] loss: 0.7711126338351857\n",
      "[EPOCH #27, step #1596] loss: 0.7714521914030062\n",
      "[EPOCH #27, step #1598] loss: 0.7714324697730987\n",
      "[EPOCH #27, step #1600] loss: 0.7716069427190313\n",
      "[EPOCH #27, step #1602] loss: 0.7712505413864229\n",
      "[EPOCH #27, step #1604] loss: 0.7713721561469021\n",
      "[EPOCH #27, step #1606] loss: 0.7712114404541555\n",
      "[EPOCH #27, step #1608] loss: 0.7712343323853091\n",
      "[EPOCH #27, step #1610] loss: 0.771005891869336\n",
      "[EPOCH #27, step #1612] loss: 0.771059570534955\n",
      "[EPOCH #27, step #1614] loss: 0.7710945403797339\n",
      "[EPOCH #27, step #1616] loss: 0.7711928603858511\n",
      "[EPOCH #27, step #1618] loss: 0.7710024337661053\n",
      "[EPOCH #27, step #1620] loss: 0.7706301988347822\n",
      "[EPOCH #27, step #1622] loss: 0.770355834850028\n",
      "[EPOCH #27, step #1624] loss: 0.7707292006749373\n",
      "[EPOCH #27, step #1626] loss: 0.7711600915705711\n",
      "[EPOCH #27, step #1628] loss: 0.771081780622604\n",
      "[EPOCH #27, step #1630] loss: 0.7713049964295217\n",
      "[EPOCH #27, step #1632] loss: 0.7712131146448781\n",
      "[EPOCH #27, step #1634] loss: 0.771366458074033\n",
      "[EPOCH #27, step #1636] loss: 0.7711406311358193\n",
      "[EPOCH #27, step #1638] loss: 0.7711145693278298\n",
      "[EPOCH #27, step #1640] loss: 0.7710369101644361\n",
      "[EPOCH #27, step #1642] loss: 0.770844439598967\n",
      "[EPOCH #27, step #1644] loss: 0.7709794070764153\n",
      "[EPOCH #27, step #1646] loss: 0.7710918477070859\n",
      "[EPOCH #27, step #1648] loss: 0.7710833160388535\n",
      "[EPOCH #27, step #1650] loss: 0.7709251618219245\n",
      "[EPOCH #27, step #1652] loss: 0.770955431537057\n",
      "[EPOCH #27, step #1654] loss: 0.7707395694046942\n",
      "[EPOCH #27, step #1656] loss: 0.771011341639722\n",
      "[EPOCH #27, step #1658] loss: 0.7713756546908075\n",
      "[EPOCH #27, step #1660] loss: 0.7715591382793746\n",
      "[EPOCH #27, step #1662] loss: 0.7715567870808164\n",
      "[EPOCH #27, step #1664] loss: 0.7715967448266061\n",
      "[EPOCH #27, step #1666] loss: 0.7717577552967038\n",
      "[EPOCH #27, step #1668] loss: 0.772206842292205\n",
      "[EPOCH #27, step #1670] loss: 0.7719764514714212\n",
      "[EPOCH #27, step #1672] loss: 0.7722528776720621\n",
      "[EPOCH #27, step #1674] loss: 0.7720157522585854\n",
      "[EPOCH #27, step #1676] loss: 0.7720087489416433\n",
      "[EPOCH #27, step #1678] loss: 0.7718266658018997\n",
      "[EPOCH #27, step #1680] loss: 0.7715379297556018\n",
      "[EPOCH #27, step #1682] loss: 0.7717084162163012\n",
      "[EPOCH #27, step #1684] loss: 0.7718293793123624\n",
      "[EPOCH #27, step #1686] loss: 0.7717375392099776\n",
      "[EPOCH #27, step #1688] loss: 0.7717343615031652\n",
      "[EPOCH #27, step #1690] loss: 0.7716600657355356\n",
      "[EPOCH #27, step #1692] loss: 0.771729523042075\n",
      "[EPOCH #27, step #1694] loss: 0.7714343834591475\n",
      "[EPOCH #27, step #1696] loss: 0.7713466859699771\n",
      "[EPOCH #27, step #1698] loss: 0.7713068353035227\n",
      "[EPOCH #27, step #1700] loss: 0.7712322754379163\n",
      "[EPOCH #27, step #1702] loss: 0.7711873480976853\n",
      "[EPOCH #27, step #1704] loss: 0.7711105550314324\n",
      "[EPOCH #27, step #1706] loss: 0.7708959048019213\n",
      "[EPOCH #27, step #1708] loss: 0.7707170329643593\n",
      "[EPOCH #27, step #1710] loss: 0.7706280876710915\n",
      "[EPOCH #27, step #1712] loss: 0.7706021013415771\n",
      "[EPOCH #27, step #1714] loss: 0.7709653351119239\n",
      "[EPOCH #27, step #1716] loss: 0.7708300054941194\n",
      "[EPOCH #27, step #1718] loss: 0.7708471714583436\n",
      "[EPOCH #27, step #1720] loss: 0.7707875245605216\n",
      "[EPOCH #27, step #1722] loss: 0.7706266689355886\n",
      "[EPOCH #27, step #1724] loss: 0.770395139179368\n",
      "[EPOCH #27, step #1726] loss: 0.7705704334607757\n",
      "[EPOCH #27, step #1728] loss: 0.7708076470466346\n",
      "[EPOCH #27, step #1730] loss: 0.7707172731214146\n",
      "[EPOCH #27, step #1732] loss: 0.770890685102531\n",
      "[EPOCH #27, step #1734] loss: 0.7710016735520762\n",
      "[EPOCH #27, step #1736] loss: 0.7707850806282112\n",
      "[EPOCH #27, step #1738] loss: 0.770663309450325\n",
      "[EPOCH #27, step #1740] loss: 0.7710569588738156\n",
      "[EPOCH #27, step #1742] loss: 0.7712656172506439\n",
      "[EPOCH #27, step #1744] loss: 0.7714286611380755\n",
      "[EPOCH #27, step #1746] loss: 0.7714537998813865\n",
      "[EPOCH #27, step #1748] loss: 0.7713099641245116\n",
      "[EPOCH #27, step #1750] loss: 0.771323863248836\n",
      "[EPOCH #27, step #1752] loss: 0.7710869428401529\n",
      "[EPOCH #27, step #1754] loss: 0.7710241049273401\n",
      "[EPOCH #27, step #1756] loss: 0.7710496500838393\n",
      "[EPOCH #27, step #1758] loss: 0.7709632434073737\n",
      "[EPOCH #27, step #1760] loss: 0.7707469087476964\n",
      "[EPOCH #27, step #1762] loss: 0.7707379360092139\n",
      "[EPOCH #27, step #1764] loss: 0.7710856154181126\n",
      "[EPOCH #27, step #1766] loss: 0.7711705607111736\n",
      "[EPOCH #27, step #1768] loss: 0.7715417640131028\n",
      "[EPOCH #27, step #1770] loss: 0.7715845363648984\n",
      "[EPOCH #27, step #1772] loss: 0.7715097378185087\n",
      "[EPOCH #27, step #1774] loss: 0.7712805657823321\n",
      "[EPOCH #27, step #1776] loss: 0.7711275953990258\n",
      "[EPOCH #27, step #1778] loss: 0.7712283838224117\n",
      "[EPOCH #27, step #1780] loss: 0.7712289415705679\n",
      "[EPOCH #27, step #1782] loss: 0.7713175858096734\n",
      "[EPOCH #27, step #1784] loss: 0.7712373738028422\n",
      "[EPOCH #27, step #1786] loss: 0.7710750110668381\n",
      "[EPOCH #27, step #1788] loss: 0.7709515527548771\n",
      "[EPOCH #27, step #1790] loss: 0.7709431190320328\n",
      "[EPOCH #27, step #1792] loss: 0.7708648186253889\n",
      "[EPOCH #27, step #1794] loss: 0.7710465313996445\n",
      "[EPOCH #27, step #1796] loss: 0.771110103040121\n",
      "[EPOCH #27, step #1798] loss: 0.7711696557166379\n",
      "[EPOCH #27, step #1800] loss: 0.7712041482800976\n",
      "[EPOCH #27, step #1802] loss: 0.7709503487058302\n",
      "[EPOCH #27, step #1804] loss: 0.771011100796121\n",
      "[EPOCH #27, step #1806] loss: 0.7714483156907472\n",
      "[EPOCH #27, step #1808] loss: 0.7715559640828255\n",
      "[EPOCH #27, step #1810] loss: 0.7716415307753525\n",
      "[EPOCH #27, step #1812] loss: 0.7714092201017505\n",
      "[EPOCH #27, step #1814] loss: 0.7713932396459185\n",
      "[EPOCH #27, step #1816] loss: 0.7712926821158886\n",
      "[EPOCH #27, step #1818] loss: 0.7709910571575165\n",
      "[EPOCH #27, step #1820] loss: 0.771011554445296\n",
      "[EPOCH #27, step #1822] loss: 0.7712819943275022\n",
      "[EPOCH #27, step #1824] loss: 0.7713398802933628\n",
      "[EPOCH #27, step #1826] loss: 0.7712784051797269\n",
      "[EPOCH #27, step #1828] loss: 0.7712013828845673\n",
      "[EPOCH #27, step #1830] loss: 0.7709529090129502\n",
      "[EPOCH #27, step #1832] loss: 0.7709626082150063\n",
      "[EPOCH #27, step #1834] loss: 0.7708477323321621\n",
      "[EPOCH #27, step #1836] loss: 0.7705530323246347\n",
      "[EPOCH #27, step #1838] loss: 0.7706174946563797\n",
      "[EPOCH #27, step #1840] loss: 0.7707422799969549\n",
      "[EPOCH #27, step #1842] loss: 0.770374616138067\n",
      "[EPOCH #27, step #1844] loss: 0.7702929702231555\n",
      "[EPOCH #27, step #1846] loss: 0.7702848198740432\n",
      "[EPOCH #27, step #1848] loss: 0.7701901046245919\n",
      "[EPOCH #27, step #1850] loss: 0.7702729002905175\n",
      "[EPOCH #27, step #1852] loss: 0.7701695333348051\n",
      "[EPOCH #27, step #1854] loss: 0.770021062462799\n",
      "[EPOCH #27, step #1856] loss: 0.769903245797771\n",
      "[EPOCH #27, step #1858] loss: 0.7699949501213558\n",
      "[EPOCH #27, step #1860] loss: 0.769956918188092\n",
      "[EPOCH #27, step #1862] loss: 0.7699293662512487\n",
      "[EPOCH #27, step #1864] loss: 0.769745618951864\n",
      "[EPOCH #27, step #1866] loss: 0.7699436710106861\n",
      "[EPOCH #27, step #1868] loss: 0.7698972693351962\n",
      "[EPOCH #27, step #1870] loss: 0.7698860519522336\n",
      "[EPOCH #27, step #1872] loss: 0.7699977302704021\n",
      "[EPOCH #27, step #1874] loss: 0.770056564839681\n",
      "[EPOCH #27, step #1876] loss: 0.7699797284304619\n",
      "[EPOCH #27, step #1878] loss: 0.7699830835965671\n",
      "[EPOCH #27, step #1880] loss: 0.7699192724349586\n",
      "[EPOCH #27, step #1882] loss: 0.7697772916902966\n",
      "[EPOCH #27, step #1884] loss: 0.769781593444809\n",
      "[EPOCH #27, step #1886] loss: 0.7699923253937505\n",
      "[EPOCH #27, step #1888] loss: 0.7697955806492623\n",
      "[EPOCH #27, step #1890] loss: 0.7696760018656078\n",
      "[EPOCH #27, step #1892] loss: 0.7693048775101615\n",
      "[EPOCH #27, step #1894] loss: 0.7694434335804238\n",
      "[EPOCH #27, step #1896] loss: 0.7694335713723364\n",
      "[EPOCH #27, step #1898] loss: 0.769411886253126\n",
      "[EPOCH #27, step #1900] loss: 0.7695383251434499\n",
      "[EPOCH #27, step #1902] loss: 0.7695560541142932\n",
      "[EPOCH #27, step #1904] loss: 0.7692868691729748\n",
      "[EPOCH #27, step #1906] loss: 0.7692083596058021\n",
      "[EPOCH #27, step #1908] loss: 0.7691493003139825\n",
      "[EPOCH #27, step #1910] loss: 0.7691921031893018\n",
      "[EPOCH #27, step #1912] loss: 0.7691551463428244\n",
      "[EPOCH #27, step #1914] loss: 0.7691367239615936\n",
      "[EPOCH #27, step #1916] loss: 0.7691012646421891\n",
      "[EPOCH #27, step #1918] loss: 0.768911368558654\n",
      "[EPOCH #27, step #1920] loss: 0.7686578252705232\n",
      "[EPOCH #27, step #1922] loss: 0.7685443156254025\n",
      "[EPOCH #27, step #1924] loss: 0.7686101385370477\n",
      "[EPOCH #27, step #1926] loss: 0.7685003453081731\n",
      "[EPOCH #27, step #1928] loss: 0.7682608303132609\n",
      "[EPOCH #27, step #1930] loss: 0.7680619983615066\n",
      "[EPOCH #27, step #1932] loss: 0.7680070037460672\n",
      "[EPOCH #27, step #1934] loss: 0.7680979720843855\n",
      "[EPOCH #27, step #1936] loss: 0.7679870305106883\n",
      "[EPOCH #27, step #1938] loss: 0.7680050928516446\n",
      "[EPOCH #27, step #1940] loss: 0.7679726371962897\n",
      "[EPOCH #27, step #1942] loss: 0.7679965555115699\n",
      "[EPOCH #27, step #1944] loss: 0.7679282648244676\n",
      "[EPOCH #27, step #1946] loss: 0.7680684272821707\n",
      "[EPOCH #27, step #1948] loss: 0.7679929407729192\n",
      "[EPOCH #27, step #1950] loss: 0.768138943284918\n",
      "[EPOCH #27, step #1952] loss: 0.7679643061334392\n",
      "[EPOCH #27, step #1954] loss: 0.767769209716631\n",
      "[EPOCH #27, step #1956] loss: 0.7677141948811059\n",
      "[EPOCH #27, step #1958] loss: 0.7677349913114184\n",
      "[EPOCH #27, step #1960] loss: 0.7678029571547307\n",
      "[EPOCH #27, step #1962] loss: 0.7678748284501199\n",
      "[EPOCH #27, step #1964] loss: 0.7678636844224905\n",
      "[EPOCH #27, step #1966] loss: 0.7677947350971336\n",
      "[EPOCH #27, step #1968] loss: 0.7675727459154134\n",
      "[EPOCH #27, step #1970] loss: 0.767816711067851\n",
      "[EPOCH #27, step #1972] loss: 0.7679854634293916\n",
      "[EPOCH #27, step #1974] loss: 0.7681782491448559\n",
      "[EPOCH #27, step #1976] loss: 0.7681038332787438\n",
      "[EPOCH #27, step #1978] loss: 0.7681428734222526\n",
      "[EPOCH #27, step #1980] loss: 0.76826404299115\n",
      "[EPOCH #27, step #1982] loss: 0.7680949956644562\n",
      "[EPOCH #27, step #1984] loss: 0.7681309455437985\n",
      "[EPOCH #27, step #1986] loss: 0.76807737348964\n",
      "[EPOCH #27, step #1988] loss: 0.7681369047449006\n",
      "[EPOCH #27, step #1990] loss: 0.767847878094117\n",
      "[EPOCH #27, step #1992] loss: 0.7679090186901207\n",
      "[EPOCH #27, step #1994] loss: 0.7678531148081137\n",
      "[EPOCH #27, step #1996] loss: 0.7680553633628276\n",
      "[EPOCH #27, step #1998] loss: 0.7681170317338311\n",
      "[EPOCH #27, step #2000] loss: 0.7679254212181668\n",
      "[EPOCH #27, step #2002] loss: 0.7677024138521327\n",
      "[EPOCH #27, step #2004] loss: 0.7675762995074218\n",
      "[EPOCH #27, step #2006] loss: 0.7675081236509761\n",
      "[EPOCH #27, step #2008] loss: 0.767405319845813\n",
      "[EPOCH #27, step #2010] loss: 0.767421092562033\n",
      "[EPOCH #27, step #2012] loss: 0.7674043340080127\n",
      "[EPOCH #27, step #2014] loss: 0.7672385223746004\n",
      "[EPOCH #27, step #2016] loss: 0.766985792790419\n",
      "[EPOCH #27, step #2018] loss: 0.7668861932628163\n",
      "[EPOCH #27, step #2020] loss: 0.7666009564407977\n",
      "[EPOCH #27, step #2022] loss: 0.766777642826249\n",
      "[EPOCH #27, step #2024] loss: 0.7666944939707533\n",
      "[EPOCH #27, step #2026] loss: 0.7665773863620692\n",
      "[EPOCH #27, step #2028] loss: 0.7663936710316539\n",
      "[EPOCH #27, step #2030] loss: 0.7662753345841906\n",
      "[EPOCH #27, step #2032] loss: 0.7662559790940808\n",
      "[EPOCH #27, step #2034] loss: 0.7660999483353382\n",
      "[EPOCH #27, step #2036] loss: 0.7663589051879383\n",
      "[EPOCH #27, step #2038] loss: 0.7663521014077223\n",
      "[EPOCH #27, step #2040] loss: 0.7664563177059469\n",
      "[EPOCH #27, step #2042] loss: 0.7665296722526243\n",
      "[EPOCH #27, step #2044] loss: 0.7668420514296785\n",
      "[EPOCH #27, step #2046] loss: 0.7668092948638001\n",
      "[EPOCH #27, step #2048] loss: 0.7665790371222284\n",
      "[EPOCH #27, step #2050] loss: 0.766730206149895\n",
      "[EPOCH #27, step #2052] loss: 0.7664515198119025\n",
      "[EPOCH #27, step #2054] loss: 0.7665281790306389\n",
      "[EPOCH #27, step #2056] loss: 0.7666678303181691\n",
      "[EPOCH #27, step #2058] loss: 0.766650121729602\n",
      "[EPOCH #27, step #2060] loss: 0.7666254894991398\n",
      "[EPOCH #27, step #2062] loss: 0.766662182475084\n",
      "[EPOCH #27, step #2064] loss: 0.7665810293204559\n",
      "[EPOCH #27, step #2066] loss: 0.7665291327062181\n",
      "[EPOCH #27, step #2068] loss: 0.7668149643845463\n",
      "[EPOCH #27, step #2070] loss: 0.7668291692685413\n",
      "[EPOCH #27, step #2072] loss: 0.7666548342734676\n",
      "[EPOCH #27, step #2074] loss: 0.7667765650979007\n",
      "[EPOCH #27, step #2076] loss: 0.7670302824097065\n",
      "[EPOCH #27, step #2078] loss: 0.7669638848006582\n",
      "[EPOCH #27, step #2080] loss: 0.7668289631275762\n",
      "[EPOCH #27, step #2082] loss: 0.7668093373955183\n",
      "[EPOCH #27, step #2084] loss: 0.7667926243169131\n",
      "[EPOCH #27, step #2086] loss: 0.7668253969049477\n",
      "[EPOCH #27, step #2088] loss: 0.7670300217437196\n",
      "[EPOCH #27, step #2090] loss: 0.7668325242985954\n",
      "[EPOCH #27, step #2092] loss: 0.7666657703149506\n",
      "[EPOCH #27, step #2094] loss: 0.7666785992415253\n",
      "[EPOCH #27, step #2096] loss: 0.7666184218315266\n",
      "[EPOCH #27, step #2098] loss: 0.7666682744094336\n",
      "[EPOCH #27, step #2100] loss: 0.7665630009190234\n",
      "[EPOCH #27, step #2102] loss: 0.7666412897893377\n",
      "[EPOCH #27, step #2104] loss: 0.7664967738675957\n",
      "[EPOCH #27, step #2106] loss: 0.7663945131778265\n",
      "[EPOCH #27, step #2108] loss: 0.7663739523287348\n",
      "[EPOCH #27, step #2110] loss: 0.7665847288749049\n",
      "[EPOCH #27, step #2112] loss: 0.7663613645403068\n",
      "[EPOCH #27, step #2114] loss: 0.7662236237215939\n",
      "[EPOCH #27, step #2116] loss: 0.7662714026167982\n",
      "[EPOCH #27, step #2118] loss: 0.7666711505008452\n",
      "[EPOCH #27, step #2120] loss: 0.7668576689752302\n",
      "[EPOCH #27, step #2122] loss: 0.7668363959425415\n",
      "[EPOCH #27, step #2124] loss: 0.7670678569148569\n",
      "[EPOCH #27, step #2126] loss: 0.7672005992822374\n",
      "[EPOCH #27, step #2128] loss: 0.7671070629271503\n",
      "[EPOCH #27, step #2130] loss: 0.7668088033466706\n",
      "[EPOCH #27, step #2132] loss: 0.7667184576315328\n",
      "[EPOCH #27, step #2134] loss: 0.7667910693400917\n",
      "[EPOCH #27, step #2136] loss: 0.7668081689617262\n",
      "[EPOCH #27, step #2138] loss: 0.766974814838759\n",
      "[EPOCH #27, step #2140] loss: 0.7670493129534679\n",
      "[EPOCH #27, step #2142] loss: 0.7670146676073328\n",
      "[EPOCH #27, step #2144] loss: 0.7668876677265256\n",
      "[EPOCH #27, step #2146] loss: 0.7670375863146549\n",
      "[EPOCH #27, step #2148] loss: 0.7669666683385404\n",
      "[EPOCH #27, step #2150] loss: 0.7668297298422307\n",
      "[EPOCH #27, step #2152] loss: 0.7667857606605879\n",
      "[EPOCH #27, step #2154] loss: 0.766653431775675\n",
      "[EPOCH #27, step #2156] loss: 0.7664908342301763\n",
      "[EPOCH #27, step #2158] loss: 0.7662998847163016\n",
      "[EPOCH #27, step #2160] loss: 0.7661460988199419\n",
      "[EPOCH #27, step #2162] loss: 0.7664307474511342\n",
      "[EPOCH #27, step #2164] loss: 0.7664068028365216\n",
      "[EPOCH #27, step #2166] loss: 0.7662563302107653\n",
      "[EPOCH #27, step #2168] loss: 0.7663103441397349\n",
      "[EPOCH #27, step #2170] loss: 0.7663358489608282\n",
      "[EPOCH #27, step #2172] loss: 0.7663078723253328\n",
      "[EPOCH #27, step #2174] loss: 0.7661676382333383\n",
      "[EPOCH #27, step #2176] loss: 0.7662680595223379\n",
      "[EPOCH #27, step #2178] loss: 0.7662026865348842\n",
      "[EPOCH #27, step #2180] loss: 0.7663820395634733\n",
      "[EPOCH #27, step #2182] loss: 0.7664901591936383\n",
      "[EPOCH #27, step #2184] loss: 0.7663760368147485\n",
      "[EPOCH #27, step #2186] loss: 0.7663317202404312\n",
      "[EPOCH #27, step #2188] loss: 0.7663219647491397\n",
      "[EPOCH #27, step #2190] loss: 0.7663144417436958\n",
      "[EPOCH #27, step #2192] loss: 0.7661074366381437\n",
      "[EPOCH #27, step #2194] loss: 0.7661113292997138\n",
      "[EPOCH #27, step #2196] loss: 0.766054926878439\n",
      "[EPOCH #27, step #2198] loss: 0.7660145675691489\n",
      "[EPOCH #27, step #2200] loss: 0.7659604775396491\n",
      "[EPOCH #27, step #2202] loss: 0.766012099605769\n",
      "[EPOCH #27, step #2204] loss: 0.7658203713883078\n",
      "[EPOCH #27, step #2206] loss: 0.7658365633917654\n",
      "[EPOCH #27, step #2208] loss: 0.7658394824573496\n",
      "[EPOCH #27, step #2210] loss: 0.765711318726779\n",
      "[EPOCH #27, step #2212] loss: 0.7656529503901836\n",
      "[EPOCH #27, step #2214] loss: 0.7653604516057344\n",
      "[EPOCH #27, step #2216] loss: 0.7652083201401934\n",
      "[EPOCH #27, step #2218] loss: 0.7649910999155625\n",
      "[EPOCH #27, step #2220] loss: 0.7651001896502896\n",
      "[EPOCH #27, step #2222] loss: 0.7651120286453322\n",
      "[EPOCH #27, step #2224] loss: 0.7652282489551587\n",
      "[EPOCH #27, step #2226] loss: 0.7651256765546315\n",
      "[EPOCH #27, step #2228] loss: 0.7652329517459057\n",
      "[EPOCH #27, step #2230] loss: 0.7652073828482617\n",
      "[EPOCH #27, step #2232] loss: 0.7649717738796017\n",
      "[EPOCH #27, step #2234] loss: 0.7647835260669658\n",
      "[EPOCH #27, step #2236] loss: 0.7647637149213306\n",
      "[EPOCH #27, step #2238] loss: 0.7646240323262856\n",
      "[EPOCH #27, step #2240] loss: 0.7646049008817345\n",
      "[EPOCH #27, step #2242] loss: 0.7643977998889986\n",
      "[EPOCH #27, step #2244] loss: 0.7645052789579787\n",
      "[EPOCH #27, step #2246] loss: 0.764600297690605\n",
      "[EPOCH #27, step #2248] loss: 0.7645160134181069\n",
      "[EPOCH #27, step #2250] loss: 0.7644176785811378\n",
      "[EPOCH #27, step #2252] loss: 0.7643101037580387\n",
      "[EPOCH #27, step #2254] loss: 0.7643405565665725\n",
      "[EPOCH #27, step #2256] loss: 0.7641758337504683\n",
      "[EPOCH #27, step #2258] loss: 0.7641588723358722\n",
      "[EPOCH #27, step #2260] loss: 0.7639142494057196\n",
      "[EPOCH #27, step #2262] loss: 0.763729889401808\n",
      "[EPOCH #27, step #2264] loss: 0.7638890659967006\n",
      "[EPOCH #27, step #2266] loss: 0.7640306138892399\n",
      "[EPOCH #27, step #2268] loss: 0.7639075794925034\n",
      "[EPOCH #27, step #2270] loss: 0.7638353596879017\n",
      "[EPOCH #27, step #2272] loss: 0.7637453095350715\n",
      "[EPOCH #27, step #2274] loss: 0.7636721308545752\n",
      "[EPOCH #27, step #2276] loss: 0.7638657074331662\n",
      "[EPOCH #27, step #2278] loss: 0.7637844949947632\n",
      "[EPOCH #27, step #2280] loss: 0.7636982948175913\n",
      "[EPOCH #27, step #2282] loss: 0.7635341162384992\n",
      "[EPOCH #27, step #2284] loss: 0.7635222191883646\n",
      "[EPOCH #27, step #2286] loss: 0.7635714231123296\n",
      "[EPOCH #27, step #2288] loss: 0.763362994278399\n",
      "[EPOCH #27, step #2290] loss: 0.7636219783674313\n",
      "[EPOCH #27, step #2292] loss: 0.7635115148508543\n",
      "[EPOCH #27, step #2294] loss: 0.7635837810491425\n",
      "[EPOCH #27, step #2296] loss: 0.7635931613448396\n",
      "[EPOCH #27, step #2298] loss: 0.76353380093112\n",
      "[EPOCH #27, step #2300] loss: 0.7636207854525\n",
      "[EPOCH #27, step #2302] loss: 0.7635233473166972\n",
      "[EPOCH #27, step #2304] loss: 0.7633957534446634\n",
      "[EPOCH #27, step #2306] loss: 0.7635306613394642\n",
      "[EPOCH #27, step #2308] loss: 0.7637983224721324\n",
      "[EPOCH #27, step #2310] loss: 0.7637147207324095\n",
      "[EPOCH #27, step #2312] loss: 0.7636780141495648\n",
      "[EPOCH #27, step #2314] loss: 0.7638635862980754\n",
      "[EPOCH #27, step #2316] loss: 0.7641371717265726\n",
      "[EPOCH #27, step #2318] loss: 0.7639762974983147\n",
      "[EPOCH #27, step #2320] loss: 0.7641237566487535\n",
      "[EPOCH #27, step #2322] loss: 0.7641218884900578\n",
      "[EPOCH #27, step #2324] loss: 0.7642139885630659\n",
      "[EPOCH #27, step #2326] loss: 0.7641321585241899\n",
      "[EPOCH #27, step #2328] loss: 0.7640787841501846\n",
      "[EPOCH #27, step #2330] loss: 0.7640174807447673\n",
      "[EPOCH #27, step #2332] loss: 0.7640122383309187\n",
      "[EPOCH #27, step #2334] loss: 0.7639801825522355\n",
      "[EPOCH #27, step #2336] loss: 0.7640243849924705\n",
      "[EPOCH #27, step #2338] loss: 0.7639742178532648\n",
      "[EPOCH #27, step #2340] loss: 0.7639307543056126\n",
      "[EPOCH #27, step #2342] loss: 0.7640844719485244\n",
      "[EPOCH #27, step #2344] loss: 0.764072025470388\n",
      "[EPOCH #27, step #2346] loss: 0.7642475950575708\n",
      "[EPOCH #27, step #2348] loss: 0.7641010341135782\n",
      "[EPOCH #27, step #2350] loss: 0.7640256688651609\n",
      "[EPOCH #27, step #2352] loss: 0.7639545806661039\n",
      "[EPOCH #27, step #2354] loss: 0.7638812394911569\n",
      "[EPOCH #27, step #2356] loss: 0.7637615383278277\n",
      "[EPOCH #27, step #2358] loss: 0.7636557575023089\n",
      "[EPOCH #27, step #2360] loss: 0.7638583360133359\n",
      "[EPOCH #27, step #2362] loss: 0.7638307864187736\n",
      "[EPOCH #27, step #2364] loss: 0.763824343139475\n",
      "[EPOCH #27, step #2366] loss: 0.7639343746362177\n",
      "[EPOCH #27, step #2368] loss: 0.763752965056076\n",
      "[EPOCH #27, step #2370] loss: 0.763678411211157\n",
      "[EPOCH #27, step #2372] loss: 0.7639252444359506\n",
      "[EPOCH #27, step #2374] loss: 0.7640257429951116\n",
      "[EPOCH #27, step #2376] loss: 0.7638603605966283\n",
      "[EPOCH #27, step #2378] loss: 0.7638470124251304\n",
      "[EPOCH #27, step #2380] loss: 0.7638631642665847\n",
      "[EPOCH #27, step #2382] loss: 0.7639241541352434\n",
      "[EPOCH #27, step #2384] loss: 0.7638499879612113\n",
      "[EPOCH #27, step #2386] loss: 0.763849567870091\n",
      "[EPOCH #27, step #2388] loss: 0.7639072638093901\n",
      "[EPOCH #27, step #2390] loss: 0.7638599487315257\n",
      "[EPOCH #27, step #2392] loss: 0.7639753488108447\n",
      "[EPOCH #27, step #2394] loss: 0.7638556838657762\n",
      "[EPOCH #27, step #2396] loss: 0.7637487390934551\n",
      "[EPOCH #27, step #2398] loss: 0.76362917853326\n",
      "[EPOCH #27, step #2400] loss: 0.763708051730076\n",
      "[EPOCH #27, step #2402] loss: 0.7636696889134581\n",
      "[EPOCH #27, step #2404] loss: 0.763654921047405\n",
      "[EPOCH #27, step #2406] loss: 0.7638023677311054\n",
      "[EPOCH #27, step #2408] loss: 0.7637845664634998\n",
      "[EPOCH #27, step #2410] loss: 0.7638550348447003\n",
      "[EPOCH #27, step #2412] loss: 0.7636312491484712\n",
      "[EPOCH #27, step #2414] loss: 0.7635361850385093\n",
      "[EPOCH #27, step #2416] loss: 0.7636211252330896\n",
      "[EPOCH #27, step #2418] loss: 0.7635887702322538\n",
      "[EPOCH #27, step #2420] loss: 0.7636028512210602\n",
      "[EPOCH #27, step #2422] loss: 0.7638644126885399\n",
      "[EPOCH #27, step #2424] loss: 0.7638361308500938\n",
      "[EPOCH #27, step #2426] loss: 0.763810805396185\n",
      "[EPOCH #27, step #2428] loss: 0.7638212417245843\n",
      "[EPOCH #27, step #2430] loss: 0.7639328420211238\n",
      "[EPOCH #27, step #2432] loss: 0.7638658940351112\n",
      "[EPOCH #27, step #2434] loss: 0.7643776332695627\n",
      "[EPOCH #27, step #2436] loss: 0.7641991970477459\n",
      "[EPOCH #27, step #2438] loss: 0.7642136439283933\n",
      "[EPOCH #27, step #2440] loss: 0.7643239758191466\n",
      "[EPOCH #27, step #2442] loss: 0.7642484910167049\n",
      "[EPOCH #27, step #2444] loss: 0.7641214857803532\n",
      "[EPOCH #27, step #2446] loss: 0.7639863664732692\n",
      "[EPOCH #27, step #2448] loss: 0.7638543014284931\n",
      "[EPOCH #27, step #2450] loss: 0.7639103073920098\n",
      "[EPOCH #27, step #2452] loss: 0.7639943735481912\n",
      "[EPOCH #27, step #2454] loss: 0.7639254237629488\n",
      "[EPOCH #27, step #2456] loss: 0.7638248201060887\n",
      "[EPOCH #27, step #2458] loss: 0.7638075444067141\n",
      "[EPOCH #27, step #2460] loss: 0.7636571511269004\n",
      "[EPOCH #27, step #2462] loss: 0.7634978534436739\n",
      "[EPOCH #27, step #2464] loss: 0.7637295289890761\n",
      "[EPOCH #27, step #2466] loss: 0.7637419585375637\n",
      "[EPOCH #27, step #2468] loss: 0.7637435492352949\n",
      "[EPOCH #27, step #2470] loss: 0.7637327188231693\n",
      "[EPOCH #27, step #2472] loss: 0.7637306587251632\n",
      "[EPOCH #27, step #2474] loss: 0.7637173548130074\n",
      "[EPOCH #27, step #2476] loss: 0.763803403248554\n",
      "[EPOCH #27, step #2478] loss: 0.7638422766006873\n",
      "[EPOCH #27, step #2480] loss: 0.7637941091592059\n",
      "[EPOCH #27, step #2482] loss: 0.7636889364634893\n",
      "[EPOCH #27, step #2484] loss: 0.7635490631313631\n",
      "[EPOCH #27, step #2486] loss: 0.7635049319406279\n",
      "[EPOCH #27, step #2488] loss: 0.7634634658987621\n",
      "[EPOCH #27, step #2490] loss: 0.7633862846206825\n",
      "[EPOCH #27, step #2492] loss: 0.7633204216274256\n",
      "[EPOCH #27, step #2494] loss: 0.7632647223367481\n",
      "[EPOCH #27, step #2496] loss: 0.7631927097755573\n",
      "[EPOCH #27, step #2498] loss: 0.763212783806989\n",
      "[EPOCH #27, elapsed time: 13622.261[sec]] loss: 0.7632685891389847\n",
      "[EPOCH #28, step #0] loss: 0.7916842103004456\n",
      "[EPOCH #28, step #2] loss: 0.7231012980143229\n",
      "[EPOCH #28, step #4] loss: 0.7219987273216247\n",
      "[EPOCH #28, step #6] loss: 0.7028133358274188\n",
      "[EPOCH #28, step #8] loss: 0.7123804092407227\n",
      "[EPOCH #28, step #10] loss: 0.7013199708678506\n",
      "[EPOCH #28, step #12] loss: 0.7089712849030128\n",
      "[EPOCH #28, step #14] loss: 0.740671972433726\n",
      "[EPOCH #28, step #16] loss: 0.7247820461497587\n",
      "[EPOCH #28, step #18] loss: 0.7306552560705888\n",
      "[EPOCH #28, step #20] loss: 0.7746343442371914\n",
      "[EPOCH #28, step #22] loss: 0.7608982195024905\n",
      "[EPOCH #28, step #24] loss: 0.7514808511734009\n",
      "[EPOCH #28, step #26] loss: 0.755163613292906\n",
      "[EPOCH #28, step #28] loss: 0.7541568731439525\n",
      "[EPOCH #28, step #30] loss: 0.7406155678533739\n",
      "[EPOCH #28, step #32] loss: 0.7349311546845869\n",
      "[EPOCH #28, step #34] loss: 0.7272573011262077\n",
      "[EPOCH #28, step #36] loss: 0.7305320823514784\n",
      "[EPOCH #28, step #38] loss: 0.7344664717331911\n",
      "[EPOCH #28, step #40] loss: 0.7284965558749873\n",
      "[EPOCH #28, step #42] loss: 0.7351938042529794\n",
      "[EPOCH #28, step #44] loss: 0.7299925963083903\n",
      "[EPOCH #28, step #46] loss: 0.7198232437701936\n",
      "[EPOCH #28, step #48] loss: 0.7169299916345246\n",
      "[EPOCH #28, step #50] loss: 0.7107363693854388\n",
      "[EPOCH #28, step #52] loss: 0.7160075756738771\n",
      "[EPOCH #28, step #54] loss: 0.7170609474182129\n",
      "[EPOCH #28, step #56] loss: 0.7139152696258143\n",
      "[EPOCH #28, step #58] loss: 0.7082759753122168\n",
      "[EPOCH #28, step #60] loss: 0.7098191365843913\n",
      "[EPOCH #28, step #62] loss: 0.7105205555756887\n",
      "[EPOCH #28, step #64] loss: 0.7088929391824282\n",
      "[EPOCH #28, step #66] loss: 0.713553058122521\n",
      "[EPOCH #28, step #68] loss: 0.715081844208897\n",
      "[EPOCH #28, step #70] loss: 0.7159435316710405\n",
      "[EPOCH #28, step #72] loss: 0.7167287211712092\n",
      "[EPOCH #28, step #74] loss: 0.7229519959290822\n",
      "[EPOCH #28, step #76] loss: 0.7259696215004116\n",
      "[EPOCH #28, step #78] loss: 0.7230615083929859\n",
      "[EPOCH #28, step #80] loss: 0.7271241453694709\n",
      "[EPOCH #28, step #82] loss: 0.7271383954099861\n",
      "[EPOCH #28, step #84] loss: 0.7249311359489665\n",
      "[EPOCH #28, step #86] loss: 0.7318303780309086\n",
      "[EPOCH #28, step #88] loss: 0.7288079298614116\n",
      "[EPOCH #28, step #90] loss: 0.7275329445089612\n",
      "[EPOCH #28, step #92] loss: 0.7287614848665012\n",
      "[EPOCH #28, step #94] loss: 0.7263655245304108\n",
      "[EPOCH #28, step #96] loss: 0.727674363507438\n",
      "[EPOCH #28, step #98] loss: 0.7241140679277555\n",
      "[EPOCH #28, step #100] loss: 0.7302067872911396\n",
      "[EPOCH #28, step #102] loss: 0.733726085679045\n",
      "[EPOCH #28, step #104] loss: 0.732849566425596\n",
      "[EPOCH #28, step #106] loss: 0.7309867413801567\n",
      "[EPOCH #28, step #108] loss: 0.7310864392223708\n",
      "[EPOCH #28, step #110] loss: 0.7273318625248231\n",
      "[EPOCH #28, step #112] loss: 0.7295004132047164\n",
      "[EPOCH #28, step #114] loss: 0.735758601323418\n",
      "[EPOCH #28, step #116] loss: 0.738536410097383\n",
      "[EPOCH #28, step #118] loss: 0.7342355797270766\n",
      "[EPOCH #28, step #120] loss: 0.7316770272806656\n",
      "[EPOCH #28, step #122] loss: 0.7297737174402408\n",
      "[EPOCH #28, step #124] loss: 0.7286159737110138\n",
      "[EPOCH #28, step #126] loss: 0.726797656046124\n",
      "[EPOCH #28, step #128] loss: 0.7284170798091001\n",
      "[EPOCH #28, step #130] loss: 0.7285274119322537\n",
      "[EPOCH #28, step #132] loss: 0.7282782777359611\n",
      "[EPOCH #28, step #134] loss: 0.729284507477725\n",
      "[EPOCH #28, step #136] loss: 0.7282636041623832\n",
      "[EPOCH #28, step #138] loss: 0.7251782623126353\n",
      "[EPOCH #28, step #140] loss: 0.7274919845533709\n",
      "[EPOCH #28, step #142] loss: 0.7270342336668001\n",
      "[EPOCH #28, step #144] loss: 0.7241545623746412\n",
      "[EPOCH #28, step #146] loss: 0.7252952837619652\n",
      "[EPOCH #28, step #148] loss: 0.7264984236067573\n",
      "[EPOCH #28, step #150] loss: 0.7268118623471418\n",
      "[EPOCH #28, step #152] loss: 0.7264760099594889\n",
      "[EPOCH #28, step #154] loss: 0.7272540113618297\n",
      "[EPOCH #28, step #156] loss: 0.7304853419209741\n",
      "[EPOCH #28, step #158] loss: 0.7279262357162979\n",
      "[EPOCH #28, step #160] loss: 0.7282963193351437\n",
      "[EPOCH #28, step #162] loss: 0.7262027345917708\n",
      "[EPOCH #28, step #164] loss: 0.7257556906252196\n",
      "[EPOCH #28, step #166] loss: 0.7263237900005843\n",
      "[EPOCH #28, step #168] loss: 0.7267974123094209\n",
      "[EPOCH #28, step #170] loss: 0.7252832740022425\n",
      "[EPOCH #28, step #172] loss: 0.7243422964060238\n",
      "[EPOCH #28, step #174] loss: 0.7265925988129207\n",
      "[EPOCH #28, step #176] loss: 0.7277832777149933\n",
      "[EPOCH #28, step #178] loss: 0.7254408900964193\n",
      "[EPOCH #28, step #180] loss: 0.7263803709277791\n",
      "[EPOCH #28, step #182] loss: 0.7250422679009985\n",
      "[EPOCH #28, step #184] loss: 0.7231143998133169\n",
      "[EPOCH #28, step #186] loss: 0.7251360720810406\n",
      "[EPOCH #28, step #188] loss: 0.7237832891562629\n",
      "[EPOCH #28, step #190] loss: 0.7233877788975601\n",
      "[EPOCH #28, step #192] loss: 0.72295388239653\n",
      "[EPOCH #28, step #194] loss: 0.7244171633170201\n",
      "[EPOCH #28, step #196] loss: 0.7244016726307457\n",
      "[EPOCH #28, step #198] loss: 0.7243336794064872\n",
      "[EPOCH #28, step #200] loss: 0.7245229813293438\n",
      "[EPOCH #28, step #202] loss: 0.7238621698518105\n",
      "[EPOCH #28, step #204] loss: 0.7236233765032233\n",
      "[EPOCH #28, step #206] loss: 0.7247011924999348\n",
      "[EPOCH #28, step #208] loss: 0.7256093126449858\n",
      "[EPOCH #28, step #210] loss: 0.7267958896137526\n",
      "[EPOCH #28, step #212] loss: 0.7259410952738193\n",
      "[EPOCH #28, step #214] loss: 0.7256595691969229\n",
      "[EPOCH #28, step #216] loss: 0.7247220654092077\n",
      "[EPOCH #28, step #218] loss: 0.7223298287010629\n",
      "[EPOCH #28, step #220] loss: 0.7227023309981662\n",
      "[EPOCH #28, step #222] loss: 0.721266827107545\n",
      "[EPOCH #28, step #224] loss: 0.7213257639937931\n",
      "[EPOCH #28, step #226] loss: 0.7211805307655083\n",
      "[EPOCH #28, step #228] loss: 0.7193564287179423\n",
      "[EPOCH #28, step #230] loss: 0.7198623236897704\n",
      "[EPOCH #28, step #232] loss: 0.7217693631996924\n",
      "[EPOCH #28, step #234] loss: 0.7220281528665664\n",
      "[EPOCH #28, step #236] loss: 0.7224694984623149\n",
      "[EPOCH #28, step #238] loss: 0.7236166036528024\n",
      "[EPOCH #28, step #240] loss: 0.7252988509864728\n",
      "[EPOCH #28, step #242] loss: 0.723429549746062\n",
      "[EPOCH #28, step #244] loss: 0.7228178324748059\n",
      "[EPOCH #28, step #246] loss: 0.7201247493385786\n",
      "[EPOCH #28, step #248] loss: 0.7183712776525911\n",
      "[EPOCH #28, step #250] loss: 0.7188554197787289\n",
      "[EPOCH #28, step #252] loss: 0.7211305068533411\n",
      "[EPOCH #28, step #254] loss: 0.7201324000662448\n",
      "[EPOCH #28, step #256] loss: 0.718828338767304\n",
      "[EPOCH #28, step #258] loss: 0.717554296938609\n",
      "[EPOCH #28, step #260] loss: 0.7163742287976532\n",
      "[EPOCH #28, step #262] loss: 0.7173562252136237\n",
      "[EPOCH #28, step #264] loss: 0.7171853221250031\n",
      "[EPOCH #28, step #266] loss: 0.7163253259681137\n",
      "[EPOCH #28, step #268] loss: 0.7167576688262166\n",
      "[EPOCH #28, step #270] loss: 0.7177061730535268\n",
      "[EPOCH #28, step #272] loss: 0.7168994879438764\n",
      "[EPOCH #28, step #274] loss: 0.71662793869322\n",
      "[EPOCH #28, step #276] loss: 0.715751543210732\n",
      "[EPOCH #28, step #278] loss: 0.7166722387502698\n",
      "[EPOCH #28, step #280] loss: 0.7146764076795442\n",
      "[EPOCH #28, step #282] loss: 0.7142265731264762\n",
      "[EPOCH #28, step #284] loss: 0.7150296706379505\n",
      "[EPOCH #28, step #286] loss: 0.7153187690607762\n",
      "[EPOCH #28, step #288] loss: 0.7139657360975306\n",
      "[EPOCH #28, step #290] loss: 0.7151990603028294\n",
      "[EPOCH #28, step #292] loss: 0.7142878162067497\n",
      "[EPOCH #28, step #294] loss: 0.7144020666005247\n",
      "[EPOCH #28, step #296] loss: 0.7138101163034889\n",
      "[EPOCH #28, step #298] loss: 0.714457587205048\n",
      "[EPOCH #28, step #300] loss: 0.71352548669541\n",
      "[EPOCH #28, step #302] loss: 0.7133338051562262\n",
      "[EPOCH #28, step #304] loss: 0.713886038152898\n",
      "[EPOCH #28, step #306] loss: 0.7144344528160188\n",
      "[EPOCH #28, step #308] loss: 0.7154546356413357\n",
      "[EPOCH #28, step #310] loss: 0.7158569087457044\n",
      "[EPOCH #28, step #312] loss: 0.7176312339096405\n",
      "[EPOCH #28, step #314] loss: 0.7170441982765047\n",
      "[EPOCH #28, step #316] loss: 0.7175904840983051\n",
      "[EPOCH #28, step #318] loss: 0.7186593489493696\n",
      "[EPOCH #28, step #320] loss: 0.7172529197463365\n",
      "[EPOCH #28, step #322] loss: 0.717872472877842\n",
      "[EPOCH #28, step #324] loss: 0.7181047582167845\n",
      "[EPOCH #28, step #326] loss: 0.7172000231819415\n",
      "[EPOCH #28, step #328] loss: 0.7181519976955779\n",
      "[EPOCH #28, step #330] loss: 0.71739735321516\n",
      "[EPOCH #28, step #332] loss: 0.7187029402087759\n",
      "[EPOCH #28, step #334] loss: 0.7181631897367649\n",
      "[EPOCH #28, step #336] loss: 0.7168926291985752\n",
      "[EPOCH #28, step #338] loss: 0.7164592415446025\n",
      "[EPOCH #28, step #340] loss: 0.7166439628234007\n",
      "[EPOCH #28, step #342] loss: 0.7173119021834854\n",
      "[EPOCH #28, step #344] loss: 0.7183231562376022\n",
      "[EPOCH #28, step #346] loss: 0.7191495283450449\n",
      "[EPOCH #28, step #348] loss: 0.7191857295511104\n",
      "[EPOCH #28, step #350] loss: 0.720681568623608\n",
      "[EPOCH #28, step #352] loss: 0.7196009693925847\n",
      "[EPOCH #28, step #354] loss: 0.7187663900600353\n",
      "[EPOCH #28, step #356] loss: 0.7194029468030823\n",
      "[EPOCH #28, step #358] loss: 0.7193717474641906\n",
      "[EPOCH #28, step #360] loss: 0.719612526224921\n",
      "[EPOCH #28, step #362] loss: 0.720447223335915\n",
      "[EPOCH #28, step #364] loss: 0.7193154857991493\n",
      "[EPOCH #28, step #366] loss: 0.7186417829356986\n",
      "[EPOCH #28, step #368] loss: 0.717959901625871\n",
      "[EPOCH #28, step #370] loss: 0.7185532058265331\n",
      "[EPOCH #28, step #372] loss: 0.7184960359143188\n",
      "[EPOCH #28, step #374] loss: 0.7200851144393285\n",
      "[EPOCH #28, step #376] loss: 0.7191941796231333\n",
      "[EPOCH #28, step #378] loss: 0.7193537843180206\n",
      "[EPOCH #28, step #380] loss: 0.7182360557042394\n",
      "[EPOCH #28, step #382] loss: 0.7175796725653482\n",
      "[EPOCH #28, step #384] loss: 0.7170707979372569\n",
      "[EPOCH #28, step #386] loss: 0.7171668131145088\n",
      "[EPOCH #28, step #388] loss: 0.7175190551038879\n",
      "[EPOCH #28, step #390] loss: 0.7177813051225584\n",
      "[EPOCH #28, step #392] loss: 0.7175355562347796\n",
      "[EPOCH #28, step #394] loss: 0.716945771439166\n",
      "[EPOCH #28, step #396] loss: 0.7165832115285643\n",
      "[EPOCH #28, step #398] loss: 0.7165146569784423\n",
      "[EPOCH #28, step #400] loss: 0.7169349108476591\n",
      "[EPOCH #28, step #402] loss: 0.7175430823718348\n",
      "[EPOCH #28, step #404] loss: 0.7160399941382585\n",
      "[EPOCH #28, step #406] loss: 0.7172831924819829\n",
      "[EPOCH #28, step #408] loss: 0.7172440877389208\n",
      "[EPOCH #28, step #410] loss: 0.7168568121473284\n",
      "[EPOCH #28, step #412] loss: 0.7168603361591012\n",
      "[EPOCH #28, step #414] loss: 0.7157790936260339\n",
      "[EPOCH #28, step #416] loss: 0.7153258331888299\n",
      "[EPOCH #28, step #418] loss: 0.7157583564946646\n",
      "[EPOCH #28, step #420] loss: 0.7152557630366214\n",
      "[EPOCH #28, step #422] loss: 0.7161428908295665\n",
      "[EPOCH #28, step #424] loss: 0.7160033656218473\n",
      "[EPOCH #28, step #426] loss: 0.7152171750188712\n",
      "[EPOCH #28, step #428] loss: 0.7151808113137603\n",
      "[EPOCH #28, step #430] loss: 0.7153662303138498\n",
      "[EPOCH #28, step #432] loss: 0.7150676568096835\n",
      "[EPOCH #28, step #434] loss: 0.7147864392776598\n",
      "[EPOCH #28, step #436] loss: 0.7139895926964911\n",
      "[EPOCH #28, step #438] loss: 0.7139713583951116\n",
      "[EPOCH #28, step #440] loss: 0.7121386901051009\n",
      "[EPOCH #28, step #442] loss: 0.7118536254756875\n",
      "[EPOCH #28, step #444] loss: 0.7120804483301184\n",
      "[EPOCH #28, step #446] loss: 0.7143860814688723\n",
      "[EPOCH #28, step #448] loss: 0.7140259029206826\n",
      "[EPOCH #28, step #450] loss: 0.7135857601387802\n",
      "[EPOCH #28, step #452] loss: 0.713499213554475\n",
      "[EPOCH #28, step #454] loss: 0.7160278717240135\n",
      "[EPOCH #28, step #456] loss: 0.715418258368056\n",
      "[EPOCH #28, step #458] loss: 0.7153197779504822\n",
      "[EPOCH #28, step #460] loss: 0.7157964946261715\n",
      "[EPOCH #28, step #462] loss: 0.7157137761491936\n",
      "[EPOCH #28, step #464] loss: 0.7149353852836035\n",
      "[EPOCH #28, step #466] loss: 0.71501801764429\n",
      "[EPOCH #28, step #468] loss: 0.7150522858095067\n",
      "[EPOCH #28, step #470] loss: 0.7148090280798084\n",
      "[EPOCH #28, step #472] loss: 0.7144684162754841\n",
      "[EPOCH #28, step #474] loss: 0.7148521542549133\n",
      "[EPOCH #28, step #476] loss: 0.714352189619836\n",
      "[EPOCH #28, step #478] loss: 0.7134431708829637\n",
      "[EPOCH #28, step #480] loss: 0.7138484914684494\n",
      "[EPOCH #28, step #482] loss: 0.713964575442715\n",
      "[EPOCH #28, step #484] loss: 0.7132686817768923\n",
      "[EPOCH #28, step #486] loss: 0.7134222963507415\n",
      "[EPOCH #28, step #488] loss: 0.7134634910916989\n",
      "[EPOCH #28, step #490] loss: 0.7143272256171388\n",
      "[EPOCH #28, step #492] loss: 0.7147586615283881\n",
      "[EPOCH #28, step #494] loss: 0.7161418807626975\n",
      "[EPOCH #28, step #496] loss: 0.7162261795350003\n",
      "[EPOCH #28, step #498] loss: 0.7162778675556183\n",
      "[EPOCH #28, step #500] loss: 0.7157384230348165\n",
      "[EPOCH #28, step #502] loss: 0.7162004854404191\n",
      "[EPOCH #28, step #504] loss: 0.7158394367978125\n",
      "[EPOCH #28, step #506] loss: 0.7157172062810826\n",
      "[EPOCH #28, step #508] loss: 0.7153221913896984\n",
      "[EPOCH #28, step #510] loss: 0.7145391115936981\n",
      "[EPOCH #28, step #512] loss: 0.7145079066414117\n",
      "[EPOCH #28, step #514] loss: 0.7148681854738772\n",
      "[EPOCH #28, step #516] loss: 0.7144822462730297\n",
      "[EPOCH #28, step #518] loss: 0.713579783779578\n",
      "[EPOCH #28, step #520] loss: 0.7134369425261089\n",
      "[EPOCH #28, step #522] loss: 0.7144722634246199\n",
      "[EPOCH #28, step #524] loss: 0.7148413679713295\n",
      "[EPOCH #28, step #526] loss: 0.7148343073575275\n",
      "[EPOCH #28, step #528] loss: 0.7152320736973408\n",
      "[EPOCH #28, step #530] loss: 0.7151129942829326\n",
      "[EPOCH #28, step #532] loss: 0.7154386542304149\n",
      "[EPOCH #28, step #534] loss: 0.7157341089204093\n",
      "[EPOCH #28, step #536] loss: 0.7154496366529269\n",
      "[EPOCH #28, step #538] loss: 0.7153905352546466\n",
      "[EPOCH #28, step #540] loss: 0.714600297637876\n",
      "[EPOCH #28, step #542] loss: 0.7136369891478431\n",
      "[EPOCH #28, step #544] loss: 0.7132099685865805\n",
      "[EPOCH #28, step #546] loss: 0.7129097161933753\n",
      "[EPOCH #28, step #548] loss: 0.7134684717828893\n",
      "[EPOCH #28, step #550] loss: 0.7128502257614516\n",
      "[EPOCH #28, step #552] loss: 0.7120016073339887\n",
      "[EPOCH #28, step #554] loss: 0.7129590188597774\n",
      "[EPOCH #28, step #556] loss: 0.7123332344651008\n",
      "[EPOCH #28, step #558] loss: 0.7119334664242425\n",
      "[EPOCH #28, step #560] loss: 0.7118303961719846\n",
      "[EPOCH #28, step #562] loss: 0.7123033204256536\n",
      "[EPOCH #28, step #564] loss: 0.7126837802144278\n",
      "[EPOCH #28, step #566] loss: 0.712224234296321\n",
      "[EPOCH #28, step #568] loss: 0.7122480957809777\n",
      "[EPOCH #28, step #570] loss: 0.712336694244328\n",
      "[EPOCH #28, step #572] loss: 0.7118784903335738\n",
      "[EPOCH #28, step #574] loss: 0.7112863099575043\n",
      "[EPOCH #28, step #576] loss: 0.711075215808647\n",
      "[EPOCH #28, step #578] loss: 0.711465627469753\n",
      "[EPOCH #28, step #580] loss: 0.7110468545181616\n",
      "[EPOCH #28, step #582] loss: 0.7108070974080067\n",
      "[EPOCH #28, step #584] loss: 0.7110328601975726\n",
      "[EPOCH #28, step #586] loss: 0.710920903508058\n",
      "[EPOCH #28, step #588] loss: 0.7110340023486036\n",
      "[EPOCH #28, step #590] loss: 0.7111957533105375\n",
      "[EPOCH #28, step #592] loss: 0.7100270577968675\n",
      "[EPOCH #28, step #594] loss: 0.7110776824610574\n",
      "[EPOCH #28, step #596] loss: 0.7105234418582277\n",
      "[EPOCH #28, step #598] loss: 0.7099633944751026\n",
      "[EPOCH #28, step #600] loss: 0.7097700005164758\n",
      "[EPOCH #28, step #602] loss: 0.710310367407095\n",
      "[EPOCH #28, step #604] loss: 0.7099482465381465\n",
      "[EPOCH #28, step #606] loss: 0.7101177157837241\n",
      "[EPOCH #28, step #608] loss: 0.7093055705327315\n",
      "[EPOCH #28, step #610] loss: 0.7090361855814383\n",
      "[EPOCH #28, step #612] loss: 0.7088631699758097\n",
      "[EPOCH #28, step #614] loss: 0.7085068690582988\n",
      "[EPOCH #28, step #616] loss: 0.708223334732473\n",
      "[EPOCH #28, step #618] loss: 0.7079004914483269\n",
      "[EPOCH #28, step #620] loss: 0.7079909098801022\n",
      "[EPOCH #28, step #622] loss: 0.7077750385668649\n",
      "[EPOCH #28, step #624] loss: 0.7073070656299592\n",
      "[EPOCH #28, step #626] loss: 0.7072897140394178\n",
      "[EPOCH #28, step #628] loss: 0.7067269820761415\n",
      "[EPOCH #28, step #630] loss: 0.7068909011344335\n",
      "[EPOCH #28, step #632] loss: 0.7073191393514003\n",
      "[EPOCH #28, step #634] loss: 0.7072450459942105\n",
      "[EPOCH #28, step #636] loss: 0.7073325191506037\n",
      "[EPOCH #28, step #638] loss: 0.7075521674980767\n",
      "[EPOCH #28, step #640] loss: 0.7069757425933844\n",
      "[EPOCH #28, step #642] loss: 0.7062022781483308\n",
      "[EPOCH #28, step #644] loss: 0.7062745166379352\n",
      "[EPOCH #28, step #646] loss: 0.7066054309169881\n",
      "[EPOCH #28, step #648] loss: 0.7060916939942605\n",
      "[EPOCH #28, step #650] loss: 0.7062757480345929\n",
      "[EPOCH #28, step #652] loss: 0.705814488768395\n",
      "[EPOCH #28, step #654] loss: 0.7054038093745253\n",
      "[EPOCH #28, step #656] loss: 0.7060050678126163\n",
      "[EPOCH #28, step #658] loss: 0.7059076055319067\n",
      "[EPOCH #28, step #660] loss: 0.7058390550732432\n",
      "[EPOCH #28, step #662] loss: 0.7060965750461969\n",
      "[EPOCH #28, step #664] loss: 0.7068143383452766\n",
      "[EPOCH #28, step #666] loss: 0.7072547588838094\n",
      "[EPOCH #28, step #668] loss: 0.7064724107494269\n",
      "[EPOCH #28, step #670] loss: 0.7059767497189887\n",
      "[EPOCH #28, step #672] loss: 0.7059464724333113\n",
      "[EPOCH #28, step #674] loss: 0.705917754040824\n",
      "[EPOCH #28, step #676] loss: 0.7059427656926643\n",
      "[EPOCH #28, step #678] loss: 0.7055593030705544\n",
      "[EPOCH #28, step #680] loss: 0.7061084698387879\n",
      "[EPOCH #28, step #682] loss: 0.706115548249394\n",
      "[EPOCH #28, step #684] loss: 0.7053077660337852\n",
      "[EPOCH #28, step #686] loss: 0.7065802845545385\n",
      "[EPOCH #28, step #688] loss: 0.7071658817534869\n",
      "[EPOCH #28, step #690] loss: 0.7072014543841095\n",
      "[EPOCH #28, step #692] loss: 0.7063702809561211\n",
      "[EPOCH #28, step #694] loss: 0.7060302281765629\n",
      "[EPOCH #28, step #696] loss: 0.7067440453398347\n",
      "[EPOCH #28, step #698] loss: 0.706434739910823\n",
      "[EPOCH #28, step #700] loss: 0.7062120284359057\n",
      "[EPOCH #28, step #702] loss: 0.7059845016106094\n",
      "[EPOCH #28, step #704] loss: 0.7058681470071171\n",
      "[EPOCH #28, step #706] loss: 0.7058209840740476\n",
      "[EPOCH #28, step #708] loss: 0.7062512638496579\n",
      "[EPOCH #28, step #710] loss: 0.7064991324050182\n",
      "[EPOCH #28, step #712] loss: 0.7068691293579666\n",
      "[EPOCH #28, step #714] loss: 0.7061599593270909\n",
      "[EPOCH #28, step #716] loss: 0.7055296693179065\n",
      "[EPOCH #28, step #718] loss: 0.7055508150137515\n",
      "[EPOCH #28, step #720] loss: 0.7054554978579324\n",
      "[EPOCH #28, step #722] loss: 0.7048171600983846\n",
      "[EPOCH #28, step #724] loss: 0.7048430157324364\n",
      "[EPOCH #28, step #726] loss: 0.7047703993984561\n",
      "[EPOCH #28, step #728] loss: 0.7045099552317085\n",
      "[EPOCH #28, step #730] loss: 0.7041956102513746\n",
      "[EPOCH #28, step #732] loss: 0.7044636401643857\n",
      "[EPOCH #28, step #734] loss: 0.7043132783807053\n",
      "[EPOCH #28, step #736] loss: 0.7046993414655307\n",
      "[EPOCH #28, step #738] loss: 0.7046794899624642\n",
      "[EPOCH #28, step #740] loss: 0.7047531924709457\n",
      "[EPOCH #28, step #742] loss: 0.7045061543964922\n",
      "[EPOCH #28, step #744] loss: 0.7041982796968229\n",
      "[EPOCH #28, step #746] loss: 0.7040371968045611\n",
      "[EPOCH #28, step #748] loss: 0.7041319038704018\n",
      "[EPOCH #28, step #750] loss: 0.7034998933540362\n",
      "[EPOCH #28, step #752] loss: 0.703780396427133\n",
      "[EPOCH #28, step #754] loss: 0.7044277260437707\n",
      "[EPOCH #28, step #756] loss: 0.7047188447953215\n",
      "[EPOCH #28, step #758] loss: 0.7048207277012437\n",
      "[EPOCH #28, step #760] loss: 0.7041447891629792\n",
      "[EPOCH #28, step #762] loss: 0.70486467160763\n",
      "[EPOCH #28, step #764] loss: 0.7053762078090431\n",
      "[EPOCH #28, step #766] loss: 0.7060048161110947\n",
      "[EPOCH #28, step #768] loss: 0.7055631291765541\n",
      "[EPOCH #28, step #770] loss: 0.7052313856461633\n",
      "[EPOCH #28, step #772] loss: 0.7049538126314133\n",
      "[EPOCH #28, step #774] loss: 0.7045509487005972\n",
      "[EPOCH #28, step #776] loss: 0.7044963416484025\n",
      "[EPOCH #28, step #778] loss: 0.7044669213167969\n",
      "[EPOCH #28, step #780] loss: 0.7044791640492011\n",
      "[EPOCH #28, step #782] loss: 0.704464611974408\n",
      "[EPOCH #28, step #784] loss: 0.7050403201086506\n",
      "[EPOCH #28, step #786] loss: 0.7051335775602273\n",
      "[EPOCH #28, step #788] loss: 0.7056066923608345\n",
      "[EPOCH #28, step #790] loss: 0.7051189481345501\n",
      "[EPOCH #28, step #792] loss: 0.7048349800093328\n",
      "[EPOCH #28, step #794] loss: 0.7047590803237831\n",
      "[EPOCH #28, step #796] loss: 0.7043907412957666\n",
      "[EPOCH #28, step #798] loss: 0.7038087118813332\n",
      "[EPOCH #28, step #800] loss: 0.7038163692875301\n",
      "[EPOCH #28, step #802] loss: 0.7038461392093566\n",
      "[EPOCH #28, step #804] loss: 0.7040344177380852\n",
      "[EPOCH #28, step #806] loss: 0.7038087834692947\n",
      "[EPOCH #28, step #808] loss: 0.7038319802881023\n",
      "[EPOCH #28, step #810] loss: 0.7039781631178391\n",
      "[EPOCH #28, step #812] loss: 0.704332474944483\n",
      "[EPOCH #28, step #814] loss: 0.7038458344943684\n",
      "[EPOCH #28, step #816] loss: 0.7039050301365928\n",
      "[EPOCH #28, step #818] loss: 0.7034322745888807\n",
      "[EPOCH #28, step #820] loss: 0.703247798472897\n",
      "[EPOCH #28, step #822] loss: 0.7032356399630862\n",
      "[EPOCH #28, step #824] loss: 0.7038600541425474\n",
      "[EPOCH #28, step #826] loss: 0.7042932789840318\n",
      "[EPOCH #28, step #828] loss: 0.7040105943620852\n",
      "[EPOCH #28, step #830] loss: 0.703938689168036\n",
      "[EPOCH #28, step #832] loss: 0.7040716803052417\n",
      "[EPOCH #28, step #834] loss: 0.703476395132299\n",
      "[EPOCH #28, step #836] loss: 0.7034423330458262\n",
      "[EPOCH #28, step #838] loss: 0.7032968082040086\n",
      "[EPOCH #28, step #840] loss: 0.7031814602517061\n",
      "[EPOCH #28, step #842] loss: 0.7031157302227168\n",
      "[EPOCH #28, step #844] loss: 0.7029626957587236\n",
      "[EPOCH #28, step #846] loss: 0.7032558715153472\n",
      "[EPOCH #28, step #848] loss: 0.7035955695964141\n",
      "[EPOCH #28, step #850] loss: 0.703543789150712\n",
      "[EPOCH #28, step #852] loss: 0.7033709483821674\n",
      "[EPOCH #28, step #854] loss: 0.702951589784427\n",
      "[EPOCH #28, step #856] loss: 0.7029104531680689\n",
      "[EPOCH #28, step #858] loss: 0.7037354883790987\n",
      "[EPOCH #28, step #860] loss: 0.7037703322028173\n",
      "[EPOCH #28, step #862] loss: 0.703726917177197\n",
      "[EPOCH #28, step #864] loss: 0.7044078632413996\n",
      "[EPOCH #28, step #866] loss: 0.704969411816839\n",
      "[EPOCH #28, step #868] loss: 0.7051559595264691\n",
      "[EPOCH #28, step #870] loss: 0.706016144833937\n",
      "[EPOCH #28, step #872] loss: 0.7062349468128242\n",
      "[EPOCH #28, step #874] loss: 0.7063325644050326\n",
      "[EPOCH #28, step #876] loss: 0.7060772514431615\n",
      "[EPOCH #28, step #878] loss: 0.7066223382170018\n",
      "[EPOCH #28, step #880] loss: 0.7063049607900702\n",
      "[EPOCH #28, step #882] loss: 0.7062867139534664\n",
      "[EPOCH #28, step #884] loss: 0.7059699518027278\n",
      "[EPOCH #28, step #886] loss: 0.705717694077309\n",
      "[EPOCH #28, step #888] loss: 0.70565529744255\n",
      "[EPOCH #28, step #890] loss: 0.7059204387912311\n",
      "[EPOCH #28, step #892] loss: 0.7059837659322401\n",
      "[EPOCH #28, step #894] loss: 0.7064856685240175\n",
      "[EPOCH #28, step #896] loss: 0.7064197745377669\n",
      "[EPOCH #28, step #898] loss: 0.7064413767933713\n",
      "[EPOCH #28, step #900] loss: 0.7057739249311726\n",
      "[EPOCH #28, step #902] loss: 0.7064790933466168\n",
      "[EPOCH #28, step #904] loss: 0.7064269476009337\n",
      "[EPOCH #28, step #906] loss: 0.7067669081812789\n",
      "[EPOCH #28, step #908] loss: 0.7066226388328802\n",
      "[EPOCH #28, step #910] loss: 0.706419739303814\n",
      "[EPOCH #28, step #912] loss: 0.7062469154661614\n",
      "[EPOCH #28, step #914] loss: 0.7061506318752883\n",
      "[EPOCH #28, step #916] loss: 0.7068381139697789\n",
      "[EPOCH #28, step #918] loss: 0.7067348494460974\n",
      "[EPOCH #28, step #920] loss: 0.7062407733466027\n",
      "[EPOCH #28, step #922] loss: 0.7061758066082569\n",
      "[EPOCH #28, step #924] loss: 0.7062569599054955\n",
      "[EPOCH #28, step #926] loss: 0.7064576001261174\n",
      "[EPOCH #28, step #928] loss: 0.7066861959685551\n",
      "[EPOCH #28, step #930] loss: 0.7064103134112507\n",
      "[EPOCH #28, step #932] loss: 0.7060991322655642\n",
      "[EPOCH #28, step #934] loss: 0.7061716364188628\n",
      "[EPOCH #28, step #936] loss: 0.706414589902889\n",
      "[EPOCH #28, step #938] loss: 0.7068671496690144\n",
      "[EPOCH #28, step #940] loss: 0.7068291412751555\n",
      "[EPOCH #28, step #942] loss: 0.7064031686945912\n",
      "[EPOCH #28, step #944] loss: 0.7068956645865919\n",
      "[EPOCH #28, step #946] loss: 0.7065925980350661\n",
      "[EPOCH #28, step #948] loss: 0.706904401973251\n",
      "[EPOCH #28, step #950] loss: 0.7071937215597722\n",
      "[EPOCH #28, step #952] loss: 0.7072705634774842\n",
      "[EPOCH #28, step #954] loss: 0.7071614374821099\n",
      "[EPOCH #28, step #956] loss: 0.7067357361659237\n",
      "[EPOCH #28, step #958] loss: 0.7061718058567474\n",
      "[EPOCH #28, step #960] loss: 0.7060773178051215\n",
      "[EPOCH #28, step #962] loss: 0.7057661063357925\n",
      "[EPOCH #28, step #964] loss: 0.7055778701842758\n",
      "[EPOCH #28, step #966] loss: 0.706109428248583\n",
      "[EPOCH #28, step #968] loss: 0.7058651335806546\n",
      "[EPOCH #28, step #970] loss: 0.7056882109964913\n",
      "[EPOCH #28, step #972] loss: 0.7055975686823844\n",
      "[EPOCH #28, step #974] loss: 0.7059813301227031\n",
      "[EPOCH #28, step #976] loss: 0.7058815225089463\n",
      "[EPOCH #28, step #978] loss: 0.7055498688986889\n",
      "[EPOCH #28, step #980] loss: 0.7053288681761084\n",
      "[EPOCH #28, step #982] loss: 0.7049404272197586\n",
      "[EPOCH #28, step #984] loss: 0.7049442251775471\n",
      "[EPOCH #28, step #986] loss: 0.7052392106741032\n",
      "[EPOCH #28, step #988] loss: 0.7051945123049318\n",
      "[EPOCH #28, step #990] loss: 0.7056098212718241\n",
      "[EPOCH #28, step #992] loss: 0.7054308228952527\n",
      "[EPOCH #28, step #994] loss: 0.7052690383028145\n",
      "[EPOCH #28, step #996] loss: 0.7049761184508966\n",
      "[EPOCH #28, step #998] loss: 0.7054117984987713\n",
      "[EPOCH #28, step #1000] loss: 0.7053326768623842\n",
      "[EPOCH #28, step #1002] loss: 0.7055467499841602\n",
      "[EPOCH #28, step #1004] loss: 0.7060675685826818\n",
      "[EPOCH #28, step #1006] loss: 0.7063521728171137\n",
      "[EPOCH #28, step #1008] loss: 0.706411552869293\n",
      "[EPOCH #28, step #1010] loss: 0.7065401689972062\n",
      "[EPOCH #28, step #1012] loss: 0.7062188703621952\n",
      "[EPOCH #28, step #1014] loss: 0.706192967471818\n",
      "[EPOCH #28, step #1016] loss: 0.7059298987145972\n",
      "[EPOCH #28, step #1018] loss: 0.7055869459140757\n",
      "[EPOCH #28, step #1020] loss: 0.7054606128947392\n",
      "[EPOCH #28, step #1022] loss: 0.7054588451966979\n",
      "[EPOCH #28, step #1024] loss: 0.7056392766644315\n",
      "[EPOCH #28, step #1026] loss: 0.7055961099809658\n",
      "[EPOCH #28, step #1028] loss: 0.705811461406616\n",
      "[EPOCH #28, step #1030] loss: 0.7058402898384458\n",
      "[EPOCH #28, step #1032] loss: 0.7061128573201864\n",
      "[EPOCH #28, step #1034] loss: 0.7065145174806244\n",
      "[EPOCH #28, step #1036] loss: 0.7065818144391105\n",
      "[EPOCH #28, step #1038] loss: 0.7067343861266211\n",
      "[EPOCH #28, step #1040] loss: 0.7068604013160601\n",
      "[EPOCH #28, step #1042] loss: 0.7066044579844918\n",
      "[EPOCH #28, step #1044] loss: 0.7062695979073857\n",
      "[EPOCH #28, step #1046] loss: 0.7057437104419401\n",
      "[EPOCH #28, step #1048] loss: 0.7056113865201649\n",
      "[EPOCH #28, step #1050] loss: 0.7054909848945692\n",
      "[EPOCH #28, step #1052] loss: 0.7056416333259454\n",
      "[EPOCH #28, step #1054] loss: 0.7055480002368231\n",
      "[EPOCH #28, step #1056] loss: 0.7056572147016832\n",
      "[EPOCH #28, step #1058] loss: 0.7058266089055987\n",
      "[EPOCH #28, step #1060] loss: 0.7054546649982972\n",
      "[EPOCH #28, step #1062] loss: 0.7053638573732448\n",
      "[EPOCH #28, step #1064] loss: 0.7051499098819186\n",
      "[EPOCH #28, step #1066] loss: 0.7047730560406638\n",
      "[EPOCH #28, step #1068] loss: 0.7045743028425078\n",
      "[EPOCH #28, step #1070] loss: 0.7048944448139153\n",
      "[EPOCH #28, step #1072] loss: 0.7047704555587244\n",
      "[EPOCH #28, step #1074] loss: 0.70473261690417\n",
      "[EPOCH #28, step #1076] loss: 0.7045411801410142\n",
      "[EPOCH #28, step #1078] loss: 0.7043658558614172\n",
      "[EPOCH #28, step #1080] loss: 0.704955986825875\n",
      "[EPOCH #28, step #1082] loss: 0.7050097947002888\n",
      "[EPOCH #28, step #1084] loss: 0.7046786924798367\n",
      "[EPOCH #28, step #1086] loss: 0.7045738476207746\n",
      "[EPOCH #28, step #1088] loss: 0.7045279271811712\n",
      "[EPOCH #28, step #1090] loss: 0.704375316512683\n",
      "[EPOCH #28, step #1092] loss: 0.704661174027176\n",
      "[EPOCH #28, step #1094] loss: 0.7044529307786732\n",
      "[EPOCH #28, step #1096] loss: 0.7043376481712353\n",
      "[EPOCH #28, step #1098] loss: 0.7044448409843055\n",
      "[EPOCH #28, step #1100] loss: 0.7045061928672643\n",
      "[EPOCH #28, step #1102] loss: 0.704449303819716\n",
      "[EPOCH #28, step #1104] loss: 0.7042341149635445\n",
      "[EPOCH #28, step #1106] loss: 0.7045163172881885\n",
      "[EPOCH #28, step #1108] loss: 0.7049393587627316\n",
      "[EPOCH #28, step #1110] loss: 0.7052776834832775\n",
      "[EPOCH #28, step #1112] loss: 0.7052127422642729\n",
      "[EPOCH #28, step #1114] loss: 0.7053487864176788\n",
      "[EPOCH #28, step #1116] loss: 0.7049959629187119\n",
      "[EPOCH #28, step #1118] loss: 0.7050191854477141\n",
      "[EPOCH #28, step #1120] loss: 0.7049778585158535\n",
      "[EPOCH #28, step #1122] loss: 0.7051182074649782\n",
      "[EPOCH #28, step #1124] loss: 0.7052080489397049\n",
      "[EPOCH #28, step #1126] loss: 0.7050783191117547\n",
      "[EPOCH #28, step #1128] loss: 0.7056926254602108\n",
      "[EPOCH #28, step #1130] loss: 0.7054745008021093\n",
      "[EPOCH #28, step #1132] loss: 0.7056648256314716\n",
      "[EPOCH #28, step #1134] loss: 0.7058888786821114\n",
      "[EPOCH #28, step #1136] loss: 0.7057459565795297\n",
      "[EPOCH #28, step #1138] loss: 0.7058409096197249\n",
      "[EPOCH #28, step #1140] loss: 0.7059095588746978\n",
      "[EPOCH #28, step #1142] loss: 0.7063489893837551\n",
      "[EPOCH #28, step #1144] loss: 0.7059628006802896\n",
      "[EPOCH #28, step #1146] loss: 0.7057920363979331\n",
      "[EPOCH #28, step #1148] loss: 0.7055416597009639\n",
      "[EPOCH #28, step #1150] loss: 0.7055186326482004\n",
      "[EPOCH #28, step #1152] loss: 0.7051441769106742\n",
      "[EPOCH #28, step #1154] loss: 0.7054057317249702\n",
      "[EPOCH #28, step #1156] loss: 0.7058588460461271\n",
      "[EPOCH #28, step #1158] loss: 0.7059341014794381\n",
      "[EPOCH #28, step #1160] loss: 0.7063132728691455\n",
      "[EPOCH #28, step #1162] loss: 0.7063097966480952\n",
      "[EPOCH #28, step #1164] loss: 0.7063833766612884\n",
      "[EPOCH #28, step #1166] loss: 0.7062875528236485\n",
      "[EPOCH #28, step #1168] loss: 0.7065745061717551\n",
      "[EPOCH #28, step #1170] loss: 0.7065803249685506\n",
      "[EPOCH #28, step #1172] loss: 0.7068071703141506\n",
      "[EPOCH #28, step #1174] loss: 0.7066267573199374\n",
      "[EPOCH #28, step #1176] loss: 0.7067839641918443\n",
      "[EPOCH #28, step #1178] loss: 0.7069458787955906\n",
      "[EPOCH #28, step #1180] loss: 0.7067893015616633\n",
      "[EPOCH #28, step #1182] loss: 0.7066436781408619\n",
      "[EPOCH #28, step #1184] loss: 0.7062318161695819\n",
      "[EPOCH #28, step #1186] loss: 0.7060341447491353\n",
      "[EPOCH #28, step #1188] loss: 0.7059441732823899\n",
      "[EPOCH #28, step #1190] loss: 0.7060880038064633\n",
      "[EPOCH #28, step #1192] loss: 0.7061303929056526\n",
      "[EPOCH #28, step #1194] loss: 0.7060188392839671\n",
      "[EPOCH #28, step #1196] loss: 0.7061997097461743\n",
      "[EPOCH #28, step #1198] loss: 0.7059578834050292\n",
      "[EPOCH #28, step #1200] loss: 0.7061660861120335\n",
      "[EPOCH #28, step #1202] loss: 0.7063872430315636\n",
      "[EPOCH #28, step #1204] loss: 0.7062444631613142\n",
      "[EPOCH #28, step #1206] loss: 0.7062739763831737\n",
      "[EPOCH #28, step #1208] loss: 0.7067723635975441\n",
      "[EPOCH #28, step #1210] loss: 0.7068563195592997\n",
      "[EPOCH #28, step #1212] loss: 0.7067980004285646\n",
      "[EPOCH #28, step #1214] loss: 0.7067255977372574\n",
      "[EPOCH #28, step #1216] loss: 0.7065709487595515\n",
      "[EPOCH #28, step #1218] loss: 0.7063570574011541\n",
      "[EPOCH #28, step #1220] loss: 0.7060485106452775\n",
      "[EPOCH #28, step #1222] loss: 0.7060327329722371\n",
      "[EPOCH #28, step #1224] loss: 0.7056517311383267\n",
      "[EPOCH #28, step #1226] loss: 0.7055847250234818\n",
      "[EPOCH #28, step #1228] loss: 0.7054369381596346\n",
      "[EPOCH #28, step #1230] loss: 0.7053932870407592\n",
      "[EPOCH #28, step #1232] loss: 0.7050863315758431\n",
      "[EPOCH #28, step #1234] loss: 0.7051973253971169\n",
      "[EPOCH #28, step #1236] loss: 0.7051502108067973\n",
      "[EPOCH #28, step #1238] loss: 0.7054316587054604\n",
      "[EPOCH #28, step #1240] loss: 0.7053437157925053\n",
      "[EPOCH #28, step #1242] loss: 0.7054072195425786\n",
      "[EPOCH #28, step #1244] loss: 0.7054123796013944\n",
      "[EPOCH #28, step #1246] loss: 0.7056074664773421\n",
      "[EPOCH #28, step #1248] loss: 0.7054934378883378\n",
      "[EPOCH #28, step #1250] loss: 0.7055576153867822\n",
      "[EPOCH #28, step #1252] loss: 0.7058452000902447\n",
      "[EPOCH #28, step #1254] loss: 0.7062654923514066\n",
      "[EPOCH #28, step #1256] loss: 0.7059997714101652\n",
      "[EPOCH #28, step #1258] loss: 0.7063532543026142\n",
      "[EPOCH #28, step #1260] loss: 0.7060919639305119\n",
      "[EPOCH #28, step #1262] loss: 0.7063206665377153\n",
      "[EPOCH #28, step #1264] loss: 0.7062428687283173\n",
      "[EPOCH #28, step #1266] loss: 0.7060649594102398\n",
      "[EPOCH #28, step #1268] loss: 0.7061078773064347\n",
      "[EPOCH #28, step #1270] loss: 0.7058508921499612\n",
      "[EPOCH #28, step #1272] loss: 0.7055853692008488\n",
      "[EPOCH #28, step #1274] loss: 0.7052666963432349\n",
      "[EPOCH #28, step #1276] loss: 0.7052731397404929\n",
      "[EPOCH #28, step #1278] loss: 0.7052271804765764\n",
      "[EPOCH #28, step #1280] loss: 0.7051252029097518\n",
      "[EPOCH #28, step #1282] loss: 0.7049948424100876\n",
      "[EPOCH #28, step #1284] loss: 0.7054537975486614\n",
      "[EPOCH #28, step #1286] loss: 0.7052452980244724\n",
      "[EPOCH #28, step #1288] loss: 0.7051808085318588\n",
      "[EPOCH #28, step #1290] loss: 0.7052611457826\n",
      "[EPOCH #28, step #1292] loss: 0.7056336415685247\n",
      "[EPOCH #28, step #1294] loss: 0.7056195035749421\n",
      "[EPOCH #28, step #1296] loss: 0.7053702854039399\n",
      "[EPOCH #28, step #1298] loss: 0.705511859362175\n",
      "[EPOCH #28, step #1300] loss: 0.7053840104819811\n",
      "[EPOCH #28, step #1302] loss: 0.705626253373149\n",
      "[EPOCH #28, step #1304] loss: 0.7059969758051109\n",
      "[EPOCH #28, step #1306] loss: 0.7055813833991352\n",
      "[EPOCH #28, step #1308] loss: 0.7059379472839095\n",
      "[EPOCH #28, step #1310] loss: 0.7060735913222296\n",
      "[EPOCH #28, step #1312] loss: 0.70641388307749\n",
      "[EPOCH #28, step #1314] loss: 0.7065310379964771\n",
      "[EPOCH #28, step #1316] loss: 0.7060820957138036\n",
      "[EPOCH #28, step #1318] loss: 0.705851340345852\n",
      "[EPOCH #28, step #1320] loss: 0.7057888000120637\n",
      "[EPOCH #28, step #1322] loss: 0.7057221803422777\n",
      "[EPOCH #28, step #1324] loss: 0.7056266539839079\n",
      "[EPOCH #28, step #1326] loss: 0.7055406749540464\n",
      "[EPOCH #28, step #1328] loss: 0.7056656407516105\n",
      "[EPOCH #28, step #1330] loss: 0.7055976895418139\n",
      "[EPOCH #28, step #1332] loss: 0.7057534760200969\n",
      "[EPOCH #28, step #1334] loss: 0.7056900840461924\n",
      "[EPOCH #28, step #1336] loss: 0.7054144955318903\n",
      "[EPOCH #28, step #1338] loss: 0.7052398197926008\n",
      "[EPOCH #28, step #1340] loss: 0.7055477954108355\n",
      "[EPOCH #28, step #1342] loss: 0.7054670014469284\n",
      "[EPOCH #28, step #1344] loss: 0.7055243221689778\n",
      "[EPOCH #28, step #1346] loss: 0.7054979216968384\n",
      "[EPOCH #28, step #1348] loss: 0.7054392997979058\n",
      "[EPOCH #28, step #1350] loss: 0.7059548351938507\n",
      "[EPOCH #28, step #1352] loss: 0.7061787495569926\n",
      "[EPOCH #28, step #1354] loss: 0.7064934615609391\n",
      "[EPOCH #28, step #1356] loss: 0.7063572859733352\n",
      "[EPOCH #28, step #1358] loss: 0.7064613145203867\n",
      "[EPOCH #28, step #1360] loss: 0.7067145333953152\n",
      "[EPOCH #28, step #1362] loss: 0.7064628420576661\n",
      "[EPOCH #28, step #1364] loss: 0.7066431115507643\n",
      "[EPOCH #28, step #1366] loss: 0.7067896842019089\n",
      "[EPOCH #28, step #1368] loss: 0.7070692707209626\n",
      "[EPOCH #28, step #1370] loss: 0.7068364294252633\n",
      "[EPOCH #28, step #1372] loss: 0.7073594937881066\n",
      "[EPOCH #28, step #1374] loss: 0.7073545244932175\n",
      "[EPOCH #28, step #1376] loss: 0.7073767016937357\n",
      "[EPOCH #28, step #1378] loss: 0.7073199159537994\n",
      "[EPOCH #28, step #1380] loss: 0.7070947636585145\n",
      "[EPOCH #28, step #1382] loss: 0.7069536260371612\n",
      "[EPOCH #28, step #1384] loss: 0.7071832188953131\n",
      "[EPOCH #28, step #1386] loss: 0.707341569303263\n",
      "[EPOCH #28, step #1388] loss: 0.7073841416273638\n",
      "[EPOCH #28, step #1390] loss: 0.7073092449384144\n",
      "[EPOCH #28, step #1392] loss: 0.7072586099599132\n",
      "[EPOCH #28, step #1394] loss: 0.7070638909882542\n",
      "[EPOCH #28, step #1396] loss: 0.7074142148666238\n",
      "[EPOCH #28, step #1398] loss: 0.707316834908285\n",
      "[EPOCH #28, step #1400] loss: 0.7072500743179301\n",
      "[EPOCH #28, step #1402] loss: 0.707557027212909\n",
      "[EPOCH #28, step #1404] loss: 0.7076651028997109\n",
      "[EPOCH #28, step #1406] loss: 0.707621381915285\n",
      "[EPOCH #28, step #1408] loss: 0.7077657422268957\n",
      "[EPOCH #28, step #1410] loss: 0.7077675105978799\n",
      "[EPOCH #28, step #1412] loss: 0.707564291522508\n",
      "[EPOCH #28, step #1414] loss: 0.7074493361972667\n",
      "[EPOCH #28, step #1416] loss: 0.7073786225151494\n",
      "[EPOCH #28, step #1418] loss: 0.7075488329290756\n",
      "[EPOCH #28, step #1420] loss: 0.7073977527003487\n",
      "[EPOCH #28, step #1422] loss: 0.7072311903776121\n",
      "[EPOCH #28, step #1424] loss: 0.7072508561088328\n",
      "[EPOCH #28, step #1426] loss: 0.7074470035601264\n",
      "[EPOCH #28, step #1428] loss: 0.7079589089223602\n",
      "[EPOCH #28, step #1430] loss: 0.7077195152983975\n",
      "[EPOCH #28, step #1432] loss: 0.7086237673254505\n",
      "[EPOCH #28, step #1434] loss: 0.7086701970171014\n",
      "[EPOCH #28, step #1436] loss: 0.7089158829273079\n",
      "[EPOCH #28, step #1438] loss: 0.709034194386693\n",
      "[EPOCH #28, step #1440] loss: 0.7093936123941442\n",
      "[EPOCH #28, step #1442] loss: 0.7095013512498541\n",
      "[EPOCH #28, step #1444] loss: 0.7097379312486385\n",
      "[EPOCH #28, step #1446] loss: 0.709819887134645\n",
      "[EPOCH #28, step #1448] loss: 0.7097257197705361\n",
      "[EPOCH #28, step #1450] loss: 0.7099041451695539\n",
      "[EPOCH #28, step #1452] loss: 0.7102405463037045\n",
      "[EPOCH #28, step #1454] loss: 0.7104947879654435\n",
      "[EPOCH #28, step #1456] loss: 0.710390151866348\n",
      "[EPOCH #28, step #1458] loss: 0.7104640465492741\n",
      "[EPOCH #28, step #1460] loss: 0.7109381003403484\n",
      "[EPOCH #28, step #1462] loss: 0.7109186761463169\n",
      "[EPOCH #28, step #1464] loss: 0.7105759262326634\n",
      "[EPOCH #28, step #1466] loss: 0.7105967046638371\n",
      "[EPOCH #28, step #1468] loss: 0.7105706345576507\n",
      "[EPOCH #28, step #1470] loss: 0.7105154163836622\n",
      "[EPOCH #28, step #1472] loss: 0.7104233861960931\n",
      "[EPOCH #28, step #1474] loss: 0.7101627930443166\n",
      "[EPOCH #28, step #1476] loss: 0.7100054662757898\n",
      "[EPOCH #28, step #1478] loss: 0.7097518239031779\n",
      "[EPOCH #28, step #1480] loss: 0.7096997888747459\n",
      "[EPOCH #28, step #1482] loss: 0.7095411793753977\n",
      "[EPOCH #28, step #1484] loss: 0.7094813586987229\n",
      "[EPOCH #28, step #1486] loss: 0.7094483866676358\n",
      "[EPOCH #28, step #1488] loss: 0.7096536880155151\n",
      "[EPOCH #28, step #1490] loss: 0.7093896615293345\n",
      "[EPOCH #28, step #1492] loss: 0.7095463059228775\n",
      "[EPOCH #28, step #1494] loss: 0.7095508509754735\n",
      "[EPOCH #28, step #1496] loss: 0.7097345415500298\n",
      "[EPOCH #28, step #1498] loss: 0.7096242723841123\n",
      "[EPOCH #28, step #1500] loss: 0.7096933679708555\n",
      "[EPOCH #28, step #1502] loss: 0.7095254817190602\n",
      "[EPOCH #28, step #1504] loss: 0.7092938430186522\n",
      "[EPOCH #28, step #1506] loss: 0.7091553312761545\n",
      "[EPOCH #28, step #1508] loss: 0.7091932191585688\n",
      "[EPOCH #28, step #1510] loss: 0.7095740893418074\n",
      "[EPOCH #28, step #1512] loss: 0.7095917393868914\n",
      "[EPOCH #28, step #1514] loss: 0.7096301615729977\n",
      "[EPOCH #28, step #1516] loss: 0.7096922026999938\n",
      "[EPOCH #28, step #1518] loss: 0.7096695916738222\n",
      "[EPOCH #28, step #1520] loss: 0.7096837072349708\n",
      "[EPOCH #28, step #1522] loss: 0.70997160480395\n",
      "[EPOCH #28, step #1524] loss: 0.7099540740446966\n",
      "[EPOCH #28, step #1526] loss: 0.7101301975065224\n",
      "[EPOCH #28, step #1528] loss: 0.7100913602300841\n",
      "[EPOCH #28, step #1530] loss: 0.7104011039905965\n",
      "[EPOCH #28, step #1532] loss: 0.7106821892487792\n",
      "[EPOCH #28, step #1534] loss: 0.7105960860023282\n",
      "[EPOCH #28, step #1536] loss: 0.7106716257938721\n",
      "[EPOCH #28, step #1538] loss: 0.7105016611066246\n",
      "[EPOCH #28, step #1540] loss: 0.7102947502283985\n",
      "[EPOCH #28, step #1542] loss: 0.7101305636564633\n",
      "[EPOCH #28, step #1544] loss: 0.7098825466382079\n",
      "[EPOCH #28, step #1546] loss: 0.7097546875996981\n",
      "[EPOCH #28, step #1548] loss: 0.7095530079960284\n",
      "[EPOCH #28, step #1550] loss: 0.7098267119039189\n",
      "[EPOCH #28, step #1552] loss: 0.7097828400399865\n",
      "[EPOCH #28, step #1554] loss: 0.7097362286312404\n",
      "[EPOCH #28, step #1556] loss: 0.7096854924830245\n",
      "[EPOCH #28, step #1558] loss: 0.709685636329452\n",
      "[EPOCH #28, step #1560] loss: 0.7096288434726775\n",
      "[EPOCH #28, step #1562] loss: 0.7096143479215282\n",
      "[EPOCH #28, step #1564] loss: 0.7094571046459789\n",
      "[EPOCH #28, step #1566] loss: 0.7096384922618993\n",
      "[EPOCH #28, step #1568] loss: 0.7096987964907142\n",
      "[EPOCH #28, step #1570] loss: 0.710002941274476\n",
      "[EPOCH #28, step #1572] loss: 0.7097841823226089\n",
      "[EPOCH #28, step #1574] loss: 0.7096185024484756\n",
      "[EPOCH #28, step #1576] loss: 0.7094264512263905\n",
      "[EPOCH #28, step #1578] loss: 0.7095238601410215\n",
      "[EPOCH #28, step #1580] loss: 0.7093148884386447\n",
      "[EPOCH #28, step #1582] loss: 0.7093148900128887\n",
      "[EPOCH #28, step #1584] loss: 0.7092081348132636\n",
      "[EPOCH #28, step #1586] loss: 0.7088432729751266\n",
      "[EPOCH #28, step #1588] loss: 0.7087227020288429\n",
      "[EPOCH #28, step #1590] loss: 0.7088018653997454\n",
      "[EPOCH #28, step #1592] loss: 0.7088067454975203\n",
      "[EPOCH #28, step #1594] loss: 0.7090420130745371\n",
      "[EPOCH #28, step #1596] loss: 0.7093787041114282\n",
      "[EPOCH #28, step #1598] loss: 0.7093052843293225\n",
      "[EPOCH #28, step #1600] loss: 0.7095603604174494\n",
      "[EPOCH #28, step #1602] loss: 0.7094708555334446\n",
      "[EPOCH #28, step #1604] loss: 0.7094887743764948\n",
      "[EPOCH #28, step #1606] loss: 0.7096554386129866\n",
      "[EPOCH #28, step #1608] loss: 0.7094808072592621\n",
      "[EPOCH #28, step #1610] loss: 0.7095705648799774\n",
      "[EPOCH #28, step #1612] loss: 0.7095887181981335\n",
      "[EPOCH #28, step #1614] loss: 0.7096336349521997\n",
      "[EPOCH #28, step #1616] loss: 0.7102274873611288\n",
      "[EPOCH #28, step #1618] loss: 0.7102100251172339\n",
      "[EPOCH #28, step #1620] loss: 0.710087733686816\n",
      "[EPOCH #28, step #1622] loss: 0.7104321311762211\n",
      "[EPOCH #28, step #1624] loss: 0.710318848985892\n",
      "[EPOCH #28, step #1626] loss: 0.7100842180853617\n",
      "[EPOCH #28, step #1628] loss: 0.7100120269955851\n",
      "[EPOCH #28, step #1630] loss: 0.710274686784484\n",
      "[EPOCH #28, step #1632] loss: 0.7103728696986786\n",
      "[EPOCH #28, step #1634] loss: 0.7102677379270577\n",
      "[EPOCH #28, step #1636] loss: 0.7105205306008449\n",
      "[EPOCH #28, step #1638] loss: 0.710330692850067\n",
      "[EPOCH #28, step #1640] loss: 0.710122326928112\n",
      "[EPOCH #28, step #1642] loss: 0.7102238285109826\n",
      "[EPOCH #28, step #1644] loss: 0.710232161741851\n",
      "[EPOCH #28, step #1646] loss: 0.7101198437634424\n",
      "[EPOCH #28, step #1648] loss: 0.710118827773196\n",
      "[EPOCH #28, step #1650] loss: 0.7102086682578854\n",
      "[EPOCH #28, step #1652] loss: 0.7101596337571262\n",
      "[EPOCH #28, step #1654] loss: 0.7102121236551204\n",
      "[EPOCH #28, step #1656] loss: 0.7100822764685446\n",
      "[EPOCH #28, step #1658] loss: 0.7098154196489856\n",
      "[EPOCH #28, step #1660] loss: 0.709713231227184\n",
      "[EPOCH #28, step #1662] loss: 0.7095863050408774\n",
      "[EPOCH #28, step #1664] loss: 0.7095977414209206\n",
      "[EPOCH #28, step #1666] loss: 0.7095351978716338\n",
      "[EPOCH #28, step #1668] loss: 0.7096678875766164\n",
      "[EPOCH #28, step #1670] loss: 0.7095235666513158\n",
      "[EPOCH #28, step #1672] loss: 0.7098242031712056\n",
      "[EPOCH #28, step #1674] loss: 0.7095960991862994\n",
      "[EPOCH #28, step #1676] loss: 0.7098131423008606\n",
      "[EPOCH #28, step #1678] loss: 0.7096433580684974\n",
      "[EPOCH #28, step #1680] loss: 0.7097859342296091\n",
      "[EPOCH #28, step #1682] loss: 0.7098090347351945\n",
      "[EPOCH #28, step #1684] loss: 0.7098694427519241\n",
      "[EPOCH #28, step #1686] loss: 0.7099297860439671\n",
      "[EPOCH #28, step #1688] loss: 0.7099880174975765\n",
      "[EPOCH #28, step #1690] loss: 0.7102424434784388\n",
      "[EPOCH #28, step #1692] loss: 0.7104511343105545\n",
      "[EPOCH #28, step #1694] loss: 0.7101987005950428\n",
      "[EPOCH #28, step #1696] loss: 0.7102061887225054\n",
      "[EPOCH #28, step #1698] loss: 0.7102328286916807\n",
      "[EPOCH #28, step #1700] loss: 0.7101046446402026\n",
      "[EPOCH #28, step #1702] loss: 0.7099516227167632\n",
      "[EPOCH #28, step #1704] loss: 0.7100480686796725\n",
      "[EPOCH #28, step #1706] loss: 0.7100386191039457\n",
      "[EPOCH #28, step #1708] loss: 0.710039814804436\n",
      "[EPOCH #28, step #1710] loss: 0.7101717809621246\n",
      "[EPOCH #28, step #1712] loss: 0.7103880807992247\n",
      "[EPOCH #28, step #1714] loss: 0.7106985590461392\n",
      "[EPOCH #28, step #1716] loss: 0.7107330665782086\n",
      "[EPOCH #28, step #1718] loss: 0.7107302280638091\n",
      "[EPOCH #28, step #1720] loss: 0.7105746697731866\n",
      "[EPOCH #28, step #1722] loss: 0.7110617583270552\n",
      "[EPOCH #28, step #1724] loss: 0.7107899915912878\n",
      "[EPOCH #28, step #1726] loss: 0.7110296957104207\n",
      "[EPOCH #28, step #1728] loss: 0.7108277241624525\n",
      "[EPOCH #28, step #1730] loss: 0.7109867838388368\n",
      "[EPOCH #28, step #1732] loss: 0.710991245547747\n",
      "[EPOCH #28, step #1734] loss: 0.7109564321958366\n",
      "[EPOCH #28, step #1736] loss: 0.7108704755978126\n",
      "[EPOCH #28, step #1738] loss: 0.7109887007754585\n",
      "[EPOCH #28, step #1740] loss: 0.710858221619996\n",
      "[EPOCH #28, step #1742] loss: 0.7109864301556359\n",
      "[EPOCH #28, step #1744] loss: 0.7111294504308427\n",
      "[EPOCH #28, step #1746] loss: 0.7113166870170822\n",
      "[EPOCH #28, step #1748] loss: 0.7116215961483153\n",
      "[EPOCH #28, step #1750] loss: 0.7116393716266535\n",
      "[EPOCH #28, step #1752] loss: 0.7117402094963001\n",
      "[EPOCH #28, step #1754] loss: 0.7115801221709646\n",
      "[EPOCH #28, step #1756] loss: 0.7114670354243225\n",
      "[EPOCH #28, step #1758] loss: 0.7115417140715498\n",
      "[EPOCH #28, step #1760] loss: 0.7114257099596633\n",
      "[EPOCH #28, step #1762] loss: 0.7114249850479094\n",
      "[EPOCH #28, step #1764] loss: 0.7114149608878846\n",
      "[EPOCH #28, step #1766] loss: 0.7115695583041132\n",
      "[EPOCH #28, step #1768] loss: 0.7115964829466854\n",
      "[EPOCH #28, step #1770] loss: 0.7116563440563987\n",
      "[EPOCH #28, step #1772] loss: 0.7115344944658484\n",
      "[EPOCH #28, step #1774] loss: 0.7115493037583123\n",
      "[EPOCH #28, step #1776] loss: 0.7114378480124353\n",
      "[EPOCH #28, step #1778] loss: 0.7111519970556803\n",
      "[EPOCH #28, step #1780] loss: 0.7110887694014116\n",
      "[EPOCH #28, step #1782] loss: 0.7110298929910478\n",
      "[EPOCH #28, step #1784] loss: 0.7110311479545107\n",
      "[EPOCH #28, step #1786] loss: 0.7109048676160573\n",
      "[EPOCH #28, step #1788] loss: 0.7108054601942914\n",
      "[EPOCH #28, step #1790] loss: 0.7106960093605658\n",
      "[EPOCH #28, step #1792] loss: 0.7106926252621881\n",
      "[EPOCH #28, step #1794] loss: 0.710680221108341\n",
      "[EPOCH #28, step #1796] loss: 0.7106075724778602\n",
      "[EPOCH #28, step #1798] loss: 0.7104815893815318\n",
      "[EPOCH #28, step #1800] loss: 0.7108687983576554\n",
      "[EPOCH #28, step #1802] loss: 0.7110279923882408\n",
      "[EPOCH #28, step #1804] loss: 0.7110901300679283\n",
      "[EPOCH #28, step #1806] loss: 0.7111032643846603\n",
      "[EPOCH #28, step #1808] loss: 0.7111480501045372\n",
      "[EPOCH #28, step #1810] loss: 0.711272251772196\n",
      "[EPOCH #28, step #1812] loss: 0.7112797057585892\n",
      "[EPOCH #28, step #1814] loss: 0.7112611066293454\n",
      "[EPOCH #28, step #1816] loss: 0.7112848111230985\n",
      "[EPOCH #28, step #1818] loss: 0.7113204995654585\n",
      "[EPOCH #28, step #1820] loss: 0.7114701321218644\n",
      "[EPOCH #28, step #1822] loss: 0.7112498027458991\n",
      "[EPOCH #28, step #1824] loss: 0.7113334538920285\n",
      "[EPOCH #28, step #1826] loss: 0.7113755096502492\n",
      "[EPOCH #28, step #1828] loss: 0.7115637855965822\n",
      "[EPOCH #28, step #1830] loss: 0.7115673828831401\n",
      "[EPOCH #28, step #1832] loss: 0.7116075727907738\n",
      "[EPOCH #28, step #1834] loss: 0.711637677459366\n",
      "[EPOCH #28, step #1836] loss: 0.7117464066152023\n",
      "[EPOCH #28, step #1838] loss: 0.7114924798603612\n",
      "[EPOCH #28, step #1840] loss: 0.7116563579250715\n",
      "[EPOCH #28, step #1842] loss: 0.7116575056825458\n",
      "[EPOCH #28, step #1844] loss: 0.7115839474650256\n",
      "[EPOCH #28, step #1846] loss: 0.7114672968451501\n",
      "[EPOCH #28, step #1848] loss: 0.7113092549189547\n",
      "[EPOCH #28, step #1850] loss: 0.7114315266821076\n",
      "[EPOCH #28, step #1852] loss: 0.7113414046591318\n",
      "[EPOCH #28, step #1854] loss: 0.7113509437867573\n",
      "[EPOCH #28, step #1856] loss: 0.7113907211447635\n",
      "[EPOCH #28, step #1858] loss: 0.7112609407813912\n",
      "[EPOCH #28, step #1860] loss: 0.7114209192997663\n",
      "[EPOCH #28, step #1862] loss: 0.7113161000092696\n",
      "[EPOCH #28, step #1864] loss: 0.711379881878321\n",
      "[EPOCH #28, step #1866] loss: 0.7115080572812392\n",
      "[EPOCH #28, step #1868] loss: 0.7117075201357157\n",
      "[EPOCH #28, step #1870] loss: 0.7116033285219104\n",
      "[EPOCH #28, step #1872] loss: 0.711775248732022\n",
      "[EPOCH #28, step #1874] loss: 0.7118187513113022\n",
      "[EPOCH #28, step #1876] loss: 0.7119028335898623\n",
      "[EPOCH #28, step #1878] loss: 0.7118893924658447\n",
      "[EPOCH #28, step #1880] loss: 0.7118065889799994\n",
      "[EPOCH #28, step #1882] loss: 0.7117966587832806\n",
      "[EPOCH #28, step #1884] loss: 0.7117211161542002\n",
      "[EPOCH #28, step #1886] loss: 0.7117432037720809\n",
      "[EPOCH #28, step #1888] loss: 0.711795871466982\n",
      "[EPOCH #28, step #1890] loss: 0.7119976327429998\n",
      "[EPOCH #28, step #1892] loss: 0.7118580593785091\n",
      "[EPOCH #28, step #1894] loss: 0.7115940110743203\n",
      "[EPOCH #28, step #1896] loss: 0.7112284791221353\n",
      "[EPOCH #28, step #1898] loss: 0.7112307063195503\n",
      "[EPOCH #28, step #1900] loss: 0.7112101587588884\n",
      "[EPOCH #28, step #1902] loss: 0.7110969796581013\n",
      "[EPOCH #28, step #1904] loss: 0.7112780616899801\n",
      "[EPOCH #28, step #1906] loss: 0.7113536083938942\n",
      "[EPOCH #28, step #1908] loss: 0.7113727691708716\n",
      "[EPOCH #28, step #1910] loss: 0.7113150779191016\n",
      "[EPOCH #28, step #1912] loss: 0.7112852830305438\n",
      "[EPOCH #28, step #1914] loss: 0.7113644248745149\n",
      "[EPOCH #28, step #1916] loss: 0.7112984306173643\n",
      "[EPOCH #28, step #1918] loss: 0.7113205511520901\n",
      "[EPOCH #28, step #1920] loss: 0.7113244885007644\n",
      "[EPOCH #28, step #1922] loss: 0.7113691150475714\n",
      "[EPOCH #28, step #1924] loss: 0.7110968908164408\n",
      "[EPOCH #28, step #1926] loss: 0.7110597825090564\n",
      "[EPOCH #28, step #1928] loss: 0.7109178614205434\n",
      "[EPOCH #28, step #1930] loss: 0.7108937648140908\n",
      "[EPOCH #28, step #1932] loss: 0.7112734768514614\n",
      "[EPOCH #28, step #1934] loss: 0.71124108474538\n",
      "[EPOCH #28, step #1936] loss: 0.7110898508183047\n",
      "[EPOCH #28, step #1938] loss: 0.7109826479593216\n",
      "[EPOCH #28, step #1940] loss: 0.7108182579063989\n",
      "[EPOCH #28, step #1942] loss: 0.7107334790451283\n",
      "[EPOCH #28, step #1944] loss: 0.7109867593086777\n",
      "[EPOCH #28, step #1946] loss: 0.7109674535917513\n",
      "[EPOCH #28, step #1948] loss: 0.7110099304465528\n",
      "[EPOCH #28, step #1950] loss: 0.7108912222709857\n",
      "[EPOCH #28, step #1952] loss: 0.7111131843166112\n",
      "[EPOCH #28, step #1954] loss: 0.7112955027910145\n",
      "[EPOCH #28, step #1956] loss: 0.7114081798263149\n",
      "[EPOCH #28, step #1958] loss: 0.711419382262376\n",
      "[EPOCH #28, step #1960] loss: 0.7114753267903039\n",
      "[EPOCH #28, step #1962] loss: 0.7116375625725614\n",
      "[EPOCH #28, step #1964] loss: 0.7118990664946214\n",
      "[EPOCH #28, step #1966] loss: 0.7118737731009616\n",
      "[EPOCH #28, step #1968] loss: 0.7118551444816613\n",
      "[EPOCH #28, step #1970] loss: 0.7117946924276004\n",
      "[EPOCH #28, step #1972] loss: 0.7117238753242536\n",
      "[EPOCH #28, step #1974] loss: 0.7115854951173445\n",
      "[EPOCH #28, step #1976] loss: 0.7115140546812333\n",
      "[EPOCH #28, step #1978] loss: 0.7117515683791564\n",
      "[EPOCH #28, step #1980] loss: 0.7114980203719647\n",
      "[EPOCH #28, step #1982] loss: 0.71156883069168\n",
      "[EPOCH #28, step #1984] loss: 0.7116328751785629\n",
      "[EPOCH #28, step #1986] loss: 0.7114818876465782\n",
      "[EPOCH #28, step #1988] loss: 0.7117142927607679\n",
      "[EPOCH #28, step #1990] loss: 0.7115450113532772\n",
      "[EPOCH #28, step #1992] loss: 0.7114602337889018\n",
      "[EPOCH #28, step #1994] loss: 0.7111282609832615\n",
      "[EPOCH #28, step #1996] loss: 0.7110831477027806\n",
      "[EPOCH #28, step #1998] loss: 0.7112083320336797\n",
      "[EPOCH #28, step #2000] loss: 0.7110758474518334\n",
      "[EPOCH #28, step #2002] loss: 0.711046197067126\n",
      "[EPOCH #28, step #2004] loss: 0.7112093306018824\n",
      "[EPOCH #28, step #2006] loss: 0.7110693834064965\n",
      "[EPOCH #28, step #2008] loss: 0.7111182865320954\n",
      "[EPOCH #28, step #2010] loss: 0.711179420826211\n",
      "[EPOCH #28, step #2012] loss: 0.7111148738366599\n",
      "[EPOCH #28, step #2014] loss: 0.7111291545274536\n",
      "[EPOCH #28, step #2016] loss: 0.7111035147233948\n",
      "[EPOCH #28, step #2018] loss: 0.7109184989824692\n",
      "[EPOCH #28, step #2020] loss: 0.7109590672004464\n",
      "[EPOCH #28, step #2022] loss: 0.7109996086806869\n",
      "[EPOCH #28, step #2024] loss: 0.7109663146439894\n",
      "[EPOCH #28, step #2026] loss: 0.7107076341507761\n",
      "[EPOCH #28, step #2028] loss: 0.710837022527619\n",
      "[EPOCH #28, step #2030] loss: 0.7109026478714452\n",
      "[EPOCH #28, step #2032] loss: 0.7109572915053403\n",
      "[EPOCH #28, step #2034] loss: 0.7109099995958131\n",
      "[EPOCH #28, step #2036] loss: 0.710915794553099\n",
      "[EPOCH #28, step #2038] loss: 0.7108407350089867\n",
      "[EPOCH #28, step #2040] loss: 0.7108241707845858\n",
      "[EPOCH #28, step #2042] loss: 0.7110756598978257\n",
      "[EPOCH #28, step #2044] loss: 0.7111019602396086\n",
      "[EPOCH #28, step #2046] loss: 0.7111206193071025\n",
      "[EPOCH #28, step #2048] loss: 0.7111485200852752\n",
      "[EPOCH #28, step #2050] loss: 0.7110249754613577\n",
      "[EPOCH #28, step #2052] loss: 0.7110711226028404\n",
      "[EPOCH #28, step #2054] loss: 0.7109665506440067\n",
      "[EPOCH #28, step #2056] loss: 0.7111810811541297\n",
      "[EPOCH #28, step #2058] loss: 0.7109835691579978\n",
      "[EPOCH #28, step #2060] loss: 0.7109141670012\n",
      "[EPOCH #28, step #2062] loss: 0.7108176378113404\n",
      "[EPOCH #28, step #2064] loss: 0.7108175542755797\n",
      "[EPOCH #28, step #2066] loss: 0.7107867961943178\n",
      "[EPOCH #28, step #2068] loss: 0.7107246686160248\n",
      "[EPOCH #28, step #2070] loss: 0.7108533571288529\n",
      "[EPOCH #28, step #2072] loss: 0.7107839181882658\n",
      "[EPOCH #28, step #2074] loss: 0.7108645741408129\n",
      "[EPOCH #28, step #2076] loss: 0.7109769139157274\n",
      "[EPOCH #28, step #2078] loss: 0.7109069961475718\n",
      "[EPOCH #28, step #2080] loss: 0.7108868766022897\n",
      "[EPOCH #28, step #2082] loss: 0.7107881258742145\n",
      "[EPOCH #28, step #2084] loss: 0.7110271529113646\n",
      "[EPOCH #28, step #2086] loss: 0.7111300943811144\n",
      "[EPOCH #28, step #2088] loss: 0.7110092035102867\n",
      "[EPOCH #28, step #2090] loss: 0.7109923214005375\n",
      "[EPOCH #28, step #2092] loss: 0.7107927468380629\n",
      "[EPOCH #28, step #2094] loss: 0.7107426344708213\n",
      "[EPOCH #28, step #2096] loss: 0.7105356105592174\n",
      "[EPOCH #28, step #2098] loss: 0.7106813775706484\n",
      "[EPOCH #28, step #2100] loss: 0.7107140831028718\n",
      "[EPOCH #28, step #2102] loss: 0.710390900402085\n",
      "[EPOCH #28, step #2104] loss: 0.7105493708276975\n",
      "[EPOCH #28, step #2106] loss: 0.7103715296755145\n",
      "[EPOCH #28, step #2108] loss: 0.7104698339801312\n",
      "[EPOCH #28, step #2110] loss: 0.7104544964504717\n",
      "[EPOCH #28, step #2112] loss: 0.7104839606345461\n",
      "[EPOCH #28, step #2114] loss: 0.7104782093994443\n",
      "[EPOCH #28, step #2116] loss: 0.7106322887079526\n",
      "[EPOCH #28, step #2118] loss: 0.7106176083340516\n",
      "[EPOCH #28, step #2120] loss: 0.7107515905205228\n",
      "[EPOCH #28, step #2122] loss: 0.7107791954750617\n",
      "[EPOCH #28, step #2124] loss: 0.710824429897701\n",
      "[EPOCH #28, step #2126] loss: 0.710889545912523\n",
      "[EPOCH #28, step #2128] loss: 0.7109989883853215\n",
      "[EPOCH #28, step #2130] loss: 0.7110263305208818\n",
      "[EPOCH #28, step #2132] loss: 0.7109641369538747\n",
      "[EPOCH #28, step #2134] loss: 0.7110325769950969\n",
      "[EPOCH #28, step #2136] loss: 0.7109875662211341\n",
      "[EPOCH #28, step #2138] loss: 0.7110958966196225\n",
      "[EPOCH #28, step #2140] loss: 0.7110279812914698\n",
      "[EPOCH #28, step #2142] loss: 0.7111778924232101\n",
      "[EPOCH #28, step #2144] loss: 0.7111928709111848\n",
      "[EPOCH #28, step #2146] loss: 0.7111331976440045\n",
      "[EPOCH #28, step #2148] loss: 0.7111914389948337\n",
      "[EPOCH #28, step #2150] loss: 0.7113655046536057\n",
      "[EPOCH #28, step #2152] loss: 0.7113734628716237\n",
      "[EPOCH #28, step #2154] loss: 0.7112430155622986\n",
      "[EPOCH #28, step #2156] loss: 0.7112528209712254\n",
      "[EPOCH #28, step #2158] loss: 0.7112628299572116\n",
      "[EPOCH #28, step #2160] loss: 0.7113117521240004\n",
      "[EPOCH #28, step #2162] loss: 0.7113154300084227\n",
      "[EPOCH #28, step #2164] loss: 0.7113923073021424\n",
      "[EPOCH #28, step #2166] loss: 0.7112566987228768\n",
      "[EPOCH #28, step #2168] loss: 0.7112470034041015\n",
      "[EPOCH #28, step #2170] loss: 0.7111085935335784\n",
      "[EPOCH #28, step #2172] loss: 0.7111209681231033\n",
      "[EPOCH #28, step #2174] loss: 0.7111511057615281\n",
      "[EPOCH #28, step #2176] loss: 0.7110613140769108\n",
      "[EPOCH #28, step #2178] loss: 0.7110958311017799\n",
      "[EPOCH #28, step #2180] loss: 0.7114493562329641\n",
      "[EPOCH #28, step #2182] loss: 0.7113716058497903\n",
      "[EPOCH #28, step #2184] loss: 0.7113884702495361\n",
      "[EPOCH #28, step #2186] loss: 0.7113059552894861\n",
      "[EPOCH #28, step #2188] loss: 0.7113386925536239\n",
      "[EPOCH #28, step #2190] loss: 0.7111851723770309\n",
      "[EPOCH #28, step #2192] loss: 0.7110662099315432\n",
      "[EPOCH #28, step #2194] loss: 0.7110211515141511\n",
      "[EPOCH #28, step #2196] loss: 0.7115063907058878\n",
      "[EPOCH #28, step #2198] loss: 0.7114193497963416\n",
      "[EPOCH #28, step #2200] loss: 0.7116526223580332\n",
      "[EPOCH #28, step #2202] loss: 0.7117423002239903\n",
      "[EPOCH #28, step #2204] loss: 0.7115753240798877\n",
      "[EPOCH #28, step #2206] loss: 0.7114036281115877\n",
      "[EPOCH #28, step #2208] loss: 0.7111952795991535\n",
      "[EPOCH #28, step #2210] loss: 0.7113186045571293\n",
      "[EPOCH #28, step #2212] loss: 0.7113152359453628\n",
      "[EPOCH #28, step #2214] loss: 0.7112546414675077\n",
      "[EPOCH #28, step #2216] loss: 0.7113253345522302\n",
      "[EPOCH #28, step #2218] loss: 0.7112771149434287\n",
      "[EPOCH #28, step #2220] loss: 0.711401155387051\n",
      "[EPOCH #28, step #2222] loss: 0.711601973337415\n",
      "[EPOCH #28, step #2224] loss: 0.7117606167645937\n",
      "[EPOCH #28, step #2226] loss: 0.7116655899595669\n",
      "[EPOCH #28, step #2228] loss: 0.7120798814786075\n",
      "[EPOCH #28, step #2230] loss: 0.7121316511459491\n",
      "[EPOCH #28, step #2232] loss: 0.7122346684970612\n",
      "[EPOCH #28, step #2234] loss: 0.7122663760145238\n",
      "[EPOCH #28, step #2236] loss: 0.7121098646839975\n",
      "[EPOCH #28, step #2238] loss: 0.7119414102836824\n",
      "[EPOCH #28, step #2240] loss: 0.7118891273383741\n",
      "[EPOCH #28, step #2242] loss: 0.7119811885773046\n",
      "[EPOCH #28, step #2244] loss: 0.712019559860495\n",
      "[EPOCH #28, step #2246] loss: 0.7120294289544895\n",
      "[EPOCH #28, step #2248] loss: 0.7120408226101067\n",
      "[EPOCH #28, step #2250] loss: 0.7121578036401601\n",
      "[EPOCH #28, step #2252] loss: 0.712122718632036\n",
      "[EPOCH #28, step #2254] loss: 0.7122256606817245\n",
      "[EPOCH #28, step #2256] loss: 0.7122333171320637\n",
      "[EPOCH #28, step #2258] loss: 0.7122617005945677\n",
      "[EPOCH #28, step #2260] loss: 0.7122325660024054\n",
      "[EPOCH #28, step #2262] loss: 0.7122086408032393\n",
      "[EPOCH #28, step #2264] loss: 0.7121913869452002\n",
      "[EPOCH #28, step #2266] loss: 0.7120260138460651\n",
      "[EPOCH #28, step #2268] loss: 0.7119708320166162\n",
      "[EPOCH #28, step #2270] loss: 0.7117955898501074\n",
      "[EPOCH #28, step #2272] loss: 0.7118263019833122\n",
      "[EPOCH #28, step #2274] loss: 0.711711384680245\n",
      "[EPOCH #28, step #2276] loss: 0.7116271133126006\n",
      "[EPOCH #28, step #2278] loss: 0.711665931247263\n",
      "[EPOCH #28, step #2280] loss: 0.7115740771162463\n",
      "[EPOCH #28, step #2282] loss: 0.7116329289362506\n",
      "[EPOCH #28, step #2284] loss: 0.711582930011092\n",
      "[EPOCH #28, step #2286] loss: 0.7113869692503129\n",
      "[EPOCH #28, step #2288] loss: 0.7115148269242207\n",
      "[EPOCH #28, step #2290] loss: 0.7114831008137391\n",
      "[EPOCH #28, step #2292] loss: 0.7113273686526698\n",
      "[EPOCH #28, step #2294] loss: 0.7113830251111963\n",
      "[EPOCH #28, step #2296] loss: 0.7113278207697971\n",
      "[EPOCH #28, step #2298] loss: 0.7115220346104429\n",
      "[EPOCH #28, step #2300] loss: 0.7115465408301985\n",
      "[EPOCH #28, step #2302] loss: 0.7116209014674347\n",
      "[EPOCH #28, step #2304] loss: 0.71157656802014\n",
      "[EPOCH #28, step #2306] loss: 0.7115736242543581\n",
      "[EPOCH #28, step #2308] loss: 0.7116846508306567\n",
      "[EPOCH #28, step #2310] loss: 0.711782909068954\n",
      "[EPOCH #28, step #2312] loss: 0.711774769408642\n",
      "[EPOCH #28, step #2314] loss: 0.7116923131386611\n",
      "[EPOCH #28, step #2316] loss: 0.7115826504622547\n",
      "[EPOCH #28, step #2318] loss: 0.7116373920553766\n",
      "[EPOCH #28, step #2320] loss: 0.7115465593153113\n",
      "[EPOCH #28, step #2322] loss: 0.71132683674426\n",
      "[EPOCH #28, step #2324] loss: 0.7114310139225375\n",
      "[EPOCH #28, step #2326] loss: 0.7111462725300004\n",
      "[EPOCH #28, step #2328] loss: 0.7112755987868384\n",
      "[EPOCH #28, step #2330] loss: 0.7112284201452631\n",
      "[EPOCH #28, step #2332] loss: 0.7112498951734926\n",
      "[EPOCH #28, step #2334] loss: 0.7113807863035345\n",
      "[EPOCH #28, step #2336] loss: 0.7113366223167139\n",
      "[EPOCH #28, step #2338] loss: 0.7112880887869028\n",
      "[EPOCH #28, step #2340] loss: 0.7109913103145598\n",
      "[EPOCH #28, step #2342] loss: 0.7108938865970965\n",
      "[EPOCH #28, step #2344] loss: 0.711210832972008\n",
      "[EPOCH #28, step #2346] loss: 0.7111657879227621\n",
      "[EPOCH #28, step #2348] loss: 0.7111884227657683\n",
      "[EPOCH #28, step #2350] loss: 0.7111745009215422\n",
      "[EPOCH #28, step #2352] loss: 0.7110464117575644\n",
      "[EPOCH #28, step #2354] loss: 0.7110058567959285\n",
      "[EPOCH #28, step #2356] loss: 0.7109809641899777\n",
      "[EPOCH #28, step #2358] loss: 0.710961816913751\n",
      "[EPOCH #28, step #2360] loss: 0.7108142822917767\n",
      "[EPOCH #28, step #2362] loss: 0.7108474504856855\n",
      "[EPOCH #28, step #2364] loss: 0.7110355872558489\n",
      "[EPOCH #28, step #2366] loss: 0.7110873768613668\n",
      "[EPOCH #28, step #2368] loss: 0.7109845338390064\n",
      "[EPOCH #28, step #2370] loss: 0.7107835854346719\n",
      "[EPOCH #28, step #2372] loss: 0.7109736180159797\n",
      "[EPOCH #28, step #2374] loss: 0.7109238763859398\n",
      "[EPOCH #28, step #2376] loss: 0.7107729635345971\n",
      "[EPOCH #28, step #2378] loss: 0.7106508144990593\n",
      "[EPOCH #28, step #2380] loss: 0.7107320777236389\n",
      "[EPOCH #28, step #2382] loss: 0.7105863474894111\n",
      "[EPOCH #28, step #2384] loss: 0.7104234564479293\n",
      "[EPOCH #28, step #2386] loss: 0.7105014630326877\n",
      "[EPOCH #28, step #2388] loss: 0.7104306199302131\n",
      "[EPOCH #28, step #2390] loss: 0.7106388170865727\n",
      "[EPOCH #28, step #2392] loss: 0.7106936836013523\n",
      "[EPOCH #28, step #2394] loss: 0.7107463475060114\n",
      "[EPOCH #28, step #2396] loss: 0.7106683021741556\n",
      "[EPOCH #28, step #2398] loss: 0.7105677499652853\n",
      "[EPOCH #28, step #2400] loss: 0.7108007964989584\n",
      "[EPOCH #28, step #2402] loss: 0.7107127420340683\n",
      "[EPOCH #28, step #2404] loss: 0.7107923964328925\n",
      "[EPOCH #28, step #2406] loss: 0.710794763231753\n",
      "[EPOCH #28, step #2408] loss: 0.7109505190622663\n",
      "[EPOCH #28, step #2410] loss: 0.7111296630632526\n",
      "[EPOCH #28, step #2412] loss: 0.7111172444016124\n",
      "[EPOCH #28, step #2414] loss: 0.7111855619812604\n",
      "[EPOCH #28, step #2416] loss: 0.7111669703485751\n",
      "[EPOCH #28, step #2418] loss: 0.711357239444377\n",
      "[EPOCH #28, step #2420] loss: 0.7112347849485846\n",
      "[EPOCH #28, step #2422] loss: 0.7112386807940787\n",
      "[EPOCH #28, step #2424] loss: 0.7111240486754584\n",
      "[EPOCH #28, step #2426] loss: 0.7112651012245401\n",
      "[EPOCH #28, step #2428] loss: 0.7113323938507953\n",
      "[EPOCH #28, step #2430] loss: 0.7115691052155944\n",
      "[EPOCH #28, step #2432] loss: 0.7116582962254463\n",
      "[EPOCH #28, step #2434] loss: 0.7115953708698617\n",
      "[EPOCH #28, step #2436] loss: 0.7116388378937714\n",
      "[EPOCH #28, step #2438] loss: 0.7115686174272855\n",
      "[EPOCH #28, step #2440] loss: 0.7118717934913393\n",
      "[EPOCH #28, step #2442] loss: 0.7117543306279466\n",
      "[EPOCH #28, step #2444] loss: 0.7116280229179406\n",
      "[EPOCH #28, step #2446] loss: 0.7117319131292126\n",
      "[EPOCH #28, step #2448] loss: 0.7118990787465799\n",
      "[EPOCH #28, step #2450] loss: 0.7118052406755577\n",
      "[EPOCH #28, step #2452] loss: 0.7118647246398685\n",
      "[EPOCH #28, step #2454] loss: 0.711708473115249\n",
      "[EPOCH #28, step #2456] loss: 0.711638212082684\n",
      "[EPOCH #28, step #2458] loss: 0.7118167395803103\n",
      "[EPOCH #28, step #2460] loss: 0.7118455122661319\n",
      "[EPOCH #28, step #2462] loss: 0.7116908342481095\n",
      "[EPOCH #28, step #2464] loss: 0.7118494295445223\n",
      "[EPOCH #28, step #2466] loss: 0.7118956381413537\n",
      "[EPOCH #28, step #2468] loss: 0.7119310496064901\n",
      "[EPOCH #28, step #2470] loss: 0.7117677723792148\n",
      "[EPOCH #28, step #2472] loss: 0.7116774081870509\n",
      "[EPOCH #28, step #2474] loss: 0.711698102746347\n",
      "[EPOCH #28, step #2476] loss: 0.7116556304402056\n",
      "[EPOCH #28, step #2478] loss: 0.7115261325820793\n",
      "[EPOCH #28, step #2480] loss: 0.711486311148175\n",
      "[EPOCH #28, step #2482] loss: 0.7114057038226916\n",
      "[EPOCH #28, step #2484] loss: 0.7113519012328364\n",
      "[EPOCH #28, step #2486] loss: 0.7113366729531558\n",
      "[EPOCH #28, step #2488] loss: 0.7112680332111805\n",
      "[EPOCH #28, step #2490] loss: 0.7111307684076402\n",
      "[EPOCH #28, step #2492] loss: 0.7111181120675489\n",
      "[EPOCH #28, step #2494] loss: 0.7109909540904548\n",
      "[EPOCH #28, step #2496] loss: 0.710855499775256\n",
      "[EPOCH #28, step #2498] loss: 0.7108143364467254\n",
      "[EPOCH #28, elapsed time: 14117.738[sec]] loss: 0.7108576246619225\n",
      "[EPOCH #29, step #0] loss: 0.3153686225414276\n",
      "[EPOCH #29, step #2] loss: 0.5779471298058828\n",
      "[EPOCH #29, step #4] loss: 0.6139363944530487\n",
      "[EPOCH #29, step #6] loss: 0.6670394667557308\n",
      "[EPOCH #29, step #8] loss: 0.635568317439821\n",
      "[EPOCH #29, step #10] loss: 0.6980274996974252\n",
      "[EPOCH #29, step #12] loss: 0.6584767298056529\n",
      "[EPOCH #29, step #14] loss: 0.6267035295565923\n",
      "[EPOCH #29, step #16] loss: 0.6322770127478767\n",
      "[EPOCH #29, step #18] loss: 0.6297687739133835\n",
      "[EPOCH #29, step #20] loss: 0.6310992347342628\n",
      "[EPOCH #29, step #22] loss: 0.627389603982801\n",
      "[EPOCH #29, step #24] loss: 0.6236113709211349\n",
      "[EPOCH #29, step #26] loss: 0.6150164576592269\n",
      "[EPOCH #29, step #28] loss: 0.6196857356819613\n",
      "[EPOCH #29, step #30] loss: 0.6175052345760407\n",
      "[EPOCH #29, step #32] loss: 0.6122422493768461\n",
      "[EPOCH #29, step #34] loss: 0.6104921898671559\n",
      "[EPOCH #29, step #36] loss: 0.6155590153223759\n",
      "[EPOCH #29, step #38] loss: 0.6075745687270776\n",
      "[EPOCH #29, step #40] loss: 0.6028546360207767\n",
      "[EPOCH #29, step #42] loss: 0.5987919302180756\n",
      "[EPOCH #29, step #44] loss: 0.6148850914504793\n",
      "[EPOCH #29, step #46] loss: 0.6162222088017362\n",
      "[EPOCH #29, step #48] loss: 0.626846584434412\n",
      "[EPOCH #29, step #50] loss: 0.6334879138306075\n",
      "[EPOCH #29, step #52] loss: 0.6387772231169466\n",
      "[EPOCH #29, step #54] loss: 0.6384893783114173\n",
      "[EPOCH #29, step #56] loss: 0.6404449644318798\n",
      "[EPOCH #29, step #58] loss: 0.6370518649533644\n",
      "[EPOCH #29, step #60] loss: 0.62814255351903\n",
      "[EPOCH #29, step #62] loss: 0.632540185536657\n",
      "[EPOCH #29, step #64] loss: 0.6249867514922068\n",
      "[EPOCH #29, step #66] loss: 0.6188732690330762\n",
      "[EPOCH #29, step #68] loss: 0.6178752194712127\n",
      "[EPOCH #29, step #70] loss: 0.6196819050631053\n",
      "[EPOCH #29, step #72] loss: 0.6238771140167158\n",
      "[EPOCH #29, step #74] loss: 0.6204774628082911\n",
      "[EPOCH #29, step #76] loss: 0.6184547185510784\n",
      "[EPOCH #29, step #78] loss: 0.6217367654737038\n",
      "[EPOCH #29, step #80] loss: 0.6199607067270043\n",
      "[EPOCH #29, step #82] loss: 0.6202125626515194\n",
      "[EPOCH #29, step #84] loss: 0.6188968018573873\n",
      "[EPOCH #29, step #86] loss: 0.6199255755235409\n",
      "[EPOCH #29, step #88] loss: 0.6254837933216202\n",
      "[EPOCH #29, step #90] loss: 0.6243084097629065\n",
      "[EPOCH #29, step #92] loss: 0.6264664163833024\n",
      "[EPOCH #29, step #94] loss: 0.6258960910533604\n",
      "[EPOCH #29, step #96] loss: 0.625154437017195\n",
      "[EPOCH #29, step #98] loss: 0.6246804903552989\n",
      "[EPOCH #29, step #100] loss: 0.6245751453213172\n",
      "[EPOCH #29, step #102] loss: 0.6228168142362706\n",
      "[EPOCH #29, step #104] loss: 0.6228673354500815\n",
      "[EPOCH #29, step #106] loss: 0.6238500285092915\n",
      "[EPOCH #29, step #108] loss: 0.6294481878707169\n",
      "[EPOCH #29, step #110] loss: 0.6324504102404053\n",
      "[EPOCH #29, step #112] loss: 0.632734253211359\n",
      "[EPOCH #29, step #114] loss: 0.628763819647872\n",
      "[EPOCH #29, step #116] loss: 0.6272460852678006\n",
      "[EPOCH #29, step #118] loss: 0.6323126533201763\n",
      "[EPOCH #29, step #120] loss: 0.6356639378080683\n",
      "[EPOCH #29, step #122] loss: 0.6371319811276304\n",
      "[EPOCH #29, step #124] loss: 0.6389692372083664\n",
      "[EPOCH #29, step #126] loss: 0.6410612444004674\n",
      "[EPOCH #29, step #128] loss: 0.6393835113723149\n",
      "[EPOCH #29, step #130] loss: 0.638519290635604\n",
      "[EPOCH #29, step #132] loss: 0.6404581640223811\n",
      "[EPOCH #29, step #134] loss: 0.6397688593025561\n",
      "[EPOCH #29, step #136] loss: 0.6393726503979551\n",
      "[EPOCH #29, step #138] loss: 0.6407813143601521\n",
      "[EPOCH #29, step #140] loss: 0.6413245278258696\n",
      "[EPOCH #29, step #142] loss: 0.6425257705516748\n",
      "[EPOCH #29, step #144] loss: 0.6421017557382583\n",
      "[EPOCH #29, step #146] loss: 0.6416353036959966\n",
      "[EPOCH #29, step #148] loss: 0.6415506624335411\n",
      "[EPOCH #29, step #150] loss: 0.6392818398230913\n",
      "[EPOCH #29, step #152] loss: 0.6373639288875792\n",
      "[EPOCH #29, step #154] loss: 0.6374333899828696\n",
      "[EPOCH #29, step #156] loss: 0.6370238634241614\n",
      "[EPOCH #29, step #158] loss: 0.6372887933591627\n",
      "[EPOCH #29, step #160] loss: 0.6378622379917536\n",
      "[EPOCH #29, step #162] loss: 0.639742452217026\n",
      "[EPOCH #29, step #164] loss: 0.6388086198857337\n",
      "[EPOCH #29, step #166] loss: 0.6383382734245883\n",
      "[EPOCH #29, step #168] loss: 0.6377645141097921\n",
      "[EPOCH #29, step #170] loss: 0.6404626274492309\n",
      "[EPOCH #29, step #172] loss: 0.6411927534493408\n",
      "[EPOCH #29, step #174] loss: 0.6382887551614217\n",
      "[EPOCH #29, step #176] loss: 0.6394875720564255\n",
      "[EPOCH #29, step #178] loss: 0.6402866934431332\n",
      "[EPOCH #29, step #180] loss: 0.6394832457791376\n",
      "[EPOCH #29, step #182] loss: 0.6382773990025286\n",
      "[EPOCH #29, step #184] loss: 0.6374884514389811\n",
      "[EPOCH #29, step #186] loss: 0.637420016096875\n",
      "[EPOCH #29, step #188] loss: 0.6375376899879446\n",
      "[EPOCH #29, step #190] loss: 0.6376866984585817\n",
      "[EPOCH #29, step #192] loss: 0.637777678629895\n",
      "[EPOCH #29, step #194] loss: 0.6361457308897606\n",
      "[EPOCH #29, step #196] loss: 0.6361012740940006\n",
      "[EPOCH #29, step #198] loss: 0.6379086058493235\n",
      "[EPOCH #29, step #200] loss: 0.6395722367425463\n",
      "[EPOCH #29, step #202] loss: 0.6395891256667123\n",
      "[EPOCH #29, step #204] loss: 0.6388515234720417\n",
      "[EPOCH #29, step #206] loss: 0.637132733412411\n",
      "[EPOCH #29, step #208] loss: 0.6381028834284778\n",
      "[EPOCH #29, step #210] loss: 0.638850552705227\n",
      "[EPOCH #29, step #212] loss: 0.6387521993246437\n",
      "[EPOCH #29, step #214] loss: 0.6393637847761775\n",
      "[EPOCH #29, step #216] loss: 0.6413502601846572\n",
      "[EPOCH #29, step #218] loss: 0.6411455463464946\n",
      "[EPOCH #29, step #220] loss: 0.6423440415799887\n",
      "[EPOCH #29, step #222] loss: 0.642173278158021\n",
      "[EPOCH #29, step #224] loss: 0.6434341965119044\n",
      "[EPOCH #29, step #226] loss: 0.6426376619659332\n",
      "[EPOCH #29, step #228] loss: 0.6422229813306092\n",
      "[EPOCH #29, step #230] loss: 0.6416547933827231\n",
      "[EPOCH #29, step #232] loss: 0.641138111508967\n",
      "[EPOCH #29, step #234] loss: 0.6410237499374024\n",
      "[EPOCH #29, step #236] loss: 0.6434809864196094\n",
      "[EPOCH #29, step #238] loss: 0.6424307199078125\n",
      "[EPOCH #29, step #240] loss: 0.6421141589207273\n",
      "[EPOCH #29, step #242] loss: 0.6425862537367354\n",
      "[EPOCH #29, step #244] loss: 0.642333246433005\n",
      "[EPOCH #29, step #246] loss: 0.6430935567086525\n",
      "[EPOCH #29, step #248] loss: 0.6445803107865843\n",
      "[EPOCH #29, step #250] loss: 0.6442169919313188\n",
      "[EPOCH #29, step #252] loss: 0.6447486247823172\n",
      "[EPOCH #29, step #254] loss: 0.6429783639370227\n",
      "[EPOCH #29, step #256] loss: 0.6434982702541908\n",
      "[EPOCH #29, step #258] loss: 0.642443627866999\n",
      "[EPOCH #29, step #260] loss: 0.6440034439623128\n",
      "[EPOCH #29, step #262] loss: 0.6451015995369211\n",
      "[EPOCH #29, step #264] loss: 0.6453881440859921\n",
      "[EPOCH #29, step #266] loss: 0.6455777677592267\n",
      "[EPOCH #29, step #268] loss: 0.6439111951226195\n",
      "[EPOCH #29, step #270] loss: 0.6459998988247445\n",
      "[EPOCH #29, step #272] loss: 0.6456258724351506\n",
      "[EPOCH #29, step #274] loss: 0.6443617538430474\n",
      "[EPOCH #29, step #276] loss: 0.6436425804123551\n",
      "[EPOCH #29, step #278] loss: 0.6435641842396883\n",
      "[EPOCH #29, step #280] loss: 0.643361379402388\n",
      "[EPOCH #29, step #282] loss: 0.643123802942859\n",
      "[EPOCH #29, step #284] loss: 0.6429120640482819\n",
      "[EPOCH #29, step #286] loss: 0.6419542197670255\n",
      "[EPOCH #29, step #288] loss: 0.6407628103214151\n",
      "[EPOCH #29, step #290] loss: 0.6406906970690206\n",
      "[EPOCH #29, step #292] loss: 0.6418612669047236\n",
      "[EPOCH #29, step #294] loss: 0.642899244367066\n",
      "[EPOCH #29, step #296] loss: 0.6424271779931354\n",
      "[EPOCH #29, step #298] loss: 0.6420738765328226\n",
      "[EPOCH #29, step #300] loss: 0.643177310939247\n",
      "[EPOCH #29, step #302] loss: 0.6432842573415328\n",
      "[EPOCH #29, step #304] loss: 0.6440942074920311\n",
      "[EPOCH #29, step #306] loss: 0.6441511881176735\n",
      "[EPOCH #29, step #308] loss: 0.6439308520756107\n",
      "[EPOCH #29, step #310] loss: 0.6438797301705628\n",
      "[EPOCH #29, step #312] loss: 0.6448493195703616\n",
      "[EPOCH #29, step #314] loss: 0.643767785505643\n",
      "[EPOCH #29, step #316] loss: 0.643935897795936\n",
      "[EPOCH #29, step #318] loss: 0.6456478309575293\n",
      "[EPOCH #29, step #320] loss: 0.6463678143570356\n",
      "[EPOCH #29, step #322] loss: 0.6472260908168905\n",
      "[EPOCH #29, step #324] loss: 0.6466826488880011\n",
      "[EPOCH #29, step #326] loss: 0.646747362221782\n",
      "[EPOCH #29, step #328] loss: 0.6463998647174575\n",
      "[EPOCH #29, step #330] loss: 0.645795720086357\n",
      "[EPOCH #29, step #332] loss: 0.6452884357702267\n",
      "[EPOCH #29, step #334] loss: 0.645144505687614\n",
      "[EPOCH #29, step #336] loss: 0.6452300958445942\n",
      "[EPOCH #29, step #338] loss: 0.6472950717956267\n",
      "[EPOCH #29, step #340] loss: 0.6472680972031484\n",
      "[EPOCH #29, step #342] loss: 0.6458384006694177\n",
      "[EPOCH #29, step #344] loss: 0.6467244210018628\n",
      "[EPOCH #29, step #346] loss: 0.6471913465075946\n",
      "[EPOCH #29, step #348] loss: 0.6476846032890686\n",
      "[EPOCH #29, step #350] loss: 0.6484652546651003\n",
      "[EPOCH #29, step #352] loss: 0.6492089253900409\n",
      "[EPOCH #29, step #354] loss: 0.6507076091749567\n",
      "[EPOCH #29, step #356] loss: 0.6514492471929357\n",
      "[EPOCH #29, step #358] loss: 0.6519750792917103\n",
      "[EPOCH #29, step #360] loss: 0.6512014030006784\n",
      "[EPOCH #29, step #362] loss: 0.6513039516105468\n",
      "[EPOCH #29, step #364] loss: 0.6513932614702068\n",
      "[EPOCH #29, step #366] loss: 0.650518938817835\n",
      "[EPOCH #29, step #368] loss: 0.6494628778560375\n",
      "[EPOCH #29, step #370] loss: 0.6480234989499789\n",
      "[EPOCH #29, step #372] loss: 0.6481526763685267\n",
      "[EPOCH #29, step #374] loss: 0.6481616452932358\n",
      "[EPOCH #29, step #376] loss: 0.6483886196458372\n",
      "[EPOCH #29, step #378] loss: 0.6493570787689616\n",
      "[EPOCH #29, step #380] loss: 0.6498488907817155\n",
      "[EPOCH #29, step #382] loss: 0.6507822709746522\n",
      "[EPOCH #29, step #384] loss: 0.6518078935997826\n",
      "[EPOCH #29, step #386] loss: 0.652836281084275\n",
      "[EPOCH #29, step #388] loss: 0.6524652458325143\n",
      "[EPOCH #29, step #390] loss: 0.6541853709827603\n",
      "[EPOCH #29, step #392] loss: 0.6537054185269746\n",
      "[EPOCH #29, step #394] loss: 0.6545105567084083\n",
      "[EPOCH #29, step #396] loss: 0.6545788212972564\n",
      "[EPOCH #29, step #398] loss: 0.6545425972768238\n",
      "[EPOCH #29, step #400] loss: 0.655869421481789\n",
      "[EPOCH #29, step #402] loss: 0.6556263490217199\n",
      "[EPOCH #29, step #404] loss: 0.6551164211682331\n",
      "[EPOCH #29, step #406] loss: 0.6551201933358752\n",
      "[EPOCH #29, step #408] loss: 0.6571026997854774\n",
      "[EPOCH #29, step #410] loss: 0.6565517035206448\n",
      "[EPOCH #29, step #412] loss: 0.6561412518668117\n",
      "[EPOCH #29, step #414] loss: 0.6558816297585706\n",
      "[EPOCH #29, step #416] loss: 0.6566126293344178\n",
      "[EPOCH #29, step #418] loss: 0.6560266888155858\n",
      "[EPOCH #29, step #420] loss: 0.6557582974646267\n",
      "[EPOCH #29, step #422] loss: 0.6556625253131204\n",
      "[EPOCH #29, step #424] loss: 0.6549895360539941\n",
      "[EPOCH #29, step #426] loss: 0.6558776190395378\n",
      "[EPOCH #29, step #428] loss: 0.6561991662342788\n",
      "[EPOCH #29, step #430] loss: 0.656406995142419\n",
      "[EPOCH #29, step #432] loss: 0.6563069448391229\n",
      "[EPOCH #29, step #434] loss: 0.6567580337839565\n",
      "[EPOCH #29, step #436] loss: 0.6573129617854169\n",
      "[EPOCH #29, step #438] loss: 0.658509694192567\n",
      "[EPOCH #29, step #440] loss: 0.6582727556258372\n",
      "[EPOCH #29, step #442] loss: 0.6582811439481331\n",
      "[EPOCH #29, step #444] loss: 0.6583763008372168\n",
      "[EPOCH #29, step #446] loss: 0.6582190982114016\n",
      "[EPOCH #29, step #448] loss: 0.6587448317582464\n",
      "[EPOCH #29, step #450] loss: 0.6605338707665382\n",
      "[EPOCH #29, step #452] loss: 0.6603144733255799\n",
      "[EPOCH #29, step #454] loss: 0.6604154361145836\n",
      "[EPOCH #29, step #456] loss: 0.6599969174916687\n",
      "[EPOCH #29, step #458] loss: 0.6606871738607847\n",
      "[EPOCH #29, step #460] loss: 0.6601884247747264\n",
      "[EPOCH #29, step #462] loss: 0.6611175805201541\n",
      "[EPOCH #29, step #464] loss: 0.6610410529118712\n",
      "[EPOCH #29, step #466] loss: 0.6604890997264319\n",
      "[EPOCH #29, step #468] loss: 0.6609987271175202\n",
      "[EPOCH #29, step #470] loss: 0.6610466108010833\n",
      "[EPOCH #29, step #472] loss: 0.6600676791045429\n",
      "[EPOCH #29, step #474] loss: 0.6601795108381071\n",
      "[EPOCH #29, step #476] loss: 0.6602109475393215\n",
      "[EPOCH #29, step #478] loss: 0.6595604115152159\n",
      "[EPOCH #29, step #480] loss: 0.6599665907775042\n",
      "[EPOCH #29, step #482] loss: 0.6593585909338471\n",
      "[EPOCH #29, step #484] loss: 0.659212387499121\n",
      "[EPOCH #29, step #486] loss: 0.6597341758330989\n",
      "[EPOCH #29, step #488] loss: 0.6600313559936356\n",
      "[EPOCH #29, step #490] loss: 0.6600138498602962\n",
      "[EPOCH #29, step #492] loss: 0.6604779671885179\n",
      "[EPOCH #29, step #494] loss: 0.6601828340027067\n",
      "[EPOCH #29, step #496] loss: 0.6609035987909171\n",
      "[EPOCH #29, step #498] loss: 0.6609753536019393\n",
      "[EPOCH #29, step #500] loss: 0.6623193887833826\n",
      "[EPOCH #29, step #502] loss: 0.6626437129545402\n",
      "[EPOCH #29, step #504] loss: 0.6630225821001695\n",
      "[EPOCH #29, step #506] loss: 0.6621896683052917\n",
      "[EPOCH #29, step #508] loss: 0.661396566244146\n",
      "[EPOCH #29, step #510] loss: 0.661794495005197\n",
      "[EPOCH #29, step #512] loss: 0.6618288145137344\n",
      "[EPOCH #29, step #514] loss: 0.661760486879395\n",
      "[EPOCH #29, step #516] loss: 0.6615603907714729\n",
      "[EPOCH #29, step #518] loss: 0.6608260428687281\n",
      "[EPOCH #29, step #520] loss: 0.6597809762105832\n",
      "[EPOCH #29, step #522] loss: 0.6603603149064412\n",
      "[EPOCH #29, step #524] loss: 0.6611761114994685\n",
      "[EPOCH #29, step #526] loss: 0.6609803557226283\n",
      "[EPOCH #29, step #528] loss: 0.6604869145132418\n",
      "[EPOCH #29, step #530] loss: 0.6609332011749516\n",
      "[EPOCH #29, step #532] loss: 0.6611048279794922\n",
      "[EPOCH #29, step #534] loss: 0.660326247711048\n",
      "[EPOCH #29, step #536] loss: 0.6600983062103474\n",
      "[EPOCH #29, step #538] loss: 0.659799401442726\n",
      "[EPOCH #29, step #540] loss: 0.6589606368222211\n",
      "[EPOCH #29, step #542] loss: 0.6583627866611955\n",
      "[EPOCH #29, step #544] loss: 0.6580750374345604\n",
      "[EPOCH #29, step #546] loss: 0.6580319543806683\n",
      "[EPOCH #29, step #548] loss: 0.6580613280743197\n",
      "[EPOCH #29, step #550] loss: 0.6578856736097058\n",
      "[EPOCH #29, step #552] loss: 0.6569584595952284\n",
      "[EPOCH #29, step #554] loss: 0.6571023016094087\n",
      "[EPOCH #29, step #556] loss: 0.6570210028005031\n",
      "[EPOCH #29, step #558] loss: 0.6567992989460343\n",
      "[EPOCH #29, step #560] loss: 0.6564852231698453\n",
      "[EPOCH #29, step #562] loss: 0.656195823956764\n",
      "[EPOCH #29, step #564] loss: 0.6555518166417569\n",
      "[EPOCH #29, step #566] loss: 0.6552955972086605\n",
      "[EPOCH #29, step #568] loss: 0.6556205045831225\n",
      "[EPOCH #29, step #570] loss: 0.6553312574762805\n",
      "[EPOCH #29, step #572] loss: 0.6563517492114977\n",
      "[EPOCH #29, step #574] loss: 0.6553888540941736\n",
      "[EPOCH #29, step #576] loss: 0.6546107340778388\n",
      "[EPOCH #29, step #578] loss: 0.6540802693274355\n",
      "[EPOCH #29, step #580] loss: 0.6539237653891109\n",
      "[EPOCH #29, step #582] loss: 0.6543889018877906\n",
      "[EPOCH #29, step #584] loss: 0.6540588804035106\n",
      "[EPOCH #29, step #586] loss: 0.6550727103038785\n",
      "[EPOCH #29, step #588] loss: 0.6549377021694426\n",
      "[EPOCH #29, step #590] loss: 0.6554618722139881\n",
      "[EPOCH #29, step #592] loss: 0.6558906385960909\n",
      "[EPOCH #29, step #594] loss: 0.6556956058039385\n",
      "[EPOCH #29, step #596] loss: 0.6563221763576096\n",
      "[EPOCH #29, step #598] loss: 0.6571348375937776\n",
      "[EPOCH #29, step #600] loss: 0.6574347641771526\n",
      "[EPOCH #29, step #602] loss: 0.6573111813015012\n",
      "[EPOCH #29, step #604] loss: 0.6578827690240765\n",
      "[EPOCH #29, step #606] loss: 0.6578404871743829\n",
      "[EPOCH #29, step #608] loss: 0.6577326913527863\n",
      "[EPOCH #29, step #610] loss: 0.6578873941970534\n",
      "[EPOCH #29, step #612] loss: 0.6582611626892261\n",
      "[EPOCH #29, step #614] loss: 0.658522849330088\n",
      "[EPOCH #29, step #616] loss: 0.6580602525457184\n",
      "[EPOCH #29, step #618] loss: 0.6573014321205882\n",
      "[EPOCH #29, step #620] loss: 0.6581746109681813\n",
      "[EPOCH #29, step #622] loss: 0.657781305249009\n",
      "[EPOCH #29, step #624] loss: 0.6576108865976333\n",
      "[EPOCH #29, step #626] loss: 0.6572935373256461\n",
      "[EPOCH #29, step #628] loss: 0.6573530684072755\n",
      "[EPOCH #29, step #630] loss: 0.6578514979541207\n",
      "[EPOCH #29, step #632] loss: 0.6574460155261448\n",
      "[EPOCH #29, step #634] loss: 0.6578151538850754\n",
      "[EPOCH #29, step #636] loss: 0.6576296220441441\n",
      "[EPOCH #29, step #638] loss: 0.6568474506781508\n",
      "[EPOCH #29, step #640] loss: 0.6576859844316745\n",
      "[EPOCH #29, step #642] loss: 0.6575776248428722\n",
      "[EPOCH #29, step #644] loss: 0.6586392278588096\n",
      "[EPOCH #29, step #646] loss: 0.659155039344173\n",
      "[EPOCH #29, step #648] loss: 0.6583699276111159\n",
      "[EPOCH #29, step #650] loss: 0.6581924676025335\n",
      "[EPOCH #29, step #652] loss: 0.6585647918592004\n",
      "[EPOCH #29, step #654] loss: 0.658311330657879\n",
      "[EPOCH #29, step #656] loss: 0.6584758269777763\n",
      "[EPOCH #29, step #658] loss: 0.6580862356561811\n",
      "[EPOCH #29, step #660] loss: 0.6577929454699226\n",
      "[EPOCH #29, step #662] loss: 0.6573819999286672\n",
      "[EPOCH #29, step #664] loss: 0.6574477153837233\n",
      "[EPOCH #29, step #666] loss: 0.6576634487514196\n",
      "[EPOCH #29, step #668] loss: 0.6570384658104635\n",
      "[EPOCH #29, step #670] loss: 0.6569192444825137\n",
      "[EPOCH #29, step #672] loss: 0.6563099187647959\n",
      "[EPOCH #29, step #674] loss: 0.6556729094408177\n",
      "[EPOCH #29, step #676] loss: 0.6555105774626245\n",
      "[EPOCH #29, step #678] loss: 0.6559857417320468\n",
      "[EPOCH #29, step #680] loss: 0.6557552749496199\n",
      "[EPOCH #29, step #682] loss: 0.656345269843216\n",
      "[EPOCH #29, step #684] loss: 0.6565250853334901\n",
      "[EPOCH #29, step #686] loss: 0.6561059159439551\n",
      "[EPOCH #29, step #688] loss: 0.6558464020490646\n",
      "[EPOCH #29, step #690] loss: 0.6556773427900806\n",
      "[EPOCH #29, step #692] loss: 0.6555118821185044\n",
      "[EPOCH #29, step #694] loss: 0.6548323895648229\n",
      "[EPOCH #29, step #696] loss: 0.6552670121064658\n",
      "[EPOCH #29, step #698] loss: 0.6551606868938656\n",
      "[EPOCH #29, step #700] loss: 0.6553027887274637\n",
      "[EPOCH #29, step #702] loss: 0.6552493733116777\n",
      "[EPOCH #29, step #704] loss: 0.655745256686887\n",
      "[EPOCH #29, step #706] loss: 0.6561257129975053\n",
      "[EPOCH #29, step #708] loss: 0.6567773037762165\n",
      "[EPOCH #29, step #710] loss: 0.656669840426217\n",
      "[EPOCH #29, step #712] loss: 0.6564124089262094\n",
      "[EPOCH #29, step #714] loss: 0.6560784074601593\n",
      "[EPOCH #29, step #716] loss: 0.6557948658946834\n",
      "[EPOCH #29, step #718] loss: 0.6556284621420092\n",
      "[EPOCH #29, step #720] loss: 0.6561827866073786\n",
      "[EPOCH #29, step #722] loss: 0.6560194811179595\n",
      "[EPOCH #29, step #724] loss: 0.6557064135526789\n",
      "[EPOCH #29, step #726] loss: 0.6555720749919647\n",
      "[EPOCH #29, step #728] loss: 0.6551003453458452\n",
      "[EPOCH #29, step #730] loss: 0.6551117457337321\n",
      "[EPOCH #29, step #732] loss: 0.6550375501870459\n",
      "[EPOCH #29, step #734] loss: 0.6555533904404868\n",
      "[EPOCH #29, step #736] loss: 0.6559462294771033\n",
      "[EPOCH #29, step #738] loss: 0.6558701939003716\n",
      "[EPOCH #29, step #740] loss: 0.6558907375684795\n",
      "[EPOCH #29, step #742] loss: 0.6562074859442332\n",
      "[EPOCH #29, step #744] loss: 0.6561953292797076\n",
      "[EPOCH #29, step #746] loss: 0.656230212315179\n",
      "[EPOCH #29, step #748] loss: 0.6567972885949589\n",
      "[EPOCH #29, step #750] loss: 0.656792677452815\n",
      "[EPOCH #29, step #752] loss: 0.6568420301593474\n",
      "[EPOCH #29, step #754] loss: 0.6566614849085839\n",
      "[EPOCH #29, step #756] loss: 0.6564106133962087\n",
      "[EPOCH #29, step #758] loss: 0.6561116236746704\n",
      "[EPOCH #29, step #760] loss: 0.6566072388915603\n",
      "[EPOCH #29, step #762] loss: 0.6561102672805948\n",
      "[EPOCH #29, step #764] loss: 0.6563241147722294\n",
      "[EPOCH #29, step #766] loss: 0.6566416178447482\n",
      "[EPOCH #29, step #768] loss: 0.6566477958379393\n",
      "[EPOCH #29, step #770] loss: 0.6564816609314907\n",
      "[EPOCH #29, step #772] loss: 0.6563594935204048\n",
      "[EPOCH #29, step #774] loss: 0.6562846576975238\n",
      "[EPOCH #29, step #776] loss: 0.656228928511514\n",
      "[EPOCH #29, step #778] loss: 0.6564031555693937\n",
      "[EPOCH #29, step #780] loss: 0.6565101763541201\n",
      "[EPOCH #29, step #782] loss: 0.6567829019303218\n",
      "[EPOCH #29, step #784] loss: 0.6571513059222774\n",
      "[EPOCH #29, step #786] loss: 0.6574089754529042\n",
      "[EPOCH #29, step #788] loss: 0.6567520836346956\n",
      "[EPOCH #29, step #790] loss: 0.6569486910903499\n",
      "[EPOCH #29, step #792] loss: 0.6572023212421135\n",
      "[EPOCH #29, step #794] loss: 0.6573730312990692\n",
      "[EPOCH #29, step #796] loss: 0.6572982311585317\n",
      "[EPOCH #29, step #798] loss: 0.6577335261321337\n",
      "[EPOCH #29, step #800] loss: 0.6578169652027137\n",
      "[EPOCH #29, step #802] loss: 0.6577097554766523\n",
      "[EPOCH #29, step #804] loss: 0.6580723844144656\n",
      "[EPOCH #29, step #806] loss: 0.6585028496705909\n",
      "[EPOCH #29, step #808] loss: 0.6589106429824133\n",
      "[EPOCH #29, step #810] loss: 0.6590224500979801\n",
      "[EPOCH #29, step #812] loss: 0.6591310553335176\n",
      "[EPOCH #29, step #814] loss: 0.6593374896086067\n",
      "[EPOCH #29, step #816] loss: 0.6592941555026987\n",
      "[EPOCH #29, step #818] loss: 0.6590102284928381\n",
      "[EPOCH #29, step #820] loss: 0.6591486716495507\n",
      "[EPOCH #29, step #822] loss: 0.6593596415089518\n",
      "[EPOCH #29, step #824] loss: 0.6596841060573404\n",
      "[EPOCH #29, step #826] loss: 0.6599864875210816\n",
      "[EPOCH #29, step #828] loss: 0.6606086477978813\n",
      "[EPOCH #29, step #830] loss: 0.6603722510462634\n",
      "[EPOCH #29, step #832] loss: 0.660616451147653\n",
      "[EPOCH #29, step #834] loss: 0.6605729302067956\n",
      "[EPOCH #29, step #836] loss: 0.6602804930513477\n",
      "[EPOCH #29, step #838] loss: 0.6602132827469788\n",
      "[EPOCH #29, step #840] loss: 0.6606637680112394\n",
      "[EPOCH #29, step #842] loss: 0.6608460864951461\n",
      "[EPOCH #29, step #844] loss: 0.6604996345628648\n",
      "[EPOCH #29, step #846] loss: 0.660548480739982\n",
      "[EPOCH #29, step #848] loss: 0.6609715594876079\n",
      "[EPOCH #29, step #850] loss: 0.6612837713662661\n",
      "[EPOCH #29, step #852] loss: 0.6614347128732543\n",
      "[EPOCH #29, step #854] loss: 0.6614465265769011\n",
      "[EPOCH #29, step #856] loss: 0.6615542100879387\n",
      "[EPOCH #29, step #858] loss: 0.6617543033136617\n",
      "[EPOCH #29, step #860] loss: 0.661729420986325\n",
      "[EPOCH #29, step #862] loss: 0.6617463174279291\n",
      "[EPOCH #29, step #864] loss: 0.6614561637529748\n",
      "[EPOCH #29, step #866] loss: 0.6616770477821533\n",
      "[EPOCH #29, step #868] loss: 0.6618111315853165\n",
      "[EPOCH #29, step #870] loss: 0.6617796449621564\n",
      "[EPOCH #29, step #872] loss: 0.662231635579675\n",
      "[EPOCH #29, step #874] loss: 0.6623854331799915\n",
      "[EPOCH #29, step #876] loss: 0.662175639070562\n",
      "[EPOCH #29, step #878] loss: 0.6625795241814018\n",
      "[EPOCH #29, step #880] loss: 0.6629682178698928\n",
      "[EPOCH #29, step #882] loss: 0.6627575454564759\n",
      "[EPOCH #29, step #884] loss: 0.662753426742419\n",
      "[EPOCH #29, step #886] loss: 0.6625110983277389\n",
      "[EPOCH #29, step #888] loss: 0.6625935069722185\n",
      "[EPOCH #29, step #890] loss: 0.6623873343873105\n",
      "[EPOCH #29, step #892] loss: 0.6626769207326189\n",
      "[EPOCH #29, step #894] loss: 0.6623150582919574\n",
      "[EPOCH #29, step #896] loss: 0.6630462620536087\n",
      "[EPOCH #29, step #898] loss: 0.6628903888323415\n",
      "[EPOCH #29, step #900] loss: 0.6627124218677443\n",
      "[EPOCH #29, step #902] loss: 0.6630562552614994\n",
      "[EPOCH #29, step #904] loss: 0.6630783766178795\n",
      "[EPOCH #29, step #906] loss: 0.6627332374798555\n",
      "[EPOCH #29, step #908] loss: 0.6628022488489402\n",
      "[EPOCH #29, step #910] loss: 0.6635004427410769\n",
      "[EPOCH #29, step #912] loss: 0.6638566106231424\n",
      "[EPOCH #29, step #914] loss: 0.6633702434965821\n",
      "[EPOCH #29, step #916] loss: 0.6630686035495548\n",
      "[EPOCH #29, step #918] loss: 0.6624788145926883\n",
      "[EPOCH #29, step #920] loss: 0.6625043165573727\n",
      "[EPOCH #29, step #922] loss: 0.6622969504780785\n",
      "[EPOCH #29, step #924] loss: 0.6619605470509142\n",
      "[EPOCH #29, step #926] loss: 0.6620728495212306\n",
      "[EPOCH #29, step #928] loss: 0.6624715379704957\n",
      "[EPOCH #29, step #930] loss: 0.6624412628973081\n",
      "[EPOCH #29, step #932] loss: 0.6623867104770287\n",
      "[EPOCH #29, step #934] loss: 0.6620268309976965\n",
      "[EPOCH #29, step #936] loss: 0.662060217723139\n",
      "[EPOCH #29, step #938] loss: 0.6621424693681689\n",
      "[EPOCH #29, step #940] loss: 0.6620359874462093\n",
      "[EPOCH #29, step #942] loss: 0.6618489922831192\n",
      "[EPOCH #29, step #944] loss: 0.6618074044506386\n",
      "[EPOCH #29, step #946] loss: 0.6619048442892187\n",
      "[EPOCH #29, step #948] loss: 0.6613235385858849\n",
      "[EPOCH #29, step #950] loss: 0.6609496736407405\n",
      "[EPOCH #29, step #952] loss: 0.6604516009437575\n",
      "[EPOCH #29, step #954] loss: 0.6599971595702995\n",
      "[EPOCH #29, step #956] loss: 0.6598519246126043\n",
      "[EPOCH #29, step #958] loss: 0.659931993941321\n",
      "[EPOCH #29, step #960] loss: 0.660059103965139\n",
      "[EPOCH #29, step #962] loss: 0.6597545919233888\n",
      "[EPOCH #29, step #964] loss: 0.6597252302064797\n",
      "[EPOCH #29, step #966] loss: 0.6590308102296575\n",
      "[EPOCH #29, step #968] loss: 0.658989515190154\n",
      "[EPOCH #29, step #970] loss: 0.6590880136227141\n",
      "[EPOCH #29, step #972] loss: 0.6592399701246378\n",
      "[EPOCH #29, step #974] loss: 0.6588296573895674\n",
      "[EPOCH #29, step #976] loss: 0.6589526601494152\n",
      "[EPOCH #29, step #978] loss: 0.6588091993660679\n",
      "[EPOCH #29, step #980] loss: 0.6583818566361699\n",
      "[EPOCH #29, step #982] loss: 0.6584221195895699\n",
      "[EPOCH #29, step #984] loss: 0.6586970235187996\n",
      "[EPOCH #29, step #986] loss: 0.6586457997892644\n",
      "[EPOCH #29, step #988] loss: 0.6588273598342622\n",
      "[EPOCH #29, step #990] loss: 0.6590295536246237\n",
      "[EPOCH #29, step #992] loss: 0.6588833580564516\n",
      "[EPOCH #29, step #994] loss: 0.6581533429011628\n",
      "[EPOCH #29, step #996] loss: 0.6579365577238613\n",
      "[EPOCH #29, step #998] loss: 0.6577979878143028\n",
      "[EPOCH #29, step #1000] loss: 0.657806694031238\n",
      "[EPOCH #29, step #1002] loss: 0.6577416427827191\n",
      "[EPOCH #29, step #1004] loss: 0.6576034669852375\n",
      "[EPOCH #29, step #1006] loss: 0.6575848544839595\n",
      "[EPOCH #29, step #1008] loss: 0.6578668596368833\n",
      "[EPOCH #29, step #1010] loss: 0.6575196782453124\n",
      "[EPOCH #29, step #1012] loss: 0.6570739951150203\n",
      "[EPOCH #29, step #1014] loss: 0.6567252665024086\n",
      "[EPOCH #29, step #1016] loss: 0.6572374648459424\n",
      "[EPOCH #29, step #1018] loss: 0.6575779297459465\n",
      "[EPOCH #29, step #1020] loss: 0.6573302071545196\n",
      "[EPOCH #29, step #1022] loss: 0.6578485490872596\n",
      "[EPOCH #29, step #1024] loss: 0.6581050176736785\n",
      "[EPOCH #29, step #1026] loss: 0.6579392012625845\n",
      "[EPOCH #29, step #1028] loss: 0.658260494731258\n",
      "[EPOCH #29, step #1030] loss: 0.6584060049311382\n",
      "[EPOCH #29, step #1032] loss: 0.6586781086441623\n",
      "[EPOCH #29, step #1034] loss: 0.658807331064473\n",
      "[EPOCH #29, step #1036] loss: 0.6591976288429452\n",
      "[EPOCH #29, step #1038] loss: 0.6591368625666569\n",
      "[EPOCH #29, step #1040] loss: 0.6590515689478827\n",
      "[EPOCH #29, step #1042] loss: 0.6590092335314216\n",
      "[EPOCH #29, step #1044] loss: 0.658675762340783\n",
      "[EPOCH #29, step #1046] loss: 0.6589550682216342\n",
      "[EPOCH #29, step #1048] loss: 0.659072574032728\n",
      "[EPOCH #29, step #1050] loss: 0.6587134346465175\n",
      "[EPOCH #29, step #1052] loss: 0.6590032998935902\n",
      "[EPOCH #29, step #1054] loss: 0.6590943577165287\n",
      "[EPOCH #29, step #1056] loss: 0.6590435191382749\n",
      "[EPOCH #29, step #1058] loss: 0.6586960128616679\n",
      "[EPOCH #29, step #1060] loss: 0.6584010268864375\n",
      "[EPOCH #29, step #1062] loss: 0.6583877342944984\n",
      "[EPOCH #29, step #1064] loss: 0.6585854397972984\n",
      "[EPOCH #29, step #1066] loss: 0.6592389857701978\n",
      "[EPOCH #29, step #1068] loss: 0.6589007272243054\n",
      "[EPOCH #29, step #1070] loss: 0.6587484442775879\n",
      "[EPOCH #29, step #1072] loss: 0.6586274008604265\n",
      "[EPOCH #29, step #1074] loss: 0.6591327571868897\n",
      "[EPOCH #29, step #1076] loss: 0.6589323706724296\n",
      "[EPOCH #29, step #1078] loss: 0.6587726831215195\n",
      "[EPOCH #29, step #1080] loss: 0.6589513053285315\n",
      "[EPOCH #29, step #1082] loss: 0.6590274454594098\n",
      "[EPOCH #29, step #1084] loss: 0.6592163561675956\n",
      "[EPOCH #29, step #1086] loss: 0.6594104330366428\n",
      "[EPOCH #29, step #1088] loss: 0.6591493706565258\n",
      "[EPOCH #29, step #1090] loss: 0.6593968949932008\n",
      "[EPOCH #29, step #1092] loss: 0.6595982007498274\n",
      "[EPOCH #29, step #1094] loss: 0.6593572053462947\n",
      "[EPOCH #29, step #1096] loss: 0.6592607441389681\n",
      "[EPOCH #29, step #1098] loss: 0.6593683616642089\n",
      "[EPOCH #29, step #1100] loss: 0.6598908152772989\n",
      "[EPOCH #29, step #1102] loss: 0.6602226828891152\n",
      "[EPOCH #29, step #1104] loss: 0.6599247956168058\n",
      "[EPOCH #29, step #1106] loss: 0.660152271861091\n",
      "[EPOCH #29, step #1108] loss: 0.660280679264404\n",
      "[EPOCH #29, step #1110] loss: 0.6604858784124081\n",
      "[EPOCH #29, step #1112] loss: 0.660626507164226\n",
      "[EPOCH #29, step #1114] loss: 0.6610396174304688\n",
      "[EPOCH #29, step #1116] loss: 0.6609711870351004\n",
      "[EPOCH #29, step #1118] loss: 0.6610785473714033\n",
      "[EPOCH #29, step #1120] loss: 0.6610403656693679\n",
      "[EPOCH #29, step #1122] loss: 0.6608266454929766\n",
      "[EPOCH #29, step #1124] loss: 0.6612445204787785\n",
      "[EPOCH #29, step #1126] loss: 0.6610992005840275\n",
      "[EPOCH #29, step #1128] loss: 0.6610553184370745\n",
      "[EPOCH #29, step #1130] loss: 0.6612621716015324\n",
      "[EPOCH #29, step #1132] loss: 0.6612017429306354\n",
      "[EPOCH #29, step #1134] loss: 0.6614775103094295\n",
      "[EPOCH #29, step #1136] loss: 0.6614758515945106\n",
      "[EPOCH #29, step #1138] loss: 0.6613732472755492\n",
      "[EPOCH #29, step #1140] loss: 0.6608947847205019\n",
      "[EPOCH #29, step #1142] loss: 0.6611568951231288\n",
      "[EPOCH #29, step #1144] loss: 0.6611318622614099\n",
      "[EPOCH #29, step #1146] loss: 0.6608335974170731\n",
      "[EPOCH #29, step #1148] loss: 0.6612076829110569\n",
      "[EPOCH #29, step #1150] loss: 0.660881307283554\n",
      "[EPOCH #29, step #1152] loss: 0.6612691254535139\n",
      "[EPOCH #29, step #1154] loss: 0.6612849426217926\n",
      "[EPOCH #29, step #1156] loss: 0.6610392479156768\n",
      "[EPOCH #29, step #1158] loss: 0.6608410751490473\n",
      "[EPOCH #29, step #1160] loss: 0.6606538515733708\n",
      "[EPOCH #29, step #1162] loss: 0.6610610415632112\n",
      "[EPOCH #29, step #1164] loss: 0.66117781280448\n",
      "[EPOCH #29, step #1166] loss: 0.6614423508100665\n",
      "[EPOCH #29, step #1168] loss: 0.6615727510178976\n",
      "[EPOCH #29, step #1170] loss: 0.6614994698869785\n",
      "[EPOCH #29, step #1172] loss: 0.6614632864132561\n",
      "[EPOCH #29, step #1174] loss: 0.6615415026279206\n",
      "[EPOCH #29, step #1176] loss: 0.661544554422949\n",
      "[EPOCH #29, step #1178] loss: 0.6617815945237445\n",
      "[EPOCH #29, step #1180] loss: 0.661516193966054\n",
      "[EPOCH #29, step #1182] loss: 0.6613278557764506\n",
      "[EPOCH #29, step #1184] loss: 0.6611964280092264\n",
      "[EPOCH #29, step #1186] loss: 0.6612467330950292\n",
      "[EPOCH #29, step #1188] loss: 0.6610988618647782\n",
      "[EPOCH #29, step #1190] loss: 0.6610176199429382\n",
      "[EPOCH #29, step #1192] loss: 0.6613622144401723\n",
      "[EPOCH #29, step #1194] loss: 0.6612109547878409\n",
      "[EPOCH #29, step #1196] loss: 0.6612773861801415\n",
      "[EPOCH #29, step #1198] loss: 0.6611456004056063\n",
      "[EPOCH #29, step #1200] loss: 0.6612045257216588\n",
      "[EPOCH #29, step #1202] loss: 0.6607970201711504\n",
      "[EPOCH #29, step #1204] loss: 0.6610846788804066\n",
      "[EPOCH #29, step #1206] loss: 0.6615784783302108\n",
      "[EPOCH #29, step #1208] loss: 0.6613485244456355\n",
      "[EPOCH #29, step #1210] loss: 0.6616289022783914\n",
      "[EPOCH #29, step #1212] loss: 0.6619655809074223\n",
      "[EPOCH #29, step #1214] loss: 0.6619850626943533\n",
      "[EPOCH #29, step #1216] loss: 0.6618936131161163\n",
      "[EPOCH #29, step #1218] loss: 0.6623530469779796\n",
      "[EPOCH #29, step #1220] loss: 0.6622586225652968\n",
      "[EPOCH #29, step #1222] loss: 0.6624979468661064\n",
      "[EPOCH #29, step #1224] loss: 0.6625709718344163\n",
      "[EPOCH #29, step #1226] loss: 0.6625992153948074\n",
      "[EPOCH #29, step #1228] loss: 0.6623932462188652\n",
      "[EPOCH #29, step #1230] loss: 0.6623746533397733\n",
      "[EPOCH #29, step #1232] loss: 0.6620295856265836\n",
      "[EPOCH #29, step #1234] loss: 0.6619084694607538\n",
      "[EPOCH #29, step #1236] loss: 0.6618986441998493\n",
      "[EPOCH #29, step #1238] loss: 0.6616055018195613\n",
      "[EPOCH #29, step #1240] loss: 0.6615949958490807\n",
      "[EPOCH #29, step #1242] loss: 0.6612588785295034\n",
      "[EPOCH #29, step #1244] loss: 0.6608638923570335\n",
      "[EPOCH #29, step #1246] loss: 0.6610158705051746\n",
      "[EPOCH #29, step #1248] loss: 0.6611548479172208\n",
      "[EPOCH #29, step #1250] loss: 0.6610951586831197\n",
      "[EPOCH #29, step #1252] loss: 0.6611859381959996\n",
      "[EPOCH #29, step #1254] loss: 0.6609539991830925\n",
      "[EPOCH #29, step #1256] loss: 0.6607784459822312\n",
      "[EPOCH #29, step #1258] loss: 0.6609064155244183\n",
      "[EPOCH #29, step #1260] loss: 0.6605414122130359\n",
      "[EPOCH #29, step #1262] loss: 0.6605421128437241\n",
      "[EPOCH #29, step #1264] loss: 0.6605856910289041\n",
      "[EPOCH #29, step #1266] loss: 0.6604068388173029\n",
      "[EPOCH #29, step #1268] loss: 0.6605810058267216\n",
      "[EPOCH #29, step #1270] loss: 0.6606898817089389\n",
      "[EPOCH #29, step #1272] loss: 0.6605118451770234\n",
      "[EPOCH #29, step #1274] loss: 0.660241658523971\n",
      "[EPOCH #29, step #1276] loss: 0.6602281910092362\n",
      "[EPOCH #29, step #1278] loss: 0.6606345598216724\n",
      "[EPOCH #29, step #1280] loss: 0.6604386918206032\n",
      "[EPOCH #29, step #1282] loss: 0.6606392134518151\n",
      "[EPOCH #29, step #1284] loss: 0.6605189012414286\n",
      "[EPOCH #29, step #1286] loss: 0.6605710279552531\n",
      "[EPOCH #29, step #1288] loss: 0.6604000059692687\n",
      "[EPOCH #29, step #1290] loss: 0.6602968457454309\n",
      "[EPOCH #29, step #1292] loss: 0.6600188348796694\n",
      "[EPOCH #29, step #1294] loss: 0.6601178869777665\n",
      "[EPOCH #29, step #1296] loss: 0.6604452429593483\n",
      "[EPOCH #29, step #1298] loss: 0.6602996627673265\n",
      "[EPOCH #29, step #1300] loss: 0.6607322034516947\n",
      "[EPOCH #29, step #1302] loss: 0.6605634296617413\n",
      "[EPOCH #29, step #1304] loss: 0.6604999419144744\n",
      "[EPOCH #29, step #1306] loss: 0.6603494205817797\n",
      "[EPOCH #29, step #1308] loss: 0.6602102497591146\n",
      "[EPOCH #29, step #1310] loss: 0.6603608243707297\n",
      "[EPOCH #29, step #1312] loss: 0.6605999492908923\n",
      "[EPOCH #29, step #1314] loss: 0.6604389986611138\n",
      "[EPOCH #29, step #1316] loss: 0.6602414330254021\n",
      "[EPOCH #29, step #1318] loss: 0.6599766059614114\n",
      "[EPOCH #29, step #1320] loss: 0.6597683880700927\n",
      "[EPOCH #29, step #1322] loss: 0.6603257875278513\n",
      "[EPOCH #29, step #1324] loss: 0.6604406678226759\n",
      "[EPOCH #29, step #1326] loss: 0.6605826207768585\n",
      "[EPOCH #29, step #1328] loss: 0.6606374452713291\n",
      "[EPOCH #29, step #1330] loss: 0.6604565925207647\n",
      "[EPOCH #29, step #1332] loss: 0.6603330143930675\n",
      "[EPOCH #29, step #1334] loss: 0.6601261175750347\n",
      "[EPOCH #29, step #1336] loss: 0.6601093639922659\n",
      "[EPOCH #29, step #1338] loss: 0.6602428097659033\n",
      "[EPOCH #29, step #1340] loss: 0.6600622045824903\n",
      "[EPOCH #29, step #1342] loss: 0.65960731039452\n",
      "[EPOCH #29, step #1344] loss: 0.6592568645468432\n",
      "[EPOCH #29, step #1346] loss: 0.6589760776351979\n",
      "[EPOCH #29, step #1348] loss: 0.6589727432662421\n",
      "[EPOCH #29, step #1350] loss: 0.6589370842865888\n",
      "[EPOCH #29, step #1352] loss: 0.6589226973823328\n",
      "[EPOCH #29, step #1354] loss: 0.6591159264979767\n",
      "[EPOCH #29, step #1356] loss: 0.6589841750850551\n",
      "[EPOCH #29, step #1358] loss: 0.6590734420671807\n",
      "[EPOCH #29, step #1360] loss: 0.6591340648523593\n",
      "[EPOCH #29, step #1362] loss: 0.6589052884655671\n",
      "[EPOCH #29, step #1364] loss: 0.6588186524726533\n",
      "[EPOCH #29, step #1366] loss: 0.6586091406343624\n",
      "[EPOCH #29, step #1368] loss: 0.658457555241442\n",
      "[EPOCH #29, step #1370] loss: 0.6581790868945577\n",
      "[EPOCH #29, step #1372] loss: 0.658144634306561\n",
      "[EPOCH #29, step #1374] loss: 0.658303312626752\n",
      "[EPOCH #29, step #1376] loss: 0.6583283519130214\n",
      "[EPOCH #29, step #1378] loss: 0.6584746054629643\n",
      "[EPOCH #29, step #1380] loss: 0.6585255323718373\n",
      "[EPOCH #29, step #1382] loss: 0.6587560891631024\n",
      "[EPOCH #29, step #1384] loss: 0.6585561904235867\n",
      "[EPOCH #29, step #1386] loss: 0.6585575388160299\n",
      "[EPOCH #29, step #1388] loss: 0.6587768283741692\n",
      "[EPOCH #29, step #1390] loss: 0.6587162952385388\n",
      "[EPOCH #29, step #1392] loss: 0.6587491219880679\n",
      "[EPOCH #29, step #1394] loss: 0.6590960044160111\n",
      "[EPOCH #29, step #1396] loss: 0.6593506866979361\n",
      "[EPOCH #29, step #1398] loss: 0.6592757968156145\n",
      "[EPOCH #29, step #1400] loss: 0.659035897080512\n",
      "[EPOCH #29, step #1402] loss: 0.65911262520109\n",
      "[EPOCH #29, step #1404] loss: 0.6590071610072329\n",
      "[EPOCH #29, step #1406] loss: 0.659148078207946\n",
      "[EPOCH #29, step #1408] loss: 0.658865749201426\n",
      "[EPOCH #29, step #1410] loss: 0.6587057168774365\n",
      "[EPOCH #29, step #1412] loss: 0.6588460571236081\n",
      "[EPOCH #29, step #1414] loss: 0.6586909826568496\n",
      "[EPOCH #29, step #1416] loss: 0.6587027359277998\n",
      "[EPOCH #29, step #1418] loss: 0.6584513528276448\n",
      "[EPOCH #29, step #1420] loss: 0.6586280417937279\n",
      "[EPOCH #29, step #1422] loss: 0.658646847002957\n",
      "[EPOCH #29, step #1424] loss: 0.6588876548775455\n",
      "[EPOCH #29, step #1426] loss: 0.6592437776762369\n",
      "[EPOCH #29, step #1428] loss: 0.6596051514816084\n",
      "[EPOCH #29, step #1430] loss: 0.6600311153798066\n",
      "[EPOCH #29, step #1432] loss: 0.6601960931261852\n",
      "[EPOCH #29, step #1434] loss: 0.6600286520316626\n",
      "[EPOCH #29, step #1436] loss: 0.6598751179526561\n",
      "[EPOCH #29, step #1438] loss: 0.6601643026330721\n",
      "[EPOCH #29, step #1440] loss: 0.6601074964614646\n",
      "[EPOCH #29, step #1442] loss: 0.6603831358444996\n",
      "[EPOCH #29, step #1444] loss: 0.6602751473242023\n",
      "[EPOCH #29, step #1446] loss: 0.6601248060989644\n",
      "[EPOCH #29, step #1448] loss: 0.6598083463268004\n",
      "[EPOCH #29, step #1450] loss: 0.659564097325281\n",
      "[EPOCH #29, step #1452] loss: 0.65963711438307\n",
      "[EPOCH #29, step #1454] loss: 0.6595477985352585\n",
      "[EPOCH #29, step #1456] loss: 0.6595499242669356\n",
      "[EPOCH #29, step #1458] loss: 0.6595096613872207\n",
      "[EPOCH #29, step #1460] loss: 0.659562109350587\n",
      "[EPOCH #29, step #1462] loss: 0.6594013399403142\n",
      "[EPOCH #29, step #1464] loss: 0.6594729323842826\n",
      "[EPOCH #29, step #1466] loss: 0.6598159969462452\n",
      "[EPOCH #29, step #1468] loss: 0.6598094232720205\n",
      "[EPOCH #29, step #1470] loss: 0.6595948866684367\n",
      "[EPOCH #29, step #1472] loss: 0.6597124031224545\n",
      "[EPOCH #29, step #1474] loss: 0.6599711105176957\n",
      "[EPOCH #29, step #1476] loss: 0.6597659402629695\n",
      "[EPOCH #29, step #1478] loss: 0.6597001911257472\n",
      "[EPOCH #29, step #1480] loss: 0.6598810652958872\n",
      "[EPOCH #29, step #1482] loss: 0.6599658589385605\n",
      "[EPOCH #29, step #1484] loss: 0.6601486149861756\n",
      "[EPOCH #29, step #1486] loss: 0.660104931402944\n",
      "[EPOCH #29, step #1488] loss: 0.6601156594370579\n",
      "[EPOCH #29, step #1490] loss: 0.6603777097184573\n",
      "[EPOCH #29, step #1492] loss: 0.6604824560006353\n",
      "[EPOCH #29, step #1494] loss: 0.6604059488478313\n",
      "[EPOCH #29, step #1496] loss: 0.6604519978951994\n",
      "[EPOCH #29, step #1498] loss: 0.6604950959043077\n",
      "[EPOCH #29, step #1500] loss: 0.6607792023457661\n",
      "[EPOCH #29, step #1502] loss: 0.6607693778580217\n",
      "[EPOCH #29, step #1504] loss: 0.6605548172100042\n",
      "[EPOCH #29, step #1506] loss: 0.6606767043303241\n",
      "[EPOCH #29, step #1508] loss: 0.660521309924015\n",
      "[EPOCH #29, step #1510] loss: 0.6607155081138636\n",
      "[EPOCH #29, step #1512] loss: 0.6608846926641874\n",
      "[EPOCH #29, step #1514] loss: 0.6614809955307359\n",
      "[EPOCH #29, step #1516] loss: 0.661780130454562\n",
      "[EPOCH #29, step #1518] loss: 0.6619116345701287\n",
      "[EPOCH #29, step #1520] loss: 0.6621893839880011\n",
      "[EPOCH #29, step #1522] loss: 0.6619760644373265\n",
      "[EPOCH #29, step #1524] loss: 0.6622793568744034\n",
      "[EPOCH #29, step #1526] loss: 0.6621823708801856\n",
      "[EPOCH #29, step #1528] loss: 0.6623248628458219\n",
      "[EPOCH #29, step #1530] loss: 0.6620509828289376\n",
      "[EPOCH #29, step #1532] loss: 0.6619077467366286\n",
      "[EPOCH #29, step #1534] loss: 0.6619860816662009\n",
      "[EPOCH #29, step #1536] loss: 0.6619234556258307\n",
      "[EPOCH #29, step #1538] loss: 0.6618162367814853\n",
      "[EPOCH #29, step #1540] loss: 0.6620601096337372\n",
      "[EPOCH #29, step #1542] loss: 0.6621499730060414\n",
      "[EPOCH #29, step #1544] loss: 0.6619954734172636\n",
      "[EPOCH #29, step #1546] loss: 0.6624161648457484\n",
      "[EPOCH #29, step #1548] loss: 0.6624299959646955\n",
      "[EPOCH #29, step #1550] loss: 0.6625335410977087\n",
      "[EPOCH #29, step #1552] loss: 0.6623064247892506\n",
      "[EPOCH #29, step #1554] loss: 0.6623124309099756\n",
      "[EPOCH #29, step #1556] loss: 0.662299521798573\n",
      "[EPOCH #29, step #1558] loss: 0.6622829339953857\n",
      "[EPOCH #29, step #1560] loss: 0.6624663281066535\n",
      "[EPOCH #29, step #1562] loss: 0.6623801074574105\n",
      "[EPOCH #29, step #1564] loss: 0.6622700745876605\n",
      "[EPOCH #29, step #1566] loss: 0.6624972831122649\n",
      "[EPOCH #29, step #1568] loss: 0.6624607077026307\n",
      "[EPOCH #29, step #1570] loss: 0.6624853937091681\n",
      "[EPOCH #29, step #1572] loss: 0.6626335140897904\n",
      "[EPOCH #29, step #1574] loss: 0.6625206004816389\n",
      "[EPOCH #29, step #1576] loss: 0.662697185556119\n",
      "[EPOCH #29, step #1578] loss: 0.6624324661859461\n",
      "[EPOCH #29, step #1580] loss: 0.6627811037762719\n",
      "[EPOCH #29, step #1582] loss: 0.6627066735594768\n",
      "[EPOCH #29, step #1584] loss: 0.6629332502933707\n",
      "[EPOCH #29, step #1586] loss: 0.6628627126593971\n",
      "[EPOCH #29, step #1588] loss: 0.6625787107317308\n",
      "[EPOCH #29, step #1590] loss: 0.6626294219853517\n",
      "[EPOCH #29, step #1592] loss: 0.6625562409934052\n",
      "[EPOCH #29, step #1594] loss: 0.6625228006451107\n",
      "[EPOCH #29, step #1596] loss: 0.6626392521370033\n",
      "[EPOCH #29, step #1598] loss: 0.6625170965467564\n",
      "[EPOCH #29, step #1600] loss: 0.6627570058426806\n",
      "[EPOCH #29, step #1602] loss: 0.662917368555545\n",
      "[EPOCH #29, step #1604] loss: 0.6631944842242006\n",
      "[EPOCH #29, step #1606] loss: 0.6630301285249963\n",
      "[EPOCH #29, step #1608] loss: 0.6628641700655722\n",
      "[EPOCH #29, step #1610] loss: 0.6627735089323374\n",
      "[EPOCH #29, step #1612] loss: 0.6628886747456306\n",
      "[EPOCH #29, step #1614] loss: 0.6627791813098979\n",
      "[EPOCH #29, step #1616] loss: 0.6625973363496229\n",
      "[EPOCH #29, step #1618] loss: 0.6628366563885649\n",
      "[EPOCH #29, step #1620] loss: 0.6629235345702492\n",
      "[EPOCH #29, step #1622] loss: 0.6626502278588542\n",
      "[EPOCH #29, step #1624] loss: 0.6629257433414459\n",
      "[EPOCH #29, step #1626] loss: 0.6632690602786422\n",
      "[EPOCH #29, step #1628] loss: 0.663292618618193\n",
      "[EPOCH #29, step #1630] loss: 0.6634132956924942\n",
      "[EPOCH #29, step #1632] loss: 0.6634383277701806\n",
      "[EPOCH #29, step #1634] loss: 0.6632409575700031\n",
      "[EPOCH #29, step #1636] loss: 0.662877101212212\n",
      "[EPOCH #29, step #1638] loss: 0.6628194686986819\n",
      "[EPOCH #29, step #1640] loss: 0.6627595216526192\n",
      "[EPOCH #29, step #1642] loss: 0.662980296302698\n",
      "[EPOCH #29, step #1644] loss: 0.6629239272564016\n",
      "[EPOCH #29, step #1646] loss: 0.6626501710362773\n",
      "[EPOCH #29, step #1648] loss: 0.6626030766761541\n",
      "[EPOCH #29, step #1650] loss: 0.662723583084103\n",
      "[EPOCH #29, step #1652] loss: 0.6629245410128499\n",
      "[EPOCH #29, step #1654] loss: 0.6631684697826823\n",
      "[EPOCH #29, step #1656] loss: 0.6630156784260496\n",
      "[EPOCH #29, step #1658] loss: 0.6630640976072579\n",
      "[EPOCH #29, step #1660] loss: 0.6628563859461303\n",
      "[EPOCH #29, step #1662] loss: 0.6630350575343859\n",
      "[EPOCH #29, step #1664] loss: 0.6630438715845973\n",
      "[EPOCH #29, step #1666] loss: 0.6632537926537732\n",
      "[EPOCH #29, step #1668] loss: 0.6631042326975183\n",
      "[EPOCH #29, step #1670] loss: 0.6634160315897706\n",
      "[EPOCH #29, step #1672] loss: 0.663485185193645\n",
      "[EPOCH #29, step #1674] loss: 0.6631865948349682\n",
      "[EPOCH #29, step #1676] loss: 0.6632758372940332\n",
      "[EPOCH #29, step #1678] loss: 0.6631320586617749\n",
      "[EPOCH #29, step #1680] loss: 0.6631434362144573\n",
      "[EPOCH #29, step #1682] loss: 0.6630070978732457\n",
      "[EPOCH #29, step #1684] loss: 0.6630651421645982\n",
      "[EPOCH #29, step #1686] loss: 0.6627743074402134\n",
      "[EPOCH #29, step #1688] loss: 0.6625957072592826\n",
      "[EPOCH #29, step #1690] loss: 0.662776908389497\n",
      "[EPOCH #29, step #1692] loss: 0.6627789732801513\n",
      "[EPOCH #29, step #1694] loss: 0.6627761051893938\n",
      "[EPOCH #29, step #1696] loss: 0.6631509722262603\n",
      "[EPOCH #29, step #1698] loss: 0.6630968705670423\n",
      "[EPOCH #29, step #1700] loss: 0.6629272681660403\n",
      "[EPOCH #29, step #1702] loss: 0.6630925391431564\n",
      "[EPOCH #29, step #1704] loss: 0.6629084319313251\n",
      "[EPOCH #29, step #1706] loss: 0.66283370887039\n",
      "[EPOCH #29, step #1708] loss: 0.6629626169547901\n",
      "[EPOCH #29, step #1710] loss: 0.6630334058120054\n",
      "[EPOCH #29, step #1712] loss: 0.6630111638732772\n",
      "[EPOCH #29, step #1714] loss: 0.6630083153094912\n",
      "[EPOCH #29, step #1716] loss: 0.66301628239084\n",
      "[EPOCH #29, step #1718] loss: 0.6630941969041841\n",
      "[EPOCH #29, step #1720] loss: 0.6631048659229611\n",
      "[EPOCH #29, step #1722] loss: 0.6635567487600718\n",
      "[EPOCH #29, step #1724] loss: 0.6634121460327204\n",
      "[EPOCH #29, step #1726] loss: 0.6634591403177313\n",
      "[EPOCH #29, step #1728] loss: 0.6634282275146663\n",
      "[EPOCH #29, step #1730] loss: 0.6633109341013439\n",
      "[EPOCH #29, step #1732] loss: 0.6634202487573277\n",
      "[EPOCH #29, step #1734] loss: 0.6632229984493695\n",
      "[EPOCH #29, step #1736] loss: 0.6633438715216889\n",
      "[EPOCH #29, step #1738] loss: 0.6631663325807704\n",
      "[EPOCH #29, step #1740] loss: 0.6631682191101865\n",
      "[EPOCH #29, step #1742] loss: 0.6634588038620426\n",
      "[EPOCH #29, step #1744] loss: 0.663374413340686\n",
      "[EPOCH #29, step #1746] loss: 0.6634274442569829\n",
      "[EPOCH #29, step #1748] loss: 0.6636250696739788\n",
      "[EPOCH #29, step #1750] loss: 0.6637358077419342\n",
      "[EPOCH #29, step #1752] loss: 0.6640192550281355\n",
      "[EPOCH #29, step #1754] loss: 0.6639927213518029\n",
      "[EPOCH #29, step #1756] loss: 0.6641217844182277\n",
      "[EPOCH #29, step #1758] loss: 0.6640074194629738\n",
      "[EPOCH #29, step #1760] loss: 0.6639985296450035\n",
      "[EPOCH #29, step #1762] loss: 0.6641240314502845\n",
      "[EPOCH #29, step #1764] loss: 0.6642259771864407\n",
      "[EPOCH #29, step #1766] loss: 0.6640720196747145\n",
      "[EPOCH #29, step #1768] loss: 0.6640521154826883\n",
      "[EPOCH #29, step #1770] loss: 0.6641368935802843\n",
      "[EPOCH #29, step #1772] loss: 0.6642048264282676\n",
      "[EPOCH #29, step #1774] loss: 0.6642313190077392\n",
      "[EPOCH #29, step #1776] loss: 0.6639935711024515\n",
      "[EPOCH #29, step #1778] loss: 0.6637029208917173\n",
      "[EPOCH #29, step #1780] loss: 0.6636777676135753\n",
      "[EPOCH #29, step #1782] loss: 0.6636099163495084\n",
      "[EPOCH #29, step #1784] loss: 0.6636455462426365\n",
      "[EPOCH #29, step #1786] loss: 0.6638226479742203\n",
      "[EPOCH #29, step #1788] loss: 0.6636066550546148\n",
      "[EPOCH #29, step #1790] loss: 0.6636011345402479\n",
      "[EPOCH #29, step #1792] loss: 0.663569951682402\n",
      "[EPOCH #29, step #1794] loss: 0.6633522256503198\n",
      "[EPOCH #29, step #1796] loss: 0.6635482047223753\n",
      "[EPOCH #29, step #1798] loss: 0.6635384407555016\n",
      "[EPOCH #29, step #1800] loss: 0.6634711303160231\n",
      "[EPOCH #29, step #1802] loss: 0.6633120998202994\n",
      "[EPOCH #29, step #1804] loss: 0.6631887454570495\n",
      "[EPOCH #29, step #1806] loss: 0.6630387926174253\n",
      "[EPOCH #29, step #1808] loss: 0.6631728974312561\n",
      "[EPOCH #29, step #1810] loss: 0.6632744158288513\n",
      "[EPOCH #29, step #1812] loss: 0.6631284221982141\n",
      "[EPOCH #29, step #1814] loss: 0.663197994593418\n",
      "[EPOCH #29, step #1816] loss: 0.6635165914901351\n",
      "[EPOCH #29, step #1818] loss: 0.6636372037219634\n",
      "[EPOCH #29, step #1820] loss: 0.6638343565284649\n",
      "[EPOCH #29, step #1822] loss: 0.6636729287009153\n",
      "[EPOCH #29, step #1824] loss: 0.6634518741908139\n",
      "[EPOCH #29, step #1826] loss: 0.6634357044392749\n",
      "[EPOCH #29, step #1828] loss: 0.6635249897780608\n",
      "[EPOCH #29, step #1830] loss: 0.6633493898508654\n",
      "[EPOCH #29, step #1832] loss: 0.6634526981301991\n",
      "[EPOCH #29, step #1834] loss: 0.6634094672404452\n",
      "[EPOCH #29, step #1836] loss: 0.6633086298137627\n",
      "[EPOCH #29, step #1838] loss: 0.6631892942714588\n",
      "[EPOCH #29, step #1840] loss: 0.6629764906483329\n",
      "[EPOCH #29, step #1842] loss: 0.6626273989354018\n",
      "[EPOCH #29, step #1844] loss: 0.6625615955691351\n",
      "[EPOCH #29, step #1846] loss: 0.6625325529395921\n",
      "[EPOCH #29, step #1848] loss: 0.6625203764586916\n",
      "[EPOCH #29, step #1850] loss: 0.6628886463190014\n",
      "[EPOCH #29, step #1852] loss: 0.6629720021439319\n",
      "[EPOCH #29, step #1854] loss: 0.663184490775805\n",
      "[EPOCH #29, step #1856] loss: 0.6629944092718966\n",
      "[EPOCH #29, step #1858] loss: 0.6628069655269369\n",
      "[EPOCH #29, step #1860] loss: 0.6629992829638742\n",
      "[EPOCH #29, step #1862] loss: 0.6631060191302676\n",
      "[EPOCH #29, step #1864] loss: 0.6632535359654925\n",
      "[EPOCH #29, step #1866] loss: 0.6630540537878863\n",
      "[EPOCH #29, step #1868] loss: 0.6632158354586494\n",
      "[EPOCH #29, step #1870] loss: 0.6632031271605489\n",
      "[EPOCH #29, step #1872] loss: 0.6633370591081914\n",
      "[EPOCH #29, step #1874] loss: 0.6631461194833119\n",
      "[EPOCH #29, step #1876] loss: 0.6632574920998524\n",
      "[EPOCH #29, step #1878] loss: 0.6631438683613365\n",
      "[EPOCH #29, step #1880] loss: 0.6629777295452556\n",
      "[EPOCH #29, step #1882] loss: 0.66302482654804\n",
      "[EPOCH #29, step #1884] loss: 0.6632909306954958\n",
      "[EPOCH #29, step #1886] loss: 0.6636946152206697\n",
      "[EPOCH #29, step #1888] loss: 0.6636758069155265\n",
      "[EPOCH #29, step #1890] loss: 0.663747585793767\n",
      "[EPOCH #29, step #1892] loss: 0.6639686662465633\n",
      "[EPOCH #29, step #1894] loss: 0.6637898943826831\n",
      "[EPOCH #29, step #1896] loss: 0.6638432844067224\n",
      "[EPOCH #29, step #1898] loss: 0.6636976243132601\n",
      "[EPOCH #29, step #1900] loss: 0.6635444168665734\n",
      "[EPOCH #29, step #1902] loss: 0.663694169292059\n",
      "[EPOCH #29, step #1904] loss: 0.663722319459039\n",
      "[EPOCH #29, step #1906] loss: 0.6636737181243937\n",
      "[EPOCH #29, step #1908] loss: 0.6635671115908216\n",
      "[EPOCH #29, step #1910] loss: 0.6634137644030422\n",
      "[EPOCH #29, step #1912] loss: 0.6631800136638448\n",
      "[EPOCH #29, step #1914] loss: 0.6632183290025895\n",
      "[EPOCH #29, step #1916] loss: 0.6632762912604482\n",
      "[EPOCH #29, step #1918] loss: 0.6632502960810878\n",
      "[EPOCH #29, step #1920] loss: 0.6632650347813414\n",
      "[EPOCH #29, step #1922] loss: 0.6634176605329251\n",
      "[EPOCH #29, step #1924] loss: 0.6633190516063145\n",
      "[EPOCH #29, step #1926] loss: 0.663117108223781\n",
      "[EPOCH #29, step #1928] loss: 0.6631252391156661\n",
      "[EPOCH #29, step #1930] loss: 0.6630429481361149\n",
      "[EPOCH #29, step #1932] loss: 0.6631579533550817\n",
      "[EPOCH #29, step #1934] loss: 0.6629542822831669\n",
      "[EPOCH #29, step #1936] loss: 0.6631259567877898\n",
      "[EPOCH #29, step #1938] loss: 0.6631010601882039\n",
      "[EPOCH #29, step #1940] loss: 0.6631494832984692\n",
      "[EPOCH #29, step #1942] loss: 0.6632014672380714\n",
      "[EPOCH #29, step #1944] loss: 0.6631728565018711\n",
      "[EPOCH #29, step #1946] loss: 0.663158424294295\n",
      "[EPOCH #29, step #1948] loss: 0.6631777911170316\n",
      "[EPOCH #29, step #1950] loss: 0.6632066473082235\n",
      "[EPOCH #29, step #1952] loss: 0.6630826603279807\n",
      "[EPOCH #29, step #1954] loss: 0.6630989195288295\n",
      "[EPOCH #29, step #1956] loss: 0.6631519838779266\n",
      "[EPOCH #29, step #1958] loss: 0.6633764282211227\n",
      "[EPOCH #29, step #1960] loss: 0.663313083004915\n",
      "[EPOCH #29, step #1962] loss: 0.6634572648570906\n",
      "[EPOCH #29, step #1964] loss: 0.663242181794334\n",
      "[EPOCH #29, step #1966] loss: 0.6633095226284206\n",
      "[EPOCH #29, step #1968] loss: 0.6631061626818654\n",
      "[EPOCH #29, step #1970] loss: 0.6633213204910524\n",
      "[EPOCH #29, step #1972] loss: 0.6637456434454582\n",
      "[EPOCH #29, step #1974] loss: 0.6638380292548409\n",
      "[EPOCH #29, step #1976] loss: 0.6638653158809901\n",
      "[EPOCH #29, step #1978] loss: 0.6638770736998654\n",
      "[EPOCH #29, step #1980] loss: 0.6636740805854826\n",
      "[EPOCH #29, step #1982] loss: 0.663962561992221\n",
      "[EPOCH #29, step #1984] loss: 0.6636473665009217\n",
      "[EPOCH #29, step #1986] loss: 0.6636136014916276\n",
      "[EPOCH #29, step #1988] loss: 0.663337905032962\n",
      "[EPOCH #29, step #1990] loss: 0.6634342766538569\n",
      "[EPOCH #29, step #1992] loss: 0.6633636806696668\n",
      "[EPOCH #29, step #1994] loss: 0.6634489248270976\n",
      "[EPOCH #29, step #1996] loss: 0.6633898520027929\n",
      "[EPOCH #29, step #1998] loss: 0.6634996019941142\n",
      "[EPOCH #29, step #2000] loss: 0.6636033311061773\n",
      "[EPOCH #29, step #2002] loss: 0.6638006260855699\n",
      "[EPOCH #29, step #2004] loss: 0.6637739678868034\n",
      "[EPOCH #29, step #2006] loss: 0.6637758174581675\n",
      "[EPOCH #29, step #2008] loss: 0.6638604144423443\n",
      "[EPOCH #29, step #2010] loss: 0.6637376853774757\n",
      "[EPOCH #29, step #2012] loss: 0.6638400868077332\n",
      "[EPOCH #29, step #2014] loss: 0.6639189261212834\n",
      "[EPOCH #29, step #2016] loss: 0.6638047348229555\n",
      "[EPOCH #29, step #2018] loss: 0.6638123942755897\n",
      "[EPOCH #29, step #2020] loss: 0.6638807008196846\n",
      "[EPOCH #29, step #2022] loss: 0.6641331092001952\n",
      "[EPOCH #29, step #2024] loss: 0.6643863466345233\n",
      "[EPOCH #29, step #2026] loss: 0.6642674205040896\n",
      "[EPOCH #29, step #2028] loss: 0.6642306044279148\n",
      "[EPOCH #29, step #2030] loss: 0.6642048965528762\n",
      "[EPOCH #29, step #2032] loss: 0.6640951845280009\n",
      "[EPOCH #29, step #2034] loss: 0.6643126260004114\n",
      "[EPOCH #29, step #2036] loss: 0.6642001287487715\n",
      "[EPOCH #29, step #2038] loss: 0.6642132727552594\n",
      "[EPOCH #29, step #2040] loss: 0.6642971483443895\n",
      "[EPOCH #29, step #2042] loss: 0.6641003985762071\n",
      "[EPOCH #29, step #2044] loss: 0.6640971763792715\n",
      "[EPOCH #29, step #2046] loss: 0.6639406251278399\n",
      "[EPOCH #29, step #2048] loss: 0.6640663475976333\n",
      "[EPOCH #29, step #2050] loss: 0.6642651105729154\n",
      "[EPOCH #29, step #2052] loss: 0.6644253503445934\n",
      "[EPOCH #29, step #2054] loss: 0.6645443443834347\n",
      "[EPOCH #29, step #2056] loss: 0.6644409248912341\n",
      "[EPOCH #29, step #2058] loss: 0.6641036310405509\n",
      "[EPOCH #29, step #2060] loss: 0.664021403233673\n",
      "[EPOCH #29, step #2062] loss: 0.6639629263382079\n",
      "[EPOCH #29, step #2064] loss: 0.6640774838427943\n",
      "[EPOCH #29, step #2066] loss: 0.6640080619129398\n",
      "[EPOCH #29, step #2068] loss: 0.6640341311419511\n",
      "[EPOCH #29, step #2070] loss: 0.6638652905929727\n",
      "[EPOCH #29, step #2072] loss: 0.6636342562832122\n",
      "[EPOCH #29, step #2074] loss: 0.6636850796406527\n",
      "[EPOCH #29, step #2076] loss: 0.663448444770745\n",
      "[EPOCH #29, step #2078] loss: 0.6633414811758883\n",
      "[EPOCH #29, step #2080] loss: 0.6633733998606378\n",
      "[EPOCH #29, step #2082] loss: 0.6633208786788836\n",
      "[EPOCH #29, step #2084] loss: 0.6631125425549148\n",
      "[EPOCH #29, step #2086] loss: 0.663186435929085\n",
      "[EPOCH #29, step #2088] loss: 0.6631944228325694\n",
      "[EPOCH #29, step #2090] loss: 0.6631391078647046\n",
      "[EPOCH #29, step #2092] loss: 0.6630375054938566\n",
      "[EPOCH #29, step #2094] loss: 0.6630618332678492\n",
      "[EPOCH #29, step #2096] loss: 0.6630268316355329\n",
      "[EPOCH #29, step #2098] loss: 0.6629309354082864\n",
      "[EPOCH #29, step #2100] loss: 0.6629128461505958\n",
      "[EPOCH #29, step #2102] loss: 0.6627243999719507\n",
      "[EPOCH #29, step #2104] loss: 0.6627968012720276\n",
      "[EPOCH #29, step #2106] loss: 0.6626774470388578\n",
      "[EPOCH #29, step #2108] loss: 0.6627287584890851\n",
      "[EPOCH #29, step #2110] loss: 0.6625089913761938\n",
      "[EPOCH #29, step #2112] loss: 0.6623893564789993\n",
      "[EPOCH #29, step #2114] loss: 0.6624798239686529\n",
      "[EPOCH #29, step #2116] loss: 0.6624927038593454\n",
      "[EPOCH #29, step #2118] loss: 0.662435018000821\n",
      "[EPOCH #29, step #2120] loss: 0.6622019174496895\n",
      "[EPOCH #29, step #2122] loss: 0.6621372444108585\n",
      "[EPOCH #29, step #2124] loss: 0.6618635422692579\n",
      "[EPOCH #29, step #2126] loss: 0.6619137345861817\n",
      "[EPOCH #29, step #2128] loss: 0.6619419384906974\n",
      "[EPOCH #29, step #2130] loss: 0.6621545206026425\n",
      "[EPOCH #29, step #2132] loss: 0.6622362813016813\n",
      "[EPOCH #29, step #2134] loss: 0.6621115679414267\n",
      "[EPOCH #29, step #2136] loss: 0.6621321239689549\n",
      "[EPOCH #29, step #2138] loss: 0.6623418449226971\n",
      "[EPOCH #29, step #2140] loss: 0.6624252040257581\n",
      "[EPOCH #29, step #2142] loss: 0.6621379772956495\n",
      "[EPOCH #29, step #2144] loss: 0.6622366300204418\n",
      "[EPOCH #29, step #2146] loss: 0.6622906921281335\n",
      "[EPOCH #29, step #2148] loss: 0.6622149282732693\n",
      "[EPOCH #29, step #2150] loss: 0.6622598275355215\n",
      "[EPOCH #29, step #2152] loss: 0.6623222149019179\n",
      "[EPOCH #29, step #2154] loss: 0.6622988360871295\n",
      "[EPOCH #29, step #2156] loss: 0.6625333324965913\n",
      "[EPOCH #29, step #2158] loss: 0.6623814106746756\n",
      "[EPOCH #29, step #2160] loss: 0.6622282587188308\n",
      "[EPOCH #29, step #2162] loss: 0.6621165520757423\n",
      "[EPOCH #29, step #2164] loss: 0.6620236056437393\n",
      "[EPOCH #29, step #2166] loss: 0.6619332647359366\n",
      "[EPOCH #29, step #2168] loss: 0.661831018141801\n",
      "[EPOCH #29, step #2170] loss: 0.6619586492054257\n",
      "[EPOCH #29, step #2172] loss: 0.6618778746398539\n",
      "[EPOCH #29, step #2174] loss: 0.6618086145869617\n",
      "[EPOCH #29, step #2176] loss: 0.6618002142977922\n",
      "[EPOCH #29, step #2178] loss: 0.6616576801081107\n",
      "[EPOCH #29, step #2180] loss: 0.6618116328758364\n",
      "[EPOCH #29, step #2182] loss: 0.6618897453926595\n",
      "[EPOCH #29, step #2184] loss: 0.6619012423115409\n",
      "[EPOCH #29, step #2186] loss: 0.6619175614956911\n",
      "[EPOCH #29, step #2188] loss: 0.6618630118691905\n",
      "[EPOCH #29, step #2190] loss: 0.6619912164157409\n",
      "[EPOCH #29, step #2192] loss: 0.6620572121228685\n",
      "[EPOCH #29, step #2194] loss: 0.6621016588936091\n",
      "[EPOCH #29, step #2196] loss: 0.6621074821320131\n",
      "[EPOCH #29, step #2198] loss: 0.6620867178013456\n",
      "[EPOCH #29, step #2200] loss: 0.6619670859782169\n",
      "[EPOCH #29, step #2202] loss: 0.6618544730648256\n",
      "[EPOCH #29, step #2204] loss: 0.6618886162026398\n",
      "[EPOCH #29, step #2206] loss: 0.6617765223204847\n",
      "[EPOCH #29, step #2208] loss: 0.6617993089598517\n",
      "[EPOCH #29, step #2210] loss: 0.6618272491988959\n",
      "[EPOCH #29, step #2212] loss: 0.6618875541126249\n",
      "[EPOCH #29, step #2214] loss: 0.6618553097374552\n",
      "[EPOCH #29, step #2216] loss: 0.6620095157453914\n",
      "[EPOCH #29, step #2218] loss: 0.6621029939789554\n",
      "[EPOCH #29, step #2220] loss: 0.6621356204534532\n",
      "[EPOCH #29, step #2222] loss: 0.6620817015058974\n",
      "[EPOCH #29, step #2224] loss: 0.6621795733658116\n",
      "[EPOCH #29, step #2226] loss: 0.6620997004261132\n",
      "[EPOCH #29, step #2228] loss: 0.6621394998466236\n",
      "[EPOCH #29, step #2230] loss: 0.6622578891028422\n",
      "[EPOCH #29, step #2232] loss: 0.6621242099968351\n",
      "[EPOCH #29, step #2234] loss: 0.6623488139852848\n",
      "[EPOCH #29, step #2236] loss: 0.6625533494890189\n",
      "[EPOCH #29, step #2238] loss: 0.6624620992152911\n",
      "[EPOCH #29, step #2240] loss: 0.6625294046828067\n",
      "[EPOCH #29, step #2242] loss: 0.6626845971912452\n",
      "[EPOCH #29, step #2244] loss: 0.6626822127332135\n",
      "[EPOCH #29, step #2246] loss: 0.6626969784710425\n",
      "[EPOCH #29, step #2248] loss: 0.6626584619257173\n",
      "[EPOCH #29, step #2250] loss: 0.6624557231662539\n",
      "[EPOCH #29, step #2252] loss: 0.6625166499993032\n",
      "[EPOCH #29, step #2254] loss: 0.6623266228881485\n",
      "[EPOCH #29, step #2256] loss: 0.6622637007938427\n",
      "[EPOCH #29, step #2258] loss: 0.6622848495900393\n",
      "[EPOCH #29, step #2260] loss: 0.6624642295984503\n",
      "[EPOCH #29, step #2262] loss: 0.6628733509562998\n",
      "[EPOCH #29, step #2264] loss: 0.6627951965097824\n",
      "[EPOCH #29, step #2266] loss: 0.6627789157823576\n",
      "[EPOCH #29, step #2268] loss: 0.6625984080263885\n",
      "[EPOCH #29, step #2270] loss: 0.6625681736365859\n",
      "[EPOCH #29, step #2272] loss: 0.662475664888087\n",
      "[EPOCH #29, step #2274] loss: 0.662340734234223\n",
      "[EPOCH #29, step #2276] loss: 0.6624161785024271\n",
      "[EPOCH #29, step #2278] loss: 0.662597470786447\n",
      "[EPOCH #29, step #2280] loss: 0.6626759892372853\n",
      "[EPOCH #29, step #2282] loss: 0.6628195229808437\n",
      "[EPOCH #29, step #2284] loss: 0.6627370023818715\n",
      "[EPOCH #29, step #2286] loss: 0.6627556760797451\n",
      "[EPOCH #29, step #2288] loss: 0.662747624068606\n",
      "[EPOCH #29, step #2290] loss: 0.6628256465854316\n",
      "[EPOCH #29, step #2292] loss: 0.6627111295282815\n",
      "[EPOCH #29, step #2294] loss: 0.6628769325469833\n",
      "[EPOCH #29, step #2296] loss: 0.6628445023018016\n",
      "[EPOCH #29, step #2298] loss: 0.6627499144548642\n",
      "[EPOCH #29, step #2300] loss: 0.662523067856239\n",
      "[EPOCH #29, step #2302] loss: 0.662569088692309\n",
      "[EPOCH #29, step #2304] loss: 0.6626364303708335\n",
      "[EPOCH #29, step #2306] loss: 0.6625019351628418\n",
      "[EPOCH #29, step #2308] loss: 0.6625353164451367\n",
      "[EPOCH #29, step #2310] loss: 0.662809237876479\n",
      "[EPOCH #29, step #2312] loss: 0.6626297181695249\n",
      "[EPOCH #29, step #2314] loss: 0.6625596018447731\n",
      "[EPOCH #29, step #2316] loss: 0.6624434600822566\n",
      "[EPOCH #29, step #2318] loss: 0.6625819175587281\n",
      "[EPOCH #29, step #2320] loss: 0.6626234095590169\n",
      "[EPOCH #29, step #2322] loss: 0.6627760861731273\n",
      "[EPOCH #29, step #2324] loss: 0.6627501356153078\n",
      "[EPOCH #29, step #2326] loss: 0.6624905623857382\n",
      "[EPOCH #29, step #2328] loss: 0.6624156116044485\n",
      "[EPOCH #29, step #2330] loss: 0.6623556618972277\n",
      "[EPOCH #29, step #2332] loss: 0.6624374258776259\n",
      "[EPOCH #29, step #2334] loss: 0.6623170165676121\n",
      "[EPOCH #29, step #2336] loss: 0.6622282681515649\n",
      "[EPOCH #29, step #2338] loss: 0.6621048870110624\n",
      "[EPOCH #29, step #2340] loss: 0.662455594339772\n",
      "[EPOCH #29, step #2342] loss: 0.6625796082217725\n",
      "[EPOCH #29, step #2344] loss: 0.6625313772385054\n",
      "[EPOCH #29, step #2346] loss: 0.6625952814925108\n",
      "[EPOCH #29, step #2348] loss: 0.662596939757257\n",
      "[EPOCH #29, step #2350] loss: 0.6626646115152646\n",
      "[EPOCH #29, step #2352] loss: 0.6626288340831887\n",
      "[EPOCH #29, step #2354] loss: 0.6627352160190068\n",
      "[EPOCH #29, step #2356] loss: 0.6626843906113997\n",
      "[EPOCH #29, step #2358] loss: 0.662867824087056\n",
      "[EPOCH #29, step #2360] loss: 0.6629335963021694\n",
      "[EPOCH #29, step #2362] loss: 0.6629885207267318\n",
      "[EPOCH #29, step #2364] loss: 0.6630169478770794\n",
      "[EPOCH #29, step #2366] loss: 0.6629482066210786\n",
      "[EPOCH #29, step #2368] loss: 0.6629236792841255\n",
      "[EPOCH #29, step #2370] loss: 0.6629739990658219\n",
      "[EPOCH #29, step #2372] loss: 0.6630772100726211\n",
      "[EPOCH #29, step #2374] loss: 0.6629992691780392\n",
      "[EPOCH #29, step #2376] loss: 0.662924588497667\n",
      "[EPOCH #29, step #2378] loss: 0.6630908577707246\n",
      "[EPOCH #29, step #2380] loss: 0.6633007944894408\n",
      "[EPOCH #29, step #2382] loss: 0.6633844284502538\n",
      "[EPOCH #29, step #2384] loss: 0.6635912200627337\n",
      "[EPOCH #29, step #2386] loss: 0.6636040527287717\n",
      "[EPOCH #29, step #2388] loss: 0.6636422278929476\n",
      "[EPOCH #29, step #2390] loss: 0.6634056282399938\n",
      "[EPOCH #29, step #2392] loss: 0.6633137644669823\n",
      "[EPOCH #29, step #2394] loss: 0.6635730464734713\n",
      "[EPOCH #29, step #2396] loss: 0.6635440820932985\n",
      "[EPOCH #29, step #2398] loss: 0.6635138345925\n",
      "[EPOCH #29, step #2400] loss: 0.6633826565526516\n",
      "[EPOCH #29, step #2402] loss: 0.6631081067568255\n",
      "[EPOCH #29, step #2404] loss: 0.6629964222159554\n",
      "[EPOCH #29, step #2406] loss: 0.6630671396634863\n",
      "[EPOCH #29, step #2408] loss: 0.6630697291067598\n",
      "[EPOCH #29, step #2410] loss: 0.6631683410697338\n",
      "[EPOCH #29, step #2412] loss: 0.6633319961817197\n",
      "[EPOCH #29, step #2414] loss: 0.6632669838318913\n",
      "[EPOCH #29, step #2416] loss: 0.6632062877857049\n",
      "[EPOCH #29, step #2418] loss: 0.6631973173781928\n",
      "[EPOCH #29, step #2420] loss: 0.6632834366041488\n",
      "[EPOCH #29, step #2422] loss: 0.6631971042337272\n",
      "[EPOCH #29, step #2424] loss: 0.6632313562299788\n",
      "[EPOCH #29, step #2426] loss: 0.6633272044664555\n",
      "[EPOCH #29, step #2428] loss: 0.6632999079788894\n",
      "[EPOCH #29, step #2430] loss: 0.6632232575419507\n",
      "[EPOCH #29, step #2432] loss: 0.662968698128035\n",
      "[EPOCH #29, step #2434] loss: 0.6628891955900486\n",
      "[EPOCH #29, step #2436] loss: 0.6630093216602558\n",
      "[EPOCH #29, step #2438] loss: 0.662879175866613\n",
      "[EPOCH #29, step #2440] loss: 0.662977230336421\n",
      "[EPOCH #29, step #2442] loss: 0.6631010989039051\n",
      "[EPOCH #29, step #2444] loss: 0.6630757628652459\n",
      "[EPOCH #29, step #2446] loss: 0.6630605966352081\n",
      "[EPOCH #29, step #2448] loss: 0.6628894672899063\n",
      "[EPOCH #29, step #2450] loss: 0.6629704359671088\n",
      "[EPOCH #29, step #2452] loss: 0.6629359728455106\n",
      "[EPOCH #29, step #2454] loss: 0.6630511408182366\n",
      "[EPOCH #29, step #2456] loss: 0.6630999355913907\n",
      "[EPOCH #29, step #2458] loss: 0.6631762954751472\n",
      "[EPOCH #29, step #2460] loss: 0.6632091224266232\n",
      "[EPOCH #29, step #2462] loss: 0.6630285098283599\n",
      "[EPOCH #29, step #2464] loss: 0.663079669255514\n",
      "[EPOCH #29, step #2466] loss: 0.6629629065911201\n",
      "[EPOCH #29, step #2468] loss: 0.662940890635011\n",
      "[EPOCH #29, step #2470] loss: 0.6630173618978742\n",
      "[EPOCH #29, step #2472] loss: 0.663388302812584\n",
      "[EPOCH #29, step #2474] loss: 0.6635073418689497\n",
      "[EPOCH #29, step #2476] loss: 0.6634709441016939\n",
      "[EPOCH #29, step #2478] loss: 0.6635091371260232\n",
      "[EPOCH #29, step #2480] loss: 0.6634629932515614\n",
      "[EPOCH #29, step #2482] loss: 0.6635312147909627\n",
      "[EPOCH #29, step #2484] loss: 0.6636560302984786\n",
      "[EPOCH #29, step #2486] loss: 0.6637069274131007\n",
      "[EPOCH #29, step #2488] loss: 0.6636495388454584\n",
      "[EPOCH #29, step #2490] loss: 0.6638034543733624\n",
      "[EPOCH #29, step #2492] loss: 0.6638488843528993\n",
      "[EPOCH #29, step #2494] loss: 0.6637400478184342\n",
      "[EPOCH #29, step #2496] loss: 0.6636978020823665\n",
      "[EPOCH #29, step #2498] loss: 0.6637819571440675\n",
      "[EPOCH #29, elapsed time: 14613.768[sec]] loss: 0.6637925670266152\n",
      "[EPOCH #30, step #0] loss: 0.43853476643562317\n",
      "[EPOCH #30, step #2] loss: 0.5436999897162119\n",
      "[EPOCH #30, step #4] loss: 0.5259263157844544\n",
      "[EPOCH #30, step #6] loss: 0.49709746667316984\n",
      "[EPOCH #30, step #8] loss: 0.4765943255689409\n",
      "[EPOCH #30, step #10] loss: 0.529374358328906\n",
      "[EPOCH #30, step #12] loss: 0.5616263770140134\n",
      "[EPOCH #30, step #14] loss: 0.5900878290335337\n",
      "[EPOCH #30, step #16] loss: 0.5981717547949623\n",
      "[EPOCH #30, step #18] loss: 0.5762456122197603\n",
      "[EPOCH #30, step #20] loss: 0.5758212818985894\n",
      "[EPOCH #30, step #22] loss: 0.5590763934280562\n",
      "[EPOCH #30, step #24] loss: 0.5554045403003692\n",
      "[EPOCH #30, step #26] loss: 0.5602184225011755\n",
      "[EPOCH #30, step #28] loss: 0.5612705144388922\n",
      "[EPOCH #30, step #30] loss: 0.5782440554711127\n",
      "[EPOCH #30, step #32] loss: 0.5752641034848762\n",
      "[EPOCH #30, step #34] loss: 0.571738029377801\n",
      "[EPOCH #30, step #36] loss: 0.5692782579241572\n",
      "[EPOCH #30, step #38] loss: 0.566245490923906\n",
      "[EPOCH #30, step #40] loss: 0.5655320235868779\n",
      "[EPOCH #30, step #42] loss: 0.570884027453356\n",
      "[EPOCH #30, step #44] loss: 0.5659894512759315\n",
      "[EPOCH #30, step #46] loss: 0.5550188155884438\n",
      "[EPOCH #30, step #48] loss: 0.5597217241112067\n",
      "[EPOCH #30, step #50] loss: 0.5581732345562355\n",
      "[EPOCH #30, step #52] loss: 0.5640031200534893\n",
      "[EPOCH #30, step #54] loss: 0.5645622822371397\n",
      "[EPOCH #30, step #56] loss: 0.5634515499859526\n",
      "[EPOCH #30, step #58] loss: 0.5621024713677875\n",
      "[EPOCH #30, step #60] loss: 0.5720293082174708\n",
      "[EPOCH #30, step #62] loss: 0.5709794636756654\n",
      "[EPOCH #30, step #64] loss: 0.5710369160542121\n",
      "[EPOCH #30, step #66] loss: 0.5687236278804381\n",
      "[EPOCH #30, step #68] loss: 0.5728938596836035\n",
      "[EPOCH #30, step #70] loss: 0.5737534308097731\n",
      "[EPOCH #30, step #72] loss: 0.5799939999841663\n",
      "[EPOCH #30, step #74] loss: 0.5728254969914754\n",
      "[EPOCH #30, step #76] loss: 0.5777156987747589\n",
      "[EPOCH #30, step #78] loss: 0.5763011997259115\n",
      "[EPOCH #30, step #80] loss: 0.5779858378716457\n",
      "[EPOCH #30, step #82] loss: 0.5782393425343985\n",
      "[EPOCH #30, step #84] loss: 0.5814392335274641\n",
      "[EPOCH #30, step #86] loss: 0.5815415776323998\n",
      "[EPOCH #30, step #88] loss: 0.5820659496141284\n",
      "[EPOCH #30, step #90] loss: 0.5823089745673504\n",
      "[EPOCH #30, step #92] loss: 0.5899354498232564\n",
      "[EPOCH #30, step #94] loss: 0.5922437627064554\n",
      "[EPOCH #30, step #96] loss: 0.593337890720859\n",
      "[EPOCH #30, step #98] loss: 0.5959770525946761\n",
      "[EPOCH #30, step #100] loss: 0.599048255398722\n",
      "[EPOCH #30, step #102] loss: 0.5997601721471953\n",
      "[EPOCH #30, step #104] loss: 0.6051533769993555\n",
      "[EPOCH #30, step #106] loss: 0.6030638685850339\n",
      "[EPOCH #30, step #108] loss: 0.6038803376189066\n",
      "[EPOCH #30, step #110] loss: 0.5980720750920407\n",
      "[EPOCH #30, step #112] loss: 0.599536526255903\n",
      "[EPOCH #30, step #114] loss: 0.5988333777241085\n",
      "[EPOCH #30, step #116] loss: 0.5999383083266071\n",
      "[EPOCH #30, step #118] loss: 0.5993468904194712\n",
      "[EPOCH #30, step #120] loss: 0.5986770162405062\n",
      "[EPOCH #30, step #122] loss: 0.606689822140748\n",
      "[EPOCH #30, step #124] loss: 0.6035841464996338\n",
      "[EPOCH #30, step #126] loss: 0.6023466408722044\n",
      "[EPOCH #30, step #128] loss: 0.6030612306077351\n",
      "[EPOCH #30, step #130] loss: 0.6027778086771491\n",
      "[EPOCH #30, step #132] loss: 0.6041135102286375\n",
      "[EPOCH #30, step #134] loss: 0.6052744927229705\n",
      "[EPOCH #30, step #136] loss: 0.6064328894998036\n",
      "[EPOCH #30, step #138] loss: 0.6073076965139924\n",
      "[EPOCH #30, step #140] loss: 0.6075927040255662\n",
      "[EPOCH #30, step #142] loss: 0.6062539213604027\n",
      "[EPOCH #30, step #144] loss: 0.6083245879617231\n",
      "[EPOCH #30, step #146] loss: 0.6082043305140774\n",
      "[EPOCH #30, step #148] loss: 0.6122254303237736\n",
      "[EPOCH #30, step #150] loss: 0.6113866526164756\n",
      "[EPOCH #30, step #152] loss: 0.6088110699373133\n",
      "[EPOCH #30, step #154] loss: 0.6066891276067303\n",
      "[EPOCH #30, step #156] loss: 0.6062636950593085\n",
      "[EPOCH #30, step #158] loss: 0.6061921353984929\n",
      "[EPOCH #30, step #160] loss: 0.6060050259465757\n",
      "[EPOCH #30, step #162] loss: 0.6044903333567403\n",
      "[EPOCH #30, step #164] loss: 0.6056146728269982\n",
      "[EPOCH #30, step #166] loss: 0.6064529627740026\n",
      "[EPOCH #30, step #168] loss: 0.6066696955960178\n",
      "[EPOCH #30, step #170] loss: 0.608215943588848\n",
      "[EPOCH #30, step #172] loss: 0.6073184090887191\n",
      "[EPOCH #30, step #174] loss: 0.6066213779790061\n",
      "[EPOCH #30, step #176] loss: 0.6066543986905093\n",
      "[EPOCH #30, step #178] loss: 0.6055693967715322\n",
      "[EPOCH #30, step #180] loss: 0.6043935582782682\n",
      "[EPOCH #30, step #182] loss: 0.6052310580764312\n",
      "[EPOCH #30, step #184] loss: 0.6055655990097973\n",
      "[EPOCH #30, step #186] loss: 0.6075096855507814\n",
      "[EPOCH #30, step #188] loss: 0.6078130617028191\n",
      "[EPOCH #30, step #190] loss: 0.6067080065530008\n",
      "[EPOCH #30, step #192] loss: 0.6071354621741438\n",
      "[EPOCH #30, step #194] loss: 0.6060572650188055\n",
      "[EPOCH #30, step #196] loss: 0.6063436620731644\n",
      "[EPOCH #30, step #198] loss: 0.6059095317394889\n",
      "[EPOCH #30, step #200] loss: 0.6095940159327948\n",
      "[EPOCH #30, step #202] loss: 0.6107419635274728\n",
      "[EPOCH #30, step #204] loss: 0.6106879475640088\n",
      "[EPOCH #30, step #206] loss: 0.608177632957265\n",
      "[EPOCH #30, step #208] loss: 0.6080791006247963\n",
      "[EPOCH #30, step #210] loss: 0.6080965162453493\n",
      "[EPOCH #30, step #212] loss: 0.6110743301015504\n",
      "[EPOCH #30, step #214] loss: 0.6111391508302023\n",
      "[EPOCH #30, step #216] loss: 0.611735194234804\n",
      "[EPOCH #30, step #218] loss: 0.6130917118564588\n",
      "[EPOCH #30, step #220] loss: 0.6122213561610399\n",
      "[EPOCH #30, step #222] loss: 0.6116925747939824\n",
      "[EPOCH #30, step #224] loss: 0.6121080417103237\n",
      "[EPOCH #30, step #226] loss: 0.6139597979411154\n",
      "[EPOCH #30, step #228] loss: 0.615167479848237\n",
      "[EPOCH #30, step #230] loss: 0.6159139652272839\n",
      "[EPOCH #30, step #232] loss: 0.6145617368395236\n",
      "[EPOCH #30, step #234] loss: 0.6121917832405009\n",
      "[EPOCH #30, step #236] loss: 0.6101135502133188\n",
      "[EPOCH #30, step #238] loss: 0.6086932460633282\n",
      "[EPOCH #30, step #240] loss: 0.610893112000588\n",
      "[EPOCH #30, step #242] loss: 0.6101023521688249\n",
      "[EPOCH #30, step #244] loss: 0.6097941845047231\n",
      "[EPOCH #30, step #246] loss: 0.6098828529298064\n",
      "[EPOCH #30, step #248] loss: 0.6104176639313679\n",
      "[EPOCH #30, step #250] loss: 0.6113331554182972\n",
      "[EPOCH #30, step #252] loss: 0.6118091099818234\n",
      "[EPOCH #30, step #254] loss: 0.6106329557942409\n",
      "[EPOCH #30, step #256] loss: 0.6095152214343446\n",
      "[EPOCH #30, step #258] loss: 0.6091193029779265\n",
      "[EPOCH #30, step #260] loss: 0.6094919721742242\n",
      "[EPOCH #30, step #262] loss: 0.6098620334052315\n",
      "[EPOCH #30, step #264] loss: 0.6107223348797493\n",
      "[EPOCH #30, step #266] loss: 0.6136514124798864\n",
      "[EPOCH #30, step #268] loss: 0.6139014307894228\n",
      "[EPOCH #30, step #270] loss: 0.6162985759027769\n",
      "[EPOCH #30, step #272] loss: 0.6153125822980762\n",
      "[EPOCH #30, step #274] loss: 0.6156866802952506\n",
      "[EPOCH #30, step #276] loss: 0.6153550468627296\n",
      "[EPOCH #30, step #278] loss: 0.6143059375892831\n",
      "[EPOCH #30, step #280] loss: 0.6139378263432784\n",
      "[EPOCH #30, step #282] loss: 0.6129860530472476\n",
      "[EPOCH #30, step #284] loss: 0.6124688199737616\n",
      "[EPOCH #30, step #286] loss: 0.61322002180362\n",
      "[EPOCH #30, step #288] loss: 0.613251292478667\n",
      "[EPOCH #30, step #290] loss: 0.6140727405900398\n",
      "[EPOCH #30, step #292] loss: 0.612882999531645\n",
      "[EPOCH #30, step #294] loss: 0.6140928453308041\n",
      "[EPOCH #30, step #296] loss: 0.6130842277497957\n",
      "[EPOCH #30, step #298] loss: 0.6137347460590478\n",
      "[EPOCH #30, step #300] loss: 0.6136144760043122\n",
      "[EPOCH #30, step #302] loss: 0.6134697863764496\n",
      "[EPOCH #30, step #304] loss: 0.6150044644465212\n",
      "[EPOCH #30, step #306] loss: 0.6161929908715165\n",
      "[EPOCH #30, step #308] loss: 0.6166726047938695\n",
      "[EPOCH #30, step #310] loss: 0.616409886113317\n",
      "[EPOCH #30, step #312] loss: 0.616151792553667\n",
      "[EPOCH #30, step #314] loss: 0.6160767051908705\n",
      "[EPOCH #30, step #316] loss: 0.616184781778498\n",
      "[EPOCH #30, step #318] loss: 0.6170916465756288\n",
      "[EPOCH #30, step #320] loss: 0.6160508006161247\n",
      "[EPOCH #30, step #322] loss: 0.6152514887298962\n",
      "[EPOCH #30, step #324] loss: 0.6157908731240492\n",
      "[EPOCH #30, step #326] loss: 0.6142504106785543\n",
      "[EPOCH #30, step #328] loss: 0.6139857874996394\n",
      "[EPOCH #30, step #330] loss: 0.6153166392238478\n",
      "[EPOCH #30, step #332] loss: 0.6154431638058957\n",
      "[EPOCH #30, step #334] loss: 0.6153347798247836\n",
      "[EPOCH #30, step #336] loss: 0.6159888352060177\n",
      "[EPOCH #30, step #338] loss: 0.6161070119666491\n",
      "[EPOCH #30, step #340] loss: 0.6156390723594822\n",
      "[EPOCH #30, step #342] loss: 0.6159733407003887\n",
      "[EPOCH #30, step #344] loss: 0.6168684454931729\n",
      "[EPOCH #30, step #346] loss: 0.6165966687010069\n",
      "[EPOCH #30, step #348] loss: 0.6170427163897407\n",
      "[EPOCH #30, step #350] loss: 0.6176335470289247\n",
      "[EPOCH #30, step #352] loss: 0.6183444180502095\n",
      "[EPOCH #30, step #354] loss: 0.6174419498779404\n",
      "[EPOCH #30, step #356] loss: 0.6158464020874654\n",
      "[EPOCH #30, step #358] loss: 0.6169281227508959\n",
      "[EPOCH #30, step #360] loss: 0.6162281464011385\n",
      "[EPOCH #30, step #362] loss: 0.6160462932153181\n",
      "[EPOCH #30, step #364] loss: 0.616295606959356\n",
      "[EPOCH #30, step #366] loss: 0.6159795180003714\n",
      "[EPOCH #30, step #368] loss: 0.6175623487650863\n",
      "[EPOCH #30, step #370] loss: 0.6181165861954907\n",
      "[EPOCH #30, step #372] loss: 0.6179153491760386\n",
      "[EPOCH #30, step #374] loss: 0.6182695356210073\n",
      "[EPOCH #30, step #376] loss: 0.6182242692781696\n",
      "[EPOCH #30, step #378] loss: 0.6179667668795523\n",
      "[EPOCH #30, step #380] loss: 0.6184118502722011\n",
      "[EPOCH #30, step #382] loss: 0.6177756717092997\n",
      "[EPOCH #30, step #384] loss: 0.6180801845990218\n",
      "[EPOCH #30, step #386] loss: 0.6175240548544152\n",
      "[EPOCH #30, step #388] loss: 0.6187984463028552\n",
      "[EPOCH #30, step #390] loss: 0.6188183471827251\n",
      "[EPOCH #30, step #392] loss: 0.6191200875598966\n",
      "[EPOCH #30, step #394] loss: 0.6188431153569041\n",
      "[EPOCH #30, step #396] loss: 0.6171278100019738\n",
      "[EPOCH #30, step #398] loss: 0.6160968110376134\n",
      "[EPOCH #30, step #400] loss: 0.6166941993254379\n",
      "[EPOCH #30, step #402] loss: 0.6165744764337469\n",
      "[EPOCH #30, step #404] loss: 0.6163232098391027\n",
      "[EPOCH #30, step #406] loss: 0.6150679530470612\n",
      "[EPOCH #30, step #408] loss: 0.6148910239375308\n",
      "[EPOCH #30, step #410] loss: 0.615059844877598\n",
      "[EPOCH #30, step #412] loss: 0.6152469137318198\n",
      "[EPOCH #30, step #414] loss: 0.615420907771731\n",
      "[EPOCH #30, step #416] loss: 0.615521281707487\n",
      "[EPOCH #30, step #418] loss: 0.6153870841981688\n",
      "[EPOCH #30, step #420] loss: 0.6156823201516461\n",
      "[EPOCH #30, step #422] loss: 0.6164547716119892\n",
      "[EPOCH #30, step #424] loss: 0.6160819528733983\n",
      "[EPOCH #30, step #426] loss: 0.6175509033423676\n",
      "[EPOCH #30, step #428] loss: 0.6174574707979923\n",
      "[EPOCH #30, step #430] loss: 0.6186896631377479\n",
      "[EPOCH #30, step #432] loss: 0.6192410837764277\n",
      "[EPOCH #30, step #434] loss: 0.6194956755158545\n",
      "[EPOCH #30, step #436] loss: 0.619151671534272\n",
      "[EPOCH #30, step #438] loss: 0.6205086245420038\n",
      "[EPOCH #30, step #440] loss: 0.6205017983305211\n",
      "[EPOCH #30, step #442] loss: 0.6208330907146226\n",
      "[EPOCH #30, step #444] loss: 0.621000838982925\n",
      "[EPOCH #30, step #446] loss: 0.6212247366406507\n",
      "[EPOCH #30, step #448] loss: 0.6206093641923106\n",
      "[EPOCH #30, step #450] loss: 0.6207743066707895\n",
      "[EPOCH #30, step #452] loss: 0.6217095689070935\n",
      "[EPOCH #30, step #454] loss: 0.6209853020670649\n",
      "[EPOCH #30, step #456] loss: 0.6214880333231105\n",
      "[EPOCH #30, step #458] loss: 0.6218364924711859\n",
      "[EPOCH #30, step #460] loss: 0.622036417788642\n",
      "[EPOCH #30, step #462] loss: 0.6229797741056261\n",
      "[EPOCH #30, step #464] loss: 0.6225528969239164\n",
      "[EPOCH #30, step #466] loss: 0.6227653174316091\n",
      "[EPOCH #30, step #468] loss: 0.6232307762670111\n",
      "[EPOCH #30, step #470] loss: 0.6223620365189898\n",
      "[EPOCH #30, step #472] loss: 0.6218288475627879\n",
      "[EPOCH #30, step #474] loss: 0.6217920372674339\n",
      "[EPOCH #30, step #476] loss: 0.6219774766725564\n",
      "[EPOCH #30, step #478] loss: 0.6216910182496451\n",
      "[EPOCH #30, step #480] loss: 0.6215583824256353\n",
      "[EPOCH #30, step #482] loss: 0.6217214779515691\n",
      "[EPOCH #30, step #484] loss: 0.6217832295857754\n",
      "[EPOCH #30, step #486] loss: 0.6218360232560297\n",
      "[EPOCH #30, step #488] loss: 0.6220990665302686\n",
      "[EPOCH #30, step #490] loss: 0.6227102099695905\n",
      "[EPOCH #30, step #492] loss: 0.6227338755046137\n",
      "[EPOCH #30, step #494] loss: 0.6228915470718134\n",
      "[EPOCH #30, step #496] loss: 0.6221346766716038\n",
      "[EPOCH #30, step #498] loss: 0.6225428775042474\n",
      "[EPOCH #30, step #500] loss: 0.6235522171277962\n",
      "[EPOCH #30, step #502] loss: 0.6242526728459903\n",
      "[EPOCH #30, step #504] loss: 0.6250423742107826\n",
      "[EPOCH #30, step #506] loss: 0.6244280484359881\n",
      "[EPOCH #30, step #508] loss: 0.6250175289473037\n",
      "[EPOCH #30, step #510] loss: 0.6244108725025695\n",
      "[EPOCH #30, step #512] loss: 0.6247573187302428\n",
      "[EPOCH #30, step #514] loss: 0.6249704607771438\n",
      "[EPOCH #30, step #516] loss: 0.6246665293347213\n",
      "[EPOCH #30, step #518] loss: 0.623975816288665\n",
      "[EPOCH #30, step #520] loss: 0.6234283615153948\n",
      "[EPOCH #30, step #522] loss: 0.6232686632848834\n",
      "[EPOCH #30, step #524] loss: 0.6230729732910792\n",
      "[EPOCH #30, step #526] loss: 0.6234930405071609\n",
      "[EPOCH #30, step #528] loss: 0.622898734725716\n",
      "[EPOCH #30, step #530] loss: 0.6229764650489875\n",
      "[EPOCH #30, step #532] loss: 0.6238163145744778\n",
      "[EPOCH #30, step #534] loss: 0.623617985621791\n",
      "[EPOCH #30, step #536] loss: 0.6232449707316731\n",
      "[EPOCH #30, step #538] loss: 0.6227445519202716\n",
      "[EPOCH #30, step #540] loss: 0.6228874813551823\n",
      "[EPOCH #30, step #542] loss: 0.623584306015055\n",
      "[EPOCH #30, step #544] loss: 0.6231949394175765\n",
      "[EPOCH #30, step #546] loss: 0.6243415826036027\n",
      "[EPOCH #30, step #548] loss: 0.624702165388453\n",
      "[EPOCH #30, step #550] loss: 0.6245354628443934\n",
      "[EPOCH #30, step #552] loss: 0.6247083002846237\n",
      "[EPOCH #30, step #554] loss: 0.6239282321554046\n",
      "[EPOCH #30, step #556] loss: 0.6238453252578766\n",
      "[EPOCH #30, step #558] loss: 0.6235076743236382\n",
      "[EPOCH #30, step #560] loss: 0.62375393140656\n",
      "[EPOCH #30, step #562] loss: 0.6234818505086865\n",
      "[EPOCH #30, step #564] loss: 0.6233471286771571\n",
      "[EPOCH #30, step #566] loss: 0.622726548311992\n",
      "[EPOCH #30, step #568] loss: 0.6223044840386547\n",
      "[EPOCH #30, step #570] loss: 0.6222545774147932\n",
      "[EPOCH #30, step #572] loss: 0.6223450163948182\n",
      "[EPOCH #30, step #574] loss: 0.6217174133787985\n",
      "[EPOCH #30, step #576] loss: 0.6220529248592552\n",
      "[EPOCH #30, step #578] loss: 0.6219782405926979\n",
      "[EPOCH #30, step #580] loss: 0.621926230966737\n",
      "[EPOCH #30, step #582] loss: 0.6213680528500477\n",
      "[EPOCH #30, step #584] loss: 0.6205453306436539\n",
      "[EPOCH #30, step #586] loss: 0.6206171111770139\n",
      "[EPOCH #30, step #588] loss: 0.6207081919665652\n",
      "[EPOCH #30, step #590] loss: 0.6204835550887936\n",
      "[EPOCH #30, step #592] loss: 0.6206168256210034\n",
      "[EPOCH #30, step #594] loss: 0.6199464095991198\n",
      "[EPOCH #30, step #596] loss: 0.6199064429730826\n",
      "[EPOCH #30, step #598] loss: 0.62044650547592\n",
      "[EPOCH #30, step #600] loss: 0.6207560405209537\n",
      "[EPOCH #30, step #602] loss: 0.6212417007629354\n",
      "[EPOCH #30, step #604] loss: 0.6205503950680583\n",
      "[EPOCH #30, step #606] loss: 0.6203176395160559\n",
      "[EPOCH #30, step #608] loss: 0.619894104222163\n",
      "[EPOCH #30, step #610] loss: 0.6194097157049491\n",
      "[EPOCH #30, step #612] loss: 0.6193014511422271\n",
      "[EPOCH #30, step #614] loss: 0.6195946803664774\n",
      "[EPOCH #30, step #616] loss: 0.6193096854843235\n",
      "[EPOCH #30, step #618] loss: 0.6187488952582411\n",
      "[EPOCH #30, step #620] loss: 0.618304377472727\n",
      "[EPOCH #30, step #622] loss: 0.6178736942155021\n",
      "[EPOCH #30, step #624] loss: 0.6179162969589234\n",
      "[EPOCH #30, step #626] loss: 0.6182062266546003\n",
      "[EPOCH #30, step #628] loss: 0.6176652965655577\n",
      "[EPOCH #30, step #630] loss: 0.6181467091886064\n",
      "[EPOCH #30, step #632] loss: 0.6187200234117101\n",
      "[EPOCH #30, step #634] loss: 0.6187990939053963\n",
      "[EPOCH #30, step #636] loss: 0.619363569904534\n",
      "[EPOCH #30, step #638] loss: 0.6194003861928024\n",
      "[EPOCH #30, step #640] loss: 0.6199514852392134\n",
      "[EPOCH #30, step #642] loss: 0.6199868947591974\n",
      "[EPOCH #30, step #644] loss: 0.6195723310459492\n",
      "[EPOCH #30, step #646] loss: 0.6197497244503988\n",
      "[EPOCH #30, step #648] loss: 0.6196311816504263\n",
      "[EPOCH #30, step #650] loss: 0.6199278906102188\n",
      "[EPOCH #30, step #652] loss: 0.6198968175359378\n",
      "[EPOCH #30, step #654] loss: 0.619365642953465\n",
      "[EPOCH #30, step #656] loss: 0.6202121042679071\n",
      "[EPOCH #30, step #658] loss: 0.6203970597528362\n",
      "[EPOCH #30, step #660] loss: 0.6207060808493402\n",
      "[EPOCH #30, step #662] loss: 0.6205991553774787\n",
      "[EPOCH #30, step #664] loss: 0.6207286986193262\n",
      "[EPOCH #30, step #666] loss: 0.6200565696209446\n",
      "[EPOCH #30, step #668] loss: 0.6195380056474598\n",
      "[EPOCH #30, step #670] loss: 0.6193844502355942\n",
      "[EPOCH #30, step #672] loss: 0.6186629583364432\n",
      "[EPOCH #30, step #674] loss: 0.6200120857909873\n",
      "[EPOCH #30, step #676] loss: 0.6196295639700868\n",
      "[EPOCH #30, step #678] loss: 0.619471281371868\n",
      "[EPOCH #30, step #680] loss: 0.6195940853215525\n",
      "[EPOCH #30, step #682] loss: 0.620396453150893\n",
      "[EPOCH #30, step #684] loss: 0.621007669581114\n",
      "[EPOCH #30, step #686] loss: 0.6209630606563157\n",
      "[EPOCH #30, step #688] loss: 0.6207236329253076\n",
      "[EPOCH #30, step #690] loss: 0.6207707352645145\n",
      "[EPOCH #30, step #692] loss: 0.6210765121303079\n",
      "[EPOCH #30, step #694] loss: 0.6208996644122995\n",
      "[EPOCH #30, step #696] loss: 0.6205425471110186\n",
      "[EPOCH #30, step #698] loss: 0.6204564850217794\n",
      "[EPOCH #30, step #700] loss: 0.6199584401368075\n",
      "[EPOCH #30, step #702] loss: 0.6198041347063452\n",
      "[EPOCH #30, step #704] loss: 0.6197211324323154\n",
      "[EPOCH #30, step #706] loss: 0.6204826002663905\n",
      "[EPOCH #30, step #708] loss: 0.6205398085171144\n",
      "[EPOCH #30, step #710] loss: 0.6207855356812645\n",
      "[EPOCH #30, step #712] loss: 0.6218905955929241\n",
      "[EPOCH #30, step #714] loss: 0.6220769162361438\n",
      "[EPOCH #30, step #716] loss: 0.6221807787358511\n",
      "[EPOCH #30, step #718] loss: 0.6223041055016789\n",
      "[EPOCH #30, step #720] loss: 0.6223690000139228\n",
      "[EPOCH #30, step #722] loss: 0.6222273720580348\n",
      "[EPOCH #30, step #724] loss: 0.6224239055863742\n",
      "[EPOCH #30, step #726] loss: 0.6220111507087167\n",
      "[EPOCH #30, step #728] loss: 0.6221697325977933\n",
      "[EPOCH #30, step #730] loss: 0.6220486430316226\n",
      "[EPOCH #30, step #732] loss: 0.6229295765963291\n",
      "[EPOCH #30, step #734] loss: 0.6230929461871686\n",
      "[EPOCH #30, step #736] loss: 0.6234006180125952\n",
      "[EPOCH #30, step #738] loss: 0.6234528969605334\n",
      "[EPOCH #30, step #740] loss: 0.6231294559885455\n",
      "[EPOCH #30, step #742] loss: 0.6229306941558663\n",
      "[EPOCH #30, step #744] loss: 0.6224786618811973\n",
      "[EPOCH #30, step #746] loss: 0.6229518541450322\n",
      "[EPOCH #30, step #748] loss: 0.6229071114585301\n",
      "[EPOCH #30, step #750] loss: 0.622354364545939\n",
      "[EPOCH #30, step #752] loss: 0.6219351184004015\n",
      "[EPOCH #30, step #754] loss: 0.6221305871641399\n",
      "[EPOCH #30, step #756] loss: 0.6220374114053567\n",
      "[EPOCH #30, step #758] loss: 0.6222667993685631\n",
      "[EPOCH #30, step #760] loss: 0.6223877230157363\n",
      "[EPOCH #30, step #762] loss: 0.6225596178484151\n",
      "[EPOCH #30, step #764] loss: 0.6231637121415605\n",
      "[EPOCH #30, step #766] loss: 0.6235958320298748\n",
      "[EPOCH #30, step #768] loss: 0.6236673146680055\n",
      "[EPOCH #30, step #770] loss: 0.623131264083271\n",
      "[EPOCH #30, step #772] loss: 0.6228275110542697\n",
      "[EPOCH #30, step #774] loss: 0.6227560173696087\n",
      "[EPOCH #30, step #776] loss: 0.6225242419515951\n",
      "[EPOCH #30, step #778] loss: 0.6225324029028798\n",
      "[EPOCH #30, step #780] loss: 0.6218777675176858\n",
      "[EPOCH #30, step #782] loss: 0.6217606169282248\n",
      "[EPOCH #30, step #784] loss: 0.6217505040062461\n",
      "[EPOCH #30, step #786] loss: 0.6215123514132397\n",
      "[EPOCH #30, step #788] loss: 0.6215195038246111\n",
      "[EPOCH #30, step #790] loss: 0.6214932759401922\n",
      "[EPOCH #30, step #792] loss: 0.6214030462811604\n",
      "[EPOCH #30, step #794] loss: 0.6210161892123193\n",
      "[EPOCH #30, step #796] loss: 0.621000017096736\n",
      "[EPOCH #30, step #798] loss: 0.6211177226300532\n",
      "[EPOCH #30, step #800] loss: 0.6213496134671082\n",
      "[EPOCH #30, step #802] loss: 0.6212986435272625\n",
      "[EPOCH #30, step #804] loss: 0.6206673708021271\n",
      "[EPOCH #30, step #806] loss: 0.6204741268500668\n",
      "[EPOCH #30, step #808] loss: 0.6203491246449785\n",
      "[EPOCH #30, step #810] loss: 0.6204119434927012\n",
      "[EPOCH #30, step #812] loss: 0.6210191570964686\n",
      "[EPOCH #30, step #814] loss: 0.6205057265202691\n",
      "[EPOCH #30, step #816] loss: 0.6205452222062441\n",
      "[EPOCH #30, step #818] loss: 0.6200410110173208\n",
      "[EPOCH #30, step #820] loss: 0.6201115491256645\n",
      "[EPOCH #30, step #822] loss: 0.6202369570949388\n",
      "[EPOCH #30, step #824] loss: 0.6203695045456742\n",
      "[EPOCH #30, step #826] loss: 0.6209314112003077\n",
      "[EPOCH #30, step #828] loss: 0.6213399745227345\n",
      "[EPOCH #30, step #830] loss: 0.6211176549771489\n",
      "[EPOCH #30, step #832] loss: 0.621017158532343\n",
      "[EPOCH #30, step #834] loss: 0.620839940145344\n",
      "[EPOCH #30, step #836] loss: 0.6205457559694384\n",
      "[EPOCH #30, step #838] loss: 0.6205725949413018\n",
      "[EPOCH #30, step #840] loss: 0.6203443829355568\n",
      "[EPOCH #30, step #842] loss: 0.6205195155644332\n",
      "[EPOCH #30, step #844] loss: 0.6204696654215367\n",
      "[EPOCH #30, step #846] loss: 0.6204278848739836\n",
      "[EPOCH #30, step #848] loss: 0.6210047701292521\n",
      "[EPOCH #30, step #850] loss: 0.6211836178000189\n",
      "[EPOCH #30, step #852] loss: 0.621265079428694\n",
      "[EPOCH #30, step #854] loss: 0.6209883138101701\n",
      "[EPOCH #30, step #856] loss: 0.6209691462814461\n",
      "[EPOCH #30, step #858] loss: 0.620886417116636\n",
      "[EPOCH #30, step #860] loss: 0.621041076350849\n",
      "[EPOCH #30, step #862] loss: 0.6210145322845543\n",
      "[EPOCH #30, step #864] loss: 0.6211208099919248\n",
      "[EPOCH #30, step #866] loss: 0.6212061976685244\n",
      "[EPOCH #30, step #868] loss: 0.6210093528923972\n",
      "[EPOCH #30, step #870] loss: 0.6209779944095491\n",
      "[EPOCH #30, step #872] loss: 0.621152429082959\n",
      "[EPOCH #30, step #874] loss: 0.621178275670324\n",
      "[EPOCH #30, step #876] loss: 0.6208559497086461\n",
      "[EPOCH #30, step #878] loss: 0.6216242250491599\n",
      "[EPOCH #30, step #880] loss: 0.6219676491655367\n",
      "[EPOCH #30, step #882] loss: 0.621944356224545\n",
      "[EPOCH #30, step #884] loss: 0.6218703210522226\n",
      "[EPOCH #30, step #886] loss: 0.6219736203769686\n",
      "[EPOCH #30, step #888] loss: 0.6219368558733214\n",
      "[EPOCH #30, step #890] loss: 0.6218968081788717\n",
      "[EPOCH #30, step #892] loss: 0.6214395155264576\n",
      "[EPOCH #30, step #894] loss: 0.6210695432717573\n",
      "[EPOCH #30, step #896] loss: 0.6209040060057953\n",
      "[EPOCH #30, step #898] loss: 0.6210981864519459\n",
      "[EPOCH #30, step #900] loss: 0.6210194516360561\n",
      "[EPOCH #30, step #902] loss: 0.6209056251171815\n",
      "[EPOCH #30, step #904] loss: 0.6207078271313925\n",
      "[EPOCH #30, step #906] loss: 0.6209016403033426\n",
      "[EPOCH #30, step #908] loss: 0.621042973416211\n",
      "[EPOCH #30, step #910] loss: 0.6215223150019065\n",
      "[EPOCH #30, step #912] loss: 0.6221884536880261\n",
      "[EPOCH #30, step #914] loss: 0.6220148707510995\n",
      "[EPOCH #30, step #916] loss: 0.6223085253065779\n",
      "[EPOCH #30, step #918] loss: 0.6223934254040526\n",
      "[EPOCH #30, step #920] loss: 0.6225649995504839\n",
      "[EPOCH #30, step #922] loss: 0.6224968697016056\n",
      "[EPOCH #30, step #924] loss: 0.6219090736717792\n",
      "[EPOCH #30, step #926] loss: 0.6217262615502974\n",
      "[EPOCH #30, step #928] loss: 0.6212988815183147\n",
      "[EPOCH #30, step #930] loss: 0.6212633182199634\n",
      "[EPOCH #30, step #932] loss: 0.6211136518663148\n",
      "[EPOCH #30, step #934] loss: 0.6216339648566781\n",
      "[EPOCH #30, step #936] loss: 0.6219205661510836\n",
      "[EPOCH #30, step #938] loss: 0.6217620451959431\n",
      "[EPOCH #30, step #940] loss: 0.6213274281254231\n",
      "[EPOCH #30, step #942] loss: 0.6212588841152848\n",
      "[EPOCH #30, step #944] loss: 0.6215381190732673\n",
      "[EPOCH #30, step #946] loss: 0.6217138856775279\n",
      "[EPOCH #30, step #948] loss: 0.621503472752139\n",
      "[EPOCH #30, step #950] loss: 0.62156025955667\n",
      "[EPOCH #30, step #952] loss: 0.6218578851579494\n",
      "[EPOCH #30, step #954] loss: 0.621704840145186\n",
      "[EPOCH #30, step #956] loss: 0.6213149275930449\n",
      "[EPOCH #30, step #958] loss: 0.6213803748300103\n",
      "[EPOCH #30, step #960] loss: 0.6211406358291902\n",
      "[EPOCH #30, step #962] loss: 0.6210481274567413\n",
      "[EPOCH #30, step #964] loss: 0.6209384076490303\n",
      "[EPOCH #30, step #966] loss: 0.6210175910280804\n",
      "[EPOCH #30, step #968] loss: 0.6210720040696078\n",
      "[EPOCH #30, step #970] loss: 0.6209271725585606\n",
      "[EPOCH #30, step #972] loss: 0.6206601585384998\n",
      "[EPOCH #30, step #974] loss: 0.6207671833496827\n",
      "[EPOCH #30, step #976] loss: 0.6210718349369668\n",
      "[EPOCH #30, step #978] loss: 0.6209781491202402\n",
      "[EPOCH #30, step #980] loss: 0.6210575985221931\n",
      "[EPOCH #30, step #982] loss: 0.6212455713827758\n",
      "[EPOCH #30, step #984] loss: 0.6212782757687689\n",
      "[EPOCH #30, step #986] loss: 0.6206500800335902\n",
      "[EPOCH #30, step #988] loss: 0.620866448576096\n",
      "[EPOCH #30, step #990] loss: 0.6206944755811383\n",
      "[EPOCH #30, step #992] loss: 0.620726045900121\n",
      "[EPOCH #30, step #994] loss: 0.6208158460843504\n",
      "[EPOCH #30, step #996] loss: 0.6208694937864062\n",
      "[EPOCH #30, step #998] loss: 0.6208365831199709\n",
      "[EPOCH #30, step #1000] loss: 0.6206844560839199\n",
      "[EPOCH #30, step #1002] loss: 0.6205415960293587\n",
      "[EPOCH #30, step #1004] loss: 0.6208589858528394\n",
      "[EPOCH #30, step #1006] loss: 0.6207908531493677\n",
      "[EPOCH #30, step #1008] loss: 0.6209286972215793\n",
      "[EPOCH #30, step #1010] loss: 0.6208367170111951\n",
      "[EPOCH #30, step #1012] loss: 0.6208213870317068\n",
      "[EPOCH #30, step #1014] loss: 0.6206239942406199\n",
      "[EPOCH #30, step #1016] loss: 0.6211806626710217\n",
      "[EPOCH #30, step #1018] loss: 0.6210039294122831\n",
      "[EPOCH #30, step #1020] loss: 0.6212842182915778\n",
      "[EPOCH #30, step #1022] loss: 0.6210452415639005\n",
      "[EPOCH #30, step #1024] loss: 0.6209794498798323\n",
      "[EPOCH #30, step #1026] loss: 0.621206617126098\n",
      "[EPOCH #30, step #1028] loss: 0.6217869970408079\n",
      "[EPOCH #30, step #1030] loss: 0.6218475322632045\n",
      "[EPOCH #30, step #1032] loss: 0.6216960732986482\n",
      "[EPOCH #30, step #1034] loss: 0.6214802040713997\n",
      "[EPOCH #30, step #1036] loss: 0.6214058109080435\n",
      "[EPOCH #30, step #1038] loss: 0.6213816841625043\n",
      "[EPOCH #30, step #1040] loss: 0.621329487529543\n",
      "[EPOCH #30, step #1042] loss: 0.6210719352000512\n",
      "[EPOCH #30, step #1044] loss: 0.6212005272864155\n",
      "[EPOCH #30, step #1046] loss: 0.6216594073441104\n",
      "[EPOCH #30, step #1048] loss: 0.6212537340514426\n",
      "[EPOCH #30, step #1050] loss: 0.6214218077973793\n",
      "[EPOCH #30, step #1052] loss: 0.6210260301941594\n",
      "[EPOCH #30, step #1054] loss: 0.6207470312361468\n",
      "[EPOCH #30, step #1056] loss: 0.6203665211021393\n",
      "[EPOCH #30, step #1058] loss: 0.6202449401641815\n",
      "[EPOCH #30, step #1060] loss: 0.6199929325312067\n",
      "[EPOCH #30, step #1062] loss: 0.6198088201367395\n",
      "[EPOCH #30, step #1064] loss: 0.6197688010237027\n",
      "[EPOCH #30, step #1066] loss: 0.6194891756035618\n",
      "[EPOCH #30, step #1068] loss: 0.6196743720067339\n",
      "[EPOCH #30, step #1070] loss: 0.6195600819326137\n",
      "[EPOCH #30, step #1072] loss: 0.6196443708084058\n",
      "[EPOCH #30, step #1074] loss: 0.6195230352739955\n",
      "[EPOCH #30, step #1076] loss: 0.6198056673522115\n",
      "[EPOCH #30, step #1078] loss: 0.619696116301061\n",
      "[EPOCH #30, step #1080] loss: 0.6202268863336341\n",
      "[EPOCH #30, step #1082] loss: 0.6204223732291166\n",
      "[EPOCH #30, step #1084] loss: 0.6204343697579775\n",
      "[EPOCH #30, step #1086] loss: 0.6203363102542883\n",
      "[EPOCH #30, step #1088] loss: 0.6205517456031262\n",
      "[EPOCH #30, step #1090] loss: 0.6204276835694431\n",
      "[EPOCH #30, step #1092] loss: 0.6200806801049729\n",
      "[EPOCH #30, step #1094] loss: 0.6196452896752859\n",
      "[EPOCH #30, step #1096] loss: 0.6194938757442406\n",
      "[EPOCH #30, step #1098] loss: 0.6197028021659495\n",
      "[EPOCH #30, step #1100] loss: 0.6196479843514925\n",
      "[EPOCH #30, step #1102] loss: 0.619487638283835\n",
      "[EPOCH #30, step #1104] loss: 0.6196041498114081\n",
      "[EPOCH #30, step #1106] loss: 0.6195865015161931\n",
      "[EPOCH #30, step #1108] loss: 0.6192727288998818\n",
      "[EPOCH #30, step #1110] loss: 0.6194545323118018\n",
      "[EPOCH #30, step #1112] loss: 0.619638842914625\n",
      "[EPOCH #30, step #1114] loss: 0.6197171927968482\n",
      "[EPOCH #30, step #1116] loss: 0.6196081941828946\n",
      "[EPOCH #30, step #1118] loss: 0.6196761243544698\n",
      "[EPOCH #30, step #1120] loss: 0.6196171162146527\n",
      "[EPOCH #30, step #1122] loss: 0.6197488060484798\n",
      "[EPOCH #30, step #1124] loss: 0.6196244898504681\n",
      "[EPOCH #30, step #1126] loss: 0.6197587917125003\n",
      "[EPOCH #30, step #1128] loss: 0.6196522211822606\n",
      "[EPOCH #30, step #1130] loss: 0.6198081059149153\n",
      "[EPOCH #30, step #1132] loss: 0.6199102401864918\n",
      "[EPOCH #30, step #1134] loss: 0.6202093859207263\n",
      "[EPOCH #30, step #1136] loss: 0.6202374770778675\n",
      "[EPOCH #30, step #1138] loss: 0.6201444762359072\n",
      "[EPOCH #30, step #1140] loss: 0.6203613315335916\n",
      "[EPOCH #30, step #1142] loss: 0.6202558547727705\n",
      "[EPOCH #30, step #1144] loss: 0.6203193342451445\n",
      "[EPOCH #30, step #1146] loss: 0.620049656437809\n",
      "[EPOCH #30, step #1148] loss: 0.6199482789472252\n",
      "[EPOCH #30, step #1150] loss: 0.6202201205398806\n",
      "[EPOCH #30, step #1152] loss: 0.6203193843545649\n",
      "[EPOCH #30, step #1154] loss: 0.6204822423267158\n",
      "[EPOCH #30, step #1156] loss: 0.6203121848552517\n",
      "[EPOCH #30, step #1158] loss: 0.6204986288513573\n",
      "[EPOCH #30, step #1160] loss: 0.6205310900723698\n",
      "[EPOCH #30, step #1162] loss: 0.6211670326166694\n",
      "[EPOCH #30, step #1164] loss: 0.6212426881549696\n",
      "[EPOCH #30, step #1166] loss: 0.6211117803412006\n",
      "[EPOCH #30, step #1168] loss: 0.6210936231043116\n",
      "[EPOCH #30, step #1170] loss: 0.6210487744143435\n",
      "[EPOCH #30, step #1172] loss: 0.6214408734900669\n",
      "[EPOCH #30, step #1174] loss: 0.6211506019627794\n",
      "[EPOCH #30, step #1176] loss: 0.6210477691058294\n",
      "[EPOCH #30, step #1178] loss: 0.6213775726194802\n",
      "[EPOCH #30, step #1180] loss: 0.6211623476406561\n",
      "[EPOCH #30, step #1182] loss: 0.6211799677533814\n",
      "[EPOCH #30, step #1184] loss: 0.6211400983580054\n",
      "[EPOCH #30, step #1186] loss: 0.6210285953317456\n",
      "[EPOCH #30, step #1188] loss: 0.6212431263958736\n",
      "[EPOCH #30, step #1190] loss: 0.6211646389275615\n",
      "[EPOCH #30, step #1192] loss: 0.6210358352318394\n",
      "[EPOCH #30, step #1194] loss: 0.6209704694014713\n",
      "[EPOCH #30, step #1196] loss: 0.6209515385086972\n",
      "[EPOCH #30, step #1198] loss: 0.6211896994717425\n",
      "[EPOCH #30, step #1200] loss: 0.621150507580033\n",
      "[EPOCH #30, step #1202] loss: 0.6213037310321432\n",
      "[EPOCH #30, step #1204] loss: 0.6213405911976866\n",
      "[EPOCH #30, step #1206] loss: 0.6210804261767183\n",
      "[EPOCH #30, step #1208] loss: 0.6215503692158596\n",
      "[EPOCH #30, step #1210] loss: 0.6216716378385818\n",
      "[EPOCH #30, step #1212] loss: 0.6211088751208557\n",
      "[EPOCH #30, step #1214] loss: 0.6212911670958554\n",
      "[EPOCH #30, step #1216] loss: 0.6211467199303032\n",
      "[EPOCH #30, step #1218] loss: 0.6209552617494546\n",
      "[EPOCH #30, step #1220] loss: 0.6208333850614757\n",
      "[EPOCH #30, step #1222] loss: 0.6208789799536044\n",
      "[EPOCH #30, step #1224] loss: 0.6207507224107275\n",
      "[EPOCH #30, step #1226] loss: 0.6204545495101078\n",
      "[EPOCH #30, step #1228] loss: 0.6203187861342659\n",
      "[EPOCH #30, step #1230] loss: 0.6205365259433354\n",
      "[EPOCH #30, step #1232] loss: 0.6204752420881176\n",
      "[EPOCH #30, step #1234] loss: 0.6203483580698369\n",
      "[EPOCH #30, step #1236] loss: 0.6201218814380534\n",
      "[EPOCH #30, step #1238] loss: 0.6198052328449762\n",
      "[EPOCH #30, step #1240] loss: 0.6201919527975039\n",
      "[EPOCH #30, step #1242] loss: 0.6201985086031911\n",
      "[EPOCH #30, step #1244] loss: 0.6199015516473586\n",
      "[EPOCH #30, step #1246] loss: 0.6197851431326763\n",
      "[EPOCH #30, step #1248] loss: 0.6198879224691894\n",
      "[EPOCH #30, step #1250] loss: 0.6198553045948061\n",
      "[EPOCH #30, step #1252] loss: 0.6194792739862646\n",
      "[EPOCH #30, step #1254] loss: 0.6191480801993632\n",
      "[EPOCH #30, step #1256] loss: 0.6190679065865378\n",
      "[EPOCH #30, step #1258] loss: 0.6188001973914001\n",
      "[EPOCH #30, step #1260] loss: 0.6189912410481028\n",
      "[EPOCH #30, step #1262] loss: 0.618976945206464\n",
      "[EPOCH #30, step #1264] loss: 0.6188124487404767\n",
      "[EPOCH #30, step #1266] loss: 0.6190124414126141\n",
      "[EPOCH #30, step #1268] loss: 0.6188878131556267\n",
      "[EPOCH #30, step #1270] loss: 0.6187821209876205\n",
      "[EPOCH #30, step #1272] loss: 0.6186525482341987\n",
      "[EPOCH #30, step #1274] loss: 0.6183115353654413\n",
      "[EPOCH #30, step #1276] loss: 0.6183281474474733\n",
      "[EPOCH #30, step #1278] loss: 0.6178359989662298\n",
      "[EPOCH #30, step #1280] loss: 0.6173732124856447\n",
      "[EPOCH #30, step #1282] loss: 0.6172033879595257\n",
      "[EPOCH #30, step #1284] loss: 0.6170403466846228\n",
      "[EPOCH #30, step #1286] loss: 0.6173283566822817\n",
      "[EPOCH #30, step #1288] loss: 0.6172161433611664\n",
      "[EPOCH #30, step #1290] loss: 0.6170172700117393\n",
      "[EPOCH #30, step #1292] loss: 0.6173483131472122\n",
      "[EPOCH #30, step #1294] loss: 0.6172213302385853\n",
      "[EPOCH #30, step #1296] loss: 0.6171618952554468\n",
      "[EPOCH #30, step #1298] loss: 0.6171858372414819\n",
      "[EPOCH #30, step #1300] loss: 0.6171658474559696\n",
      "[EPOCH #30, step #1302] loss: 0.6172351423402246\n",
      "[EPOCH #30, step #1304] loss: 0.617231468930555\n",
      "[EPOCH #30, step #1306] loss: 0.6171232754480045\n",
      "[EPOCH #30, step #1308] loss: 0.617075428400812\n",
      "[EPOCH #30, step #1310] loss: 0.6168773187016096\n",
      "[EPOCH #30, step #1312] loss: 0.6166341523132702\n",
      "[EPOCH #30, step #1314] loss: 0.6166661751134314\n",
      "[EPOCH #30, step #1316] loss: 0.6167088359164395\n",
      "[EPOCH #30, step #1318] loss: 0.6164416203768168\n",
      "[EPOCH #30, step #1320] loss: 0.6162518320843453\n",
      "[EPOCH #30, step #1322] loss: 0.6164856286140796\n",
      "[EPOCH #30, step #1324] loss: 0.6169672159203943\n",
      "[EPOCH #30, step #1326] loss: 0.616868855612747\n",
      "[EPOCH #30, step #1328] loss: 0.6165958356260804\n",
      "[EPOCH #30, step #1330] loss: 0.6168158123203904\n",
      "[EPOCH #30, step #1332] loss: 0.6168133784909938\n",
      "[EPOCH #30, step #1334] loss: 0.6163974396633298\n",
      "[EPOCH #30, step #1336] loss: 0.6160755957140348\n",
      "[EPOCH #30, step #1338] loss: 0.6159074611522263\n",
      "[EPOCH #30, step #1340] loss: 0.6158674528779244\n",
      "[EPOCH #30, step #1342] loss: 0.616153376378058\n",
      "[EPOCH #30, step #1344] loss: 0.6162436893549107\n",
      "[EPOCH #30, step #1346] loss: 0.6163829382185415\n",
      "[EPOCH #30, step #1348] loss: 0.616383296138627\n",
      "[EPOCH #30, step #1350] loss: 0.6163000050052548\n",
      "[EPOCH #30, step #1352] loss: 0.6163048193420381\n",
      "[EPOCH #30, step #1354] loss: 0.6164022630541087\n",
      "[EPOCH #30, step #1356] loss: 0.6165218390277316\n",
      "[EPOCH #30, step #1358] loss: 0.6162571811320766\n",
      "[EPOCH #30, step #1360] loss: 0.6162604892258255\n",
      "[EPOCH #30, step #1362] loss: 0.6162823078195925\n",
      "[EPOCH #30, step #1364] loss: 0.616105191993626\n",
      "[EPOCH #30, step #1366] loss: 0.615860062255507\n",
      "[EPOCH #30, step #1368] loss: 0.6160626713488553\n",
      "[EPOCH #30, step #1370] loss: 0.6157929142468346\n",
      "[EPOCH #30, step #1372] loss: 0.615750375394394\n",
      "[EPOCH #30, step #1374] loss: 0.6159070539366115\n",
      "[EPOCH #30, step #1376] loss: 0.6160388694847504\n",
      "[EPOCH #30, step #1378] loss: 0.6160691140936803\n",
      "[EPOCH #30, step #1380] loss: 0.6163108502389899\n",
      "[EPOCH #30, step #1382] loss: 0.6162365191735311\n",
      "[EPOCH #30, step #1384] loss: 0.6163080294962825\n",
      "[EPOCH #30, step #1386] loss: 0.6161080012561266\n",
      "[EPOCH #30, step #1388] loss: 0.6160774270972389\n",
      "[EPOCH #30, step #1390] loss: 0.6159597913688417\n",
      "[EPOCH #30, step #1392] loss: 0.6155621589877498\n",
      "[EPOCH #30, step #1394] loss: 0.6153036084119564\n",
      "[EPOCH #30, step #1396] loss: 0.6153263687426138\n",
      "[EPOCH #30, step #1398] loss: 0.6154379368020092\n",
      "[EPOCH #30, step #1400] loss: 0.6153611805526636\n",
      "[EPOCH #30, step #1402] loss: 0.6154540412377564\n",
      "[EPOCH #30, step #1404] loss: 0.6158376266205438\n",
      "[EPOCH #30, step #1406] loss: 0.6157842640577688\n",
      "[EPOCH #30, step #1408] loss: 0.6156543770671483\n",
      "[EPOCH #30, step #1410] loss: 0.6161180711295231\n",
      "[EPOCH #30, step #1412] loss: 0.6160060159614216\n",
      "[EPOCH #30, step #1414] loss: 0.6158430488181198\n",
      "[EPOCH #30, step #1416] loss: 0.6155699202626544\n",
      "[EPOCH #30, step #1418] loss: 0.615528334512351\n",
      "[EPOCH #30, step #1420] loss: 0.6158736906342738\n",
      "[EPOCH #30, step #1422] loss: 0.6157273175908241\n",
      "[EPOCH #30, step #1424] loss: 0.615414395677416\n",
      "[EPOCH #30, step #1426] loss: 0.6153387823302009\n",
      "[EPOCH #30, step #1428] loss: 0.6155743472554451\n",
      "[EPOCH #30, step #1430] loss: 0.6158534648699997\n",
      "[EPOCH #30, step #1432] loss: 0.6155645639868941\n",
      "[EPOCH #30, step #1434] loss: 0.6155103425219499\n",
      "[EPOCH #30, step #1436] loss: 0.6154208524553163\n",
      "[EPOCH #30, step #1438] loss: 0.6157971085712594\n",
      "[EPOCH #30, step #1440] loss: 0.6158007507126502\n",
      "[EPOCH #30, step #1442] loss: 0.6157218452571418\n",
      "[EPOCH #30, step #1444] loss: 0.615817072595692\n",
      "[EPOCH #30, step #1446] loss: 0.6158471012226696\n",
      "[EPOCH #30, step #1448] loss: 0.6160394485919043\n",
      "[EPOCH #30, step #1450] loss: 0.6159858182637467\n",
      "[EPOCH #30, step #1452] loss: 0.6164189538849852\n",
      "[EPOCH #30, step #1454] loss: 0.6164399868331824\n",
      "[EPOCH #30, step #1456] loss: 0.6163796348345141\n",
      "[EPOCH #30, step #1458] loss: 0.6162246218011181\n",
      "[EPOCH #30, step #1460] loss: 0.6163803836219854\n",
      "[EPOCH #30, step #1462] loss: 0.6163913299083221\n",
      "[EPOCH #30, step #1464] loss: 0.6161890891936859\n",
      "[EPOCH #30, step #1466] loss: 0.6162787875657026\n",
      "[EPOCH #30, step #1468] loss: 0.6160160459430953\n",
      "[EPOCH #30, step #1470] loss: 0.6162634077098886\n",
      "[EPOCH #30, step #1472] loss: 0.6163221367123333\n",
      "[EPOCH #30, step #1474] loss: 0.6164513262954809\n",
      "[EPOCH #30, step #1476] loss: 0.6163242862546613\n",
      "[EPOCH #30, step #1478] loss: 0.6164715925308399\n",
      "[EPOCH #30, step #1480] loss: 0.6164676004028417\n",
      "[EPOCH #30, step #1482] loss: 0.6167690930278897\n",
      "[EPOCH #30, step #1484] loss: 0.6169396300809552\n",
      "[EPOCH #30, step #1486] loss: 0.6169849784585077\n",
      "[EPOCH #30, step #1488] loss: 0.617070728666515\n",
      "[EPOCH #30, step #1490] loss: 0.6171554304724328\n",
      "[EPOCH #30, step #1492] loss: 0.6171119176075911\n",
      "[EPOCH #30, step #1494] loss: 0.6169229733405703\n",
      "[EPOCH #30, step #1496] loss: 0.6169992083199596\n",
      "[EPOCH #30, step #1498] loss: 0.6170135748294928\n",
      "[EPOCH #30, step #1500] loss: 0.6173124529674481\n",
      "[EPOCH #30, step #1502] loss: 0.6172160980646719\n",
      "[EPOCH #30, step #1504] loss: 0.6170081586635786\n",
      "[EPOCH #30, step #1506] loss: 0.6168820046892052\n",
      "[EPOCH #30, step #1508] loss: 0.6172320679709009\n",
      "[EPOCH #30, step #1510] loss: 0.6173232417580783\n",
      "[EPOCH #30, step #1512] loss: 0.6174031381506992\n",
      "[EPOCH #30, step #1514] loss: 0.6173882106841594\n",
      "[EPOCH #30, step #1516] loss: 0.6174940621393169\n",
      "[EPOCH #30, step #1518] loss: 0.6173746128608868\n",
      "[EPOCH #30, step #1520] loss: 0.6172593018183341\n",
      "[EPOCH #30, step #1522] loss: 0.6173223464193895\n",
      "[EPOCH #30, step #1524] loss: 0.6176729272721244\n",
      "[EPOCH #30, step #1526] loss: 0.6178138477882686\n",
      "[EPOCH #30, step #1528] loss: 0.6176220234446934\n",
      "[EPOCH #30, step #1530] loss: 0.6175076688507817\n",
      "[EPOCH #30, step #1532] loss: 0.6172492403903975\n",
      "[EPOCH #30, step #1534] loss: 0.6171167353368349\n",
      "[EPOCH #30, step #1536] loss: 0.6172497069963636\n",
      "[EPOCH #30, step #1538] loss: 0.6172644463721771\n",
      "[EPOCH #30, step #1540] loss: 0.6169537867163777\n",
      "[EPOCH #30, step #1542] loss: 0.6168487954761638\n",
      "[EPOCH #30, step #1544] loss: 0.6169218542217051\n",
      "[EPOCH #30, step #1546] loss: 0.6170084776324307\n",
      "[EPOCH #30, step #1548] loss: 0.6169238209705187\n",
      "[EPOCH #30, step #1550] loss: 0.6167785291764754\n",
      "[EPOCH #30, step #1552] loss: 0.6166877696975461\n",
      "[EPOCH #30, step #1554] loss: 0.6166022416383891\n",
      "[EPOCH #30, step #1556] loss: 0.6168370054617247\n",
      "[EPOCH #30, step #1558] loss: 0.6168074724171848\n",
      "[EPOCH #30, step #1560] loss: 0.6165312517823355\n",
      "[EPOCH #30, step #1562] loss: 0.6161570202270839\n",
      "[EPOCH #30, step #1564] loss: 0.616209686592745\n",
      "[EPOCH #30, step #1566] loss: 0.6162359417911236\n",
      "[EPOCH #30, step #1568] loss: 0.6160401709619945\n",
      "[EPOCH #30, step #1570] loss: 0.6161556822205713\n",
      "[EPOCH #30, step #1572] loss: 0.6159780060248397\n",
      "[EPOCH #30, step #1574] loss: 0.6157871366020233\n",
      "[EPOCH #30, step #1576] loss: 0.6156423901200068\n",
      "[EPOCH #30, step #1578] loss: 0.6156316804708447\n",
      "[EPOCH #30, step #1580] loss: 0.6155587832981239\n",
      "[EPOCH #30, step #1582] loss: 0.6153357218261467\n",
      "[EPOCH #30, step #1584] loss: 0.615159377756555\n",
      "[EPOCH #30, step #1586] loss: 0.6154443048781093\n",
      "[EPOCH #30, step #1588] loss: 0.6155092248738825\n",
      "[EPOCH #30, step #1590] loss: 0.6153580250510025\n",
      "[EPOCH #30, step #1592] loss: 0.6154616978452105\n",
      "[EPOCH #30, step #1594] loss: 0.6154723281116695\n",
      "[EPOCH #30, step #1596] loss: 0.6154447898184723\n",
      "[EPOCH #30, step #1598] loss: 0.6158094934052121\n",
      "[EPOCH #30, step #1600] loss: 0.6154207540053565\n",
      "[EPOCH #30, step #1602] loss: 0.6156322873259662\n",
      "[EPOCH #30, step #1604] loss: 0.6156043024170808\n",
      "[EPOCH #30, step #1606] loss: 0.6152648828789249\n",
      "[EPOCH #30, step #1608] loss: 0.6153121133299627\n",
      "[EPOCH #30, step #1610] loss: 0.6151995858666617\n",
      "[EPOCH #30, step #1612] loss: 0.6149133718575444\n",
      "[EPOCH #30, step #1614] loss: 0.6151105505578658\n",
      "[EPOCH #30, step #1616] loss: 0.6150930067898686\n",
      "[EPOCH #30, step #1618] loss: 0.6150332002672169\n",
      "[EPOCH #30, step #1620] loss: 0.6154161332419887\n",
      "[EPOCH #30, step #1622] loss: 0.6151866023546373\n",
      "[EPOCH #30, step #1624] loss: 0.615330213528413\n",
      "[EPOCH #30, step #1626] loss: 0.6152886358703948\n",
      "[EPOCH #30, step #1628] loss: 0.6153923936641019\n",
      "[EPOCH #30, step #1630] loss: 0.6153268339917529\n",
      "[EPOCH #30, step #1632] loss: 0.6151873658605682\n",
      "[EPOCH #30, step #1634] loss: 0.6148266919891404\n",
      "[EPOCH #30, step #1636] loss: 0.6146788316014778\n",
      "[EPOCH #30, step #1638] loss: 0.6147563064003805\n",
      "[EPOCH #30, step #1640] loss: 0.6149804526752702\n",
      "[EPOCH #30, step #1642] loss: 0.6148090755438849\n",
      "[EPOCH #30, step #1644] loss: 0.6147438022141036\n",
      "[EPOCH #30, step #1646] loss: 0.6145756642747519\n",
      "[EPOCH #30, step #1648] loss: 0.6143988263903422\n",
      "[EPOCH #30, step #1650] loss: 0.6145369464307031\n",
      "[EPOCH #30, step #1652] loss: 0.6144060347921114\n",
      "[EPOCH #30, step #1654] loss: 0.6144301121328533\n",
      "[EPOCH #30, step #1656] loss: 0.6144182830239608\n",
      "[EPOCH #30, step #1658] loss: 0.6146531761447086\n",
      "[EPOCH #30, step #1660] loss: 0.614485823555498\n",
      "[EPOCH #30, step #1662] loss: 0.6142500398643606\n",
      "[EPOCH #30, step #1664] loss: 0.6141974313660069\n",
      "[EPOCH #30, step #1666] loss: 0.6143222964482173\n",
      "[EPOCH #30, step #1668] loss: 0.6143881223421742\n",
      "[EPOCH #30, step #1670] loss: 0.6146697353667516\n",
      "[EPOCH #30, step #1672] loss: 0.614518122336712\n",
      "[EPOCH #30, step #1674] loss: 0.6144365918636322\n",
      "[EPOCH #30, step #1676] loss: 0.6144041441954099\n",
      "[EPOCH #30, step #1678] loss: 0.6144232542795962\n",
      "[EPOCH #30, step #1680] loss: 0.6143988469645496\n",
      "[EPOCH #30, step #1682] loss: 0.6141701632500828\n",
      "[EPOCH #30, step #1684] loss: 0.6143298558382323\n",
      "[EPOCH #30, step #1686] loss: 0.6145163171377561\n",
      "[EPOCH #30, step #1688] loss: 0.6146797244897462\n",
      "[EPOCH #30, step #1690] loss: 0.614765578088924\n",
      "[EPOCH #30, step #1692] loss: 0.6148371115564526\n",
      "[EPOCH #30, step #1694] loss: 0.6147854800948703\n",
      "[EPOCH #30, step #1696] loss: 0.6146775926641668\n",
      "[EPOCH #30, step #1698] loss: 0.6148260164218765\n",
      "[EPOCH #30, step #1700] loss: 0.614901218885257\n",
      "[EPOCH #30, step #1702] loss: 0.6148158959690011\n",
      "[EPOCH #30, step #1704] loss: 0.6148282861779513\n",
      "[EPOCH #30, step #1706] loss: 0.6146854685808247\n",
      "[EPOCH #30, step #1708] loss: 0.6146605311429173\n",
      "[EPOCH #30, step #1710] loss: 0.6148338479684989\n",
      "[EPOCH #30, step #1712] loss: 0.6145713904136395\n",
      "[EPOCH #30, step #1714] loss: 0.6146331186544791\n",
      "[EPOCH #30, step #1716] loss: 0.6146215031538582\n",
      "[EPOCH #30, step #1718] loss: 0.6145956603297665\n",
      "[EPOCH #30, step #1720] loss: 0.6144139599585381\n",
      "[EPOCH #30, step #1722] loss: 0.6145360115407444\n",
      "[EPOCH #30, step #1724] loss: 0.6148089484028194\n",
      "[EPOCH #30, step #1726] loss: 0.6145042437449589\n",
      "[EPOCH #30, step #1728] loss: 0.6144873161340739\n",
      "[EPOCH #30, step #1730] loss: 0.6146466390443358\n",
      "[EPOCH #30, step #1732] loss: 0.6144674042367687\n",
      "[EPOCH #30, step #1734] loss: 0.6144913871281429\n",
      "[EPOCH #30, step #1736] loss: 0.6146224967419037\n",
      "[EPOCH #30, step #1738] loss: 0.6145600716124464\n",
      "[EPOCH #30, step #1740] loss: 0.6145969955041996\n",
      "[EPOCH #30, step #1742] loss: 0.6150539342145159\n",
      "[EPOCH #30, step #1744] loss: 0.6149068393304218\n",
      "[EPOCH #30, step #1746] loss: 0.6152126303419223\n",
      "[EPOCH #30, step #1748] loss: 0.6154837732897137\n",
      "[EPOCH #30, step #1750] loss: 0.6154249079359524\n",
      "[EPOCH #30, step #1752] loss: 0.6157637067474914\n",
      "[EPOCH #30, step #1754] loss: 0.6157043578787746\n",
      "[EPOCH #30, step #1756] loss: 0.6158292891460857\n",
      "[EPOCH #30, step #1758] loss: 0.616004447746575\n",
      "[EPOCH #30, step #1760] loss: 0.6161151609422131\n",
      "[EPOCH #30, step #1762] loss: 0.6160626168522859\n",
      "[EPOCH #30, step #1764] loss: 0.6162768053096684\n",
      "[EPOCH #30, step #1766] loss: 0.6163002310766631\n",
      "[EPOCH #30, step #1768] loss: 0.6161671213136007\n",
      "[EPOCH #30, step #1770] loss: 0.6164458546511943\n",
      "[EPOCH #30, step #1772] loss: 0.616364881471934\n",
      "[EPOCH #30, step #1774] loss: 0.6161871389771851\n",
      "[EPOCH #30, step #1776] loss: 0.6161402769147779\n",
      "[EPOCH #30, step #1778] loss: 0.616358541316568\n",
      "[EPOCH #30, step #1780] loss: 0.6162249580117707\n",
      "[EPOCH #30, step #1782] loss: 0.6166869501551415\n",
      "[EPOCH #30, step #1784] loss: 0.6165146820017604\n",
      "[EPOCH #30, step #1786] loss: 0.6162034217111879\n",
      "[EPOCH #30, step #1788] loss: 0.6159768482871133\n",
      "[EPOCH #30, step #1790] loss: 0.6159930547511092\n",
      "[EPOCH #30, step #1792] loss: 0.6159798659330231\n",
      "[EPOCH #30, step #1794] loss: 0.6159583490040973\n",
      "[EPOCH #30, step #1796] loss: 0.6159809117159315\n",
      "[EPOCH #30, step #1798] loss: 0.6161139109619728\n",
      "[EPOCH #30, step #1800] loss: 0.6162566141344851\n",
      "[EPOCH #30, step #1802] loss: 0.616176486808726\n",
      "[EPOCH #30, step #1804] loss: 0.616066591445759\n",
      "[EPOCH #30, step #1806] loss: 0.6161244112645715\n",
      "[EPOCH #30, step #1808] loss: 0.6160970888887736\n",
      "[EPOCH #30, step #1810] loss: 0.6160731974686792\n",
      "[EPOCH #30, step #1812] loss: 0.616166846221544\n",
      "[EPOCH #30, step #1814] loss: 0.6161499328685529\n",
      "[EPOCH #30, step #1816] loss: 0.616278065172735\n",
      "[EPOCH #30, step #1818] loss: 0.6165017797404295\n",
      "[EPOCH #30, step #1820] loss: 0.6165387607714031\n",
      "[EPOCH #30, step #1822] loss: 0.6166610470101915\n",
      "[EPOCH #30, step #1824] loss: 0.6166377990213159\n",
      "[EPOCH #30, step #1826] loss: 0.6165555750305821\n",
      "[EPOCH #30, step #1828] loss: 0.6164504180292147\n",
      "[EPOCH #30, step #1830] loss: 0.6164196825366017\n",
      "[EPOCH #30, step #1832] loss: 0.6167976437405817\n",
      "[EPOCH #30, step #1834] loss: 0.6169161380149363\n",
      "[EPOCH #30, step #1836] loss: 0.6166886523909457\n",
      "[EPOCH #30, step #1838] loss: 0.6168917448155059\n",
      "[EPOCH #30, step #1840] loss: 0.6171020388700339\n",
      "[EPOCH #30, step #1842] loss: 0.617098676223698\n",
      "[EPOCH #30, step #1844] loss: 0.6170433055902238\n",
      "[EPOCH #30, step #1846] loss: 0.6172466725191685\n",
      "[EPOCH #30, step #1848] loss: 0.6172882621355351\n",
      "[EPOCH #30, step #1850] loss: 0.6173457837246483\n",
      "[EPOCH #30, step #1852] loss: 0.617152549322399\n",
      "[EPOCH #30, step #1854] loss: 0.6170781935964312\n",
      "[EPOCH #30, step #1856] loss: 0.6169856844823978\n",
      "[EPOCH #30, step #1858] loss: 0.6167983531535088\n",
      "[EPOCH #30, step #1860] loss: 0.6166719155949588\n",
      "[EPOCH #30, step #1862] loss: 0.616704581088426\n",
      "[EPOCH #30, step #1864] loss: 0.616589009857689\n",
      "[EPOCH #30, step #1866] loss: 0.6166781044989649\n",
      "[EPOCH #30, step #1868] loss: 0.616492197069017\n",
      "[EPOCH #30, step #1870] loss: 0.6165617249312725\n",
      "[EPOCH #30, step #1872] loss: 0.6164616325356015\n",
      "[EPOCH #30, step #1874] loss: 0.616614050801595\n",
      "[EPOCH #30, step #1876] loss: 0.6166482750379982\n",
      "[EPOCH #30, step #1878] loss: 0.6168400483793753\n",
      "[EPOCH #30, step #1880] loss: 0.6167728125985666\n",
      "[EPOCH #30, step #1882] loss: 0.6167942756867066\n",
      "[EPOCH #30, step #1884] loss: 0.6168114605885918\n",
      "[EPOCH #30, step #1886] loss: 0.6169567540264281\n",
      "[EPOCH #30, step #1888] loss: 0.6169295234141241\n",
      "[EPOCH #30, step #1890] loss: 0.6171527892776673\n",
      "[EPOCH #30, step #1892] loss: 0.6172875377373662\n",
      "[EPOCH #30, step #1894] loss: 0.6171119249118664\n",
      "[EPOCH #30, step #1896] loss: 0.6170762827601254\n",
      "[EPOCH #30, step #1898] loss: 0.6172006266753632\n",
      "[EPOCH #30, step #1900] loss: 0.6171340292250088\n",
      "[EPOCH #30, step #1902] loss: 0.6172787639666281\n",
      "[EPOCH #30, step #1904] loss: 0.6173379935148194\n",
      "[EPOCH #30, step #1906] loss: 0.6174028189662369\n",
      "[EPOCH #30, step #1908] loss: 0.6172330151870652\n",
      "[EPOCH #30, step #1910] loss: 0.6170459279428908\n",
      "[EPOCH #30, step #1912] loss: 0.6171762969284487\n",
      "[EPOCH #30, step #1914] loss: 0.6174213953958168\n",
      "[EPOCH #30, step #1916] loss: 0.6172565830736404\n",
      "[EPOCH #30, step #1918] loss: 0.6173644285297692\n",
      "[EPOCH #30, step #1920] loss: 0.6173815603587604\n",
      "[EPOCH #30, step #1922] loss: 0.6177315510038405\n",
      "[EPOCH #30, step #1924] loss: 0.6176320519849852\n",
      "[EPOCH #30, step #1926] loss: 0.6174893032626037\n",
      "[EPOCH #30, step #1928] loss: 0.6174274824671698\n",
      "[EPOCH #30, step #1930] loss: 0.6174373344119382\n",
      "[EPOCH #30, step #1932] loss: 0.6177710366107242\n",
      "[EPOCH #30, step #1934] loss: 0.6177012863085252\n",
      "[EPOCH #30, step #1936] loss: 0.6175516377605602\n",
      "[EPOCH #30, step #1938] loss: 0.6175410659611994\n",
      "[EPOCH #30, step #1940] loss: 0.6175741826456149\n",
      "[EPOCH #30, step #1942] loss: 0.6177275297847901\n",
      "[EPOCH #30, step #1944] loss: 0.6176680217671824\n",
      "[EPOCH #30, step #1946] loss: 0.6179465522016693\n",
      "[EPOCH #30, step #1948] loss: 0.6178180762992387\n",
      "[EPOCH #30, step #1950] loss: 0.617892786990307\n",
      "[EPOCH #30, step #1952] loss: 0.6181780392093287\n",
      "[EPOCH #30, step #1954] loss: 0.6182013132230705\n",
      "[EPOCH #30, step #1956] loss: 0.6181410010304449\n",
      "[EPOCH #30, step #1958] loss: 0.6181243399596446\n",
      "[EPOCH #30, step #1960] loss: 0.6179801960006045\n",
      "[EPOCH #30, step #1962] loss: 0.6179352282900866\n",
      "[EPOCH #30, step #1964] loss: 0.617886370132291\n",
      "[EPOCH #30, step #1966] loss: 0.6179597050512146\n",
      "[EPOCH #30, step #1968] loss: 0.6182354813968548\n",
      "[EPOCH #30, step #1970] loss: 0.6181345604386564\n",
      "[EPOCH #30, step #1972] loss: 0.6182189983458792\n",
      "[EPOCH #30, step #1974] loss: 0.6183541942548149\n",
      "[EPOCH #30, step #1976] loss: 0.6184897972105969\n",
      "[EPOCH #30, step #1978] loss: 0.618488419953472\n",
      "[EPOCH #30, step #1980] loss: 0.618311431005048\n",
      "[EPOCH #30, step #1982] loss: 0.617977590608705\n",
      "[EPOCH #30, step #1984] loss: 0.617860472525097\n",
      "[EPOCH #30, step #1986] loss: 0.6178712673789002\n",
      "[EPOCH #30, step #1988] loss: 0.6180439699813911\n",
      "[EPOCH #30, step #1990] loss: 0.6179597029534493\n",
      "[EPOCH #30, step #1992] loss: 0.6176771143319555\n",
      "[EPOCH #30, step #1994] loss: 0.6174579908450445\n",
      "[EPOCH #30, step #1996] loss: 0.6172595010006136\n",
      "[EPOCH #30, step #1998] loss: 0.6172350739809559\n",
      "[EPOCH #30, step #2000] loss: 0.6172516629330699\n",
      "[EPOCH #30, step #2002] loss: 0.6170797916022289\n",
      "[EPOCH #30, step #2004] loss: 0.6171555274665504\n",
      "[EPOCH #30, step #2006] loss: 0.6173717926836869\n",
      "[EPOCH #30, step #2008] loss: 0.6173020369781672\n",
      "[EPOCH #30, step #2010] loss: 0.6173241369867135\n",
      "[EPOCH #30, step #2012] loss: 0.6173508012333262\n",
      "[EPOCH #30, step #2014] loss: 0.6171738917197542\n",
      "[EPOCH #30, step #2016] loss: 0.6173172287927385\n",
      "[EPOCH #30, step #2018] loss: 0.6174464902188768\n",
      "[EPOCH #30, step #2020] loss: 0.6175916282877599\n",
      "[EPOCH #30, step #2022] loss: 0.6175889748853443\n",
      "[EPOCH #30, step #2024] loss: 0.6177446929392991\n",
      "[EPOCH #30, step #2026] loss: 0.6178710696861317\n",
      "[EPOCH #30, step #2028] loss: 0.6176260747143998\n",
      "[EPOCH #30, step #2030] loss: 0.6176227259333646\n",
      "[EPOCH #30, step #2032] loss: 0.6176077042359527\n",
      "[EPOCH #30, step #2034] loss: 0.6174809858825342\n",
      "[EPOCH #30, step #2036] loss: 0.6173833897799093\n",
      "[EPOCH #30, step #2038] loss: 0.6175382403677852\n",
      "[EPOCH #30, step #2040] loss: 0.6173919890439142\n",
      "[EPOCH #30, step #2042] loss: 0.6173351604785047\n",
      "[EPOCH #30, step #2044] loss: 0.6173166888048713\n",
      "[EPOCH #30, step #2046] loss: 0.6173015911883707\n",
      "[EPOCH #30, step #2048] loss: 0.6172687412835494\n",
      "[EPOCH #30, step #2050] loss: 0.6171082567073031\n",
      "[EPOCH #30, step #2052] loss: 0.6171988142201568\n",
      "[EPOCH #30, step #2054] loss: 0.6172510144846863\n",
      "[EPOCH #30, step #2056] loss: 0.6173006812591372\n",
      "[EPOCH #30, step #2058] loss: 0.6172127099495133\n",
      "[EPOCH #30, step #2060] loss: 0.6170499537434756\n",
      "[EPOCH #30, step #2062] loss: 0.6171539815967082\n",
      "[EPOCH #30, step #2064] loss: 0.6173619188999726\n",
      "[EPOCH #30, step #2066] loss: 0.6173489240341044\n",
      "[EPOCH #30, step #2068] loss: 0.6171935713553325\n",
      "[EPOCH #30, step #2070] loss: 0.6170526341949322\n",
      "[EPOCH #30, step #2072] loss: 0.6169126928427687\n",
      "[EPOCH #30, step #2074] loss: 0.6169495136335672\n",
      "[EPOCH #30, step #2076] loss: 0.6168348177672006\n",
      "[EPOCH #30, step #2078] loss: 0.6167019862375218\n",
      "[EPOCH #30, step #2080] loss: 0.6168616147267022\n",
      "[EPOCH #30, step #2082] loss: 0.6168063304856942\n",
      "[EPOCH #30, step #2084] loss: 0.616810513957799\n",
      "[EPOCH #30, step #2086] loss: 0.6168965450958824\n",
      "[EPOCH #30, step #2088] loss: 0.6169423672244445\n",
      "[EPOCH #30, step #2090] loss: 0.6170005373040321\n",
      "[EPOCH #30, step #2092] loss: 0.6167938300313645\n",
      "[EPOCH #30, step #2094] loss: 0.61653844753996\n",
      "[EPOCH #30, step #2096] loss: 0.616463225727486\n",
      "[EPOCH #30, step #2098] loss: 0.616626701351005\n",
      "[EPOCH #30, step #2100] loss: 0.6165360828656801\n",
      "[EPOCH #30, step #2102] loss: 0.6163905342023145\n",
      "[EPOCH #30, step #2104] loss: 0.6166561013446001\n",
      "[EPOCH #30, step #2106] loss: 0.6167716649000714\n",
      "[EPOCH #30, step #2108] loss: 0.6168042954080418\n",
      "[EPOCH #30, step #2110] loss: 0.6169882671124898\n",
      "[EPOCH #30, step #2112] loss: 0.6170141235156134\n",
      "[EPOCH #30, step #2114] loss: 0.6169936315669518\n",
      "[EPOCH #30, step #2116] loss: 0.6170179641184854\n",
      "[EPOCH #30, step #2118] loss: 0.617004058365554\n",
      "[EPOCH #30, step #2120] loss: 0.6169768714893544\n",
      "[EPOCH #30, step #2122] loss: 0.6169728000687362\n",
      "[EPOCH #30, step #2124] loss: 0.616870409376481\n",
      "[EPOCH #30, step #2126] loss: 0.6168864785251787\n",
      "[EPOCH #30, step #2128] loss: 0.6167684840366503\n",
      "[EPOCH #30, step #2130] loss: 0.6166103324354226\n",
      "[EPOCH #30, step #2132] loss: 0.6164455328309586\n",
      "[EPOCH #30, step #2134] loss: 0.616405881986685\n",
      "[EPOCH #30, step #2136] loss: 0.6162310964072705\n",
      "[EPOCH #30, step #2138] loss: 0.6161904908357908\n",
      "[EPOCH #30, step #2140] loss: 0.6161243891894177\n",
      "[EPOCH #30, step #2142] loss: 0.6160935612132046\n",
      "[EPOCH #30, step #2144] loss: 0.6161006131928006\n",
      "[EPOCH #30, step #2146] loss: 0.6160241305328381\n",
      "[EPOCH #30, step #2148] loss: 0.6162746760694301\n",
      "[EPOCH #30, step #2150] loss: 0.6162307915411568\n",
      "[EPOCH #30, step #2152] loss: 0.6162417654070919\n",
      "[EPOCH #30, step #2154] loss: 0.6162567912840788\n",
      "[EPOCH #30, step #2156] loss: 0.6163750320438107\n",
      "[EPOCH #30, step #2158] loss: 0.6163877151309478\n",
      "[EPOCH #30, step #2160] loss: 0.6164248548741145\n",
      "[EPOCH #30, step #2162] loss: 0.6163991467301293\n",
      "[EPOCH #30, step #2164] loss: 0.616467388053414\n",
      "[EPOCH #30, step #2166] loss: 0.6163655296827606\n",
      "[EPOCH #30, step #2168] loss: 0.6165927824280458\n",
      "[EPOCH #30, step #2170] loss: 0.6164693448714867\n",
      "[EPOCH #30, step #2172] loss: 0.6163876444663642\n",
      "[EPOCH #30, step #2174] loss: 0.6165428938399786\n",
      "[EPOCH #30, step #2176] loss: 0.6165256667942096\n",
      "[EPOCH #30, step #2178] loss: 0.6163087502402305\n",
      "[EPOCH #30, step #2180] loss: 0.6162293318185933\n",
      "[EPOCH #30, step #2182] loss: 0.616196180572217\n",
      "[EPOCH #30, step #2184] loss: 0.6162481189183294\n",
      "[EPOCH #30, step #2186] loss: 0.6161258180609128\n",
      "[EPOCH #30, step #2188] loss: 0.6160622834614718\n",
      "[EPOCH #30, step #2190] loss: 0.6162034229620685\n",
      "[EPOCH #30, step #2192] loss: 0.6162827465015626\n",
      "[EPOCH #30, step #2194] loss: 0.6162880789989219\n",
      "[EPOCH #30, step #2196] loss: 0.6162052292361496\n",
      "[EPOCH #30, step #2198] loss: 0.6160575244956907\n",
      "[EPOCH #30, step #2200] loss: 0.6157696238570406\n",
      "[EPOCH #30, step #2202] loss: 0.6157791610338771\n",
      "[EPOCH #30, step #2204] loss: 0.6157274360694582\n",
      "[EPOCH #30, step #2206] loss: 0.6156578731985183\n",
      "[EPOCH #30, step #2208] loss: 0.6156389119264604\n",
      "[EPOCH #30, step #2210] loss: 0.615589099130389\n",
      "[EPOCH #30, step #2212] loss: 0.6156886318960288\n",
      "[EPOCH #30, step #2214] loss: 0.6154971814451584\n",
      "[EPOCH #30, step #2216] loss: 0.6154407607605719\n",
      "[EPOCH #30, step #2218] loss: 0.6154136108272298\n",
      "[EPOCH #30, step #2220] loss: 0.6156042443503672\n",
      "[EPOCH #30, step #2222] loss: 0.6157829091857802\n",
      "[EPOCH #30, step #2224] loss: 0.615928151808428\n",
      "[EPOCH #30, step #2226] loss: 0.6160751006155738\n",
      "[EPOCH #30, step #2228] loss: 0.6160166924205154\n",
      "[EPOCH #30, step #2230] loss: 0.6159050992816513\n",
      "[EPOCH #30, step #2232] loss: 0.6161011996634381\n",
      "[EPOCH #30, step #2234] loss: 0.6163135814453398\n",
      "[EPOCH #30, step #2236] loss: 0.6163956035073442\n",
      "[EPOCH #30, step #2238] loss: 0.6163957139220074\n",
      "[EPOCH #30, step #2240] loss: 0.6163849259715483\n",
      "[EPOCH #30, step #2242] loss: 0.6164367200671378\n",
      "[EPOCH #30, step #2244] loss: 0.616391642388363\n",
      "[EPOCH #30, step #2246] loss: 0.6163592585389435\n",
      "[EPOCH #30, step #2248] loss: 0.6162693667883553\n",
      "[EPOCH #30, step #2250] loss: 0.6165387266771044\n",
      "[EPOCH #30, step #2252] loss: 0.6166117440527193\n",
      "[EPOCH #30, step #2254] loss: 0.6166351704798358\n",
      "[EPOCH #30, step #2256] loss: 0.6167190019990366\n",
      "[EPOCH #30, step #2258] loss: 0.6167704462477358\n",
      "[EPOCH #30, step #2260] loss: 0.6166866573940489\n",
      "[EPOCH #30, step #2262] loss: 0.6168226397279822\n",
      "[EPOCH #30, step #2264] loss: 0.6166031457993632\n",
      "[EPOCH #30, step #2266] loss: 0.6164915037407558\n",
      "[EPOCH #30, step #2268] loss: 0.6164121314548301\n",
      "[EPOCH #30, step #2270] loss: 0.616424574417881\n",
      "[EPOCH #30, step #2272] loss: 0.6164885941471657\n",
      "[EPOCH #30, step #2274] loss: 0.6165044696645422\n",
      "[EPOCH #30, step #2276] loss: 0.6167634121540297\n",
      "[EPOCH #30, step #2278] loss: 0.6167823602856121\n",
      "[EPOCH #30, step #2280] loss: 0.6166054783344059\n",
      "[EPOCH #30, step #2282] loss: 0.6164864183673199\n",
      "[EPOCH #30, step #2284] loss: 0.6164637664736491\n",
      "[EPOCH #30, step #2286] loss: 0.6166605113060338\n",
      "[EPOCH #30, step #2288] loss: 0.6165312841866619\n",
      "[EPOCH #30, step #2290] loss: 0.6165094905573955\n",
      "[EPOCH #30, step #2292] loss: 0.616640016677023\n",
      "[EPOCH #30, step #2294] loss: 0.6169123750366676\n",
      "[EPOCH #30, step #2296] loss: 0.6168933788174176\n",
      "[EPOCH #30, step #2298] loss: 0.6168316069402193\n",
      "[EPOCH #30, step #2300] loss: 0.6168341130756493\n",
      "[EPOCH #30, step #2302] loss: 0.6167348500598372\n",
      "[EPOCH #30, step #2304] loss: 0.6167947052357771\n",
      "[EPOCH #30, step #2306] loss: 0.6166645310428372\n",
      "[EPOCH #30, step #2308] loss: 0.6164121566886456\n",
      "[EPOCH #30, step #2310] loss: 0.6162427409883703\n",
      "[EPOCH #30, step #2312] loss: 0.6163522702787946\n",
      "[EPOCH #30, step #2314] loss: 0.616513827076226\n",
      "[EPOCH #30, step #2316] loss: 0.6167340637359529\n",
      "[EPOCH #30, step #2318] loss: 0.6165701616627741\n",
      "[EPOCH #30, step #2320] loss: 0.6167890167041156\n",
      "[EPOCH #30, step #2322] loss: 0.6168335431667941\n",
      "[EPOCH #30, step #2324] loss: 0.616905688547319\n",
      "[EPOCH #30, step #2326] loss: 0.6167046242662905\n",
      "[EPOCH #30, step #2328] loss: 0.6168480410935183\n",
      "[EPOCH #30, step #2330] loss: 0.616906225259393\n",
      "[EPOCH #30, step #2332] loss: 0.6168346928390269\n",
      "[EPOCH #30, step #2334] loss: 0.6170148107300989\n",
      "[EPOCH #30, step #2336] loss: 0.6169546941406052\n",
      "[EPOCH #30, step #2338] loss: 0.616864032333047\n",
      "[EPOCH #30, step #2340] loss: 0.6169291891409057\n",
      "[EPOCH #30, step #2342] loss: 0.616858067532355\n",
      "[EPOCH #30, step #2344] loss: 0.6170592921756224\n",
      "[EPOCH #30, step #2346] loss: 0.6171157194875279\n",
      "[EPOCH #30, step #2348] loss: 0.6169222235781124\n",
      "[EPOCH #30, step #2350] loss: 0.6170429555166026\n",
      "[EPOCH #30, step #2352] loss: 0.6170566316062321\n",
      "[EPOCH #30, step #2354] loss: 0.6171673969858011\n",
      "[EPOCH #30, step #2356] loss: 0.6171023725173612\n",
      "[EPOCH #30, step #2358] loss: 0.6169061152459505\n",
      "[EPOCH #30, step #2360] loss: 0.6169093039355406\n",
      "[EPOCH #30, step #2362] loss: 0.6169446804073974\n",
      "[EPOCH #30, step #2364] loss: 0.6167610865377725\n",
      "[EPOCH #30, step #2366] loss: 0.6167600770375876\n",
      "[EPOCH #30, step #2368] loss: 0.616705649767862\n",
      "[EPOCH #30, step #2370] loss: 0.6167734487116563\n",
      "[EPOCH #30, step #2372] loss: 0.6167821662553091\n",
      "[EPOCH #30, step #2374] loss: 0.6166714054973502\n",
      "[EPOCH #30, step #2376] loss: 0.6167733857661273\n",
      "[EPOCH #30, step #2378] loss: 0.616546991362247\n",
      "[EPOCH #30, step #2380] loss: 0.6164604266530473\n",
      "[EPOCH #30, step #2382] loss: 0.6163776444190698\n",
      "[EPOCH #30, step #2384] loss: 0.616484607047005\n",
      "[EPOCH #30, step #2386] loss: 0.616326378755955\n",
      "[EPOCH #30, step #2388] loss: 0.6162101538136895\n",
      "[EPOCH #30, step #2390] loss: 0.61615708226666\n",
      "[EPOCH #30, step #2392] loss: 0.6164157641354935\n",
      "[EPOCH #30, step #2394] loss: 0.6164437154078534\n",
      "[EPOCH #30, step #2396] loss: 0.6165147228729839\n",
      "[EPOCH #30, step #2398] loss: 0.6165393026372501\n",
      "[EPOCH #30, step #2400] loss: 0.6163511009315111\n",
      "[EPOCH #30, step #2402] loss: 0.616273860800182\n",
      "[EPOCH #30, step #2404] loss: 0.616292258031403\n",
      "[EPOCH #30, step #2406] loss: 0.6164870213796154\n",
      "[EPOCH #30, step #2408] loss: 0.616458422065573\n",
      "[EPOCH #30, step #2410] loss: 0.6164423047766948\n",
      "[EPOCH #30, step #2412] loss: 0.6163341408997614\n",
      "[EPOCH #30, step #2414] loss: 0.6163083659997884\n",
      "[EPOCH #30, step #2416] loss: 0.6163006921383187\n",
      "[EPOCH #30, step #2418] loss: 0.616409820932995\n",
      "[EPOCH #30, step #2420] loss: 0.6165036315922401\n",
      "[EPOCH #30, step #2422] loss: 0.616538980758195\n",
      "[EPOCH #30, step #2424] loss: 0.6165021938454245\n",
      "[EPOCH #30, step #2426] loss: 0.6165294309837808\n",
      "[EPOCH #30, step #2428] loss: 0.6164754536439971\n",
      "[EPOCH #30, step #2430] loss: 0.61651448442067\n",
      "[EPOCH #30, step #2432] loss: 0.6164244308828867\n",
      "[EPOCH #30, step #2434] loss: 0.6164593692738907\n",
      "[EPOCH #30, step #2436] loss: 0.6164490916308781\n",
      "[EPOCH #30, step #2438] loss: 0.616330314490237\n",
      "[EPOCH #30, step #2440] loss: 0.6163937391645349\n",
      "[EPOCH #30, step #2442] loss: 0.6164699088548765\n",
      "[EPOCH #30, step #2444] loss: 0.6165493770672013\n",
      "[EPOCH #30, step #2446] loss: 0.6163509464660956\n",
      "[EPOCH #30, step #2448] loss: 0.6164069064919829\n",
      "[EPOCH #30, step #2450] loss: 0.6161781960740376\n",
      "[EPOCH #30, step #2452] loss: 0.6161740528737775\n",
      "[EPOCH #30, step #2454] loss: 0.6163161265206677\n",
      "[EPOCH #30, step #2456] loss: 0.6163258381099976\n",
      "[EPOCH #30, step #2458] loss: 0.6161885741051255\n",
      "[EPOCH #30, step #2460] loss: 0.6160618866461169\n",
      "[EPOCH #30, step #2462] loss: 0.6160632540274092\n",
      "[EPOCH #30, step #2464] loss: 0.6159118026253176\n",
      "[EPOCH #30, step #2466] loss: 0.6158099992039912\n",
      "[EPOCH #30, step #2468] loss: 0.6157498366982892\n",
      "[EPOCH #30, step #2470] loss: 0.6158006472813846\n",
      "[EPOCH #30, step #2472] loss: 0.6157874218001811\n",
      "[EPOCH #30, step #2474] loss: 0.6157910172445605\n",
      "[EPOCH #30, step #2476] loss: 0.6156129147082892\n",
      "[EPOCH #30, step #2478] loss: 0.6157553219937085\n",
      "[EPOCH #30, step #2480] loss: 0.6157751499657571\n",
      "[EPOCH #30, step #2482] loss: 0.6159029627429637\n",
      "[EPOCH #30, step #2484] loss: 0.6160080136607591\n",
      "[EPOCH #30, step #2486] loss: 0.6161696787370847\n",
      "[EPOCH #30, step #2488] loss: 0.6160144846678355\n",
      "[EPOCH #30, step #2490] loss: 0.6159921804916327\n",
      "[EPOCH #30, step #2492] loss: 0.616123484007527\n",
      "[EPOCH #30, step #2494] loss: 0.6162311127106985\n",
      "[EPOCH #30, step #2496] loss: 0.616326111415457\n",
      "[EPOCH #30, step #2498] loss: 0.6162907886249916\n",
      "[EPOCH #30, elapsed time: 15116.272[sec]] loss: 0.6162437168776989\n"
     ]
    }
   ],
   "source": [
    "model_dir = 'coco2014_clf'\n",
    "model.train(dataloader.dataset.trainloader, epochs=epochs, lr=learning_rate, wd=weight_decay, output_dir=model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ba45fa-de0f-4164-a9f4-8aab6c875907",
   "metadata": {},
   "source": [
    "## Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb3a83ec-4044-46fe-bdaf-bc2963063a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = model.predict(dataloader.dataset.trainloader)\n",
    "train_predictions, train_labels = train_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "50fcb205-1cff-48c0-9ad2-1881319b9056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9287875,\n",
      " 'classification_report': {'1': {'f1-score': 0.7256637168141593,\n",
      "                                 'precision': 0.8848920863309353,\n",
      "                                 'recall': 0.615,\n",
      "                                 'support': 1000},\n",
      "                           '10': {'f1-score': 0.998003992015968,\n",
      "                                  'precision': 0.9960159362549801,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '11': {'f1-score': 0.9720176730486009,\n",
      "                                  'precision': 0.9546769527483124,\n",
      "                                  'recall': 0.99,\n",
      "                                  'support': 1000},\n",
      "                           '13': {'f1-score': 0.9990009990009989,\n",
      "                                  'precision': 0.998003992015968,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '14': {'f1-score': 0.9847365829640571,\n",
      "                                  'precision': 0.9699321047526673,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '15': {'f1-score': 0.8165289256198348,\n",
      "                                  'precision': 0.90920245398773,\n",
      "                                  'recall': 0.741,\n",
      "                                  'support': 1000},\n",
      "                           '16': {'f1-score': 0.8895768833849329,\n",
      "                                  'precision': 0.9189765458422174,\n",
      "                                  'recall': 0.862,\n",
      "                                  'support': 1000},\n",
      "                           '17': {'f1-score': 0.7663280116110306,\n",
      "                                  'precision': 0.7422680412371134,\n",
      "                                  'recall': 0.792,\n",
      "                                  'support': 1000},\n",
      "                           '18': {'f1-score': 0.7184579439252337,\n",
      "                                  'precision': 0.8637640449438202,\n",
      "                                  'recall': 0.615,\n",
      "                                  'support': 1000},\n",
      "                           '19': {'f1-score': 0.8625877632898695,\n",
      "                                  'precision': 0.8651911468812877,\n",
      "                                  'recall': 0.86,\n",
      "                                  'support': 1000},\n",
      "                           '2': {'f1-score': 0.9063221042916475,\n",
      "                                 'precision': 0.8414738646101114,\n",
      "                                 'recall': 0.982,\n",
      "                                 'support': 1000},\n",
      "                           '20': {'f1-score': 0.9249512670565303,\n",
      "                                  'precision': 0.9020912547528517,\n",
      "                                  'recall': 0.949,\n",
      "                                  'support': 1000},\n",
      "                           '21': {'f1-score': 0.8816568047337278,\n",
      "                                  'precision': 0.8696498054474708,\n",
      "                                  'recall': 0.894,\n",
      "                                  'support': 1000},\n",
      "                           '22': {'f1-score': 0.8726945569050832,\n",
      "                                  'precision': 0.7931316434995912,\n",
      "                                  'recall': 0.97,\n",
      "                                  'support': 1000},\n",
      "                           '23': {'f1-score': 0.922930542340628,\n",
      "                                  'precision': 0.8802177858439202,\n",
      "                                  'recall': 0.97,\n",
      "                                  'support': 1000},\n",
      "                           '24': {'f1-score': 0.9835411471321694,\n",
      "                                  'precision': 0.981094527363184,\n",
      "                                  'recall': 0.986,\n",
      "                                  'support': 1000},\n",
      "                           '25': {'f1-score': 0.9634146341463414,\n",
      "                                  'precision': 0.9793388429752066,\n",
      "                                  'recall': 0.948,\n",
      "                                  'support': 1000},\n",
      "                           '27': {'f1-score': 0.9970089730807578,\n",
      "                                  'precision': 0.9940357852882704,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '28': {'f1-score': 0.8831849135673128,\n",
      "                                  'precision': 0.9273927392739274,\n",
      "                                  'recall': 0.843,\n",
      "                                  'support': 1000},\n",
      "                           '3': {'f1-score': 0.8074074074074075,\n",
      "                                 'precision': 0.8573033707865169,\n",
      "                                 'recall': 0.763,\n",
      "                                 'support': 1000},\n",
      "                           '31': {'f1-score': 0.998001998001998,\n",
      "                                  'precision': 0.9970059880239521,\n",
      "                                  'recall': 0.999,\n",
      "                                  'support': 1000},\n",
      "                           '32': {'f1-score': 0.9743847312908086,\n",
      "                                  'precision': 0.9788092835519677,\n",
      "                                  'recall': 0.97,\n",
      "                                  'support': 1000},\n",
      "                           '33': {'f1-score': 0.8832777513101476,\n",
      "                                  'precision': 0.8434940855323021,\n",
      "                                  'recall': 0.927,\n",
      "                                  'support': 1000},\n",
      "                           '34': {'f1-score': 1.0,\n",
      "                                  'precision': 1.0,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '35': {'f1-score': 0.9791666666666667,\n",
      "                                  'precision': 0.9714566929133859,\n",
      "                                  'recall': 0.987,\n",
      "                                  'support': 1000},\n",
      "                           '36': {'f1-score': 0.9870388833499502,\n",
      "                                  'precision': 0.9840954274353877,\n",
      "                                  'recall': 0.99,\n",
      "                                  'support': 1000},\n",
      "                           '37': {'f1-score': 0.9995002498750626,\n",
      "                                  'precision': 0.999000999000999,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '38': {'f1-score': 0.9756340129288911,\n",
      "                                  'precision': 0.9703264094955489,\n",
      "                                  'recall': 0.981,\n",
      "                                  'support': 1000},\n",
      "                           '39': {'f1-score': 0.9970059880239521,\n",
      "                                  'precision': 0.9950199203187251,\n",
      "                                  'recall': 0.999,\n",
      "                                  'support': 1000},\n",
      "                           '4': {'f1-score': 0.8662192393736017,\n",
      "                                 'precision': 0.7838056680161943,\n",
      "                                 'recall': 0.968,\n",
      "                                 'support': 1000},\n",
      "                           '40': {'f1-score': 1.0,\n",
      "                                  'precision': 1.0,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '41': {'f1-score': 0.972972972972973,\n",
      "                                  'precision': 0.9739478957915831,\n",
      "                                  'recall': 0.972,\n",
      "                                  'support': 1000},\n",
      "                           '42': {'f1-score': 0.942857142857143,\n",
      "                                  'precision': 0.9625,\n",
      "                                  'recall': 0.924,\n",
      "                                  'support': 1000},\n",
      "                           '43': {'f1-score': 0.9914786967418546,\n",
      "                                  'precision': 0.9939698492462311,\n",
      "                                  'recall': 0.989,\n",
      "                                  'support': 1000},\n",
      "                           '44': {'f1-score': 0.960755091902633,\n",
      "                                  'precision': 0.9545903257650543,\n",
      "                                  'recall': 0.967,\n",
      "                                  'support': 1000},\n",
      "                           '46': {'f1-score': 0.9678362573099415,\n",
      "                                  'precision': 0.9439163498098859,\n",
      "                                  'recall': 0.993,\n",
      "                                  'support': 1000},\n",
      "                           '47': {'f1-score': 0.9754385964912281,\n",
      "                                  'precision': 0.9778894472361809,\n",
      "                                  'recall': 0.973,\n",
      "                                  'support': 1000},\n",
      "                           '48': {'f1-score': 0.9602888086642599,\n",
      "                                  'precision': 0.9914802981895634,\n",
      "                                  'recall': 0.931,\n",
      "                                  'support': 1000},\n",
      "                           '49': {'f1-score': 0.9529470034670628,\n",
      "                                  'precision': 0.9440628066732091,\n",
      "                                  'recall': 0.962,\n",
      "                                  'support': 1000},\n",
      "                           '5': {'f1-score': 0.8889970788704966,\n",
      "                                 'precision': 0.8662239089184061,\n",
      "                                 'recall': 0.913,\n",
      "                                 'support': 1000},\n",
      "                           '50': {'f1-score': 0.9924812030075189,\n",
      "                                  'precision': 0.9949748743718593,\n",
      "                                  'recall': 0.99,\n",
      "                                  'support': 1000},\n",
      "                           '51': {'f1-score': 0.8684645019262521,\n",
      "                                  'precision': 0.9657282741738066,\n",
      "                                  'recall': 0.789,\n",
      "                                  'support': 1000},\n",
      "                           '52': {'f1-score': 0.9290523045054376,\n",
      "                                  'precision': 0.9634801288936627,\n",
      "                                  'recall': 0.897,\n",
      "                                  'support': 1000},\n",
      "                           '53': {'f1-score': 0.9950149551345961,\n",
      "                                  'precision': 0.9920477137176938,\n",
      "                                  'recall': 0.998,\n",
      "                                  'support': 1000},\n",
      "                           '54': {'f1-score': 0.91015625,\n",
      "                                  'precision': 0.8893129770992366,\n",
      "                                  'recall': 0.932,\n",
      "                                  'support': 1000},\n",
      "                           '55': {'f1-score': 0.9886082218920257,\n",
      "                                  'precision': 0.9793915603532876,\n",
      "                                  'recall': 0.998,\n",
      "                                  'support': 1000},\n",
      "                           '56': {'f1-score': 0.9726166328600406,\n",
      "                                  'precision': 0.9866255144032922,\n",
      "                                  'recall': 0.959,\n",
      "                                  'support': 1000},\n",
      "                           '57': {'f1-score': 0.9945300845350572,\n",
      "                                  'precision': 0.9891196834817013,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '58': {'f1-score': 0.9652777777777778,\n",
      "                                  'precision': 0.9576771653543307,\n",
      "                                  'recall': 0.973,\n",
      "                                  'support': 1000},\n",
      "                           '59': {'f1-score': 0.921259842519685,\n",
      "                                  'precision': 0.9069767441860465,\n",
      "                                  'recall': 0.936,\n",
      "                                  'support': 1000},\n",
      "                           '6': {'f1-score': 0.8884705882352941,\n",
      "                                 'precision': 0.8391111111111111,\n",
      "                                 'recall': 0.944,\n",
      "                                 'support': 1000},\n",
      "                           '60': {'f1-score': 0.9846153846153847,\n",
      "                                  'precision': 0.9773399014778326,\n",
      "                                  'recall': 0.992,\n",
      "                                  'support': 1000},\n",
      "                           '61': {'f1-score': 0.917879417879418,\n",
      "                                  'precision': 0.9556277056277056,\n",
      "                                  'recall': 0.883,\n",
      "                                  'support': 1000},\n",
      "                           '62': {'f1-score': 0.7531610775151182,\n",
      "                                  'precision': 0.8363858363858364,\n",
      "                                  'recall': 0.685,\n",
      "                                  'support': 1000},\n",
      "                           '63': {'f1-score': 0.7494949494949494,\n",
      "                                  'precision': 0.7571428571428571,\n",
      "                                  'recall': 0.742,\n",
      "                                  'support': 1000},\n",
      "                           '64': {'f1-score': 0.9699745547073791,\n",
      "                                  'precision': 0.9875647668393782,\n",
      "                                  'recall': 0.953,\n",
      "                                  'support': 1000},\n",
      "                           '65': {'f1-score': 0.7729812087353986,\n",
      "                                  'precision': 0.7853457172342622,\n",
      "                                  'recall': 0.761,\n",
      "                                  'support': 1000},\n",
      "                           '67': {'f1-score': 0.76552881925014,\n",
      "                                  'precision': 0.8691232528589581,\n",
      "                                  'recall': 0.684,\n",
      "                                  'support': 1000},\n",
      "                           '7': {'f1-score': 0.8450261780104713,\n",
      "                                 'precision': 0.8868131868131868,\n",
      "                                 'recall': 0.807,\n",
      "                                 'support': 1000},\n",
      "                           '70': {'f1-score': 0.8958724202626641,\n",
      "                                  'precision': 0.8436395759717314,\n",
      "                                  'recall': 0.955,\n",
      "                                  'support': 1000},\n",
      "                           '72': {'f1-score': 0.9560493827160493,\n",
      "                                  'precision': 0.944390243902439,\n",
      "                                  'recall': 0.968,\n",
      "                                  'support': 1000},\n",
      "                           '73': {'f1-score': 0.9099283520982601,\n",
      "                                  'precision': 0.9318658280922432,\n",
      "                                  'recall': 0.889,\n",
      "                                  'support': 1000},\n",
      "                           '74': {'f1-score': 0.998003992015968,\n",
      "                                  'precision': 0.9960159362549801,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '75': {'f1-score': 0.9950149551345961,\n",
      "                                  'precision': 0.9920477137176938,\n",
      "                                  'recall': 0.998,\n",
      "                                  'support': 1000},\n",
      "                           '76': {'f1-score': 0.9369458128078817,\n",
      "                                  'precision': 0.9233009708737864,\n",
      "                                  'recall': 0.951,\n",
      "                                  'support': 1000},\n",
      "                           '77': {'f1-score': 0.9910358565737053,\n",
      "                                  'precision': 0.9871031746031746,\n",
      "                                  'recall': 0.995,\n",
      "                                  'support': 1000},\n",
      "                           '78': {'f1-score': 0.9871541501976284,\n",
      "                                  'precision': 0.9755859375,\n",
      "                                  'recall': 0.999,\n",
      "                                  'support': 1000},\n",
      "                           '79': {'f1-score': 0.9335918565196316,\n",
      "                                  'precision': 0.9059266227657573,\n",
      "                                  'recall': 0.963,\n",
      "                                  'support': 1000},\n",
      "                           '8': {'f1-score': 0.7848421052631579,\n",
      "                                 'precision': 0.6778181818181818,\n",
      "                                 'recall': 0.932,\n",
      "                                 'support': 1000},\n",
      "                           '80': {'f1-score': 0.9995002498750626,\n",
      "                                  'precision': 0.999000999000999,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '81': {'f1-score': 0.9218516674962669,\n",
      "                                  'precision': 0.9177403369672944,\n",
      "                                  'recall': 0.926,\n",
      "                                  'support': 1000},\n",
      "                           '82': {'f1-score': 0.8984700973574409,\n",
      "                                  'precision': 0.8375108038029386,\n",
      "                                  'recall': 0.969,\n",
      "                                  'support': 1000},\n",
      "                           '84': {'f1-score': 0.9594731509625125,\n",
      "                                  'precision': 0.9722792607802875,\n",
      "                                  'recall': 0.947,\n",
      "                                  'support': 1000},\n",
      "                           '85': {'f1-score': 0.9970089730807578,\n",
      "                                  'precision': 0.9940357852882704,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '86': {'f1-score': 0.9589457678661937,\n",
      "                                  'precision': 0.9722507708119219,\n",
      "                                  'recall': 0.946,\n",
      "                                  'support': 1000},\n",
      "                           '87': {'f1-score': 0.9960079840319361,\n",
      "                                  'precision': 0.9940239043824701,\n",
      "                                  'recall': 0.998,\n",
      "                                  'support': 1000},\n",
      "                           '88': {'f1-score': 0.8891181021144919,\n",
      "                                  'precision': 0.9179978700745474,\n",
      "                                  'recall': 0.862,\n",
      "                                  'support': 1000},\n",
      "                           '89': {'f1-score': 1.0,\n",
      "                                  'precision': 1.0,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           '9': {'f1-score': 0.884873515745999,\n",
      "                                 'precision': 0.9146211312700107,\n",
      "                                 'recall': 0.857,\n",
      "                                 'support': 1000},\n",
      "                           '90': {'f1-score': 0.9985022466300548,\n",
      "                                  'precision': 0.9970089730807578,\n",
      "                                  'recall': 1.0,\n",
      "                                  'support': 1000},\n",
      "                           'accuracy': 0.9287875,\n",
      "                           'macro avg': {'f1-score': 0.9278325075473395,\n",
      "                                         'precision': 0.9309275159155025,\n",
      "                                         'recall': 0.9287875,\n",
      "                                         'support': 80000},\n",
      "                           'weighted avg': {'f1-score': 0.9278325075473396,\n",
      "                                            'precision': 0.9309275159155024,\n",
      "                                            'recall': 0.9287875,\n",
      "                                            'support': 80000}}}\n"
     ]
    }
   ],
   "source": [
    "train_eval_result = model.evaluate(train_labels, train_predictions)\n",
    "pprint.pprint(train_eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7768822-0900-4959-8618-20c89b0f5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result = model.predict(dataloader.dataset.testloader)\n",
    "test_predictions, test_labels = test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9521acc2-29d8-4dbb-81e2-0e264b4155a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.31785,\n",
      " 'classification_report': {'1': {'f1-score': 0.12547528517110265,\n",
      "                                 'precision': 0.09183673469387756,\n",
      "                                 'recall': 0.198,\n",
      "                                 'support': 1000},\n",
      "                           '10': {'f1-score': 0.5640695428203477,\n",
      "                                  'precision': 0.7920433996383364,\n",
      "                                  'recall': 0.438,\n",
      "                                  'support': 1000},\n",
      "                           '11': {'f1-score': 0.5625,\n",
      "                                  'precision': 0.5140728476821192,\n",
      "                                  'recall': 0.621,\n",
      "                                  'support': 1000},\n",
      "                           '13': {'f1-score': 0.7940199335548173,\n",
      "                                  'precision': 0.8895781637717122,\n",
      "                                  'recall': 0.717,\n",
      "                                  'support': 1000},\n",
      "                           '14': {'f1-score': 0.45601436265709155,\n",
      "                                  'precision': 0.5678092399403875,\n",
      "                                  'recall': 0.381,\n",
      "                                  'support': 1000},\n",
      "                           '15': {'f1-score': 0.17232640648758238,\n",
      "                                  'precision': 0.1747173689619733,\n",
      "                                  'recall': 0.17,\n",
      "                                  'support': 1000},\n",
      "                           '16': {'f1-score': 0.21561338289962825,\n",
      "                                  'precision': 0.22989807474518686,\n",
      "                                  'recall': 0.203,\n",
      "                                  'support': 1000},\n",
      "                           '17': {'f1-score': 0.2541737649063032,\n",
      "                                  'precision': 0.19276485788113695,\n",
      "                                  'recall': 0.373,\n",
      "                                  'support': 1000},\n",
      "                           '18': {'f1-score': 0.12351274787535411,\n",
      "                                  'precision': 0.14248366013071895,\n",
      "                                  'recall': 0.109,\n",
      "                                  'support': 1000},\n",
      "                           '19': {'f1-score': 0.3644820295983086,\n",
      "                                  'precision': 0.31575091575091574,\n",
      "                                  'recall': 0.431,\n",
      "                                  'support': 1000},\n",
      "                           '2': {'f1-score': 0.2946242946242946,\n",
      "                                 'precision': 0.20954795099281792,\n",
      "                                 'recall': 0.496,\n",
      "                                 'support': 1000},\n",
      "                           '20': {'f1-score': 0.43712898003237993,\n",
      "                                  'precision': 0.47479484173505276,\n",
      "                                  'recall': 0.405,\n",
      "                                  'support': 1000},\n",
      "                           '21': {'f1-score': 0.30730223123732253,\n",
      "                                  'precision': 0.3117283950617284,\n",
      "                                  'recall': 0.303,\n",
      "                                  'support': 1000},\n",
      "                           '22': {'f1-score': 0.48057644110275693,\n",
      "                                  'precision': 0.3499087591240876,\n",
      "                                  'recall': 0.767,\n",
      "                                  'support': 1000},\n",
      "                           '23': {'f1-score': 0.5685983159980187,\n",
      "                                  'precision': 0.563297350343474,\n",
      "                                  'recall': 0.574,\n",
      "                                  'support': 1000},\n",
      "                           '24': {'f1-score': 0.8357109986194202,\n",
      "                                  'precision': 0.7740835464620631,\n",
      "                                  'recall': 0.908,\n",
      "                                  'support': 1000},\n",
      "                           '25': {'f1-score': 0.7267384916748286,\n",
      "                                  'precision': 0.7120921305182342,\n",
      "                                  'recall': 0.742,\n",
      "                                  'support': 1000},\n",
      "                           '27': {'f1-score': 0.05958132045088566,\n",
      "                                  'precision': 0.15289256198347106,\n",
      "                                  'recall': 0.037,\n",
      "                                  'support': 1000},\n",
      "                           '28': {'f1-score': 0.2607645875251509,\n",
      "                                  'precision': 0.21818181818181817,\n",
      "                                  'recall': 0.324,\n",
      "                                  'support': 1000},\n",
      "                           '3': {'f1-score': 0.16484374999999998,\n",
      "                                 'precision': 0.13525641025641025,\n",
      "                                 'recall': 0.211,\n",
      "                                 'support': 1000},\n",
      "                           '31': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 1000},\n",
      "                           '32': {'f1-score': 0.39831401475237094,\n",
      "                                  'precision': 0.4209354120267261,\n",
      "                                  'recall': 0.378,\n",
      "                                  'support': 1000},\n",
      "                           '33': {'f1-score': 0.11049723756906078,\n",
      "                                  'precision': 0.07790077900779008,\n",
      "                                  'recall': 0.19,\n",
      "                                  'support': 1000},\n",
      "                           '34': {'f1-score': 0.09541627689429372,\n",
      "                                  'precision': 0.7391304347826086,\n",
      "                                  'recall': 0.051,\n",
      "                                  'support': 1000},\n",
      "                           '35': {'f1-score': 0.573170731707317,\n",
      "                                  'precision': 0.5826446280991735,\n",
      "                                  'recall': 0.564,\n",
      "                                  'support': 1000},\n",
      "                           '36': {'f1-score': 0.34690265486725663,\n",
      "                                  'precision': 0.42302158273381296,\n",
      "                                  'recall': 0.294,\n",
      "                                  'support': 1000},\n",
      "                           '37': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 1000},\n",
      "                           '38': {'f1-score': 0.4216216216216216,\n",
      "                                  'precision': 0.4588235294117647,\n",
      "                                  'recall': 0.39,\n",
      "                                  'support': 1000},\n",
      "                           '39': {'f1-score': 0.06501283147989735,\n",
      "                                  'precision': 0.22485207100591717,\n",
      "                                  'recall': 0.038,\n",
      "                                  'support': 1000},\n",
      "                           '4': {'f1-score': 0.42623858289510097,\n",
      "                                 'precision': 0.29468044393417525,\n",
      "                                 'recall': 0.77,\n",
      "                                 'support': 1000},\n",
      "                           '40': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 1000},\n",
      "                           '41': {'f1-score': 0.3323716099249856,\n",
      "                                  'precision': 0.39290586630286495,\n",
      "                                  'recall': 0.288,\n",
      "                                  'support': 1000},\n",
      "                           '42': {'f1-score': 0.25823314166231054,\n",
      "                                  'precision': 0.27053669222343923,\n",
      "                                  'recall': 0.247,\n",
      "                                  'support': 1000},\n",
      "                           '43': {'f1-score': 0.34544208361891704,\n",
      "                                  'precision': 0.5490196078431373,\n",
      "                                  'recall': 0.252,\n",
      "                                  'support': 1000},\n",
      "                           '44': {'f1-score': 0.14261069580218516,\n",
      "                                  'precision': 0.16779431664411368,\n",
      "                                  'recall': 0.124,\n",
      "                                  'support': 1000},\n",
      "                           '46': {'f1-score': 0.30971659919028344,\n",
      "                                  'precision': 0.3135245901639344,\n",
      "                                  'recall': 0.306,\n",
      "                                  'support': 1000},\n",
      "                           '47': {'f1-score': 0.2840690978886756,\n",
      "                                  'precision': 0.39431616341030196,\n",
      "                                  'recall': 0.222,\n",
      "                                  'support': 1000},\n",
      "                           '48': {'f1-score': 0.15602836879432624,\n",
      "                                  'precision': 0.2682926829268293,\n",
      "                                  'recall': 0.11,\n",
      "                                  'support': 1000},\n",
      "                           '49': {'f1-score': 0.1725417439703154,\n",
      "                                  'precision': 0.16089965397923875,\n",
      "                                  'recall': 0.186,\n",
      "                                  'support': 1000},\n",
      "                           '5': {'f1-score': 0.4824269330373659,\n",
      "                                 'precision': 0.3828537874339401,\n",
      "                                 'recall': 0.652,\n",
      "                                 'support': 1000},\n",
      "                           '50': {'f1-score': 0.08353033884948778,\n",
      "                                  'precision': 0.1970260223048327,\n",
      "                                  'recall': 0.053,\n",
      "                                  'support': 1000},\n",
      "                           '51': {'f1-score': 0.26181353767560667,\n",
      "                                  'precision': 0.3621908127208481,\n",
      "                                  'recall': 0.205,\n",
      "                                  'support': 1000},\n",
      "                           '52': {'f1-score': 0.381758345086977,\n",
      "                                  'precision': 0.36024844720496896,\n",
      "                                  'recall': 0.406,\n",
      "                                  'support': 1000},\n",
      "                           '53': {'f1-score': 0.24032258064516127,\n",
      "                                  'precision': 0.6208333333333333,\n",
      "                                  'recall': 0.149,\n",
      "                                  'support': 1000},\n",
      "                           '54': {'f1-score': 0.39916839916839914,\n",
      "                                  'precision': 0.3416370106761566,\n",
      "                                  'recall': 0.48,\n",
      "                                  'support': 1000},\n",
      "                           '55': {'f1-score': 0.4347826086956522,\n",
      "                                  'precision': 0.4993514915693904,\n",
      "                                  'recall': 0.385,\n",
      "                                  'support': 1000},\n",
      "                           '56': {'f1-score': 0.6053268765133172,\n",
      "                                  'precision': 0.7668711656441718,\n",
      "                                  'recall': 0.5,\n",
      "                                  'support': 1000},\n",
      "                           '57': {'f1-score': 0.28775113415424497,\n",
      "                                  'precision': 0.4088397790055249,\n",
      "                                  'recall': 0.222,\n",
      "                                  'support': 1000},\n",
      "                           '58': {'f1-score': 0.3651226158038148,\n",
      "                                  'precision': 0.40119760479041916,\n",
      "                                  'recall': 0.335,\n",
      "                                  'support': 1000},\n",
      "                           '59': {'f1-score': 0.436462216197899,\n",
      "                                  'precision': 0.3300871348026653,\n",
      "                                  'recall': 0.644,\n",
      "                                  'support': 1000},\n",
      "                           '6': {'f1-score': 0.4154160982264666,\n",
      "                                 'precision': 0.31521739130434784,\n",
      "                                 'recall': 0.609,\n",
      "                                 'support': 1000},\n",
      "                           '60': {'f1-score': 0.24205378973105135,\n",
      "                                  'precision': 0.3113207547169811,\n",
      "                                  'recall': 0.198,\n",
      "                                  'support': 1000},\n",
      "                           '61': {'f1-score': 0.21331689272503082,\n",
      "                                  'precision': 0.27813504823151125,\n",
      "                                  'recall': 0.173,\n",
      "                                  'support': 1000},\n",
      "                           '62': {'f1-score': 0.08333333333333333,\n",
      "                                  'precision': 0.07548701298701299,\n",
      "                                  'recall': 0.093,\n",
      "                                  'support': 1000},\n",
      "                           '63': {'f1-score': 0.17481709664998077,\n",
      "                                  'precision': 0.14214151534126487,\n",
      "                                  'recall': 0.227,\n",
      "                                  'support': 1000},\n",
      "                           '64': {'f1-score': 0.2985274431057564,\n",
      "                                  'precision': 0.451417004048583,\n",
      "                                  'recall': 0.223,\n",
      "                                  'support': 1000},\n",
      "                           '65': {'f1-score': 0.2246376811594203,\n",
      "                                  'precision': 0.18800539083557952,\n",
      "                                  'recall': 0.279,\n",
      "                                  'support': 1000},\n",
      "                           '67': {'f1-score': 0.19426201175250604,\n",
      "                                  'precision': 0.14844162704701533,\n",
      "                                  'recall': 0.281,\n",
      "                                  'support': 1000},\n",
      "                           '7': {'f1-score': 0.3381562629185614,\n",
      "                                 'precision': 0.288231148696265,\n",
      "                                 'recall': 0.409,\n",
      "                                 'support': 1000},\n",
      "                           '70': {'f1-score': 0.4439716312056738,\n",
      "                                  'precision': 0.34395604395604396,\n",
      "                                  'recall': 0.626,\n",
      "                                  'support': 1000},\n",
      "                           '72': {'f1-score': 0.49235181644359466,\n",
      "                                  'precision': 0.4716117216117216,\n",
      "                                  'recall': 0.515,\n",
      "                                  'support': 1000},\n",
      "                           '73': {'f1-score': 0.3082191780821918,\n",
      "                                  'precision': 0.2694610778443114,\n",
      "                                  'recall': 0.36,\n",
      "                                  'support': 1000},\n",
      "                           '74': {'f1-score': 0.08994708994708994,\n",
      "                                  'precision': 0.3805970149253731,\n",
      "                                  'recall': 0.051,\n",
      "                                  'support': 1000},\n",
      "                           '75': {'f1-score': 0.15048543689320387,\n",
      "                                  'precision': 0.3940677966101695,\n",
      "                                  'recall': 0.093,\n",
      "                                  'support': 1000},\n",
      "                           '76': {'f1-score': 0.4115148655025956,\n",
      "                                  'precision': 0.3896336014298481,\n",
      "                                  'recall': 0.436,\n",
      "                                  'support': 1000},\n",
      "                           '77': {'f1-score': 0.25554259043173866,\n",
      "                                  'precision': 0.3067226890756303,\n",
      "                                  'recall': 0.219,\n",
      "                                  'support': 1000},\n",
      "                           '78': {'f1-score': 0.49695493300852617,\n",
      "                                  'precision': 0.6355140186915887,\n",
      "                                  'recall': 0.408,\n",
      "                                  'support': 1000},\n",
      "                           '79': {'f1-score': 0.2583732057416268,\n",
      "                                  'precision': 0.21485411140583555,\n",
      "                                  'recall': 0.324,\n",
      "                                  'support': 1000},\n",
      "                           '8': {'f1-score': 0.2572463768115942,\n",
      "                                 'precision': 0.1735335195530726,\n",
      "                                 'recall': 0.497,\n",
      "                                 'support': 1000},\n",
      "                           '80': {'f1-score': 0.21847246891651867,\n",
      "                                  'precision': 0.9761904761904762,\n",
      "                                  'recall': 0.123,\n",
      "                                  'support': 1000},\n",
      "                           '81': {'f1-score': 0.40309278350515465,\n",
      "                                  'precision': 0.41595744680851066,\n",
      "                                  'recall': 0.391,\n",
      "                                  'support': 1000},\n",
      "                           '82': {'f1-score': 0.3016428763802855,\n",
      "                                  'precision': 0.206413564319941,\n",
      "                                  'recall': 0.56,\n",
      "                                  'support': 1000},\n",
      "                           '84': {'f1-score': 0.02641232575201761,\n",
      "                                  'precision': 0.049586776859504134,\n",
      "                                  'recall': 0.018,\n",
      "                                  'support': 1000},\n",
      "                           '85': {'f1-score': 0.5420792079207921,\n",
      "                                  'precision': 0.711038961038961,\n",
      "                                  'recall': 0.438,\n",
      "                                  'support': 1000},\n",
      "                           '86': {'f1-score': 0.23013048635824437,\n",
      "                                  'precision': 0.282798833819242,\n",
      "                                  'recall': 0.194,\n",
      "                                  'support': 1000},\n",
      "                           '87': {'f1-score': 0.14264919941775836,\n",
      "                                  'precision': 0.2620320855614973,\n",
      "                                  'recall': 0.098,\n",
      "                                  'support': 1000},\n",
      "                           '88': {'f1-score': 0.27277302466029185,\n",
      "                                  'precision': 0.2745694022289767,\n",
      "                                  'recall': 0.271,\n",
      "                                  'support': 1000},\n",
      "                           '89': {'f1-score': 0.0,\n",
      "                                  'precision': 0.0,\n",
      "                                  'recall': 0.0,\n",
      "                                  'support': 1000},\n",
      "                           '9': {'f1-score': 0.29962894248608535,\n",
      "                                 'precision': 0.27941176470588236,\n",
      "                                 'recall': 0.323,\n",
      "                                 'support': 1000},\n",
      "                           '90': {'f1-score': 0.22774659182036885,\n",
      "                                  'precision': 0.5748987854251012,\n",
      "                                  'recall': 0.142,\n",
      "                                  'support': 1000},\n",
      "                           'accuracy': 0.31785,\n",
      "                           'macro avg': {'f1-score': 0.30248081733237375,\n",
      "                                         'precision': 0.3504300082138482,\n",
      "                                         'recall': 0.31784999999999997,\n",
      "                                         'support': 80000},\n",
      "                           'weighted avg': {'f1-score': 0.30248081733237375,\n",
      "                                            'precision': 0.3504300082138481,\n",
      "                                            'recall': 0.31785,\n",
      "                                            'support': 80000}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "test_eval_result = model.evaluate(test_labels, test_predictions)\n",
    "pprint.pprint(test_eval_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
